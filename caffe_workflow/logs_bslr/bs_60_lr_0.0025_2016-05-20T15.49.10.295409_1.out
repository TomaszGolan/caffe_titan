2808682
I0523 16:00:35.181205 11620 caffe.cpp:184] Using GPUs 0
I0523 16:00:35.607473 11620 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.0025
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409.prototxt"
I0523 16:00:35.609436 11620 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409.prototxt
I0523 16:00:35.631000 11620 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 16:00:35.631058 11620 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 16:00:35.631407 11620 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 16:00:35.631584 11620 layer_factory.hpp:77] Creating layer data_hdf5
I0523 16:00:35.631608 11620 net.cpp:106] Creating Layer data_hdf5
I0523 16:00:35.631623 11620 net.cpp:411] data_hdf5 -> data
I0523 16:00:35.631656 11620 net.cpp:411] data_hdf5 -> label
I0523 16:00:35.631688 11620 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 16:00:35.638797 11620 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 16:00:35.653688 11620 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 16:00:57.235432 11620 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 16:00:57.240576 11620 net.cpp:150] Setting up data_hdf5
I0523 16:00:57.240622 11620 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 16:00:57.240636 11620 net.cpp:157] Top shape: 60 (60)
I0523 16:00:57.240646 11620 net.cpp:165] Memory required for data: 1524240
I0523 16:00:57.240660 11620 layer_factory.hpp:77] Creating layer conv1
I0523 16:00:57.240694 11620 net.cpp:106] Creating Layer conv1
I0523 16:00:57.240705 11620 net.cpp:454] conv1 <- data
I0523 16:00:57.240727 11620 net.cpp:411] conv1 -> conv1
I0523 16:01:00.174109 11620 net.cpp:150] Setting up conv1
I0523 16:01:00.174157 11620 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:01:00.174170 11620 net.cpp:165] Memory required for data: 18113040
I0523 16:01:00.174198 11620 layer_factory.hpp:77] Creating layer relu1
I0523 16:01:00.174219 11620 net.cpp:106] Creating Layer relu1
I0523 16:01:00.174231 11620 net.cpp:454] relu1 <- conv1
I0523 16:01:00.174244 11620 net.cpp:397] relu1 -> conv1 (in-place)
I0523 16:01:00.174756 11620 net.cpp:150] Setting up relu1
I0523 16:01:00.174772 11620 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:01:00.174782 11620 net.cpp:165] Memory required for data: 34701840
I0523 16:01:00.174793 11620 layer_factory.hpp:77] Creating layer pool1
I0523 16:01:00.174808 11620 net.cpp:106] Creating Layer pool1
I0523 16:01:00.174818 11620 net.cpp:454] pool1 <- conv1
I0523 16:01:00.174830 11620 net.cpp:411] pool1 -> pool1
I0523 16:01:00.174909 11620 net.cpp:150] Setting up pool1
I0523 16:01:00.174922 11620 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 16:01:00.174932 11620 net.cpp:165] Memory required for data: 42996240
I0523 16:01:00.174942 11620 layer_factory.hpp:77] Creating layer conv2
I0523 16:01:00.174963 11620 net.cpp:106] Creating Layer conv2
I0523 16:01:00.174973 11620 net.cpp:454] conv2 <- pool1
I0523 16:01:00.174986 11620 net.cpp:411] conv2 -> conv2
I0523 16:01:00.177726 11620 net.cpp:150] Setting up conv2
I0523 16:01:00.177754 11620 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:01:00.177765 11620 net.cpp:165] Memory required for data: 54919440
I0523 16:01:00.177784 11620 layer_factory.hpp:77] Creating layer relu2
I0523 16:01:00.177799 11620 net.cpp:106] Creating Layer relu2
I0523 16:01:00.177809 11620 net.cpp:454] relu2 <- conv2
I0523 16:01:00.177822 11620 net.cpp:397] relu2 -> conv2 (in-place)
I0523 16:01:00.178154 11620 net.cpp:150] Setting up relu2
I0523 16:01:00.178169 11620 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:01:00.178179 11620 net.cpp:165] Memory required for data: 66842640
I0523 16:01:00.178189 11620 layer_factory.hpp:77] Creating layer pool2
I0523 16:01:00.178201 11620 net.cpp:106] Creating Layer pool2
I0523 16:01:00.178211 11620 net.cpp:454] pool2 <- conv2
I0523 16:01:00.178225 11620 net.cpp:411] pool2 -> pool2
I0523 16:01:00.178304 11620 net.cpp:150] Setting up pool2
I0523 16:01:00.178318 11620 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 16:01:00.178328 11620 net.cpp:165] Memory required for data: 72804240
I0523 16:01:00.178338 11620 layer_factory.hpp:77] Creating layer conv3
I0523 16:01:00.178356 11620 net.cpp:106] Creating Layer conv3
I0523 16:01:00.178367 11620 net.cpp:454] conv3 <- pool2
I0523 16:01:00.178380 11620 net.cpp:411] conv3 -> conv3
I0523 16:01:00.180321 11620 net.cpp:150] Setting up conv3
I0523 16:01:00.180343 11620 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:01:00.180356 11620 net.cpp:165] Memory required for data: 79309200
I0523 16:01:00.180374 11620 layer_factory.hpp:77] Creating layer relu3
I0523 16:01:00.180392 11620 net.cpp:106] Creating Layer relu3
I0523 16:01:00.180402 11620 net.cpp:454] relu3 <- conv3
I0523 16:01:00.180413 11620 net.cpp:397] relu3 -> conv3 (in-place)
I0523 16:01:00.180882 11620 net.cpp:150] Setting up relu3
I0523 16:01:00.180899 11620 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:01:00.180909 11620 net.cpp:165] Memory required for data: 85814160
I0523 16:01:00.180919 11620 layer_factory.hpp:77] Creating layer pool3
I0523 16:01:00.180932 11620 net.cpp:106] Creating Layer pool3
I0523 16:01:00.180943 11620 net.cpp:454] pool3 <- conv3
I0523 16:01:00.180955 11620 net.cpp:411] pool3 -> pool3
I0523 16:01:00.181022 11620 net.cpp:150] Setting up pool3
I0523 16:01:00.181035 11620 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 16:01:00.181046 11620 net.cpp:165] Memory required for data: 89066640
I0523 16:01:00.181054 11620 layer_factory.hpp:77] Creating layer conv4
I0523 16:01:00.181071 11620 net.cpp:106] Creating Layer conv4
I0523 16:01:00.181082 11620 net.cpp:454] conv4 <- pool3
I0523 16:01:00.181095 11620 net.cpp:411] conv4 -> conv4
I0523 16:01:00.183845 11620 net.cpp:150] Setting up conv4
I0523 16:01:00.183872 11620 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:01:00.183883 11620 net.cpp:165] Memory required for data: 91243920
I0523 16:01:00.183898 11620 layer_factory.hpp:77] Creating layer relu4
I0523 16:01:00.183913 11620 net.cpp:106] Creating Layer relu4
I0523 16:01:00.183923 11620 net.cpp:454] relu4 <- conv4
I0523 16:01:00.183936 11620 net.cpp:397] relu4 -> conv4 (in-place)
I0523 16:01:00.184415 11620 net.cpp:150] Setting up relu4
I0523 16:01:00.184432 11620 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:01:00.184442 11620 net.cpp:165] Memory required for data: 93421200
I0523 16:01:00.184453 11620 layer_factory.hpp:77] Creating layer pool4
I0523 16:01:00.184465 11620 net.cpp:106] Creating Layer pool4
I0523 16:01:00.184475 11620 net.cpp:454] pool4 <- conv4
I0523 16:01:00.184489 11620 net.cpp:411] pool4 -> pool4
I0523 16:01:00.184556 11620 net.cpp:150] Setting up pool4
I0523 16:01:00.184569 11620 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 16:01:00.184579 11620 net.cpp:165] Memory required for data: 94509840
I0523 16:01:00.184589 11620 layer_factory.hpp:77] Creating layer ip1
I0523 16:01:00.184607 11620 net.cpp:106] Creating Layer ip1
I0523 16:01:00.184618 11620 net.cpp:454] ip1 <- pool4
I0523 16:01:00.184631 11620 net.cpp:411] ip1 -> ip1
I0523 16:01:00.200126 11620 net.cpp:150] Setting up ip1
I0523 16:01:00.200155 11620 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:01:00.200173 11620 net.cpp:165] Memory required for data: 94556880
I0523 16:01:00.200199 11620 layer_factory.hpp:77] Creating layer relu5
I0523 16:01:00.200214 11620 net.cpp:106] Creating Layer relu5
I0523 16:01:00.200224 11620 net.cpp:454] relu5 <- ip1
I0523 16:01:00.200238 11620 net.cpp:397] relu5 -> ip1 (in-place)
I0523 16:01:00.200580 11620 net.cpp:150] Setting up relu5
I0523 16:01:00.200594 11620 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:01:00.200604 11620 net.cpp:165] Memory required for data: 94603920
I0523 16:01:00.200615 11620 layer_factory.hpp:77] Creating layer drop1
I0523 16:01:00.200636 11620 net.cpp:106] Creating Layer drop1
I0523 16:01:00.200646 11620 net.cpp:454] drop1 <- ip1
I0523 16:01:00.200659 11620 net.cpp:397] drop1 -> ip1 (in-place)
I0523 16:01:00.200718 11620 net.cpp:150] Setting up drop1
I0523 16:01:00.200731 11620 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:01:00.200742 11620 net.cpp:165] Memory required for data: 94650960
I0523 16:01:00.200752 11620 layer_factory.hpp:77] Creating layer ip2
I0523 16:01:00.200769 11620 net.cpp:106] Creating Layer ip2
I0523 16:01:00.200780 11620 net.cpp:454] ip2 <- ip1
I0523 16:01:00.200793 11620 net.cpp:411] ip2 -> ip2
I0523 16:01:00.201256 11620 net.cpp:150] Setting up ip2
I0523 16:01:00.201268 11620 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:01:00.201278 11620 net.cpp:165] Memory required for data: 94674480
I0523 16:01:00.201293 11620 layer_factory.hpp:77] Creating layer relu6
I0523 16:01:00.201305 11620 net.cpp:106] Creating Layer relu6
I0523 16:01:00.201315 11620 net.cpp:454] relu6 <- ip2
I0523 16:01:00.201328 11620 net.cpp:397] relu6 -> ip2 (in-place)
I0523 16:01:00.201845 11620 net.cpp:150] Setting up relu6
I0523 16:01:00.201863 11620 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:01:00.201874 11620 net.cpp:165] Memory required for data: 94698000
I0523 16:01:00.201884 11620 layer_factory.hpp:77] Creating layer drop2
I0523 16:01:00.201896 11620 net.cpp:106] Creating Layer drop2
I0523 16:01:00.201906 11620 net.cpp:454] drop2 <- ip2
I0523 16:01:00.201918 11620 net.cpp:397] drop2 -> ip2 (in-place)
I0523 16:01:00.201961 11620 net.cpp:150] Setting up drop2
I0523 16:01:00.201974 11620 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:01:00.201985 11620 net.cpp:165] Memory required for data: 94721520
I0523 16:01:00.201994 11620 layer_factory.hpp:77] Creating layer ip3
I0523 16:01:00.202008 11620 net.cpp:106] Creating Layer ip3
I0523 16:01:00.202018 11620 net.cpp:454] ip3 <- ip2
I0523 16:01:00.202030 11620 net.cpp:411] ip3 -> ip3
I0523 16:01:00.202241 11620 net.cpp:150] Setting up ip3
I0523 16:01:00.202255 11620 net.cpp:157] Top shape: 60 11 (660)
I0523 16:01:00.202263 11620 net.cpp:165] Memory required for data: 94724160
I0523 16:01:00.202280 11620 layer_factory.hpp:77] Creating layer drop3
I0523 16:01:00.202291 11620 net.cpp:106] Creating Layer drop3
I0523 16:01:00.202301 11620 net.cpp:454] drop3 <- ip3
I0523 16:01:00.202312 11620 net.cpp:397] drop3 -> ip3 (in-place)
I0523 16:01:00.202353 11620 net.cpp:150] Setting up drop3
I0523 16:01:00.202364 11620 net.cpp:157] Top shape: 60 11 (660)
I0523 16:01:00.202375 11620 net.cpp:165] Memory required for data: 94726800
I0523 16:01:00.202384 11620 layer_factory.hpp:77] Creating layer loss
I0523 16:01:00.202404 11620 net.cpp:106] Creating Layer loss
I0523 16:01:00.202414 11620 net.cpp:454] loss <- ip3
I0523 16:01:00.202425 11620 net.cpp:454] loss <- label
I0523 16:01:00.202437 11620 net.cpp:411] loss -> loss
I0523 16:01:00.202455 11620 layer_factory.hpp:77] Creating layer loss
I0523 16:01:00.203090 11620 net.cpp:150] Setting up loss
I0523 16:01:00.203112 11620 net.cpp:157] Top shape: (1)
I0523 16:01:00.203125 11620 net.cpp:160]     with loss weight 1
I0523 16:01:00.203166 11620 net.cpp:165] Memory required for data: 94726804
I0523 16:01:00.203177 11620 net.cpp:226] loss needs backward computation.
I0523 16:01:00.203188 11620 net.cpp:226] drop3 needs backward computation.
I0523 16:01:00.203197 11620 net.cpp:226] ip3 needs backward computation.
I0523 16:01:00.203207 11620 net.cpp:226] drop2 needs backward computation.
I0523 16:01:00.203217 11620 net.cpp:226] relu6 needs backward computation.
I0523 16:01:00.203227 11620 net.cpp:226] ip2 needs backward computation.
I0523 16:01:00.203236 11620 net.cpp:226] drop1 needs backward computation.
I0523 16:01:00.203246 11620 net.cpp:226] relu5 needs backward computation.
I0523 16:01:00.203256 11620 net.cpp:226] ip1 needs backward computation.
I0523 16:01:00.203266 11620 net.cpp:226] pool4 needs backward computation.
I0523 16:01:00.203277 11620 net.cpp:226] relu4 needs backward computation.
I0523 16:01:00.203286 11620 net.cpp:226] conv4 needs backward computation.
I0523 16:01:00.203297 11620 net.cpp:226] pool3 needs backward computation.
I0523 16:01:00.203307 11620 net.cpp:226] relu3 needs backward computation.
I0523 16:01:00.203317 11620 net.cpp:226] conv3 needs backward computation.
I0523 16:01:00.203336 11620 net.cpp:226] pool2 needs backward computation.
I0523 16:01:00.203347 11620 net.cpp:226] relu2 needs backward computation.
I0523 16:01:00.203357 11620 net.cpp:226] conv2 needs backward computation.
I0523 16:01:00.203367 11620 net.cpp:226] pool1 needs backward computation.
I0523 16:01:00.203378 11620 net.cpp:226] relu1 needs backward computation.
I0523 16:01:00.203388 11620 net.cpp:226] conv1 needs backward computation.
I0523 16:01:00.203399 11620 net.cpp:228] data_hdf5 does not need backward computation.
I0523 16:01:00.203409 11620 net.cpp:270] This network produces output loss
I0523 16:01:00.203433 11620 net.cpp:283] Network initialization done.
I0523 16:01:00.205193 11620 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409.prototxt
I0523 16:01:00.205265 11620 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 16:01:00.205621 11620 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 16:01:00.205811 11620 layer_factory.hpp:77] Creating layer data_hdf5
I0523 16:01:00.205826 11620 net.cpp:106] Creating Layer data_hdf5
I0523 16:01:00.205839 11620 net.cpp:411] data_hdf5 -> data
I0523 16:01:00.205855 11620 net.cpp:411] data_hdf5 -> label
I0523 16:01:00.205871 11620 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 16:01:00.215116 11620 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 16:01:21.575896 11620 net.cpp:150] Setting up data_hdf5
I0523 16:01:21.576067 11620 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 16:01:21.576082 11620 net.cpp:157] Top shape: 60 (60)
I0523 16:01:21.576092 11620 net.cpp:165] Memory required for data: 1524240
I0523 16:01:21.576107 11620 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 16:01:21.576134 11620 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 16:01:21.576145 11620 net.cpp:454] label_data_hdf5_1_split <- label
I0523 16:01:21.576159 11620 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 16:01:21.576180 11620 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 16:01:21.576251 11620 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 16:01:21.576266 11620 net.cpp:157] Top shape: 60 (60)
I0523 16:01:21.576277 11620 net.cpp:157] Top shape: 60 (60)
I0523 16:01:21.576287 11620 net.cpp:165] Memory required for data: 1524720
I0523 16:01:21.576297 11620 layer_factory.hpp:77] Creating layer conv1
I0523 16:01:21.576316 11620 net.cpp:106] Creating Layer conv1
I0523 16:01:21.576326 11620 net.cpp:454] conv1 <- data
I0523 16:01:21.576341 11620 net.cpp:411] conv1 -> conv1
I0523 16:01:21.578310 11620 net.cpp:150] Setting up conv1
I0523 16:01:21.578330 11620 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:01:21.578341 11620 net.cpp:165] Memory required for data: 18113520
I0523 16:01:21.578361 11620 layer_factory.hpp:77] Creating layer relu1
I0523 16:01:21.578375 11620 net.cpp:106] Creating Layer relu1
I0523 16:01:21.578385 11620 net.cpp:454] relu1 <- conv1
I0523 16:01:21.578398 11620 net.cpp:397] relu1 -> conv1 (in-place)
I0523 16:01:21.578899 11620 net.cpp:150] Setting up relu1
I0523 16:01:21.578915 11620 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:01:21.578925 11620 net.cpp:165] Memory required for data: 34702320
I0523 16:01:21.578936 11620 layer_factory.hpp:77] Creating layer pool1
I0523 16:01:21.578953 11620 net.cpp:106] Creating Layer pool1
I0523 16:01:21.578963 11620 net.cpp:454] pool1 <- conv1
I0523 16:01:21.578975 11620 net.cpp:411] pool1 -> pool1
I0523 16:01:21.579051 11620 net.cpp:150] Setting up pool1
I0523 16:01:21.579064 11620 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 16:01:21.579073 11620 net.cpp:165] Memory required for data: 42996720
I0523 16:01:21.579082 11620 layer_factory.hpp:77] Creating layer conv2
I0523 16:01:21.579099 11620 net.cpp:106] Creating Layer conv2
I0523 16:01:21.579109 11620 net.cpp:454] conv2 <- pool1
I0523 16:01:21.579124 11620 net.cpp:411] conv2 -> conv2
I0523 16:01:21.581043 11620 net.cpp:150] Setting up conv2
I0523 16:01:21.581065 11620 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:01:21.581079 11620 net.cpp:165] Memory required for data: 54919920
I0523 16:01:21.581094 11620 layer_factory.hpp:77] Creating layer relu2
I0523 16:01:21.581109 11620 net.cpp:106] Creating Layer relu2
I0523 16:01:21.581118 11620 net.cpp:454] relu2 <- conv2
I0523 16:01:21.581131 11620 net.cpp:397] relu2 -> conv2 (in-place)
I0523 16:01:21.581464 11620 net.cpp:150] Setting up relu2
I0523 16:01:21.581477 11620 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:01:21.581487 11620 net.cpp:165] Memory required for data: 66843120
I0523 16:01:21.581497 11620 layer_factory.hpp:77] Creating layer pool2
I0523 16:01:21.581511 11620 net.cpp:106] Creating Layer pool2
I0523 16:01:21.581521 11620 net.cpp:454] pool2 <- conv2
I0523 16:01:21.581533 11620 net.cpp:411] pool2 -> pool2
I0523 16:01:21.581604 11620 net.cpp:150] Setting up pool2
I0523 16:01:21.581616 11620 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 16:01:21.581626 11620 net.cpp:165] Memory required for data: 72804720
I0523 16:01:21.581636 11620 layer_factory.hpp:77] Creating layer conv3
I0523 16:01:21.581655 11620 net.cpp:106] Creating Layer conv3
I0523 16:01:21.581665 11620 net.cpp:454] conv3 <- pool2
I0523 16:01:21.581681 11620 net.cpp:411] conv3 -> conv3
I0523 16:01:21.583639 11620 net.cpp:150] Setting up conv3
I0523 16:01:21.583662 11620 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:01:21.583674 11620 net.cpp:165] Memory required for data: 79309680
I0523 16:01:21.583706 11620 layer_factory.hpp:77] Creating layer relu3
I0523 16:01:21.583719 11620 net.cpp:106] Creating Layer relu3
I0523 16:01:21.583729 11620 net.cpp:454] relu3 <- conv3
I0523 16:01:21.583742 11620 net.cpp:397] relu3 -> conv3 (in-place)
I0523 16:01:21.584218 11620 net.cpp:150] Setting up relu3
I0523 16:01:21.584235 11620 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:01:21.584245 11620 net.cpp:165] Memory required for data: 85814640
I0523 16:01:21.584255 11620 layer_factory.hpp:77] Creating layer pool3
I0523 16:01:21.584270 11620 net.cpp:106] Creating Layer pool3
I0523 16:01:21.584280 11620 net.cpp:454] pool3 <- conv3
I0523 16:01:21.584292 11620 net.cpp:411] pool3 -> pool3
I0523 16:01:21.584364 11620 net.cpp:150] Setting up pool3
I0523 16:01:21.584378 11620 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 16:01:21.584388 11620 net.cpp:165] Memory required for data: 89067120
I0523 16:01:21.584396 11620 layer_factory.hpp:77] Creating layer conv4
I0523 16:01:21.584414 11620 net.cpp:106] Creating Layer conv4
I0523 16:01:21.584424 11620 net.cpp:454] conv4 <- pool3
I0523 16:01:21.584439 11620 net.cpp:411] conv4 -> conv4
I0523 16:01:21.586495 11620 net.cpp:150] Setting up conv4
I0523 16:01:21.586518 11620 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:01:21.586529 11620 net.cpp:165] Memory required for data: 91244400
I0523 16:01:21.586544 11620 layer_factory.hpp:77] Creating layer relu4
I0523 16:01:21.586558 11620 net.cpp:106] Creating Layer relu4
I0523 16:01:21.586567 11620 net.cpp:454] relu4 <- conv4
I0523 16:01:21.586580 11620 net.cpp:397] relu4 -> conv4 (in-place)
I0523 16:01:21.587049 11620 net.cpp:150] Setting up relu4
I0523 16:01:21.587064 11620 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:01:21.587074 11620 net.cpp:165] Memory required for data: 93421680
I0523 16:01:21.587085 11620 layer_factory.hpp:77] Creating layer pool4
I0523 16:01:21.587097 11620 net.cpp:106] Creating Layer pool4
I0523 16:01:21.587106 11620 net.cpp:454] pool4 <- conv4
I0523 16:01:21.587121 11620 net.cpp:411] pool4 -> pool4
I0523 16:01:21.587190 11620 net.cpp:150] Setting up pool4
I0523 16:01:21.587203 11620 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 16:01:21.587213 11620 net.cpp:165] Memory required for data: 94510320
I0523 16:01:21.587222 11620 layer_factory.hpp:77] Creating layer ip1
I0523 16:01:21.587237 11620 net.cpp:106] Creating Layer ip1
I0523 16:01:21.587249 11620 net.cpp:454] ip1 <- pool4
I0523 16:01:21.587261 11620 net.cpp:411] ip1 -> ip1
I0523 16:01:21.602736 11620 net.cpp:150] Setting up ip1
I0523 16:01:21.602764 11620 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:01:21.602777 11620 net.cpp:165] Memory required for data: 94557360
I0523 16:01:21.602799 11620 layer_factory.hpp:77] Creating layer relu5
I0523 16:01:21.602813 11620 net.cpp:106] Creating Layer relu5
I0523 16:01:21.602824 11620 net.cpp:454] relu5 <- ip1
I0523 16:01:21.602838 11620 net.cpp:397] relu5 -> ip1 (in-place)
I0523 16:01:21.603185 11620 net.cpp:150] Setting up relu5
I0523 16:01:21.603199 11620 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:01:21.603209 11620 net.cpp:165] Memory required for data: 94604400
I0523 16:01:21.603219 11620 layer_factory.hpp:77] Creating layer drop1
I0523 16:01:21.603238 11620 net.cpp:106] Creating Layer drop1
I0523 16:01:21.603248 11620 net.cpp:454] drop1 <- ip1
I0523 16:01:21.603261 11620 net.cpp:397] drop1 -> ip1 (in-place)
I0523 16:01:21.603307 11620 net.cpp:150] Setting up drop1
I0523 16:01:21.603319 11620 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:01:21.603330 11620 net.cpp:165] Memory required for data: 94651440
I0523 16:01:21.603339 11620 layer_factory.hpp:77] Creating layer ip2
I0523 16:01:21.603354 11620 net.cpp:106] Creating Layer ip2
I0523 16:01:21.603363 11620 net.cpp:454] ip2 <- ip1
I0523 16:01:21.603377 11620 net.cpp:411] ip2 -> ip2
I0523 16:01:21.603853 11620 net.cpp:150] Setting up ip2
I0523 16:01:21.603866 11620 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:01:21.603876 11620 net.cpp:165] Memory required for data: 94674960
I0523 16:01:21.603891 11620 layer_factory.hpp:77] Creating layer relu6
I0523 16:01:21.603916 11620 net.cpp:106] Creating Layer relu6
I0523 16:01:21.603926 11620 net.cpp:454] relu6 <- ip2
I0523 16:01:21.603940 11620 net.cpp:397] relu6 -> ip2 (in-place)
I0523 16:01:21.604476 11620 net.cpp:150] Setting up relu6
I0523 16:01:21.604501 11620 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:01:21.604511 11620 net.cpp:165] Memory required for data: 94698480
I0523 16:01:21.604521 11620 layer_factory.hpp:77] Creating layer drop2
I0523 16:01:21.604532 11620 net.cpp:106] Creating Layer drop2
I0523 16:01:21.604542 11620 net.cpp:454] drop2 <- ip2
I0523 16:01:21.604557 11620 net.cpp:397] drop2 -> ip2 (in-place)
I0523 16:01:21.604600 11620 net.cpp:150] Setting up drop2
I0523 16:01:21.604614 11620 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:01:21.604624 11620 net.cpp:165] Memory required for data: 94722000
I0523 16:01:21.604634 11620 layer_factory.hpp:77] Creating layer ip3
I0523 16:01:21.604647 11620 net.cpp:106] Creating Layer ip3
I0523 16:01:21.604657 11620 net.cpp:454] ip3 <- ip2
I0523 16:01:21.604671 11620 net.cpp:411] ip3 -> ip3
I0523 16:01:21.604894 11620 net.cpp:150] Setting up ip3
I0523 16:01:21.604908 11620 net.cpp:157] Top shape: 60 11 (660)
I0523 16:01:21.604918 11620 net.cpp:165] Memory required for data: 94724640
I0523 16:01:21.604933 11620 layer_factory.hpp:77] Creating layer drop3
I0523 16:01:21.604946 11620 net.cpp:106] Creating Layer drop3
I0523 16:01:21.604956 11620 net.cpp:454] drop3 <- ip3
I0523 16:01:21.604969 11620 net.cpp:397] drop3 -> ip3 (in-place)
I0523 16:01:21.605010 11620 net.cpp:150] Setting up drop3
I0523 16:01:21.605023 11620 net.cpp:157] Top shape: 60 11 (660)
I0523 16:01:21.605033 11620 net.cpp:165] Memory required for data: 94727280
I0523 16:01:21.605042 11620 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 16:01:21.605057 11620 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 16:01:21.605065 11620 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 16:01:21.605078 11620 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 16:01:21.605093 11620 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 16:01:21.605167 11620 net.cpp:150] Setting up ip3_drop3_0_split
I0523 16:01:21.605180 11620 net.cpp:157] Top shape: 60 11 (660)
I0523 16:01:21.605193 11620 net.cpp:157] Top shape: 60 11 (660)
I0523 16:01:21.605203 11620 net.cpp:165] Memory required for data: 94732560
I0523 16:01:21.605213 11620 layer_factory.hpp:77] Creating layer accuracy
I0523 16:01:21.605234 11620 net.cpp:106] Creating Layer accuracy
I0523 16:01:21.605244 11620 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 16:01:21.605255 11620 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 16:01:21.605269 11620 net.cpp:411] accuracy -> accuracy
I0523 16:01:21.605293 11620 net.cpp:150] Setting up accuracy
I0523 16:01:21.605305 11620 net.cpp:157] Top shape: (1)
I0523 16:01:21.605315 11620 net.cpp:165] Memory required for data: 94732564
I0523 16:01:21.605325 11620 layer_factory.hpp:77] Creating layer loss
I0523 16:01:21.605340 11620 net.cpp:106] Creating Layer loss
I0523 16:01:21.605350 11620 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 16:01:21.605360 11620 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 16:01:21.605372 11620 net.cpp:411] loss -> loss
I0523 16:01:21.605391 11620 layer_factory.hpp:77] Creating layer loss
I0523 16:01:21.605875 11620 net.cpp:150] Setting up loss
I0523 16:01:21.605890 11620 net.cpp:157] Top shape: (1)
I0523 16:01:21.605900 11620 net.cpp:160]     with loss weight 1
I0523 16:01:21.605917 11620 net.cpp:165] Memory required for data: 94732568
I0523 16:01:21.605927 11620 net.cpp:226] loss needs backward computation.
I0523 16:01:21.605937 11620 net.cpp:228] accuracy does not need backward computation.
I0523 16:01:21.605949 11620 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 16:01:21.605959 11620 net.cpp:226] drop3 needs backward computation.
I0523 16:01:21.605967 11620 net.cpp:226] ip3 needs backward computation.
I0523 16:01:21.605978 11620 net.cpp:226] drop2 needs backward computation.
I0523 16:01:21.605988 11620 net.cpp:226] relu6 needs backward computation.
I0523 16:01:21.606005 11620 net.cpp:226] ip2 needs backward computation.
I0523 16:01:21.606015 11620 net.cpp:226] drop1 needs backward computation.
I0523 16:01:21.606025 11620 net.cpp:226] relu5 needs backward computation.
I0523 16:01:21.606034 11620 net.cpp:226] ip1 needs backward computation.
I0523 16:01:21.606045 11620 net.cpp:226] pool4 needs backward computation.
I0523 16:01:21.606055 11620 net.cpp:226] relu4 needs backward computation.
I0523 16:01:21.606065 11620 net.cpp:226] conv4 needs backward computation.
I0523 16:01:21.606073 11620 net.cpp:226] pool3 needs backward computation.
I0523 16:01:21.606084 11620 net.cpp:226] relu3 needs backward computation.
I0523 16:01:21.606094 11620 net.cpp:226] conv3 needs backward computation.
I0523 16:01:21.606104 11620 net.cpp:226] pool2 needs backward computation.
I0523 16:01:21.606114 11620 net.cpp:226] relu2 needs backward computation.
I0523 16:01:21.606124 11620 net.cpp:226] conv2 needs backward computation.
I0523 16:01:21.606134 11620 net.cpp:226] pool1 needs backward computation.
I0523 16:01:21.606144 11620 net.cpp:226] relu1 needs backward computation.
I0523 16:01:21.606154 11620 net.cpp:226] conv1 needs backward computation.
I0523 16:01:21.606165 11620 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 16:01:21.606178 11620 net.cpp:228] data_hdf5 does not need backward computation.
I0523 16:01:21.606186 11620 net.cpp:270] This network produces output accuracy
I0523 16:01:21.606195 11620 net.cpp:270] This network produces output loss
I0523 16:01:21.606225 11620 net.cpp:283] Network initialization done.
I0523 16:01:21.606358 11620 solver.cpp:60] Solver scaffolding done.
I0523 16:01:21.607486 11620 caffe.cpp:212] Starting Optimization
I0523 16:01:21.607506 11620 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 16:01:21.607518 11620 solver.cpp:289] Learning Rate Policy: fixed
I0523 16:01:21.608742 11620 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 16:02:09.802172 11620 solver.cpp:409]     Test net output #0: accuracy = 0.107794
I0523 16:02:09.802331 11620 solver.cpp:409]     Test net output #1: loss = 2.39654 (* 1 = 2.39654 loss)
I0523 16:02:09.828171 11620 solver.cpp:237] Iteration 0, loss = 2.39883
I0523 16:02:09.828207 11620 solver.cpp:253]     Train net output #0: loss = 2.39883 (* 1 = 2.39883 loss)
I0523 16:02:09.828227 11620 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0523 16:02:18.930376 11620 solver.cpp:237] Iteration 250, loss = 2.23351
I0523 16:02:18.930413 11620 solver.cpp:253]     Train net output #0: loss = 2.23351 (* 1 = 2.23351 loss)
I0523 16:02:18.930428 11620 sgd_solver.cpp:106] Iteration 250, lr = 0.0025
I0523 16:02:28.029552 11620 solver.cpp:237] Iteration 500, loss = 2.05006
I0523 16:02:28.029593 11620 solver.cpp:253]     Train net output #0: loss = 2.05006 (* 1 = 2.05006 loss)
I0523 16:02:28.029611 11620 sgd_solver.cpp:106] Iteration 500, lr = 0.0025
I0523 16:02:37.132208 11620 solver.cpp:237] Iteration 750, loss = 1.99451
I0523 16:02:37.132242 11620 solver.cpp:253]     Train net output #0: loss = 1.99451 (* 1 = 1.99451 loss)
I0523 16:02:37.132259 11620 sgd_solver.cpp:106] Iteration 750, lr = 0.0025
I0523 16:02:46.231359 11620 solver.cpp:237] Iteration 1000, loss = 1.74973
I0523 16:02:46.231505 11620 solver.cpp:253]     Train net output #0: loss = 1.74973 (* 1 = 1.74973 loss)
I0523 16:02:46.231518 11620 sgd_solver.cpp:106] Iteration 1000, lr = 0.0025
I0523 16:02:55.321380 11620 solver.cpp:237] Iteration 1250, loss = 1.94159
I0523 16:02:55.321424 11620 solver.cpp:253]     Train net output #0: loss = 1.94159 (* 1 = 1.94159 loss)
I0523 16:02:55.321439 11620 sgd_solver.cpp:106] Iteration 1250, lr = 0.0025
I0523 16:03:04.416591 11620 solver.cpp:237] Iteration 1500, loss = 1.93039
I0523 16:03:04.416626 11620 solver.cpp:253]     Train net output #0: loss = 1.93039 (* 1 = 1.93039 loss)
I0523 16:03:04.416643 11620 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0523 16:03:35.640802 11620 solver.cpp:237] Iteration 1750, loss = 1.81029
I0523 16:03:35.640962 11620 solver.cpp:253]     Train net output #0: loss = 1.81029 (* 1 = 1.81029 loss)
I0523 16:03:35.640976 11620 sgd_solver.cpp:106] Iteration 1750, lr = 0.0025
I0523 16:03:44.740314 11620 solver.cpp:237] Iteration 2000, loss = 1.84373
I0523 16:03:44.740355 11620 solver.cpp:253]     Train net output #0: loss = 1.84373 (* 1 = 1.84373 loss)
I0523 16:03:44.740375 11620 sgd_solver.cpp:106] Iteration 2000, lr = 0.0025
I0523 16:03:53.848700 11620 solver.cpp:237] Iteration 2250, loss = 1.84484
I0523 16:03:53.848736 11620 solver.cpp:253]     Train net output #0: loss = 1.84484 (* 1 = 1.84484 loss)
I0523 16:03:53.848752 11620 sgd_solver.cpp:106] Iteration 2250, lr = 0.0025
I0523 16:04:02.917980 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_2500.caffemodel
I0523 16:04:02.984050 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_2500.solverstate
I0523 16:04:03.020463 11620 solver.cpp:237] Iteration 2500, loss = 1.85514
I0523 16:04:03.020509 11620 solver.cpp:253]     Train net output #0: loss = 1.85514 (* 1 = 1.85514 loss)
I0523 16:04:03.020525 11620 sgd_solver.cpp:106] Iteration 2500, lr = 0.0025
I0523 16:04:12.126087 11620 solver.cpp:237] Iteration 2750, loss = 1.76311
I0523 16:04:12.126237 11620 solver.cpp:253]     Train net output #0: loss = 1.76311 (* 1 = 1.76311 loss)
I0523 16:04:12.126251 11620 sgd_solver.cpp:106] Iteration 2750, lr = 0.0025
I0523 16:04:21.228693 11620 solver.cpp:237] Iteration 3000, loss = 1.52031
I0523 16:04:21.228727 11620 solver.cpp:253]     Train net output #0: loss = 1.52031 (* 1 = 1.52031 loss)
I0523 16:04:21.228744 11620 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0523 16:04:30.336608 11620 solver.cpp:237] Iteration 3250, loss = 1.84989
I0523 16:04:30.336644 11620 solver.cpp:253]     Train net output #0: loss = 1.84989 (* 1 = 1.84989 loss)
I0523 16:04:30.336660 11620 sgd_solver.cpp:106] Iteration 3250, lr = 0.0025
I0523 16:05:01.584074 11620 solver.cpp:237] Iteration 3500, loss = 1.24177
I0523 16:05:01.584228 11620 solver.cpp:253]     Train net output #0: loss = 1.24177 (* 1 = 1.24177 loss)
I0523 16:05:01.584244 11620 sgd_solver.cpp:106] Iteration 3500, lr = 0.0025
I0523 16:05:10.687265 11620 solver.cpp:237] Iteration 3750, loss = 1.72756
I0523 16:05:10.687299 11620 solver.cpp:253]     Train net output #0: loss = 1.72756 (* 1 = 1.72756 loss)
I0523 16:05:10.687314 11620 sgd_solver.cpp:106] Iteration 3750, lr = 0.0025
I0523 16:05:19.790740 11620 solver.cpp:237] Iteration 4000, loss = 1.76553
I0523 16:05:19.790776 11620 solver.cpp:253]     Train net output #0: loss = 1.76553 (* 1 = 1.76553 loss)
I0523 16:05:19.790792 11620 sgd_solver.cpp:106] Iteration 4000, lr = 0.0025
I0523 16:05:28.898797 11620 solver.cpp:237] Iteration 4250, loss = 1.38544
I0523 16:05:28.898843 11620 solver.cpp:253]     Train net output #0: loss = 1.38544 (* 1 = 1.38544 loss)
I0523 16:05:28.898859 11620 sgd_solver.cpp:106] Iteration 4250, lr = 0.0025
I0523 16:05:38.006345 11620 solver.cpp:237] Iteration 4500, loss = 1.68927
I0523 16:05:38.006490 11620 solver.cpp:253]     Train net output #0: loss = 1.68927 (* 1 = 1.68927 loss)
I0523 16:05:38.006505 11620 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0523 16:05:47.111410 11620 solver.cpp:237] Iteration 4750, loss = 1.56234
I0523 16:05:47.111455 11620 solver.cpp:253]     Train net output #0: loss = 1.56234 (* 1 = 1.56234 loss)
I0523 16:05:47.111472 11620 sgd_solver.cpp:106] Iteration 4750, lr = 0.0025
I0523 16:05:56.178588 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_5000.caffemodel
I0523 16:05:56.240777 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_5000.solverstate
I0523 16:05:56.265903 11620 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 16:06:43.505736 11620 solver.cpp:409]     Test net output #0: accuracy = 0.785575
I0523 16:06:43.505895 11620 solver.cpp:409]     Test net output #1: loss = 0.807383 (* 1 = 0.807383 loss)
I0523 16:07:05.665755 11620 solver.cpp:237] Iteration 5000, loss = 1.47701
I0523 16:07:05.665807 11620 solver.cpp:253]     Train net output #0: loss = 1.47701 (* 1 = 1.47701 loss)
I0523 16:07:05.665822 11620 sgd_solver.cpp:106] Iteration 5000, lr = 0.0025
I0523 16:07:14.738768 11620 solver.cpp:237] Iteration 5250, loss = 1.26691
I0523 16:07:14.738910 11620 solver.cpp:253]     Train net output #0: loss = 1.26691 (* 1 = 1.26691 loss)
I0523 16:07:14.738924 11620 sgd_solver.cpp:106] Iteration 5250, lr = 0.0025
I0523 16:07:23.820725 11620 solver.cpp:237] Iteration 5500, loss = 1.62366
I0523 16:07:23.820760 11620 solver.cpp:253]     Train net output #0: loss = 1.62366 (* 1 = 1.62366 loss)
I0523 16:07:23.820775 11620 sgd_solver.cpp:106] Iteration 5500, lr = 0.0025
I0523 16:07:32.891042 11620 solver.cpp:237] Iteration 5750, loss = 1.44923
I0523 16:07:32.891086 11620 solver.cpp:253]     Train net output #0: loss = 1.44923 (* 1 = 1.44923 loss)
I0523 16:07:32.891100 11620 sgd_solver.cpp:106] Iteration 5750, lr = 0.0025
I0523 16:07:41.958297 11620 solver.cpp:237] Iteration 6000, loss = 1.32465
I0523 16:07:41.958326 11620 solver.cpp:253]     Train net output #0: loss = 1.32465 (* 1 = 1.32465 loss)
I0523 16:07:41.958339 11620 sgd_solver.cpp:106] Iteration 6000, lr = 0.0025
I0523 16:07:51.024974 11620 solver.cpp:237] Iteration 6250, loss = 1.29368
I0523 16:07:51.025126 11620 solver.cpp:253]     Train net output #0: loss = 1.29368 (* 1 = 1.29368 loss)
I0523 16:07:51.025140 11620 sgd_solver.cpp:106] Iteration 6250, lr = 0.0025
I0523 16:08:00.109673 11620 solver.cpp:237] Iteration 6500, loss = 1.41595
I0523 16:08:00.109705 11620 solver.cpp:253]     Train net output #0: loss = 1.41595 (* 1 = 1.41595 loss)
I0523 16:08:00.109726 11620 sgd_solver.cpp:106] Iteration 6500, lr = 0.0025
I0523 16:08:31.384981 11620 solver.cpp:237] Iteration 6750, loss = 1.40953
I0523 16:08:31.385136 11620 solver.cpp:253]     Train net output #0: loss = 1.40953 (* 1 = 1.40953 loss)
I0523 16:08:31.385150 11620 sgd_solver.cpp:106] Iteration 6750, lr = 0.0025
I0523 16:08:40.459065 11620 solver.cpp:237] Iteration 7000, loss = 1.14478
I0523 16:08:40.459101 11620 solver.cpp:253]     Train net output #0: loss = 1.14478 (* 1 = 1.14478 loss)
I0523 16:08:40.459115 11620 sgd_solver.cpp:106] Iteration 7000, lr = 0.0025
I0523 16:08:49.536128 11620 solver.cpp:237] Iteration 7250, loss = 1.42157
I0523 16:08:49.536167 11620 solver.cpp:253]     Train net output #0: loss = 1.42157 (* 1 = 1.42157 loss)
I0523 16:08:49.536188 11620 sgd_solver.cpp:106] Iteration 7250, lr = 0.0025
I0523 16:08:58.575686 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_7500.caffemodel
I0523 16:08:58.641460 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_7500.solverstate
I0523 16:08:58.680692 11620 solver.cpp:237] Iteration 7500, loss = 1.28612
I0523 16:08:58.680742 11620 solver.cpp:253]     Train net output #0: loss = 1.28612 (* 1 = 1.28612 loss)
I0523 16:08:58.680755 11620 sgd_solver.cpp:106] Iteration 7500, lr = 0.0025
I0523 16:09:07.757467 11620 solver.cpp:237] Iteration 7750, loss = 1.44531
I0523 16:09:07.757634 11620 solver.cpp:253]     Train net output #0: loss = 1.44531 (* 1 = 1.44531 loss)
I0523 16:09:07.757648 11620 sgd_solver.cpp:106] Iteration 7750, lr = 0.0025
I0523 16:09:16.830334 11620 solver.cpp:237] Iteration 8000, loss = 1.32506
I0523 16:09:16.830368 11620 solver.cpp:253]     Train net output #0: loss = 1.32506 (* 1 = 1.32506 loss)
I0523 16:09:16.830385 11620 sgd_solver.cpp:106] Iteration 8000, lr = 0.0025
I0523 16:09:25.906810 11620 solver.cpp:237] Iteration 8250, loss = 1.2621
I0523 16:09:25.906846 11620 solver.cpp:253]     Train net output #0: loss = 1.2621 (* 1 = 1.2621 loss)
I0523 16:09:25.906862 11620 sgd_solver.cpp:106] Iteration 8250, lr = 0.0025
I0523 16:09:57.239835 11620 solver.cpp:237] Iteration 8500, loss = 1.38935
I0523 16:09:57.239995 11620 solver.cpp:253]     Train net output #0: loss = 1.38935 (* 1 = 1.38935 loss)
I0523 16:09:57.240010 11620 sgd_solver.cpp:106] Iteration 8500, lr = 0.0025
I0523 16:10:06.320674 11620 solver.cpp:237] Iteration 8750, loss = 1.18571
I0523 16:10:06.320708 11620 solver.cpp:253]     Train net output #0: loss = 1.18571 (* 1 = 1.18571 loss)
I0523 16:10:06.320726 11620 sgd_solver.cpp:106] Iteration 8750, lr = 0.0025
I0523 16:10:15.393386 11620 solver.cpp:237] Iteration 9000, loss = 1.55111
I0523 16:10:15.393422 11620 solver.cpp:253]     Train net output #0: loss = 1.55111 (* 1 = 1.55111 loss)
I0523 16:10:15.393440 11620 sgd_solver.cpp:106] Iteration 9000, lr = 0.0025
I0523 16:10:24.472090 11620 solver.cpp:237] Iteration 9250, loss = 1.32386
I0523 16:10:24.472133 11620 solver.cpp:253]     Train net output #0: loss = 1.32386 (* 1 = 1.32386 loss)
I0523 16:10:24.472147 11620 sgd_solver.cpp:106] Iteration 9250, lr = 0.0025
I0523 16:10:33.540948 11620 solver.cpp:237] Iteration 9500, loss = 1.41578
I0523 16:10:33.541103 11620 solver.cpp:253]     Train net output #0: loss = 1.41578 (* 1 = 1.41578 loss)
I0523 16:10:33.541116 11620 sgd_solver.cpp:106] Iteration 9500, lr = 0.0025
I0523 16:10:42.611244 11620 solver.cpp:237] Iteration 9750, loss = 1.16639
I0523 16:10:42.611279 11620 solver.cpp:253]     Train net output #0: loss = 1.16639 (* 1 = 1.16639 loss)
I0523 16:10:42.611296 11620 sgd_solver.cpp:106] Iteration 9750, lr = 0.0025
I0523 16:10:51.644207 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_10000.caffemodel
I0523 16:10:51.709367 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_10000.solverstate
I0523 16:10:51.737407 11620 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 16:11:59.802670 11620 solver.cpp:409]     Test net output #0: accuracy = 0.835741
I0523 16:11:59.802827 11620 solver.cpp:409]     Test net output #1: loss = 0.603287 (* 1 = 0.603287 loss)
I0523 16:12:22.077895 11620 solver.cpp:237] Iteration 10000, loss = 1.17119
I0523 16:12:22.077949 11620 solver.cpp:253]     Train net output #0: loss = 1.17119 (* 1 = 1.17119 loss)
I0523 16:12:22.077963 11620 sgd_solver.cpp:106] Iteration 10000, lr = 0.0025
I0523 16:12:31.193084 11620 solver.cpp:237] Iteration 10250, loss = 1.46389
I0523 16:12:31.193259 11620 solver.cpp:253]     Train net output #0: loss = 1.46389 (* 1 = 1.46389 loss)
I0523 16:12:31.193274 11620 sgd_solver.cpp:106] Iteration 10250, lr = 0.0025
I0523 16:12:40.311280 11620 solver.cpp:237] Iteration 10500, loss = 1.48966
I0523 16:12:40.311312 11620 solver.cpp:253]     Train net output #0: loss = 1.48966 (* 1 = 1.48966 loss)
I0523 16:12:40.311329 11620 sgd_solver.cpp:106] Iteration 10500, lr = 0.0025
I0523 16:12:49.428552 11620 solver.cpp:237] Iteration 10750, loss = 1.35449
I0523 16:12:49.428582 11620 solver.cpp:253]     Train net output #0: loss = 1.35449 (* 1 = 1.35449 loss)
I0523 16:12:49.428596 11620 sgd_solver.cpp:106] Iteration 10750, lr = 0.0025
I0523 16:12:58.538070 11620 solver.cpp:237] Iteration 11000, loss = 1.31167
I0523 16:12:58.538111 11620 solver.cpp:253]     Train net output #0: loss = 1.31167 (* 1 = 1.31167 loss)
I0523 16:12:58.538132 11620 sgd_solver.cpp:106] Iteration 11000, lr = 0.0025
I0523 16:13:07.648766 11620 solver.cpp:237] Iteration 11250, loss = 1.20079
I0523 16:13:07.648908 11620 solver.cpp:253]     Train net output #0: loss = 1.20079 (* 1 = 1.20079 loss)
I0523 16:13:07.648921 11620 sgd_solver.cpp:106] Iteration 11250, lr = 0.0025
I0523 16:13:16.774744 11620 solver.cpp:237] Iteration 11500, loss = 1.50834
I0523 16:13:16.774778 11620 solver.cpp:253]     Train net output #0: loss = 1.50834 (* 1 = 1.50834 loss)
I0523 16:13:16.774796 11620 sgd_solver.cpp:106] Iteration 11500, lr = 0.0025
I0523 16:13:48.117426 11620 solver.cpp:237] Iteration 11750, loss = 1.20479
I0523 16:13:48.117588 11620 solver.cpp:253]     Train net output #0: loss = 1.20479 (* 1 = 1.20479 loss)
I0523 16:13:48.117602 11620 sgd_solver.cpp:106] Iteration 11750, lr = 0.0025
I0523 16:13:57.226008 11620 solver.cpp:237] Iteration 12000, loss = 1.38464
I0523 16:13:57.226043 11620 solver.cpp:253]     Train net output #0: loss = 1.38464 (* 1 = 1.38464 loss)
I0523 16:13:57.226059 11620 sgd_solver.cpp:106] Iteration 12000, lr = 0.0025
I0523 16:14:06.340226 11620 solver.cpp:237] Iteration 12250, loss = 1.14222
I0523 16:14:06.340262 11620 solver.cpp:253]     Train net output #0: loss = 1.14222 (* 1 = 1.14222 loss)
I0523 16:14:06.340276 11620 sgd_solver.cpp:106] Iteration 12250, lr = 0.0025
I0523 16:14:15.424726 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_12500.caffemodel
I0523 16:14:15.489336 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_12500.solverstate
I0523 16:14:15.528048 11620 solver.cpp:237] Iteration 12500, loss = 1.51753
I0523 16:14:15.528101 11620 solver.cpp:253]     Train net output #0: loss = 1.51753 (* 1 = 1.51753 loss)
I0523 16:14:15.528120 11620 sgd_solver.cpp:106] Iteration 12500, lr = 0.0025
I0523 16:14:24.645413 11620 solver.cpp:237] Iteration 12750, loss = 1.56477
I0523 16:14:24.645560 11620 solver.cpp:253]     Train net output #0: loss = 1.56477 (* 1 = 1.56477 loss)
I0523 16:14:24.645575 11620 sgd_solver.cpp:106] Iteration 12750, lr = 0.0025
I0523 16:14:33.758637 11620 solver.cpp:237] Iteration 13000, loss = 1.22185
I0523 16:14:33.758683 11620 solver.cpp:253]     Train net output #0: loss = 1.22185 (* 1 = 1.22185 loss)
I0523 16:14:33.758703 11620 sgd_solver.cpp:106] Iteration 13000, lr = 0.0025
I0523 16:14:42.868001 11620 solver.cpp:237] Iteration 13250, loss = 1.40737
I0523 16:14:42.868036 11620 solver.cpp:253]     Train net output #0: loss = 1.40737 (* 1 = 1.40737 loss)
I0523 16:14:42.868052 11620 sgd_solver.cpp:106] Iteration 13250, lr = 0.0025
I0523 16:15:14.212898 11620 solver.cpp:237] Iteration 13500, loss = 1.40867
I0523 16:15:14.213075 11620 solver.cpp:253]     Train net output #0: loss = 1.40867 (* 1 = 1.40867 loss)
I0523 16:15:14.213089 11620 sgd_solver.cpp:106] Iteration 13500, lr = 0.0025
I0523 16:15:23.328709 11620 solver.cpp:237] Iteration 13750, loss = 1.29424
I0523 16:15:23.328755 11620 solver.cpp:253]     Train net output #0: loss = 1.29424 (* 1 = 1.29424 loss)
I0523 16:15:23.328773 11620 sgd_solver.cpp:106] Iteration 13750, lr = 0.0025
I0523 16:15:32.442724 11620 solver.cpp:237] Iteration 14000, loss = 1.30845
I0523 16:15:32.442760 11620 solver.cpp:253]     Train net output #0: loss = 1.30845 (* 1 = 1.30845 loss)
I0523 16:15:32.442776 11620 sgd_solver.cpp:106] Iteration 14000, lr = 0.0025
I0523 16:15:41.561131 11620 solver.cpp:237] Iteration 14250, loss = 1.3342
I0523 16:15:41.561164 11620 solver.cpp:253]     Train net output #0: loss = 1.3342 (* 1 = 1.3342 loss)
I0523 16:15:41.561180 11620 sgd_solver.cpp:106] Iteration 14250, lr = 0.0025
I0523 16:15:50.661119 11620 solver.cpp:237] Iteration 14500, loss = 1.38167
I0523 16:15:50.661276 11620 solver.cpp:253]     Train net output #0: loss = 1.38167 (* 1 = 1.38167 loss)
I0523 16:15:50.661290 11620 sgd_solver.cpp:106] Iteration 14500, lr = 0.0025
I0523 16:15:59.776581 11620 solver.cpp:237] Iteration 14750, loss = 1.02575
I0523 16:15:59.776615 11620 solver.cpp:253]     Train net output #0: loss = 1.02575 (* 1 = 1.02575 loss)
I0523 16:15:59.776631 11620 sgd_solver.cpp:106] Iteration 14750, lr = 0.0025
I0523 16:16:08.852558 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_15000.caffemodel
I0523 16:16:08.916419 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_15000.solverstate
I0523 16:16:08.941748 11620 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 16:16:55.911128 11620 solver.cpp:409]     Test net output #0: accuracy = 0.836855
I0523 16:16:55.911288 11620 solver.cpp:409]     Test net output #1: loss = 0.622178 (* 1 = 0.622178 loss)
I0523 16:17:18.128387 11620 solver.cpp:237] Iteration 15000, loss = 1.28246
I0523 16:17:18.128440 11620 solver.cpp:253]     Train net output #0: loss = 1.28246 (* 1 = 1.28246 loss)
I0523 16:17:18.128454 11620 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0523 16:17:27.158565 11620 solver.cpp:237] Iteration 15250, loss = 1.08992
I0523 16:17:27.158728 11620 solver.cpp:253]     Train net output #0: loss = 1.08992 (* 1 = 1.08992 loss)
I0523 16:17:27.158742 11620 sgd_solver.cpp:106] Iteration 15250, lr = 0.0025
I0523 16:17:36.188035 11620 solver.cpp:237] Iteration 15500, loss = 1.23766
I0523 16:17:36.188074 11620 solver.cpp:253]     Train net output #0: loss = 1.23766 (* 1 = 1.23766 loss)
I0523 16:17:36.188087 11620 sgd_solver.cpp:106] Iteration 15500, lr = 0.0025
I0523 16:17:45.215804 11620 solver.cpp:237] Iteration 15750, loss = 1.25065
I0523 16:17:45.215839 11620 solver.cpp:253]     Train net output #0: loss = 1.25065 (* 1 = 1.25065 loss)
I0523 16:17:45.215855 11620 sgd_solver.cpp:106] Iteration 15750, lr = 0.0025
I0523 16:17:54.250262 11620 solver.cpp:237] Iteration 16000, loss = 1.33286
I0523 16:17:54.250299 11620 solver.cpp:253]     Train net output #0: loss = 1.33286 (* 1 = 1.33286 loss)
I0523 16:17:54.250318 11620 sgd_solver.cpp:106] Iteration 16000, lr = 0.0025
I0523 16:18:03.277212 11620 solver.cpp:237] Iteration 16250, loss = 1.30465
I0523 16:18:03.277367 11620 solver.cpp:253]     Train net output #0: loss = 1.30465 (* 1 = 1.30465 loss)
I0523 16:18:03.277381 11620 sgd_solver.cpp:106] Iteration 16250, lr = 0.0025
I0523 16:18:12.308235 11620 solver.cpp:237] Iteration 16500, loss = 1.20284
I0523 16:18:12.308269 11620 solver.cpp:253]     Train net output #0: loss = 1.20284 (* 1 = 1.20284 loss)
I0523 16:18:12.308287 11620 sgd_solver.cpp:106] Iteration 16500, lr = 0.0025
I0523 16:18:43.604084 11620 solver.cpp:237] Iteration 16750, loss = 1.17782
I0523 16:18:43.604260 11620 solver.cpp:253]     Train net output #0: loss = 1.17782 (* 1 = 1.17782 loss)
I0523 16:18:43.604276 11620 sgd_solver.cpp:106] Iteration 16750, lr = 0.0025
I0523 16:18:52.633067 11620 solver.cpp:237] Iteration 17000, loss = 1.31336
I0523 16:18:52.633102 11620 solver.cpp:253]     Train net output #0: loss = 1.31336 (* 1 = 1.31336 loss)
I0523 16:18:52.633119 11620 sgd_solver.cpp:106] Iteration 17000, lr = 0.0025
I0523 16:19:01.667858 11620 solver.cpp:237] Iteration 17250, loss = 1.06792
I0523 16:19:01.667893 11620 solver.cpp:253]     Train net output #0: loss = 1.06792 (* 1 = 1.06792 loss)
I0523 16:19:01.667906 11620 sgd_solver.cpp:106] Iteration 17250, lr = 0.0025
I0523 16:19:10.666278 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_17500.caffemodel
I0523 16:19:10.729616 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_17500.solverstate
I0523 16:19:10.767112 11620 solver.cpp:237] Iteration 17500, loss = 1.11064
I0523 16:19:10.767158 11620 solver.cpp:253]     Train net output #0: loss = 1.11064 (* 1 = 1.11064 loss)
I0523 16:19:10.767171 11620 sgd_solver.cpp:106] Iteration 17500, lr = 0.0025
I0523 16:19:19.796803 11620 solver.cpp:237] Iteration 17750, loss = 1.36094
I0523 16:19:19.796947 11620 solver.cpp:253]     Train net output #0: loss = 1.36094 (* 1 = 1.36094 loss)
I0523 16:19:19.796960 11620 sgd_solver.cpp:106] Iteration 17750, lr = 0.0025
I0523 16:19:28.832967 11620 solver.cpp:237] Iteration 18000, loss = 1.48264
I0523 16:19:28.833000 11620 solver.cpp:253]     Train net output #0: loss = 1.48264 (* 1 = 1.48264 loss)
I0523 16:19:28.833019 11620 sgd_solver.cpp:106] Iteration 18000, lr = 0.0025
I0523 16:19:37.858702 11620 solver.cpp:237] Iteration 18250, loss = 1.33562
I0523 16:19:37.858744 11620 solver.cpp:253]     Train net output #0: loss = 1.33562 (* 1 = 1.33562 loss)
I0523 16:19:37.858763 11620 sgd_solver.cpp:106] Iteration 18250, lr = 0.0025
I0523 16:20:09.065971 11620 solver.cpp:237] Iteration 18500, loss = 1.25932
I0523 16:20:09.066139 11620 solver.cpp:253]     Train net output #0: loss = 1.25932 (* 1 = 1.25932 loss)
I0523 16:20:09.066154 11620 sgd_solver.cpp:106] Iteration 18500, lr = 0.0025
I0523 16:20:18.096593 11620 solver.cpp:237] Iteration 18750, loss = 1.31319
I0523 16:20:18.096627 11620 solver.cpp:253]     Train net output #0: loss = 1.31319 (* 1 = 1.31319 loss)
I0523 16:20:18.096644 11620 sgd_solver.cpp:106] Iteration 18750, lr = 0.0025
I0523 16:20:27.127287 11620 solver.cpp:237] Iteration 19000, loss = 1.24866
I0523 16:20:27.127336 11620 solver.cpp:253]     Train net output #0: loss = 1.24866 (* 1 = 1.24866 loss)
I0523 16:20:27.127349 11620 sgd_solver.cpp:106] Iteration 19000, lr = 0.0025
I0523 16:20:36.153424 11620 solver.cpp:237] Iteration 19250, loss = 1.47036
I0523 16:20:36.153460 11620 solver.cpp:253]     Train net output #0: loss = 1.47036 (* 1 = 1.47036 loss)
I0523 16:20:36.153475 11620 sgd_solver.cpp:106] Iteration 19250, lr = 0.0025
I0523 16:20:45.175735 11620 solver.cpp:237] Iteration 19500, loss = 1.4586
I0523 16:20:45.175879 11620 solver.cpp:253]     Train net output #0: loss = 1.4586 (* 1 = 1.4586 loss)
I0523 16:20:45.175892 11620 sgd_solver.cpp:106] Iteration 19500, lr = 0.0025
I0523 16:20:54.197222 11620 solver.cpp:237] Iteration 19750, loss = 1.41387
I0523 16:20:54.197263 11620 solver.cpp:253]     Train net output #0: loss = 1.41387 (* 1 = 1.41387 loss)
I0523 16:20:54.197283 11620 sgd_solver.cpp:106] Iteration 19750, lr = 0.0025
I0523 16:21:03.188371 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_20000.caffemodel
I0523 16:21:03.251299 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_20000.solverstate
I0523 16:21:03.277948 11620 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 16:22:11.378206 11620 solver.cpp:409]     Test net output #0: accuracy = 0.858094
I0523 16:22:11.378389 11620 solver.cpp:409]     Test net output #1: loss = 0.457252 (* 1 = 0.457252 loss)
I0523 16:22:33.586890 11620 solver.cpp:237] Iteration 20000, loss = 1.25408
I0523 16:22:33.586941 11620 solver.cpp:253]     Train net output #0: loss = 1.25408 (* 1 = 1.25408 loss)
I0523 16:22:33.586959 11620 sgd_solver.cpp:106] Iteration 20000, lr = 0.0025
I0523 16:22:42.648730 11620 solver.cpp:237] Iteration 20250, loss = 1.26021
I0523 16:22:42.648885 11620 solver.cpp:253]     Train net output #0: loss = 1.26021 (* 1 = 1.26021 loss)
I0523 16:22:42.648897 11620 sgd_solver.cpp:106] Iteration 20250, lr = 0.0025
I0523 16:22:51.710575 11620 solver.cpp:237] Iteration 20500, loss = 1.26873
I0523 16:22:51.710609 11620 solver.cpp:253]     Train net output #0: loss = 1.26873 (* 1 = 1.26873 loss)
I0523 16:22:51.710625 11620 sgd_solver.cpp:106] Iteration 20500, lr = 0.0025
I0523 16:23:00.768455 11620 solver.cpp:237] Iteration 20750, loss = 1.06699
I0523 16:23:00.768499 11620 solver.cpp:253]     Train net output #0: loss = 1.06699 (* 1 = 1.06699 loss)
I0523 16:23:00.768517 11620 sgd_solver.cpp:106] Iteration 20750, lr = 0.0025
I0523 16:23:09.827265 11620 solver.cpp:237] Iteration 21000, loss = 0.990484
I0523 16:23:09.827301 11620 solver.cpp:253]     Train net output #0: loss = 0.990484 (* 1 = 0.990484 loss)
I0523 16:23:09.827313 11620 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0523 16:23:18.899329 11620 solver.cpp:237] Iteration 21250, loss = 1.38273
I0523 16:23:18.899485 11620 solver.cpp:253]     Train net output #0: loss = 1.38273 (* 1 = 1.38273 loss)
I0523 16:23:18.899499 11620 sgd_solver.cpp:106] Iteration 21250, lr = 0.0025
I0523 16:23:27.960310 11620 solver.cpp:237] Iteration 21500, loss = 1.00728
I0523 16:23:27.960345 11620 solver.cpp:253]     Train net output #0: loss = 1.00728 (* 1 = 1.00728 loss)
I0523 16:23:27.960361 11620 sgd_solver.cpp:106] Iteration 21500, lr = 0.0025
I0523 16:23:59.151381 11620 solver.cpp:237] Iteration 21750, loss = 1.20991
I0523 16:23:59.151548 11620 solver.cpp:253]     Train net output #0: loss = 1.20991 (* 1 = 1.20991 loss)
I0523 16:23:59.151562 11620 sgd_solver.cpp:106] Iteration 21750, lr = 0.0025
I0523 16:24:08.214319 11620 solver.cpp:237] Iteration 22000, loss = 1.47605
I0523 16:24:08.214362 11620 solver.cpp:253]     Train net output #0: loss = 1.47605 (* 1 = 1.47605 loss)
I0523 16:24:08.214381 11620 sgd_solver.cpp:106] Iteration 22000, lr = 0.0025
I0523 16:24:17.276707 11620 solver.cpp:237] Iteration 22250, loss = 1.29039
I0523 16:24:17.276742 11620 solver.cpp:253]     Train net output #0: loss = 1.29039 (* 1 = 1.29039 loss)
I0523 16:24:17.276758 11620 sgd_solver.cpp:106] Iteration 22250, lr = 0.0025
I0523 16:24:26.298315 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_22500.caffemodel
I0523 16:24:26.364289 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_22500.solverstate
I0523 16:24:26.404422 11620 solver.cpp:237] Iteration 22500, loss = 1.43117
I0523 16:24:26.404471 11620 solver.cpp:253]     Train net output #0: loss = 1.43117 (* 1 = 1.43117 loss)
I0523 16:24:26.404489 11620 sgd_solver.cpp:106] Iteration 22500, lr = 0.0025
I0523 16:24:35.473034 11620 solver.cpp:237] Iteration 22750, loss = 1.29977
I0523 16:24:35.473196 11620 solver.cpp:253]     Train net output #0: loss = 1.29977 (* 1 = 1.29977 loss)
I0523 16:24:35.473209 11620 sgd_solver.cpp:106] Iteration 22750, lr = 0.0025
I0523 16:24:44.540873 11620 solver.cpp:237] Iteration 23000, loss = 1.38398
I0523 16:24:44.540906 11620 solver.cpp:253]     Train net output #0: loss = 1.38398 (* 1 = 1.38398 loss)
I0523 16:24:44.540925 11620 sgd_solver.cpp:106] Iteration 23000, lr = 0.0025
I0523 16:24:53.605584 11620 solver.cpp:237] Iteration 23250, loss = 1.27488
I0523 16:24:53.605619 11620 solver.cpp:253]     Train net output #0: loss = 1.27488 (* 1 = 1.27488 loss)
I0523 16:24:53.605635 11620 sgd_solver.cpp:106] Iteration 23250, lr = 0.0025
I0523 16:25:24.894155 11620 solver.cpp:237] Iteration 23500, loss = 1.08373
I0523 16:25:24.894330 11620 solver.cpp:253]     Train net output #0: loss = 1.08373 (* 1 = 1.08373 loss)
I0523 16:25:24.894345 11620 sgd_solver.cpp:106] Iteration 23500, lr = 0.0025
I0523 16:25:33.960046 11620 solver.cpp:237] Iteration 23750, loss = 1.22364
I0523 16:25:33.960085 11620 solver.cpp:253]     Train net output #0: loss = 1.22364 (* 1 = 1.22364 loss)
I0523 16:25:33.960103 11620 sgd_solver.cpp:106] Iteration 23750, lr = 0.0025
I0523 16:25:43.021422 11620 solver.cpp:237] Iteration 24000, loss = 1.38688
I0523 16:25:43.021456 11620 solver.cpp:253]     Train net output #0: loss = 1.38688 (* 1 = 1.38688 loss)
I0523 16:25:43.021473 11620 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0523 16:25:52.068559 11620 solver.cpp:237] Iteration 24250, loss = 1.43132
I0523 16:25:52.068605 11620 solver.cpp:253]     Train net output #0: loss = 1.43132 (* 1 = 1.43132 loss)
I0523 16:25:52.068621 11620 sgd_solver.cpp:106] Iteration 24250, lr = 0.0025
I0523 16:26:01.126770 11620 solver.cpp:237] Iteration 24500, loss = 1.34856
I0523 16:26:01.126919 11620 solver.cpp:253]     Train net output #0: loss = 1.34856 (* 1 = 1.34856 loss)
I0523 16:26:01.126932 11620 sgd_solver.cpp:106] Iteration 24500, lr = 0.0025
I0523 16:26:10.186007 11620 solver.cpp:237] Iteration 24750, loss = 1.11922
I0523 16:26:10.186041 11620 solver.cpp:253]     Train net output #0: loss = 1.11922 (* 1 = 1.11922 loss)
I0523 16:26:10.186054 11620 sgd_solver.cpp:106] Iteration 24750, lr = 0.0025
I0523 16:26:19.218963 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_25000.caffemodel
I0523 16:26:19.284370 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_25000.solverstate
I0523 16:26:19.312818 11620 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 16:27:06.632458 11620 solver.cpp:409]     Test net output #0: accuracy = 0.8654
I0523 16:27:06.632622 11620 solver.cpp:409]     Test net output #1: loss = 0.425826 (* 1 = 0.425826 loss)
I0523 16:27:27.528302 11620 solver.cpp:237] Iteration 25000, loss = 1.18575
I0523 16:27:27.528353 11620 solver.cpp:253]     Train net output #0: loss = 1.18575 (* 1 = 1.18575 loss)
I0523 16:27:27.528373 11620 sgd_solver.cpp:106] Iteration 25000, lr = 0.0025
I0523 16:27:36.538012 11620 solver.cpp:237] Iteration 25250, loss = 1.06974
I0523 16:27:36.538045 11620 solver.cpp:253]     Train net output #0: loss = 1.06974 (* 1 = 1.06974 loss)
I0523 16:27:36.538064 11620 sgd_solver.cpp:106] Iteration 25250, lr = 0.0025
I0523 16:27:45.547014 11620 solver.cpp:237] Iteration 25500, loss = 1.50495
I0523 16:27:45.547168 11620 solver.cpp:253]     Train net output #0: loss = 1.50495 (* 1 = 1.50495 loss)
I0523 16:27:45.547181 11620 sgd_solver.cpp:106] Iteration 25500, lr = 0.0025
I0523 16:27:54.562150 11620 solver.cpp:237] Iteration 25750, loss = 1.11316
I0523 16:27:54.562192 11620 solver.cpp:253]     Train net output #0: loss = 1.11316 (* 1 = 1.11316 loss)
I0523 16:27:54.562212 11620 sgd_solver.cpp:106] Iteration 25750, lr = 0.0025
I0523 16:28:03.567405 11620 solver.cpp:237] Iteration 26000, loss = 1.42011
I0523 16:28:03.567440 11620 solver.cpp:253]     Train net output #0: loss = 1.42011 (* 1 = 1.42011 loss)
I0523 16:28:03.567456 11620 sgd_solver.cpp:106] Iteration 26000, lr = 0.0025
I0523 16:28:12.575785 11620 solver.cpp:237] Iteration 26250, loss = 1.35304
I0523 16:28:12.575820 11620 solver.cpp:253]     Train net output #0: loss = 1.35304 (* 1 = 1.35304 loss)
I0523 16:28:12.575837 11620 sgd_solver.cpp:106] Iteration 26250, lr = 0.0025
I0523 16:28:21.593595 11620 solver.cpp:237] Iteration 26500, loss = 1.12131
I0523 16:28:21.593760 11620 solver.cpp:253]     Train net output #0: loss = 1.12131 (* 1 = 1.12131 loss)
I0523 16:28:21.593775 11620 sgd_solver.cpp:106] Iteration 26500, lr = 0.0025
I0523 16:28:51.495618 11620 solver.cpp:237] Iteration 26750, loss = 1.02828
I0523 16:28:51.495667 11620 solver.cpp:253]     Train net output #0: loss = 1.02828 (* 1 = 1.02828 loss)
I0523 16:28:51.495682 11620 sgd_solver.cpp:106] Iteration 26750, lr = 0.0025
I0523 16:29:00.506033 11620 solver.cpp:237] Iteration 27000, loss = 1.16142
I0523 16:29:00.506178 11620 solver.cpp:253]     Train net output #0: loss = 1.16142 (* 1 = 1.16142 loss)
I0523 16:29:00.506192 11620 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0523 16:29:09.521005 11620 solver.cpp:237] Iteration 27250, loss = 1.53268
I0523 16:29:09.521049 11620 solver.cpp:253]     Train net output #0: loss = 1.53268 (* 1 = 1.53268 loss)
I0523 16:29:09.521066 11620 sgd_solver.cpp:106] Iteration 27250, lr = 0.0025
I0523 16:29:18.501850 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_27500.caffemodel
I0523 16:29:18.564234 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_27500.solverstate
I0523 16:29:18.601883 11620 solver.cpp:237] Iteration 27500, loss = 1.19283
I0523 16:29:18.601928 11620 solver.cpp:253]     Train net output #0: loss = 1.19283 (* 1 = 1.19283 loss)
I0523 16:29:18.601951 11620 sgd_solver.cpp:106] Iteration 27500, lr = 0.0025
I0523 16:29:27.612010 11620 solver.cpp:237] Iteration 27750, loss = 1.60309
I0523 16:29:27.612046 11620 solver.cpp:253]     Train net output #0: loss = 1.60309 (* 1 = 1.60309 loss)
I0523 16:29:27.612066 11620 sgd_solver.cpp:106] Iteration 27750, lr = 0.0025
I0523 16:29:36.628033 11620 solver.cpp:237] Iteration 28000, loss = 0.993526
I0523 16:29:36.628201 11620 solver.cpp:253]     Train net output #0: loss = 0.993526 (* 1 = 0.993526 loss)
I0523 16:29:36.628214 11620 sgd_solver.cpp:106] Iteration 28000, lr = 0.0025
I0523 16:29:45.638497 11620 solver.cpp:237] Iteration 28250, loss = 1.12195
I0523 16:29:45.638531 11620 solver.cpp:253]     Train net output #0: loss = 1.12195 (* 1 = 1.12195 loss)
I0523 16:29:45.638548 11620 sgd_solver.cpp:106] Iteration 28250, lr = 0.0025
I0523 16:30:15.552075 11620 solver.cpp:237] Iteration 28500, loss = 1.05946
I0523 16:30:15.552247 11620 solver.cpp:253]     Train net output #0: loss = 1.05946 (* 1 = 1.05946 loss)
I0523 16:30:15.552260 11620 sgd_solver.cpp:106] Iteration 28500, lr = 0.0025
I0523 16:30:24.558676 11620 solver.cpp:237] Iteration 28750, loss = 1.12651
I0523 16:30:24.558724 11620 solver.cpp:253]     Train net output #0: loss = 1.12651 (* 1 = 1.12651 loss)
I0523 16:30:24.558740 11620 sgd_solver.cpp:106] Iteration 28750, lr = 0.0025
I0523 16:30:33.572582 11620 solver.cpp:237] Iteration 29000, loss = 1.22613
I0523 16:30:33.572618 11620 solver.cpp:253]     Train net output #0: loss = 1.22613 (* 1 = 1.22613 loss)
I0523 16:30:33.572634 11620 sgd_solver.cpp:106] Iteration 29000, lr = 0.0025
I0523 16:30:42.586731 11620 solver.cpp:237] Iteration 29250, loss = 1.32621
I0523 16:30:42.586766 11620 solver.cpp:253]     Train net output #0: loss = 1.32621 (* 1 = 1.32621 loss)
I0523 16:30:42.586782 11620 sgd_solver.cpp:106] Iteration 29250, lr = 0.0025
I0523 16:30:51.598613 11620 solver.cpp:237] Iteration 29500, loss = 1.13213
I0523 16:30:51.598767 11620 solver.cpp:253]     Train net output #0: loss = 1.13213 (* 1 = 1.13213 loss)
I0523 16:30:51.598781 11620 sgd_solver.cpp:106] Iteration 29500, lr = 0.0025
I0523 16:31:00.608603 11620 solver.cpp:237] Iteration 29750, loss = 1.20534
I0523 16:31:00.608639 11620 solver.cpp:253]     Train net output #0: loss = 1.20534 (* 1 = 1.20534 loss)
I0523 16:31:00.608655 11620 sgd_solver.cpp:106] Iteration 29750, lr = 0.0025
I0523 16:31:09.584277 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_30000.caffemodel
I0523 16:31:09.646909 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_30000.solverstate
I0523 16:31:09.673228 11620 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 16:32:17.773766 11620 solver.cpp:409]     Test net output #0: accuracy = 0.869254
I0523 16:32:17.773941 11620 solver.cpp:409]     Test net output #1: loss = 0.400827 (* 1 = 0.400827 loss)
I0523 16:32:38.710142 11620 solver.cpp:237] Iteration 30000, loss = 1.16647
I0523 16:32:38.710194 11620 solver.cpp:253]     Train net output #0: loss = 1.16647 (* 1 = 1.16647 loss)
I0523 16:32:38.710209 11620 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0523 16:32:47.813838 11620 solver.cpp:237] Iteration 30250, loss = 1.17603
I0523 16:32:47.813992 11620 solver.cpp:253]     Train net output #0: loss = 1.17603 (* 1 = 1.17603 loss)
I0523 16:32:47.814007 11620 sgd_solver.cpp:106] Iteration 30250, lr = 0.0025
I0523 16:32:56.926229 11620 solver.cpp:237] Iteration 30500, loss = 1.15353
I0523 16:32:56.926275 11620 solver.cpp:253]     Train net output #0: loss = 1.15353 (* 1 = 1.15353 loss)
I0523 16:32:56.926291 11620 sgd_solver.cpp:106] Iteration 30500, lr = 0.0025
I0523 16:33:06.036597 11620 solver.cpp:237] Iteration 30750, loss = 1.37548
I0523 16:33:06.036633 11620 solver.cpp:253]     Train net output #0: loss = 1.37548 (* 1 = 1.37548 loss)
I0523 16:33:06.036650 11620 sgd_solver.cpp:106] Iteration 30750, lr = 0.0025
I0523 16:33:15.142452 11620 solver.cpp:237] Iteration 31000, loss = 1.09303
I0523 16:33:15.142487 11620 solver.cpp:253]     Train net output #0: loss = 1.09303 (* 1 = 1.09303 loss)
I0523 16:33:15.142503 11620 sgd_solver.cpp:106] Iteration 31000, lr = 0.0025
I0523 16:33:24.242856 11620 solver.cpp:237] Iteration 31250, loss = 1.10612
I0523 16:33:24.243031 11620 solver.cpp:253]     Train net output #0: loss = 1.10612 (* 1 = 1.10612 loss)
I0523 16:33:24.243043 11620 sgd_solver.cpp:106] Iteration 31250, lr = 0.0025
I0523 16:33:33.348109 11620 solver.cpp:237] Iteration 31500, loss = 1.16947
I0523 16:33:33.348145 11620 solver.cpp:253]     Train net output #0: loss = 1.16947 (* 1 = 1.16947 loss)
I0523 16:33:33.348158 11620 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0523 16:34:03.354305 11620 solver.cpp:237] Iteration 31750, loss = 1.34638
I0523 16:34:03.354476 11620 solver.cpp:253]     Train net output #0: loss = 1.34638 (* 1 = 1.34638 loss)
I0523 16:34:03.354490 11620 sgd_solver.cpp:106] Iteration 31750, lr = 0.0025
I0523 16:34:12.467942 11620 solver.cpp:237] Iteration 32000, loss = 0.961243
I0523 16:34:12.467983 11620 solver.cpp:253]     Train net output #0: loss = 0.961243 (* 1 = 0.961243 loss)
I0523 16:34:12.468003 11620 sgd_solver.cpp:106] Iteration 32000, lr = 0.0025
I0523 16:34:21.574582 11620 solver.cpp:237] Iteration 32250, loss = 1.40785
I0523 16:34:21.574618 11620 solver.cpp:253]     Train net output #0: loss = 1.40785 (* 1 = 1.40785 loss)
I0523 16:34:21.574630 11620 sgd_solver.cpp:106] Iteration 32250, lr = 0.0025
I0523 16:34:30.644862 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_32500.caffemodel
I0523 16:34:30.707336 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_32500.solverstate
I0523 16:34:30.744693 11620 solver.cpp:237] Iteration 32500, loss = 1.1146
I0523 16:34:30.744735 11620 solver.cpp:253]     Train net output #0: loss = 1.1146 (* 1 = 1.1146 loss)
I0523 16:34:30.744751 11620 sgd_solver.cpp:106] Iteration 32500, lr = 0.0025
I0523 16:34:39.846508 11620 solver.cpp:237] Iteration 32750, loss = 1.00884
I0523 16:34:39.846683 11620 solver.cpp:253]     Train net output #0: loss = 1.00884 (* 1 = 1.00884 loss)
I0523 16:34:39.846698 11620 sgd_solver.cpp:106] Iteration 32750, lr = 0.0025
I0523 16:34:48.952715 11620 solver.cpp:237] Iteration 33000, loss = 1.32645
I0523 16:34:48.952749 11620 solver.cpp:253]     Train net output #0: loss = 1.32645 (* 1 = 1.32645 loss)
I0523 16:34:48.952765 11620 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0523 16:34:58.051379 11620 solver.cpp:237] Iteration 33250, loss = 1.34505
I0523 16:34:58.051429 11620 solver.cpp:253]     Train net output #0: loss = 1.34505 (* 1 = 1.34505 loss)
I0523 16:34:58.051442 11620 sgd_solver.cpp:106] Iteration 33250, lr = 0.0025
I0523 16:35:28.026396 11620 solver.cpp:237] Iteration 33500, loss = 1.3259
I0523 16:35:28.026564 11620 solver.cpp:253]     Train net output #0: loss = 1.3259 (* 1 = 1.3259 loss)
I0523 16:35:28.026578 11620 sgd_solver.cpp:106] Iteration 33500, lr = 0.0025
I0523 16:35:37.128763 11620 solver.cpp:237] Iteration 33750, loss = 1.20384
I0523 16:35:37.128798 11620 solver.cpp:253]     Train net output #0: loss = 1.20384 (* 1 = 1.20384 loss)
I0523 16:35:37.128813 11620 sgd_solver.cpp:106] Iteration 33750, lr = 0.0025
I0523 16:35:46.222981 11620 solver.cpp:237] Iteration 34000, loss = 1.61273
I0523 16:35:46.223017 11620 solver.cpp:253]     Train net output #0: loss = 1.61273 (* 1 = 1.61273 loss)
I0523 16:35:46.223031 11620 sgd_solver.cpp:106] Iteration 34000, lr = 0.0025
I0523 16:35:55.327064 11620 solver.cpp:237] Iteration 34250, loss = 1.15578
I0523 16:35:55.327102 11620 solver.cpp:253]     Train net output #0: loss = 1.15578 (* 1 = 1.15578 loss)
I0523 16:35:55.327116 11620 sgd_solver.cpp:106] Iteration 34250, lr = 0.0025
I0523 16:36:04.438788 11620 solver.cpp:237] Iteration 34500, loss = 1.17404
I0523 16:36:04.438941 11620 solver.cpp:253]     Train net output #0: loss = 1.17404 (* 1 = 1.17404 loss)
I0523 16:36:04.438953 11620 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0523 16:36:13.541769 11620 solver.cpp:237] Iteration 34750, loss = 1.12806
I0523 16:36:13.541815 11620 solver.cpp:253]     Train net output #0: loss = 1.12806 (* 1 = 1.12806 loss)
I0523 16:36:13.541828 11620 sgd_solver.cpp:106] Iteration 34750, lr = 0.0025
I0523 16:36:22.612007 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_35000.caffemodel
I0523 16:36:22.674968 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_35000.solverstate
I0523 16:36:22.701112 11620 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 16:37:09.662072 11620 solver.cpp:409]     Test net output #0: accuracy = 0.874
I0523 16:37:09.662240 11620 solver.cpp:409]     Test net output #1: loss = 0.45195 (* 1 = 0.45195 loss)
I0523 16:37:30.547688 11620 solver.cpp:237] Iteration 35000, loss = 1.13895
I0523 16:37:30.547741 11620 solver.cpp:253]     Train net output #0: loss = 1.13895 (* 1 = 1.13895 loss)
I0523 16:37:30.547756 11620 sgd_solver.cpp:106] Iteration 35000, lr = 0.0025
I0523 16:37:39.628381 11620 solver.cpp:237] Iteration 35250, loss = 1.44023
I0523 16:37:39.628417 11620 solver.cpp:253]     Train net output #0: loss = 1.44023 (* 1 = 1.44023 loss)
I0523 16:37:39.628432 11620 sgd_solver.cpp:106] Iteration 35250, lr = 0.0025
I0523 16:37:48.711375 11620 solver.cpp:237] Iteration 35500, loss = 1.29961
I0523 16:37:48.711524 11620 solver.cpp:253]     Train net output #0: loss = 1.29961 (* 1 = 1.29961 loss)
I0523 16:37:48.711537 11620 sgd_solver.cpp:106] Iteration 35500, lr = 0.0025
I0523 16:37:57.781429 11620 solver.cpp:237] Iteration 35750, loss = 1.03903
I0523 16:37:57.781468 11620 solver.cpp:253]     Train net output #0: loss = 1.03903 (* 1 = 1.03903 loss)
I0523 16:37:57.781488 11620 sgd_solver.cpp:106] Iteration 35750, lr = 0.0025
I0523 16:38:06.852738 11620 solver.cpp:237] Iteration 36000, loss = 1.47387
I0523 16:38:06.852773 11620 solver.cpp:253]     Train net output #0: loss = 1.47387 (* 1 = 1.47387 loss)
I0523 16:38:06.852788 11620 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0523 16:38:15.924502 11620 solver.cpp:237] Iteration 36250, loss = 1.06725
I0523 16:38:15.924538 11620 solver.cpp:253]     Train net output #0: loss = 1.06725 (* 1 = 1.06725 loss)
I0523 16:38:15.924552 11620 sgd_solver.cpp:106] Iteration 36250, lr = 0.0025
I0523 16:38:25.000051 11620 solver.cpp:237] Iteration 36500, loss = 1.26297
I0523 16:38:25.000229 11620 solver.cpp:253]     Train net output #0: loss = 1.26297 (* 1 = 1.26297 loss)
I0523 16:38:25.000243 11620 sgd_solver.cpp:106] Iteration 36500, lr = 0.0025
I0523 16:38:54.942327 11620 solver.cpp:237] Iteration 36750, loss = 1.09875
I0523 16:38:54.942379 11620 solver.cpp:253]     Train net output #0: loss = 1.09875 (* 1 = 1.09875 loss)
I0523 16:38:54.942394 11620 sgd_solver.cpp:106] Iteration 36750, lr = 0.0025
I0523 16:39:04.013084 11620 solver.cpp:237] Iteration 37000, loss = 1.07287
I0523 16:39:04.013241 11620 solver.cpp:253]     Train net output #0: loss = 1.07287 (* 1 = 1.07287 loss)
I0523 16:39:04.013253 11620 sgd_solver.cpp:106] Iteration 37000, lr = 0.0025
I0523 16:39:13.088373 11620 solver.cpp:237] Iteration 37250, loss = 1.19919
I0523 16:39:13.088418 11620 solver.cpp:253]     Train net output #0: loss = 1.19919 (* 1 = 1.19919 loss)
I0523 16:39:13.088434 11620 sgd_solver.cpp:106] Iteration 37250, lr = 0.0025
I0523 16:39:22.132812 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_37500.caffemodel
I0523 16:39:22.198489 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_37500.solverstate
I0523 16:39:22.238400 11620 solver.cpp:237] Iteration 37500, loss = 1.34549
I0523 16:39:22.238451 11620 solver.cpp:253]     Train net output #0: loss = 1.34549 (* 1 = 1.34549 loss)
I0523 16:39:22.238466 11620 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0523 16:39:31.315328 11620 solver.cpp:237] Iteration 37750, loss = 1.33605
I0523 16:39:31.315363 11620 solver.cpp:253]     Train net output #0: loss = 1.33605 (* 1 = 1.33605 loss)
I0523 16:39:31.315379 11620 sgd_solver.cpp:106] Iteration 37750, lr = 0.0025
I0523 16:39:40.386863 11620 solver.cpp:237] Iteration 38000, loss = 1.16244
I0523 16:39:40.387034 11620 solver.cpp:253]     Train net output #0: loss = 1.16244 (* 1 = 1.16244 loss)
I0523 16:39:40.387048 11620 sgd_solver.cpp:106] Iteration 38000, lr = 0.0025
I0523 16:39:49.463763 11620 solver.cpp:237] Iteration 38250, loss = 1.58283
I0523 16:39:49.463798 11620 solver.cpp:253]     Train net output #0: loss = 1.58283 (* 1 = 1.58283 loss)
I0523 16:39:49.463812 11620 sgd_solver.cpp:106] Iteration 38250, lr = 0.0025
I0523 16:40:19.419692 11620 solver.cpp:237] Iteration 38500, loss = 1.17951
I0523 16:40:19.419878 11620 solver.cpp:253]     Train net output #0: loss = 1.17951 (* 1 = 1.17951 loss)
I0523 16:40:19.419891 11620 sgd_solver.cpp:106] Iteration 38500, lr = 0.0025
I0523 16:40:28.505473 11620 solver.cpp:237] Iteration 38750, loss = 1.30192
I0523 16:40:28.505517 11620 solver.cpp:253]     Train net output #0: loss = 1.30192 (* 1 = 1.30192 loss)
I0523 16:40:28.505535 11620 sgd_solver.cpp:106] Iteration 38750, lr = 0.0025
I0523 16:40:37.581598 11620 solver.cpp:237] Iteration 39000, loss = 1.15252
I0523 16:40:37.581634 11620 solver.cpp:253]     Train net output #0: loss = 1.15252 (* 1 = 1.15252 loss)
I0523 16:40:37.581647 11620 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0523 16:40:46.652525 11620 solver.cpp:237] Iteration 39250, loss = 1.28455
I0523 16:40:46.652560 11620 solver.cpp:253]     Train net output #0: loss = 1.28455 (* 1 = 1.28455 loss)
I0523 16:40:46.652575 11620 sgd_solver.cpp:106] Iteration 39250, lr = 0.0025
I0523 16:40:55.727494 11620 solver.cpp:237] Iteration 39500, loss = 1.07231
I0523 16:40:55.727658 11620 solver.cpp:253]     Train net output #0: loss = 1.07231 (* 1 = 1.07231 loss)
I0523 16:40:55.727672 11620 sgd_solver.cpp:106] Iteration 39500, lr = 0.0025
I0523 16:41:04.804949 11620 solver.cpp:237] Iteration 39750, loss = 0.985291
I0523 16:41:04.804982 11620 solver.cpp:253]     Train net output #0: loss = 0.985291 (* 1 = 0.985291 loss)
I0523 16:41:04.804997 11620 sgd_solver.cpp:106] Iteration 39750, lr = 0.0025
I0523 16:41:13.841720 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_40000.caffemodel
I0523 16:41:13.904211 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_40000.solverstate
I0523 16:41:13.930474 11620 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 16:42:22.050096 11620 solver.cpp:409]     Test net output #0: accuracy = 0.881274
I0523 16:42:22.050268 11620 solver.cpp:409]     Test net output #1: loss = 0.394099 (* 1 = 0.394099 loss)
I0523 16:42:42.930212 11620 solver.cpp:237] Iteration 40000, loss = 0.928138
I0523 16:42:42.930265 11620 solver.cpp:253]     Train net output #0: loss = 0.928138 (* 1 = 0.928138 loss)
I0523 16:42:42.930280 11620 sgd_solver.cpp:106] Iteration 40000, lr = 0.0025
I0523 16:42:52.045531 11620 solver.cpp:237] Iteration 40250, loss = 1.13573
I0523 16:42:52.045583 11620 solver.cpp:253]     Train net output #0: loss = 1.13573 (* 1 = 1.13573 loss)
I0523 16:42:52.045598 11620 sgd_solver.cpp:106] Iteration 40250, lr = 0.0025
I0523 16:43:01.159189 11620 solver.cpp:237] Iteration 40500, loss = 1.28905
I0523 16:43:01.159344 11620 solver.cpp:253]     Train net output #0: loss = 1.28905 (* 1 = 1.28905 loss)
I0523 16:43:01.159358 11620 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0523 16:43:10.266635 11620 solver.cpp:237] Iteration 40750, loss = 1.31683
I0523 16:43:10.266669 11620 solver.cpp:253]     Train net output #0: loss = 1.31683 (* 1 = 1.31683 loss)
I0523 16:43:10.266685 11620 sgd_solver.cpp:106] Iteration 40750, lr = 0.0025
I0523 16:43:19.381621 11620 solver.cpp:237] Iteration 41000, loss = 1.31021
I0523 16:43:19.381656 11620 solver.cpp:253]     Train net output #0: loss = 1.31021 (* 1 = 1.31021 loss)
I0523 16:43:19.381669 11620 sgd_solver.cpp:106] Iteration 41000, lr = 0.0025
I0523 16:43:28.486721 11620 solver.cpp:237] Iteration 41250, loss = 1.25564
I0523 16:43:28.486754 11620 solver.cpp:253]     Train net output #0: loss = 1.25564 (* 1 = 1.25564 loss)
I0523 16:43:28.486770 11620 sgd_solver.cpp:106] Iteration 41250, lr = 0.0025
I0523 16:43:37.605407 11620 solver.cpp:237] Iteration 41500, loss = 1.03345
I0523 16:43:37.605556 11620 solver.cpp:253]     Train net output #0: loss = 1.03345 (* 1 = 1.03345 loss)
I0523 16:43:37.605569 11620 sgd_solver.cpp:106] Iteration 41500, lr = 0.0025
I0523 16:44:07.591575 11620 solver.cpp:237] Iteration 41750, loss = 1.26639
I0523 16:44:07.591624 11620 solver.cpp:253]     Train net output #0: loss = 1.26639 (* 1 = 1.26639 loss)
I0523 16:44:07.591640 11620 sgd_solver.cpp:106] Iteration 41750, lr = 0.0025
I0523 16:44:16.706573 11620 solver.cpp:237] Iteration 42000, loss = 1.20403
I0523 16:44:16.706725 11620 solver.cpp:253]     Train net output #0: loss = 1.20403 (* 1 = 1.20403 loss)
I0523 16:44:16.706738 11620 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0523 16:44:25.825006 11620 solver.cpp:237] Iteration 42250, loss = 1.23425
I0523 16:44:25.825039 11620 solver.cpp:253]     Train net output #0: loss = 1.23425 (* 1 = 1.23425 loss)
I0523 16:44:25.825054 11620 sgd_solver.cpp:106] Iteration 42250, lr = 0.0025
I0523 16:44:34.897706 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_42500.caffemodel
I0523 16:44:34.960582 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_42500.solverstate
I0523 16:44:34.998131 11620 solver.cpp:237] Iteration 42500, loss = 1.19355
I0523 16:44:34.998172 11620 solver.cpp:253]     Train net output #0: loss = 1.19355 (* 1 = 1.19355 loss)
I0523 16:44:34.998185 11620 sgd_solver.cpp:106] Iteration 42500, lr = 0.0025
I0523 16:44:44.117599 11620 solver.cpp:237] Iteration 42750, loss = 1.1907
I0523 16:44:44.117632 11620 solver.cpp:253]     Train net output #0: loss = 1.1907 (* 1 = 1.1907 loss)
I0523 16:44:44.117647 11620 sgd_solver.cpp:106] Iteration 42750, lr = 0.0025
I0523 16:44:53.232300 11620 solver.cpp:237] Iteration 43000, loss = 1.27292
I0523 16:44:53.232465 11620 solver.cpp:253]     Train net output #0: loss = 1.27292 (* 1 = 1.27292 loss)
I0523 16:44:53.232478 11620 sgd_solver.cpp:106] Iteration 43000, lr = 0.0025
I0523 16:45:02.348011 11620 solver.cpp:237] Iteration 43250, loss = 1.12999
I0523 16:45:02.348049 11620 solver.cpp:253]     Train net output #0: loss = 1.12999 (* 1 = 1.12999 loss)
I0523 16:45:02.348068 11620 sgd_solver.cpp:106] Iteration 43250, lr = 0.0025
I0523 16:45:32.322026 11620 solver.cpp:237] Iteration 43500, loss = 1.19417
I0523 16:45:32.322206 11620 solver.cpp:253]     Train net output #0: loss = 1.19417 (* 1 = 1.19417 loss)
I0523 16:45:32.322221 11620 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0523 16:45:41.423674 11620 solver.cpp:237] Iteration 43750, loss = 1.25173
I0523 16:45:41.423709 11620 solver.cpp:253]     Train net output #0: loss = 1.25173 (* 1 = 1.25173 loss)
I0523 16:45:41.423724 11620 sgd_solver.cpp:106] Iteration 43750, lr = 0.0025
I0523 16:45:50.530509 11620 solver.cpp:237] Iteration 44000, loss = 1.41465
I0523 16:45:50.530550 11620 solver.cpp:253]     Train net output #0: loss = 1.41465 (* 1 = 1.41465 loss)
I0523 16:45:50.530571 11620 sgd_solver.cpp:106] Iteration 44000, lr = 0.0025
I0523 16:45:59.643748 11620 solver.cpp:237] Iteration 44250, loss = 1.30019
I0523 16:45:59.643784 11620 solver.cpp:253]     Train net output #0: loss = 1.30019 (* 1 = 1.30019 loss)
I0523 16:45:59.643798 11620 sgd_solver.cpp:106] Iteration 44250, lr = 0.0025
I0523 16:46:08.760920 11620 solver.cpp:237] Iteration 44500, loss = 1.08802
I0523 16:46:08.761075 11620 solver.cpp:253]     Train net output #0: loss = 1.08802 (* 1 = 1.08802 loss)
I0523 16:46:08.761088 11620 sgd_solver.cpp:106] Iteration 44500, lr = 0.0025
I0523 16:46:17.879323 11620 solver.cpp:237] Iteration 44750, loss = 1.10559
I0523 16:46:17.879370 11620 solver.cpp:253]     Train net output #0: loss = 1.10559 (* 1 = 1.10559 loss)
I0523 16:46:17.879385 11620 sgd_solver.cpp:106] Iteration 44750, lr = 0.0025
I0523 16:46:26.955178 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_45000.caffemodel
I0523 16:46:27.018915 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_45000.solverstate
I0523 16:46:27.045310 11620 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 16:47:14.291365 11620 solver.cpp:409]     Test net output #0: accuracy = 0.882825
I0523 16:47:14.291537 11620 solver.cpp:409]     Test net output #1: loss = 0.376641 (* 1 = 0.376641 loss)
I0523 16:47:35.175818 11620 solver.cpp:237] Iteration 45000, loss = 1.12475
I0523 16:47:35.175871 11620 solver.cpp:253]     Train net output #0: loss = 1.12475 (* 1 = 1.12475 loss)
I0523 16:47:35.175886 11620 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0523 16:47:44.206805 11620 solver.cpp:237] Iteration 45250, loss = 1.29545
I0523 16:47:44.206841 11620 solver.cpp:253]     Train net output #0: loss = 1.29545 (* 1 = 1.29545 loss)
I0523 16:47:44.206856 11620 sgd_solver.cpp:106] Iteration 45250, lr = 0.0025
I0523 16:47:53.234416 11620 solver.cpp:237] Iteration 45500, loss = 1.12475
I0523 16:47:53.234591 11620 solver.cpp:253]     Train net output #0: loss = 1.12475 (* 1 = 1.12475 loss)
I0523 16:47:53.234604 11620 sgd_solver.cpp:106] Iteration 45500, lr = 0.0025
I0523 16:48:02.268573 11620 solver.cpp:237] Iteration 45750, loss = 0.939453
I0523 16:48:02.268609 11620 solver.cpp:253]     Train net output #0: loss = 0.939453 (* 1 = 0.939453 loss)
I0523 16:48:02.268622 11620 sgd_solver.cpp:106] Iteration 45750, lr = 0.0025
I0523 16:48:11.291455 11620 solver.cpp:237] Iteration 46000, loss = 1.40224
I0523 16:48:11.291491 11620 solver.cpp:253]     Train net output #0: loss = 1.40224 (* 1 = 1.40224 loss)
I0523 16:48:11.291504 11620 sgd_solver.cpp:106] Iteration 46000, lr = 0.0025
I0523 16:48:20.318683 11620 solver.cpp:237] Iteration 46250, loss = 1.1001
I0523 16:48:20.318722 11620 solver.cpp:253]     Train net output #0: loss = 1.1001 (* 1 = 1.1001 loss)
I0523 16:48:20.318734 11620 sgd_solver.cpp:106] Iteration 46250, lr = 0.0025
I0523 16:48:29.343499 11620 solver.cpp:237] Iteration 46500, loss = 0.994007
I0523 16:48:29.343672 11620 solver.cpp:253]     Train net output #0: loss = 0.994007 (* 1 = 0.994007 loss)
I0523 16:48:29.343685 11620 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0523 16:48:59.266664 11620 solver.cpp:237] Iteration 46750, loss = 1.19766
I0523 16:48:59.266715 11620 solver.cpp:253]     Train net output #0: loss = 1.19766 (* 1 = 1.19766 loss)
I0523 16:48:59.266728 11620 sgd_solver.cpp:106] Iteration 46750, lr = 0.0025
I0523 16:49:08.286941 11620 solver.cpp:237] Iteration 47000, loss = 1.152
I0523 16:49:08.287123 11620 solver.cpp:253]     Train net output #0: loss = 1.152 (* 1 = 1.152 loss)
I0523 16:49:08.287137 11620 sgd_solver.cpp:106] Iteration 47000, lr = 0.0025
I0523 16:49:17.316272 11620 solver.cpp:237] Iteration 47250, loss = 1.32877
I0523 16:49:17.316305 11620 solver.cpp:253]     Train net output #0: loss = 1.32877 (* 1 = 1.32877 loss)
I0523 16:49:17.316321 11620 sgd_solver.cpp:106] Iteration 47250, lr = 0.0025
I0523 16:49:26.315752 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_47500.caffemodel
I0523 16:49:26.380427 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_47500.solverstate
I0523 16:49:26.420311 11620 solver.cpp:237] Iteration 47500, loss = 1.66058
I0523 16:49:26.420362 11620 solver.cpp:253]     Train net output #0: loss = 1.66058 (* 1 = 1.66058 loss)
I0523 16:49:26.420377 11620 sgd_solver.cpp:106] Iteration 47500, lr = 0.0025
I0523 16:49:35.443553 11620 solver.cpp:237] Iteration 47750, loss = 1.11654
I0523 16:49:35.443598 11620 solver.cpp:253]     Train net output #0: loss = 1.11654 (* 1 = 1.11654 loss)
I0523 16:49:35.443614 11620 sgd_solver.cpp:106] Iteration 47750, lr = 0.0025
I0523 16:49:44.475530 11620 solver.cpp:237] Iteration 48000, loss = 1.36968
I0523 16:49:44.475689 11620 solver.cpp:253]     Train net output #0: loss = 1.36968 (* 1 = 1.36968 loss)
I0523 16:49:44.475703 11620 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0523 16:49:53.511467 11620 solver.cpp:237] Iteration 48250, loss = 1.14936
I0523 16:49:53.511502 11620 solver.cpp:253]     Train net output #0: loss = 1.14936 (* 1 = 1.14936 loss)
I0523 16:49:53.511517 11620 sgd_solver.cpp:106] Iteration 48250, lr = 0.0025
I0523 16:50:23.449512 11620 solver.cpp:237] Iteration 48500, loss = 1.17698
I0523 16:50:23.449699 11620 solver.cpp:253]     Train net output #0: loss = 1.17698 (* 1 = 1.17698 loss)
I0523 16:50:23.449712 11620 sgd_solver.cpp:106] Iteration 48500, lr = 0.0025
I0523 16:50:32.480991 11620 solver.cpp:237] Iteration 48750, loss = 1.17673
I0523 16:50:32.481026 11620 solver.cpp:253]     Train net output #0: loss = 1.17673 (* 1 = 1.17673 loss)
I0523 16:50:32.481041 11620 sgd_solver.cpp:106] Iteration 48750, lr = 0.0025
I0523 16:50:41.512047 11620 solver.cpp:237] Iteration 49000, loss = 1.22774
I0523 16:50:41.512087 11620 solver.cpp:253]     Train net output #0: loss = 1.22774 (* 1 = 1.22774 loss)
I0523 16:50:41.512101 11620 sgd_solver.cpp:106] Iteration 49000, lr = 0.0025
I0523 16:50:50.546843 11620 solver.cpp:237] Iteration 49250, loss = 1.31554
I0523 16:50:50.546883 11620 solver.cpp:253]     Train net output #0: loss = 1.31554 (* 1 = 1.31554 loss)
I0523 16:50:50.546901 11620 sgd_solver.cpp:106] Iteration 49250, lr = 0.0025
I0523 16:50:59.579164 11620 solver.cpp:237] Iteration 49500, loss = 1.13886
I0523 16:50:59.579331 11620 solver.cpp:253]     Train net output #0: loss = 1.13886 (* 1 = 1.13886 loss)
I0523 16:50:59.579344 11620 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0523 16:51:08.607846 11620 solver.cpp:237] Iteration 49750, loss = 1.32053
I0523 16:51:08.607880 11620 solver.cpp:253]     Train net output #0: loss = 1.32053 (* 1 = 1.32053 loss)
I0523 16:51:08.607897 11620 sgd_solver.cpp:106] Iteration 49750, lr = 0.0025
I0523 16:51:17.599997 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_50000.caffemodel
I0523 16:51:17.665719 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_50000.solverstate
I0523 16:51:17.694092 11620 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 16:52:25.865864 11620 solver.cpp:409]     Test net output #0: accuracy = 0.885173
I0523 16:52:25.866050 11620 solver.cpp:409]     Test net output #1: loss = 0.373957 (* 1 = 0.373957 loss)
I0523 16:52:46.701055 11620 solver.cpp:237] Iteration 50000, loss = 1.24204
I0523 16:52:46.701108 11620 solver.cpp:253]     Train net output #0: loss = 1.24204 (* 1 = 1.24204 loss)
I0523 16:52:46.701123 11620 sgd_solver.cpp:106] Iteration 50000, lr = 0.0025
I0523 16:52:55.750715 11620 solver.cpp:237] Iteration 50250, loss = 0.830096
I0523 16:52:55.750757 11620 solver.cpp:253]     Train net output #0: loss = 0.830096 (* 1 = 0.830096 loss)
I0523 16:52:55.750776 11620 sgd_solver.cpp:106] Iteration 50250, lr = 0.0025
I0523 16:53:04.816661 11620 solver.cpp:237] Iteration 50500, loss = 1.21951
I0523 16:53:04.816819 11620 solver.cpp:253]     Train net output #0: loss = 1.21951 (* 1 = 1.21951 loss)
I0523 16:53:04.816833 11620 sgd_solver.cpp:106] Iteration 50500, lr = 0.0025
I0523 16:53:13.871173 11620 solver.cpp:237] Iteration 50750, loss = 1.11308
I0523 16:53:13.871208 11620 solver.cpp:253]     Train net output #0: loss = 1.11308 (* 1 = 1.11308 loss)
I0523 16:53:13.871223 11620 sgd_solver.cpp:106] Iteration 50750, lr = 0.0025
I0523 16:53:22.924607 11620 solver.cpp:237] Iteration 51000, loss = 1.34035
I0523 16:53:22.924650 11620 solver.cpp:253]     Train net output #0: loss = 1.34035 (* 1 = 1.34035 loss)
I0523 16:53:22.924664 11620 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0523 16:53:31.984099 11620 solver.cpp:237] Iteration 51250, loss = 1.16817
I0523 16:53:31.984135 11620 solver.cpp:253]     Train net output #0: loss = 1.16817 (* 1 = 1.16817 loss)
I0523 16:53:31.984148 11620 sgd_solver.cpp:106] Iteration 51250, lr = 0.0025
I0523 16:53:41.045264 11620 solver.cpp:237] Iteration 51500, loss = 1.32437
I0523 16:53:41.045419 11620 solver.cpp:253]     Train net output #0: loss = 1.32437 (* 1 = 1.32437 loss)
I0523 16:53:41.045433 11620 sgd_solver.cpp:106] Iteration 51500, lr = 0.0025
I0523 16:54:10.961379 11620 solver.cpp:237] Iteration 51750, loss = 1.34064
I0523 16:54:10.961428 11620 solver.cpp:253]     Train net output #0: loss = 1.34064 (* 1 = 1.34064 loss)
I0523 16:54:10.961444 11620 sgd_solver.cpp:106] Iteration 51750, lr = 0.0025
I0523 16:54:20.021888 11620 solver.cpp:237] Iteration 52000, loss = 1.23099
I0523 16:54:20.022047 11620 solver.cpp:253]     Train net output #0: loss = 1.23099 (* 1 = 1.23099 loss)
I0523 16:54:20.022060 11620 sgd_solver.cpp:106] Iteration 52000, lr = 0.0025
I0523 16:54:29.079144 11620 solver.cpp:237] Iteration 52250, loss = 1.14907
I0523 16:54:29.079180 11620 solver.cpp:253]     Train net output #0: loss = 1.14907 (* 1 = 1.14907 loss)
I0523 16:54:29.079195 11620 sgd_solver.cpp:106] Iteration 52250, lr = 0.0025
I0523 16:54:38.101053 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_52500.caffemodel
I0523 16:54:38.165530 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_52500.solverstate
I0523 16:54:38.203027 11620 solver.cpp:237] Iteration 52500, loss = 1.23764
I0523 16:54:38.203068 11620 solver.cpp:253]     Train net output #0: loss = 1.23764 (* 1 = 1.23764 loss)
I0523 16:54:38.203088 11620 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0523 16:54:47.260727 11620 solver.cpp:237] Iteration 52750, loss = 1.26334
I0523 16:54:47.260762 11620 solver.cpp:253]     Train net output #0: loss = 1.26334 (* 1 = 1.26334 loss)
I0523 16:54:47.260777 11620 sgd_solver.cpp:106] Iteration 52750, lr = 0.0025
I0523 16:54:56.321382 11620 solver.cpp:237] Iteration 53000, loss = 1.41206
I0523 16:54:56.321550 11620 solver.cpp:253]     Train net output #0: loss = 1.41206 (* 1 = 1.41206 loss)
I0523 16:54:56.321563 11620 sgd_solver.cpp:106] Iteration 53000, lr = 0.0025
I0523 16:55:05.377846 11620 solver.cpp:237] Iteration 53250, loss = 1.13013
I0523 16:55:05.377884 11620 solver.cpp:253]     Train net output #0: loss = 1.13013 (* 1 = 1.13013 loss)
I0523 16:55:05.377904 11620 sgd_solver.cpp:106] Iteration 53250, lr = 0.0025
I0523 16:55:35.300986 11620 solver.cpp:237] Iteration 53500, loss = 1.11478
I0523 16:55:35.301162 11620 solver.cpp:253]     Train net output #0: loss = 1.11478 (* 1 = 1.11478 loss)
I0523 16:55:35.301175 11620 sgd_solver.cpp:106] Iteration 53500, lr = 0.0025
I0523 16:55:44.360615 11620 solver.cpp:237] Iteration 53750, loss = 0.986787
I0523 16:55:44.360649 11620 solver.cpp:253]     Train net output #0: loss = 0.986787 (* 1 = 0.986787 loss)
I0523 16:55:44.360664 11620 sgd_solver.cpp:106] Iteration 53750, lr = 0.0025
I0523 16:55:53.410519 11620 solver.cpp:237] Iteration 54000, loss = 1.37432
I0523 16:55:53.410567 11620 solver.cpp:253]     Train net output #0: loss = 1.37432 (* 1 = 1.37432 loss)
I0523 16:55:53.410580 11620 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0523 16:56:02.457556 11620 solver.cpp:237] Iteration 54250, loss = 1.29736
I0523 16:56:02.457592 11620 solver.cpp:253]     Train net output #0: loss = 1.29736 (* 1 = 1.29736 loss)
I0523 16:56:02.457604 11620 sgd_solver.cpp:106] Iteration 54250, lr = 0.0025
I0523 16:56:11.514873 11620 solver.cpp:237] Iteration 54500, loss = 0.971457
I0523 16:56:11.515031 11620 solver.cpp:253]     Train net output #0: loss = 0.971457 (* 1 = 0.971457 loss)
I0523 16:56:11.515045 11620 sgd_solver.cpp:106] Iteration 54500, lr = 0.0025
I0523 16:56:20.573272 11620 solver.cpp:237] Iteration 54750, loss = 1.37978
I0523 16:56:20.573317 11620 solver.cpp:253]     Train net output #0: loss = 1.37978 (* 1 = 1.37978 loss)
I0523 16:56:20.573333 11620 sgd_solver.cpp:106] Iteration 54750, lr = 0.0025
I0523 16:56:29.594800 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_55000.caffemodel
I0523 16:56:29.657289 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_55000.solverstate
I0523 16:56:29.684221 11620 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 16:57:16.643573 11620 solver.cpp:409]     Test net output #0: accuracy = 0.8853
I0523 16:57:16.643748 11620 solver.cpp:409]     Test net output #1: loss = 0.36412 (* 1 = 0.36412 loss)
I0523 16:57:37.502866 11620 solver.cpp:237] Iteration 55000, loss = 1.12802
I0523 16:57:37.502918 11620 solver.cpp:253]     Train net output #0: loss = 1.12802 (* 1 = 1.12802 loss)
I0523 16:57:37.502933 11620 sgd_solver.cpp:106] Iteration 55000, lr = 0.0025
I0523 16:57:46.514040 11620 solver.cpp:237] Iteration 55250, loss = 1.16422
I0523 16:57:46.514076 11620 solver.cpp:253]     Train net output #0: loss = 1.16422 (* 1 = 1.16422 loss)
I0523 16:57:46.514091 11620 sgd_solver.cpp:106] Iteration 55250, lr = 0.0025
I0523 16:57:55.531265 11620 solver.cpp:237] Iteration 55500, loss = 1.23804
I0523 16:57:55.531447 11620 solver.cpp:253]     Train net output #0: loss = 1.23804 (* 1 = 1.23804 loss)
I0523 16:57:55.531461 11620 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0523 16:58:04.547356 11620 solver.cpp:237] Iteration 55750, loss = 1.38921
I0523 16:58:04.547391 11620 solver.cpp:253]     Train net output #0: loss = 1.38921 (* 1 = 1.38921 loss)
I0523 16:58:04.547407 11620 sgd_solver.cpp:106] Iteration 55750, lr = 0.0025
I0523 16:58:13.554006 11620 solver.cpp:237] Iteration 56000, loss = 0.847985
I0523 16:58:13.554042 11620 solver.cpp:253]     Train net output #0: loss = 0.847985 (* 1 = 0.847985 loss)
I0523 16:58:13.554055 11620 sgd_solver.cpp:106] Iteration 56000, lr = 0.0025
I0523 16:58:22.563218 11620 solver.cpp:237] Iteration 56250, loss = 1.16121
I0523 16:58:22.563261 11620 solver.cpp:253]     Train net output #0: loss = 1.16121 (* 1 = 1.16121 loss)
I0523 16:58:22.563279 11620 sgd_solver.cpp:106] Iteration 56250, lr = 0.0025
I0523 16:58:31.572950 11620 solver.cpp:237] Iteration 56500, loss = 1.3267
I0523 16:58:31.573112 11620 solver.cpp:253]     Train net output #0: loss = 1.3267 (* 1 = 1.3267 loss)
I0523 16:58:31.573124 11620 sgd_solver.cpp:106] Iteration 56500, lr = 0.0025
I0523 16:59:01.482918 11620 solver.cpp:237] Iteration 56750, loss = 1.25077
I0523 16:59:01.482969 11620 solver.cpp:253]     Train net output #0: loss = 1.25077 (* 1 = 1.25077 loss)
I0523 16:59:01.482983 11620 sgd_solver.cpp:106] Iteration 56750, lr = 0.0025
I0523 16:59:10.498929 11620 solver.cpp:237] Iteration 57000, loss = 1.06282
I0523 16:59:10.499101 11620 solver.cpp:253]     Train net output #0: loss = 1.06282 (* 1 = 1.06282 loss)
I0523 16:59:10.499115 11620 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0523 16:59:19.508638 11620 solver.cpp:237] Iteration 57250, loss = 1.32616
I0523 16:59:19.508672 11620 solver.cpp:253]     Train net output #0: loss = 1.32616 (* 1 = 1.32616 loss)
I0523 16:59:19.508688 11620 sgd_solver.cpp:106] Iteration 57250, lr = 0.0025
I0523 16:59:28.481035 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_57500.caffemodel
I0523 16:59:28.544301 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_57500.solverstate
I0523 16:59:28.581775 11620 solver.cpp:237] Iteration 57500, loss = 1.26128
I0523 16:59:28.581821 11620 solver.cpp:253]     Train net output #0: loss = 1.26128 (* 1 = 1.26128 loss)
I0523 16:59:28.581835 11620 sgd_solver.cpp:106] Iteration 57500, lr = 0.0025
I0523 16:59:37.590198 11620 solver.cpp:237] Iteration 57750, loss = 0.964741
I0523 16:59:37.590246 11620 solver.cpp:253]     Train net output #0: loss = 0.964741 (* 1 = 0.964741 loss)
I0523 16:59:37.590260 11620 sgd_solver.cpp:106] Iteration 57750, lr = 0.0025
I0523 16:59:46.599191 11620 solver.cpp:237] Iteration 58000, loss = 1.16921
I0523 16:59:46.599366 11620 solver.cpp:253]     Train net output #0: loss = 1.16921 (* 1 = 1.16921 loss)
I0523 16:59:46.599380 11620 sgd_solver.cpp:106] Iteration 58000, lr = 0.0025
I0523 16:59:55.610028 11620 solver.cpp:237] Iteration 58250, loss = 1.08891
I0523 16:59:55.610064 11620 solver.cpp:253]     Train net output #0: loss = 1.08891 (* 1 = 1.08891 loss)
I0523 16:59:55.610077 11620 sgd_solver.cpp:106] Iteration 58250, lr = 0.0025
I0523 17:00:25.541000 11620 solver.cpp:237] Iteration 58500, loss = 1.05882
I0523 17:00:25.541187 11620 solver.cpp:253]     Train net output #0: loss = 1.05882 (* 1 = 1.05882 loss)
I0523 17:00:25.541200 11620 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
I0523 17:00:34.549958 11620 solver.cpp:237] Iteration 58750, loss = 1.21172
I0523 17:00:34.549993 11620 solver.cpp:253]     Train net output #0: loss = 1.21172 (* 1 = 1.21172 loss)
I0523 17:00:34.550009 11620 sgd_solver.cpp:106] Iteration 58750, lr = 0.0025
I0523 17:00:43.562698 11620 solver.cpp:237] Iteration 59000, loss = 1.26905
I0523 17:00:43.562733 11620 solver.cpp:253]     Train net output #0: loss = 1.26905 (* 1 = 1.26905 loss)
I0523 17:00:43.562748 11620 sgd_solver.cpp:106] Iteration 59000, lr = 0.0025
I0523 17:00:52.577963 11620 solver.cpp:237] Iteration 59250, loss = 1.14261
I0523 17:00:52.578004 11620 solver.cpp:253]     Train net output #0: loss = 1.14261 (* 1 = 1.14261 loss)
I0523 17:00:52.578018 11620 sgd_solver.cpp:106] Iteration 59250, lr = 0.0025
I0523 17:01:01.584015 11620 solver.cpp:237] Iteration 59500, loss = 1.19227
I0523 17:01:01.584189 11620 solver.cpp:253]     Train net output #0: loss = 1.19227 (* 1 = 1.19227 loss)
I0523 17:01:01.584203 11620 sgd_solver.cpp:106] Iteration 59500, lr = 0.0025
I0523 17:01:10.590744 11620 solver.cpp:237] Iteration 59750, loss = 1.04879
I0523 17:01:10.590777 11620 solver.cpp:253]     Train net output #0: loss = 1.04879 (* 1 = 1.04879 loss)
I0523 17:01:10.590792 11620 sgd_solver.cpp:106] Iteration 59750, lr = 0.0025
I0523 17:01:19.565384 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_60000.caffemodel
I0523 17:01:19.628537 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_60000.solverstate
I0523 17:01:19.654813 11620 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 17:02:27.741775 11620 solver.cpp:409]     Test net output #0: accuracy = 0.890019
I0523 17:02:27.741951 11620 solver.cpp:409]     Test net output #1: loss = 0.371881 (* 1 = 0.371881 loss)
I0523 17:02:48.575664 11620 solver.cpp:237] Iteration 60000, loss = 0.939378
I0523 17:02:48.575718 11620 solver.cpp:253]     Train net output #0: loss = 0.939378 (* 1 = 0.939378 loss)
I0523 17:02:48.575733 11620 sgd_solver.cpp:106] Iteration 60000, lr = 0.0025
I0523 17:02:57.687091 11620 solver.cpp:237] Iteration 60250, loss = 1.14173
I0523 17:02:57.687136 11620 solver.cpp:253]     Train net output #0: loss = 1.14173 (* 1 = 1.14173 loss)
I0523 17:02:57.687152 11620 sgd_solver.cpp:106] Iteration 60250, lr = 0.0025
I0523 17:03:06.796319 11620 solver.cpp:237] Iteration 60500, loss = 1.21432
I0523 17:03:06.796483 11620 solver.cpp:253]     Train net output #0: loss = 1.21432 (* 1 = 1.21432 loss)
I0523 17:03:06.796497 11620 sgd_solver.cpp:106] Iteration 60500, lr = 0.0025
I0523 17:03:15.896050 11620 solver.cpp:237] Iteration 60750, loss = 1.14095
I0523 17:03:15.896088 11620 solver.cpp:253]     Train net output #0: loss = 1.14095 (* 1 = 1.14095 loss)
I0523 17:03:15.896103 11620 sgd_solver.cpp:106] Iteration 60750, lr = 0.0025
I0523 17:03:24.991427 11620 solver.cpp:237] Iteration 61000, loss = 1.19643
I0523 17:03:24.991468 11620 solver.cpp:253]     Train net output #0: loss = 1.19643 (* 1 = 1.19643 loss)
I0523 17:03:24.991488 11620 sgd_solver.cpp:106] Iteration 61000, lr = 0.0025
I0523 17:03:34.096127 11620 solver.cpp:237] Iteration 61250, loss = 1.24059
I0523 17:03:34.096161 11620 solver.cpp:253]     Train net output #0: loss = 1.24059 (* 1 = 1.24059 loss)
I0523 17:03:34.096176 11620 sgd_solver.cpp:106] Iteration 61250, lr = 0.0025
I0523 17:03:43.196568 11620 solver.cpp:237] Iteration 61500, loss = 1.18426
I0523 17:03:43.196738 11620 solver.cpp:253]     Train net output #0: loss = 1.18426 (* 1 = 1.18426 loss)
I0523 17:03:43.196753 11620 sgd_solver.cpp:106] Iteration 61500, lr = 0.0025
I0523 17:04:13.152745 11620 solver.cpp:237] Iteration 61750, loss = 1.2063
I0523 17:04:13.152792 11620 solver.cpp:253]     Train net output #0: loss = 1.2063 (* 1 = 1.2063 loss)
I0523 17:04:13.152808 11620 sgd_solver.cpp:106] Iteration 61750, lr = 0.0025
I0523 17:04:22.251366 11620 solver.cpp:237] Iteration 62000, loss = 1.06631
I0523 17:04:22.251552 11620 solver.cpp:253]     Train net output #0: loss = 1.06631 (* 1 = 1.06631 loss)
I0523 17:04:22.251566 11620 sgd_solver.cpp:106] Iteration 62000, lr = 0.0025
I0523 17:04:31.345125 11620 solver.cpp:237] Iteration 62250, loss = 0.947012
I0523 17:04:31.345160 11620 solver.cpp:253]     Train net output #0: loss = 0.947012 (* 1 = 0.947012 loss)
I0523 17:04:31.345175 11620 sgd_solver.cpp:106] Iteration 62250, lr = 0.0025
I0523 17:04:40.412559 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_62500.caffemodel
I0523 17:04:40.477948 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_62500.solverstate
I0523 17:04:40.517664 11620 solver.cpp:237] Iteration 62500, loss = 1.18842
I0523 17:04:40.517712 11620 solver.cpp:253]     Train net output #0: loss = 1.18842 (* 1 = 1.18842 loss)
I0523 17:04:40.517729 11620 sgd_solver.cpp:106] Iteration 62500, lr = 0.0025
I0523 17:04:49.616827 11620 solver.cpp:237] Iteration 62750, loss = 1.07421
I0523 17:04:49.616861 11620 solver.cpp:253]     Train net output #0: loss = 1.07421 (* 1 = 1.07421 loss)
I0523 17:04:49.616878 11620 sgd_solver.cpp:106] Iteration 62750, lr = 0.0025
I0523 17:04:58.726946 11620 solver.cpp:237] Iteration 63000, loss = 1.31516
I0523 17:04:58.727130 11620 solver.cpp:253]     Train net output #0: loss = 1.31516 (* 1 = 1.31516 loss)
I0523 17:04:58.727144 11620 sgd_solver.cpp:106] Iteration 63000, lr = 0.0025
I0523 17:05:07.823956 11620 solver.cpp:237] Iteration 63250, loss = 1.30692
I0523 17:05:07.823999 11620 solver.cpp:253]     Train net output #0: loss = 1.30692 (* 1 = 1.30692 loss)
I0523 17:05:07.824012 11620 sgd_solver.cpp:106] Iteration 63250, lr = 0.0025
I0523 17:05:37.788282 11620 solver.cpp:237] Iteration 63500, loss = 1.07297
I0523 17:05:37.788466 11620 solver.cpp:253]     Train net output #0: loss = 1.07297 (* 1 = 1.07297 loss)
I0523 17:05:37.788480 11620 sgd_solver.cpp:106] Iteration 63500, lr = 0.0025
I0523 17:05:46.892825 11620 solver.cpp:237] Iteration 63750, loss = 1.09685
I0523 17:05:46.892868 11620 solver.cpp:253]     Train net output #0: loss = 1.09685 (* 1 = 1.09685 loss)
I0523 17:05:46.892884 11620 sgd_solver.cpp:106] Iteration 63750, lr = 0.0025
I0523 17:05:55.995087 11620 solver.cpp:237] Iteration 64000, loss = 1.02605
I0523 17:05:55.995123 11620 solver.cpp:253]     Train net output #0: loss = 1.02605 (* 1 = 1.02605 loss)
I0523 17:05:55.995137 11620 sgd_solver.cpp:106] Iteration 64000, lr = 0.0025
I0523 17:06:05.093639 11620 solver.cpp:237] Iteration 64250, loss = 1.05223
I0523 17:06:05.093674 11620 solver.cpp:253]     Train net output #0: loss = 1.05223 (* 1 = 1.05223 loss)
I0523 17:06:05.093689 11620 sgd_solver.cpp:106] Iteration 64250, lr = 0.0025
I0523 17:06:14.193816 11620 solver.cpp:237] Iteration 64500, loss = 1.27227
I0523 17:06:14.193990 11620 solver.cpp:253]     Train net output #0: loss = 1.27227 (* 1 = 1.27227 loss)
I0523 17:06:14.194005 11620 sgd_solver.cpp:106] Iteration 64500, lr = 0.0025
I0523 17:06:23.294772 11620 solver.cpp:237] Iteration 64750, loss = 0.958125
I0523 17:06:23.294806 11620 solver.cpp:253]     Train net output #0: loss = 0.958125 (* 1 = 0.958125 loss)
I0523 17:06:23.294822 11620 sgd_solver.cpp:106] Iteration 64750, lr = 0.0025
I0523 17:06:32.363420 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_65000.caffemodel
I0523 17:06:32.432422 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_65000.solverstate
I0523 17:06:32.464440 11620 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 17:07:19.739888 11620 solver.cpp:409]     Test net output #0: accuracy = 0.888006
I0523 17:07:19.740085 11620 solver.cpp:409]     Test net output #1: loss = 0.355225 (* 1 = 0.355225 loss)
I0523 17:07:40.669231 11620 solver.cpp:237] Iteration 65000, loss = 1.00228
I0523 17:07:40.669283 11620 solver.cpp:253]     Train net output #0: loss = 1.00228 (* 1 = 1.00228 loss)
I0523 17:07:40.669298 11620 sgd_solver.cpp:106] Iteration 65000, lr = 0.0025
I0523 17:07:49.735657 11620 solver.cpp:237] Iteration 65250, loss = 0.821621
I0523 17:07:49.735693 11620 solver.cpp:253]     Train net output #0: loss = 0.821621 (* 1 = 0.821621 loss)
I0523 17:07:49.735707 11620 sgd_solver.cpp:106] Iteration 65250, lr = 0.0025
I0523 17:07:58.817625 11620 solver.cpp:237] Iteration 65500, loss = 1.35474
I0523 17:07:58.817800 11620 solver.cpp:253]     Train net output #0: loss = 1.35474 (* 1 = 1.35474 loss)
I0523 17:07:58.817814 11620 sgd_solver.cpp:106] Iteration 65500, lr = 0.0025
I0523 17:08:07.894119 11620 solver.cpp:237] Iteration 65750, loss = 1.31621
I0523 17:08:07.894153 11620 solver.cpp:253]     Train net output #0: loss = 1.31621 (* 1 = 1.31621 loss)
I0523 17:08:07.894168 11620 sgd_solver.cpp:106] Iteration 65750, lr = 0.0025
I0523 17:08:16.970038 11620 solver.cpp:237] Iteration 66000, loss = 1.02851
I0523 17:08:16.970078 11620 solver.cpp:253]     Train net output #0: loss = 1.02851 (* 1 = 1.02851 loss)
I0523 17:08:16.970091 11620 sgd_solver.cpp:106] Iteration 66000, lr = 0.0025
I0523 17:08:26.048152 11620 solver.cpp:237] Iteration 66250, loss = 1.42095
I0523 17:08:26.048187 11620 solver.cpp:253]     Train net output #0: loss = 1.42095 (* 1 = 1.42095 loss)
I0523 17:08:26.048202 11620 sgd_solver.cpp:106] Iteration 66250, lr = 0.0025
I0523 17:08:35.122984 11620 solver.cpp:237] Iteration 66500, loss = 1.04855
I0523 17:08:35.123145 11620 solver.cpp:253]     Train net output #0: loss = 1.04855 (* 1 = 1.04855 loss)
I0523 17:08:35.123158 11620 sgd_solver.cpp:106] Iteration 66500, lr = 0.0025
I0523 17:09:05.131837 11620 solver.cpp:237] Iteration 66750, loss = 1.27425
I0523 17:09:05.132024 11620 solver.cpp:253]     Train net output #0: loss = 1.27425 (* 1 = 1.27425 loss)
I0523 17:09:05.132037 11620 sgd_solver.cpp:106] Iteration 66750, lr = 0.0025
I0523 17:09:14.215983 11620 solver.cpp:237] Iteration 67000, loss = 1.05148
I0523 17:09:14.216017 11620 solver.cpp:253]     Train net output #0: loss = 1.05148 (* 1 = 1.05148 loss)
I0523 17:09:14.216028 11620 sgd_solver.cpp:106] Iteration 67000, lr = 0.0025
I0523 17:09:23.294728 11620 solver.cpp:237] Iteration 67250, loss = 1.20925
I0523 17:09:23.294764 11620 solver.cpp:253]     Train net output #0: loss = 1.20925 (* 1 = 1.20925 loss)
I0523 17:09:23.294777 11620 sgd_solver.cpp:106] Iteration 67250, lr = 0.0025
I0523 17:09:32.339931 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_67500.caffemodel
I0523 17:09:32.403481 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_67500.solverstate
I0523 17:09:32.441028 11620 solver.cpp:237] Iteration 67500, loss = 1.10891
I0523 17:09:32.441069 11620 solver.cpp:253]     Train net output #0: loss = 1.10891 (* 1 = 1.10891 loss)
I0523 17:09:32.441089 11620 sgd_solver.cpp:106] Iteration 67500, lr = 0.0025
I0523 17:09:41.514133 11620 solver.cpp:237] Iteration 67750, loss = 1.13628
I0523 17:09:41.514297 11620 solver.cpp:253]     Train net output #0: loss = 1.13628 (* 1 = 1.13628 loss)
I0523 17:09:41.514310 11620 sgd_solver.cpp:106] Iteration 67750, lr = 0.0025
I0523 17:09:50.594877 11620 solver.cpp:237] Iteration 68000, loss = 1.16702
I0523 17:09:50.594912 11620 solver.cpp:253]     Train net output #0: loss = 1.16702 (* 1 = 1.16702 loss)
I0523 17:09:50.594928 11620 sgd_solver.cpp:106] Iteration 68000, lr = 0.0025
I0523 17:09:59.668993 11620 solver.cpp:237] Iteration 68250, loss = 1.13176
I0523 17:09:59.669033 11620 solver.cpp:253]     Train net output #0: loss = 1.13176 (* 1 = 1.13176 loss)
I0523 17:09:59.669050 11620 sgd_solver.cpp:106] Iteration 68250, lr = 0.0025
I0523 17:10:29.615677 11620 solver.cpp:237] Iteration 68500, loss = 0.997683
I0523 17:10:29.615874 11620 solver.cpp:253]     Train net output #0: loss = 0.997683 (* 1 = 0.997683 loss)
I0523 17:10:29.615887 11620 sgd_solver.cpp:106] Iteration 68500, lr = 0.0025
I0523 17:10:38.692442 11620 solver.cpp:237] Iteration 68750, loss = 0.982826
I0523 17:10:38.692477 11620 solver.cpp:253]     Train net output #0: loss = 0.982826 (* 1 = 0.982826 loss)
I0523 17:10:38.692493 11620 sgd_solver.cpp:106] Iteration 68750, lr = 0.0025
I0523 17:10:47.764775 11620 solver.cpp:237] Iteration 69000, loss = 1.20359
I0523 17:10:47.764825 11620 solver.cpp:253]     Train net output #0: loss = 1.20359 (* 1 = 1.20359 loss)
I0523 17:10:47.764842 11620 sgd_solver.cpp:106] Iteration 69000, lr = 0.0025
I0523 17:10:56.841446 11620 solver.cpp:237] Iteration 69250, loss = 1.2036
I0523 17:10:56.841482 11620 solver.cpp:253]     Train net output #0: loss = 1.2036 (* 1 = 1.2036 loss)
I0523 17:10:56.841496 11620 sgd_solver.cpp:106] Iteration 69250, lr = 0.0025
I0523 17:11:05.915621 11620 solver.cpp:237] Iteration 69500, loss = 1.16272
I0523 17:11:05.915786 11620 solver.cpp:253]     Train net output #0: loss = 1.16272 (* 1 = 1.16272 loss)
I0523 17:11:05.915801 11620 sgd_solver.cpp:106] Iteration 69500, lr = 0.0025
I0523 17:11:14.987457 11620 solver.cpp:237] Iteration 69750, loss = 1.1241
I0523 17:11:14.987504 11620 solver.cpp:253]     Train net output #0: loss = 1.1241 (* 1 = 1.1241 loss)
I0523 17:11:14.987519 11620 sgd_solver.cpp:106] Iteration 69750, lr = 0.0025
I0523 17:11:24.024852 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_70000.caffemodel
I0523 17:11:24.087636 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_70000.solverstate
I0523 17:11:24.113821 11620 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 17:12:32.289582 11620 solver.cpp:409]     Test net output #0: accuracy = 0.889198
I0523 17:12:32.289764 11620 solver.cpp:409]     Test net output #1: loss = 0.366915 (* 1 = 0.366915 loss)
I0523 17:12:53.142503 11620 solver.cpp:237] Iteration 70000, loss = 1.0551
I0523 17:12:53.142554 11620 solver.cpp:253]     Train net output #0: loss = 1.0551 (* 1 = 1.0551 loss)
I0523 17:12:53.142570 11620 sgd_solver.cpp:106] Iteration 70000, lr = 0.0025
I0523 17:13:02.250633 11620 solver.cpp:237] Iteration 70250, loss = 1.37461
I0523 17:13:02.250668 11620 solver.cpp:253]     Train net output #0: loss = 1.37461 (* 1 = 1.37461 loss)
I0523 17:13:02.250682 11620 sgd_solver.cpp:106] Iteration 70250, lr = 0.0025
I0523 17:13:11.364923 11620 solver.cpp:237] Iteration 70500, loss = 1.06509
I0523 17:13:11.365103 11620 solver.cpp:253]     Train net output #0: loss = 1.06509 (* 1 = 1.06509 loss)
I0523 17:13:11.365115 11620 sgd_solver.cpp:106] Iteration 70500, lr = 0.0025
I0523 17:13:20.479146 11620 solver.cpp:237] Iteration 70750, loss = 1.03837
I0523 17:13:20.479192 11620 solver.cpp:253]     Train net output #0: loss = 1.03837 (* 1 = 1.03837 loss)
I0523 17:13:20.479207 11620 sgd_solver.cpp:106] Iteration 70750, lr = 0.0025
I0523 17:13:29.595443 11620 solver.cpp:237] Iteration 71000, loss = 1.2453
I0523 17:13:29.595477 11620 solver.cpp:253]     Train net output #0: loss = 1.2453 (* 1 = 1.2453 loss)
I0523 17:13:29.595494 11620 sgd_solver.cpp:106] Iteration 71000, lr = 0.0025
I0523 17:13:38.710046 11620 solver.cpp:237] Iteration 71250, loss = 1.07841
I0523 17:13:38.710081 11620 solver.cpp:253]     Train net output #0: loss = 1.07841 (* 1 = 1.07841 loss)
I0523 17:13:38.710094 11620 sgd_solver.cpp:106] Iteration 71250, lr = 0.0025
I0523 17:13:47.819358 11620 solver.cpp:237] Iteration 71500, loss = 0.923508
I0523 17:13:47.819532 11620 solver.cpp:253]     Train net output #0: loss = 0.923508 (* 1 = 0.923508 loss)
I0523 17:13:47.819546 11620 sgd_solver.cpp:106] Iteration 71500, lr = 0.0025
I0523 17:14:17.824406 11620 solver.cpp:237] Iteration 71750, loss = 1.20956
I0523 17:14:17.824587 11620 solver.cpp:253]     Train net output #0: loss = 1.20956 (* 1 = 1.20956 loss)
I0523 17:14:17.824601 11620 sgd_solver.cpp:106] Iteration 71750, lr = 0.0025
I0523 17:14:26.942354 11620 solver.cpp:237] Iteration 72000, loss = 1.19778
I0523 17:14:26.942390 11620 solver.cpp:253]     Train net output #0: loss = 1.19778 (* 1 = 1.19778 loss)
I0523 17:14:26.942404 11620 sgd_solver.cpp:106] Iteration 72000, lr = 0.0025
I0523 17:14:36.060714 11620 solver.cpp:237] Iteration 72250, loss = 1.25987
I0523 17:14:36.060750 11620 solver.cpp:253]     Train net output #0: loss = 1.25987 (* 1 = 1.25987 loss)
I0523 17:14:36.060765 11620 sgd_solver.cpp:106] Iteration 72250, lr = 0.0025
I0523 17:14:45.140668 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_72500.caffemodel
I0523 17:14:45.206086 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_72500.solverstate
I0523 17:14:45.245868 11620 solver.cpp:237] Iteration 72500, loss = 1.19719
I0523 17:14:45.245914 11620 solver.cpp:253]     Train net output #0: loss = 1.19719 (* 1 = 1.19719 loss)
I0523 17:14:45.245929 11620 sgd_solver.cpp:106] Iteration 72500, lr = 0.0025
I0523 17:14:54.362614 11620 solver.cpp:237] Iteration 72750, loss = 1.00056
I0523 17:14:54.362785 11620 solver.cpp:253]     Train net output #0: loss = 1.00056 (* 1 = 1.00056 loss)
I0523 17:14:54.362799 11620 sgd_solver.cpp:106] Iteration 72750, lr = 0.0025
I0523 17:15:03.476824 11620 solver.cpp:237] Iteration 73000, loss = 1.41939
I0523 17:15:03.476863 11620 solver.cpp:253]     Train net output #0: loss = 1.41939 (* 1 = 1.41939 loss)
I0523 17:15:03.476881 11620 sgd_solver.cpp:106] Iteration 73000, lr = 0.0025
I0523 17:15:12.589941 11620 solver.cpp:237] Iteration 73250, loss = 1.38739
I0523 17:15:12.589974 11620 solver.cpp:253]     Train net output #0: loss = 1.38739 (* 1 = 1.38739 loss)
I0523 17:15:12.589989 11620 sgd_solver.cpp:106] Iteration 73250, lr = 0.0025
I0523 17:15:42.581746 11620 solver.cpp:237] Iteration 73500, loss = 1.05039
I0523 17:15:42.581933 11620 solver.cpp:253]     Train net output #0: loss = 1.05039 (* 1 = 1.05039 loss)
I0523 17:15:42.581948 11620 sgd_solver.cpp:106] Iteration 73500, lr = 0.0025
I0523 17:15:51.700863 11620 solver.cpp:237] Iteration 73750, loss = 1.16649
I0523 17:15:51.700906 11620 solver.cpp:253]     Train net output #0: loss = 1.16649 (* 1 = 1.16649 loss)
I0523 17:15:51.700924 11620 sgd_solver.cpp:106] Iteration 73750, lr = 0.0025
I0523 17:16:00.809973 11620 solver.cpp:237] Iteration 74000, loss = 1.25206
I0523 17:16:00.810008 11620 solver.cpp:253]     Train net output #0: loss = 1.25206 (* 1 = 1.25206 loss)
I0523 17:16:00.810024 11620 sgd_solver.cpp:106] Iteration 74000, lr = 0.0025
I0523 17:16:09.926681 11620 solver.cpp:237] Iteration 74250, loss = 1.12218
I0523 17:16:09.926715 11620 solver.cpp:253]     Train net output #0: loss = 1.12218 (* 1 = 1.12218 loss)
I0523 17:16:09.926728 11620 sgd_solver.cpp:106] Iteration 74250, lr = 0.0025
I0523 17:16:19.029968 11620 solver.cpp:237] Iteration 74500, loss = 1.05295
I0523 17:16:19.030141 11620 solver.cpp:253]     Train net output #0: loss = 1.05295 (* 1 = 1.05295 loss)
I0523 17:16:19.030155 11620 sgd_solver.cpp:106] Iteration 74500, lr = 0.0025
I0523 17:16:28.150024 11620 solver.cpp:237] Iteration 74750, loss = 1.53766
I0523 17:16:28.150059 11620 solver.cpp:253]     Train net output #0: loss = 1.53766 (* 1 = 1.53766 loss)
I0523 17:16:28.150074 11620 sgd_solver.cpp:106] Iteration 74750, lr = 0.0025
I0523 17:16:37.235044 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_75000.caffemodel
I0523 17:16:37.300391 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_75000.solverstate
I0523 17:16:37.329015 11620 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 17:17:24.316481 11620 solver.cpp:409]     Test net output #0: accuracy = 0.89286
I0523 17:17:24.316674 11620 solver.cpp:409]     Test net output #1: loss = 0.362514 (* 1 = 0.362514 loss)
I0523 17:17:45.219326 11620 solver.cpp:237] Iteration 75000, loss = 1.40302
I0523 17:17:45.219377 11620 solver.cpp:253]     Train net output #0: loss = 1.40302 (* 1 = 1.40302 loss)
I0523 17:17:45.219393 11620 sgd_solver.cpp:106] Iteration 75000, lr = 0.0025
I0523 17:17:54.243871 11620 solver.cpp:237] Iteration 75250, loss = 1.12659
I0523 17:17:54.243914 11620 solver.cpp:253]     Train net output #0: loss = 1.12659 (* 1 = 1.12659 loss)
I0523 17:17:54.243932 11620 sgd_solver.cpp:106] Iteration 75250, lr = 0.0025
I0523 17:18:03.277994 11620 solver.cpp:237] Iteration 75500, loss = 1.40267
I0523 17:18:03.278167 11620 solver.cpp:253]     Train net output #0: loss = 1.40267 (* 1 = 1.40267 loss)
I0523 17:18:03.278180 11620 sgd_solver.cpp:106] Iteration 75500, lr = 0.0025
I0523 17:18:12.303444 11620 solver.cpp:237] Iteration 75750, loss = 1.26059
I0523 17:18:12.303479 11620 solver.cpp:253]     Train net output #0: loss = 1.26059 (* 1 = 1.26059 loss)
I0523 17:18:12.303494 11620 sgd_solver.cpp:106] Iteration 75750, lr = 0.0025
I0523 17:18:21.331729 11620 solver.cpp:237] Iteration 76000, loss = 0.856813
I0523 17:18:21.331773 11620 solver.cpp:253]     Train net output #0: loss = 0.856813 (* 1 = 0.856813 loss)
I0523 17:18:21.331791 11620 sgd_solver.cpp:106] Iteration 76000, lr = 0.0025
I0523 17:18:30.366533 11620 solver.cpp:237] Iteration 76250, loss = 1.2486
I0523 17:18:30.366567 11620 solver.cpp:253]     Train net output #0: loss = 1.2486 (* 1 = 1.2486 loss)
I0523 17:18:30.366581 11620 sgd_solver.cpp:106] Iteration 76250, lr = 0.0025
I0523 17:18:39.404206 11620 solver.cpp:237] Iteration 76500, loss = 1.43288
I0523 17:18:39.404369 11620 solver.cpp:253]     Train net output #0: loss = 1.43288 (* 1 = 1.43288 loss)
I0523 17:18:39.404382 11620 sgd_solver.cpp:106] Iteration 76500, lr = 0.0025
I0523 17:19:09.302793 11620 solver.cpp:237] Iteration 76750, loss = 1.08461
I0523 17:19:09.302842 11620 solver.cpp:253]     Train net output #0: loss = 1.08461 (* 1 = 1.08461 loss)
I0523 17:19:09.302857 11620 sgd_solver.cpp:106] Iteration 76750, lr = 0.0025
I0523 17:19:18.325124 11620 solver.cpp:237] Iteration 77000, loss = 1.11067
I0523 17:19:18.325292 11620 solver.cpp:253]     Train net output #0: loss = 1.11067 (* 1 = 1.11067 loss)
I0523 17:19:18.325305 11620 sgd_solver.cpp:106] Iteration 77000, lr = 0.0025
I0523 17:19:27.347406 11620 solver.cpp:237] Iteration 77250, loss = 1.52321
I0523 17:19:27.347440 11620 solver.cpp:253]     Train net output #0: loss = 1.52321 (* 1 = 1.52321 loss)
I0523 17:19:27.347455 11620 sgd_solver.cpp:106] Iteration 77250, lr = 0.0025
I0523 17:19:36.340996 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_77500.caffemodel
I0523 17:19:36.404671 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_77500.solverstate
I0523 17:19:36.442282 11620 solver.cpp:237] Iteration 77500, loss = 1.17215
I0523 17:19:36.442329 11620 solver.cpp:253]     Train net output #0: loss = 1.17215 (* 1 = 1.17215 loss)
I0523 17:19:36.442345 11620 sgd_solver.cpp:106] Iteration 77500, lr = 0.0025
I0523 17:19:45.474490 11620 solver.cpp:237] Iteration 77750, loss = 1.33273
I0523 17:19:45.474525 11620 solver.cpp:253]     Train net output #0: loss = 1.33273 (* 1 = 1.33273 loss)
I0523 17:19:45.474540 11620 sgd_solver.cpp:106] Iteration 77750, lr = 0.0025
I0523 17:19:54.501207 11620 solver.cpp:237] Iteration 78000, loss = 1.09581
I0523 17:19:54.501384 11620 solver.cpp:253]     Train net output #0: loss = 1.09581 (* 1 = 1.09581 loss)
I0523 17:19:54.501396 11620 sgd_solver.cpp:106] Iteration 78000, lr = 0.0025
I0523 17:20:03.534858 11620 solver.cpp:237] Iteration 78250, loss = 1.06417
I0523 17:20:03.534895 11620 solver.cpp:253]     Train net output #0: loss = 1.06417 (* 1 = 1.06417 loss)
I0523 17:20:03.534915 11620 sgd_solver.cpp:106] Iteration 78250, lr = 0.0025
I0523 17:20:33.422534 11620 solver.cpp:237] Iteration 78500, loss = 1.06186
I0523 17:20:33.422722 11620 solver.cpp:253]     Train net output #0: loss = 1.06186 (* 1 = 1.06186 loss)
I0523 17:20:33.422735 11620 sgd_solver.cpp:106] Iteration 78500, lr = 0.0025
I0523 17:20:42.451699 11620 solver.cpp:237] Iteration 78750, loss = 1.06788
I0523 17:20:42.451733 11620 solver.cpp:253]     Train net output #0: loss = 1.06788 (* 1 = 1.06788 loss)
I0523 17:20:42.451748 11620 sgd_solver.cpp:106] Iteration 78750, lr = 0.0025
I0523 17:20:51.479280 11620 solver.cpp:237] Iteration 79000, loss = 1.25719
I0523 17:20:51.479320 11620 solver.cpp:253]     Train net output #0: loss = 1.25719 (* 1 = 1.25719 loss)
I0523 17:20:51.479332 11620 sgd_solver.cpp:106] Iteration 79000, lr = 0.0025
I0523 17:21:00.507082 11620 solver.cpp:237] Iteration 79250, loss = 1.08013
I0523 17:21:00.507119 11620 solver.cpp:253]     Train net output #0: loss = 1.08013 (* 1 = 1.08013 loss)
I0523 17:21:00.507133 11620 sgd_solver.cpp:106] Iteration 79250, lr = 0.0025
I0523 17:21:09.534210 11620 solver.cpp:237] Iteration 79500, loss = 1.23391
I0523 17:21:09.534384 11620 solver.cpp:253]     Train net output #0: loss = 1.23391 (* 1 = 1.23391 loss)
I0523 17:21:09.534397 11620 sgd_solver.cpp:106] Iteration 79500, lr = 0.0025
I0523 17:21:18.567039 11620 solver.cpp:237] Iteration 79750, loss = 1.29511
I0523 17:21:18.567076 11620 solver.cpp:253]     Train net output #0: loss = 1.29511 (* 1 = 1.29511 loss)
I0523 17:21:18.567090 11620 sgd_solver.cpp:106] Iteration 79750, lr = 0.0025
I0523 17:21:27.562747 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_80000.caffemodel
I0523 17:21:27.625001 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_80000.solverstate
I0523 17:21:27.651437 11620 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 17:22:35.795194 11620 solver.cpp:409]     Test net output #0: accuracy = 0.89306
I0523 17:22:35.795382 11620 solver.cpp:409]     Test net output #1: loss = 0.343922 (* 1 = 0.343922 loss)
I0523 17:22:56.696449 11620 solver.cpp:237] Iteration 80000, loss = 1.08966
I0523 17:22:56.696501 11620 solver.cpp:253]     Train net output #0: loss = 1.08966 (* 1 = 1.08966 loss)
I0523 17:22:56.696516 11620 sgd_solver.cpp:106] Iteration 80000, lr = 0.0025
I0523 17:23:05.751680 11620 solver.cpp:237] Iteration 80250, loss = 1.23486
I0523 17:23:05.751715 11620 solver.cpp:253]     Train net output #0: loss = 1.23486 (* 1 = 1.23486 loss)
I0523 17:23:05.751731 11620 sgd_solver.cpp:106] Iteration 80250, lr = 0.0025
I0523 17:23:14.802635 11620 solver.cpp:237] Iteration 80500, loss = 0.87607
I0523 17:23:14.802819 11620 solver.cpp:253]     Train net output #0: loss = 0.87607 (* 1 = 0.87607 loss)
I0523 17:23:14.802834 11620 sgd_solver.cpp:106] Iteration 80500, lr = 0.0025
I0523 17:23:23.855865 11620 solver.cpp:237] Iteration 80750, loss = 1.33095
I0523 17:23:23.855907 11620 solver.cpp:253]     Train net output #0: loss = 1.33095 (* 1 = 1.33095 loss)
I0523 17:23:23.855924 11620 sgd_solver.cpp:106] Iteration 80750, lr = 0.0025
I0523 17:23:32.924762 11620 solver.cpp:237] Iteration 81000, loss = 1.01031
I0523 17:23:32.924798 11620 solver.cpp:253]     Train net output #0: loss = 1.01031 (* 1 = 1.01031 loss)
I0523 17:23:32.924810 11620 sgd_solver.cpp:106] Iteration 81000, lr = 0.0025
I0523 17:23:41.987558 11620 solver.cpp:237] Iteration 81250, loss = 1.19793
I0523 17:23:41.987607 11620 solver.cpp:253]     Train net output #0: loss = 1.19793 (* 1 = 1.19793 loss)
I0523 17:23:41.987619 11620 sgd_solver.cpp:106] Iteration 81250, lr = 0.0025
I0523 17:23:51.040786 11620 solver.cpp:237] Iteration 81500, loss = 0.985618
I0523 17:23:51.040966 11620 solver.cpp:253]     Train net output #0: loss = 0.985618 (* 1 = 0.985618 loss)
I0523 17:23:51.040979 11620 sgd_solver.cpp:106] Iteration 81500, lr = 0.0025
I0523 17:24:20.983520 11620 solver.cpp:237] Iteration 81750, loss = 1.28558
I0523 17:24:20.983568 11620 solver.cpp:253]     Train net output #0: loss = 1.28558 (* 1 = 1.28558 loss)
I0523 17:24:20.983583 11620 sgd_solver.cpp:106] Iteration 81750, lr = 0.0025
I0523 17:24:30.031745 11620 solver.cpp:237] Iteration 82000, loss = 1.02221
I0523 17:24:30.031918 11620 solver.cpp:253]     Train net output #0: loss = 1.02221 (* 1 = 1.02221 loss)
I0523 17:24:30.031931 11620 sgd_solver.cpp:106] Iteration 82000, lr = 0.0025
I0523 17:24:39.100361 11620 solver.cpp:237] Iteration 82250, loss = 1.23508
I0523 17:24:39.100399 11620 solver.cpp:253]     Train net output #0: loss = 1.23508 (* 1 = 1.23508 loss)
I0523 17:24:39.100411 11620 sgd_solver.cpp:106] Iteration 82250, lr = 0.0025
I0523 17:24:48.118366 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_82500.caffemodel
I0523 17:24:48.181697 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_82500.solverstate
I0523 17:24:48.219166 11620 solver.cpp:237] Iteration 82500, loss = 1.07582
I0523 17:24:48.219213 11620 solver.cpp:253]     Train net output #0: loss = 1.07582 (* 1 = 1.07582 loss)
I0523 17:24:48.219229 11620 sgd_solver.cpp:106] Iteration 82500, lr = 0.0025
I0523 17:24:57.261551 11620 solver.cpp:237] Iteration 82750, loss = 0.989979
I0523 17:24:57.261595 11620 solver.cpp:253]     Train net output #0: loss = 0.989979 (* 1 = 0.989979 loss)
I0523 17:24:57.261611 11620 sgd_solver.cpp:106] Iteration 82750, lr = 0.0025
I0523 17:25:06.310184 11620 solver.cpp:237] Iteration 83000, loss = 0.902539
I0523 17:25:06.310364 11620 solver.cpp:253]     Train net output #0: loss = 0.902539 (* 1 = 0.902539 loss)
I0523 17:25:06.310377 11620 sgd_solver.cpp:106] Iteration 83000, lr = 0.0025
I0523 17:25:15.378033 11620 solver.cpp:237] Iteration 83250, loss = 1.15106
I0523 17:25:15.378068 11620 solver.cpp:253]     Train net output #0: loss = 1.15106 (* 1 = 1.15106 loss)
I0523 17:25:15.378083 11620 sgd_solver.cpp:106] Iteration 83250, lr = 0.0025
I0523 17:25:45.280033 11620 solver.cpp:237] Iteration 83500, loss = 1.1171
I0523 17:25:45.280227 11620 solver.cpp:253]     Train net output #0: loss = 1.1171 (* 1 = 1.1171 loss)
I0523 17:25:45.280241 11620 sgd_solver.cpp:106] Iteration 83500, lr = 0.0025
I0523 17:25:54.342376 11620 solver.cpp:237] Iteration 83750, loss = 1.20911
I0523 17:25:54.342422 11620 solver.cpp:253]     Train net output #0: loss = 1.20911 (* 1 = 1.20911 loss)
I0523 17:25:54.342437 11620 sgd_solver.cpp:106] Iteration 83750, lr = 0.0025
I0523 17:26:03.406263 11620 solver.cpp:237] Iteration 84000, loss = 1.08316
I0523 17:26:03.406299 11620 solver.cpp:253]     Train net output #0: loss = 1.08316 (* 1 = 1.08316 loss)
I0523 17:26:03.406313 11620 sgd_solver.cpp:106] Iteration 84000, lr = 0.0025
I0523 17:26:12.474252 11620 solver.cpp:237] Iteration 84250, loss = 1.03082
I0523 17:26:12.474303 11620 solver.cpp:253]     Train net output #0: loss = 1.03082 (* 1 = 1.03082 loss)
I0523 17:26:12.474318 11620 sgd_solver.cpp:106] Iteration 84250, lr = 0.0025
I0523 17:26:21.534267 11620 solver.cpp:237] Iteration 84500, loss = 1.21813
I0523 17:26:21.534438 11620 solver.cpp:253]     Train net output #0: loss = 1.21813 (* 1 = 1.21813 loss)
I0523 17:26:21.534453 11620 sgd_solver.cpp:106] Iteration 84500, lr = 0.0025
I0523 17:26:30.598762 11620 solver.cpp:237] Iteration 84750, loss = 1.06007
I0523 17:26:30.598798 11620 solver.cpp:253]     Train net output #0: loss = 1.06007 (* 1 = 1.06007 loss)
I0523 17:26:30.598812 11620 sgd_solver.cpp:106] Iteration 84750, lr = 0.0025
I0523 17:26:39.624974 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_85000.caffemodel
I0523 17:26:39.688293 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_85000.solverstate
I0523 17:26:39.714699 11620 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 17:27:27.046581 11620 solver.cpp:409]     Test net output #0: accuracy = 0.892885
I0523 17:27:27.046768 11620 solver.cpp:409]     Test net output #1: loss = 0.361226 (* 1 = 0.361226 loss)
I0523 17:27:47.941963 11620 solver.cpp:237] Iteration 85000, loss = 1.00241
I0523 17:27:47.942019 11620 solver.cpp:253]     Train net output #0: loss = 1.00241 (* 1 = 1.00241 loss)
I0523 17:27:47.942034 11620 sgd_solver.cpp:106] Iteration 85000, lr = 0.0025
I0523 17:27:56.958190 11620 solver.cpp:237] Iteration 85250, loss = 1.19034
I0523 17:27:56.958238 11620 solver.cpp:253]     Train net output #0: loss = 1.19034 (* 1 = 1.19034 loss)
I0523 17:27:56.958252 11620 sgd_solver.cpp:106] Iteration 85250, lr = 0.0025
I0523 17:28:05.972031 11620 solver.cpp:237] Iteration 85500, loss = 1.4071
I0523 17:28:05.972213 11620 solver.cpp:253]     Train net output #0: loss = 1.4071 (* 1 = 1.4071 loss)
I0523 17:28:05.972225 11620 sgd_solver.cpp:106] Iteration 85500, lr = 0.0025
I0523 17:28:14.982111 11620 solver.cpp:237] Iteration 85750, loss = 1.26409
I0523 17:28:14.982146 11620 solver.cpp:253]     Train net output #0: loss = 1.26409 (* 1 = 1.26409 loss)
I0523 17:28:14.982161 11620 sgd_solver.cpp:106] Iteration 85750, lr = 0.0025
I0523 17:28:23.990499 11620 solver.cpp:237] Iteration 86000, loss = 1.16234
I0523 17:28:23.990536 11620 solver.cpp:253]     Train net output #0: loss = 1.16234 (* 1 = 1.16234 loss)
I0523 17:28:23.990550 11620 sgd_solver.cpp:106] Iteration 86000, lr = 0.0025
I0523 17:28:33.000885 11620 solver.cpp:237] Iteration 86250, loss = 1.03929
I0523 17:28:33.000921 11620 solver.cpp:253]     Train net output #0: loss = 1.03929 (* 1 = 1.03929 loss)
I0523 17:28:33.000934 11620 sgd_solver.cpp:106] Iteration 86250, lr = 0.0025
I0523 17:28:42.008424 11620 solver.cpp:237] Iteration 86500, loss = 0.966101
I0523 17:28:42.008592 11620 solver.cpp:253]     Train net output #0: loss = 0.966101 (* 1 = 0.966101 loss)
I0523 17:28:42.008607 11620 sgd_solver.cpp:106] Iteration 86500, lr = 0.0025
I0523 17:29:11.902984 11620 solver.cpp:237] Iteration 86750, loss = 1.32038
I0523 17:29:11.903033 11620 solver.cpp:253]     Train net output #0: loss = 1.32038 (* 1 = 1.32038 loss)
I0523 17:29:11.903048 11620 sgd_solver.cpp:106] Iteration 86750, lr = 0.0025
I0523 17:29:20.915895 11620 solver.cpp:237] Iteration 87000, loss = 1.12325
I0523 17:29:20.916076 11620 solver.cpp:253]     Train net output #0: loss = 1.12325 (* 1 = 1.12325 loss)
I0523 17:29:20.916090 11620 sgd_solver.cpp:106] Iteration 87000, lr = 0.0025
I0523 17:29:29.923310 11620 solver.cpp:237] Iteration 87250, loss = 1.16046
I0523 17:29:29.923343 11620 solver.cpp:253]     Train net output #0: loss = 1.16046 (* 1 = 1.16046 loss)
I0523 17:29:29.923358 11620 sgd_solver.cpp:106] Iteration 87250, lr = 0.0025
I0523 17:29:38.908143 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_87500.caffemodel
I0523 17:29:38.973106 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_87500.solverstate
I0523 17:29:39.012629 11620 solver.cpp:237] Iteration 87500, loss = 1.1881
I0523 17:29:39.012676 11620 solver.cpp:253]     Train net output #0: loss = 1.1881 (* 1 = 1.1881 loss)
I0523 17:29:39.012694 11620 sgd_solver.cpp:106] Iteration 87500, lr = 0.0025
I0523 17:29:48.027477 11620 solver.cpp:237] Iteration 87750, loss = 1.24831
I0523 17:29:48.027513 11620 solver.cpp:253]     Train net output #0: loss = 1.24831 (* 1 = 1.24831 loss)
I0523 17:29:48.027529 11620 sgd_solver.cpp:106] Iteration 87750, lr = 0.0025
I0523 17:29:57.032114 11620 solver.cpp:237] Iteration 88000, loss = 1.33425
I0523 17:29:57.032299 11620 solver.cpp:253]     Train net output #0: loss = 1.33425 (* 1 = 1.33425 loss)
I0523 17:29:57.032313 11620 sgd_solver.cpp:106] Iteration 88000, lr = 0.0025
I0523 17:30:06.045734 11620 solver.cpp:237] Iteration 88250, loss = 1.36288
I0523 17:30:06.045768 11620 solver.cpp:253]     Train net output #0: loss = 1.36288 (* 1 = 1.36288 loss)
I0523 17:30:06.045784 11620 sgd_solver.cpp:106] Iteration 88250, lr = 0.0025
I0523 17:30:35.929622 11620 solver.cpp:237] Iteration 88500, loss = 1.10638
I0523 17:30:35.929811 11620 solver.cpp:253]     Train net output #0: loss = 1.10638 (* 1 = 1.10638 loss)
I0523 17:30:35.929826 11620 sgd_solver.cpp:106] Iteration 88500, lr = 0.0025
I0523 17:30:44.940207 11620 solver.cpp:237] Iteration 88750, loss = 1.13013
I0523 17:30:44.940237 11620 solver.cpp:253]     Train net output #0: loss = 1.13013 (* 1 = 1.13013 loss)
I0523 17:30:44.940250 11620 sgd_solver.cpp:106] Iteration 88750, lr = 0.0025
I0523 17:30:53.953510 11620 solver.cpp:237] Iteration 89000, loss = 1.12434
I0523 17:30:53.953554 11620 solver.cpp:253]     Train net output #0: loss = 1.12434 (* 1 = 1.12434 loss)
I0523 17:30:53.953570 11620 sgd_solver.cpp:106] Iteration 89000, lr = 0.0025
I0523 17:31:02.965674 11620 solver.cpp:237] Iteration 89250, loss = 1.30964
I0523 17:31:02.965708 11620 solver.cpp:253]     Train net output #0: loss = 1.30964 (* 1 = 1.30964 loss)
I0523 17:31:02.965723 11620 sgd_solver.cpp:106] Iteration 89250, lr = 0.0025
I0523 17:31:11.971081 11620 solver.cpp:237] Iteration 89500, loss = 1.13361
I0523 17:31:11.971268 11620 solver.cpp:253]     Train net output #0: loss = 1.13361 (* 1 = 1.13361 loss)
I0523 17:31:11.971282 11620 sgd_solver.cpp:106] Iteration 89500, lr = 0.0025
I0523 17:31:20.976450 11620 solver.cpp:237] Iteration 89750, loss = 1.08232
I0523 17:31:20.976485 11620 solver.cpp:253]     Train net output #0: loss = 1.08232 (* 1 = 1.08232 loss)
I0523 17:31:20.976501 11620 sgd_solver.cpp:106] Iteration 89750, lr = 0.0025
I0523 17:31:29.950765 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_90000.caffemodel
I0523 17:31:30.016258 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_90000.solverstate
I0523 17:31:30.044960 11620 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 17:32:38.220351 11620 solver.cpp:409]     Test net output #0: accuracy = 0.896192
I0523 17:32:38.220541 11620 solver.cpp:409]     Test net output #1: loss = 0.327163 (* 1 = 0.327163 loss)
I0523 17:32:59.089750 11620 solver.cpp:237] Iteration 90000, loss = 1.05378
I0523 17:32:59.089802 11620 solver.cpp:253]     Train net output #0: loss = 1.05378 (* 1 = 1.05378 loss)
I0523 17:32:59.089815 11620 sgd_solver.cpp:106] Iteration 90000, lr = 0.0025
I0523 17:33:08.196946 11620 solver.cpp:237] Iteration 90250, loss = 1.12128
I0523 17:33:08.196981 11620 solver.cpp:253]     Train net output #0: loss = 1.12128 (* 1 = 1.12128 loss)
I0523 17:33:08.196996 11620 sgd_solver.cpp:106] Iteration 90250, lr = 0.0025
I0523 17:33:17.292044 11620 solver.cpp:237] Iteration 90500, loss = 1.17276
I0523 17:33:17.292229 11620 solver.cpp:253]     Train net output #0: loss = 1.17276 (* 1 = 1.17276 loss)
I0523 17:33:17.292243 11620 sgd_solver.cpp:106] Iteration 90500, lr = 0.0025
I0523 17:33:26.394204 11620 solver.cpp:237] Iteration 90750, loss = 1.11112
I0523 17:33:26.394238 11620 solver.cpp:253]     Train net output #0: loss = 1.11112 (* 1 = 1.11112 loss)
I0523 17:33:26.394254 11620 sgd_solver.cpp:106] Iteration 90750, lr = 0.0025
I0523 17:33:35.497303 11620 solver.cpp:237] Iteration 91000, loss = 1.26347
I0523 17:33:35.497337 11620 solver.cpp:253]     Train net output #0: loss = 1.26347 (* 1 = 1.26347 loss)
I0523 17:33:35.497352 11620 sgd_solver.cpp:106] Iteration 91000, lr = 0.0025
I0523 17:33:44.596976 11620 solver.cpp:237] Iteration 91250, loss = 1.07145
I0523 17:33:44.597019 11620 solver.cpp:253]     Train net output #0: loss = 1.07145 (* 1 = 1.07145 loss)
I0523 17:33:44.597035 11620 sgd_solver.cpp:106] Iteration 91250, lr = 0.0025
I0523 17:33:53.708498 11620 solver.cpp:237] Iteration 91500, loss = 1.07313
I0523 17:33:53.708678 11620 solver.cpp:253]     Train net output #0: loss = 1.07313 (* 1 = 1.07313 loss)
I0523 17:33:53.708691 11620 sgd_solver.cpp:106] Iteration 91500, lr = 0.0025
I0523 17:34:23.669550 11620 solver.cpp:237] Iteration 91750, loss = 1.16459
I0523 17:34:23.669600 11620 solver.cpp:253]     Train net output #0: loss = 1.16459 (* 1 = 1.16459 loss)
I0523 17:34:23.669615 11620 sgd_solver.cpp:106] Iteration 91750, lr = 0.0025
I0523 17:34:32.766540 11620 solver.cpp:237] Iteration 92000, loss = 1.10017
I0523 17:34:32.766726 11620 solver.cpp:253]     Train net output #0: loss = 1.10017 (* 1 = 1.10017 loss)
I0523 17:34:32.766739 11620 sgd_solver.cpp:106] Iteration 92000, lr = 0.0025
I0523 17:34:41.871275 11620 solver.cpp:237] Iteration 92250, loss = 0.955784
I0523 17:34:41.871310 11620 solver.cpp:253]     Train net output #0: loss = 0.955784 (* 1 = 0.955784 loss)
I0523 17:34:41.871326 11620 sgd_solver.cpp:106] Iteration 92250, lr = 0.0025
I0523 17:34:50.936280 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_92500.caffemodel
I0523 17:34:50.999418 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_92500.solverstate
I0523 17:34:51.037133 11620 solver.cpp:237] Iteration 92500, loss = 1.18149
I0523 17:34:51.037179 11620 solver.cpp:253]     Train net output #0: loss = 1.18149 (* 1 = 1.18149 loss)
I0523 17:34:51.037194 11620 sgd_solver.cpp:106] Iteration 92500, lr = 0.0025
I0523 17:35:00.141057 11620 solver.cpp:237] Iteration 92750, loss = 1.36854
I0523 17:35:00.141098 11620 solver.cpp:253]     Train net output #0: loss = 1.36854 (* 1 = 1.36854 loss)
I0523 17:35:00.141116 11620 sgd_solver.cpp:106] Iteration 92750, lr = 0.0025
I0523 17:35:09.257637 11620 solver.cpp:237] Iteration 93000, loss = 1.23935
I0523 17:35:09.257813 11620 solver.cpp:253]     Train net output #0: loss = 1.23935 (* 1 = 1.23935 loss)
I0523 17:35:09.257827 11620 sgd_solver.cpp:106] Iteration 93000, lr = 0.0025
I0523 17:35:18.357601 11620 solver.cpp:237] Iteration 93250, loss = 1.06741
I0523 17:35:18.357635 11620 solver.cpp:253]     Train net output #0: loss = 1.06741 (* 1 = 1.06741 loss)
I0523 17:35:18.357650 11620 sgd_solver.cpp:106] Iteration 93250, lr = 0.0025
I0523 17:35:48.347184 11620 solver.cpp:237] Iteration 93500, loss = 1.11999
I0523 17:35:48.347379 11620 solver.cpp:253]     Train net output #0: loss = 1.11999 (* 1 = 1.11999 loss)
I0523 17:35:48.347393 11620 sgd_solver.cpp:106] Iteration 93500, lr = 0.0025
I0523 17:35:57.447443 11620 solver.cpp:237] Iteration 93750, loss = 1.30082
I0523 17:35:57.447477 11620 solver.cpp:253]     Train net output #0: loss = 1.30082 (* 1 = 1.30082 loss)
I0523 17:35:57.447492 11620 sgd_solver.cpp:106] Iteration 93750, lr = 0.0025
I0523 17:36:06.555869 11620 solver.cpp:237] Iteration 94000, loss = 1.06618
I0523 17:36:06.555904 11620 solver.cpp:253]     Train net output #0: loss = 1.06618 (* 1 = 1.06618 loss)
I0523 17:36:06.555919 11620 sgd_solver.cpp:106] Iteration 94000, lr = 0.0025
I0523 17:36:15.663944 11620 solver.cpp:237] Iteration 94250, loss = 1.09342
I0523 17:36:15.663990 11620 solver.cpp:253]     Train net output #0: loss = 1.09342 (* 1 = 1.09342 loss)
I0523 17:36:15.664005 11620 sgd_solver.cpp:106] Iteration 94250, lr = 0.0025
I0523 17:36:24.775745 11620 solver.cpp:237] Iteration 94500, loss = 0.725472
I0523 17:36:24.775930 11620 solver.cpp:253]     Train net output #0: loss = 0.725472 (* 1 = 0.725472 loss)
I0523 17:36:24.775943 11620 sgd_solver.cpp:106] Iteration 94500, lr = 0.0025
I0523 17:36:33.886657 11620 solver.cpp:237] Iteration 94750, loss = 1.15362
I0523 17:36:33.886692 11620 solver.cpp:253]     Train net output #0: loss = 1.15362 (* 1 = 1.15362 loss)
I0523 17:36:33.886705 11620 sgd_solver.cpp:106] Iteration 94750, lr = 0.0025
I0523 17:36:42.952823 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_95000.caffemodel
I0523 17:36:43.015200 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_95000.solverstate
I0523 17:36:43.041223 11620 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 17:37:30.030793 11620 solver.cpp:409]     Test net output #0: accuracy = 0.894026
I0523 17:37:30.030982 11620 solver.cpp:409]     Test net output #1: loss = 0.33416 (* 1 = 0.33416 loss)
I0523 17:37:50.920260 11620 solver.cpp:237] Iteration 95000, loss = 1.19916
I0523 17:37:50.920313 11620 solver.cpp:253]     Train net output #0: loss = 1.19916 (* 1 = 1.19916 loss)
I0523 17:37:50.920328 11620 sgd_solver.cpp:106] Iteration 95000, lr = 0.0025
I0523 17:37:59.998217 11620 solver.cpp:237] Iteration 95250, loss = 1.20566
I0523 17:37:59.998255 11620 solver.cpp:253]     Train net output #0: loss = 1.20566 (* 1 = 1.20566 loss)
I0523 17:37:59.998275 11620 sgd_solver.cpp:106] Iteration 95250, lr = 0.0025
I0523 17:38:09.069970 11620 solver.cpp:237] Iteration 95500, loss = 1.0703
I0523 17:38:09.070147 11620 solver.cpp:253]     Train net output #0: loss = 1.0703 (* 1 = 1.0703 loss)
I0523 17:38:09.070159 11620 sgd_solver.cpp:106] Iteration 95500, lr = 0.0025
I0523 17:38:18.142259 11620 solver.cpp:237] Iteration 95750, loss = 1.15722
I0523 17:38:18.142304 11620 solver.cpp:253]     Train net output #0: loss = 1.15722 (* 1 = 1.15722 loss)
I0523 17:38:18.142320 11620 sgd_solver.cpp:106] Iteration 95750, lr = 0.0025
I0523 17:38:27.214484 11620 solver.cpp:237] Iteration 96000, loss = 0.992434
I0523 17:38:27.214520 11620 solver.cpp:253]     Train net output #0: loss = 0.992434 (* 1 = 0.992434 loss)
I0523 17:38:27.214534 11620 sgd_solver.cpp:106] Iteration 96000, lr = 0.0025
I0523 17:38:36.289505 11620 solver.cpp:237] Iteration 96250, loss = 1.10097
I0523 17:38:36.289541 11620 solver.cpp:253]     Train net output #0: loss = 1.10097 (* 1 = 1.10097 loss)
I0523 17:38:36.289554 11620 sgd_solver.cpp:106] Iteration 96250, lr = 0.0025
I0523 17:38:45.371536 11620 solver.cpp:237] Iteration 96500, loss = 0.988184
I0523 17:38:45.371733 11620 solver.cpp:253]     Train net output #0: loss = 0.988184 (* 1 = 0.988184 loss)
I0523 17:38:45.371747 11620 sgd_solver.cpp:106] Iteration 96500, lr = 0.0025
I0523 17:39:15.299810 11620 solver.cpp:237] Iteration 96750, loss = 1.04806
I0523 17:39:15.299860 11620 solver.cpp:253]     Train net output #0: loss = 1.04806 (* 1 = 1.04806 loss)
I0523 17:39:15.299875 11620 sgd_solver.cpp:106] Iteration 96750, lr = 0.0025
I0523 17:39:24.381644 11620 solver.cpp:237] Iteration 97000, loss = 1.16293
I0523 17:39:24.381822 11620 solver.cpp:253]     Train net output #0: loss = 1.16293 (* 1 = 1.16293 loss)
I0523 17:39:24.381835 11620 sgd_solver.cpp:106] Iteration 97000, lr = 0.0025
I0523 17:39:33.461946 11620 solver.cpp:237] Iteration 97250, loss = 1.18986
I0523 17:39:33.461987 11620 solver.cpp:253]     Train net output #0: loss = 1.18986 (* 1 = 1.18986 loss)
I0523 17:39:33.462000 11620 sgd_solver.cpp:106] Iteration 97250, lr = 0.0025
I0523 17:39:42.496642 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_97500.caffemodel
I0523 17:39:42.559973 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_97500.solverstate
I0523 17:39:42.597738 11620 solver.cpp:237] Iteration 97500, loss = 1.54447
I0523 17:39:42.597782 11620 solver.cpp:253]     Train net output #0: loss = 1.54447 (* 1 = 1.54447 loss)
I0523 17:39:42.597798 11620 sgd_solver.cpp:106] Iteration 97500, lr = 0.0025
I0523 17:39:51.678905 11620 solver.cpp:237] Iteration 97750, loss = 1.04301
I0523 17:39:51.678941 11620 solver.cpp:253]     Train net output #0: loss = 1.04301 (* 1 = 1.04301 loss)
I0523 17:39:51.678956 11620 sgd_solver.cpp:106] Iteration 97750, lr = 0.0025
I0523 17:40:00.751478 11620 solver.cpp:237] Iteration 98000, loss = 1.12575
I0523 17:40:00.751677 11620 solver.cpp:253]     Train net output #0: loss = 1.12575 (* 1 = 1.12575 loss)
I0523 17:40:00.751690 11620 sgd_solver.cpp:106] Iteration 98000, lr = 0.0025
I0523 17:40:09.823885 11620 solver.cpp:237] Iteration 98250, loss = 0.975574
I0523 17:40:09.823920 11620 solver.cpp:253]     Train net output #0: loss = 0.975574 (* 1 = 0.975574 loss)
I0523 17:40:09.823935 11620 sgd_solver.cpp:106] Iteration 98250, lr = 0.0025
I0523 17:40:39.795017 11620 solver.cpp:237] Iteration 98500, loss = 1.20428
I0523 17:40:39.795213 11620 solver.cpp:253]     Train net output #0: loss = 1.20428 (* 1 = 1.20428 loss)
I0523 17:40:39.795228 11620 sgd_solver.cpp:106] Iteration 98500, lr = 0.0025
I0523 17:40:48.868628 11620 solver.cpp:237] Iteration 98750, loss = 1.04843
I0523 17:40:48.868667 11620 solver.cpp:253]     Train net output #0: loss = 1.04843 (* 1 = 1.04843 loss)
I0523 17:40:48.868687 11620 sgd_solver.cpp:106] Iteration 98750, lr = 0.0025
I0523 17:40:57.942296 11620 solver.cpp:237] Iteration 99000, loss = 1.27313
I0523 17:40:57.942330 11620 solver.cpp:253]     Train net output #0: loss = 1.27313 (* 1 = 1.27313 loss)
I0523 17:40:57.942344 11620 sgd_solver.cpp:106] Iteration 99000, lr = 0.0025
I0523 17:41:07.012439 11620 solver.cpp:237] Iteration 99250, loss = 1.40744
I0523 17:41:07.012475 11620 solver.cpp:253]     Train net output #0: loss = 1.40744 (* 1 = 1.40744 loss)
I0523 17:41:07.012490 11620 sgd_solver.cpp:106] Iteration 99250, lr = 0.0025
I0523 17:41:16.089145 11620 solver.cpp:237] Iteration 99500, loss = 1.12095
I0523 17:41:16.089334 11620 solver.cpp:253]     Train net output #0: loss = 1.12095 (* 1 = 1.12095 loss)
I0523 17:41:16.089347 11620 sgd_solver.cpp:106] Iteration 99500, lr = 0.0025
I0523 17:41:25.169539 11620 solver.cpp:237] Iteration 99750, loss = 1.14177
I0523 17:41:25.169574 11620 solver.cpp:253]     Train net output #0: loss = 1.14177 (* 1 = 1.14177 loss)
I0523 17:41:25.169589 11620 sgd_solver.cpp:106] Iteration 99750, lr = 0.0025
I0523 17:41:34.204802 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_100000.caffemodel
I0523 17:41:34.269495 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_100000.solverstate
I0523 17:41:34.296633 11620 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 17:42:42.491212 11620 solver.cpp:409]     Test net output #0: accuracy = 0.894713
I0523 17:42:42.491405 11620 solver.cpp:409]     Test net output #1: loss = 0.346161 (* 1 = 0.346161 loss)
I0523 17:43:03.371031 11620 solver.cpp:237] Iteration 100000, loss = 1.2611
I0523 17:43:03.371084 11620 solver.cpp:253]     Train net output #0: loss = 1.2611 (* 1 = 1.2611 loss)
I0523 17:43:03.371099 11620 sgd_solver.cpp:106] Iteration 100000, lr = 0.0025
I0523 17:43:12.487195 11620 solver.cpp:237] Iteration 100250, loss = 1.03319
I0523 17:43:12.487231 11620 solver.cpp:253]     Train net output #0: loss = 1.03319 (* 1 = 1.03319 loss)
I0523 17:43:12.487246 11620 sgd_solver.cpp:106] Iteration 100250, lr = 0.0025
I0523 17:43:21.602212 11620 solver.cpp:237] Iteration 100500, loss = 1.52213
I0523 17:43:21.602414 11620 solver.cpp:253]     Train net output #0: loss = 1.52213 (* 1 = 1.52213 loss)
I0523 17:43:21.602428 11620 sgd_solver.cpp:106] Iteration 100500, lr = 0.0025
I0523 17:43:30.711071 11620 solver.cpp:237] Iteration 100750, loss = 1.17451
I0523 17:43:30.711105 11620 solver.cpp:253]     Train net output #0: loss = 1.17451 (* 1 = 1.17451 loss)
I0523 17:43:30.711122 11620 sgd_solver.cpp:106] Iteration 100750, lr = 0.0025
I0523 17:43:39.830327 11620 solver.cpp:237] Iteration 101000, loss = 1.24635
I0523 17:43:39.830360 11620 solver.cpp:253]     Train net output #0: loss = 1.24635 (* 1 = 1.24635 loss)
I0523 17:43:39.830377 11620 sgd_solver.cpp:106] Iteration 101000, lr = 0.0025
I0523 17:43:48.955015 11620 solver.cpp:237] Iteration 101250, loss = 1.25237
I0523 17:43:48.955057 11620 solver.cpp:253]     Train net output #0: loss = 1.25237 (* 1 = 1.25237 loss)
I0523 17:43:48.955071 11620 sgd_solver.cpp:106] Iteration 101250, lr = 0.0025
I0523 17:43:58.063330 11620 solver.cpp:237] Iteration 101500, loss = 1.22194
I0523 17:43:58.063505 11620 solver.cpp:253]     Train net output #0: loss = 1.22194 (* 1 = 1.22194 loss)
I0523 17:43:58.063519 11620 sgd_solver.cpp:106] Iteration 101500, lr = 0.0025
I0523 17:44:28.061204 11620 solver.cpp:237] Iteration 101750, loss = 1.21843
I0523 17:44:28.061254 11620 solver.cpp:253]     Train net output #0: loss = 1.21843 (* 1 = 1.21843 loss)
I0523 17:44:28.061269 11620 sgd_solver.cpp:106] Iteration 101750, lr = 0.0025
I0523 17:44:37.175272 11620 solver.cpp:237] Iteration 102000, loss = 1.17059
I0523 17:44:37.175462 11620 solver.cpp:253]     Train net output #0: loss = 1.17059 (* 1 = 1.17059 loss)
I0523 17:44:37.175477 11620 sgd_solver.cpp:106] Iteration 102000, lr = 0.0025
I0523 17:44:46.289973 11620 solver.cpp:237] Iteration 102250, loss = 1.24867
I0523 17:44:46.290009 11620 solver.cpp:253]     Train net output #0: loss = 1.24867 (* 1 = 1.24867 loss)
I0523 17:44:46.290024 11620 sgd_solver.cpp:106] Iteration 102250, lr = 0.0025
I0523 17:44:55.366251 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_102500.caffemodel
I0523 17:44:55.428817 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_102500.solverstate
I0523 17:44:55.467201 11620 solver.cpp:237] Iteration 102500, loss = 1.0903
I0523 17:44:55.467243 11620 solver.cpp:253]     Train net output #0: loss = 1.0903 (* 1 = 1.0903 loss)
I0523 17:44:55.467263 11620 sgd_solver.cpp:106] Iteration 102500, lr = 0.0025
I0523 17:45:04.592777 11620 solver.cpp:237] Iteration 102750, loss = 1.37523
I0523 17:45:04.592823 11620 solver.cpp:253]     Train net output #0: loss = 1.37523 (* 1 = 1.37523 loss)
I0523 17:45:04.592838 11620 sgd_solver.cpp:106] Iteration 102750, lr = 0.0025
I0523 17:45:13.707739 11620 solver.cpp:237] Iteration 103000, loss = 1.17387
I0523 17:45:13.707921 11620 solver.cpp:253]     Train net output #0: loss = 1.17387 (* 1 = 1.17387 loss)
I0523 17:45:13.707936 11620 sgd_solver.cpp:106] Iteration 103000, lr = 0.0025
I0523 17:45:22.818514 11620 solver.cpp:237] Iteration 103250, loss = 1.02534
I0523 17:45:22.818564 11620 solver.cpp:253]     Train net output #0: loss = 1.02534 (* 1 = 1.02534 loss)
I0523 17:45:22.818578 11620 sgd_solver.cpp:106] Iteration 103250, lr = 0.0025
I0523 17:45:52.779640 11620 solver.cpp:237] Iteration 103500, loss = 1.17707
I0523 17:45:52.779832 11620 solver.cpp:253]     Train net output #0: loss = 1.17707 (* 1 = 1.17707 loss)
I0523 17:45:52.779846 11620 sgd_solver.cpp:106] Iteration 103500, lr = 0.0025
I0523 17:46:01.888967 11620 solver.cpp:237] Iteration 103750, loss = 1.1924
I0523 17:46:01.889000 11620 solver.cpp:253]     Train net output #0: loss = 1.1924 (* 1 = 1.1924 loss)
I0523 17:46:01.889015 11620 sgd_solver.cpp:106] Iteration 103750, lr = 0.0025
I0523 17:46:11.007401 11620 solver.cpp:237] Iteration 104000, loss = 1.46932
I0523 17:46:11.007437 11620 solver.cpp:253]     Train net output #0: loss = 1.46932 (* 1 = 1.46932 loss)
I0523 17:46:11.007450 11620 sgd_solver.cpp:106] Iteration 104000, lr = 0.0025
I0523 17:46:20.116061 11620 solver.cpp:237] Iteration 104250, loss = 1.12742
I0523 17:46:20.116101 11620 solver.cpp:253]     Train net output #0: loss = 1.12742 (* 1 = 1.12742 loss)
I0523 17:46:20.116119 11620 sgd_solver.cpp:106] Iteration 104250, lr = 0.0025
I0523 17:46:29.234194 11620 solver.cpp:237] Iteration 104500, loss = 1.39179
I0523 17:46:29.234380 11620 solver.cpp:253]     Train net output #0: loss = 1.39179 (* 1 = 1.39179 loss)
I0523 17:46:29.234393 11620 sgd_solver.cpp:106] Iteration 104500, lr = 0.0025
I0523 17:46:38.352089 11620 solver.cpp:237] Iteration 104750, loss = 1.15759
I0523 17:46:38.352133 11620 solver.cpp:253]     Train net output #0: loss = 1.15759 (* 1 = 1.15759 loss)
I0523 17:46:38.352149 11620 sgd_solver.cpp:106] Iteration 104750, lr = 0.0025
I0523 17:46:47.425282 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_105000.caffemodel
I0523 17:46:47.489760 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_105000.solverstate
I0523 17:46:47.516146 11620 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 17:47:34.745748 11620 solver.cpp:409]     Test net output #0: accuracy = 0.896321
I0523 17:47:34.745941 11620 solver.cpp:409]     Test net output #1: loss = 0.320971 (* 1 = 0.320971 loss)
I0523 17:47:55.612552 11620 solver.cpp:237] Iteration 105000, loss = 1.06654
I0523 17:47:55.612604 11620 solver.cpp:253]     Train net output #0: loss = 1.06654 (* 1 = 1.06654 loss)
I0523 17:47:55.612620 11620 sgd_solver.cpp:106] Iteration 105000, lr = 0.0025
I0523 17:48:04.637100 11620 solver.cpp:237] Iteration 105250, loss = 1.38008
I0523 17:48:04.637135 11620 solver.cpp:253]     Train net output #0: loss = 1.38008 (* 1 = 1.38008 loss)
I0523 17:48:04.637151 11620 sgd_solver.cpp:106] Iteration 105250, lr = 0.0025
I0523 17:48:13.663849 11620 solver.cpp:237] Iteration 105500, loss = 0.988031
I0523 17:48:13.664032 11620 solver.cpp:253]     Train net output #0: loss = 0.988031 (* 1 = 0.988031 loss)
I0523 17:48:13.664047 11620 sgd_solver.cpp:106] Iteration 105500, lr = 0.0025
I0523 17:48:22.693893 11620 solver.cpp:237] Iteration 105750, loss = 1.15021
I0523 17:48:22.693933 11620 solver.cpp:253]     Train net output #0: loss = 1.15021 (* 1 = 1.15021 loss)
I0523 17:48:22.693953 11620 sgd_solver.cpp:106] Iteration 105750, lr = 0.0025
I0523 17:48:31.724100 11620 solver.cpp:237] Iteration 106000, loss = 1.07859
I0523 17:48:31.724136 11620 solver.cpp:253]     Train net output #0: loss = 1.07859 (* 1 = 1.07859 loss)
I0523 17:48:31.724150 11620 sgd_solver.cpp:106] Iteration 106000, lr = 0.0025
I0523 17:48:40.754345 11620 solver.cpp:237] Iteration 106250, loss = 1.43413
I0523 17:48:40.754381 11620 solver.cpp:253]     Train net output #0: loss = 1.43413 (* 1 = 1.43413 loss)
I0523 17:48:40.754395 11620 sgd_solver.cpp:106] Iteration 106250, lr = 0.0025
I0523 17:48:49.788171 11620 solver.cpp:237] Iteration 106500, loss = 1.18646
I0523 17:48:49.788357 11620 solver.cpp:253]     Train net output #0: loss = 1.18646 (* 1 = 1.18646 loss)
I0523 17:48:49.788372 11620 sgd_solver.cpp:106] Iteration 106500, lr = 0.0025
I0523 17:49:19.665297 11620 solver.cpp:237] Iteration 106750, loss = 1.14471
I0523 17:49:19.665345 11620 solver.cpp:253]     Train net output #0: loss = 1.14471 (* 1 = 1.14471 loss)
I0523 17:49:19.665360 11620 sgd_solver.cpp:106] Iteration 106750, lr = 0.0025
I0523 17:49:28.693846 11620 solver.cpp:237] Iteration 107000, loss = 1.09452
I0523 17:49:28.694026 11620 solver.cpp:253]     Train net output #0: loss = 1.09452 (* 1 = 1.09452 loss)
I0523 17:49:28.694039 11620 sgd_solver.cpp:106] Iteration 107000, lr = 0.0025
I0523 17:49:37.722995 11620 solver.cpp:237] Iteration 107250, loss = 0.993606
I0523 17:49:37.723038 11620 solver.cpp:253]     Train net output #0: loss = 0.993606 (* 1 = 0.993606 loss)
I0523 17:49:37.723054 11620 sgd_solver.cpp:106] Iteration 107250, lr = 0.0025
I0523 17:49:46.713168 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_107500.caffemodel
I0523 17:49:46.776242 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_107500.solverstate
I0523 17:49:46.812450 11620 solver.cpp:237] Iteration 107500, loss = 1.01184
I0523 17:49:46.812490 11620 solver.cpp:253]     Train net output #0: loss = 1.01184 (* 1 = 1.01184 loss)
I0523 17:49:46.812503 11620 sgd_solver.cpp:106] Iteration 107500, lr = 0.0025
I0523 17:49:55.844104 11620 solver.cpp:237] Iteration 107750, loss = 0.992088
I0523 17:49:55.844135 11620 solver.cpp:253]     Train net output #0: loss = 0.992088 (* 1 = 0.992088 loss)
I0523 17:49:55.844148 11620 sgd_solver.cpp:106] Iteration 107750, lr = 0.0025
I0523 17:50:04.879415 11620 solver.cpp:237] Iteration 108000, loss = 1.12808
I0523 17:50:04.879614 11620 solver.cpp:253]     Train net output #0: loss = 1.12808 (* 1 = 1.12808 loss)
I0523 17:50:04.879628 11620 sgd_solver.cpp:106] Iteration 108000, lr = 0.0025
I0523 17:50:13.907526 11620 solver.cpp:237] Iteration 108250, loss = 1.22231
I0523 17:50:13.907560 11620 solver.cpp:253]     Train net output #0: loss = 1.22231 (* 1 = 1.22231 loss)
I0523 17:50:13.907575 11620 sgd_solver.cpp:106] Iteration 108250, lr = 0.0025
I0523 17:50:43.800448 11620 solver.cpp:237] Iteration 108500, loss = 0.986898
I0523 17:50:43.800645 11620 solver.cpp:253]     Train net output #0: loss = 0.986898 (* 1 = 0.986898 loss)
I0523 17:50:43.800659 11620 sgd_solver.cpp:106] Iteration 108500, lr = 0.0025
I0523 17:50:52.831940 11620 solver.cpp:237] Iteration 108750, loss = 0.964078
I0523 17:50:52.831986 11620 solver.cpp:253]     Train net output #0: loss = 0.964078 (* 1 = 0.964078 loss)
I0523 17:50:52.832000 11620 sgd_solver.cpp:106] Iteration 108750, lr = 0.0025
I0523 17:51:01.865895 11620 solver.cpp:237] Iteration 109000, loss = 1.16769
I0523 17:51:01.865929 11620 solver.cpp:253]     Train net output #0: loss = 1.16769 (* 1 = 1.16769 loss)
I0523 17:51:01.865942 11620 sgd_solver.cpp:106] Iteration 109000, lr = 0.0025
I0523 17:51:10.894605 11620 solver.cpp:237] Iteration 109250, loss = 1.12629
I0523 17:51:10.894640 11620 solver.cpp:253]     Train net output #0: loss = 1.12629 (* 1 = 1.12629 loss)
I0523 17:51:10.894654 11620 sgd_solver.cpp:106] Iteration 109250, lr = 0.0025
I0523 17:51:19.926978 11620 solver.cpp:237] Iteration 109500, loss = 1.33694
I0523 17:51:19.927170 11620 solver.cpp:253]     Train net output #0: loss = 1.33694 (* 1 = 1.33694 loss)
I0523 17:51:19.927184 11620 sgd_solver.cpp:106] Iteration 109500, lr = 0.0025
I0523 17:51:28.961195 11620 solver.cpp:237] Iteration 109750, loss = 0.95777
I0523 17:51:28.961230 11620 solver.cpp:253]     Train net output #0: loss = 0.95777 (* 1 = 0.95777 loss)
I0523 17:51:28.961244 11620 sgd_solver.cpp:106] Iteration 109750, lr = 0.0025
I0523 17:51:37.953992 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_110000.caffemodel
I0523 17:51:38.022403 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_110000.solverstate
I0523 17:51:38.048310 11620 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 17:52:46.113287 11620 solver.cpp:409]     Test net output #0: accuracy = 0.897525
I0523 17:52:46.113493 11620 solver.cpp:409]     Test net output #1: loss = 0.342343 (* 1 = 0.342343 loss)
I0523 17:53:06.953613 11620 solver.cpp:237] Iteration 110000, loss = 1.23631
I0523 17:53:06.953667 11620 solver.cpp:253]     Train net output #0: loss = 1.23631 (* 1 = 1.23631 loss)
I0523 17:53:06.953682 11620 sgd_solver.cpp:106] Iteration 110000, lr = 0.0025
I0523 17:53:16.004133 11620 solver.cpp:237] Iteration 110250, loss = 1.29014
I0523 17:53:16.004168 11620 solver.cpp:253]     Train net output #0: loss = 1.29014 (* 1 = 1.29014 loss)
I0523 17:53:16.004184 11620 sgd_solver.cpp:106] Iteration 110250, lr = 0.0025
I0523 17:53:25.062458 11620 solver.cpp:237] Iteration 110500, loss = 1.02419
I0523 17:53:25.062659 11620 solver.cpp:253]     Train net output #0: loss = 1.02419 (* 1 = 1.02419 loss)
I0523 17:53:25.062674 11620 sgd_solver.cpp:106] Iteration 110500, lr = 0.0025
I0523 17:53:34.120344 11620 solver.cpp:237] Iteration 110750, loss = 1.16063
I0523 17:53:34.120378 11620 solver.cpp:253]     Train net output #0: loss = 1.16063 (* 1 = 1.16063 loss)
I0523 17:53:34.120393 11620 sgd_solver.cpp:106] Iteration 110750, lr = 0.0025
I0523 17:53:43.179882 11620 solver.cpp:237] Iteration 111000, loss = 1.25109
I0523 17:53:43.179924 11620 solver.cpp:253]     Train net output #0: loss = 1.25109 (* 1 = 1.25109 loss)
I0523 17:53:43.179937 11620 sgd_solver.cpp:106] Iteration 111000, lr = 0.0025
I0523 17:53:52.241884 11620 solver.cpp:237] Iteration 111250, loss = 1.10841
I0523 17:53:52.241919 11620 solver.cpp:253]     Train net output #0: loss = 1.10841 (* 1 = 1.10841 loss)
I0523 17:53:52.241933 11620 sgd_solver.cpp:106] Iteration 111250, lr = 0.0025
I0523 17:54:01.303365 11620 solver.cpp:237] Iteration 111500, loss = 1.44408
I0523 17:54:01.303542 11620 solver.cpp:253]     Train net output #0: loss = 1.44408 (* 1 = 1.44408 loss)
I0523 17:54:01.303555 11620 sgd_solver.cpp:106] Iteration 111500, lr = 0.0025
I0523 17:54:31.211732 11620 solver.cpp:237] Iteration 111750, loss = 1.14681
I0523 17:54:31.211781 11620 solver.cpp:253]     Train net output #0: loss = 1.14681 (* 1 = 1.14681 loss)
I0523 17:54:31.211796 11620 sgd_solver.cpp:106] Iteration 111750, lr = 0.0025
I0523 17:54:40.278549 11620 solver.cpp:237] Iteration 112000, loss = 1.06995
I0523 17:54:40.278740 11620 solver.cpp:253]     Train net output #0: loss = 1.06995 (* 1 = 1.06995 loss)
I0523 17:54:40.278754 11620 sgd_solver.cpp:106] Iteration 112000, lr = 0.0025
I0523 17:54:49.319897 11620 solver.cpp:237] Iteration 112250, loss = 1.27055
I0523 17:54:49.319932 11620 solver.cpp:253]     Train net output #0: loss = 1.27055 (* 1 = 1.27055 loss)
I0523 17:54:49.319947 11620 sgd_solver.cpp:106] Iteration 112250, lr = 0.0025
I0523 17:54:58.346072 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_112500.caffemodel
I0523 17:54:58.411427 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_112500.solverstate
I0523 17:54:58.449842 11620 solver.cpp:237] Iteration 112500, loss = 1.20671
I0523 17:54:58.449888 11620 solver.cpp:253]     Train net output #0: loss = 1.20671 (* 1 = 1.20671 loss)
I0523 17:54:58.449903 11620 sgd_solver.cpp:106] Iteration 112500, lr = 0.0025
I0523 17:55:07.507066 11620 solver.cpp:237] Iteration 112750, loss = 1.03381
I0523 17:55:07.507102 11620 solver.cpp:253]     Train net output #0: loss = 1.03381 (* 1 = 1.03381 loss)
I0523 17:55:07.507117 11620 sgd_solver.cpp:106] Iteration 112750, lr = 0.0025
I0523 17:55:16.559965 11620 solver.cpp:237] Iteration 113000, loss = 1.0201
I0523 17:55:16.560155 11620 solver.cpp:253]     Train net output #0: loss = 1.0201 (* 1 = 1.0201 loss)
I0523 17:55:16.560168 11620 sgd_solver.cpp:106] Iteration 113000, lr = 0.0025
I0523 17:55:25.624547 11620 solver.cpp:237] Iteration 113250, loss = 1.19192
I0523 17:55:25.624593 11620 solver.cpp:253]     Train net output #0: loss = 1.19192 (* 1 = 1.19192 loss)
I0523 17:55:25.624608 11620 sgd_solver.cpp:106] Iteration 113250, lr = 0.0025
I0523 17:55:55.551309 11620 solver.cpp:237] Iteration 113500, loss = 1.10458
I0523 17:55:55.551519 11620 solver.cpp:253]     Train net output #0: loss = 1.10458 (* 1 = 1.10458 loss)
I0523 17:55:55.551533 11620 sgd_solver.cpp:106] Iteration 113500, lr = 0.0025
I0523 17:56:04.616852 11620 solver.cpp:237] Iteration 113750, loss = 0.851049
I0523 17:56:04.616886 11620 solver.cpp:253]     Train net output #0: loss = 0.851049 (* 1 = 0.851049 loss)
I0523 17:56:04.616901 11620 sgd_solver.cpp:106] Iteration 113750, lr = 0.0025
I0523 17:56:13.673568 11620 solver.cpp:237] Iteration 114000, loss = 1.16603
I0523 17:56:13.673609 11620 solver.cpp:253]     Train net output #0: loss = 1.16603 (* 1 = 1.16603 loss)
I0523 17:56:13.673626 11620 sgd_solver.cpp:106] Iteration 114000, lr = 0.0025
I0523 17:56:22.723330 11620 solver.cpp:237] Iteration 114250, loss = 1.36755
I0523 17:56:22.723366 11620 solver.cpp:253]     Train net output #0: loss = 1.36755 (* 1 = 1.36755 loss)
I0523 17:56:22.723379 11620 sgd_solver.cpp:106] Iteration 114250, lr = 0.0025
I0523 17:56:31.781985 11620 solver.cpp:237] Iteration 114500, loss = 1.16618
I0523 17:56:31.782165 11620 solver.cpp:253]     Train net output #0: loss = 1.16618 (* 1 = 1.16618 loss)
I0523 17:56:31.782177 11620 sgd_solver.cpp:106] Iteration 114500, lr = 0.0025
I0523 17:56:40.843508 11620 solver.cpp:237] Iteration 114750, loss = 1.08475
I0523 17:56:40.843554 11620 solver.cpp:253]     Train net output #0: loss = 1.08475 (* 1 = 1.08475 loss)
I0523 17:56:40.843566 11620 sgd_solver.cpp:106] Iteration 114750, lr = 0.0025
I0523 17:56:49.872658 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_115000.caffemodel
I0523 17:56:49.935529 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_115000.solverstate
I0523 17:56:49.960621 11620 solver.cpp:341] Iteration 115000, Testing net (#0)
I0523 17:57:36.950701 11620 solver.cpp:409]     Test net output #0: accuracy = 0.899692
I0523 17:57:36.950897 11620 solver.cpp:409]     Test net output #1: loss = 0.315558 (* 1 = 0.315558 loss)
I0523 17:57:57.798836 11620 solver.cpp:237] Iteration 115000, loss = 0.831264
I0523 17:57:57.798890 11620 solver.cpp:253]     Train net output #0: loss = 0.831264 (* 1 = 0.831264 loss)
I0523 17:57:57.798905 11620 sgd_solver.cpp:106] Iteration 115000, lr = 0.0025
I0523 17:58:06.803006 11620 solver.cpp:237] Iteration 115250, loss = 1.04519
I0523 17:58:06.803040 11620 solver.cpp:253]     Train net output #0: loss = 1.04519 (* 1 = 1.04519 loss)
I0523 17:58:06.803056 11620 sgd_solver.cpp:106] Iteration 115250, lr = 0.0025
I0523 17:58:15.812826 11620 solver.cpp:237] Iteration 115500, loss = 1.24626
I0523 17:58:15.813021 11620 solver.cpp:253]     Train net output #0: loss = 1.24626 (* 1 = 1.24626 loss)
I0523 17:58:15.813035 11620 sgd_solver.cpp:106] Iteration 115500, lr = 0.0025
I0523 17:58:24.827675 11620 solver.cpp:237] Iteration 115750, loss = 1.1345
I0523 17:58:24.827708 11620 solver.cpp:253]     Train net output #0: loss = 1.1345 (* 1 = 1.1345 loss)
I0523 17:58:24.827721 11620 sgd_solver.cpp:106] Iteration 115750, lr = 0.0025
I0523 17:58:33.839339 11620 solver.cpp:237] Iteration 116000, loss = 1.33945
I0523 17:58:33.839373 11620 solver.cpp:253]     Train net output #0: loss = 1.33945 (* 1 = 1.33945 loss)
I0523 17:58:33.839387 11620 sgd_solver.cpp:106] Iteration 116000, lr = 0.0025
I0523 17:58:42.850147 11620 solver.cpp:237] Iteration 116250, loss = 1.14
I0523 17:58:42.850191 11620 solver.cpp:253]     Train net output #0: loss = 1.14 (* 1 = 1.14 loss)
I0523 17:58:42.850206 11620 sgd_solver.cpp:106] Iteration 116250, lr = 0.0025
I0523 17:58:51.852493 11620 solver.cpp:237] Iteration 116500, loss = 0.980429
I0523 17:58:51.852669 11620 solver.cpp:253]     Train net output #0: loss = 0.980429 (* 1 = 0.980429 loss)
I0523 17:58:51.852684 11620 sgd_solver.cpp:106] Iteration 116500, lr = 0.0025
I0523 17:59:21.739637 11620 solver.cpp:237] Iteration 116750, loss = 1.22291
I0523 17:59:21.739688 11620 solver.cpp:253]     Train net output #0: loss = 1.22291 (* 1 = 1.22291 loss)
I0523 17:59:21.739702 11620 sgd_solver.cpp:106] Iteration 116750, lr = 0.0025
I0523 17:59:30.751041 11620 solver.cpp:237] Iteration 117000, loss = 0.995784
I0523 17:59:30.751248 11620 solver.cpp:253]     Train net output #0: loss = 0.995784 (* 1 = 0.995784 loss)
I0523 17:59:30.751263 11620 sgd_solver.cpp:106] Iteration 117000, lr = 0.0025
I0523 17:59:39.763725 11620 solver.cpp:237] Iteration 117250, loss = 1.06719
I0523 17:59:39.763761 11620 solver.cpp:253]     Train net output #0: loss = 1.06719 (* 1 = 1.06719 loss)
I0523 17:59:39.763774 11620 sgd_solver.cpp:106] Iteration 117250, lr = 0.0025
I0523 17:59:48.735695 11620 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_117500.caffemodel
I0523 17:59:48.798583 11620 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0025_2016-05-20T15.49.10.295409_iter_117500.solverstate
I0523 17:59:48.835271 11620 solver.cpp:237] Iteration 117500, loss = 1.16624
I0523 17:59:48.835316 11620 solver.cpp:253]     Train net output #0: loss = 1.16624 (* 1 = 1.16624 loss)
I0523 17:59:48.835333 11620 sgd_solver.cpp:106] Iteration 117500, lr = 0.0025
I0523 17:59:57.845296 11620 solver.cpp:237] Iteration 117750, loss = 1.10354
I0523 17:59:57.845345 11620 solver.cpp:253]     Train net output #0: loss = 1.10354 (* 1 = 1.10354 loss)
I0523 17:59:57.845360 11620 sgd_solver.cpp:106] Iteration 117750, lr = 0.0025
I0523 18:00:06.852560 11620 solver.cpp:237] Iteration 118000, loss = 1.01835
I0523 18:00:06.852746 11620 solver.cpp:253]     Train net output #0: loss = 1.01835 (* 1 = 1.01835 loss)
I0523 18:00:06.852759 11620 sgd_solver.cpp:106] Iteration 118000, lr = 0.0025
I0523 18:00:15.863998 11620 solver.cpp:237] Iteration 118250, loss = 1.13295
I0523 18:00:15.864032 11620 solver.cpp:253]     Train net output #0: loss = 1.13295 (* 1 = 1.13295 loss)
I0523 18:00:15.864048 11620 sgd_solver.cpp:106] Iteration 118250, lr = 0.0025
aprun: Apid 11256754: Caught signal Terminated, sending to application
aprun: Apid 11256754: Caught signal Terminated, sending to application
*** Aborted at 1464040844 (unix time) try "date -d @1464040844" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7221 exceeded limit 7200
aprun: Apid 11256754: Caught signal Terminated, sending to application
*** SIGTERM (@0x2d61) received by PID 11620 (TID 0x2aaac746f900) from PID 11617; stack trace: ***
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11256754: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11256754: Caught signal Terminated, sending to application
aprun: Apid 11256754: Caught signal Terminated, sending to application
aprun: Apid 11256754: Caught signal Terminated, sending to application
aprun: Apid 11256754: Caught signal Terminated, sending to application
aprun: Apid 11256754: Caught signal Terminated, sending to application
