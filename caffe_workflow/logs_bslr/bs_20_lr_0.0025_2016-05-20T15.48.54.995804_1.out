2807086
I0522 00:04:18.799975 18599 caffe.cpp:184] Using GPUs 0
I0522 00:04:19.234506 18599 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0025
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804.prototxt"
I0522 00:04:19.236708 18599 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804.prototxt
I0522 00:04:19.254595 18599 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 00:04:19.254653 18599 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 00:04:19.255002 18599 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 00:04:19.255184 18599 layer_factory.hpp:77] Creating layer data_hdf5
I0522 00:04:19.255208 18599 net.cpp:106] Creating Layer data_hdf5
I0522 00:04:19.255223 18599 net.cpp:411] data_hdf5 -> data
I0522 00:04:19.255257 18599 net.cpp:411] data_hdf5 -> label
I0522 00:04:19.255291 18599 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 00:04:19.256687 18599 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 00:04:19.259104 18599 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 00:04:40.824167 18599 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 00:04:40.829306 18599 net.cpp:150] Setting up data_hdf5
I0522 00:04:40.829346 18599 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 00:04:40.829361 18599 net.cpp:157] Top shape: 20 (20)
I0522 00:04:40.829373 18599 net.cpp:165] Memory required for data: 508080
I0522 00:04:40.829386 18599 layer_factory.hpp:77] Creating layer conv1
I0522 00:04:40.829421 18599 net.cpp:106] Creating Layer conv1
I0522 00:04:40.829432 18599 net.cpp:454] conv1 <- data
I0522 00:04:40.829452 18599 net.cpp:411] conv1 -> conv1
I0522 00:04:41.192054 18599 net.cpp:150] Setting up conv1
I0522 00:04:41.192102 18599 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 00:04:41.192113 18599 net.cpp:165] Memory required for data: 6037680
I0522 00:04:41.192143 18599 layer_factory.hpp:77] Creating layer relu1
I0522 00:04:41.192164 18599 net.cpp:106] Creating Layer relu1
I0522 00:04:41.192175 18599 net.cpp:454] relu1 <- conv1
I0522 00:04:41.192188 18599 net.cpp:397] relu1 -> conv1 (in-place)
I0522 00:04:41.192708 18599 net.cpp:150] Setting up relu1
I0522 00:04:41.192725 18599 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 00:04:41.192736 18599 net.cpp:165] Memory required for data: 11567280
I0522 00:04:41.192747 18599 layer_factory.hpp:77] Creating layer pool1
I0522 00:04:41.192764 18599 net.cpp:106] Creating Layer pool1
I0522 00:04:41.192773 18599 net.cpp:454] pool1 <- conv1
I0522 00:04:41.192786 18599 net.cpp:411] pool1 -> pool1
I0522 00:04:41.192878 18599 net.cpp:150] Setting up pool1
I0522 00:04:41.192891 18599 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 00:04:41.192901 18599 net.cpp:165] Memory required for data: 14332080
I0522 00:04:41.192912 18599 layer_factory.hpp:77] Creating layer conv2
I0522 00:04:41.192935 18599 net.cpp:106] Creating Layer conv2
I0522 00:04:41.192945 18599 net.cpp:454] conv2 <- pool1
I0522 00:04:41.192958 18599 net.cpp:411] conv2 -> conv2
I0522 00:04:41.195644 18599 net.cpp:150] Setting up conv2
I0522 00:04:41.195672 18599 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 00:04:41.195683 18599 net.cpp:165] Memory required for data: 18306480
I0522 00:04:41.195703 18599 layer_factory.hpp:77] Creating layer relu2
I0522 00:04:41.195718 18599 net.cpp:106] Creating Layer relu2
I0522 00:04:41.195727 18599 net.cpp:454] relu2 <- conv2
I0522 00:04:41.195740 18599 net.cpp:397] relu2 -> conv2 (in-place)
I0522 00:04:41.196068 18599 net.cpp:150] Setting up relu2
I0522 00:04:41.196081 18599 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 00:04:41.196092 18599 net.cpp:165] Memory required for data: 22280880
I0522 00:04:41.196104 18599 layer_factory.hpp:77] Creating layer pool2
I0522 00:04:41.196115 18599 net.cpp:106] Creating Layer pool2
I0522 00:04:41.196125 18599 net.cpp:454] pool2 <- conv2
I0522 00:04:41.196137 18599 net.cpp:411] pool2 -> pool2
I0522 00:04:41.196220 18599 net.cpp:150] Setting up pool2
I0522 00:04:41.196233 18599 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 00:04:41.196244 18599 net.cpp:165] Memory required for data: 24268080
I0522 00:04:41.196254 18599 layer_factory.hpp:77] Creating layer conv3
I0522 00:04:41.196270 18599 net.cpp:106] Creating Layer conv3
I0522 00:04:41.196281 18599 net.cpp:454] conv3 <- pool2
I0522 00:04:41.196295 18599 net.cpp:411] conv3 -> conv3
I0522 00:04:41.198248 18599 net.cpp:150] Setting up conv3
I0522 00:04:41.198271 18599 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 00:04:41.198283 18599 net.cpp:165] Memory required for data: 26436400
I0522 00:04:41.198302 18599 layer_factory.hpp:77] Creating layer relu3
I0522 00:04:41.198318 18599 net.cpp:106] Creating Layer relu3
I0522 00:04:41.198328 18599 net.cpp:454] relu3 <- conv3
I0522 00:04:41.198340 18599 net.cpp:397] relu3 -> conv3 (in-place)
I0522 00:04:41.198808 18599 net.cpp:150] Setting up relu3
I0522 00:04:41.198825 18599 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 00:04:41.198835 18599 net.cpp:165] Memory required for data: 28604720
I0522 00:04:41.198845 18599 layer_factory.hpp:77] Creating layer pool3
I0522 00:04:41.198858 18599 net.cpp:106] Creating Layer pool3
I0522 00:04:41.198868 18599 net.cpp:454] pool3 <- conv3
I0522 00:04:41.198881 18599 net.cpp:411] pool3 -> pool3
I0522 00:04:41.198950 18599 net.cpp:150] Setting up pool3
I0522 00:04:41.198962 18599 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 00:04:41.198972 18599 net.cpp:165] Memory required for data: 29688880
I0522 00:04:41.198982 18599 layer_factory.hpp:77] Creating layer conv4
I0522 00:04:41.198997 18599 net.cpp:106] Creating Layer conv4
I0522 00:04:41.199007 18599 net.cpp:454] conv4 <- pool3
I0522 00:04:41.199021 18599 net.cpp:411] conv4 -> conv4
I0522 00:04:41.201764 18599 net.cpp:150] Setting up conv4
I0522 00:04:41.201792 18599 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 00:04:41.201802 18599 net.cpp:165] Memory required for data: 30414640
I0522 00:04:41.201818 18599 layer_factory.hpp:77] Creating layer relu4
I0522 00:04:41.201833 18599 net.cpp:106] Creating Layer relu4
I0522 00:04:41.201843 18599 net.cpp:454] relu4 <- conv4
I0522 00:04:41.201855 18599 net.cpp:397] relu4 -> conv4 (in-place)
I0522 00:04:41.202322 18599 net.cpp:150] Setting up relu4
I0522 00:04:41.202338 18599 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 00:04:41.202349 18599 net.cpp:165] Memory required for data: 31140400
I0522 00:04:41.202359 18599 layer_factory.hpp:77] Creating layer pool4
I0522 00:04:41.202373 18599 net.cpp:106] Creating Layer pool4
I0522 00:04:41.202383 18599 net.cpp:454] pool4 <- conv4
I0522 00:04:41.202395 18599 net.cpp:411] pool4 -> pool4
I0522 00:04:41.202464 18599 net.cpp:150] Setting up pool4
I0522 00:04:41.202478 18599 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 00:04:41.202489 18599 net.cpp:165] Memory required for data: 31503280
I0522 00:04:41.202499 18599 layer_factory.hpp:77] Creating layer ip1
I0522 00:04:41.202519 18599 net.cpp:106] Creating Layer ip1
I0522 00:04:41.202529 18599 net.cpp:454] ip1 <- pool4
I0522 00:04:41.202543 18599 net.cpp:411] ip1 -> ip1
I0522 00:04:41.218029 18599 net.cpp:150] Setting up ip1
I0522 00:04:41.218058 18599 net.cpp:157] Top shape: 20 196 (3920)
I0522 00:04:41.218075 18599 net.cpp:165] Memory required for data: 31518960
I0522 00:04:41.218101 18599 layer_factory.hpp:77] Creating layer relu5
I0522 00:04:41.218116 18599 net.cpp:106] Creating Layer relu5
I0522 00:04:41.218127 18599 net.cpp:454] relu5 <- ip1
I0522 00:04:41.218140 18599 net.cpp:397] relu5 -> ip1 (in-place)
I0522 00:04:41.218482 18599 net.cpp:150] Setting up relu5
I0522 00:04:41.218497 18599 net.cpp:157] Top shape: 20 196 (3920)
I0522 00:04:41.218507 18599 net.cpp:165] Memory required for data: 31534640
I0522 00:04:41.218516 18599 layer_factory.hpp:77] Creating layer drop1
I0522 00:04:41.218538 18599 net.cpp:106] Creating Layer drop1
I0522 00:04:41.218547 18599 net.cpp:454] drop1 <- ip1
I0522 00:04:41.218560 18599 net.cpp:397] drop1 -> ip1 (in-place)
I0522 00:04:41.218621 18599 net.cpp:150] Setting up drop1
I0522 00:04:41.218633 18599 net.cpp:157] Top shape: 20 196 (3920)
I0522 00:04:41.218643 18599 net.cpp:165] Memory required for data: 31550320
I0522 00:04:41.218653 18599 layer_factory.hpp:77] Creating layer ip2
I0522 00:04:41.218672 18599 net.cpp:106] Creating Layer ip2
I0522 00:04:41.218683 18599 net.cpp:454] ip2 <- ip1
I0522 00:04:41.218695 18599 net.cpp:411] ip2 -> ip2
I0522 00:04:41.219157 18599 net.cpp:150] Setting up ip2
I0522 00:04:41.219171 18599 net.cpp:157] Top shape: 20 98 (1960)
I0522 00:04:41.219180 18599 net.cpp:165] Memory required for data: 31558160
I0522 00:04:41.219197 18599 layer_factory.hpp:77] Creating layer relu6
I0522 00:04:41.219208 18599 net.cpp:106] Creating Layer relu6
I0522 00:04:41.219218 18599 net.cpp:454] relu6 <- ip2
I0522 00:04:41.219229 18599 net.cpp:397] relu6 -> ip2 (in-place)
I0522 00:04:41.219750 18599 net.cpp:150] Setting up relu6
I0522 00:04:41.219766 18599 net.cpp:157] Top shape: 20 98 (1960)
I0522 00:04:41.219776 18599 net.cpp:165] Memory required for data: 31566000
I0522 00:04:41.219787 18599 layer_factory.hpp:77] Creating layer drop2
I0522 00:04:41.219800 18599 net.cpp:106] Creating Layer drop2
I0522 00:04:41.219810 18599 net.cpp:454] drop2 <- ip2
I0522 00:04:41.219822 18599 net.cpp:397] drop2 -> ip2 (in-place)
I0522 00:04:41.219864 18599 net.cpp:150] Setting up drop2
I0522 00:04:41.219877 18599 net.cpp:157] Top shape: 20 98 (1960)
I0522 00:04:41.219888 18599 net.cpp:165] Memory required for data: 31573840
I0522 00:04:41.219898 18599 layer_factory.hpp:77] Creating layer ip3
I0522 00:04:41.219913 18599 net.cpp:106] Creating Layer ip3
I0522 00:04:41.219921 18599 net.cpp:454] ip3 <- ip2
I0522 00:04:41.219934 18599 net.cpp:411] ip3 -> ip3
I0522 00:04:41.220142 18599 net.cpp:150] Setting up ip3
I0522 00:04:41.220155 18599 net.cpp:157] Top shape: 20 11 (220)
I0522 00:04:41.220165 18599 net.cpp:165] Memory required for data: 31574720
I0522 00:04:41.220180 18599 layer_factory.hpp:77] Creating layer drop3
I0522 00:04:41.220192 18599 net.cpp:106] Creating Layer drop3
I0522 00:04:41.220202 18599 net.cpp:454] drop3 <- ip3
I0522 00:04:41.220214 18599 net.cpp:397] drop3 -> ip3 (in-place)
I0522 00:04:41.220253 18599 net.cpp:150] Setting up drop3
I0522 00:04:41.220266 18599 net.cpp:157] Top shape: 20 11 (220)
I0522 00:04:41.220276 18599 net.cpp:165] Memory required for data: 31575600
I0522 00:04:41.220286 18599 layer_factory.hpp:77] Creating layer loss
I0522 00:04:41.220305 18599 net.cpp:106] Creating Layer loss
I0522 00:04:41.220315 18599 net.cpp:454] loss <- ip3
I0522 00:04:41.220326 18599 net.cpp:454] loss <- label
I0522 00:04:41.220338 18599 net.cpp:411] loss -> loss
I0522 00:04:41.220355 18599 layer_factory.hpp:77] Creating layer loss
I0522 00:04:41.220999 18599 net.cpp:150] Setting up loss
I0522 00:04:41.221020 18599 net.cpp:157] Top shape: (1)
I0522 00:04:41.221034 18599 net.cpp:160]     with loss weight 1
I0522 00:04:41.221079 18599 net.cpp:165] Memory required for data: 31575604
I0522 00:04:41.221089 18599 net.cpp:226] loss needs backward computation.
I0522 00:04:41.221101 18599 net.cpp:226] drop3 needs backward computation.
I0522 00:04:41.221108 18599 net.cpp:226] ip3 needs backward computation.
I0522 00:04:41.221119 18599 net.cpp:226] drop2 needs backward computation.
I0522 00:04:41.221129 18599 net.cpp:226] relu6 needs backward computation.
I0522 00:04:41.221139 18599 net.cpp:226] ip2 needs backward computation.
I0522 00:04:41.221149 18599 net.cpp:226] drop1 needs backward computation.
I0522 00:04:41.221158 18599 net.cpp:226] relu5 needs backward computation.
I0522 00:04:41.221168 18599 net.cpp:226] ip1 needs backward computation.
I0522 00:04:41.221179 18599 net.cpp:226] pool4 needs backward computation.
I0522 00:04:41.221189 18599 net.cpp:226] relu4 needs backward computation.
I0522 00:04:41.221199 18599 net.cpp:226] conv4 needs backward computation.
I0522 00:04:41.221210 18599 net.cpp:226] pool3 needs backward computation.
I0522 00:04:41.221220 18599 net.cpp:226] relu3 needs backward computation.
I0522 00:04:41.221230 18599 net.cpp:226] conv3 needs backward computation.
I0522 00:04:41.221249 18599 net.cpp:226] pool2 needs backward computation.
I0522 00:04:41.221261 18599 net.cpp:226] relu2 needs backward computation.
I0522 00:04:41.221271 18599 net.cpp:226] conv2 needs backward computation.
I0522 00:04:41.221282 18599 net.cpp:226] pool1 needs backward computation.
I0522 00:04:41.221292 18599 net.cpp:226] relu1 needs backward computation.
I0522 00:04:41.221302 18599 net.cpp:226] conv1 needs backward computation.
I0522 00:04:41.221313 18599 net.cpp:228] data_hdf5 does not need backward computation.
I0522 00:04:41.221323 18599 net.cpp:270] This network produces output loss
I0522 00:04:41.221346 18599 net.cpp:283] Network initialization done.
I0522 00:04:41.223016 18599 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804.prototxt
I0522 00:04:41.223086 18599 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 00:04:41.223444 18599 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 00:04:41.223633 18599 layer_factory.hpp:77] Creating layer data_hdf5
I0522 00:04:41.223649 18599 net.cpp:106] Creating Layer data_hdf5
I0522 00:04:41.223660 18599 net.cpp:411] data_hdf5 -> data
I0522 00:04:41.223678 18599 net.cpp:411] data_hdf5 -> label
I0522 00:04:41.223695 18599 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 00:04:41.224930 18599 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 00:05:02.525182 18599 net.cpp:150] Setting up data_hdf5
I0522 00:05:02.525352 18599 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 00:05:02.525367 18599 net.cpp:157] Top shape: 20 (20)
I0522 00:05:02.525377 18599 net.cpp:165] Memory required for data: 508080
I0522 00:05:02.525390 18599 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 00:05:02.525418 18599 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 00:05:02.525429 18599 net.cpp:454] label_data_hdf5_1_split <- label
I0522 00:05:02.525444 18599 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 00:05:02.525465 18599 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 00:05:02.525538 18599 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 00:05:02.525552 18599 net.cpp:157] Top shape: 20 (20)
I0522 00:05:02.525563 18599 net.cpp:157] Top shape: 20 (20)
I0522 00:05:02.525573 18599 net.cpp:165] Memory required for data: 508240
I0522 00:05:02.525583 18599 layer_factory.hpp:77] Creating layer conv1
I0522 00:05:02.525604 18599 net.cpp:106] Creating Layer conv1
I0522 00:05:02.525614 18599 net.cpp:454] conv1 <- data
I0522 00:05:02.525626 18599 net.cpp:411] conv1 -> conv1
I0522 00:05:02.527552 18599 net.cpp:150] Setting up conv1
I0522 00:05:02.527576 18599 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 00:05:02.527588 18599 net.cpp:165] Memory required for data: 6037840
I0522 00:05:02.527609 18599 layer_factory.hpp:77] Creating layer relu1
I0522 00:05:02.527623 18599 net.cpp:106] Creating Layer relu1
I0522 00:05:02.527633 18599 net.cpp:454] relu1 <- conv1
I0522 00:05:02.527647 18599 net.cpp:397] relu1 -> conv1 (in-place)
I0522 00:05:02.528144 18599 net.cpp:150] Setting up relu1
I0522 00:05:02.528161 18599 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 00:05:02.528172 18599 net.cpp:165] Memory required for data: 11567440
I0522 00:05:02.528182 18599 layer_factory.hpp:77] Creating layer pool1
I0522 00:05:02.528198 18599 net.cpp:106] Creating Layer pool1
I0522 00:05:02.528208 18599 net.cpp:454] pool1 <- conv1
I0522 00:05:02.528221 18599 net.cpp:411] pool1 -> pool1
I0522 00:05:02.528296 18599 net.cpp:150] Setting up pool1
I0522 00:05:02.528309 18599 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 00:05:02.528319 18599 net.cpp:165] Memory required for data: 14332240
I0522 00:05:02.528329 18599 layer_factory.hpp:77] Creating layer conv2
I0522 00:05:02.528347 18599 net.cpp:106] Creating Layer conv2
I0522 00:05:02.528357 18599 net.cpp:454] conv2 <- pool1
I0522 00:05:02.528370 18599 net.cpp:411] conv2 -> conv2
I0522 00:05:02.530297 18599 net.cpp:150] Setting up conv2
I0522 00:05:02.530318 18599 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 00:05:02.530331 18599 net.cpp:165] Memory required for data: 18306640
I0522 00:05:02.530349 18599 layer_factory.hpp:77] Creating layer relu2
I0522 00:05:02.530362 18599 net.cpp:106] Creating Layer relu2
I0522 00:05:02.530372 18599 net.cpp:454] relu2 <- conv2
I0522 00:05:02.530385 18599 net.cpp:397] relu2 -> conv2 (in-place)
I0522 00:05:02.530716 18599 net.cpp:150] Setting up relu2
I0522 00:05:02.530730 18599 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 00:05:02.530740 18599 net.cpp:165] Memory required for data: 22281040
I0522 00:05:02.530750 18599 layer_factory.hpp:77] Creating layer pool2
I0522 00:05:02.530763 18599 net.cpp:106] Creating Layer pool2
I0522 00:05:02.530773 18599 net.cpp:454] pool2 <- conv2
I0522 00:05:02.530786 18599 net.cpp:411] pool2 -> pool2
I0522 00:05:02.530858 18599 net.cpp:150] Setting up pool2
I0522 00:05:02.530870 18599 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 00:05:02.530880 18599 net.cpp:165] Memory required for data: 24268240
I0522 00:05:02.530890 18599 layer_factory.hpp:77] Creating layer conv3
I0522 00:05:02.530908 18599 net.cpp:106] Creating Layer conv3
I0522 00:05:02.530918 18599 net.cpp:454] conv3 <- pool2
I0522 00:05:02.530932 18599 net.cpp:411] conv3 -> conv3
I0522 00:05:02.532915 18599 net.cpp:150] Setting up conv3
I0522 00:05:02.532938 18599 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 00:05:02.532950 18599 net.cpp:165] Memory required for data: 26436560
I0522 00:05:02.532969 18599 layer_factory.hpp:77] Creating layer relu3
I0522 00:05:02.532995 18599 net.cpp:106] Creating Layer relu3
I0522 00:05:02.533005 18599 net.cpp:454] relu3 <- conv3
I0522 00:05:02.533018 18599 net.cpp:397] relu3 -> conv3 (in-place)
I0522 00:05:02.533490 18599 net.cpp:150] Setting up relu3
I0522 00:05:02.533506 18599 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 00:05:02.533516 18599 net.cpp:165] Memory required for data: 28604880
I0522 00:05:02.533526 18599 layer_factory.hpp:77] Creating layer pool3
I0522 00:05:02.533540 18599 net.cpp:106] Creating Layer pool3
I0522 00:05:02.533550 18599 net.cpp:454] pool3 <- conv3
I0522 00:05:02.533562 18599 net.cpp:411] pool3 -> pool3
I0522 00:05:02.533634 18599 net.cpp:150] Setting up pool3
I0522 00:05:02.533648 18599 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 00:05:02.533658 18599 net.cpp:165] Memory required for data: 29689040
I0522 00:05:02.533668 18599 layer_factory.hpp:77] Creating layer conv4
I0522 00:05:02.533682 18599 net.cpp:106] Creating Layer conv4
I0522 00:05:02.533694 18599 net.cpp:454] conv4 <- pool3
I0522 00:05:02.533707 18599 net.cpp:411] conv4 -> conv4
I0522 00:05:02.535755 18599 net.cpp:150] Setting up conv4
I0522 00:05:02.535778 18599 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 00:05:02.535789 18599 net.cpp:165] Memory required for data: 30414800
I0522 00:05:02.535804 18599 layer_factory.hpp:77] Creating layer relu4
I0522 00:05:02.535817 18599 net.cpp:106] Creating Layer relu4
I0522 00:05:02.535827 18599 net.cpp:454] relu4 <- conv4
I0522 00:05:02.535840 18599 net.cpp:397] relu4 -> conv4 (in-place)
I0522 00:05:02.536310 18599 net.cpp:150] Setting up relu4
I0522 00:05:02.536326 18599 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 00:05:02.536337 18599 net.cpp:165] Memory required for data: 31140560
I0522 00:05:02.536347 18599 layer_factory.hpp:77] Creating layer pool4
I0522 00:05:02.536360 18599 net.cpp:106] Creating Layer pool4
I0522 00:05:02.536370 18599 net.cpp:454] pool4 <- conv4
I0522 00:05:02.536383 18599 net.cpp:411] pool4 -> pool4
I0522 00:05:02.536454 18599 net.cpp:150] Setting up pool4
I0522 00:05:02.536468 18599 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 00:05:02.536478 18599 net.cpp:165] Memory required for data: 31503440
I0522 00:05:02.536487 18599 layer_factory.hpp:77] Creating layer ip1
I0522 00:05:02.536501 18599 net.cpp:106] Creating Layer ip1
I0522 00:05:02.536512 18599 net.cpp:454] ip1 <- pool4
I0522 00:05:02.536525 18599 net.cpp:411] ip1 -> ip1
I0522 00:05:02.551995 18599 net.cpp:150] Setting up ip1
I0522 00:05:02.552022 18599 net.cpp:157] Top shape: 20 196 (3920)
I0522 00:05:02.552033 18599 net.cpp:165] Memory required for data: 31519120
I0522 00:05:02.552055 18599 layer_factory.hpp:77] Creating layer relu5
I0522 00:05:02.552070 18599 net.cpp:106] Creating Layer relu5
I0522 00:05:02.552081 18599 net.cpp:454] relu5 <- ip1
I0522 00:05:02.552094 18599 net.cpp:397] relu5 -> ip1 (in-place)
I0522 00:05:02.552440 18599 net.cpp:150] Setting up relu5
I0522 00:05:02.552454 18599 net.cpp:157] Top shape: 20 196 (3920)
I0522 00:05:02.552464 18599 net.cpp:165] Memory required for data: 31534800
I0522 00:05:02.552474 18599 layer_factory.hpp:77] Creating layer drop1
I0522 00:05:02.552494 18599 net.cpp:106] Creating Layer drop1
I0522 00:05:02.552503 18599 net.cpp:454] drop1 <- ip1
I0522 00:05:02.552517 18599 net.cpp:397] drop1 -> ip1 (in-place)
I0522 00:05:02.552563 18599 net.cpp:150] Setting up drop1
I0522 00:05:02.552577 18599 net.cpp:157] Top shape: 20 196 (3920)
I0522 00:05:02.552587 18599 net.cpp:165] Memory required for data: 31550480
I0522 00:05:02.552595 18599 layer_factory.hpp:77] Creating layer ip2
I0522 00:05:02.552610 18599 net.cpp:106] Creating Layer ip2
I0522 00:05:02.552620 18599 net.cpp:454] ip2 <- ip1
I0522 00:05:02.552634 18599 net.cpp:411] ip2 -> ip2
I0522 00:05:02.553117 18599 net.cpp:150] Setting up ip2
I0522 00:05:02.553130 18599 net.cpp:157] Top shape: 20 98 (1960)
I0522 00:05:02.553140 18599 net.cpp:165] Memory required for data: 31558320
I0522 00:05:02.553155 18599 layer_factory.hpp:77] Creating layer relu6
I0522 00:05:02.553181 18599 net.cpp:106] Creating Layer relu6
I0522 00:05:02.553191 18599 net.cpp:454] relu6 <- ip2
I0522 00:05:02.553205 18599 net.cpp:397] relu6 -> ip2 (in-place)
I0522 00:05:02.553740 18599 net.cpp:150] Setting up relu6
I0522 00:05:02.553755 18599 net.cpp:157] Top shape: 20 98 (1960)
I0522 00:05:02.553766 18599 net.cpp:165] Memory required for data: 31566160
I0522 00:05:02.553776 18599 layer_factory.hpp:77] Creating layer drop2
I0522 00:05:02.553789 18599 net.cpp:106] Creating Layer drop2
I0522 00:05:02.553799 18599 net.cpp:454] drop2 <- ip2
I0522 00:05:02.553812 18599 net.cpp:397] drop2 -> ip2 (in-place)
I0522 00:05:02.553856 18599 net.cpp:150] Setting up drop2
I0522 00:05:02.553869 18599 net.cpp:157] Top shape: 20 98 (1960)
I0522 00:05:02.553879 18599 net.cpp:165] Memory required for data: 31574000
I0522 00:05:02.553889 18599 layer_factory.hpp:77] Creating layer ip3
I0522 00:05:02.553902 18599 net.cpp:106] Creating Layer ip3
I0522 00:05:02.553912 18599 net.cpp:454] ip3 <- ip2
I0522 00:05:02.553926 18599 net.cpp:411] ip3 -> ip3
I0522 00:05:02.554150 18599 net.cpp:150] Setting up ip3
I0522 00:05:02.554163 18599 net.cpp:157] Top shape: 20 11 (220)
I0522 00:05:02.554172 18599 net.cpp:165] Memory required for data: 31574880
I0522 00:05:02.554188 18599 layer_factory.hpp:77] Creating layer drop3
I0522 00:05:02.554200 18599 net.cpp:106] Creating Layer drop3
I0522 00:05:02.554210 18599 net.cpp:454] drop3 <- ip3
I0522 00:05:02.554224 18599 net.cpp:397] drop3 -> ip3 (in-place)
I0522 00:05:02.554265 18599 net.cpp:150] Setting up drop3
I0522 00:05:02.554276 18599 net.cpp:157] Top shape: 20 11 (220)
I0522 00:05:02.554286 18599 net.cpp:165] Memory required for data: 31575760
I0522 00:05:02.554296 18599 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 00:05:02.554308 18599 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 00:05:02.554318 18599 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 00:05:02.554332 18599 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 00:05:02.554347 18599 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 00:05:02.554420 18599 net.cpp:150] Setting up ip3_drop3_0_split
I0522 00:05:02.554433 18599 net.cpp:157] Top shape: 20 11 (220)
I0522 00:05:02.554445 18599 net.cpp:157] Top shape: 20 11 (220)
I0522 00:05:02.554455 18599 net.cpp:165] Memory required for data: 31577520
I0522 00:05:02.554466 18599 layer_factory.hpp:77] Creating layer accuracy
I0522 00:05:02.554486 18599 net.cpp:106] Creating Layer accuracy
I0522 00:05:02.554496 18599 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 00:05:02.554507 18599 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 00:05:02.554520 18599 net.cpp:411] accuracy -> accuracy
I0522 00:05:02.554543 18599 net.cpp:150] Setting up accuracy
I0522 00:05:02.554556 18599 net.cpp:157] Top shape: (1)
I0522 00:05:02.554566 18599 net.cpp:165] Memory required for data: 31577524
I0522 00:05:02.554575 18599 layer_factory.hpp:77] Creating layer loss
I0522 00:05:02.554589 18599 net.cpp:106] Creating Layer loss
I0522 00:05:02.554600 18599 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 00:05:02.554610 18599 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 00:05:02.554623 18599 net.cpp:411] loss -> loss
I0522 00:05:02.554641 18599 layer_factory.hpp:77] Creating layer loss
I0522 00:05:02.555120 18599 net.cpp:150] Setting up loss
I0522 00:05:02.555133 18599 net.cpp:157] Top shape: (1)
I0522 00:05:02.555143 18599 net.cpp:160]     with loss weight 1
I0522 00:05:02.555165 18599 net.cpp:165] Memory required for data: 31577528
I0522 00:05:02.555174 18599 net.cpp:226] loss needs backward computation.
I0522 00:05:02.555186 18599 net.cpp:228] accuracy does not need backward computation.
I0522 00:05:02.555197 18599 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 00:05:02.555207 18599 net.cpp:226] drop3 needs backward computation.
I0522 00:05:02.555217 18599 net.cpp:226] ip3 needs backward computation.
I0522 00:05:02.555228 18599 net.cpp:226] drop2 needs backward computation.
I0522 00:05:02.555238 18599 net.cpp:226] relu6 needs backward computation.
I0522 00:05:02.555255 18599 net.cpp:226] ip2 needs backward computation.
I0522 00:05:02.555266 18599 net.cpp:226] drop1 needs backward computation.
I0522 00:05:02.555275 18599 net.cpp:226] relu5 needs backward computation.
I0522 00:05:02.555285 18599 net.cpp:226] ip1 needs backward computation.
I0522 00:05:02.555295 18599 net.cpp:226] pool4 needs backward computation.
I0522 00:05:02.555305 18599 net.cpp:226] relu4 needs backward computation.
I0522 00:05:02.555315 18599 net.cpp:226] conv4 needs backward computation.
I0522 00:05:02.555323 18599 net.cpp:226] pool3 needs backward computation.
I0522 00:05:02.555333 18599 net.cpp:226] relu3 needs backward computation.
I0522 00:05:02.555344 18599 net.cpp:226] conv3 needs backward computation.
I0522 00:05:02.555356 18599 net.cpp:226] pool2 needs backward computation.
I0522 00:05:02.555366 18599 net.cpp:226] relu2 needs backward computation.
I0522 00:05:02.555376 18599 net.cpp:226] conv2 needs backward computation.
I0522 00:05:02.555385 18599 net.cpp:226] pool1 needs backward computation.
I0522 00:05:02.555395 18599 net.cpp:226] relu1 needs backward computation.
I0522 00:05:02.555404 18599 net.cpp:226] conv1 needs backward computation.
I0522 00:05:02.555416 18599 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 00:05:02.555428 18599 net.cpp:228] data_hdf5 does not need backward computation.
I0522 00:05:02.555440 18599 net.cpp:270] This network produces output accuracy
I0522 00:05:02.555450 18599 net.cpp:270] This network produces output loss
I0522 00:05:02.555480 18599 net.cpp:283] Network initialization done.
I0522 00:05:02.555611 18599 solver.cpp:60] Solver scaffolding done.
I0522 00:05:02.556740 18599 caffe.cpp:212] Starting Optimization
I0522 00:05:02.556759 18599 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 00:05:02.556772 18599 solver.cpp:289] Learning Rate Policy: fixed
I0522 00:05:02.558006 18599 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 00:05:55.357134 18599 solver.cpp:409]     Test net output #0: accuracy = 0.150167
I0522 00:05:55.357297 18599 solver.cpp:409]     Test net output #1: loss = 2.39741 (* 1 = 2.39741 loss)
I0522 00:05:55.376425 18599 solver.cpp:237] Iteration 0, loss = 2.38997
I0522 00:05:55.376462 18599 solver.cpp:253]     Train net output #0: loss = 2.38997 (* 1 = 2.38997 loss)
I0522 00:05:55.376479 18599 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0522 00:06:07.522904 18599 solver.cpp:237] Iteration 750, loss = 2.09903
I0522 00:06:07.522944 18599 solver.cpp:253]     Train net output #0: loss = 2.09903 (* 1 = 2.09903 loss)
I0522 00:06:07.522960 18599 sgd_solver.cpp:106] Iteration 750, lr = 0.0025
I0522 00:06:19.691170 18599 solver.cpp:237] Iteration 1500, loss = 2.24409
I0522 00:06:19.691228 18599 solver.cpp:253]     Train net output #0: loss = 2.24409 (* 1 = 2.24409 loss)
I0522 00:06:19.691243 18599 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0522 00:06:31.895465 18599 solver.cpp:237] Iteration 2250, loss = 1.78391
I0522 00:06:31.895619 18599 solver.cpp:253]     Train net output #0: loss = 1.78391 (* 1 = 1.78391 loss)
I0522 00:06:31.895634 18599 sgd_solver.cpp:106] Iteration 2250, lr = 0.0025
I0522 00:06:44.052574 18599 solver.cpp:237] Iteration 3000, loss = 1.19906
I0522 00:06:44.052626 18599 solver.cpp:253]     Train net output #0: loss = 1.19906 (* 1 = 1.19906 loss)
I0522 00:06:44.052639 18599 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0522 00:06:56.258337 18599 solver.cpp:237] Iteration 3750, loss = 1.95106
I0522 00:06:56.258374 18599 solver.cpp:253]     Train net output #0: loss = 1.95106 (* 1 = 1.95106 loss)
I0522 00:06:56.258390 18599 sgd_solver.cpp:106] Iteration 3750, lr = 0.0025
I0522 00:07:08.418222 18599 solver.cpp:237] Iteration 4500, loss = 1.86828
I0522 00:07:08.418380 18599 solver.cpp:253]     Train net output #0: loss = 1.86828 (* 1 = 1.86828 loss)
I0522 00:07:08.418395 18599 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0522 00:07:42.645931 18599 solver.cpp:237] Iteration 5250, loss = 1.75641
I0522 00:07:42.646100 18599 solver.cpp:253]     Train net output #0: loss = 1.75641 (* 1 = 1.75641 loss)
I0522 00:07:42.646116 18599 sgd_solver.cpp:106] Iteration 5250, lr = 0.0025
I0522 00:07:54.772318 18599 solver.cpp:237] Iteration 6000, loss = 1.24633
I0522 00:07:54.772372 18599 solver.cpp:253]     Train net output #0: loss = 1.24633 (* 1 = 1.24633 loss)
I0522 00:07:54.772387 18599 sgd_solver.cpp:106] Iteration 6000, lr = 0.0025
I0522 00:08:06.928066 18599 solver.cpp:237] Iteration 6750, loss = 1.49184
I0522 00:08:06.928102 18599 solver.cpp:253]     Train net output #0: loss = 1.49184 (* 1 = 1.49184 loss)
I0522 00:08:06.928117 18599 sgd_solver.cpp:106] Iteration 6750, lr = 0.0025
I0522 00:08:19.048816 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_7500.caffemodel
I0522 00:08:19.101843 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_7500.solverstate
I0522 00:08:19.132259 18599 solver.cpp:237] Iteration 7500, loss = 1.25117
I0522 00:08:19.132304 18599 solver.cpp:253]     Train net output #0: loss = 1.25117 (* 1 = 1.25117 loss)
I0522 00:08:19.132326 18599 sgd_solver.cpp:106] Iteration 7500, lr = 0.0025
I0522 00:08:31.271757 18599 solver.cpp:237] Iteration 8250, loss = 1.35792
I0522 00:08:31.271795 18599 solver.cpp:253]     Train net output #0: loss = 1.35792 (* 1 = 1.35792 loss)
I0522 00:08:31.271808 18599 sgd_solver.cpp:106] Iteration 8250, lr = 0.0025
I0522 00:08:43.430613 18599 solver.cpp:237] Iteration 9000, loss = 1.01626
I0522 00:08:43.430651 18599 solver.cpp:253]     Train net output #0: loss = 1.01626 (* 1 = 1.01626 loss)
I0522 00:08:43.430663 18599 sgd_solver.cpp:106] Iteration 9000, lr = 0.0025
I0522 00:08:55.594545 18599 solver.cpp:237] Iteration 9750, loss = 1.50994
I0522 00:08:55.594697 18599 solver.cpp:253]     Train net output #0: loss = 1.50994 (* 1 = 1.50994 loss)
I0522 00:08:55.594712 18599 sgd_solver.cpp:106] Iteration 9750, lr = 0.0025
I0522 00:09:29.829116 18599 solver.cpp:237] Iteration 10500, loss = 0.821164
I0522 00:09:29.829287 18599 solver.cpp:253]     Train net output #0: loss = 0.821164 (* 1 = 0.821164 loss)
I0522 00:09:29.829301 18599 sgd_solver.cpp:106] Iteration 10500, lr = 0.0025
I0522 00:09:42.030606 18599 solver.cpp:237] Iteration 11250, loss = 0.961998
I0522 00:09:42.030654 18599 solver.cpp:253]     Train net output #0: loss = 0.961998 (* 1 = 0.961998 loss)
I0522 00:09:42.030669 18599 sgd_solver.cpp:106] Iteration 11250, lr = 0.0025
I0522 00:09:54.178699 18599 solver.cpp:237] Iteration 12000, loss = 1.31365
I0522 00:09:54.178735 18599 solver.cpp:253]     Train net output #0: loss = 1.31365 (* 1 = 1.31365 loss)
I0522 00:09:54.178751 18599 sgd_solver.cpp:106] Iteration 12000, lr = 0.0025
I0522 00:10:06.293578 18599 solver.cpp:237] Iteration 12750, loss = 1.32568
I0522 00:10:06.293745 18599 solver.cpp:253]     Train net output #0: loss = 1.32568 (* 1 = 1.32568 loss)
I0522 00:10:06.293761 18599 sgd_solver.cpp:106] Iteration 12750, lr = 0.0025
I0522 00:10:18.501309 18599 solver.cpp:237] Iteration 13500, loss = 1.56532
I0522 00:10:18.501345 18599 solver.cpp:253]     Train net output #0: loss = 1.56532 (* 1 = 1.56532 loss)
I0522 00:10:18.501363 18599 sgd_solver.cpp:106] Iteration 13500, lr = 0.0025
I0522 00:10:30.667714 18599 solver.cpp:237] Iteration 14250, loss = 1.07945
I0522 00:10:30.667767 18599 solver.cpp:253]     Train net output #0: loss = 1.07945 (* 1 = 1.07945 loss)
I0522 00:10:30.667781 18599 sgd_solver.cpp:106] Iteration 14250, lr = 0.0025
I0522 00:10:42.825665 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_15000.caffemodel
I0522 00:10:42.874836 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_15000.solverstate
I0522 00:10:42.899880 18599 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 00:11:34.833663 18599 solver.cpp:409]     Test net output #0: accuracy = 0.84756
I0522 00:11:34.833830 18599 solver.cpp:409]     Test net output #1: loss = 0.536782 (* 1 = 0.536782 loss)
I0522 00:11:56.932798 18599 solver.cpp:237] Iteration 15000, loss = 1.34654
I0522 00:11:56.932857 18599 solver.cpp:253]     Train net output #0: loss = 1.34654 (* 1 = 1.34654 loss)
I0522 00:11:56.932879 18599 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0522 00:12:09.064183 18599 solver.cpp:237] Iteration 15750, loss = 1.39676
I0522 00:12:09.064357 18599 solver.cpp:253]     Train net output #0: loss = 1.39676 (* 1 = 1.39676 loss)
I0522 00:12:09.064373 18599 sgd_solver.cpp:106] Iteration 15750, lr = 0.0025
I0522 00:12:21.192087 18599 solver.cpp:237] Iteration 16500, loss = 1.53712
I0522 00:12:21.192126 18599 solver.cpp:253]     Train net output #0: loss = 1.53712 (* 1 = 1.53712 loss)
I0522 00:12:21.192142 18599 sgd_solver.cpp:106] Iteration 16500, lr = 0.0025
I0522 00:12:33.310747 18599 solver.cpp:237] Iteration 17250, loss = 1.37848
I0522 00:12:33.310802 18599 solver.cpp:253]     Train net output #0: loss = 1.37848 (* 1 = 1.37848 loss)
I0522 00:12:33.310817 18599 sgd_solver.cpp:106] Iteration 17250, lr = 0.0025
I0522 00:12:45.478713 18599 solver.cpp:237] Iteration 18000, loss = 1.17428
I0522 00:12:45.478853 18599 solver.cpp:253]     Train net output #0: loss = 1.17428 (* 1 = 1.17428 loss)
I0522 00:12:45.478868 18599 sgd_solver.cpp:106] Iteration 18000, lr = 0.0025
I0522 00:12:57.628605 18599 solver.cpp:237] Iteration 18750, loss = 2.22925
I0522 00:12:57.628654 18599 solver.cpp:253]     Train net output #0: loss = 2.22925 (* 1 = 2.22925 loss)
I0522 00:12:57.628669 18599 sgd_solver.cpp:106] Iteration 18750, lr = 0.0025
I0522 00:13:09.753267 18599 solver.cpp:237] Iteration 19500, loss = 1.31583
I0522 00:13:09.753304 18599 solver.cpp:253]     Train net output #0: loss = 1.31583 (* 1 = 1.31583 loss)
I0522 00:13:09.753321 18599 sgd_solver.cpp:106] Iteration 19500, lr = 0.0025
I0522 00:13:44.049240 18599 solver.cpp:237] Iteration 20250, loss = 1.28628
I0522 00:13:44.049407 18599 solver.cpp:253]     Train net output #0: loss = 1.28628 (* 1 = 1.28628 loss)
I0522 00:13:44.049422 18599 sgd_solver.cpp:106] Iteration 20250, lr = 0.0025
I0522 00:13:56.190471 18599 solver.cpp:237] Iteration 21000, loss = 1.23214
I0522 00:13:56.190507 18599 solver.cpp:253]     Train net output #0: loss = 1.23214 (* 1 = 1.23214 loss)
I0522 00:13:56.190524 18599 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0522 00:14:08.370391 18599 solver.cpp:237] Iteration 21750, loss = 1.51293
I0522 00:14:08.370429 18599 solver.cpp:253]     Train net output #0: loss = 1.51293 (* 1 = 1.51293 loss)
I0522 00:14:08.370445 18599 sgd_solver.cpp:106] Iteration 21750, lr = 0.0025
I0522 00:14:20.523749 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_22500.caffemodel
I0522 00:14:20.576030 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_22500.solverstate
I0522 00:14:20.609997 18599 solver.cpp:237] Iteration 22500, loss = 1.80771
I0522 00:14:20.610050 18599 solver.cpp:253]     Train net output #0: loss = 1.80771 (* 1 = 1.80771 loss)
I0522 00:14:20.610069 18599 sgd_solver.cpp:106] Iteration 22500, lr = 0.0025
I0522 00:14:32.759589 18599 solver.cpp:237] Iteration 23250, loss = 0.87659
I0522 00:14:32.759626 18599 solver.cpp:253]     Train net output #0: loss = 0.87659 (* 1 = 0.87659 loss)
I0522 00:14:32.759644 18599 sgd_solver.cpp:106] Iteration 23250, lr = 0.0025
I0522 00:14:44.967376 18599 solver.cpp:237] Iteration 24000, loss = 1.1536
I0522 00:14:44.967429 18599 solver.cpp:253]     Train net output #0: loss = 1.1536 (* 1 = 1.1536 loss)
I0522 00:14:44.967445 18599 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0522 00:14:57.129148 18599 solver.cpp:237] Iteration 24750, loss = 1.33498
I0522 00:14:57.129293 18599 solver.cpp:253]     Train net output #0: loss = 1.33498 (* 1 = 1.33498 loss)
I0522 00:14:57.129307 18599 sgd_solver.cpp:106] Iteration 24750, lr = 0.0025
I0522 00:15:31.458957 18599 solver.cpp:237] Iteration 25500, loss = 1.40026
I0522 00:15:31.459125 18599 solver.cpp:253]     Train net output #0: loss = 1.40026 (* 1 = 1.40026 loss)
I0522 00:15:31.459139 18599 sgd_solver.cpp:106] Iteration 25500, lr = 0.0025
I0522 00:15:43.636934 18599 solver.cpp:237] Iteration 26250, loss = 1.78238
I0522 00:15:43.636970 18599 solver.cpp:253]     Train net output #0: loss = 1.78238 (* 1 = 1.78238 loss)
I0522 00:15:43.636986 18599 sgd_solver.cpp:106] Iteration 26250, lr = 0.0025
I0522 00:15:55.794013 18599 solver.cpp:237] Iteration 27000, loss = 1.15478
I0522 00:15:55.794067 18599 solver.cpp:253]     Train net output #0: loss = 1.15478 (* 1 = 1.15478 loss)
I0522 00:15:55.794080 18599 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0522 00:16:07.960300 18599 solver.cpp:237] Iteration 27750, loss = 1.04597
I0522 00:16:07.960443 18599 solver.cpp:253]     Train net output #0: loss = 1.04597 (* 1 = 1.04597 loss)
I0522 00:16:07.960458 18599 sgd_solver.cpp:106] Iteration 27750, lr = 0.0025
I0522 00:16:20.105813 18599 solver.cpp:237] Iteration 28500, loss = 1.00138
I0522 00:16:20.105866 18599 solver.cpp:253]     Train net output #0: loss = 1.00138 (* 1 = 1.00138 loss)
I0522 00:16:20.105881 18599 sgd_solver.cpp:106] Iteration 28500, lr = 0.0025
I0522 00:16:32.213023 18599 solver.cpp:237] Iteration 29250, loss = 1.15561
I0522 00:16:32.213060 18599 solver.cpp:253]     Train net output #0: loss = 1.15561 (* 1 = 1.15561 loss)
I0522 00:16:32.213078 18599 sgd_solver.cpp:106] Iteration 29250, lr = 0.0025
I0522 00:16:44.322168 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_30000.caffemodel
I0522 00:16:44.373029 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_30000.solverstate
I0522 00:16:44.401654 18599 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 00:17:57.249537 18599 solver.cpp:409]     Test net output #0: accuracy = 0.864921
I0522 00:17:57.249709 18599 solver.cpp:409]     Test net output #1: loss = 0.475829 (* 1 = 0.475829 loss)
I0522 00:18:19.372862 18599 solver.cpp:237] Iteration 30000, loss = 1.28202
I0522 00:18:19.372927 18599 solver.cpp:253]     Train net output #0: loss = 1.28202 (* 1 = 1.28202 loss)
I0522 00:18:19.372943 18599 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0522 00:18:31.572667 18599 solver.cpp:237] Iteration 30750, loss = 0.939003
I0522 00:18:31.572824 18599 solver.cpp:253]     Train net output #0: loss = 0.939002 (* 1 = 0.939002 loss)
I0522 00:18:31.572839 18599 sgd_solver.cpp:106] Iteration 30750, lr = 0.0025
I0522 00:18:43.738838 18599 solver.cpp:237] Iteration 31500, loss = 1.14895
I0522 00:18:43.738893 18599 solver.cpp:253]     Train net output #0: loss = 1.14895 (* 1 = 1.14895 loss)
I0522 00:18:43.738906 18599 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0522 00:18:55.921332 18599 solver.cpp:237] Iteration 32250, loss = 1.17863
I0522 00:18:55.921370 18599 solver.cpp:253]     Train net output #0: loss = 1.17863 (* 1 = 1.17863 loss)
I0522 00:18:55.921386 18599 sgd_solver.cpp:106] Iteration 32250, lr = 0.0025
I0522 00:19:08.124104 18599 solver.cpp:237] Iteration 33000, loss = 0.869402
I0522 00:19:08.124246 18599 solver.cpp:253]     Train net output #0: loss = 0.869401 (* 1 = 0.869401 loss)
I0522 00:19:08.124261 18599 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0522 00:19:20.331514 18599 solver.cpp:237] Iteration 33750, loss = 1.07692
I0522 00:19:20.331562 18599 solver.cpp:253]     Train net output #0: loss = 1.07692 (* 1 = 1.07692 loss)
I0522 00:19:20.331578 18599 sgd_solver.cpp:106] Iteration 33750, lr = 0.0025
I0522 00:19:32.539582 18599 solver.cpp:237] Iteration 34500, loss = 1.21297
I0522 00:19:32.539618 18599 solver.cpp:253]     Train net output #0: loss = 1.21297 (* 1 = 1.21297 loss)
I0522 00:19:32.539634 18599 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0522 00:20:06.836766 18599 solver.cpp:237] Iteration 35250, loss = 1.7797
I0522 00:20:06.836952 18599 solver.cpp:253]     Train net output #0: loss = 1.7797 (* 1 = 1.7797 loss)
I0522 00:20:06.836967 18599 sgd_solver.cpp:106] Iteration 35250, lr = 0.0025
I0522 00:20:19.019244 18599 solver.cpp:237] Iteration 36000, loss = 0.951763
I0522 00:20:19.019282 18599 solver.cpp:253]     Train net output #0: loss = 0.951762 (* 1 = 0.951762 loss)
I0522 00:20:19.019295 18599 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0522 00:20:31.190006 18599 solver.cpp:237] Iteration 36750, loss = 1.48167
I0522 00:20:31.190059 18599 solver.cpp:253]     Train net output #0: loss = 1.48167 (* 1 = 1.48167 loss)
I0522 00:20:31.190073 18599 sgd_solver.cpp:106] Iteration 36750, lr = 0.0025
I0522 00:20:43.335899 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_37500.caffemodel
I0522 00:20:43.387935 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_37500.solverstate
I0522 00:20:43.421484 18599 solver.cpp:237] Iteration 37500, loss = 0.823783
I0522 00:20:43.421538 18599 solver.cpp:253]     Train net output #0: loss = 0.823782 (* 1 = 0.823782 loss)
I0522 00:20:43.421555 18599 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0522 00:20:55.576558 18599 solver.cpp:237] Iteration 38250, loss = 1.19724
I0522 00:20:55.576609 18599 solver.cpp:253]     Train net output #0: loss = 1.19724 (* 1 = 1.19724 loss)
I0522 00:20:55.576623 18599 sgd_solver.cpp:106] Iteration 38250, lr = 0.0025
I0522 00:21:07.780156 18599 solver.cpp:237] Iteration 39000, loss = 1.49853
I0522 00:21:07.780194 18599 solver.cpp:253]     Train net output #0: loss = 1.49853 (* 1 = 1.49853 loss)
I0522 00:21:07.780210 18599 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0522 00:21:19.987952 18599 solver.cpp:237] Iteration 39750, loss = 0.892774
I0522 00:21:19.988119 18599 solver.cpp:253]     Train net output #0: loss = 0.892773 (* 1 = 0.892773 loss)
I0522 00:21:19.988135 18599 sgd_solver.cpp:106] Iteration 39750, lr = 0.0025
I0522 00:21:54.327986 18599 solver.cpp:237] Iteration 40500, loss = 1.22308
I0522 00:21:54.328168 18599 solver.cpp:253]     Train net output #0: loss = 1.22307 (* 1 = 1.22307 loss)
I0522 00:21:54.328183 18599 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0522 00:22:06.551461 18599 solver.cpp:237] Iteration 41250, loss = 0.779645
I0522 00:22:06.551515 18599 solver.cpp:253]     Train net output #0: loss = 0.779644 (* 1 = 0.779644 loss)
I0522 00:22:06.551528 18599 sgd_solver.cpp:106] Iteration 41250, lr = 0.0025
I0522 00:22:18.761005 18599 solver.cpp:237] Iteration 42000, loss = 1.06689
I0522 00:22:18.761041 18599 solver.cpp:253]     Train net output #0: loss = 1.06689 (* 1 = 1.06689 loss)
I0522 00:22:18.761057 18599 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0522 00:22:30.960922 18599 solver.cpp:237] Iteration 42750, loss = 1.49455
I0522 00:22:30.961087 18599 solver.cpp:253]     Train net output #0: loss = 1.49455 (* 1 = 1.49455 loss)
I0522 00:22:30.961102 18599 sgd_solver.cpp:106] Iteration 42750, lr = 0.0025
I0522 00:22:43.163964 18599 solver.cpp:237] Iteration 43500, loss = 1.19151
I0522 00:22:43.164000 18599 solver.cpp:253]     Train net output #0: loss = 1.19151 (* 1 = 1.19151 loss)
I0522 00:22:43.164016 18599 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0522 00:22:55.377051 18599 solver.cpp:237] Iteration 44250, loss = 1.10684
I0522 00:22:55.377096 18599 solver.cpp:253]     Train net output #0: loss = 1.10684 (* 1 = 1.10684 loss)
I0522 00:22:55.377113 18599 sgd_solver.cpp:106] Iteration 44250, lr = 0.0025
I0522 00:23:07.547925 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_45000.caffemodel
I0522 00:23:07.601346 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_45000.solverstate
I0522 00:23:07.627878 18599 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 00:23:59.151976 18599 solver.cpp:409]     Test net output #0: accuracy = 0.867916
I0522 00:23:59.152140 18599 solver.cpp:409]     Test net output #1: loss = 0.415924 (* 1 = 0.415924 loss)
I0522 00:24:21.260401 18599 solver.cpp:237] Iteration 45000, loss = 1.33498
I0522 00:24:21.260457 18599 solver.cpp:253]     Train net output #0: loss = 1.33498 (* 1 = 1.33498 loss)
I0522 00:24:21.260473 18599 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0522 00:24:33.369627 18599 solver.cpp:237] Iteration 45750, loss = 1.21991
I0522 00:24:33.369781 18599 solver.cpp:253]     Train net output #0: loss = 1.2199 (* 1 = 1.2199 loss)
I0522 00:24:33.369796 18599 sgd_solver.cpp:106] Iteration 45750, lr = 0.0025
I0522 00:24:45.453410 18599 solver.cpp:237] Iteration 46500, loss = 1.7388
I0522 00:24:45.453459 18599 solver.cpp:253]     Train net output #0: loss = 1.7388 (* 1 = 1.7388 loss)
I0522 00:24:45.453474 18599 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0522 00:24:57.540714 18599 solver.cpp:237] Iteration 47250, loss = 1.41598
I0522 00:24:57.540750 18599 solver.cpp:253]     Train net output #0: loss = 1.41598 (* 1 = 1.41598 loss)
I0522 00:24:57.540767 18599 sgd_solver.cpp:106] Iteration 47250, lr = 0.0025
I0522 00:25:09.653551 18599 solver.cpp:237] Iteration 48000, loss = 1.19557
I0522 00:25:09.653710 18599 solver.cpp:253]     Train net output #0: loss = 1.19557 (* 1 = 1.19557 loss)
I0522 00:25:09.653724 18599 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0522 00:25:21.771889 18599 solver.cpp:237] Iteration 48750, loss = 1.17844
I0522 00:25:21.771925 18599 solver.cpp:253]     Train net output #0: loss = 1.17844 (* 1 = 1.17844 loss)
I0522 00:25:21.771942 18599 sgd_solver.cpp:106] Iteration 48750, lr = 0.0025
I0522 00:25:33.894927 18599 solver.cpp:237] Iteration 49500, loss = 0.979952
I0522 00:25:33.894984 18599 solver.cpp:253]     Train net output #0: loss = 0.979951 (* 1 = 0.979951 loss)
I0522 00:25:33.894997 18599 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0522 00:26:08.161921 18599 solver.cpp:237] Iteration 50250, loss = 1.14927
I0522 00:26:08.162102 18599 solver.cpp:253]     Train net output #0: loss = 1.14927 (* 1 = 1.14927 loss)
I0522 00:26:08.162117 18599 sgd_solver.cpp:106] Iteration 50250, lr = 0.0025
I0522 00:26:20.314632 18599 solver.cpp:237] Iteration 51000, loss = 0.842439
I0522 00:26:20.314682 18599 solver.cpp:253]     Train net output #0: loss = 0.842438 (* 1 = 0.842438 loss)
I0522 00:26:20.314697 18599 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0522 00:26:32.444809 18599 solver.cpp:237] Iteration 51750, loss = 1.06827
I0522 00:26:32.444845 18599 solver.cpp:253]     Train net output #0: loss = 1.06827 (* 1 = 1.06827 loss)
I0522 00:26:32.444861 18599 sgd_solver.cpp:106] Iteration 51750, lr = 0.0025
I0522 00:26:44.582476 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_52500.caffemodel
I0522 00:26:44.632241 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_52500.solverstate
I0522 00:26:44.663420 18599 solver.cpp:237] Iteration 52500, loss = 1.31914
I0522 00:26:44.663463 18599 solver.cpp:253]     Train net output #0: loss = 1.31914 (* 1 = 1.31914 loss)
I0522 00:26:44.663486 18599 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0522 00:26:56.809355 18599 solver.cpp:237] Iteration 53250, loss = 0.830091
I0522 00:26:56.809392 18599 solver.cpp:253]     Train net output #0: loss = 0.83009 (* 1 = 0.83009 loss)
I0522 00:26:56.809408 18599 sgd_solver.cpp:106] Iteration 53250, lr = 0.0025
I0522 00:27:08.938936 18599 solver.cpp:237] Iteration 54000, loss = 0.967842
I0522 00:27:08.938990 18599 solver.cpp:253]     Train net output #0: loss = 0.967841 (* 1 = 0.967841 loss)
I0522 00:27:08.939007 18599 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0522 00:27:21.096560 18599 solver.cpp:237] Iteration 54750, loss = 1.00747
I0522 00:27:21.096719 18599 solver.cpp:253]     Train net output #0: loss = 1.00747 (* 1 = 1.00747 loss)
I0522 00:27:21.096734 18599 sgd_solver.cpp:106] Iteration 54750, lr = 0.0025
I0522 00:27:55.373886 18599 solver.cpp:237] Iteration 55500, loss = 1.11644
I0522 00:27:55.374058 18599 solver.cpp:253]     Train net output #0: loss = 1.11644 (* 1 = 1.11644 loss)
I0522 00:27:55.374073 18599 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0522 00:28:07.503882 18599 solver.cpp:237] Iteration 56250, loss = 1.30184
I0522 00:28:07.503918 18599 solver.cpp:253]     Train net output #0: loss = 1.30184 (* 1 = 1.30184 loss)
I0522 00:28:07.503932 18599 sgd_solver.cpp:106] Iteration 56250, lr = 0.0025
I0522 00:28:19.651250 18599 solver.cpp:237] Iteration 57000, loss = 1.31634
I0522 00:28:19.651305 18599 solver.cpp:253]     Train net output #0: loss = 1.31634 (* 1 = 1.31634 loss)
I0522 00:28:19.651319 18599 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0522 00:28:31.795513 18599 solver.cpp:237] Iteration 57750, loss = 1.26126
I0522 00:28:31.795660 18599 solver.cpp:253]     Train net output #0: loss = 1.26126 (* 1 = 1.26126 loss)
I0522 00:28:31.795675 18599 sgd_solver.cpp:106] Iteration 57750, lr = 0.0025
I0522 00:28:43.938652 18599 solver.cpp:237] Iteration 58500, loss = 1.18085
I0522 00:28:43.938704 18599 solver.cpp:253]     Train net output #0: loss = 1.18085 (* 1 = 1.18085 loss)
I0522 00:28:43.938716 18599 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
I0522 00:28:56.081331 18599 solver.cpp:237] Iteration 59250, loss = 1.25568
I0522 00:28:56.081367 18599 solver.cpp:253]     Train net output #0: loss = 1.25568 (* 1 = 1.25568 loss)
I0522 00:28:56.081383 18599 sgd_solver.cpp:106] Iteration 59250, lr = 0.0025
I0522 00:29:08.232285 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_60000.caffemodel
I0522 00:29:08.281544 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_60000.solverstate
I0522 00:29:08.308102 18599 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 00:30:21.113731 18599 solver.cpp:409]     Test net output #0: accuracy = 0.880081
I0522 00:30:21.113901 18599 solver.cpp:409]     Test net output #1: loss = 0.367417 (* 1 = 0.367417 loss)
I0522 00:30:43.325553 18599 solver.cpp:237] Iteration 60000, loss = 1.56887
I0522 00:30:43.325609 18599 solver.cpp:253]     Train net output #0: loss = 1.56886 (* 1 = 1.56886 loss)
I0522 00:30:43.325626 18599 sgd_solver.cpp:106] Iteration 60000, lr = 0.0025
I0522 00:30:55.500480 18599 solver.cpp:237] Iteration 60750, loss = 0.974141
I0522 00:30:55.500651 18599 solver.cpp:253]     Train net output #0: loss = 0.97414 (* 1 = 0.97414 loss)
I0522 00:30:55.500666 18599 sgd_solver.cpp:106] Iteration 60750, lr = 0.0025
I0522 00:31:07.645563 18599 solver.cpp:237] Iteration 61500, loss = 0.81114
I0522 00:31:07.645601 18599 solver.cpp:253]     Train net output #0: loss = 0.811139 (* 1 = 0.811139 loss)
I0522 00:31:07.645617 18599 sgd_solver.cpp:106] Iteration 61500, lr = 0.0025
I0522 00:31:19.826272 18599 solver.cpp:237] Iteration 62250, loss = 1.22525
I0522 00:31:19.826325 18599 solver.cpp:253]     Train net output #0: loss = 1.22525 (* 1 = 1.22525 loss)
I0522 00:31:19.826340 18599 sgd_solver.cpp:106] Iteration 62250, lr = 0.0025
I0522 00:31:32.006062 18599 solver.cpp:237] Iteration 63000, loss = 1.08927
I0522 00:31:32.006207 18599 solver.cpp:253]     Train net output #0: loss = 1.08927 (* 1 = 1.08927 loss)
I0522 00:31:32.006222 18599 sgd_solver.cpp:106] Iteration 63000, lr = 0.0025
I0522 00:31:44.182306 18599 solver.cpp:237] Iteration 63750, loss = 1.06072
I0522 00:31:44.182351 18599 solver.cpp:253]     Train net output #0: loss = 1.06071 (* 1 = 1.06071 loss)
I0522 00:31:44.182368 18599 sgd_solver.cpp:106] Iteration 63750, lr = 0.0025
I0522 00:31:56.333497 18599 solver.cpp:237] Iteration 64500, loss = 1.02095
I0522 00:31:56.333533 18599 solver.cpp:253]     Train net output #0: loss = 1.02095 (* 1 = 1.02095 loss)
I0522 00:31:56.333549 18599 sgd_solver.cpp:106] Iteration 64500, lr = 0.0025
I0522 00:32:30.580420 18599 solver.cpp:237] Iteration 65250, loss = 1.30579
I0522 00:32:30.580593 18599 solver.cpp:253]     Train net output #0: loss = 1.30579 (* 1 = 1.30579 loss)
I0522 00:32:30.580607 18599 sgd_solver.cpp:106] Iteration 65250, lr = 0.0025
I0522 00:32:42.696504 18599 solver.cpp:237] Iteration 66000, loss = 1.35767
I0522 00:32:42.696540 18599 solver.cpp:253]     Train net output #0: loss = 1.35767 (* 1 = 1.35767 loss)
I0522 00:32:42.696553 18599 sgd_solver.cpp:106] Iteration 66000, lr = 0.0025
I0522 00:32:54.875707 18599 solver.cpp:237] Iteration 66750, loss = 1.36185
I0522 00:32:54.875759 18599 solver.cpp:253]     Train net output #0: loss = 1.36185 (* 1 = 1.36185 loss)
I0522 00:32:54.875777 18599 sgd_solver.cpp:106] Iteration 66750, lr = 0.0025
I0522 00:33:07.049892 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_67500.caffemodel
I0522 00:33:07.102072 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_67500.solverstate
I0522 00:33:07.135095 18599 solver.cpp:237] Iteration 67500, loss = 1.1422
I0522 00:33:07.135149 18599 solver.cpp:253]     Train net output #0: loss = 1.1422 (* 1 = 1.1422 loss)
I0522 00:33:07.135164 18599 sgd_solver.cpp:106] Iteration 67500, lr = 0.0025
I0522 00:33:19.293587 18599 solver.cpp:237] Iteration 68250, loss = 0.500354
I0522 00:33:19.293643 18599 solver.cpp:253]     Train net output #0: loss = 0.500352 (* 1 = 0.500352 loss)
I0522 00:33:19.293659 18599 sgd_solver.cpp:106] Iteration 68250, lr = 0.0025
I0522 00:33:31.452214 18599 solver.cpp:237] Iteration 69000, loss = 1.5459
I0522 00:33:31.452251 18599 solver.cpp:253]     Train net output #0: loss = 1.5459 (* 1 = 1.5459 loss)
I0522 00:33:31.452265 18599 sgd_solver.cpp:106] Iteration 69000, lr = 0.0025
I0522 00:33:43.606302 18599 solver.cpp:237] Iteration 69750, loss = 1.01353
I0522 00:33:43.606461 18599 solver.cpp:253]     Train net output #0: loss = 1.01353 (* 1 = 1.01353 loss)
I0522 00:33:43.606474 18599 sgd_solver.cpp:106] Iteration 69750, lr = 0.0025
I0522 00:34:17.953797 18599 solver.cpp:237] Iteration 70500, loss = 1.15052
I0522 00:34:17.953977 18599 solver.cpp:253]     Train net output #0: loss = 1.15052 (* 1 = 1.15052 loss)
I0522 00:34:17.953991 18599 sgd_solver.cpp:106] Iteration 70500, lr = 0.0025
I0522 00:34:30.144105 18599 solver.cpp:237] Iteration 71250, loss = 1.09824
I0522 00:34:30.144142 18599 solver.cpp:253]     Train net output #0: loss = 1.09824 (* 1 = 1.09824 loss)
I0522 00:34:30.144157 18599 sgd_solver.cpp:106] Iteration 71250, lr = 0.0025
I0522 00:34:42.325294 18599 solver.cpp:237] Iteration 72000, loss = 1.12266
I0522 00:34:42.325350 18599 solver.cpp:253]     Train net output #0: loss = 1.12266 (* 1 = 1.12266 loss)
I0522 00:34:42.325363 18599 sgd_solver.cpp:106] Iteration 72000, lr = 0.0025
I0522 00:34:54.494189 18599 solver.cpp:237] Iteration 72750, loss = 1.35008
I0522 00:34:54.494349 18599 solver.cpp:253]     Train net output #0: loss = 1.35008 (* 1 = 1.35008 loss)
I0522 00:34:54.494364 18599 sgd_solver.cpp:106] Iteration 72750, lr = 0.0025
I0522 00:35:06.660213 18599 solver.cpp:237] Iteration 73500, loss = 1.75021
I0522 00:35:06.660267 18599 solver.cpp:253]     Train net output #0: loss = 1.75021 (* 1 = 1.75021 loss)
I0522 00:35:06.660281 18599 sgd_solver.cpp:106] Iteration 73500, lr = 0.0025
I0522 00:35:18.827175 18599 solver.cpp:237] Iteration 74250, loss = 1.46119
I0522 00:35:18.827211 18599 solver.cpp:253]     Train net output #0: loss = 1.46119 (* 1 = 1.46119 loss)
I0522 00:35:18.827227 18599 sgd_solver.cpp:106] Iteration 74250, lr = 0.0025
I0522 00:35:31.015416 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_75000.caffemodel
I0522 00:35:31.066545 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_75000.solverstate
I0522 00:35:31.095648 18599 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 00:36:23.013243 18599 solver.cpp:409]     Test net output #0: accuracy = 0.886368
I0522 00:36:23.013412 18599 solver.cpp:409]     Test net output #1: loss = 0.363209 (* 1 = 0.363209 loss)
I0522 00:36:43.919522 18599 solver.cpp:237] Iteration 75000, loss = 1.02847
I0522 00:36:43.919579 18599 solver.cpp:253]     Train net output #0: loss = 1.02847 (* 1 = 1.02847 loss)
I0522 00:36:43.919595 18599 sgd_solver.cpp:106] Iteration 75000, lr = 0.0025
I0522 00:36:56.100867 18599 solver.cpp:237] Iteration 75750, loss = 1.3997
I0522 00:36:56.101027 18599 solver.cpp:253]     Train net output #0: loss = 1.39969 (* 1 = 1.39969 loss)
I0522 00:36:56.101042 18599 sgd_solver.cpp:106] Iteration 75750, lr = 0.0025
I0522 00:37:08.286564 18599 solver.cpp:237] Iteration 76500, loss = 1.55423
I0522 00:37:08.286617 18599 solver.cpp:253]     Train net output #0: loss = 1.55422 (* 1 = 1.55422 loss)
I0522 00:37:08.286631 18599 sgd_solver.cpp:106] Iteration 76500, lr = 0.0025
I0522 00:37:20.496567 18599 solver.cpp:237] Iteration 77250, loss = 1.23855
I0522 00:37:20.496603 18599 solver.cpp:253]     Train net output #0: loss = 1.23855 (* 1 = 1.23855 loss)
I0522 00:37:20.496619 18599 sgd_solver.cpp:106] Iteration 77250, lr = 0.0025
I0522 00:37:32.718564 18599 solver.cpp:237] Iteration 78000, loss = 0.943927
I0522 00:37:32.718729 18599 solver.cpp:253]     Train net output #0: loss = 0.943926 (* 1 = 0.943926 loss)
I0522 00:37:32.718744 18599 sgd_solver.cpp:106] Iteration 78000, lr = 0.0025
I0522 00:37:44.940723 18599 solver.cpp:237] Iteration 78750, loss = 1.61671
I0522 00:37:44.940759 18599 solver.cpp:253]     Train net output #0: loss = 1.61671 (* 1 = 1.61671 loss)
I0522 00:37:44.940775 18599 sgd_solver.cpp:106] Iteration 78750, lr = 0.0025
I0522 00:37:57.157269 18599 solver.cpp:237] Iteration 79500, loss = 1.55967
I0522 00:37:57.157315 18599 solver.cpp:253]     Train net output #0: loss = 1.55967 (* 1 = 1.55967 loss)
I0522 00:37:57.157330 18599 sgd_solver.cpp:106] Iteration 79500, lr = 0.0025
I0522 00:38:30.279218 18599 solver.cpp:237] Iteration 80250, loss = 1.50875
I0522 00:38:30.279404 18599 solver.cpp:253]     Train net output #0: loss = 1.50874 (* 1 = 1.50874 loss)
I0522 00:38:30.279419 18599 sgd_solver.cpp:106] Iteration 80250, lr = 0.0025
I0522 00:38:42.516170 18599 solver.cpp:237] Iteration 81000, loss = 1.1454
I0522 00:38:42.516206 18599 solver.cpp:253]     Train net output #0: loss = 1.1454 (* 1 = 1.1454 loss)
I0522 00:38:42.516222 18599 sgd_solver.cpp:106] Iteration 81000, lr = 0.0025
I0522 00:38:54.715471 18599 solver.cpp:237] Iteration 81750, loss = 1.83803
I0522 00:38:54.715522 18599 solver.cpp:253]     Train net output #0: loss = 1.83803 (* 1 = 1.83803 loss)
I0522 00:38:54.715535 18599 sgd_solver.cpp:106] Iteration 81750, lr = 0.0025
I0522 00:39:06.905416 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_82500.caffemodel
I0522 00:39:06.955160 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_82500.solverstate
I0522 00:39:06.986853 18599 solver.cpp:237] Iteration 82500, loss = 0.765058
I0522 00:39:06.986904 18599 solver.cpp:253]     Train net output #0: loss = 0.765056 (* 1 = 0.765056 loss)
I0522 00:39:06.986920 18599 sgd_solver.cpp:106] Iteration 82500, lr = 0.0025
I0522 00:39:19.192276 18599 solver.cpp:237] Iteration 83250, loss = 1.66477
I0522 00:39:19.192327 18599 solver.cpp:253]     Train net output #0: loss = 1.66477 (* 1 = 1.66477 loss)
I0522 00:39:19.192342 18599 sgd_solver.cpp:106] Iteration 83250, lr = 0.0025
I0522 00:39:31.419657 18599 solver.cpp:237] Iteration 84000, loss = 0.9775
I0522 00:39:31.419693 18599 solver.cpp:253]     Train net output #0: loss = 0.977499 (* 1 = 0.977499 loss)
I0522 00:39:31.419709 18599 sgd_solver.cpp:106] Iteration 84000, lr = 0.0025
I0522 00:39:43.659163 18599 solver.cpp:237] Iteration 84750, loss = 0.652952
I0522 00:39:43.659337 18599 solver.cpp:253]     Train net output #0: loss = 0.65295 (* 1 = 0.65295 loss)
I0522 00:39:43.659351 18599 sgd_solver.cpp:106] Iteration 84750, lr = 0.0025
I0522 00:40:16.719871 18599 solver.cpp:237] Iteration 85500, loss = 0.918788
I0522 00:40:16.720047 18599 solver.cpp:253]     Train net output #0: loss = 0.918787 (* 1 = 0.918787 loss)
I0522 00:40:16.720063 18599 sgd_solver.cpp:106] Iteration 85500, lr = 0.0025
I0522 00:40:28.960047 18599 solver.cpp:237] Iteration 86250, loss = 1.075
I0522 00:40:28.960095 18599 solver.cpp:253]     Train net output #0: loss = 1.075 (* 1 = 1.075 loss)
I0522 00:40:28.960110 18599 sgd_solver.cpp:106] Iteration 86250, lr = 0.0025
I0522 00:40:41.199340 18599 solver.cpp:237] Iteration 87000, loss = 1.43098
I0522 00:40:41.199375 18599 solver.cpp:253]     Train net output #0: loss = 1.43098 (* 1 = 1.43098 loss)
I0522 00:40:41.199393 18599 sgd_solver.cpp:106] Iteration 87000, lr = 0.0025
I0522 00:40:53.440193 18599 solver.cpp:237] Iteration 87750, loss = 1.19016
I0522 00:40:53.440356 18599 solver.cpp:253]     Train net output #0: loss = 1.19016 (* 1 = 1.19016 loss)
I0522 00:40:53.440371 18599 sgd_solver.cpp:106] Iteration 87750, lr = 0.0025
I0522 00:41:05.626606 18599 solver.cpp:237] Iteration 88500, loss = 1.29384
I0522 00:41:05.626642 18599 solver.cpp:253]     Train net output #0: loss = 1.29384 (* 1 = 1.29384 loss)
I0522 00:41:05.626657 18599 sgd_solver.cpp:106] Iteration 88500, lr = 0.0025
I0522 00:41:17.828893 18599 solver.cpp:237] Iteration 89250, loss = 1.52566
I0522 00:41:17.828941 18599 solver.cpp:253]     Train net output #0: loss = 1.52565 (* 1 = 1.52565 loss)
I0522 00:41:17.828956 18599 sgd_solver.cpp:106] Iteration 89250, lr = 0.0025
I0522 00:41:30.051592 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_90000.caffemodel
I0522 00:41:30.100659 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_90000.solverstate
I0522 00:41:30.126950 18599 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 00:42:42.950772 18599 solver.cpp:409]     Test net output #0: accuracy = 0.89011
I0522 00:42:42.950948 18599 solver.cpp:409]     Test net output #1: loss = 0.357868 (* 1 = 0.357868 loss)
I0522 00:43:03.806095 18599 solver.cpp:237] Iteration 90000, loss = 0.677793
I0522 00:43:03.806154 18599 solver.cpp:253]     Train net output #0: loss = 0.677791 (* 1 = 0.677791 loss)
I0522 00:43:03.806169 18599 sgd_solver.cpp:106] Iteration 90000, lr = 0.0025
I0522 00:43:15.959553 18599 solver.cpp:237] Iteration 90750, loss = 1.44412
I0522 00:43:15.959712 18599 solver.cpp:253]     Train net output #0: loss = 1.44412 (* 1 = 1.44412 loss)
I0522 00:43:15.959727 18599 sgd_solver.cpp:106] Iteration 90750, lr = 0.0025
I0522 00:43:28.063458 18599 solver.cpp:237] Iteration 91500, loss = 0.77599
I0522 00:43:28.063508 18599 solver.cpp:253]     Train net output #0: loss = 0.775988 (* 1 = 0.775988 loss)
I0522 00:43:28.063524 18599 sgd_solver.cpp:106] Iteration 91500, lr = 0.0025
I0522 00:43:40.174875 18599 solver.cpp:237] Iteration 92250, loss = 1.50187
I0522 00:43:40.174911 18599 solver.cpp:253]     Train net output #0: loss = 1.50187 (* 1 = 1.50187 loss)
I0522 00:43:40.174927 18599 sgd_solver.cpp:106] Iteration 92250, lr = 0.0025
I0522 00:43:52.283018 18599 solver.cpp:237] Iteration 93000, loss = 0.991144
I0522 00:43:52.283179 18599 solver.cpp:253]     Train net output #0: loss = 0.991142 (* 1 = 0.991142 loss)
I0522 00:43:52.283195 18599 sgd_solver.cpp:106] Iteration 93000, lr = 0.0025
I0522 00:44:04.392012 18599 solver.cpp:237] Iteration 93750, loss = 1.43049
I0522 00:44:04.392050 18599 solver.cpp:253]     Train net output #0: loss = 1.43049 (* 1 = 1.43049 loss)
I0522 00:44:04.392065 18599 sgd_solver.cpp:106] Iteration 93750, lr = 0.0025
I0522 00:44:16.570291 18599 solver.cpp:237] Iteration 94500, loss = 1.27322
I0522 00:44:16.570335 18599 solver.cpp:253]     Train net output #0: loss = 1.27322 (* 1 = 1.27322 loss)
I0522 00:44:16.570353 18599 sgd_solver.cpp:106] Iteration 94500, lr = 0.0025
I0522 00:44:49.618317 18599 solver.cpp:237] Iteration 95250, loss = 0.935319
I0522 00:44:49.618496 18599 solver.cpp:253]     Train net output #0: loss = 0.935317 (* 1 = 0.935317 loss)
I0522 00:44:49.618511 18599 sgd_solver.cpp:106] Iteration 95250, lr = 0.0025
I0522 00:45:01.831135 18599 solver.cpp:237] Iteration 96000, loss = 1.24591
I0522 00:45:01.831184 18599 solver.cpp:253]     Train net output #0: loss = 1.24591 (* 1 = 1.24591 loss)
I0522 00:45:01.831200 18599 sgd_solver.cpp:106] Iteration 96000, lr = 0.0025
I0522 00:45:14.017725 18599 solver.cpp:237] Iteration 96750, loss = 1.39258
I0522 00:45:14.017761 18599 solver.cpp:253]     Train net output #0: loss = 1.39258 (* 1 = 1.39258 loss)
I0522 00:45:14.017778 18599 sgd_solver.cpp:106] Iteration 96750, lr = 0.0025
I0522 00:45:26.161911 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_97500.caffemodel
I0522 00:45:26.210292 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_97500.solverstate
I0522 00:45:26.241590 18599 solver.cpp:237] Iteration 97500, loss = 1.30095
I0522 00:45:26.241636 18599 solver.cpp:253]     Train net output #0: loss = 1.30095 (* 1 = 1.30095 loss)
I0522 00:45:26.241657 18599 sgd_solver.cpp:106] Iteration 97500, lr = 0.0025
I0522 00:45:38.404417 18599 solver.cpp:237] Iteration 98250, loss = 1.10098
I0522 00:45:38.404453 18599 solver.cpp:253]     Train net output #0: loss = 1.10098 (* 1 = 1.10098 loss)
I0522 00:45:38.404469 18599 sgd_solver.cpp:106] Iteration 98250, lr = 0.0025
I0522 00:45:50.561920 18599 solver.cpp:237] Iteration 99000, loss = 1.03379
I0522 00:45:50.561966 18599 solver.cpp:253]     Train net output #0: loss = 1.03379 (* 1 = 1.03379 loss)
I0522 00:45:50.561980 18599 sgd_solver.cpp:106] Iteration 99000, lr = 0.0025
I0522 00:46:02.721104 18599 solver.cpp:237] Iteration 99750, loss = 1.26596
I0522 00:46:02.721278 18599 solver.cpp:253]     Train net output #0: loss = 1.26596 (* 1 = 1.26596 loss)
I0522 00:46:02.721292 18599 sgd_solver.cpp:106] Iteration 99750, lr = 0.0025
I0522 00:46:35.743547 18599 solver.cpp:237] Iteration 100500, loss = 0.888481
I0522 00:46:35.743732 18599 solver.cpp:253]     Train net output #0: loss = 0.888479 (* 1 = 0.888479 loss)
I0522 00:46:35.743747 18599 sgd_solver.cpp:106] Iteration 100500, lr = 0.0025
I0522 00:46:47.912612 18599 solver.cpp:237] Iteration 101250, loss = 1.07404
I0522 00:46:47.912662 18599 solver.cpp:253]     Train net output #0: loss = 1.07404 (* 1 = 1.07404 loss)
I0522 00:46:47.912678 18599 sgd_solver.cpp:106] Iteration 101250, lr = 0.0025
I0522 00:47:00.077886 18599 solver.cpp:237] Iteration 102000, loss = 1.29045
I0522 00:47:00.077922 18599 solver.cpp:253]     Train net output #0: loss = 1.29045 (* 1 = 1.29045 loss)
I0522 00:47:00.077939 18599 sgd_solver.cpp:106] Iteration 102000, lr = 0.0025
I0522 00:47:12.221436 18599 solver.cpp:237] Iteration 102750, loss = 1.09537
I0522 00:47:12.221603 18599 solver.cpp:253]     Train net output #0: loss = 1.09537 (* 1 = 1.09537 loss)
I0522 00:47:12.221618 18599 sgd_solver.cpp:106] Iteration 102750, lr = 0.0025
I0522 00:47:24.339717 18599 solver.cpp:237] Iteration 103500, loss = 1.08343
I0522 00:47:24.339752 18599 solver.cpp:253]     Train net output #0: loss = 1.08343 (* 1 = 1.08343 loss)
I0522 00:47:24.339769 18599 sgd_solver.cpp:106] Iteration 103500, lr = 0.0025
I0522 00:47:36.456338 18599 solver.cpp:237] Iteration 104250, loss = 1.13661
I0522 00:47:36.456387 18599 solver.cpp:253]     Train net output #0: loss = 1.13661 (* 1 = 1.13661 loss)
I0522 00:47:36.456403 18599 sgd_solver.cpp:106] Iteration 104250, lr = 0.0025
I0522 00:47:48.593137 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_105000.caffemodel
I0522 00:47:48.642344 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_105000.solverstate
I0522 00:47:48.667820 18599 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 00:48:40.267482 18599 solver.cpp:409]     Test net output #0: accuracy = 0.88613
I0522 00:48:40.267657 18599 solver.cpp:409]     Test net output #1: loss = 0.366918 (* 1 = 0.366918 loss)
I0522 00:49:01.127862 18599 solver.cpp:237] Iteration 105000, loss = 0.958321
I0522 00:49:01.127923 18599 solver.cpp:253]     Train net output #0: loss = 0.958319 (* 1 = 0.958319 loss)
I0522 00:49:01.127938 18599 sgd_solver.cpp:106] Iteration 105000, lr = 0.0025
I0522 00:49:13.264730 18599 solver.cpp:237] Iteration 105750, loss = 0.87081
I0522 00:49:13.264909 18599 solver.cpp:253]     Train net output #0: loss = 0.870808 (* 1 = 0.870808 loss)
I0522 00:49:13.264925 18599 sgd_solver.cpp:106] Iteration 105750, lr = 0.0025
I0522 00:49:25.424361 18599 solver.cpp:237] Iteration 106500, loss = 1.06362
I0522 00:49:25.424397 18599 solver.cpp:253]     Train net output #0: loss = 1.06362 (* 1 = 1.06362 loss)
I0522 00:49:25.424412 18599 sgd_solver.cpp:106] Iteration 106500, lr = 0.0025
I0522 00:49:37.569649 18599 solver.cpp:237] Iteration 107250, loss = 1.07986
I0522 00:49:37.569703 18599 solver.cpp:253]     Train net output #0: loss = 1.07986 (* 1 = 1.07986 loss)
I0522 00:49:37.569718 18599 sgd_solver.cpp:106] Iteration 107250, lr = 0.0025
I0522 00:49:49.696844 18599 solver.cpp:237] Iteration 108000, loss = 1.20137
I0522 00:49:49.697023 18599 solver.cpp:253]     Train net output #0: loss = 1.20137 (* 1 = 1.20137 loss)
I0522 00:49:49.697038 18599 sgd_solver.cpp:106] Iteration 108000, lr = 0.0025
I0522 00:50:01.802434 18599 solver.cpp:237] Iteration 108750, loss = 1.12158
I0522 00:50:01.802489 18599 solver.cpp:253]     Train net output #0: loss = 1.12158 (* 1 = 1.12158 loss)
I0522 00:50:01.802502 18599 sgd_solver.cpp:106] Iteration 108750, lr = 0.0025
I0522 00:50:13.866720 18599 solver.cpp:237] Iteration 109500, loss = 1.26706
I0522 00:50:13.866756 18599 solver.cpp:253]     Train net output #0: loss = 1.26706 (* 1 = 1.26706 loss)
I0522 00:50:13.866772 18599 sgd_solver.cpp:106] Iteration 109500, lr = 0.0025
I0522 00:50:46.828788 18599 solver.cpp:237] Iteration 110250, loss = 1.3105
I0522 00:50:46.828976 18599 solver.cpp:253]     Train net output #0: loss = 1.3105 (* 1 = 1.3105 loss)
I0522 00:50:46.828992 18599 sgd_solver.cpp:106] Iteration 110250, lr = 0.0025
I0522 00:50:58.907455 18599 solver.cpp:237] Iteration 111000, loss = 0.946049
I0522 00:50:58.907505 18599 solver.cpp:253]     Train net output #0: loss = 0.946047 (* 1 = 0.946047 loss)
I0522 00:50:58.907521 18599 sgd_solver.cpp:106] Iteration 111000, lr = 0.0025
I0522 00:51:10.990836 18599 solver.cpp:237] Iteration 111750, loss = 0.804537
I0522 00:51:10.990874 18599 solver.cpp:253]     Train net output #0: loss = 0.804534 (* 1 = 0.804534 loss)
I0522 00:51:10.990890 18599 sgd_solver.cpp:106] Iteration 111750, lr = 0.0025
I0522 00:51:23.119608 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_112500.caffemodel
I0522 00:51:23.170379 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_112500.solverstate
I0522 00:51:23.202536 18599 solver.cpp:237] Iteration 112500, loss = 1.36963
I0522 00:51:23.202590 18599 solver.cpp:253]     Train net output #0: loss = 1.36963 (* 1 = 1.36963 loss)
I0522 00:51:23.202605 18599 sgd_solver.cpp:106] Iteration 112500, lr = 0.0025
I0522 00:51:35.288990 18599 solver.cpp:237] Iteration 113250, loss = 1.2926
I0522 00:51:35.289026 18599 solver.cpp:253]     Train net output #0: loss = 1.2926 (* 1 = 1.2926 loss)
I0522 00:51:35.289042 18599 sgd_solver.cpp:106] Iteration 113250, lr = 0.0025
I0522 00:51:47.374423 18599 solver.cpp:237] Iteration 114000, loss = 1.23865
I0522 00:51:47.374480 18599 solver.cpp:253]     Train net output #0: loss = 1.23864 (* 1 = 1.23864 loss)
I0522 00:51:47.374495 18599 sgd_solver.cpp:106] Iteration 114000, lr = 0.0025
I0522 00:51:59.468164 18599 solver.cpp:237] Iteration 114750, loss = 1.11788
I0522 00:51:59.468323 18599 solver.cpp:253]     Train net output #0: loss = 1.11787 (* 1 = 1.11787 loss)
I0522 00:51:59.468338 18599 sgd_solver.cpp:106] Iteration 114750, lr = 0.0025
I0522 00:52:32.432351 18599 solver.cpp:237] Iteration 115500, loss = 1.40462
I0522 00:52:32.432530 18599 solver.cpp:253]     Train net output #0: loss = 1.40462 (* 1 = 1.40462 loss)
I0522 00:52:32.432545 18599 sgd_solver.cpp:106] Iteration 115500, lr = 0.0025
I0522 00:52:44.514695 18599 solver.cpp:237] Iteration 116250, loss = 0.963025
I0522 00:52:44.514732 18599 solver.cpp:253]     Train net output #0: loss = 0.963023 (* 1 = 0.963023 loss)
I0522 00:52:44.514749 18599 sgd_solver.cpp:106] Iteration 116250, lr = 0.0025
I0522 00:52:56.590729 18599 solver.cpp:237] Iteration 117000, loss = 1.20758
I0522 00:52:56.590785 18599 solver.cpp:253]     Train net output #0: loss = 1.20758 (* 1 = 1.20758 loss)
I0522 00:52:56.590801 18599 sgd_solver.cpp:106] Iteration 117000, lr = 0.0025
I0522 00:53:08.670328 18599 solver.cpp:237] Iteration 117750, loss = 0.886388
I0522 00:53:08.670485 18599 solver.cpp:253]     Train net output #0: loss = 0.886385 (* 1 = 0.886385 loss)
I0522 00:53:08.670500 18599 sgd_solver.cpp:106] Iteration 117750, lr = 0.0025
I0522 00:53:20.757072 18599 solver.cpp:237] Iteration 118500, loss = 1.01321
I0522 00:53:20.757122 18599 solver.cpp:253]     Train net output #0: loss = 1.01321 (* 1 = 1.01321 loss)
I0522 00:53:20.757138 18599 sgd_solver.cpp:106] Iteration 118500, lr = 0.0025
I0522 00:53:32.907989 18599 solver.cpp:237] Iteration 119250, loss = 1.12856
I0522 00:53:32.908025 18599 solver.cpp:253]     Train net output #0: loss = 1.12856 (* 1 = 1.12856 loss)
I0522 00:53:32.908041 18599 sgd_solver.cpp:106] Iteration 119250, lr = 0.0025
I0522 00:53:45.044301 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_120000.caffemodel
I0522 00:53:45.094576 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_120000.solverstate
I0522 00:53:45.120507 18599 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 00:54:57.970826 18599 solver.cpp:409]     Test net output #0: accuracy = 0.894023
I0522 00:54:57.971009 18599 solver.cpp:409]     Test net output #1: loss = 0.350979 (* 1 = 0.350979 loss)
I0522 00:55:18.865942 18599 solver.cpp:237] Iteration 120000, loss = 1.21239
I0522 00:55:18.866000 18599 solver.cpp:253]     Train net output #0: loss = 1.21239 (* 1 = 1.21239 loss)
I0522 00:55:18.866015 18599 sgd_solver.cpp:106] Iteration 120000, lr = 0.0025
I0522 00:55:31.027403 18599 solver.cpp:237] Iteration 120750, loss = 1.197
I0522 00:55:31.027593 18599 solver.cpp:253]     Train net output #0: loss = 1.197 (* 1 = 1.197 loss)
I0522 00:55:31.027609 18599 sgd_solver.cpp:106] Iteration 120750, lr = 0.0025
I0522 00:55:43.200227 18599 solver.cpp:237] Iteration 121500, loss = 0.993352
I0522 00:55:43.200263 18599 solver.cpp:253]     Train net output #0: loss = 0.993349 (* 1 = 0.993349 loss)
I0522 00:55:43.200279 18599 sgd_solver.cpp:106] Iteration 121500, lr = 0.0025
I0522 00:55:55.300592 18599 solver.cpp:237] Iteration 122250, loss = 1.32028
I0522 00:55:55.300647 18599 solver.cpp:253]     Train net output #0: loss = 1.32028 (* 1 = 1.32028 loss)
I0522 00:55:55.300660 18599 sgd_solver.cpp:106] Iteration 122250, lr = 0.0025
I0522 00:56:07.373631 18599 solver.cpp:237] Iteration 123000, loss = 1.05607
I0522 00:56:07.373785 18599 solver.cpp:253]     Train net output #0: loss = 1.05607 (* 1 = 1.05607 loss)
I0522 00:56:07.373800 18599 sgd_solver.cpp:106] Iteration 123000, lr = 0.0025
I0522 00:56:19.439813 18599 solver.cpp:237] Iteration 123750, loss = 1.25323
I0522 00:56:19.439867 18599 solver.cpp:253]     Train net output #0: loss = 1.25323 (* 1 = 1.25323 loss)
I0522 00:56:19.439882 18599 sgd_solver.cpp:106] Iteration 123750, lr = 0.0025
I0522 00:56:31.515435 18599 solver.cpp:237] Iteration 124500, loss = 0.898589
I0522 00:56:31.515471 18599 solver.cpp:253]     Train net output #0: loss = 0.898586 (* 1 = 0.898586 loss)
I0522 00:56:31.515489 18599 sgd_solver.cpp:106] Iteration 124500, lr = 0.0025
I0522 00:57:04.461673 18599 solver.cpp:237] Iteration 125250, loss = 0.903193
I0522 00:57:04.461854 18599 solver.cpp:253]     Train net output #0: loss = 0.90319 (* 1 = 0.90319 loss)
I0522 00:57:04.461869 18599 sgd_solver.cpp:106] Iteration 125250, lr = 0.0025
I0522 00:57:16.612751 18599 solver.cpp:237] Iteration 126000, loss = 1.25566
I0522 00:57:16.612788 18599 solver.cpp:253]     Train net output #0: loss = 1.25566 (* 1 = 1.25566 loss)
I0522 00:57:16.612805 18599 sgd_solver.cpp:106] Iteration 126000, lr = 0.0025
I0522 00:57:28.776329 18599 solver.cpp:237] Iteration 126750, loss = 1.1972
I0522 00:57:28.776379 18599 solver.cpp:253]     Train net output #0: loss = 1.1972 (* 1 = 1.1972 loss)
I0522 00:57:28.776399 18599 sgd_solver.cpp:106] Iteration 126750, lr = 0.0025
I0522 00:57:40.908138 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_127500.caffemodel
I0522 00:57:40.958106 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_127500.solverstate
I0522 00:57:40.989097 18599 solver.cpp:237] Iteration 127500, loss = 0.847906
I0522 00:57:40.989150 18599 solver.cpp:253]     Train net output #0: loss = 0.847903 (* 1 = 0.847903 loss)
I0522 00:57:40.989164 18599 sgd_solver.cpp:106] Iteration 127500, lr = 0.0025
I0522 00:57:53.115123 18599 solver.cpp:237] Iteration 128250, loss = 1.33169
I0522 00:57:53.115160 18599 solver.cpp:253]     Train net output #0: loss = 1.33169 (* 1 = 1.33169 loss)
I0522 00:57:53.115176 18599 sgd_solver.cpp:106] Iteration 128250, lr = 0.0025
I0522 00:58:05.305819 18599 solver.cpp:237] Iteration 129000, loss = 1.20876
I0522 00:58:05.305868 18599 solver.cpp:253]     Train net output #0: loss = 1.20875 (* 1 = 1.20875 loss)
I0522 00:58:05.305883 18599 sgd_solver.cpp:106] Iteration 129000, lr = 0.0025
I0522 00:58:17.473140 18599 solver.cpp:237] Iteration 129750, loss = 0.96675
I0522 00:58:17.473299 18599 solver.cpp:253]     Train net output #0: loss = 0.966748 (* 1 = 0.966748 loss)
I0522 00:58:17.473312 18599 sgd_solver.cpp:106] Iteration 129750, lr = 0.0025
I0522 00:58:50.489524 18599 solver.cpp:237] Iteration 130500, loss = 1.08948
I0522 00:58:50.489706 18599 solver.cpp:253]     Train net output #0: loss = 1.08948 (* 1 = 1.08948 loss)
I0522 00:58:50.489722 18599 sgd_solver.cpp:106] Iteration 130500, lr = 0.0025
I0522 00:59:02.588714 18599 solver.cpp:237] Iteration 131250, loss = 1.54144
I0522 00:59:02.588752 18599 solver.cpp:253]     Train net output #0: loss = 1.54143 (* 1 = 1.54143 loss)
I0522 00:59:02.588768 18599 sgd_solver.cpp:106] Iteration 131250, lr = 0.0025
I0522 00:59:14.715221 18599 solver.cpp:237] Iteration 132000, loss = 0.968549
I0522 00:59:14.715275 18599 solver.cpp:253]     Train net output #0: loss = 0.968547 (* 1 = 0.968547 loss)
I0522 00:59:14.715288 18599 sgd_solver.cpp:106] Iteration 132000, lr = 0.0025
I0522 00:59:26.812396 18599 solver.cpp:237] Iteration 132750, loss = 1.0577
I0522 00:59:26.812552 18599 solver.cpp:253]     Train net output #0: loss = 1.0577 (* 1 = 1.0577 loss)
I0522 00:59:26.812567 18599 sgd_solver.cpp:106] Iteration 132750, lr = 0.0025
I0522 00:59:38.923001 18599 solver.cpp:237] Iteration 133500, loss = 0.792105
I0522 00:59:38.923059 18599 solver.cpp:253]     Train net output #0: loss = 0.792103 (* 1 = 0.792103 loss)
I0522 00:59:38.923074 18599 sgd_solver.cpp:106] Iteration 133500, lr = 0.0025
I0522 00:59:51.051667 18599 solver.cpp:237] Iteration 134250, loss = 1.84753
I0522 00:59:51.051704 18599 solver.cpp:253]     Train net output #0: loss = 1.84753 (* 1 = 1.84753 loss)
I0522 00:59:51.051720 18599 sgd_solver.cpp:106] Iteration 134250, lr = 0.0025
I0522 01:00:03.168663 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_135000.caffemodel
I0522 01:00:03.217895 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_135000.solverstate
I0522 01:00:03.243083 18599 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 01:00:55.164551 18599 solver.cpp:409]     Test net output #0: accuracy = 0.894219
I0522 01:00:55.164728 18599 solver.cpp:409]     Test net output #1: loss = 0.332159 (* 1 = 0.332159 loss)
I0522 01:01:16.052083 18599 solver.cpp:237] Iteration 135000, loss = 1.11055
I0522 01:01:16.052140 18599 solver.cpp:253]     Train net output #0: loss = 1.11054 (* 1 = 1.11054 loss)
I0522 01:01:16.052155 18599 sgd_solver.cpp:106] Iteration 135000, lr = 0.0025
I0522 01:01:28.200839 18599 solver.cpp:237] Iteration 135750, loss = 1.1068
I0522 01:01:28.201006 18599 solver.cpp:253]     Train net output #0: loss = 1.1068 (* 1 = 1.1068 loss)
I0522 01:01:28.201021 18599 sgd_solver.cpp:106] Iteration 135750, lr = 0.0025
I0522 01:01:40.342874 18599 solver.cpp:237] Iteration 136500, loss = 1.06809
I0522 01:01:40.342923 18599 solver.cpp:253]     Train net output #0: loss = 1.06809 (* 1 = 1.06809 loss)
I0522 01:01:40.342938 18599 sgd_solver.cpp:106] Iteration 136500, lr = 0.0025
I0522 01:01:52.490525 18599 solver.cpp:237] Iteration 137250, loss = 1.05507
I0522 01:01:52.490561 18599 solver.cpp:253]     Train net output #0: loss = 1.05507 (* 1 = 1.05507 loss)
I0522 01:01:52.490577 18599 sgd_solver.cpp:106] Iteration 137250, lr = 0.0025
I0522 01:02:04.638370 18599 solver.cpp:237] Iteration 138000, loss = 1.01479
I0522 01:02:04.638550 18599 solver.cpp:253]     Train net output #0: loss = 1.01479 (* 1 = 1.01479 loss)
I0522 01:02:04.638563 18599 sgd_solver.cpp:106] Iteration 138000, lr = 0.0025
I0522 01:02:16.703272 18599 solver.cpp:237] Iteration 138750, loss = 1.12159
I0522 01:02:16.703308 18599 solver.cpp:253]     Train net output #0: loss = 1.12159 (* 1 = 1.12159 loss)
I0522 01:02:16.703326 18599 sgd_solver.cpp:106] Iteration 138750, lr = 0.0025
I0522 01:02:28.770661 18599 solver.cpp:237] Iteration 139500, loss = 0.91741
I0522 01:02:28.770711 18599 solver.cpp:253]     Train net output #0: loss = 0.917407 (* 1 = 0.917407 loss)
I0522 01:02:28.770725 18599 sgd_solver.cpp:106] Iteration 139500, lr = 0.0025
I0522 01:03:01.748334 18599 solver.cpp:237] Iteration 140250, loss = 1.30629
I0522 01:03:01.748520 18599 solver.cpp:253]     Train net output #0: loss = 1.30629 (* 1 = 1.30629 loss)
I0522 01:03:01.748535 18599 sgd_solver.cpp:106] Iteration 140250, lr = 0.0025
I0522 01:03:13.840574 18599 solver.cpp:237] Iteration 141000, loss = 1.55356
I0522 01:03:13.840610 18599 solver.cpp:253]     Train net output #0: loss = 1.55356 (* 1 = 1.55356 loss)
I0522 01:03:13.840625 18599 sgd_solver.cpp:106] Iteration 141000, lr = 0.0025
I0522 01:03:25.938487 18599 solver.cpp:237] Iteration 141750, loss = 1.11783
I0522 01:03:25.938531 18599 solver.cpp:253]     Train net output #0: loss = 1.11783 (* 1 = 1.11783 loss)
I0522 01:03:25.938546 18599 sgd_solver.cpp:106] Iteration 141750, lr = 0.0025
I0522 01:03:38.029681 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_142500.caffemodel
I0522 01:03:38.082547 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_142500.solverstate
I0522 01:03:38.114547 18599 solver.cpp:237] Iteration 142500, loss = 1.61018
I0522 01:03:38.114600 18599 solver.cpp:253]     Train net output #0: loss = 1.61018 (* 1 = 1.61018 loss)
I0522 01:03:38.114615 18599 sgd_solver.cpp:106] Iteration 142500, lr = 0.0025
I0522 01:03:50.203253 18599 solver.cpp:237] Iteration 143250, loss = 1.22506
I0522 01:03:50.203305 18599 solver.cpp:253]     Train net output #0: loss = 1.22506 (* 1 = 1.22506 loss)
I0522 01:03:50.203320 18599 sgd_solver.cpp:106] Iteration 143250, lr = 0.0025
I0522 01:04:02.300463 18599 solver.cpp:237] Iteration 144000, loss = 1.87057
I0522 01:04:02.300498 18599 solver.cpp:253]     Train net output #0: loss = 1.87057 (* 1 = 1.87057 loss)
I0522 01:04:02.300514 18599 sgd_solver.cpp:106] Iteration 144000, lr = 0.0025
I0522 01:04:14.461412 18599 solver.cpp:237] Iteration 144750, loss = 1.06602
I0522 01:04:14.461591 18599 solver.cpp:253]     Train net output #0: loss = 1.06601 (* 1 = 1.06601 loss)
I0522 01:04:14.461607 18599 sgd_solver.cpp:106] Iteration 144750, lr = 0.0025
I0522 01:04:47.512442 18599 solver.cpp:237] Iteration 145500, loss = 1.11277
I0522 01:04:47.512629 18599 solver.cpp:253]     Train net output #0: loss = 1.11277 (* 1 = 1.11277 loss)
I0522 01:04:47.512644 18599 sgd_solver.cpp:106] Iteration 145500, lr = 0.0025
I0522 01:04:59.659638 18599 solver.cpp:237] Iteration 146250, loss = 0.970552
I0522 01:04:59.659688 18599 solver.cpp:253]     Train net output #0: loss = 0.970549 (* 1 = 0.970549 loss)
I0522 01:04:59.659703 18599 sgd_solver.cpp:106] Iteration 146250, lr = 0.0025
I0522 01:05:11.794607 18599 solver.cpp:237] Iteration 147000, loss = 1.03427
I0522 01:05:11.794643 18599 solver.cpp:253]     Train net output #0: loss = 1.03427 (* 1 = 1.03427 loss)
I0522 01:05:11.794661 18599 sgd_solver.cpp:106] Iteration 147000, lr = 0.0025
I0522 01:05:23.915542 18599 solver.cpp:237] Iteration 147750, loss = 1.22696
I0522 01:05:23.915735 18599 solver.cpp:253]     Train net output #0: loss = 1.22696 (* 1 = 1.22696 loss)
I0522 01:05:23.915748 18599 sgd_solver.cpp:106] Iteration 147750, lr = 0.0025
I0522 01:05:36.040177 18599 solver.cpp:237] Iteration 148500, loss = 1.5314
I0522 01:05:36.040213 18599 solver.cpp:253]     Train net output #0: loss = 1.5314 (* 1 = 1.5314 loss)
I0522 01:05:36.040230 18599 sgd_solver.cpp:106] Iteration 148500, lr = 0.0025
I0522 01:05:48.155288 18599 solver.cpp:237] Iteration 149250, loss = 1.52301
I0522 01:05:48.155324 18599 solver.cpp:253]     Train net output #0: loss = 1.52301 (* 1 = 1.52301 loss)
I0522 01:05:48.155338 18599 sgd_solver.cpp:106] Iteration 149250, lr = 0.0025
I0522 01:06:00.298257 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_150000.caffemodel
I0522 01:06:00.349498 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_150000.solverstate
I0522 01:06:00.376895 18599 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 01:07:13.328667 18599 solver.cpp:409]     Test net output #0: accuracy = 0.897406
I0522 01:07:13.328851 18599 solver.cpp:409]     Test net output #1: loss = 0.351305 (* 1 = 0.351305 loss)
I0522 01:07:34.224576 18599 solver.cpp:237] Iteration 150000, loss = 1.00535
I0522 01:07:34.224632 18599 solver.cpp:253]     Train net output #0: loss = 1.00535 (* 1 = 1.00535 loss)
I0522 01:07:34.224647 18599 sgd_solver.cpp:106] Iteration 150000, lr = 0.0025
I0522 01:07:46.326575 18599 solver.cpp:237] Iteration 150750, loss = 1.00198
I0522 01:07:46.326740 18599 solver.cpp:253]     Train net output #0: loss = 1.00198 (* 1 = 1.00198 loss)
I0522 01:07:46.326755 18599 sgd_solver.cpp:106] Iteration 150750, lr = 0.0025
I0522 01:07:58.421530 18599 solver.cpp:237] Iteration 151500, loss = 0.840164
I0522 01:07:58.421577 18599 solver.cpp:253]     Train net output #0: loss = 0.840162 (* 1 = 0.840162 loss)
I0522 01:07:58.421592 18599 sgd_solver.cpp:106] Iteration 151500, lr = 0.0025
I0522 01:08:10.520313 18599 solver.cpp:237] Iteration 152250, loss = 0.954851
I0522 01:08:10.520350 18599 solver.cpp:253]     Train net output #0: loss = 0.95485 (* 1 = 0.95485 loss)
I0522 01:08:10.520366 18599 sgd_solver.cpp:106] Iteration 152250, lr = 0.0025
I0522 01:08:22.710316 18599 solver.cpp:237] Iteration 153000, loss = 0.980883
I0522 01:08:22.710489 18599 solver.cpp:253]     Train net output #0: loss = 0.980881 (* 1 = 0.980881 loss)
I0522 01:08:22.710505 18599 sgd_solver.cpp:106] Iteration 153000, lr = 0.0025
I0522 01:08:34.873004 18599 solver.cpp:237] Iteration 153750, loss = 1.00771
I0522 01:08:34.873040 18599 solver.cpp:253]     Train net output #0: loss = 1.00771 (* 1 = 1.00771 loss)
I0522 01:08:34.873057 18599 sgd_solver.cpp:106] Iteration 153750, lr = 0.0025
I0522 01:08:47.018203 18599 solver.cpp:237] Iteration 154500, loss = 1.93234
I0522 01:08:47.018254 18599 solver.cpp:253]     Train net output #0: loss = 1.93234 (* 1 = 1.93234 loss)
I0522 01:08:47.018270 18599 sgd_solver.cpp:106] Iteration 154500, lr = 0.0025
I0522 01:09:20.083889 18599 solver.cpp:237] Iteration 155250, loss = 0.773235
I0522 01:09:20.084075 18599 solver.cpp:253]     Train net output #0: loss = 0.773233 (* 1 = 0.773233 loss)
I0522 01:09:20.084090 18599 sgd_solver.cpp:106] Iteration 155250, lr = 0.0025
I0522 01:09:32.206475 18599 solver.cpp:237] Iteration 156000, loss = 0.844912
I0522 01:09:32.206511 18599 solver.cpp:253]     Train net output #0: loss = 0.84491 (* 1 = 0.84491 loss)
I0522 01:09:32.206527 18599 sgd_solver.cpp:106] Iteration 156000, lr = 0.0025
I0522 01:09:44.333283 18599 solver.cpp:237] Iteration 156750, loss = 1.95495
I0522 01:09:44.333328 18599 solver.cpp:253]     Train net output #0: loss = 1.95494 (* 1 = 1.95494 loss)
I0522 01:09:44.333343 18599 sgd_solver.cpp:106] Iteration 156750, lr = 0.0025
I0522 01:09:56.476094 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_157500.caffemodel
I0522 01:09:56.526212 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_157500.solverstate
I0522 01:09:56.557188 18599 solver.cpp:237] Iteration 157500, loss = 1.15127
I0522 01:09:56.557238 18599 solver.cpp:253]     Train net output #0: loss = 1.15127 (* 1 = 1.15127 loss)
I0522 01:09:56.557255 18599 sgd_solver.cpp:106] Iteration 157500, lr = 0.0025
I0522 01:10:08.703642 18599 solver.cpp:237] Iteration 158250, loss = 1.75714
I0522 01:10:08.703692 18599 solver.cpp:253]     Train net output #0: loss = 1.75714 (* 1 = 1.75714 loss)
I0522 01:10:08.703706 18599 sgd_solver.cpp:106] Iteration 158250, lr = 0.0025
I0522 01:10:20.840796 18599 solver.cpp:237] Iteration 159000, loss = 0.888295
I0522 01:10:20.840833 18599 solver.cpp:253]     Train net output #0: loss = 0.888293 (* 1 = 0.888293 loss)
I0522 01:10:20.840848 18599 sgd_solver.cpp:106] Iteration 159000, lr = 0.0025
I0522 01:10:32.955629 18599 solver.cpp:237] Iteration 159750, loss = 0.771328
I0522 01:10:32.955809 18599 solver.cpp:253]     Train net output #0: loss = 0.771327 (* 1 = 0.771327 loss)
I0522 01:10:32.955824 18599 sgd_solver.cpp:106] Iteration 159750, lr = 0.0025
I0522 01:11:06.095247 18599 solver.cpp:237] Iteration 160500, loss = 1.10709
I0522 01:11:06.095432 18599 solver.cpp:253]     Train net output #0: loss = 1.10709 (* 1 = 1.10709 loss)
I0522 01:11:06.095448 18599 sgd_solver.cpp:106] Iteration 160500, lr = 0.0025
I0522 01:11:18.202503 18599 solver.cpp:237] Iteration 161250, loss = 1.19759
I0522 01:11:18.202550 18599 solver.cpp:253]     Train net output #0: loss = 1.19759 (* 1 = 1.19759 loss)
I0522 01:11:18.202566 18599 sgd_solver.cpp:106] Iteration 161250, lr = 0.0025
I0522 01:11:30.303833 18599 solver.cpp:237] Iteration 162000, loss = 1.15058
I0522 01:11:30.303869 18599 solver.cpp:253]     Train net output #0: loss = 1.15058 (* 1 = 1.15058 loss)
I0522 01:11:30.303886 18599 sgd_solver.cpp:106] Iteration 162000, lr = 0.0025
I0522 01:11:42.438870 18599 solver.cpp:237] Iteration 162750, loss = 0.737994
I0522 01:11:42.439040 18599 solver.cpp:253]     Train net output #0: loss = 0.737992 (* 1 = 0.737992 loss)
I0522 01:11:42.439056 18599 sgd_solver.cpp:106] Iteration 162750, lr = 0.0025
I0522 01:11:54.579632 18599 solver.cpp:237] Iteration 163500, loss = 1.57158
I0522 01:11:54.579668 18599 solver.cpp:253]     Train net output #0: loss = 1.57158 (* 1 = 1.57158 loss)
I0522 01:11:54.579684 18599 sgd_solver.cpp:106] Iteration 163500, lr = 0.0025
I0522 01:12:06.723206 18599 solver.cpp:237] Iteration 164250, loss = 1.27315
I0522 01:12:06.723249 18599 solver.cpp:253]     Train net output #0: loss = 1.27314 (* 1 = 1.27314 loss)
I0522 01:12:06.723268 18599 sgd_solver.cpp:106] Iteration 164250, lr = 0.0025
I0522 01:12:18.857092 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_165000.caffemodel
I0522 01:12:18.906035 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_165000.solverstate
I0522 01:12:18.931087 18599 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 01:13:10.629076 18599 solver.cpp:409]     Test net output #0: accuracy = 0.897537
I0522 01:13:10.629271 18599 solver.cpp:409]     Test net output #1: loss = 0.339217 (* 1 = 0.339217 loss)
I0522 01:13:31.514438 18599 solver.cpp:237] Iteration 165000, loss = 1.47104
I0522 01:13:31.514494 18599 solver.cpp:253]     Train net output #0: loss = 1.47104 (* 1 = 1.47104 loss)
I0522 01:13:31.514509 18599 sgd_solver.cpp:106] Iteration 165000, lr = 0.0025
I0522 01:13:43.689363 18599 solver.cpp:237] Iteration 165750, loss = 0.869002
I0522 01:13:43.689540 18599 solver.cpp:253]     Train net output #0: loss = 0.869 (* 1 = 0.869 loss)
I0522 01:13:43.689555 18599 sgd_solver.cpp:106] Iteration 165750, lr = 0.0025
I0522 01:13:55.826545 18599 solver.cpp:237] Iteration 166500, loss = 1.31969
I0522 01:13:55.826582 18599 solver.cpp:253]     Train net output #0: loss = 1.31969 (* 1 = 1.31969 loss)
I0522 01:13:55.826597 18599 sgd_solver.cpp:106] Iteration 166500, lr = 0.0025
I0522 01:14:08.045904 18599 solver.cpp:237] Iteration 167250, loss = 1.17735
I0522 01:14:08.045940 18599 solver.cpp:253]     Train net output #0: loss = 1.17735 (* 1 = 1.17735 loss)
I0522 01:14:08.045956 18599 sgd_solver.cpp:106] Iteration 167250, lr = 0.0025
I0522 01:14:20.285326 18599 solver.cpp:237] Iteration 168000, loss = 1.40233
I0522 01:14:20.285504 18599 solver.cpp:253]     Train net output #0: loss = 1.40233 (* 1 = 1.40233 loss)
I0522 01:14:20.285519 18599 sgd_solver.cpp:106] Iteration 168000, lr = 0.0025
I0522 01:14:32.525465 18599 solver.cpp:237] Iteration 168750, loss = 1.65999
I0522 01:14:32.525501 18599 solver.cpp:253]     Train net output #0: loss = 1.65999 (* 1 = 1.65999 loss)
I0522 01:14:32.525517 18599 sgd_solver.cpp:106] Iteration 168750, lr = 0.0025
I0522 01:14:44.765355 18599 solver.cpp:237] Iteration 169500, loss = 1.29021
I0522 01:14:44.765398 18599 solver.cpp:253]     Train net output #0: loss = 1.2902 (* 1 = 1.2902 loss)
I0522 01:14:44.765414 18599 sgd_solver.cpp:106] Iteration 169500, lr = 0.0025
I0522 01:15:17.879942 18599 solver.cpp:237] Iteration 170250, loss = 1.31482
I0522 01:15:17.880131 18599 solver.cpp:253]     Train net output #0: loss = 1.31481 (* 1 = 1.31481 loss)
I0522 01:15:17.880146 18599 sgd_solver.cpp:106] Iteration 170250, lr = 0.0025
I0522 01:15:30.115819 18599 solver.cpp:237] Iteration 171000, loss = 1.04832
I0522 01:15:30.115872 18599 solver.cpp:253]     Train net output #0: loss = 1.04831 (* 1 = 1.04831 loss)
I0522 01:15:30.115887 18599 sgd_solver.cpp:106] Iteration 171000, lr = 0.0025
I0522 01:15:42.318570 18599 solver.cpp:237] Iteration 171750, loss = 1.33879
I0522 01:15:42.318606 18599 solver.cpp:253]     Train net output #0: loss = 1.33879 (* 1 = 1.33879 loss)
I0522 01:15:42.318624 18599 sgd_solver.cpp:106] Iteration 171750, lr = 0.0025
I0522 01:15:54.500474 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_172500.caffemodel
I0522 01:15:54.549628 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_172500.solverstate
I0522 01:15:54.579430 18599 solver.cpp:237] Iteration 172500, loss = 1.10148
I0522 01:15:54.579479 18599 solver.cpp:253]     Train net output #0: loss = 1.10148 (* 1 = 1.10148 loss)
I0522 01:15:54.579493 18599 sgd_solver.cpp:106] Iteration 172500, lr = 0.0025
I0522 01:16:06.803968 18599 solver.cpp:237] Iteration 173250, loss = 1.24417
I0522 01:16:06.804005 18599 solver.cpp:253]     Train net output #0: loss = 1.24417 (* 1 = 1.24417 loss)
I0522 01:16:06.804020 18599 sgd_solver.cpp:106] Iteration 173250, lr = 0.0025
I0522 01:16:19.010727 18599 solver.cpp:237] Iteration 174000, loss = 1.02182
I0522 01:16:19.010778 18599 solver.cpp:253]     Train net output #0: loss = 1.02182 (* 1 = 1.02182 loss)
I0522 01:16:19.010793 18599 sgd_solver.cpp:106] Iteration 174000, lr = 0.0025
I0522 01:16:31.227720 18599 solver.cpp:237] Iteration 174750, loss = 1.23547
I0522 01:16:31.227882 18599 solver.cpp:253]     Train net output #0: loss = 1.23546 (* 1 = 1.23546 loss)
I0522 01:16:31.227896 18599 sgd_solver.cpp:106] Iteration 174750, lr = 0.0025
I0522 01:17:04.328706 18599 solver.cpp:237] Iteration 175500, loss = 0.930027
I0522 01:17:04.328908 18599 solver.cpp:253]     Train net output #0: loss = 0.930025 (* 1 = 0.930025 loss)
I0522 01:17:04.328922 18599 sgd_solver.cpp:106] Iteration 175500, lr = 0.0025
I0522 01:17:16.531834 18599 solver.cpp:237] Iteration 176250, loss = 1.51715
I0522 01:17:16.531870 18599 solver.cpp:253]     Train net output #0: loss = 1.51715 (* 1 = 1.51715 loss)
I0522 01:17:16.531884 18599 sgd_solver.cpp:106] Iteration 176250, lr = 0.0025
I0522 01:17:28.721256 18599 solver.cpp:237] Iteration 177000, loss = 1.34139
I0522 01:17:28.721300 18599 solver.cpp:253]     Train net output #0: loss = 1.34138 (* 1 = 1.34138 loss)
I0522 01:17:28.721323 18599 sgd_solver.cpp:106] Iteration 177000, lr = 0.0025
I0522 01:17:40.904713 18599 solver.cpp:237] Iteration 177750, loss = 0.952437
I0522 01:17:40.904881 18599 solver.cpp:253]     Train net output #0: loss = 0.952436 (* 1 = 0.952436 loss)
I0522 01:17:40.904896 18599 sgd_solver.cpp:106] Iteration 177750, lr = 0.0025
I0522 01:17:53.152864 18599 solver.cpp:237] Iteration 178500, loss = 1.04419
I0522 01:17:53.152905 18599 solver.cpp:253]     Train net output #0: loss = 1.04419 (* 1 = 1.04419 loss)
I0522 01:17:53.152921 18599 sgd_solver.cpp:106] Iteration 178500, lr = 0.0025
I0522 01:18:05.435395 18599 solver.cpp:237] Iteration 179250, loss = 0.837398
I0522 01:18:05.435436 18599 solver.cpp:253]     Train net output #0: loss = 0.837396 (* 1 = 0.837396 loss)
I0522 01:18:05.435449 18599 sgd_solver.cpp:106] Iteration 179250, lr = 0.0025
I0522 01:18:17.642642 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_180000.caffemodel
I0522 01:18:17.691329 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_180000.solverstate
I0522 01:18:17.717149 18599 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 01:19:30.634985 18599 solver.cpp:409]     Test net output #0: accuracy = 0.894796
I0522 01:19:30.635170 18599 solver.cpp:409]     Test net output #1: loss = 0.337292 (* 1 = 0.337292 loss)
I0522 01:19:51.536146 18599 solver.cpp:237] Iteration 180000, loss = 1.06218
I0522 01:19:51.536206 18599 solver.cpp:253]     Train net output #0: loss = 1.06218 (* 1 = 1.06218 loss)
I0522 01:19:51.536222 18599 sgd_solver.cpp:106] Iteration 180000, lr = 0.0025
I0522 01:20:03.673516 18599 solver.cpp:237] Iteration 180750, loss = 1.04784
I0522 01:20:03.673692 18599 solver.cpp:253]     Train net output #0: loss = 1.04784 (* 1 = 1.04784 loss)
I0522 01:20:03.673707 18599 sgd_solver.cpp:106] Iteration 180750, lr = 0.0025
I0522 01:20:15.787106 18599 solver.cpp:237] Iteration 181500, loss = 0.84518
I0522 01:20:15.787142 18599 solver.cpp:253]     Train net output #0: loss = 0.845179 (* 1 = 0.845179 loss)
I0522 01:20:15.787158 18599 sgd_solver.cpp:106] Iteration 181500, lr = 0.0025
I0522 01:20:27.880832 18599 solver.cpp:237] Iteration 182250, loss = 1.05569
I0522 01:20:27.880895 18599 solver.cpp:253]     Train net output #0: loss = 1.05569 (* 1 = 1.05569 loss)
I0522 01:20:27.880911 18599 sgd_solver.cpp:106] Iteration 182250, lr = 0.0025
I0522 01:20:39.952762 18599 solver.cpp:237] Iteration 183000, loss = 0.767349
I0522 01:20:39.952935 18599 solver.cpp:253]     Train net output #0: loss = 0.767348 (* 1 = 0.767348 loss)
I0522 01:20:39.952950 18599 sgd_solver.cpp:106] Iteration 183000, lr = 0.0025
I0522 01:20:52.023181 18599 solver.cpp:237] Iteration 183750, loss = 1.0438
I0522 01:20:52.023233 18599 solver.cpp:253]     Train net output #0: loss = 1.0438 (* 1 = 1.0438 loss)
I0522 01:20:52.023247 18599 sgd_solver.cpp:106] Iteration 183750, lr = 0.0025
I0522 01:21:04.114471 18599 solver.cpp:237] Iteration 184500, loss = 1.29331
I0522 01:21:04.114507 18599 solver.cpp:253]     Train net output #0: loss = 1.29331 (* 1 = 1.29331 loss)
I0522 01:21:04.114524 18599 sgd_solver.cpp:106] Iteration 184500, lr = 0.0025
I0522 01:21:37.082378 18599 solver.cpp:237] Iteration 185250, loss = 1.82508
I0522 01:21:37.082577 18599 solver.cpp:253]     Train net output #0: loss = 1.82508 (* 1 = 1.82508 loss)
I0522 01:21:37.082592 18599 sgd_solver.cpp:106] Iteration 185250, lr = 0.0025
I0522 01:21:49.218220 18599 solver.cpp:237] Iteration 186000, loss = 1.21849
I0522 01:21:49.218269 18599 solver.cpp:253]     Train net output #0: loss = 1.21849 (* 1 = 1.21849 loss)
I0522 01:21:49.218282 18599 sgd_solver.cpp:106] Iteration 186000, lr = 0.0025
I0522 01:22:01.301923 18599 solver.cpp:237] Iteration 186750, loss = 1.12787
I0522 01:22:01.301959 18599 solver.cpp:253]     Train net output #0: loss = 1.12787 (* 1 = 1.12787 loss)
I0522 01:22:01.301975 18599 sgd_solver.cpp:106] Iteration 186750, lr = 0.0025
I0522 01:22:13.406967 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_187500.caffemodel
I0522 01:22:13.457305 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_187500.solverstate
I0522 01:22:13.488723 18599 solver.cpp:237] Iteration 187500, loss = 1.53189
I0522 01:22:13.488775 18599 solver.cpp:253]     Train net output #0: loss = 1.53189 (* 1 = 1.53189 loss)
I0522 01:22:13.488790 18599 sgd_solver.cpp:106] Iteration 187500, lr = 0.0025
I0522 01:22:25.613764 18599 solver.cpp:237] Iteration 188250, loss = 0.968202
I0522 01:22:25.613801 18599 solver.cpp:253]     Train net output #0: loss = 0.968201 (* 1 = 0.968201 loss)
I0522 01:22:25.613814 18599 sgd_solver.cpp:106] Iteration 188250, lr = 0.0025
I0522 01:22:37.704155 18599 solver.cpp:237] Iteration 189000, loss = 1.32492
I0522 01:22:37.704211 18599 solver.cpp:253]     Train net output #0: loss = 1.32492 (* 1 = 1.32492 loss)
I0522 01:22:37.704226 18599 sgd_solver.cpp:106] Iteration 189000, lr = 0.0025
I0522 01:22:49.836958 18599 solver.cpp:237] Iteration 189750, loss = 0.96992
I0522 01:22:49.837126 18599 solver.cpp:253]     Train net output #0: loss = 0.969918 (* 1 = 0.969918 loss)
I0522 01:22:49.837141 18599 sgd_solver.cpp:106] Iteration 189750, lr = 0.0025
I0522 01:23:22.871356 18599 solver.cpp:237] Iteration 190500, loss = 0.975976
I0522 01:23:22.871546 18599 solver.cpp:253]     Train net output #0: loss = 0.975974 (* 1 = 0.975974 loss)
I0522 01:23:22.871561 18599 sgd_solver.cpp:106] Iteration 190500, lr = 0.0025
I0522 01:23:34.991511 18599 solver.cpp:237] Iteration 191250, loss = 0.935165
I0522 01:23:34.991549 18599 solver.cpp:253]     Train net output #0: loss = 0.935163 (* 1 = 0.935163 loss)
I0522 01:23:34.991561 18599 sgd_solver.cpp:106] Iteration 191250, lr = 0.0025
I0522 01:23:47.141669 18599 solver.cpp:237] Iteration 192000, loss = 1.39279
I0522 01:23:47.141721 18599 solver.cpp:253]     Train net output #0: loss = 1.39279 (* 1 = 1.39279 loss)
I0522 01:23:47.141736 18599 sgd_solver.cpp:106] Iteration 192000, lr = 0.0025
I0522 01:23:59.314801 18599 solver.cpp:237] Iteration 192750, loss = 1.0503
I0522 01:23:59.314963 18599 solver.cpp:253]     Train net output #0: loss = 1.0503 (* 1 = 1.0503 loss)
I0522 01:23:59.314978 18599 sgd_solver.cpp:106] Iteration 192750, lr = 0.0025
I0522 01:24:11.459395 18599 solver.cpp:237] Iteration 193500, loss = 0.952229
I0522 01:24:11.459450 18599 solver.cpp:253]     Train net output #0: loss = 0.952227 (* 1 = 0.952227 loss)
I0522 01:24:11.459465 18599 sgd_solver.cpp:106] Iteration 193500, lr = 0.0025
I0522 01:24:23.625097 18599 solver.cpp:237] Iteration 194250, loss = 1.06484
I0522 01:24:23.625133 18599 solver.cpp:253]     Train net output #0: loss = 1.06484 (* 1 = 1.06484 loss)
I0522 01:24:23.625149 18599 sgd_solver.cpp:106] Iteration 194250, lr = 0.0025
I0522 01:24:35.736255 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_195000.caffemodel
I0522 01:24:35.785094 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_195000.solverstate
I0522 01:24:35.809907 18599 solver.cpp:341] Iteration 195000, Testing net (#0)
I0522 01:25:27.819898 18599 solver.cpp:409]     Test net output #0: accuracy = 0.897436
I0522 01:25:27.820086 18599 solver.cpp:409]     Test net output #1: loss = 0.332676 (* 1 = 0.332676 loss)
I0522 01:25:48.706398 18599 solver.cpp:237] Iteration 195000, loss = 0.802485
I0522 01:25:48.706455 18599 solver.cpp:253]     Train net output #0: loss = 0.802484 (* 1 = 0.802484 loss)
I0522 01:25:48.706470 18599 sgd_solver.cpp:106] Iteration 195000, lr = 0.0025
I0522 01:26:00.821766 18599 solver.cpp:237] Iteration 195750, loss = 0.920113
I0522 01:26:00.821938 18599 solver.cpp:253]     Train net output #0: loss = 0.920111 (* 1 = 0.920111 loss)
I0522 01:26:00.821952 18599 sgd_solver.cpp:106] Iteration 195750, lr = 0.0025
I0522 01:26:12.948137 18599 solver.cpp:237] Iteration 196500, loss = 1.14242
I0522 01:26:12.948171 18599 solver.cpp:253]     Train net output #0: loss = 1.14242 (* 1 = 1.14242 loss)
I0522 01:26:12.948187 18599 sgd_solver.cpp:106] Iteration 196500, lr = 0.0025
I0522 01:26:25.112429 18599 solver.cpp:237] Iteration 197250, loss = 0.823585
I0522 01:26:25.112484 18599 solver.cpp:253]     Train net output #0: loss = 0.823584 (* 1 = 0.823584 loss)
I0522 01:26:25.112498 18599 sgd_solver.cpp:106] Iteration 197250, lr = 0.0025
I0522 01:26:37.246397 18599 solver.cpp:237] Iteration 198000, loss = 1.04607
I0522 01:26:37.246561 18599 solver.cpp:253]     Train net output #0: loss = 1.04607 (* 1 = 1.04607 loss)
I0522 01:26:37.246574 18599 sgd_solver.cpp:106] Iteration 198000, lr = 0.0025
I0522 01:26:49.416335 18599 solver.cpp:237] Iteration 198750, loss = 0.931433
I0522 01:26:49.416388 18599 solver.cpp:253]     Train net output #0: loss = 0.931431 (* 1 = 0.931431 loss)
I0522 01:26:49.416402 18599 sgd_solver.cpp:106] Iteration 198750, lr = 0.0025
I0522 01:27:01.599969 18599 solver.cpp:237] Iteration 199500, loss = 1.21914
I0522 01:27:01.600004 18599 solver.cpp:253]     Train net output #0: loss = 1.21914 (* 1 = 1.21914 loss)
I0522 01:27:01.600020 18599 sgd_solver.cpp:106] Iteration 199500, lr = 0.0025
I0522 01:27:34.558027 18599 solver.cpp:237] Iteration 200250, loss = 1.06333
I0522 01:27:34.558220 18599 solver.cpp:253]     Train net output #0: loss = 1.06333 (* 1 = 1.06333 loss)
I0522 01:27:34.558234 18599 sgd_solver.cpp:106] Iteration 200250, lr = 0.0025
I0522 01:27:46.635965 18599 solver.cpp:237] Iteration 201000, loss = 1.22229
I0522 01:27:46.636003 18599 solver.cpp:253]     Train net output #0: loss = 1.22229 (* 1 = 1.22229 loss)
I0522 01:27:46.636019 18599 sgd_solver.cpp:106] Iteration 201000, lr = 0.0025
I0522 01:27:58.709734 18599 solver.cpp:237] Iteration 201750, loss = 1.09349
I0522 01:27:58.709784 18599 solver.cpp:253]     Train net output #0: loss = 1.09349 (* 1 = 1.09349 loss)
I0522 01:27:58.709800 18599 sgd_solver.cpp:106] Iteration 201750, lr = 0.0025
I0522 01:28:10.774024 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_202500.caffemodel
I0522 01:28:10.823287 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_202500.solverstate
I0522 01:28:10.853546 18599 solver.cpp:237] Iteration 202500, loss = 1.05312
I0522 01:28:10.853595 18599 solver.cpp:253]     Train net output #0: loss = 1.05311 (* 1 = 1.05311 loss)
I0522 01:28:10.853610 18599 sgd_solver.cpp:106] Iteration 202500, lr = 0.0025
I0522 01:28:22.974711 18599 solver.cpp:237] Iteration 203250, loss = 0.979731
I0522 01:28:22.974761 18599 solver.cpp:253]     Train net output #0: loss = 0.97973 (* 1 = 0.97973 loss)
I0522 01:28:22.974774 18599 sgd_solver.cpp:106] Iteration 203250, lr = 0.0025
I0522 01:28:35.115144 18599 solver.cpp:237] Iteration 204000, loss = 1.05314
I0522 01:28:35.115180 18599 solver.cpp:253]     Train net output #0: loss = 1.05314 (* 1 = 1.05314 loss)
I0522 01:28:35.115196 18599 sgd_solver.cpp:106] Iteration 204000, lr = 0.0025
I0522 01:28:47.262011 18599 solver.cpp:237] Iteration 204750, loss = 0.709997
I0522 01:28:47.262198 18599 solver.cpp:253]     Train net output #0: loss = 0.709996 (* 1 = 0.709996 loss)
I0522 01:28:47.262212 18599 sgd_solver.cpp:106] Iteration 204750, lr = 0.0025
I0522 01:29:20.233785 18599 solver.cpp:237] Iteration 205500, loss = 1.08856
I0522 01:29:20.233978 18599 solver.cpp:253]     Train net output #0: loss = 1.08856 (* 1 = 1.08856 loss)
I0522 01:29:20.233994 18599 sgd_solver.cpp:106] Iteration 205500, lr = 0.0025
I0522 01:29:32.359004 18599 solver.cpp:237] Iteration 206250, loss = 1.46422
I0522 01:29:32.359040 18599 solver.cpp:253]     Train net output #0: loss = 1.46422 (* 1 = 1.46422 loss)
I0522 01:29:32.359057 18599 sgd_solver.cpp:106] Iteration 206250, lr = 0.0025
I0522 01:29:44.477628 18599 solver.cpp:237] Iteration 207000, loss = 1.12913
I0522 01:29:44.477675 18599 solver.cpp:253]     Train net output #0: loss = 1.12913 (* 1 = 1.12913 loss)
I0522 01:29:44.477692 18599 sgd_solver.cpp:106] Iteration 207000, lr = 0.0025
I0522 01:29:56.567072 18599 solver.cpp:237] Iteration 207750, loss = 1.38384
I0522 01:29:56.567239 18599 solver.cpp:253]     Train net output #0: loss = 1.38384 (* 1 = 1.38384 loss)
I0522 01:29:56.567253 18599 sgd_solver.cpp:106] Iteration 207750, lr = 0.0025
I0522 01:30:08.683734 18599 solver.cpp:237] Iteration 208500, loss = 0.958987
I0522 01:30:08.683782 18599 solver.cpp:253]     Train net output #0: loss = 0.958986 (* 1 = 0.958986 loss)
I0522 01:30:08.683799 18599 sgd_solver.cpp:106] Iteration 208500, lr = 0.0025
I0522 01:30:20.824847 18599 solver.cpp:237] Iteration 209250, loss = 1.41629
I0522 01:30:20.824889 18599 solver.cpp:253]     Train net output #0: loss = 1.41629 (* 1 = 1.41629 loss)
I0522 01:30:20.824903 18599 sgd_solver.cpp:106] Iteration 209250, lr = 0.0025
I0522 01:30:32.970986 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_210000.caffemodel
I0522 01:30:33.020086 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_210000.solverstate
I0522 01:30:33.045249 18599 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 01:31:45.984036 18599 solver.cpp:409]     Test net output #0: accuracy = 0.899118
I0522 01:31:45.984225 18599 solver.cpp:409]     Test net output #1: loss = 0.312433 (* 1 = 0.312433 loss)
I0522 01:32:06.836798 18599 solver.cpp:237] Iteration 210000, loss = 1.29265
I0522 01:32:06.836856 18599 solver.cpp:253]     Train net output #0: loss = 1.29265 (* 1 = 1.29265 loss)
I0522 01:32:06.836877 18599 sgd_solver.cpp:106] Iteration 210000, lr = 0.0025
I0522 01:32:18.979749 18599 solver.cpp:237] Iteration 210750, loss = 1.24283
I0522 01:32:18.979919 18599 solver.cpp:253]     Train net output #0: loss = 1.24283 (* 1 = 1.24283 loss)
I0522 01:32:18.979933 18599 sgd_solver.cpp:106] Iteration 210750, lr = 0.0025
I0522 01:32:31.124538 18599 solver.cpp:237] Iteration 211500, loss = 0.965033
I0522 01:32:31.124593 18599 solver.cpp:253]     Train net output #0: loss = 0.965032 (* 1 = 0.965032 loss)
I0522 01:32:31.124608 18599 sgd_solver.cpp:106] Iteration 211500, lr = 0.0025
I0522 01:32:43.257848 18599 solver.cpp:237] Iteration 212250, loss = 0.731182
I0522 01:32:43.257884 18599 solver.cpp:253]     Train net output #0: loss = 0.731181 (* 1 = 0.731181 loss)
I0522 01:32:43.257900 18599 sgd_solver.cpp:106] Iteration 212250, lr = 0.0025
I0522 01:32:55.349165 18599 solver.cpp:237] Iteration 213000, loss = 0.991292
I0522 01:32:55.349344 18599 solver.cpp:253]     Train net output #0: loss = 0.991291 (* 1 = 0.991291 loss)
I0522 01:32:55.349357 18599 sgd_solver.cpp:106] Iteration 213000, lr = 0.0025
I0522 01:33:07.425977 18599 solver.cpp:237] Iteration 213750, loss = 1.13318
I0522 01:33:07.426013 18599 solver.cpp:253]     Train net output #0: loss = 1.13318 (* 1 = 1.13318 loss)
I0522 01:33:07.426030 18599 sgd_solver.cpp:106] Iteration 213750, lr = 0.0025
I0522 01:33:19.504730 18599 solver.cpp:237] Iteration 214500, loss = 1.24358
I0522 01:33:19.504781 18599 solver.cpp:253]     Train net output #0: loss = 1.24358 (* 1 = 1.24358 loss)
I0522 01:33:19.504797 18599 sgd_solver.cpp:106] Iteration 214500, lr = 0.0025
I0522 01:33:52.508790 18599 solver.cpp:237] Iteration 215250, loss = 1.22606
I0522 01:33:52.509001 18599 solver.cpp:253]     Train net output #0: loss = 1.22606 (* 1 = 1.22606 loss)
I0522 01:33:52.509016 18599 sgd_solver.cpp:106] Iteration 215250, lr = 0.0025
I0522 01:34:04.647621 18599 solver.cpp:237] Iteration 216000, loss = 1.24712
I0522 01:34:04.647658 18599 solver.cpp:253]     Train net output #0: loss = 1.24712 (* 1 = 1.24712 loss)
I0522 01:34:04.647675 18599 sgd_solver.cpp:106] Iteration 216000, lr = 0.0025
I0522 01:34:16.784003 18599 solver.cpp:237] Iteration 216750, loss = 1.12952
I0522 01:34:16.784056 18599 solver.cpp:253]     Train net output #0: loss = 1.12952 (* 1 = 1.12952 loss)
I0522 01:34:16.784071 18599 sgd_solver.cpp:106] Iteration 216750, lr = 0.0025
I0522 01:34:28.899838 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_217500.caffemodel
I0522 01:34:28.950866 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_217500.solverstate
I0522 01:34:28.991459 18599 solver.cpp:237] Iteration 217500, loss = 2.00982
I0522 01:34:28.991514 18599 solver.cpp:253]     Train net output #0: loss = 2.00982 (* 1 = 2.00982 loss)
I0522 01:34:28.991528 18599 sgd_solver.cpp:106] Iteration 217500, lr = 0.0025
I0522 01:34:41.117470 18599 solver.cpp:237] Iteration 218250, loss = 1.05124
I0522 01:34:41.117522 18599 solver.cpp:253]     Train net output #0: loss = 1.05124 (* 1 = 1.05124 loss)
I0522 01:34:41.117537 18599 sgd_solver.cpp:106] Iteration 218250, lr = 0.0025
I0522 01:34:53.244626 18599 solver.cpp:237] Iteration 219000, loss = 2.03932
I0522 01:34:53.244660 18599 solver.cpp:253]     Train net output #0: loss = 2.03932 (* 1 = 2.03932 loss)
I0522 01:34:53.244679 18599 sgd_solver.cpp:106] Iteration 219000, lr = 0.0025
I0522 01:35:05.337424 18599 solver.cpp:237] Iteration 219750, loss = 1.08362
I0522 01:35:05.337615 18599 solver.cpp:253]     Train net output #0: loss = 1.08362 (* 1 = 1.08362 loss)
I0522 01:35:05.337631 18599 sgd_solver.cpp:106] Iteration 219750, lr = 0.0025
I0522 01:35:38.385805 18599 solver.cpp:237] Iteration 220500, loss = 0.903651
I0522 01:35:38.385998 18599 solver.cpp:253]     Train net output #0: loss = 0.903651 (* 1 = 0.903651 loss)
I0522 01:35:38.386013 18599 sgd_solver.cpp:106] Iteration 220500, lr = 0.0025
I0522 01:35:50.544433 18599 solver.cpp:237] Iteration 221250, loss = 0.783037
I0522 01:35:50.544486 18599 solver.cpp:253]     Train net output #0: loss = 0.783037 (* 1 = 0.783037 loss)
I0522 01:35:50.544502 18599 sgd_solver.cpp:106] Iteration 221250, lr = 0.0025
I0522 01:36:02.735249 18599 solver.cpp:237] Iteration 222000, loss = 1.16447
I0522 01:36:02.735285 18599 solver.cpp:253]     Train net output #0: loss = 1.16447 (* 1 = 1.16447 loss)
I0522 01:36:02.735302 18599 sgd_solver.cpp:106] Iteration 222000, lr = 0.0025
I0522 01:36:14.874877 18599 solver.cpp:237] Iteration 222750, loss = 1.29415
I0522 01:36:14.875068 18599 solver.cpp:253]     Train net output #0: loss = 1.29415 (* 1 = 1.29415 loss)
I0522 01:36:14.875082 18599 sgd_solver.cpp:106] Iteration 222750, lr = 0.0025
I0522 01:36:27.034977 18599 solver.cpp:237] Iteration 223500, loss = 1.60672
I0522 01:36:27.035013 18599 solver.cpp:253]     Train net output #0: loss = 1.60672 (* 1 = 1.60672 loss)
I0522 01:36:27.035032 18599 sgd_solver.cpp:106] Iteration 223500, lr = 0.0025
I0522 01:36:39.185550 18599 solver.cpp:237] Iteration 224250, loss = 1.63995
I0522 01:36:39.185597 18599 solver.cpp:253]     Train net output #0: loss = 1.63995 (* 1 = 1.63995 loss)
I0522 01:36:39.185613 18599 sgd_solver.cpp:106] Iteration 224250, lr = 0.0025
I0522 01:36:51.313526 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_225000.caffemodel
I0522 01:36:51.364387 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_225000.solverstate
I0522 01:36:51.393182 18599 solver.cpp:341] Iteration 225000, Testing net (#0)
I0522 01:37:42.969522 18599 solver.cpp:409]     Test net output #0: accuracy = 0.899997
I0522 01:37:42.969714 18599 solver.cpp:409]     Test net output #1: loss = 0.332966 (* 1 = 0.332966 loss)
I0522 01:38:03.873744 18599 solver.cpp:237] Iteration 225000, loss = 1.36821
I0522 01:38:03.873800 18599 solver.cpp:253]     Train net output #0: loss = 1.36821 (* 1 = 1.36821 loss)
I0522 01:38:03.873816 18599 sgd_solver.cpp:106] Iteration 225000, lr = 0.0025
I0522 01:38:16.037212 18599 solver.cpp:237] Iteration 225750, loss = 0.957242
I0522 01:38:16.037386 18599 solver.cpp:253]     Train net output #0: loss = 0.957242 (* 1 = 0.957242 loss)
I0522 01:38:16.037401 18599 sgd_solver.cpp:106] Iteration 225750, lr = 0.0025
I0522 01:38:28.204277 18599 solver.cpp:237] Iteration 226500, loss = 1.03889
I0522 01:38:28.204320 18599 solver.cpp:253]     Train net output #0: loss = 1.03889 (* 1 = 1.03889 loss)
I0522 01:38:28.204336 18599 sgd_solver.cpp:106] Iteration 226500, lr = 0.0025
I0522 01:38:40.348386 18599 solver.cpp:237] Iteration 227250, loss = 1.02324
I0522 01:38:40.348422 18599 solver.cpp:253]     Train net output #0: loss = 1.02324 (* 1 = 1.02324 loss)
I0522 01:38:40.348438 18599 sgd_solver.cpp:106] Iteration 227250, lr = 0.0025
I0522 01:38:52.420588 18599 solver.cpp:237] Iteration 228000, loss = 0.751429
I0522 01:38:52.420766 18599 solver.cpp:253]     Train net output #0: loss = 0.751429 (* 1 = 0.751429 loss)
I0522 01:38:52.420783 18599 sgd_solver.cpp:106] Iteration 228000, lr = 0.0025
I0522 01:39:04.494501 18599 solver.cpp:237] Iteration 228750, loss = 1.26304
I0522 01:39:04.494537 18599 solver.cpp:253]     Train net output #0: loss = 1.26304 (* 1 = 1.26304 loss)
I0522 01:39:04.494554 18599 sgd_solver.cpp:106] Iteration 228750, lr = 0.0025
I0522 01:39:16.564311 18599 solver.cpp:237] Iteration 229500, loss = 1.40659
I0522 01:39:16.564359 18599 solver.cpp:253]     Train net output #0: loss = 1.40659 (* 1 = 1.40659 loss)
I0522 01:39:16.564373 18599 sgd_solver.cpp:106] Iteration 229500, lr = 0.0025
I0522 01:39:49.514894 18599 solver.cpp:237] Iteration 230250, loss = 1.44376
I0522 01:39:49.515085 18599 solver.cpp:253]     Train net output #0: loss = 1.44376 (* 1 = 1.44376 loss)
I0522 01:39:49.515101 18599 sgd_solver.cpp:106] Iteration 230250, lr = 0.0025
I0522 01:40:01.586220 18599 solver.cpp:237] Iteration 231000, loss = 0.848538
I0522 01:40:01.586273 18599 solver.cpp:253]     Train net output #0: loss = 0.848538 (* 1 = 0.848538 loss)
I0522 01:40:01.586289 18599 sgd_solver.cpp:106] Iteration 231000, lr = 0.0025
I0522 01:40:13.660450 18599 solver.cpp:237] Iteration 231750, loss = 1.32575
I0522 01:40:13.660486 18599 solver.cpp:253]     Train net output #0: loss = 1.32575 (* 1 = 1.32575 loss)
I0522 01:40:13.660503 18599 sgd_solver.cpp:106] Iteration 231750, lr = 0.0025
I0522 01:40:25.716740 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_232500.caffemodel
I0522 01:40:25.766347 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_232500.solverstate
I0522 01:40:25.796213 18599 solver.cpp:237] Iteration 232500, loss = 1.12634
I0522 01:40:25.796262 18599 solver.cpp:253]     Train net output #0: loss = 1.12634 (* 1 = 1.12634 loss)
I0522 01:40:25.796277 18599 sgd_solver.cpp:106] Iteration 232500, lr = 0.0025
I0522 01:40:37.864054 18599 solver.cpp:237] Iteration 233250, loss = 1.47497
I0522 01:40:37.864092 18599 solver.cpp:253]     Train net output #0: loss = 1.47497 (* 1 = 1.47497 loss)
I0522 01:40:37.864109 18599 sgd_solver.cpp:106] Iteration 233250, lr = 0.0025
I0522 01:40:49.936508 18599 solver.cpp:237] Iteration 234000, loss = 0.873431
I0522 01:40:49.936559 18599 solver.cpp:253]     Train net output #0: loss = 0.873431 (* 1 = 0.873431 loss)
I0522 01:40:49.936574 18599 sgd_solver.cpp:106] Iteration 234000, lr = 0.0025
I0522 01:41:02.123313 18599 solver.cpp:237] Iteration 234750, loss = 0.85744
I0522 01:41:02.123507 18599 solver.cpp:253]     Train net output #0: loss = 0.85744 (* 1 = 0.85744 loss)
I0522 01:41:02.123522 18599 sgd_solver.cpp:106] Iteration 234750, lr = 0.0025
I0522 01:41:35.157310 18599 solver.cpp:237] Iteration 235500, loss = 0.867065
I0522 01:41:35.157506 18599 solver.cpp:253]     Train net output #0: loss = 0.867065 (* 1 = 0.867065 loss)
I0522 01:41:35.157521 18599 sgd_solver.cpp:106] Iteration 235500, lr = 0.0025
I0522 01:41:47.320587 18599 solver.cpp:237] Iteration 236250, loss = 0.778824
I0522 01:41:47.320637 18599 solver.cpp:253]     Train net output #0: loss = 0.778824 (* 1 = 0.778824 loss)
I0522 01:41:47.320652 18599 sgd_solver.cpp:106] Iteration 236250, lr = 0.0025
I0522 01:41:59.480600 18599 solver.cpp:237] Iteration 237000, loss = 0.568202
I0522 01:41:59.480638 18599 solver.cpp:253]     Train net output #0: loss = 0.568202 (* 1 = 0.568202 loss)
I0522 01:41:59.480654 18599 sgd_solver.cpp:106] Iteration 237000, lr = 0.0025
I0522 01:42:11.646630 18599 solver.cpp:237] Iteration 237750, loss = 0.920529
I0522 01:42:11.646813 18599 solver.cpp:253]     Train net output #0: loss = 0.920529 (* 1 = 0.920529 loss)
I0522 01:42:11.646829 18599 sgd_solver.cpp:106] Iteration 237750, lr = 0.0025
I0522 01:42:23.803644 18599 solver.cpp:237] Iteration 238500, loss = 1.07493
I0522 01:42:23.803681 18599 solver.cpp:253]     Train net output #0: loss = 1.07493 (* 1 = 1.07493 loss)
I0522 01:42:23.803696 18599 sgd_solver.cpp:106] Iteration 238500, lr = 0.0025
I0522 01:42:35.960980 18599 solver.cpp:237] Iteration 239250, loss = 1.41415
I0522 01:42:35.961031 18599 solver.cpp:253]     Train net output #0: loss = 1.41415 (* 1 = 1.41415 loss)
I0522 01:42:35.961045 18599 sgd_solver.cpp:106] Iteration 239250, lr = 0.0025
I0522 01:42:48.091411 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_240000.caffemodel
I0522 01:42:48.141037 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_240000.solverstate
I0522 01:42:48.166296 18599 solver.cpp:341] Iteration 240000, Testing net (#0)
I0522 01:44:00.942100 18599 solver.cpp:409]     Test net output #0: accuracy = 0.901224
I0522 01:44:00.942304 18599 solver.cpp:409]     Test net output #1: loss = 0.312578 (* 1 = 0.312578 loss)
I0522 01:44:21.827822 18599 solver.cpp:237] Iteration 240000, loss = 1.57578
I0522 01:44:21.827880 18599 solver.cpp:253]     Train net output #0: loss = 1.57578 (* 1 = 1.57578 loss)
I0522 01:44:21.827895 18599 sgd_solver.cpp:106] Iteration 240000, lr = 0.0025
I0522 01:44:33.970650 18599 solver.cpp:237] Iteration 240750, loss = 0.899489
I0522 01:44:33.970837 18599 solver.cpp:253]     Train net output #0: loss = 0.899488 (* 1 = 0.899488 loss)
I0522 01:44:33.970852 18599 sgd_solver.cpp:106] Iteration 240750, lr = 0.0025
I0522 01:44:46.078243 18599 solver.cpp:237] Iteration 241500, loss = 1.04938
I0522 01:44:46.078279 18599 solver.cpp:253]     Train net output #0: loss = 1.04938 (* 1 = 1.04938 loss)
I0522 01:44:46.078294 18599 sgd_solver.cpp:106] Iteration 241500, lr = 0.0025
I0522 01:44:58.153480 18599 solver.cpp:237] Iteration 242250, loss = 1.19839
I0522 01:44:58.153515 18599 solver.cpp:253]     Train net output #0: loss = 1.19839 (* 1 = 1.19839 loss)
I0522 01:44:58.153532 18599 sgd_solver.cpp:106] Iteration 242250, lr = 0.0025
I0522 01:45:10.240783 18599 solver.cpp:237] Iteration 243000, loss = 1.00731
I0522 01:45:10.240969 18599 solver.cpp:253]     Train net output #0: loss = 1.00731 (* 1 = 1.00731 loss)
I0522 01:45:10.240984 18599 sgd_solver.cpp:106] Iteration 243000, lr = 0.0025
I0522 01:45:22.364382 18599 solver.cpp:237] Iteration 243750, loss = 1.51183
I0522 01:45:22.364418 18599 solver.cpp:253]     Train net output #0: loss = 1.51183 (* 1 = 1.51183 loss)
I0522 01:45:22.364434 18599 sgd_solver.cpp:106] Iteration 243750, lr = 0.0025
I0522 01:45:34.491508 18599 solver.cpp:237] Iteration 244500, loss = 1.15931
I0522 01:45:34.491554 18599 solver.cpp:253]     Train net output #0: loss = 1.15931 (* 1 = 1.15931 loss)
I0522 01:45:34.491569 18599 sgd_solver.cpp:106] Iteration 244500, lr = 0.0025
I0522 01:46:07.563462 18599 solver.cpp:237] Iteration 245250, loss = 0.613082
I0522 01:46:07.563662 18599 solver.cpp:253]     Train net output #0: loss = 0.613081 (* 1 = 0.613081 loss)
I0522 01:46:07.563676 18599 sgd_solver.cpp:106] Iteration 245250, lr = 0.0025
I0522 01:46:19.691464 18599 solver.cpp:237] Iteration 246000, loss = 1.17166
I0522 01:46:19.691509 18599 solver.cpp:253]     Train net output #0: loss = 1.17166 (* 1 = 1.17166 loss)
I0522 01:46:19.691527 18599 sgd_solver.cpp:106] Iteration 246000, lr = 0.0025
I0522 01:46:31.797554 18599 solver.cpp:237] Iteration 246750, loss = 1.38409
I0522 01:46:31.797591 18599 solver.cpp:253]     Train net output #0: loss = 1.38409 (* 1 = 1.38409 loss)
I0522 01:46:31.797608 18599 sgd_solver.cpp:106] Iteration 246750, lr = 0.0025
I0522 01:46:43.887800 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_247500.caffemodel
I0522 01:46:43.936920 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_247500.solverstate
I0522 01:46:43.967597 18599 solver.cpp:237] Iteration 247500, loss = 0.979689
I0522 01:46:43.967648 18599 solver.cpp:253]     Train net output #0: loss = 0.979689 (* 1 = 0.979689 loss)
I0522 01:46:43.967666 18599 sgd_solver.cpp:106] Iteration 247500, lr = 0.0025
I0522 01:46:56.116768 18599 solver.cpp:237] Iteration 248250, loss = 0.867255
I0522 01:46:56.116806 18599 solver.cpp:253]     Train net output #0: loss = 0.867255 (* 1 = 0.867255 loss)
I0522 01:46:56.116819 18599 sgd_solver.cpp:106] Iteration 248250, lr = 0.0025
I0522 01:47:08.251924 18599 solver.cpp:237] Iteration 249000, loss = 1.10572
I0522 01:47:08.251974 18599 solver.cpp:253]     Train net output #0: loss = 1.10572 (* 1 = 1.10572 loss)
I0522 01:47:08.251989 18599 sgd_solver.cpp:106] Iteration 249000, lr = 0.0025
I0522 01:47:20.366539 18599 solver.cpp:237] Iteration 249750, loss = 0.782673
I0522 01:47:20.366717 18599 solver.cpp:253]     Train net output #0: loss = 0.782672 (* 1 = 0.782672 loss)
I0522 01:47:20.366732 18599 sgd_solver.cpp:106] Iteration 249750, lr = 0.0025
I0522 01:47:53.416050 18599 solver.cpp:237] Iteration 250500, loss = 1.0528
I0522 01:47:53.416247 18599 solver.cpp:253]     Train net output #0: loss = 1.0528 (* 1 = 1.0528 loss)
I0522 01:47:53.416262 18599 sgd_solver.cpp:106] Iteration 250500, lr = 0.0025
I0522 01:48:05.570226 18599 solver.cpp:237] Iteration 251250, loss = 1.21155
I0522 01:48:05.570273 18599 solver.cpp:253]     Train net output #0: loss = 1.21155 (* 1 = 1.21155 loss)
I0522 01:48:05.570288 18599 sgd_solver.cpp:106] Iteration 251250, lr = 0.0025
I0522 01:48:17.720554 18599 solver.cpp:237] Iteration 252000, loss = 1.09445
I0522 01:48:17.720590 18599 solver.cpp:253]     Train net output #0: loss = 1.09444 (* 1 = 1.09444 loss)
I0522 01:48:17.720604 18599 sgd_solver.cpp:106] Iteration 252000, lr = 0.0025
I0522 01:48:29.868418 18599 solver.cpp:237] Iteration 252750, loss = 0.76601
I0522 01:48:29.868615 18599 solver.cpp:253]     Train net output #0: loss = 0.766009 (* 1 = 0.766009 loss)
I0522 01:48:29.868630 18599 sgd_solver.cpp:106] Iteration 252750, lr = 0.0025
I0522 01:48:41.940090 18599 solver.cpp:237] Iteration 253500, loss = 1.11889
I0522 01:48:41.940127 18599 solver.cpp:253]     Train net output #0: loss = 1.11888 (* 1 = 1.11888 loss)
I0522 01:48:41.940142 18599 sgd_solver.cpp:106] Iteration 253500, lr = 0.0025
I0522 01:48:54.031225 18599 solver.cpp:237] Iteration 254250, loss = 1.22368
I0522 01:48:54.031275 18599 solver.cpp:253]     Train net output #0: loss = 1.22368 (* 1 = 1.22368 loss)
I0522 01:48:54.031288 18599 sgd_solver.cpp:106] Iteration 254250, lr = 0.0025
I0522 01:49:06.116186 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_255000.caffemodel
I0522 01:49:06.166147 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_255000.solverstate
I0522 01:49:06.191668 18599 solver.cpp:341] Iteration 255000, Testing net (#0)
I0522 01:49:58.243616 18599 solver.cpp:409]     Test net output #0: accuracy = 0.90156
I0522 01:49:58.243811 18599 solver.cpp:409]     Test net output #1: loss = 0.319906 (* 1 = 0.319906 loss)
I0522 01:50:19.118733 18599 solver.cpp:237] Iteration 255000, loss = 1.33736
I0522 01:50:19.118791 18599 solver.cpp:253]     Train net output #0: loss = 1.33736 (* 1 = 1.33736 loss)
I0522 01:50:19.118806 18599 sgd_solver.cpp:106] Iteration 255000, lr = 0.0025
I0522 01:50:31.272876 18599 solver.cpp:237] Iteration 255750, loss = 1.02971
I0522 01:50:31.273067 18599 solver.cpp:253]     Train net output #0: loss = 1.02971 (* 1 = 1.02971 loss)
I0522 01:50:31.273082 18599 sgd_solver.cpp:106] Iteration 255750, lr = 0.0025
I0522 01:50:43.428269 18599 solver.cpp:237] Iteration 256500, loss = 0.994913
I0522 01:50:43.428306 18599 solver.cpp:253]     Train net output #0: loss = 0.994911 (* 1 = 0.994911 loss)
I0522 01:50:43.428320 18599 sgd_solver.cpp:106] Iteration 256500, lr = 0.0025
I0522 01:50:55.543057 18599 solver.cpp:237] Iteration 257250, loss = 0.938333
I0522 01:50:55.543112 18599 solver.cpp:253]     Train net output #0: loss = 0.938332 (* 1 = 0.938332 loss)
I0522 01:50:55.543125 18599 sgd_solver.cpp:106] Iteration 257250, lr = 0.0025
I0522 01:51:07.620537 18599 solver.cpp:237] Iteration 258000, loss = 1.46671
I0522 01:51:07.620709 18599 solver.cpp:253]     Train net output #0: loss = 1.46671 (* 1 = 1.46671 loss)
I0522 01:51:07.620724 18599 sgd_solver.cpp:106] Iteration 258000, lr = 0.0025
I0522 01:51:19.696144 18599 solver.cpp:237] Iteration 258750, loss = 1.1898
I0522 01:51:19.696193 18599 solver.cpp:253]     Train net output #0: loss = 1.1898 (* 1 = 1.1898 loss)
I0522 01:51:19.696209 18599 sgd_solver.cpp:106] Iteration 258750, lr = 0.0025
I0522 01:51:31.825613 18599 solver.cpp:237] Iteration 259500, loss = 1.62726
I0522 01:51:31.825649 18599 solver.cpp:253]     Train net output #0: loss = 1.62726 (* 1 = 1.62726 loss)
I0522 01:51:31.825661 18599 sgd_solver.cpp:106] Iteration 259500, lr = 0.0025
I0522 01:52:04.862872 18599 solver.cpp:237] Iteration 260250, loss = 1.51948
I0522 01:52:04.863070 18599 solver.cpp:253]     Train net output #0: loss = 1.51948 (* 1 = 1.51948 loss)
I0522 01:52:04.863083 18599 sgd_solver.cpp:106] Iteration 260250, lr = 0.0025
I0522 01:52:16.959034 18599 solver.cpp:237] Iteration 261000, loss = 1.1978
I0522 01:52:16.959071 18599 solver.cpp:253]     Train net output #0: loss = 1.1978 (* 1 = 1.1978 loss)
I0522 01:52:16.959087 18599 sgd_solver.cpp:106] Iteration 261000, lr = 0.0025
I0522 01:52:29.082617 18599 solver.cpp:237] Iteration 261750, loss = 1.01932
I0522 01:52:29.082665 18599 solver.cpp:253]     Train net output #0: loss = 1.01932 (* 1 = 1.01932 loss)
I0522 01:52:29.082679 18599 sgd_solver.cpp:106] Iteration 261750, lr = 0.0025
I0522 01:52:41.166311 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_262500.caffemodel
I0522 01:52:41.217445 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_262500.solverstate
I0522 01:52:41.250712 18599 solver.cpp:237] Iteration 262500, loss = 1.40059
I0522 01:52:41.250767 18599 solver.cpp:253]     Train net output #0: loss = 1.40059 (* 1 = 1.40059 loss)
I0522 01:52:41.250782 18599 sgd_solver.cpp:106] Iteration 262500, lr = 0.0025
I0522 01:52:53.410660 18599 solver.cpp:237] Iteration 263250, loss = 1.30559
I0522 01:52:53.410696 18599 solver.cpp:253]     Train net output #0: loss = 1.30559 (* 1 = 1.30559 loss)
I0522 01:52:53.410712 18599 sgd_solver.cpp:106] Iteration 263250, lr = 0.0025
I0522 01:53:05.575454 18599 solver.cpp:237] Iteration 264000, loss = 0.668944
I0522 01:53:05.575501 18599 solver.cpp:253]     Train net output #0: loss = 0.668943 (* 1 = 0.668943 loss)
I0522 01:53:05.575516 18599 sgd_solver.cpp:106] Iteration 264000, lr = 0.0025
I0522 01:53:17.700371 18599 solver.cpp:237] Iteration 264750, loss = 1.12381
I0522 01:53:17.700559 18599 solver.cpp:253]     Train net output #0: loss = 1.12381 (* 1 = 1.12381 loss)
I0522 01:53:17.700573 18599 sgd_solver.cpp:106] Iteration 264750, lr = 0.0025
I0522 01:53:50.723562 18599 solver.cpp:237] Iteration 265500, loss = 1.28913
I0522 01:53:50.723760 18599 solver.cpp:253]     Train net output #0: loss = 1.28913 (* 1 = 1.28913 loss)
I0522 01:53:50.723776 18599 sgd_solver.cpp:106] Iteration 265500, lr = 0.0025
I0522 01:54:02.911401 18599 solver.cpp:237] Iteration 266250, loss = 1.05824
I0522 01:54:02.911437 18599 solver.cpp:253]     Train net output #0: loss = 1.05824 (* 1 = 1.05824 loss)
I0522 01:54:02.911453 18599 sgd_solver.cpp:106] Iteration 266250, lr = 0.0025
I0522 01:54:15.110858 18599 solver.cpp:237] Iteration 267000, loss = 1.41647
I0522 01:54:15.110908 18599 solver.cpp:253]     Train net output #0: loss = 1.41646 (* 1 = 1.41646 loss)
I0522 01:54:15.110924 18599 sgd_solver.cpp:106] Iteration 267000, lr = 0.0025
I0522 01:54:27.298383 18599 solver.cpp:237] Iteration 267750, loss = 0.727268
I0522 01:54:27.298555 18599 solver.cpp:253]     Train net output #0: loss = 0.727267 (* 1 = 0.727267 loss)
I0522 01:54:27.298569 18599 sgd_solver.cpp:106] Iteration 267750, lr = 0.0025
I0522 01:54:39.397042 18599 solver.cpp:237] Iteration 268500, loss = 1.25747
I0522 01:54:39.397094 18599 solver.cpp:253]     Train net output #0: loss = 1.25747 (* 1 = 1.25747 loss)
I0522 01:54:39.397109 18599 sgd_solver.cpp:106] Iteration 268500, lr = 0.0025
I0522 01:54:51.492326 18599 solver.cpp:237] Iteration 269250, loss = 0.735939
I0522 01:54:51.492363 18599 solver.cpp:253]     Train net output #0: loss = 0.735937 (* 1 = 0.735937 loss)
I0522 01:54:51.492380 18599 sgd_solver.cpp:106] Iteration 269250, lr = 0.0025
I0522 01:55:03.588806 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_270000.caffemodel
I0522 01:55:03.640008 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_270000.solverstate
I0522 01:55:03.667729 18599 solver.cpp:341] Iteration 270000, Testing net (#0)
I0522 01:56:16.488102 18599 solver.cpp:409]     Test net output #0: accuracy = 0.903311
I0522 01:56:16.488309 18599 solver.cpp:409]     Test net output #1: loss = 0.31558 (* 1 = 0.31558 loss)
I0522 01:56:37.364409 18599 solver.cpp:237] Iteration 270000, loss = 0.494985
I0522 01:56:37.364470 18599 solver.cpp:253]     Train net output #0: loss = 0.494983 (* 1 = 0.494983 loss)
I0522 01:56:37.364485 18599 sgd_solver.cpp:106] Iteration 270000, lr = 0.0025
I0522 01:56:49.499744 18599 solver.cpp:237] Iteration 270750, loss = 0.981748
I0522 01:56:49.499948 18599 solver.cpp:253]     Train net output #0: loss = 0.981747 (* 1 = 0.981747 loss)
I0522 01:56:49.499964 18599 sgd_solver.cpp:106] Iteration 270750, lr = 0.0025
I0522 01:57:01.562659 18599 solver.cpp:237] Iteration 271500, loss = 1.04773
I0522 01:57:01.562695 18599 solver.cpp:253]     Train net output #0: loss = 1.04773 (* 1 = 1.04773 loss)
I0522 01:57:01.562710 18599 sgd_solver.cpp:106] Iteration 271500, lr = 0.0025
I0522 01:57:13.703277 18599 solver.cpp:237] Iteration 272250, loss = 0.954104
I0522 01:57:13.703328 18599 solver.cpp:253]     Train net output #0: loss = 0.954103 (* 1 = 0.954103 loss)
I0522 01:57:13.703342 18599 sgd_solver.cpp:106] Iteration 272250, lr = 0.0025
I0522 01:57:25.861649 18599 solver.cpp:237] Iteration 273000, loss = 1.07411
I0522 01:57:25.861831 18599 solver.cpp:253]     Train net output #0: loss = 1.07411 (* 1 = 1.07411 loss)
I0522 01:57:25.861846 18599 sgd_solver.cpp:106] Iteration 273000, lr = 0.0025
I0522 01:57:37.952064 18599 solver.cpp:237] Iteration 273750, loss = 1.54298
I0522 01:57:37.952118 18599 solver.cpp:253]     Train net output #0: loss = 1.54298 (* 1 = 1.54298 loss)
I0522 01:57:37.952132 18599 sgd_solver.cpp:106] Iteration 273750, lr = 0.0025
I0522 01:57:50.022022 18599 solver.cpp:237] Iteration 274500, loss = 1.04508
I0522 01:57:50.022058 18599 solver.cpp:253]     Train net output #0: loss = 1.04508 (* 1 = 1.04508 loss)
I0522 01:57:50.022073 18599 sgd_solver.cpp:106] Iteration 274500, lr = 0.0025
I0522 01:58:22.971117 18599 solver.cpp:237] Iteration 275250, loss = 1.15961
I0522 01:58:22.971318 18599 solver.cpp:253]     Train net output #0: loss = 1.15961 (* 1 = 1.15961 loss)
I0522 01:58:22.971334 18599 sgd_solver.cpp:106] Iteration 275250, lr = 0.0025
I0522 01:58:35.113497 18599 solver.cpp:237] Iteration 276000, loss = 1.00323
I0522 01:58:35.113533 18599 solver.cpp:253]     Train net output #0: loss = 1.00323 (* 1 = 1.00323 loss)
I0522 01:58:35.113548 18599 sgd_solver.cpp:106] Iteration 276000, lr = 0.0025
I0522 01:58:47.280963 18599 solver.cpp:237] Iteration 276750, loss = 0.707876
I0522 01:58:47.281013 18599 solver.cpp:253]     Train net output #0: loss = 0.707874 (* 1 = 0.707874 loss)
I0522 01:58:47.281028 18599 sgd_solver.cpp:106] Iteration 276750, lr = 0.0025
I0522 01:58:59.441537 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_277500.caffemodel
I0522 01:58:59.491163 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_277500.solverstate
I0522 01:58:59.521977 18599 solver.cpp:237] Iteration 277500, loss = 1.4306
I0522 01:58:59.522025 18599 solver.cpp:253]     Train net output #0: loss = 1.43059 (* 1 = 1.43059 loss)
I0522 01:58:59.522044 18599 sgd_solver.cpp:106] Iteration 277500, lr = 0.0025
I0522 01:59:11.679142 18599 solver.cpp:237] Iteration 278250, loss = 1.01452
I0522 01:59:11.679194 18599 solver.cpp:253]     Train net output #0: loss = 1.01451 (* 1 = 1.01451 loss)
I0522 01:59:11.679208 18599 sgd_solver.cpp:106] Iteration 278250, lr = 0.0025
I0522 01:59:23.801961 18599 solver.cpp:237] Iteration 279000, loss = 1.23903
I0522 01:59:23.801998 18599 solver.cpp:253]     Train net output #0: loss = 1.23903 (* 1 = 1.23903 loss)
I0522 01:59:23.802012 18599 sgd_solver.cpp:106] Iteration 279000, lr = 0.0025
I0522 01:59:35.909457 18599 solver.cpp:237] Iteration 279750, loss = 0.852355
I0522 01:59:35.909659 18599 solver.cpp:253]     Train net output #0: loss = 0.852353 (* 1 = 0.852353 loss)
I0522 01:59:35.909675 18599 sgd_solver.cpp:106] Iteration 279750, lr = 0.0025
I0522 02:00:08.906913 18599 solver.cpp:237] Iteration 280500, loss = 1.01617
I0522 02:00:08.907117 18599 solver.cpp:253]     Train net output #0: loss = 1.01617 (* 1 = 1.01617 loss)
I0522 02:00:08.907132 18599 sgd_solver.cpp:106] Iteration 280500, lr = 0.0025
I0522 02:00:21.054972 18599 solver.cpp:237] Iteration 281250, loss = 1.51205
I0522 02:00:21.055008 18599 solver.cpp:253]     Train net output #0: loss = 1.51205 (* 1 = 1.51205 loss)
I0522 02:00:21.055023 18599 sgd_solver.cpp:106] Iteration 281250, lr = 0.0025
I0522 02:00:33.152194 18599 solver.cpp:237] Iteration 282000, loss = 1.31949
I0522 02:00:33.152245 18599 solver.cpp:253]     Train net output #0: loss = 1.31949 (* 1 = 1.31949 loss)
I0522 02:00:33.152259 18599 sgd_solver.cpp:106] Iteration 282000, lr = 0.0025
I0522 02:00:45.252354 18599 solver.cpp:237] Iteration 282750, loss = 0.911975
I0522 02:00:45.252539 18599 solver.cpp:253]     Train net output #0: loss = 0.911973 (* 1 = 0.911973 loss)
I0522 02:00:45.252554 18599 sgd_solver.cpp:106] Iteration 282750, lr = 0.0025
I0522 02:00:57.366616 18599 solver.cpp:237] Iteration 283500, loss = 1.02849
I0522 02:00:57.366670 18599 solver.cpp:253]     Train net output #0: loss = 1.02849 (* 1 = 1.02849 loss)
I0522 02:00:57.366684 18599 sgd_solver.cpp:106] Iteration 283500, lr = 0.0025
I0522 02:01:09.455188 18599 solver.cpp:237] Iteration 284250, loss = 1.33808
I0522 02:01:09.455224 18599 solver.cpp:253]     Train net output #0: loss = 1.33808 (* 1 = 1.33808 loss)
I0522 02:01:09.455240 18599 sgd_solver.cpp:106] Iteration 284250, lr = 0.0025
I0522 02:01:21.515980 18599 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_285000.caffemodel
I0522 02:01:21.564893 18599 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_285000.solverstate
I0522 02:01:21.590286 18599 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 02:02:13.312711 18599 solver.cpp:409]     Test net output #0: accuracy = 0.90068
I0522 02:02:13.312913 18599 solver.cpp:409]     Test net output #1: loss = 0.311097 (* 1 = 0.311097 loss)
I0522 02:02:34.206262 18599 solver.cpp:237] Iteration 285000, loss = 1.19296
I0522 02:02:34.206321 18599 solver.cpp:253]     Train net output #0: loss = 1.19296 (* 1 = 1.19296 loss)
I0522 02:02:34.206334 18599 sgd_solver.cpp:106] Iteration 285000, lr = 0.0025
I0522 02:02:46.353580 18599 solver.cpp:237] Iteration 285750, loss = 1.10593
I0522 02:02:46.353760 18599 solver.cpp:253]     Train net output #0: loss = 1.10593 (* 1 = 1.10593 loss)
I0522 02:02:46.353772 18599 sgd_solver.cpp:106] Iteration 285750, lr = 0.0025
I0522 02:02:58.543649 18599 solver.cpp:237] Iteration 286500, loss = 0.871417
I0522 02:02:58.543704 18599 solver.cpp:253]     Train net output #0: loss = 0.871416 (* 1 = 0.871416 loss)
I0522 02:02:58.543718 18599 sgd_solver.cpp:106] Iteration 286500, lr = 0.0025
I0522 02:03:10.718735 18599 solver.cpp:237] Iteration 287250, loss = 0.980159
I0522 02:03:10.718772 18599 solver.cpp:253]     Train net output #0: loss = 0.980157 (* 1 = 0.980157 loss)
I0522 02:03:10.718788 18599 sgd_solver.cpp:106] Iteration 287250, lr = 0.0025
I0522 02:03:22.893833 18599 solver.cpp:237] Iteration 288000, loss = 1.07106
I0522 02:03:22.894026 18599 solver.cpp:253]     Train net output #0: loss = 1.07106 (* 1 = 1.07106 loss)
I0522 02:03:22.894042 18599 sgd_solver.cpp:106] Iteration 288000, lr = 0.0025
I0522 02:03:35.079332 18599 solver.cpp:237] Iteration 288750, loss = 1.34854
I0522 02:03:35.079368 18599 solver.cpp:253]     Train net output #0: loss = 1.34854 (* 1 = 1.34854 loss)
I0522 02:03:35.079385 18599 sgd_solver.cpp:106] Iteration 288750, lr = 0.0025
I0522 02:03:47.295624 18599 solver.cpp:237] Iteration 289500, loss = 1.05123
I0522 02:03:47.295671 18599 solver.cpp:253]     Train net output #0: loss = 1.05123 (* 1 = 1.05123 loss)
I0522 02:03:47.295688 18599 sgd_solver.cpp:106] Iteration 289500, lr = 0.0025
I0522 02:04:20.379339 18599 solver.cpp:237] Iteration 290250, loss = 0.998244
I0522 02:04:20.379542 18599 solver.cpp:253]     Train net output #0: loss = 0.998242 (* 1 = 0.998242 loss)
I0522 02:04:20.379557 18599 sgd_solver.cpp:106] Iteration 290250, lr = 0.0025
aprun: Apid 11243409: Caught signal Terminated, sending to application
*** Aborted at 1463897063 (unix time) try "date -d @1463897063" if you are using GNU date ***
aprun: Apid 11243409: Caught signal Terminated, sending to application
PC: @     0x2aaab7c724f0 __pthread_mutex_lock_internal
aprun: Apid 11243409: Caught signal Terminated, sending to application
*** SIGTERM (@0x48a4) received by PID 18599 (TID 0x2aaac746f900) from PID 18596; stack trace: ***
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab7c724f0 __pthread_mutex_lock_internal
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab91e3f86 (unknown)
=>> PBS: job killed: walltime 7214 exceeded limit 7200
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab91abffb cuTexRefSetMipmapFilterMode
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab499ea8f (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab499f555 (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab49957cf (unknown)
    @     0x2aaab49afa5d (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab48e4147 (unknown)
    @     0x2aaab48e42a3 (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab481cfcf (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab4819553 (unknown)
    @     0x2aaab474abaf cudnnConvolutionBackwardData_v3
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x62f9db caffe::CuDNNConvolutionLayer<>::Backward_gpu()
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x5f02f3 caffe::Net<>::BackwardFromTo()
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x5f033f caffe::Net<>::Backward()
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x5ca111 caffe::Solver<>::Step()
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11243409: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11243409: Caught signal Terminated, sending to application
