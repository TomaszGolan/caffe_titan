2811232
I0526 01:29:42.138752 27551 caffe.cpp:184] Using GPUs 0
I0526 01:29:42.562433 27551 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2142
test_interval: 4285
base_lr: 0.0025
display: 214
max_iter: 214280
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2142
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224.prototxt"
I0526 01:29:42.564401 27551 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224.prototxt
I0526 01:29:42.579852 27551 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 01:29:42.579916 27551 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 01:29:42.580296 27551 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 01:29:42.580505 27551 layer_factory.hpp:77] Creating layer data_hdf5
I0526 01:29:42.580541 27551 net.cpp:106] Creating Layer data_hdf5
I0526 01:29:42.580559 27551 net.cpp:411] data_hdf5 -> data
I0526 01:29:42.580593 27551 net.cpp:411] data_hdf5 -> label
I0526 01:29:42.580636 27551 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 01:29:42.582113 27551 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 01:29:42.584456 27551 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 01:30:04.148591 27551 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 01:30:04.153916 27551 net.cpp:150] Setting up data_hdf5
I0526 01:30:04.153957 27551 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0526 01:30:04.153975 27551 net.cpp:157] Top shape: 70 (70)
I0526 01:30:04.153987 27551 net.cpp:165] Memory required for data: 1778280
I0526 01:30:04.154006 27551 layer_factory.hpp:77] Creating layer conv1
I0526 01:30:04.154052 27551 net.cpp:106] Creating Layer conv1
I0526 01:30:04.154067 27551 net.cpp:454] conv1 <- data
I0526 01:30:04.154091 27551 net.cpp:411] conv1 -> conv1
I0526 01:30:05.687841 27551 net.cpp:150] Setting up conv1
I0526 01:30:05.687894 27551 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0526 01:30:05.687922 27551 net.cpp:165] Memory required for data: 21131880
I0526 01:30:05.687952 27551 layer_factory.hpp:77] Creating layer relu1
I0526 01:30:05.687974 27551 net.cpp:106] Creating Layer relu1
I0526 01:30:05.687994 27551 net.cpp:454] relu1 <- conv1
I0526 01:30:05.688030 27551 net.cpp:397] relu1 -> conv1 (in-place)
I0526 01:30:05.688562 27551 net.cpp:150] Setting up relu1
I0526 01:30:05.688586 27551 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0526 01:30:05.688599 27551 net.cpp:165] Memory required for data: 40485480
I0526 01:30:05.688616 27551 layer_factory.hpp:77] Creating layer pool1
I0526 01:30:05.688643 27551 net.cpp:106] Creating Layer pool1
I0526 01:30:05.688657 27551 net.cpp:454] pool1 <- conv1
I0526 01:30:05.688673 27551 net.cpp:411] pool1 -> pool1
I0526 01:30:05.688778 27551 net.cpp:150] Setting up pool1
I0526 01:30:05.688799 27551 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0526 01:30:05.688819 27551 net.cpp:165] Memory required for data: 50162280
I0526 01:30:05.688832 27551 layer_factory.hpp:77] Creating layer conv2
I0526 01:30:05.688856 27551 net.cpp:106] Creating Layer conv2
I0526 01:30:05.688869 27551 net.cpp:454] conv2 <- pool1
I0526 01:30:05.688889 27551 net.cpp:411] conv2 -> conv2
I0526 01:30:05.691630 27551 net.cpp:150] Setting up conv2
I0526 01:30:05.691661 27551 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0526 01:30:05.691678 27551 net.cpp:165] Memory required for data: 64072680
I0526 01:30:05.691705 27551 layer_factory.hpp:77] Creating layer relu2
I0526 01:30:05.691732 27551 net.cpp:106] Creating Layer relu2
I0526 01:30:05.691746 27551 net.cpp:454] relu2 <- conv2
I0526 01:30:05.691763 27551 net.cpp:397] relu2 -> conv2 (in-place)
I0526 01:30:05.692121 27551 net.cpp:150] Setting up relu2
I0526 01:30:05.692140 27551 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0526 01:30:05.692154 27551 net.cpp:165] Memory required for data: 77983080
I0526 01:30:05.692169 27551 layer_factory.hpp:77] Creating layer pool2
I0526 01:30:05.692193 27551 net.cpp:106] Creating Layer pool2
I0526 01:30:05.692206 27551 net.cpp:454] pool2 <- conv2
I0526 01:30:05.692222 27551 net.cpp:411] pool2 -> pool2
I0526 01:30:05.692318 27551 net.cpp:150] Setting up pool2
I0526 01:30:05.692339 27551 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0526 01:30:05.692358 27551 net.cpp:165] Memory required for data: 84938280
I0526 01:30:05.692370 27551 layer_factory.hpp:77] Creating layer conv3
I0526 01:30:05.692391 27551 net.cpp:106] Creating Layer conv3
I0526 01:30:05.692405 27551 net.cpp:454] conv3 <- pool2
I0526 01:30:05.692421 27551 net.cpp:411] conv3 -> conv3
I0526 01:30:05.694375 27551 net.cpp:150] Setting up conv3
I0526 01:30:05.694401 27551 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0526 01:30:05.694422 27551 net.cpp:165] Memory required for data: 92527400
I0526 01:30:05.694443 27551 layer_factory.hpp:77] Creating layer relu3
I0526 01:30:05.694466 27551 net.cpp:106] Creating Layer relu3
I0526 01:30:05.694489 27551 net.cpp:454] relu3 <- conv3
I0526 01:30:05.694504 27551 net.cpp:397] relu3 -> conv3 (in-place)
I0526 01:30:05.694991 27551 net.cpp:150] Setting up relu3
I0526 01:30:05.695015 27551 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0526 01:30:05.695029 27551 net.cpp:165] Memory required for data: 100116520
I0526 01:30:05.695044 27551 layer_factory.hpp:77] Creating layer pool3
I0526 01:30:05.695060 27551 net.cpp:106] Creating Layer pool3
I0526 01:30:05.695082 27551 net.cpp:454] pool3 <- conv3
I0526 01:30:05.695098 27551 net.cpp:411] pool3 -> pool3
I0526 01:30:05.695180 27551 net.cpp:150] Setting up pool3
I0526 01:30:05.695199 27551 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0526 01:30:05.695214 27551 net.cpp:165] Memory required for data: 103911080
I0526 01:30:05.695226 27551 layer_factory.hpp:77] Creating layer conv4
I0526 01:30:05.695253 27551 net.cpp:106] Creating Layer conv4
I0526 01:30:05.695266 27551 net.cpp:454] conv4 <- pool3
I0526 01:30:05.695283 27551 net.cpp:411] conv4 -> conv4
I0526 01:30:05.698096 27551 net.cpp:150] Setting up conv4
I0526 01:30:05.698128 27551 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0526 01:30:05.698143 27551 net.cpp:165] Memory required for data: 106451240
I0526 01:30:05.698163 27551 layer_factory.hpp:77] Creating layer relu4
I0526 01:30:05.698184 27551 net.cpp:106] Creating Layer relu4
I0526 01:30:05.698210 27551 net.cpp:454] relu4 <- conv4
I0526 01:30:05.698226 27551 net.cpp:397] relu4 -> conv4 (in-place)
I0526 01:30:05.698725 27551 net.cpp:150] Setting up relu4
I0526 01:30:05.698750 27551 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0526 01:30:05.698762 27551 net.cpp:165] Memory required for data: 108991400
I0526 01:30:05.698778 27551 layer_factory.hpp:77] Creating layer pool4
I0526 01:30:05.698794 27551 net.cpp:106] Creating Layer pool4
I0526 01:30:05.698817 27551 net.cpp:454] pool4 <- conv4
I0526 01:30:05.698833 27551 net.cpp:411] pool4 -> pool4
I0526 01:30:05.698909 27551 net.cpp:150] Setting up pool4
I0526 01:30:05.698937 27551 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0526 01:30:05.698951 27551 net.cpp:165] Memory required for data: 110261480
I0526 01:30:05.698966 27551 layer_factory.hpp:77] Creating layer ip1
I0526 01:30:05.698987 27551 net.cpp:106] Creating Layer ip1
I0526 01:30:05.699007 27551 net.cpp:454] ip1 <- pool4
I0526 01:30:05.699023 27551 net.cpp:411] ip1 -> ip1
I0526 01:30:05.714447 27551 net.cpp:150] Setting up ip1
I0526 01:30:05.714479 27551 net.cpp:157] Top shape: 70 196 (13720)
I0526 01:30:05.714501 27551 net.cpp:165] Memory required for data: 110316360
I0526 01:30:05.714529 27551 layer_factory.hpp:77] Creating layer relu5
I0526 01:30:05.714550 27551 net.cpp:106] Creating Layer relu5
I0526 01:30:05.714575 27551 net.cpp:454] relu5 <- ip1
I0526 01:30:05.714591 27551 net.cpp:397] relu5 -> ip1 (in-place)
I0526 01:30:05.714947 27551 net.cpp:150] Setting up relu5
I0526 01:30:05.714967 27551 net.cpp:157] Top shape: 70 196 (13720)
I0526 01:30:05.714980 27551 net.cpp:165] Memory required for data: 110371240
I0526 01:30:05.714996 27551 layer_factory.hpp:77] Creating layer drop1
I0526 01:30:05.715026 27551 net.cpp:106] Creating Layer drop1
I0526 01:30:05.715040 27551 net.cpp:454] drop1 <- ip1
I0526 01:30:05.715055 27551 net.cpp:397] drop1 -> ip1 (in-place)
I0526 01:30:05.715122 27551 net.cpp:150] Setting up drop1
I0526 01:30:05.715154 27551 net.cpp:157] Top shape: 70 196 (13720)
I0526 01:30:05.715168 27551 net.cpp:165] Memory required for data: 110426120
I0526 01:30:05.715183 27551 layer_factory.hpp:77] Creating layer ip2
I0526 01:30:05.715204 27551 net.cpp:106] Creating Layer ip2
I0526 01:30:05.715217 27551 net.cpp:454] ip2 <- ip1
I0526 01:30:05.715240 27551 net.cpp:411] ip2 -> ip2
I0526 01:30:05.715728 27551 net.cpp:150] Setting up ip2
I0526 01:30:05.715746 27551 net.cpp:157] Top shape: 70 98 (6860)
I0526 01:30:05.715759 27551 net.cpp:165] Memory required for data: 110453560
I0526 01:30:05.715780 27551 layer_factory.hpp:77] Creating layer relu6
I0526 01:30:05.715801 27551 net.cpp:106] Creating Layer relu6
I0526 01:30:05.715814 27551 net.cpp:454] relu6 <- ip2
I0526 01:30:05.715831 27551 net.cpp:397] relu6 -> ip2 (in-place)
I0526 01:30:05.716373 27551 net.cpp:150] Setting up relu6
I0526 01:30:05.716397 27551 net.cpp:157] Top shape: 70 98 (6860)
I0526 01:30:05.716410 27551 net.cpp:165] Memory required for data: 110481000
I0526 01:30:05.716426 27551 layer_factory.hpp:77] Creating layer drop2
I0526 01:30:05.716442 27551 net.cpp:106] Creating Layer drop2
I0526 01:30:05.716464 27551 net.cpp:454] drop2 <- ip2
I0526 01:30:05.716480 27551 net.cpp:397] drop2 -> ip2 (in-place)
I0526 01:30:05.716531 27551 net.cpp:150] Setting up drop2
I0526 01:30:05.716547 27551 net.cpp:157] Top shape: 70 98 (6860)
I0526 01:30:05.716567 27551 net.cpp:165] Memory required for data: 110508440
I0526 01:30:05.716581 27551 layer_factory.hpp:77] Creating layer ip3
I0526 01:30:05.716596 27551 net.cpp:106] Creating Layer ip3
I0526 01:30:05.716611 27551 net.cpp:454] ip3 <- ip2
I0526 01:30:05.716627 27551 net.cpp:411] ip3 -> ip3
I0526 01:30:05.716868 27551 net.cpp:150] Setting up ip3
I0526 01:30:05.716887 27551 net.cpp:157] Top shape: 70 11 (770)
I0526 01:30:05.716900 27551 net.cpp:165] Memory required for data: 110511520
I0526 01:30:05.716922 27551 layer_factory.hpp:77] Creating layer drop3
I0526 01:30:05.716943 27551 net.cpp:106] Creating Layer drop3
I0526 01:30:05.716956 27551 net.cpp:454] drop3 <- ip3
I0526 01:30:05.716971 27551 net.cpp:397] drop3 -> ip3 (in-place)
I0526 01:30:05.717027 27551 net.cpp:150] Setting up drop3
I0526 01:30:05.717047 27551 net.cpp:157] Top shape: 70 11 (770)
I0526 01:30:05.717067 27551 net.cpp:165] Memory required for data: 110514600
I0526 01:30:05.717079 27551 layer_factory.hpp:77] Creating layer loss
I0526 01:30:05.717103 27551 net.cpp:106] Creating Layer loss
I0526 01:30:05.717116 27551 net.cpp:454] loss <- ip3
I0526 01:30:05.717133 27551 net.cpp:454] loss <- label
I0526 01:30:05.717154 27551 net.cpp:411] loss -> loss
I0526 01:30:05.717175 27551 layer_factory.hpp:77] Creating layer loss
I0526 01:30:05.717833 27551 net.cpp:150] Setting up loss
I0526 01:30:05.717854 27551 net.cpp:157] Top shape: (1)
I0526 01:30:05.717870 27551 net.cpp:160]     with loss weight 1
I0526 01:30:05.717921 27551 net.cpp:165] Memory required for data: 110514604
I0526 01:30:05.717942 27551 net.cpp:226] loss needs backward computation.
I0526 01:30:05.717957 27551 net.cpp:226] drop3 needs backward computation.
I0526 01:30:05.717969 27551 net.cpp:226] ip3 needs backward computation.
I0526 01:30:05.717983 27551 net.cpp:226] drop2 needs backward computation.
I0526 01:30:05.717994 27551 net.cpp:226] relu6 needs backward computation.
I0526 01:30:05.718009 27551 net.cpp:226] ip2 needs backward computation.
I0526 01:30:05.718029 27551 net.cpp:226] drop1 needs backward computation.
I0526 01:30:05.718041 27551 net.cpp:226] relu5 needs backward computation.
I0526 01:30:05.718055 27551 net.cpp:226] ip1 needs backward computation.
I0526 01:30:05.718070 27551 net.cpp:226] pool4 needs backward computation.
I0526 01:30:05.718085 27551 net.cpp:226] relu4 needs backward computation.
I0526 01:30:05.718096 27551 net.cpp:226] conv4 needs backward computation.
I0526 01:30:05.718109 27551 net.cpp:226] pool3 needs backward computation.
I0526 01:30:05.718124 27551 net.cpp:226] relu3 needs backward computation.
I0526 01:30:05.718154 27551 net.cpp:226] conv3 needs backward computation.
I0526 01:30:05.718168 27551 net.cpp:226] pool2 needs backward computation.
I0526 01:30:05.718180 27551 net.cpp:226] relu2 needs backward computation.
I0526 01:30:05.718194 27551 net.cpp:226] conv2 needs backward computation.
I0526 01:30:05.718205 27551 net.cpp:226] pool1 needs backward computation.
I0526 01:30:05.718221 27551 net.cpp:226] relu1 needs backward computation.
I0526 01:30:05.718235 27551 net.cpp:226] conv1 needs backward computation.
I0526 01:30:05.718255 27551 net.cpp:228] data_hdf5 does not need backward computation.
I0526 01:30:05.718267 27551 net.cpp:270] This network produces output loss
I0526 01:30:05.718294 27551 net.cpp:283] Network initialization done.
I0526 01:30:05.720274 27551 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224.prototxt
I0526 01:30:05.720353 27551 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 01:30:05.720746 27551 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 01:30:05.720973 27551 layer_factory.hpp:77] Creating layer data_hdf5
I0526 01:30:05.720994 27551 net.cpp:106] Creating Layer data_hdf5
I0526 01:30:05.721010 27551 net.cpp:411] data_hdf5 -> data
I0526 01:30:05.721029 27551 net.cpp:411] data_hdf5 -> label
I0526 01:30:05.721050 27551 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 01:30:05.722321 27551 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 01:30:27.042826 27551 net.cpp:150] Setting up data_hdf5
I0526 01:30:27.042994 27551 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0526 01:30:27.043014 27551 net.cpp:157] Top shape: 70 (70)
I0526 01:30:27.043025 27551 net.cpp:165] Memory required for data: 1778280
I0526 01:30:27.043041 27551 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 01:30:27.043076 27551 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 01:30:27.043089 27551 net.cpp:454] label_data_hdf5_1_split <- label
I0526 01:30:27.043124 27551 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 01:30:27.043148 27551 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 01:30:27.043233 27551 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 01:30:27.043251 27551 net.cpp:157] Top shape: 70 (70)
I0526 01:30:27.043265 27551 net.cpp:157] Top shape: 70 (70)
I0526 01:30:27.043280 27551 net.cpp:165] Memory required for data: 1778840
I0526 01:30:27.043292 27551 layer_factory.hpp:77] Creating layer conv1
I0526 01:30:27.043324 27551 net.cpp:106] Creating Layer conv1
I0526 01:30:27.043337 27551 net.cpp:454] conv1 <- data
I0526 01:30:27.043354 27551 net.cpp:411] conv1 -> conv1
I0526 01:30:27.045320 27551 net.cpp:150] Setting up conv1
I0526 01:30:27.045346 27551 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0526 01:30:27.045358 27551 net.cpp:165] Memory required for data: 21132440
I0526 01:30:27.045385 27551 layer_factory.hpp:77] Creating layer relu1
I0526 01:30:27.045413 27551 net.cpp:106] Creating Layer relu1
I0526 01:30:27.045428 27551 net.cpp:454] relu1 <- conv1
I0526 01:30:27.045444 27551 net.cpp:397] relu1 -> conv1 (in-place)
I0526 01:30:27.045970 27551 net.cpp:150] Setting up relu1
I0526 01:30:27.045994 27551 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0526 01:30:27.046007 27551 net.cpp:165] Memory required for data: 40486040
I0526 01:30:27.046020 27551 layer_factory.hpp:77] Creating layer pool1
I0526 01:30:27.046051 27551 net.cpp:106] Creating Layer pool1
I0526 01:30:27.046063 27551 net.cpp:454] pool1 <- conv1
I0526 01:30:27.046080 27551 net.cpp:411] pool1 -> pool1
I0526 01:30:27.046169 27551 net.cpp:150] Setting up pool1
I0526 01:30:27.046186 27551 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0526 01:30:27.046200 27551 net.cpp:165] Memory required for data: 50162840
I0526 01:30:27.046221 27551 layer_factory.hpp:77] Creating layer conv2
I0526 01:30:27.046241 27551 net.cpp:106] Creating Layer conv2
I0526 01:30:27.046254 27551 net.cpp:454] conv2 <- pool1
I0526 01:30:27.046272 27551 net.cpp:411] conv2 -> conv2
I0526 01:30:27.048208 27551 net.cpp:150] Setting up conv2
I0526 01:30:27.048233 27551 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0526 01:30:27.048254 27551 net.cpp:165] Memory required for data: 64073240
I0526 01:30:27.048275 27551 layer_factory.hpp:77] Creating layer relu2
I0526 01:30:27.048295 27551 net.cpp:106] Creating Layer relu2
I0526 01:30:27.048316 27551 net.cpp:454] relu2 <- conv2
I0526 01:30:27.048332 27551 net.cpp:397] relu2 -> conv2 (in-place)
I0526 01:30:27.048681 27551 net.cpp:150] Setting up relu2
I0526 01:30:27.048701 27551 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0526 01:30:27.048713 27551 net.cpp:165] Memory required for data: 77983640
I0526 01:30:27.048738 27551 layer_factory.hpp:77] Creating layer pool2
I0526 01:30:27.048761 27551 net.cpp:106] Creating Layer pool2
I0526 01:30:27.048774 27551 net.cpp:454] pool2 <- conv2
I0526 01:30:27.048789 27551 net.cpp:411] pool2 -> pool2
I0526 01:30:27.048877 27551 net.cpp:150] Setting up pool2
I0526 01:30:27.048893 27551 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0526 01:30:27.048907 27551 net.cpp:165] Memory required for data: 84938840
I0526 01:30:27.048925 27551 layer_factory.hpp:77] Creating layer conv3
I0526 01:30:27.048949 27551 net.cpp:106] Creating Layer conv3
I0526 01:30:27.048961 27551 net.cpp:454] conv3 <- pool2
I0526 01:30:27.048979 27551 net.cpp:411] conv3 -> conv3
I0526 01:30:27.050987 27551 net.cpp:150] Setting up conv3
I0526 01:30:27.051012 27551 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0526 01:30:27.051031 27551 net.cpp:165] Memory required for data: 92527960
I0526 01:30:27.051070 27551 layer_factory.hpp:77] Creating layer relu3
I0526 01:30:27.051095 27551 net.cpp:106] Creating Layer relu3
I0526 01:30:27.051110 27551 net.cpp:454] relu3 <- conv3
I0526 01:30:27.051126 27551 net.cpp:397] relu3 -> conv3 (in-place)
I0526 01:30:27.051625 27551 net.cpp:150] Setting up relu3
I0526 01:30:27.051650 27551 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0526 01:30:27.051662 27551 net.cpp:165] Memory required for data: 100117080
I0526 01:30:27.051678 27551 layer_factory.hpp:77] Creating layer pool3
I0526 01:30:27.051702 27551 net.cpp:106] Creating Layer pool3
I0526 01:30:27.051717 27551 net.cpp:454] pool3 <- conv3
I0526 01:30:27.051733 27551 net.cpp:411] pool3 -> pool3
I0526 01:30:27.051817 27551 net.cpp:150] Setting up pool3
I0526 01:30:27.051836 27551 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0526 01:30:27.051851 27551 net.cpp:165] Memory required for data: 103911640
I0526 01:30:27.051862 27551 layer_factory.hpp:77] Creating layer conv4
I0526 01:30:27.051890 27551 net.cpp:106] Creating Layer conv4
I0526 01:30:27.051903 27551 net.cpp:454] conv4 <- pool3
I0526 01:30:27.051919 27551 net.cpp:411] conv4 -> conv4
I0526 01:30:27.054014 27551 net.cpp:150] Setting up conv4
I0526 01:30:27.054039 27551 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0526 01:30:27.054059 27551 net.cpp:165] Memory required for data: 106451800
I0526 01:30:27.054078 27551 layer_factory.hpp:77] Creating layer relu4
I0526 01:30:27.054098 27551 net.cpp:106] Creating Layer relu4
I0526 01:30:27.054111 27551 net.cpp:454] relu4 <- conv4
I0526 01:30:27.054136 27551 net.cpp:397] relu4 -> conv4 (in-place)
I0526 01:30:27.054623 27551 net.cpp:150] Setting up relu4
I0526 01:30:27.054647 27551 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0526 01:30:27.054661 27551 net.cpp:165] Memory required for data: 108991960
I0526 01:30:27.054677 27551 layer_factory.hpp:77] Creating layer pool4
I0526 01:30:27.054700 27551 net.cpp:106] Creating Layer pool4
I0526 01:30:27.054713 27551 net.cpp:454] pool4 <- conv4
I0526 01:30:27.054729 27551 net.cpp:411] pool4 -> pool4
I0526 01:30:27.054817 27551 net.cpp:150] Setting up pool4
I0526 01:30:27.054834 27551 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0526 01:30:27.054849 27551 net.cpp:165] Memory required for data: 110262040
I0526 01:30:27.054862 27551 layer_factory.hpp:77] Creating layer ip1
I0526 01:30:27.054886 27551 net.cpp:106] Creating Layer ip1
I0526 01:30:27.054899 27551 net.cpp:454] ip1 <- pool4
I0526 01:30:27.054922 27551 net.cpp:411] ip1 -> ip1
I0526 01:30:27.070289 27551 net.cpp:150] Setting up ip1
I0526 01:30:27.070322 27551 net.cpp:157] Top shape: 70 196 (13720)
I0526 01:30:27.070344 27551 net.cpp:165] Memory required for data: 110316920
I0526 01:30:27.070370 27551 layer_factory.hpp:77] Creating layer relu5
I0526 01:30:27.070392 27551 net.cpp:106] Creating Layer relu5
I0526 01:30:27.070417 27551 net.cpp:454] relu5 <- ip1
I0526 01:30:27.070435 27551 net.cpp:397] relu5 -> ip1 (in-place)
I0526 01:30:27.070799 27551 net.cpp:150] Setting up relu5
I0526 01:30:27.070821 27551 net.cpp:157] Top shape: 70 196 (13720)
I0526 01:30:27.070834 27551 net.cpp:165] Memory required for data: 110371800
I0526 01:30:27.070849 27551 layer_factory.hpp:77] Creating layer drop1
I0526 01:30:27.070878 27551 net.cpp:106] Creating Layer drop1
I0526 01:30:27.070893 27551 net.cpp:454] drop1 <- ip1
I0526 01:30:27.070909 27551 net.cpp:397] drop1 -> ip1 (in-place)
I0526 01:30:27.070969 27551 net.cpp:150] Setting up drop1
I0526 01:30:27.070986 27551 net.cpp:157] Top shape: 70 196 (13720)
I0526 01:30:27.070998 27551 net.cpp:165] Memory required for data: 110426680
I0526 01:30:27.071012 27551 layer_factory.hpp:77] Creating layer ip2
I0526 01:30:27.071032 27551 net.cpp:106] Creating Layer ip2
I0526 01:30:27.071043 27551 net.cpp:454] ip2 <- ip1
I0526 01:30:27.071066 27551 net.cpp:411] ip2 -> ip2
I0526 01:30:27.071565 27551 net.cpp:150] Setting up ip2
I0526 01:30:27.071585 27551 net.cpp:157] Top shape: 70 98 (6860)
I0526 01:30:27.071597 27551 net.cpp:165] Memory required for data: 110454120
I0526 01:30:27.071619 27551 layer_factory.hpp:77] Creating layer relu6
I0526 01:30:27.071653 27551 net.cpp:106] Creating Layer relu6
I0526 01:30:27.071666 27551 net.cpp:454] relu6 <- ip2
I0526 01:30:27.071682 27551 net.cpp:397] relu6 -> ip2 (in-place)
I0526 01:30:27.072243 27551 net.cpp:150] Setting up relu6
I0526 01:30:27.072268 27551 net.cpp:157] Top shape: 70 98 (6860)
I0526 01:30:27.072280 27551 net.cpp:165] Memory required for data: 110481560
I0526 01:30:27.072293 27551 layer_factory.hpp:77] Creating layer drop2
I0526 01:30:27.072314 27551 net.cpp:106] Creating Layer drop2
I0526 01:30:27.072335 27551 net.cpp:454] drop2 <- ip2
I0526 01:30:27.072351 27551 net.cpp:397] drop2 -> ip2 (in-place)
I0526 01:30:27.072403 27551 net.cpp:150] Setting up drop2
I0526 01:30:27.072427 27551 net.cpp:157] Top shape: 70 98 (6860)
I0526 01:30:27.072439 27551 net.cpp:165] Memory required for data: 110509000
I0526 01:30:27.072453 27551 layer_factory.hpp:77] Creating layer ip3
I0526 01:30:27.072468 27551 net.cpp:106] Creating Layer ip3
I0526 01:30:27.072484 27551 net.cpp:454] ip3 <- ip2
I0526 01:30:27.072507 27551 net.cpp:411] ip3 -> ip3
I0526 01:30:27.072756 27551 net.cpp:150] Setting up ip3
I0526 01:30:27.072773 27551 net.cpp:157] Top shape: 70 11 (770)
I0526 01:30:27.072787 27551 net.cpp:165] Memory required for data: 110512080
I0526 01:30:27.072808 27551 layer_factory.hpp:77] Creating layer drop3
I0526 01:30:27.072829 27551 net.cpp:106] Creating Layer drop3
I0526 01:30:27.072844 27551 net.cpp:454] drop3 <- ip3
I0526 01:30:27.072860 27551 net.cpp:397] drop3 -> ip3 (in-place)
I0526 01:30:27.072914 27551 net.cpp:150] Setting up drop3
I0526 01:30:27.072932 27551 net.cpp:157] Top shape: 70 11 (770)
I0526 01:30:27.072943 27551 net.cpp:165] Memory required for data: 110515160
I0526 01:30:27.072957 27551 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 01:30:27.072971 27551 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 01:30:27.072984 27551 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 01:30:27.073004 27551 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 01:30:27.073029 27551 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 01:30:27.073115 27551 net.cpp:150] Setting up ip3_drop3_0_split
I0526 01:30:27.073132 27551 net.cpp:157] Top shape: 70 11 (770)
I0526 01:30:27.073148 27551 net.cpp:157] Top shape: 70 11 (770)
I0526 01:30:27.073160 27551 net.cpp:165] Memory required for data: 110521320
I0526 01:30:27.073175 27551 layer_factory.hpp:77] Creating layer accuracy
I0526 01:30:27.073197 27551 net.cpp:106] Creating Layer accuracy
I0526 01:30:27.073217 27551 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 01:30:27.073231 27551 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 01:30:27.073248 27551 net.cpp:411] accuracy -> accuracy
I0526 01:30:27.073276 27551 net.cpp:150] Setting up accuracy
I0526 01:30:27.073297 27551 net.cpp:157] Top shape: (1)
I0526 01:30:27.073312 27551 net.cpp:165] Memory required for data: 110521324
I0526 01:30:27.073323 27551 layer_factory.hpp:77] Creating layer loss
I0526 01:30:27.073339 27551 net.cpp:106] Creating Layer loss
I0526 01:30:27.073353 27551 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 01:30:27.073369 27551 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 01:30:27.073390 27551 net.cpp:411] loss -> loss
I0526 01:30:27.073412 27551 layer_factory.hpp:77] Creating layer loss
I0526 01:30:27.073928 27551 net.cpp:150] Setting up loss
I0526 01:30:27.073948 27551 net.cpp:157] Top shape: (1)
I0526 01:30:27.073961 27551 net.cpp:160]     with loss weight 1
I0526 01:30:27.073984 27551 net.cpp:165] Memory required for data: 110521328
I0526 01:30:27.074005 27551 net.cpp:226] loss needs backward computation.
I0526 01:30:27.074019 27551 net.cpp:228] accuracy does not need backward computation.
I0526 01:30:27.074033 27551 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 01:30:27.074046 27551 net.cpp:226] drop3 needs backward computation.
I0526 01:30:27.074059 27551 net.cpp:226] ip3 needs backward computation.
I0526 01:30:27.074074 27551 net.cpp:226] drop2 needs backward computation.
I0526 01:30:27.074092 27551 net.cpp:226] relu6 needs backward computation.
I0526 01:30:27.074115 27551 net.cpp:226] ip2 needs backward computation.
I0526 01:30:27.074133 27551 net.cpp:226] drop1 needs backward computation.
I0526 01:30:27.074146 27551 net.cpp:226] relu5 needs backward computation.
I0526 01:30:27.074158 27551 net.cpp:226] ip1 needs backward computation.
I0526 01:30:27.074173 27551 net.cpp:226] pool4 needs backward computation.
I0526 01:30:27.074187 27551 net.cpp:226] relu4 needs backward computation.
I0526 01:30:27.074205 27551 net.cpp:226] conv4 needs backward computation.
I0526 01:30:27.074219 27551 net.cpp:226] pool3 needs backward computation.
I0526 01:30:27.074232 27551 net.cpp:226] relu3 needs backward computation.
I0526 01:30:27.074245 27551 net.cpp:226] conv3 needs backward computation.
I0526 01:30:27.074257 27551 net.cpp:226] pool2 needs backward computation.
I0526 01:30:27.074273 27551 net.cpp:226] relu2 needs backward computation.
I0526 01:30:27.074285 27551 net.cpp:226] conv2 needs backward computation.
I0526 01:30:27.074304 27551 net.cpp:226] pool1 needs backward computation.
I0526 01:30:27.074318 27551 net.cpp:226] relu1 needs backward computation.
I0526 01:30:27.074337 27551 net.cpp:226] conv1 needs backward computation.
I0526 01:30:27.074352 27551 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 01:30:27.074365 27551 net.cpp:228] data_hdf5 does not need backward computation.
I0526 01:30:27.074378 27551 net.cpp:270] This network produces output accuracy
I0526 01:30:27.074393 27551 net.cpp:270] This network produces output loss
I0526 01:30:27.074424 27551 net.cpp:283] Network initialization done.
I0526 01:30:27.074558 27551 solver.cpp:60] Solver scaffolding done.
I0526 01:30:27.075706 27551 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_102816.solverstate
I0526 01:30:27.281112 27551 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 01:30:27.286594 27551 caffe.cpp:212] Starting Optimization
I0526 01:30:27.286639 27551 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 01:30:27.286662 27551 solver.cpp:289] Learning Rate Policy: fixed
I0526 01:30:28.276840 27551 solver.cpp:341] Iteration 102840, Testing net (#0)
I0526 01:31:17.205904 27551 solver.cpp:409]     Test net output #0: accuracy = 0.897859
I0526 01:31:17.206069 27551 solver.cpp:409]     Test net output #1: loss = 0.318853 (* 1 = 0.318853 loss)
I0526 01:31:21.123201 27551 solver.cpp:237] Iteration 102934, loss = 1.08835
I0526 01:31:21.123239 27551 solver.cpp:253]     Train net output #0: loss = 1.08835 (* 1 = 1.08835 loss)
I0526 01:31:21.123255 27551 sgd_solver.cpp:106] Iteration 102934, lr = 0.0025
I0526 01:31:30.017555 27551 solver.cpp:237] Iteration 103148, loss = 1.27212
I0526 01:31:30.017601 27551 solver.cpp:253]     Train net output #0: loss = 1.27212 (* 1 = 1.27212 loss)
I0526 01:31:30.017618 27551 sgd_solver.cpp:106] Iteration 103148, lr = 0.0025
I0526 01:31:38.917112 27551 solver.cpp:237] Iteration 103362, loss = 1.21116
I0526 01:31:38.917148 27551 solver.cpp:253]     Train net output #0: loss = 1.21116 (* 1 = 1.21116 loss)
I0526 01:31:38.917167 27551 sgd_solver.cpp:106] Iteration 103362, lr = 0.0025
I0526 01:31:47.809718 27551 solver.cpp:237] Iteration 103576, loss = 1.16554
I0526 01:31:47.809859 27551 solver.cpp:253]     Train net output #0: loss = 1.16554 (* 1 = 1.16554 loss)
I0526 01:31:47.809876 27551 sgd_solver.cpp:106] Iteration 103576, lr = 0.0025
I0526 01:31:56.695679 27551 solver.cpp:237] Iteration 103790, loss = 1.32964
I0526 01:31:56.695727 27551 solver.cpp:253]     Train net output #0: loss = 1.32964 (* 1 = 1.32964 loss)
I0526 01:31:56.695745 27551 sgd_solver.cpp:106] Iteration 103790, lr = 0.0025
I0526 01:32:05.583581 27551 solver.cpp:237] Iteration 104004, loss = 1.14969
I0526 01:32:05.583619 27551 solver.cpp:253]     Train net output #0: loss = 1.14969 (* 1 = 1.14969 loss)
I0526 01:32:05.583636 27551 sgd_solver.cpp:106] Iteration 104004, lr = 0.0025
I0526 01:32:14.464668 27551 solver.cpp:237] Iteration 104218, loss = 1.2271
I0526 01:32:14.464725 27551 solver.cpp:253]     Train net output #0: loss = 1.2271 (* 1 = 1.2271 loss)
I0526 01:32:14.464745 27551 sgd_solver.cpp:106] Iteration 104218, lr = 0.0025
I0526 01:32:45.505434 27551 solver.cpp:237] Iteration 104432, loss = 0.955825
I0526 01:32:45.505599 27551 solver.cpp:253]     Train net output #0: loss = 0.955825 (* 1 = 0.955825 loss)
I0526 01:32:45.505617 27551 sgd_solver.cpp:106] Iteration 104432, lr = 0.0025
I0526 01:32:54.395273 27551 solver.cpp:237] Iteration 104646, loss = 1.07596
I0526 01:32:54.395310 27551 solver.cpp:253]     Train net output #0: loss = 1.07596 (* 1 = 1.07596 loss)
I0526 01:32:54.395329 27551 sgd_solver.cpp:106] Iteration 104646, lr = 0.0025
I0526 01:33:03.285225 27551 solver.cpp:237] Iteration 104860, loss = 1.01223
I0526 01:33:03.285261 27551 solver.cpp:253]     Train net output #0: loss = 1.01223 (* 1 = 1.01223 loss)
I0526 01:33:03.285280 27551 sgd_solver.cpp:106] Iteration 104860, lr = 0.0025
I0526 01:33:07.313088 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_104958.caffemodel
I0526 01:33:07.382491 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_104958.solverstate
I0526 01:33:12.249799 27551 solver.cpp:237] Iteration 105074, loss = 1.11118
I0526 01:33:12.249851 27551 solver.cpp:253]     Train net output #0: loss = 1.11118 (* 1 = 1.11118 loss)
I0526 01:33:12.249876 27551 sgd_solver.cpp:106] Iteration 105074, lr = 0.0025
I0526 01:33:21.140144 27551 solver.cpp:237] Iteration 105288, loss = 1.12826
I0526 01:33:21.140290 27551 solver.cpp:253]     Train net output #0: loss = 1.12826 (* 1 = 1.12826 loss)
I0526 01:33:21.140306 27551 sgd_solver.cpp:106] Iteration 105288, lr = 0.0025
I0526 01:33:30.035048 27551 solver.cpp:237] Iteration 105502, loss = 1.04893
I0526 01:33:30.035099 27551 solver.cpp:253]     Train net output #0: loss = 1.04893 (* 1 = 1.04893 loss)
I0526 01:33:30.035117 27551 sgd_solver.cpp:106] Iteration 105502, lr = 0.0025
I0526 01:34:01.074009 27551 solver.cpp:237] Iteration 105716, loss = 0.88883
I0526 01:34:01.074177 27551 solver.cpp:253]     Train net output #0: loss = 0.88883 (* 1 = 0.88883 loss)
I0526 01:34:01.074194 27551 sgd_solver.cpp:106] Iteration 105716, lr = 0.0025
I0526 01:34:09.971946 27551 solver.cpp:237] Iteration 105930, loss = 1.2631
I0526 01:34:09.971983 27551 solver.cpp:253]     Train net output #0: loss = 1.2631 (* 1 = 1.2631 loss)
I0526 01:34:09.972000 27551 sgd_solver.cpp:106] Iteration 105930, lr = 0.0025
I0526 01:34:18.869949 27551 solver.cpp:237] Iteration 106144, loss = 1.25218
I0526 01:34:18.870002 27551 solver.cpp:253]     Train net output #0: loss = 1.25218 (* 1 = 1.25218 loss)
I0526 01:34:18.870028 27551 sgd_solver.cpp:106] Iteration 106144, lr = 0.0025
I0526 01:34:27.762944 27551 solver.cpp:237] Iteration 106358, loss = 1.18571
I0526 01:34:27.762981 27551 solver.cpp:253]     Train net output #0: loss = 1.18571 (* 1 = 1.18571 loss)
I0526 01:34:27.763005 27551 sgd_solver.cpp:106] Iteration 106358, lr = 0.0025
I0526 01:34:36.664449 27551 solver.cpp:237] Iteration 106572, loss = 1.18255
I0526 01:34:36.664600 27551 solver.cpp:253]     Train net output #0: loss = 1.18255 (* 1 = 1.18255 loss)
I0526 01:34:36.664618 27551 sgd_solver.cpp:106] Iteration 106572, lr = 0.0025
I0526 01:34:45.566720 27551 solver.cpp:237] Iteration 106786, loss = 0.882179
I0526 01:34:45.566771 27551 solver.cpp:253]     Train net output #0: loss = 0.882179 (* 1 = 0.882179 loss)
I0526 01:34:45.566798 27551 sgd_solver.cpp:106] Iteration 106786, lr = 0.0025
I0526 01:34:54.467308 27551 solver.cpp:237] Iteration 107000, loss = 1.20488
I0526 01:34:54.467345 27551 solver.cpp:253]     Train net output #0: loss = 1.20488 (* 1 = 1.20488 loss)
I0526 01:34:54.467365 27551 sgd_solver.cpp:106] Iteration 107000, lr = 0.0025
I0526 01:34:58.583493 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_107100.caffemodel
I0526 01:34:58.652371 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_107100.solverstate
I0526 01:35:21.880817 27551 solver.cpp:341] Iteration 107125, Testing net (#0)
I0526 01:36:09.843390 27551 solver.cpp:409]     Test net output #0: accuracy = 0.896292
I0526 01:36:09.843554 27551 solver.cpp:409]     Test net output #1: loss = 0.328106 (* 1 = 0.328106 loss)
I0526 01:36:13.550148 27551 solver.cpp:237] Iteration 107214, loss = 1.24732
I0526 01:36:13.550184 27551 solver.cpp:253]     Train net output #0: loss = 1.24732 (* 1 = 1.24732 loss)
I0526 01:36:13.550201 27551 sgd_solver.cpp:106] Iteration 107214, lr = 0.0025
I0526 01:36:22.441478 27551 solver.cpp:237] Iteration 107428, loss = 1.33484
I0526 01:36:22.441514 27551 solver.cpp:253]     Train net output #0: loss = 1.33484 (* 1 = 1.33484 loss)
I0526 01:36:22.441539 27551 sgd_solver.cpp:106] Iteration 107428, lr = 0.0025
I0526 01:36:31.321230 27551 solver.cpp:237] Iteration 107642, loss = 1.1507
I0526 01:36:31.321280 27551 solver.cpp:253]     Train net output #0: loss = 1.1507 (* 1 = 1.1507 loss)
I0526 01:36:31.321306 27551 sgd_solver.cpp:106] Iteration 107642, lr = 0.0025
I0526 01:36:40.202473 27551 solver.cpp:237] Iteration 107856, loss = 0.981111
I0526 01:36:40.202618 27551 solver.cpp:253]     Train net output #0: loss = 0.981111 (* 1 = 0.981111 loss)
I0526 01:36:40.202636 27551 sgd_solver.cpp:106] Iteration 107856, lr = 0.0025
I0526 01:36:49.077339 27551 solver.cpp:237] Iteration 108070, loss = 1.07045
I0526 01:36:49.077394 27551 solver.cpp:253]     Train net output #0: loss = 1.07045 (* 1 = 1.07045 loss)
I0526 01:36:49.077419 27551 sgd_solver.cpp:106] Iteration 108070, lr = 0.0025
I0526 01:36:57.952042 27551 solver.cpp:237] Iteration 108284, loss = 1.12789
I0526 01:36:57.952080 27551 solver.cpp:253]     Train net output #0: loss = 1.12789 (* 1 = 1.12789 loss)
I0526 01:36:57.952098 27551 sgd_solver.cpp:106] Iteration 108284, lr = 0.0025
I0526 01:37:06.829759 27551 solver.cpp:237] Iteration 108498, loss = 0.995431
I0526 01:37:06.829795 27551 solver.cpp:253]     Train net output #0: loss = 0.995431 (* 1 = 0.995431 loss)
I0526 01:37:06.829814 27551 sgd_solver.cpp:106] Iteration 108498, lr = 0.0025
I0526 01:37:37.933908 27551 solver.cpp:237] Iteration 108712, loss = 1.12389
I0526 01:37:37.934082 27551 solver.cpp:253]     Train net output #0: loss = 1.12389 (* 1 = 1.12389 loss)
I0526 01:37:37.934099 27551 sgd_solver.cpp:106] Iteration 108712, lr = 0.0025
I0526 01:37:46.811825 27551 solver.cpp:237] Iteration 108926, loss = 1.07324
I0526 01:37:46.811877 27551 solver.cpp:253]     Train net output #0: loss = 1.07324 (* 1 = 1.07324 loss)
I0526 01:37:46.811902 27551 sgd_solver.cpp:106] Iteration 108926, lr = 0.0025
I0526 01:37:55.687971 27551 solver.cpp:237] Iteration 109140, loss = 1.23338
I0526 01:37:55.688010 27551 solver.cpp:253]     Train net output #0: loss = 1.23338 (* 1 = 1.23338 loss)
I0526 01:37:55.688026 27551 sgd_solver.cpp:106] Iteration 109140, lr = 0.0025
I0526 01:37:59.876731 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_109242.caffemodel
I0526 01:37:59.946264 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_109242.solverstate
I0526 01:38:04.631047 27551 solver.cpp:237] Iteration 109354, loss = 1.11464
I0526 01:38:04.631099 27551 solver.cpp:253]     Train net output #0: loss = 1.11464 (* 1 = 1.11464 loss)
I0526 01:38:04.631117 27551 sgd_solver.cpp:106] Iteration 109354, lr = 0.0025
I0526 01:38:13.510745 27551 solver.cpp:237] Iteration 109568, loss = 1.0824
I0526 01:38:13.510893 27551 solver.cpp:253]     Train net output #0: loss = 1.0824 (* 1 = 1.0824 loss)
I0526 01:38:13.510910 27551 sgd_solver.cpp:106] Iteration 109568, lr = 0.0025
I0526 01:38:22.381222 27551 solver.cpp:237] Iteration 109782, loss = 0.950187
I0526 01:38:22.381261 27551 solver.cpp:253]     Train net output #0: loss = 0.950187 (* 1 = 0.950187 loss)
I0526 01:38:22.381278 27551 sgd_solver.cpp:106] Iteration 109782, lr = 0.0025
I0526 01:38:53.451243 27551 solver.cpp:237] Iteration 109996, loss = 1.16613
I0526 01:38:53.451407 27551 solver.cpp:253]     Train net output #0: loss = 1.16613 (* 1 = 1.16613 loss)
I0526 01:38:53.451424 27551 sgd_solver.cpp:106] Iteration 109996, lr = 0.0025
I0526 01:39:02.329648 27551 solver.cpp:237] Iteration 110210, loss = 1.03475
I0526 01:39:02.329685 27551 solver.cpp:253]     Train net output #0: loss = 1.03475 (* 1 = 1.03475 loss)
I0526 01:39:02.329704 27551 sgd_solver.cpp:106] Iteration 110210, lr = 0.0025
I0526 01:39:11.208825 27551 solver.cpp:237] Iteration 110424, loss = 1.08368
I0526 01:39:11.208861 27551 solver.cpp:253]     Train net output #0: loss = 1.08368 (* 1 = 1.08368 loss)
I0526 01:39:11.208880 27551 sgd_solver.cpp:106] Iteration 110424, lr = 0.0025
I0526 01:39:20.085455 27551 solver.cpp:237] Iteration 110638, loss = 0.960059
I0526 01:39:20.085510 27551 solver.cpp:253]     Train net output #0: loss = 0.960059 (* 1 = 0.960059 loss)
I0526 01:39:20.085536 27551 sgd_solver.cpp:106] Iteration 110638, lr = 0.0025
I0526 01:39:28.976099 27551 solver.cpp:237] Iteration 110852, loss = 1.14514
I0526 01:39:28.976244 27551 solver.cpp:253]     Train net output #0: loss = 1.14514 (* 1 = 1.14514 loss)
I0526 01:39:28.976261 27551 sgd_solver.cpp:106] Iteration 110852, lr = 0.0025
I0526 01:39:37.863435 27551 solver.cpp:237] Iteration 111066, loss = 1.42957
I0526 01:39:37.863472 27551 solver.cpp:253]     Train net output #0: loss = 1.42957 (* 1 = 1.42957 loss)
I0526 01:39:37.863495 27551 sgd_solver.cpp:106] Iteration 111066, lr = 0.0025
I0526 01:39:46.759016 27551 solver.cpp:237] Iteration 111280, loss = 1.01103
I0526 01:39:46.759066 27551 solver.cpp:253]     Train net output #0: loss = 1.01103 (* 1 = 1.01103 loss)
I0526 01:39:46.759095 27551 sgd_solver.cpp:106] Iteration 111280, lr = 0.0025
I0526 01:39:51.042784 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_111384.caffemodel
I0526 01:39:51.111637 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_111384.solverstate
I0526 01:40:14.355646 27551 solver.cpp:341] Iteration 111410, Testing net (#0)
I0526 01:41:23.032546 27551 solver.cpp:409]     Test net output #0: accuracy = 0.895445
I0526 01:41:23.032711 27551 solver.cpp:409]     Test net output #1: loss = 0.331257 (* 1 = 0.331257 loss)
I0526 01:41:26.545919 27551 solver.cpp:237] Iteration 111494, loss = 1.11452
I0526 01:41:26.545974 27551 solver.cpp:253]     Train net output #0: loss = 1.11452 (* 1 = 1.11452 loss)
I0526 01:41:26.545992 27551 sgd_solver.cpp:106] Iteration 111494, lr = 0.0025
I0526 01:41:35.451319 27551 solver.cpp:237] Iteration 111708, loss = 1.04148
I0526 01:41:35.451356 27551 solver.cpp:253]     Train net output #0: loss = 1.04148 (* 1 = 1.04148 loss)
I0526 01:41:35.451380 27551 sgd_solver.cpp:106] Iteration 111708, lr = 0.0025
I0526 01:41:44.356485 27551 solver.cpp:237] Iteration 111922, loss = 1.28847
I0526 01:41:44.356521 27551 solver.cpp:253]     Train net output #0: loss = 1.28847 (* 1 = 1.28847 loss)
I0526 01:41:44.356545 27551 sgd_solver.cpp:106] Iteration 111922, lr = 0.0025
I0526 01:41:53.268405 27551 solver.cpp:237] Iteration 112136, loss = 1.02787
I0526 01:41:53.268568 27551 solver.cpp:253]     Train net output #0: loss = 1.02787 (* 1 = 1.02787 loss)
I0526 01:41:53.268584 27551 sgd_solver.cpp:106] Iteration 112136, lr = 0.0025
I0526 01:42:02.172122 27551 solver.cpp:237] Iteration 112350, loss = 0.95399
I0526 01:42:02.172158 27551 solver.cpp:253]     Train net output #0: loss = 0.95399 (* 1 = 0.95399 loss)
I0526 01:42:02.172178 27551 sgd_solver.cpp:106] Iteration 112350, lr = 0.0025
I0526 01:42:11.079478 27551 solver.cpp:237] Iteration 112564, loss = 1.06488
I0526 01:42:11.079514 27551 solver.cpp:253]     Train net output #0: loss = 1.06488 (* 1 = 1.06488 loss)
I0526 01:42:11.079531 27551 sgd_solver.cpp:106] Iteration 112564, lr = 0.0025
I0526 01:42:19.994376 27551 solver.cpp:237] Iteration 112778, loss = 1.13665
I0526 01:42:19.994427 27551 solver.cpp:253]     Train net output #0: loss = 1.13665 (* 1 = 1.13665 loss)
I0526 01:42:19.994452 27551 sgd_solver.cpp:106] Iteration 112778, lr = 0.0025
I0526 01:42:51.025923 27551 solver.cpp:237] Iteration 112992, loss = 1.00473
I0526 01:42:51.026083 27551 solver.cpp:253]     Train net output #0: loss = 1.00473 (* 1 = 1.00473 loss)
I0526 01:42:51.026100 27551 sgd_solver.cpp:106] Iteration 112992, lr = 0.0025
I0526 01:42:59.930979 27551 solver.cpp:237] Iteration 113206, loss = 1.20136
I0526 01:42:59.931017 27551 solver.cpp:253]     Train net output #0: loss = 1.20136 (* 1 = 1.20136 loss)
I0526 01:42:59.931035 27551 sgd_solver.cpp:106] Iteration 113206, lr = 0.0025
I0526 01:43:08.852497 27551 solver.cpp:237] Iteration 113420, loss = 1.07176
I0526 01:43:08.852546 27551 solver.cpp:253]     Train net output #0: loss = 1.07176 (* 1 = 1.07176 loss)
I0526 01:43:08.852565 27551 sgd_solver.cpp:106] Iteration 113420, lr = 0.0025
I0526 01:43:13.226817 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_113526.caffemodel
I0526 01:43:13.295775 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_113526.solverstate
I0526 01:43:17.837939 27551 solver.cpp:237] Iteration 113634, loss = 1.28796
I0526 01:43:17.837988 27551 solver.cpp:253]     Train net output #0: loss = 1.28796 (* 1 = 1.28796 loss)
I0526 01:43:17.838016 27551 sgd_solver.cpp:106] Iteration 113634, lr = 0.0025
I0526 01:43:26.754050 27551 solver.cpp:237] Iteration 113848, loss = 1.17958
I0526 01:43:26.754199 27551 solver.cpp:253]     Train net output #0: loss = 1.17958 (* 1 = 1.17958 loss)
I0526 01:43:26.754216 27551 sgd_solver.cpp:106] Iteration 113848, lr = 0.0025
I0526 01:43:35.678561 27551 solver.cpp:237] Iteration 114062, loss = 0.905209
I0526 01:43:35.678614 27551 solver.cpp:253]     Train net output #0: loss = 0.905209 (* 1 = 0.905209 loss)
I0526 01:43:35.678642 27551 sgd_solver.cpp:106] Iteration 114062, lr = 0.0025
I0526 01:44:06.778885 27551 solver.cpp:237] Iteration 114276, loss = 1.31796
I0526 01:44:06.779062 27551 solver.cpp:253]     Train net output #0: loss = 1.31796 (* 1 = 1.31796 loss)
I0526 01:44:06.779080 27551 sgd_solver.cpp:106] Iteration 114276, lr = 0.0025
I0526 01:44:15.690740 27551 solver.cpp:237] Iteration 114490, loss = 1.13511
I0526 01:44:15.690778 27551 solver.cpp:253]     Train net output #0: loss = 1.13511 (* 1 = 1.13511 loss)
I0526 01:44:15.690795 27551 sgd_solver.cpp:106] Iteration 114490, lr = 0.0025
I0526 01:44:24.609978 27551 solver.cpp:237] Iteration 114704, loss = 1.02902
I0526 01:44:24.610029 27551 solver.cpp:253]     Train net output #0: loss = 1.02902 (* 1 = 1.02902 loss)
I0526 01:44:24.610057 27551 sgd_solver.cpp:106] Iteration 114704, lr = 0.0025
I0526 01:44:33.531661 27551 solver.cpp:237] Iteration 114918, loss = 1.18254
I0526 01:44:33.531699 27551 solver.cpp:253]     Train net output #0: loss = 1.18254 (* 1 = 1.18254 loss)
I0526 01:44:33.531716 27551 sgd_solver.cpp:106] Iteration 114918, lr = 0.0025
I0526 01:44:42.450137 27551 solver.cpp:237] Iteration 115132, loss = 1.12927
I0526 01:44:42.450284 27551 solver.cpp:253]     Train net output #0: loss = 1.12927 (* 1 = 1.12927 loss)
I0526 01:44:42.450300 27551 sgd_solver.cpp:106] Iteration 115132, lr = 0.0025
I0526 01:44:51.361600 27551 solver.cpp:237] Iteration 115346, loss = 1.00191
I0526 01:44:51.361649 27551 solver.cpp:253]     Train net output #0: loss = 1.00191 (* 1 = 1.00191 loss)
I0526 01:44:51.361677 27551 sgd_solver.cpp:106] Iteration 115346, lr = 0.0025
I0526 01:45:00.273586 27551 solver.cpp:237] Iteration 115560, loss = 1.13053
I0526 01:45:00.273625 27551 solver.cpp:253]     Train net output #0: loss = 1.13053 (* 1 = 1.13053 loss)
I0526 01:45:00.273643 27551 sgd_solver.cpp:106] Iteration 115560, lr = 0.0025
I0526 01:45:04.736423 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_115668.caffemodel
I0526 01:45:04.804064 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_115668.solverstate
I0526 01:45:28.036602 27551 solver.cpp:341] Iteration 115695, Testing net (#0)
I0526 01:46:15.662123 27551 solver.cpp:409]     Test net output #0: accuracy = 0.897399
I0526 01:46:15.662286 27551 solver.cpp:409]     Test net output #1: loss = 0.335582 (* 1 = 0.335582 loss)
I0526 01:46:18.953032 27551 solver.cpp:237] Iteration 115774, loss = 1.15143
I0526 01:46:18.953068 27551 solver.cpp:253]     Train net output #0: loss = 1.15143 (* 1 = 1.15143 loss)
I0526 01:46:18.953085 27551 sgd_solver.cpp:106] Iteration 115774, lr = 0.0025
I0526 01:46:27.839817 27551 solver.cpp:237] Iteration 115988, loss = 1.1038
I0526 01:46:27.839860 27551 solver.cpp:253]     Train net output #0: loss = 1.1038 (* 1 = 1.1038 loss)
I0526 01:46:27.839877 27551 sgd_solver.cpp:106] Iteration 115988, lr = 0.0025
I0526 01:46:36.725623 27551 solver.cpp:237] Iteration 116202, loss = 1.00765
I0526 01:46:36.725661 27551 solver.cpp:253]     Train net output #0: loss = 1.00765 (* 1 = 1.00765 loss)
I0526 01:46:36.725678 27551 sgd_solver.cpp:106] Iteration 116202, lr = 0.0025
I0526 01:46:45.615870 27551 solver.cpp:237] Iteration 116416, loss = 1.05073
I0526 01:46:45.615907 27551 solver.cpp:253]     Train net output #0: loss = 1.05073 (* 1 = 1.05073 loss)
I0526 01:46:45.615926 27551 sgd_solver.cpp:106] Iteration 116416, lr = 0.0025
I0526 01:46:54.500236 27551 solver.cpp:237] Iteration 116630, loss = 0.864772
I0526 01:46:54.500392 27551 solver.cpp:253]     Train net output #0: loss = 0.864772 (* 1 = 0.864772 loss)
I0526 01:46:54.500411 27551 sgd_solver.cpp:106] Iteration 116630, lr = 0.0025
I0526 01:47:03.388170 27551 solver.cpp:237] Iteration 116844, loss = 1.10109
I0526 01:47:03.388206 27551 solver.cpp:253]     Train net output #0: loss = 1.10109 (* 1 = 1.10109 loss)
I0526 01:47:03.388223 27551 sgd_solver.cpp:106] Iteration 116844, lr = 0.0025
I0526 01:47:12.275851 27551 solver.cpp:237] Iteration 117058, loss = 1.32824
I0526 01:47:12.275887 27551 solver.cpp:253]     Train net output #0: loss = 1.32824 (* 1 = 1.32824 loss)
I0526 01:47:12.275904 27551 sgd_solver.cpp:106] Iteration 117058, lr = 0.0025
I0526 01:47:43.316782 27551 solver.cpp:237] Iteration 117272, loss = 0.965847
I0526 01:47:43.316964 27551 solver.cpp:253]     Train net output #0: loss = 0.965847 (* 1 = 0.965847 loss)
I0526 01:47:43.316982 27551 sgd_solver.cpp:106] Iteration 117272, lr = 0.0025
I0526 01:47:52.209708 27551 solver.cpp:237] Iteration 117486, loss = 1.06796
I0526 01:47:52.209745 27551 solver.cpp:253]     Train net output #0: loss = 1.06796 (* 1 = 1.06796 loss)
I0526 01:47:52.209764 27551 sgd_solver.cpp:106] Iteration 117486, lr = 0.0025
I0526 01:48:01.092169 27551 solver.cpp:237] Iteration 117700, loss = 1.35124
I0526 01:48:01.092206 27551 solver.cpp:253]     Train net output #0: loss = 1.35124 (* 1 = 1.35124 loss)
I0526 01:48:01.092222 27551 sgd_solver.cpp:106] Iteration 117700, lr = 0.0025
I0526 01:48:05.621639 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_117810.caffemodel
I0526 01:48:05.687938 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_117810.solverstate
I0526 01:48:10.044833 27551 solver.cpp:237] Iteration 117914, loss = 1.00353
I0526 01:48:10.044884 27551 solver.cpp:253]     Train net output #0: loss = 1.00353 (* 1 = 1.00353 loss)
I0526 01:48:10.044914 27551 sgd_solver.cpp:106] Iteration 117914, lr = 0.0025
I0526 01:48:18.935979 27551 solver.cpp:237] Iteration 118128, loss = 1.06697
I0526 01:48:18.936130 27551 solver.cpp:253]     Train net output #0: loss = 1.06697 (* 1 = 1.06697 loss)
I0526 01:48:18.936146 27551 sgd_solver.cpp:106] Iteration 118128, lr = 0.0025
I0526 01:48:27.819763 27551 solver.cpp:237] Iteration 118342, loss = 0.896012
I0526 01:48:27.819802 27551 solver.cpp:253]     Train net output #0: loss = 0.896012 (* 1 = 0.896012 loss)
I0526 01:48:27.819818 27551 sgd_solver.cpp:106] Iteration 118342, lr = 0.0025
I0526 01:48:58.860142 27551 solver.cpp:237] Iteration 118556, loss = 1.09717
I0526 01:48:58.860314 27551 solver.cpp:253]     Train net output #0: loss = 1.09717 (* 1 = 1.09717 loss)
I0526 01:48:58.860332 27551 sgd_solver.cpp:106] Iteration 118556, lr = 0.0025
I0526 01:49:07.750648 27551 solver.cpp:237] Iteration 118770, loss = 1.15734
I0526 01:49:07.750684 27551 solver.cpp:253]     Train net output #0: loss = 1.15734 (* 1 = 1.15734 loss)
I0526 01:49:07.750704 27551 sgd_solver.cpp:106] Iteration 118770, lr = 0.0025
I0526 01:49:16.634418 27551 solver.cpp:237] Iteration 118984, loss = 1.11492
I0526 01:49:16.634455 27551 solver.cpp:253]     Train net output #0: loss = 1.11492 (* 1 = 1.11492 loss)
I0526 01:49:16.634474 27551 sgd_solver.cpp:106] Iteration 118984, lr = 0.0025
I0526 01:49:25.519274 27551 solver.cpp:237] Iteration 119198, loss = 1.05801
I0526 01:49:25.519317 27551 solver.cpp:253]     Train net output #0: loss = 1.05801 (* 1 = 1.05801 loss)
I0526 01:49:25.519335 27551 sgd_solver.cpp:106] Iteration 119198, lr = 0.0025
I0526 01:49:34.405396 27551 solver.cpp:237] Iteration 119412, loss = 1.02376
I0526 01:49:34.405544 27551 solver.cpp:253]     Train net output #0: loss = 1.02376 (* 1 = 1.02376 loss)
I0526 01:49:34.405560 27551 sgd_solver.cpp:106] Iteration 119412, lr = 0.0025
I0526 01:49:43.289981 27551 solver.cpp:237] Iteration 119626, loss = 1.23619
I0526 01:49:43.290017 27551 solver.cpp:253]     Train net output #0: loss = 1.23619 (* 1 = 1.23619 loss)
I0526 01:49:43.290040 27551 sgd_solver.cpp:106] Iteration 119626, lr = 0.0025
I0526 01:49:52.189851 27551 solver.cpp:237] Iteration 119840, loss = 1.20848
I0526 01:49:52.189888 27551 solver.cpp:253]     Train net output #0: loss = 1.20848 (* 1 = 1.20848 loss)
I0526 01:49:52.189904 27551 sgd_solver.cpp:106] Iteration 119840, lr = 0.0025
I0526 01:49:56.804855 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_119952.caffemodel
I0526 01:49:56.871074 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_119952.solverstate
I0526 01:50:20.172267 27551 solver.cpp:341] Iteration 119980, Testing net (#0)
I0526 01:51:28.982183 27551 solver.cpp:409]     Test net output #0: accuracy = 0.8991
I0526 01:51:28.982350 27551 solver.cpp:409]     Test net output #1: loss = 0.324933 (* 1 = 0.324933 loss)
I0526 01:51:32.065744 27551 solver.cpp:237] Iteration 120054, loss = 1.40203
I0526 01:51:32.065780 27551 solver.cpp:253]     Train net output #0: loss = 1.40203 (* 1 = 1.40203 loss)
I0526 01:51:32.065798 27551 sgd_solver.cpp:106] Iteration 120054, lr = 0.0025
I0526 01:51:40.947289 27551 solver.cpp:237] Iteration 120268, loss = 1.19515
I0526 01:51:40.947324 27551 solver.cpp:253]     Train net output #0: loss = 1.19515 (* 1 = 1.19515 loss)
I0526 01:51:40.947348 27551 sgd_solver.cpp:106] Iteration 120268, lr = 0.0025
I0526 01:51:49.828781 27551 solver.cpp:237] Iteration 120482, loss = 1.09168
I0526 01:51:49.828835 27551 solver.cpp:253]     Train net output #0: loss = 1.09168 (* 1 = 1.09168 loss)
I0526 01:51:49.828861 27551 sgd_solver.cpp:106] Iteration 120482, lr = 0.0025
I0526 01:51:58.712688 27551 solver.cpp:237] Iteration 120696, loss = 1.1514
I0526 01:51:58.712731 27551 solver.cpp:253]     Train net output #0: loss = 1.1514 (* 1 = 1.1514 loss)
I0526 01:51:58.712748 27551 sgd_solver.cpp:106] Iteration 120696, lr = 0.0025
I0526 01:52:07.591786 27551 solver.cpp:237] Iteration 120910, loss = 1.01829
I0526 01:52:07.591936 27551 solver.cpp:253]     Train net output #0: loss = 1.01829 (* 1 = 1.01829 loss)
I0526 01:52:07.591953 27551 sgd_solver.cpp:106] Iteration 120910, lr = 0.0025
I0526 01:52:16.478679 27551 solver.cpp:237] Iteration 121124, loss = 1.08681
I0526 01:52:16.478734 27551 solver.cpp:253]     Train net output #0: loss = 1.08681 (* 1 = 1.08681 loss)
I0526 01:52:16.478757 27551 sgd_solver.cpp:106] Iteration 121124, lr = 0.0025
I0526 01:52:25.366778 27551 solver.cpp:237] Iteration 121338, loss = 1.27436
I0526 01:52:25.366816 27551 solver.cpp:253]     Train net output #0: loss = 1.27436 (* 1 = 1.27436 loss)
I0526 01:52:25.366833 27551 sgd_solver.cpp:106] Iteration 121338, lr = 0.0025
I0526 01:52:56.426367 27551 solver.cpp:237] Iteration 121552, loss = 0.992637
I0526 01:52:56.426539 27551 solver.cpp:253]     Train net output #0: loss = 0.992637 (* 1 = 0.992637 loss)
I0526 01:52:56.426556 27551 sgd_solver.cpp:106] Iteration 121552, lr = 0.0025
I0526 01:53:05.305299 27551 solver.cpp:237] Iteration 121766, loss = 1.02037
I0526 01:53:05.305351 27551 solver.cpp:253]     Train net output #0: loss = 1.02037 (* 1 = 1.02037 loss)
I0526 01:53:05.305379 27551 sgd_solver.cpp:106] Iteration 121766, lr = 0.0025
I0526 01:53:14.193064 27551 solver.cpp:237] Iteration 121980, loss = 0.979618
I0526 01:53:14.193100 27551 solver.cpp:253]     Train net output #0: loss = 0.979618 (* 1 = 0.979618 loss)
I0526 01:53:14.193120 27551 sgd_solver.cpp:106] Iteration 121980, lr = 0.0025
I0526 01:53:18.881855 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_122094.caffemodel
I0526 01:53:18.950670 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_122094.solverstate
I0526 01:53:23.143736 27551 solver.cpp:237] Iteration 122194, loss = 1.18408
I0526 01:53:23.143786 27551 solver.cpp:253]     Train net output #0: loss = 1.18408 (* 1 = 1.18408 loss)
I0526 01:53:23.143815 27551 sgd_solver.cpp:106] Iteration 122194, lr = 0.0025
I0526 01:53:32.026185 27551 solver.cpp:237] Iteration 122408, loss = 1.27533
I0526 01:53:32.026365 27551 solver.cpp:253]     Train net output #0: loss = 1.27533 (* 1 = 1.27533 loss)
I0526 01:53:32.026383 27551 sgd_solver.cpp:106] Iteration 122408, lr = 0.0025
I0526 01:53:40.913846 27551 solver.cpp:237] Iteration 122622, loss = 1.06469
I0526 01:53:40.913883 27551 solver.cpp:253]     Train net output #0: loss = 1.06469 (* 1 = 1.06469 loss)
I0526 01:53:40.913900 27551 sgd_solver.cpp:106] Iteration 122622, lr = 0.0025
I0526 01:54:11.966470 27551 solver.cpp:237] Iteration 122836, loss = 1.14057
I0526 01:54:11.966650 27551 solver.cpp:253]     Train net output #0: loss = 1.14057 (* 1 = 1.14057 loss)
I0526 01:54:11.966667 27551 sgd_solver.cpp:106] Iteration 122836, lr = 0.0025
I0526 01:54:20.856186 27551 solver.cpp:237] Iteration 123050, loss = 1.21555
I0526 01:54:20.856233 27551 solver.cpp:253]     Train net output #0: loss = 1.21555 (* 1 = 1.21555 loss)
I0526 01:54:20.856251 27551 sgd_solver.cpp:106] Iteration 123050, lr = 0.0025
I0526 01:54:29.740289 27551 solver.cpp:237] Iteration 123264, loss = 1.39803
I0526 01:54:29.740326 27551 solver.cpp:253]     Train net output #0: loss = 1.39803 (* 1 = 1.39803 loss)
I0526 01:54:29.740344 27551 sgd_solver.cpp:106] Iteration 123264, lr = 0.0025
I0526 01:54:38.628705 27551 solver.cpp:237] Iteration 123478, loss = 1.09146
I0526 01:54:38.628746 27551 solver.cpp:253]     Train net output #0: loss = 1.09146 (* 1 = 1.09146 loss)
I0526 01:54:38.628770 27551 sgd_solver.cpp:106] Iteration 123478, lr = 0.0025
I0526 01:54:47.520457 27551 solver.cpp:237] Iteration 123692, loss = 1.32672
I0526 01:54:47.520618 27551 solver.cpp:253]     Train net output #0: loss = 1.32672 (* 1 = 1.32672 loss)
I0526 01:54:47.520637 27551 sgd_solver.cpp:106] Iteration 123692, lr = 0.0025
I0526 01:54:56.402143 27551 solver.cpp:237] Iteration 123906, loss = 1.10008
I0526 01:54:56.402179 27551 solver.cpp:253]     Train net output #0: loss = 1.10008 (* 1 = 1.10008 loss)
I0526 01:54:56.402197 27551 sgd_solver.cpp:106] Iteration 123906, lr = 0.0025
I0526 01:55:05.287587 27551 solver.cpp:237] Iteration 124120, loss = 1.08692
I0526 01:55:05.287624 27551 solver.cpp:253]     Train net output #0: loss = 1.08692 (* 1 = 1.08692 loss)
I0526 01:55:05.287642 27551 sgd_solver.cpp:106] Iteration 124120, lr = 0.0025
I0526 01:55:10.066967 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_124236.caffemodel
I0526 01:55:10.136184 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_124236.solverstate
I0526 01:55:32.226274 27551 solver.cpp:341] Iteration 124265, Testing net (#0)
I0526 01:56:20.153108 27551 solver.cpp:409]     Test net output #0: accuracy = 0.895998
I0526 01:56:20.153286 27551 solver.cpp:409]     Test net output #1: loss = 0.319507 (* 1 = 0.319507 loss)
I0526 01:56:23.031780 27551 solver.cpp:237] Iteration 124334, loss = 1.18826
I0526 01:56:23.031816 27551 solver.cpp:253]     Train net output #0: loss = 1.18826 (* 1 = 1.18826 loss)
I0526 01:56:23.031833 27551 sgd_solver.cpp:106] Iteration 124334, lr = 0.0025
I0526 01:56:31.918584 27551 solver.cpp:237] Iteration 124548, loss = 1.2671
I0526 01:56:31.918634 27551 solver.cpp:253]     Train net output #0: loss = 1.2671 (* 1 = 1.2671 loss)
I0526 01:56:31.918661 27551 sgd_solver.cpp:106] Iteration 124548, lr = 0.0025
I0526 01:56:40.806782 27551 solver.cpp:237] Iteration 124762, loss = 1.06046
I0526 01:56:40.806819 27551 solver.cpp:253]     Train net output #0: loss = 1.06046 (* 1 = 1.06046 loss)
I0526 01:56:40.806836 27551 sgd_solver.cpp:106] Iteration 124762, lr = 0.0025
I0526 01:56:49.704912 27551 solver.cpp:237] Iteration 124976, loss = 1.06105
I0526 01:56:49.704963 27551 solver.cpp:253]     Train net output #0: loss = 1.06105 (* 1 = 1.06105 loss)
I0526 01:56:49.704991 27551 sgd_solver.cpp:106] Iteration 124976, lr = 0.0025
I0526 01:56:58.600031 27551 solver.cpp:237] Iteration 125190, loss = 1.19465
I0526 01:56:58.600193 27551 solver.cpp:253]     Train net output #0: loss = 1.19465 (* 1 = 1.19465 loss)
I0526 01:56:58.600210 27551 sgd_solver.cpp:106] Iteration 125190, lr = 0.0025
I0526 01:57:07.495973 27551 solver.cpp:237] Iteration 125404, loss = 1.26758
I0526 01:57:07.496011 27551 solver.cpp:253]     Train net output #0: loss = 1.26758 (* 1 = 1.26758 loss)
I0526 01:57:07.496026 27551 sgd_solver.cpp:106] Iteration 125404, lr = 0.0025
I0526 01:57:16.389133 27551 solver.cpp:237] Iteration 125618, loss = 1.19431
I0526 01:57:16.389186 27551 solver.cpp:253]     Train net output #0: loss = 1.19431 (* 1 = 1.19431 loss)
I0526 01:57:16.389211 27551 sgd_solver.cpp:106] Iteration 125618, lr = 0.0025
I0526 01:57:46.131403 27551 solver.cpp:237] Iteration 125832, loss = 1.14115
I0526 01:57:46.131577 27551 solver.cpp:253]     Train net output #0: loss = 1.14115 (* 1 = 1.14115 loss)
I0526 01:57:46.131594 27551 sgd_solver.cpp:106] Iteration 125832, lr = 0.0025
I0526 01:57:55.029055 27551 solver.cpp:237] Iteration 126046, loss = 1.13898
I0526 01:57:55.029091 27551 solver.cpp:253]     Train net output #0: loss = 1.13898 (* 1 = 1.13898 loss)
I0526 01:57:55.029109 27551 sgd_solver.cpp:106] Iteration 126046, lr = 0.0025
I0526 01:58:03.933761 27551 solver.cpp:237] Iteration 126260, loss = 1.06431
I0526 01:58:03.933815 27551 solver.cpp:253]     Train net output #0: loss = 1.06431 (* 1 = 1.06431 loss)
I0526 01:58:03.933835 27551 sgd_solver.cpp:106] Iteration 126260, lr = 0.0025
I0526 01:58:08.801118 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_126378.caffemodel
I0526 01:58:08.867471 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_126378.solverstate
I0526 01:58:12.896998 27551 solver.cpp:237] Iteration 126474, loss = 1.33514
I0526 01:58:12.897049 27551 solver.cpp:253]     Train net output #0: loss = 1.33514 (* 1 = 1.33514 loss)
I0526 01:58:12.897068 27551 sgd_solver.cpp:106] Iteration 126474, lr = 0.0025
I0526 01:58:21.793846 27551 solver.cpp:237] Iteration 126688, loss = 1.12713
I0526 01:58:21.794000 27551 solver.cpp:253]     Train net output #0: loss = 1.12713 (* 1 = 1.12713 loss)
I0526 01:58:21.794018 27551 sgd_solver.cpp:106] Iteration 126688, lr = 0.0025
I0526 01:58:30.683938 27551 solver.cpp:237] Iteration 126902, loss = 0.975622
I0526 01:58:30.683993 27551 solver.cpp:253]     Train net output #0: loss = 0.975622 (* 1 = 0.975622 loss)
I0526 01:58:30.684018 27551 sgd_solver.cpp:106] Iteration 126902, lr = 0.0025
I0526 01:59:00.413774 27551 solver.cpp:237] Iteration 127116, loss = 1.2845
I0526 01:59:00.413946 27551 solver.cpp:253]     Train net output #0: loss = 1.2845 (* 1 = 1.2845 loss)
I0526 01:59:00.413964 27551 sgd_solver.cpp:106] Iteration 127116, lr = 0.0025
I0526 01:59:09.307056 27551 solver.cpp:237] Iteration 127330, loss = 1.07201
I0526 01:59:09.307093 27551 solver.cpp:253]     Train net output #0: loss = 1.07201 (* 1 = 1.07201 loss)
I0526 01:59:09.307112 27551 sgd_solver.cpp:106] Iteration 127330, lr = 0.0025
I0526 01:59:18.205365 27551 solver.cpp:237] Iteration 127544, loss = 1.31834
I0526 01:59:18.205401 27551 solver.cpp:253]     Train net output #0: loss = 1.31834 (* 1 = 1.31834 loss)
I0526 01:59:18.205420 27551 sgd_solver.cpp:106] Iteration 127544, lr = 0.0025
I0526 01:59:27.103600 27551 solver.cpp:237] Iteration 127758, loss = 1.10814
I0526 01:59:27.103649 27551 solver.cpp:253]     Train net output #0: loss = 1.10814 (* 1 = 1.10814 loss)
I0526 01:59:27.103673 27551 sgd_solver.cpp:106] Iteration 127758, lr = 0.0025
I0526 01:59:36.000737 27551 solver.cpp:237] Iteration 127972, loss = 1.07354
I0526 01:59:36.000901 27551 solver.cpp:253]     Train net output #0: loss = 1.07354 (* 1 = 1.07354 loss)
I0526 01:59:36.000918 27551 sgd_solver.cpp:106] Iteration 127972, lr = 0.0025
I0526 01:59:44.898360 27551 solver.cpp:237] Iteration 128186, loss = 1.16046
I0526 01:59:44.898409 27551 solver.cpp:253]     Train net output #0: loss = 1.16046 (* 1 = 1.16046 loss)
I0526 01:59:44.898427 27551 sgd_solver.cpp:106] Iteration 128186, lr = 0.0025
I0526 01:59:53.799680 27551 solver.cpp:237] Iteration 128400, loss = 0.813577
I0526 01:59:53.799718 27551 solver.cpp:253]     Train net output #0: loss = 0.813577 (* 1 = 0.813577 loss)
I0526 01:59:53.799736 27551 sgd_solver.cpp:106] Iteration 128400, lr = 0.0025
I0526 01:59:58.745750 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_128520.caffemodel
I0526 01:59:58.812170 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_128520.solverstate
I0526 02:00:20.888794 27551 solver.cpp:341] Iteration 128550, Testing net (#0)
I0526 02:01:29.637754 27551 solver.cpp:409]     Test net output #0: accuracy = 0.89932
I0526 02:01:29.637924 27551 solver.cpp:409]     Test net output #1: loss = 0.331947 (* 1 = 0.331947 loss)
I0526 02:01:32.307658 27551 solver.cpp:237] Iteration 128614, loss = 1.26948
I0526 02:01:32.307693 27551 solver.cpp:253]     Train net output #0: loss = 1.26948 (* 1 = 1.26948 loss)
I0526 02:01:32.307710 27551 sgd_solver.cpp:106] Iteration 128614, lr = 0.0025
I0526 02:01:41.203178 27551 solver.cpp:237] Iteration 128828, loss = 1.14354
I0526 02:01:41.203217 27551 solver.cpp:253]     Train net output #0: loss = 1.14354 (* 1 = 1.14354 loss)
I0526 02:01:41.203233 27551 sgd_solver.cpp:106] Iteration 128828, lr = 0.0025
I0526 02:01:50.095799 27551 solver.cpp:237] Iteration 129042, loss = 1.27111
I0526 02:01:50.095854 27551 solver.cpp:253]     Train net output #0: loss = 1.27111 (* 1 = 1.27111 loss)
I0526 02:01:50.095878 27551 sgd_solver.cpp:106] Iteration 129042, lr = 0.0025
I0526 02:01:58.987661 27551 solver.cpp:237] Iteration 129256, loss = 1.04484
I0526 02:01:58.987699 27551 solver.cpp:253]     Train net output #0: loss = 1.04484 (* 1 = 1.04484 loss)
I0526 02:01:58.987716 27551 sgd_solver.cpp:106] Iteration 129256, lr = 0.0025
I0526 02:02:07.883889 27551 solver.cpp:237] Iteration 129470, loss = 1.28299
I0526 02:02:07.884039 27551 solver.cpp:253]     Train net output #0: loss = 1.28299 (* 1 = 1.28299 loss)
I0526 02:02:07.884055 27551 sgd_solver.cpp:106] Iteration 129470, lr = 0.0025
I0526 02:02:16.775496 27551 solver.cpp:237] Iteration 129684, loss = 1.16785
I0526 02:02:16.775549 27551 solver.cpp:253]     Train net output #0: loss = 1.16785 (* 1 = 1.16785 loss)
I0526 02:02:16.775575 27551 sgd_solver.cpp:106] Iteration 129684, lr = 0.0025
I0526 02:02:25.673147 27551 solver.cpp:237] Iteration 129898, loss = 1.09291
I0526 02:02:25.673182 27551 solver.cpp:253]     Train net output #0: loss = 1.09291 (* 1 = 1.09291 loss)
I0526 02:02:25.673202 27551 sgd_solver.cpp:106] Iteration 129898, lr = 0.0025
I0526 02:02:55.407814 27551 solver.cpp:237] Iteration 130112, loss = 1.14083
I0526 02:02:55.407985 27551 solver.cpp:253]     Train net output #0: loss = 1.14083 (* 1 = 1.14083 loss)
I0526 02:02:55.408002 27551 sgd_solver.cpp:106] Iteration 130112, lr = 0.0025
I0526 02:03:04.302875 27551 solver.cpp:237] Iteration 130326, loss = 1.14586
I0526 02:03:04.302927 27551 solver.cpp:253]     Train net output #0: loss = 1.14586 (* 1 = 1.14586 loss)
I0526 02:03:04.302953 27551 sgd_solver.cpp:106] Iteration 130326, lr = 0.0025
I0526 02:03:13.199483 27551 solver.cpp:237] Iteration 130540, loss = 1.19025
I0526 02:03:13.199520 27551 solver.cpp:253]     Train net output #0: loss = 1.19025 (* 1 = 1.19025 loss)
I0526 02:03:13.199538 27551 sgd_solver.cpp:106] Iteration 130540, lr = 0.0025
I0526 02:03:18.235406 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_130662.caffemodel
I0526 02:03:18.305707 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_130662.solverstate
I0526 02:03:22.174197 27551 solver.cpp:237] Iteration 130754, loss = 1.00503
I0526 02:03:22.174248 27551 solver.cpp:253]     Train net output #0: loss = 1.00503 (* 1 = 1.00503 loss)
I0526 02:03:22.174273 27551 sgd_solver.cpp:106] Iteration 130754, lr = 0.0025
I0526 02:03:31.077508 27551 solver.cpp:237] Iteration 130968, loss = 1.0893
I0526 02:03:31.077692 27551 solver.cpp:253]     Train net output #0: loss = 1.0893 (* 1 = 1.0893 loss)
I0526 02:03:31.077713 27551 sgd_solver.cpp:106] Iteration 130968, lr = 0.0025
I0526 02:03:39.978540 27551 solver.cpp:237] Iteration 131182, loss = 1.20941
I0526 02:03:39.978577 27551 solver.cpp:253]     Train net output #0: loss = 1.20941 (* 1 = 1.20941 loss)
I0526 02:03:39.978595 27551 sgd_solver.cpp:106] Iteration 131182, lr = 0.0025
I0526 02:04:09.692657 27551 solver.cpp:237] Iteration 131396, loss = 1.03044
I0526 02:04:09.692845 27551 solver.cpp:253]     Train net output #0: loss = 1.03044 (* 1 = 1.03044 loss)
I0526 02:04:09.692862 27551 sgd_solver.cpp:106] Iteration 131396, lr = 0.0025
I0526 02:04:18.589565 27551 solver.cpp:237] Iteration 131610, loss = 0.8582
I0526 02:04:18.589617 27551 solver.cpp:253]     Train net output #0: loss = 0.8582 (* 1 = 0.8582 loss)
I0526 02:04:18.589643 27551 sgd_solver.cpp:106] Iteration 131610, lr = 0.0025
I0526 02:04:27.486500 27551 solver.cpp:237] Iteration 131824, loss = 1.3193
I0526 02:04:27.486537 27551 solver.cpp:253]     Train net output #0: loss = 1.3193 (* 1 = 1.3193 loss)
I0526 02:04:27.486554 27551 sgd_solver.cpp:106] Iteration 131824, lr = 0.0025
I0526 02:04:36.376179 27551 solver.cpp:237] Iteration 132038, loss = 1.19665
I0526 02:04:36.376215 27551 solver.cpp:253]     Train net output #0: loss = 1.19665 (* 1 = 1.19665 loss)
I0526 02:04:36.376235 27551 sgd_solver.cpp:106] Iteration 132038, lr = 0.0025
I0526 02:04:45.268988 27551 solver.cpp:237] Iteration 132252, loss = 1.15344
I0526 02:04:45.269155 27551 solver.cpp:253]     Train net output #0: loss = 1.15344 (* 1 = 1.15344 loss)
I0526 02:04:45.269172 27551 sgd_solver.cpp:106] Iteration 132252, lr = 0.0025
I0526 02:04:54.153664 27551 solver.cpp:237] Iteration 132466, loss = 1.03646
I0526 02:04:54.153699 27551 solver.cpp:253]     Train net output #0: loss = 1.03646 (* 1 = 1.03646 loss)
I0526 02:04:54.153718 27551 sgd_solver.cpp:106] Iteration 132466, lr = 0.0025
I0526 02:05:03.042295 27551 solver.cpp:237] Iteration 132680, loss = 1.06395
I0526 02:05:03.042331 27551 solver.cpp:253]     Train net output #0: loss = 1.06395 (* 1 = 1.06395 loss)
I0526 02:05:03.042349 27551 sgd_solver.cpp:106] Iteration 132680, lr = 0.0025
I0526 02:05:08.147673 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_132804.caffemodel
I0526 02:05:08.216279 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_132804.solverstate
I0526 02:05:30.317112 27551 solver.cpp:341] Iteration 132835, Testing net (#0)
I0526 02:06:17.881747 27551 solver.cpp:409]     Test net output #0: accuracy = 0.898546
I0526 02:06:17.881919 27551 solver.cpp:409]     Test net output #1: loss = 0.324496 (* 1 = 0.324496 loss)
I0526 02:06:20.343036 27551 solver.cpp:237] Iteration 132894, loss = 1.06147
I0526 02:06:20.343073 27551 solver.cpp:253]     Train net output #0: loss = 1.06147 (* 1 = 1.06147 loss)
I0526 02:06:20.343091 27551 sgd_solver.cpp:106] Iteration 132894, lr = 0.0025
I0526 02:06:29.225167 27551 solver.cpp:237] Iteration 133108, loss = 0.893688
I0526 02:06:29.225219 27551 solver.cpp:253]     Train net output #0: loss = 0.893688 (* 1 = 0.893688 loss)
I0526 02:06:29.225244 27551 sgd_solver.cpp:106] Iteration 133108, lr = 0.0025
I0526 02:06:38.101519 27551 solver.cpp:237] Iteration 133322, loss = 0.924455
I0526 02:06:38.101557 27551 solver.cpp:253]     Train net output #0: loss = 0.924455 (* 1 = 0.924455 loss)
I0526 02:06:38.101575 27551 sgd_solver.cpp:106] Iteration 133322, lr = 0.0025
I0526 02:06:46.986227 27551 solver.cpp:237] Iteration 133536, loss = 1.18081
I0526 02:06:46.986265 27551 solver.cpp:253]     Train net output #0: loss = 1.18081 (* 1 = 1.18081 loss)
I0526 02:06:46.986282 27551 sgd_solver.cpp:106] Iteration 133536, lr = 0.0025
I0526 02:06:55.866924 27551 solver.cpp:237] Iteration 133750, loss = 1.03715
I0526 02:06:55.867103 27551 solver.cpp:253]     Train net output #0: loss = 1.03715 (* 1 = 1.03715 loss)
I0526 02:06:55.867121 27551 sgd_solver.cpp:106] Iteration 133750, lr = 0.0025
I0526 02:07:04.754585 27551 solver.cpp:237] Iteration 133964, loss = 1.14429
I0526 02:07:04.754621 27551 solver.cpp:253]     Train net output #0: loss = 1.14429 (* 1 = 1.14429 loss)
I0526 02:07:04.754639 27551 sgd_solver.cpp:106] Iteration 133964, lr = 0.0025
I0526 02:07:13.636355 27551 solver.cpp:237] Iteration 134178, loss = 0.980715
I0526 02:07:13.636409 27551 solver.cpp:253]     Train net output #0: loss = 0.980715 (* 1 = 0.980715 loss)
I0526 02:07:13.636430 27551 sgd_solver.cpp:106] Iteration 134178, lr = 0.0025
I0526 02:07:43.370337 27551 solver.cpp:237] Iteration 134392, loss = 1.26395
I0526 02:07:43.370517 27551 solver.cpp:253]     Train net output #0: loss = 1.26395 (* 1 = 1.26395 loss)
I0526 02:07:43.370535 27551 sgd_solver.cpp:106] Iteration 134392, lr = 0.0025
I0526 02:07:52.249502 27551 solver.cpp:237] Iteration 134606, loss = 1.15343
I0526 02:07:52.249539 27551 solver.cpp:253]     Train net output #0: loss = 1.15343 (* 1 = 1.15343 loss)
I0526 02:07:52.249557 27551 sgd_solver.cpp:106] Iteration 134606, lr = 0.0025
I0526 02:08:01.130432 27551 solver.cpp:237] Iteration 134820, loss = 1.22045
I0526 02:08:01.130467 27551 solver.cpp:253]     Train net output #0: loss = 1.22045 (* 1 = 1.22045 loss)
I0526 02:08:01.130486 27551 sgd_solver.cpp:106] Iteration 134820, lr = 0.0025
I0526 02:08:06.320737 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_134946.caffemodel
I0526 02:08:06.389128 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_134946.solverstate
I0526 02:08:10.082063 27551 solver.cpp:237] Iteration 135034, loss = 0.835912
I0526 02:08:10.082118 27551 solver.cpp:253]     Train net output #0: loss = 0.835912 (* 1 = 0.835912 loss)
I0526 02:08:10.082136 27551 sgd_solver.cpp:106] Iteration 135034, lr = 0.0025
I0526 02:08:18.969867 27551 solver.cpp:237] Iteration 135248, loss = 1.12938
I0526 02:08:18.970037 27551 solver.cpp:253]     Train net output #0: loss = 1.12938 (* 1 = 1.12938 loss)
I0526 02:08:18.970054 27551 sgd_solver.cpp:106] Iteration 135248, lr = 0.0025
I0526 02:08:27.855084 27551 solver.cpp:237] Iteration 135462, loss = 1.1065
I0526 02:08:27.855123 27551 solver.cpp:253]     Train net output #0: loss = 1.1065 (* 1 = 1.1065 loss)
I0526 02:08:27.855139 27551 sgd_solver.cpp:106] Iteration 135462, lr = 0.0025
I0526 02:08:57.552508 27551 solver.cpp:237] Iteration 135676, loss = 1.13402
I0526 02:08:57.552687 27551 solver.cpp:253]     Train net output #0: loss = 1.13402 (* 1 = 1.13402 loss)
I0526 02:08:57.552706 27551 sgd_solver.cpp:106] Iteration 135676, lr = 0.0025
I0526 02:09:06.440942 27551 solver.cpp:237] Iteration 135890, loss = 1.17101
I0526 02:09:06.440979 27551 solver.cpp:253]     Train net output #0: loss = 1.17101 (* 1 = 1.17101 loss)
I0526 02:09:06.440995 27551 sgd_solver.cpp:106] Iteration 135890, lr = 0.0025
I0526 02:09:15.332700 27551 solver.cpp:237] Iteration 136104, loss = 1.2904
I0526 02:09:15.332743 27551 solver.cpp:253]     Train net output #0: loss = 1.2904 (* 1 = 1.2904 loss)
I0526 02:09:15.332764 27551 sgd_solver.cpp:106] Iteration 136104, lr = 0.0025
I0526 02:09:24.220698 27551 solver.cpp:237] Iteration 136318, loss = 1.00126
I0526 02:09:24.220757 27551 solver.cpp:253]     Train net output #0: loss = 1.00126 (* 1 = 1.00126 loss)
I0526 02:09:24.220783 27551 sgd_solver.cpp:106] Iteration 136318, lr = 0.0025
I0526 02:09:33.104424 27551 solver.cpp:237] Iteration 136532, loss = 1.1645
I0526 02:09:33.104590 27551 solver.cpp:253]     Train net output #0: loss = 1.1645 (* 1 = 1.1645 loss)
I0526 02:09:33.104607 27551 sgd_solver.cpp:106] Iteration 136532, lr = 0.0025
I0526 02:09:41.999963 27551 solver.cpp:237] Iteration 136746, loss = 1.16116
I0526 02:09:42.000000 27551 solver.cpp:253]     Train net output #0: loss = 1.16116 (* 1 = 1.16116 loss)
I0526 02:09:42.000018 27551 sgd_solver.cpp:106] Iteration 136746, lr = 0.0025
I0526 02:09:50.893645 27551 solver.cpp:237] Iteration 136960, loss = 1.10396
I0526 02:09:50.893694 27551 solver.cpp:253]     Train net output #0: loss = 1.10396 (* 1 = 1.10396 loss)
I0526 02:09:50.893714 27551 sgd_solver.cpp:106] Iteration 136960, lr = 0.0025
I0526 02:09:56.165603 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_137088.caffemodel
I0526 02:09:56.232661 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_137088.solverstate
I0526 02:10:18.406638 27551 solver.cpp:341] Iteration 137120, Testing net (#0)
I0526 02:11:27.104106 27551 solver.cpp:409]     Test net output #0: accuracy = 0.900347
I0526 02:11:27.104279 27551 solver.cpp:409]     Test net output #1: loss = 0.311051 (* 1 = 0.311051 loss)
I0526 02:11:29.367806 27551 solver.cpp:237] Iteration 137174, loss = 1.22004
I0526 02:11:29.367841 27551 solver.cpp:253]     Train net output #0: loss = 1.22004 (* 1 = 1.22004 loss)
I0526 02:11:29.367859 27551 sgd_solver.cpp:106] Iteration 137174, lr = 0.0025
I0526 02:11:38.292330 27551 solver.cpp:237] Iteration 137388, loss = 1.14852
I0526 02:11:38.292367 27551 solver.cpp:253]     Train net output #0: loss = 1.14852 (* 1 = 1.14852 loss)
I0526 02:11:38.292387 27551 sgd_solver.cpp:106] Iteration 137388, lr = 0.0025
I0526 02:11:47.213337 27551 solver.cpp:237] Iteration 137602, loss = 1.00903
I0526 02:11:47.213374 27551 solver.cpp:253]     Train net output #0: loss = 1.00903 (* 1 = 1.00903 loss)
I0526 02:11:47.213393 27551 sgd_solver.cpp:106] Iteration 137602, lr = 0.0025
I0526 02:11:56.137717 27551 solver.cpp:237] Iteration 137816, loss = 0.781588
I0526 02:11:56.137770 27551 solver.cpp:253]     Train net output #0: loss = 0.781588 (* 1 = 0.781588 loss)
I0526 02:11:56.137795 27551 sgd_solver.cpp:106] Iteration 137816, lr = 0.0025
I0526 02:12:05.061434 27551 solver.cpp:237] Iteration 138030, loss = 0.917359
I0526 02:12:05.061592 27551 solver.cpp:253]     Train net output #0: loss = 0.917359 (* 1 = 0.917359 loss)
I0526 02:12:05.061609 27551 sgd_solver.cpp:106] Iteration 138030, lr = 0.0025
I0526 02:12:13.986500 27551 solver.cpp:237] Iteration 138244, loss = 1.29744
I0526 02:12:13.986553 27551 solver.cpp:253]     Train net output #0: loss = 1.29744 (* 1 = 1.29744 loss)
I0526 02:12:13.986580 27551 sgd_solver.cpp:106] Iteration 138244, lr = 0.0025
I0526 02:12:22.907074 27551 solver.cpp:237] Iteration 138458, loss = 1.02008
I0526 02:12:22.907111 27551 solver.cpp:253]     Train net output #0: loss = 1.02008 (* 1 = 1.02008 loss)
I0526 02:12:22.907130 27551 sgd_solver.cpp:106] Iteration 138458, lr = 0.0025
I0526 02:12:52.613896 27551 solver.cpp:237] Iteration 138672, loss = 1.0813
I0526 02:12:52.614073 27551 solver.cpp:253]     Train net output #0: loss = 1.0813 (* 1 = 1.0813 loss)
I0526 02:12:52.614090 27551 sgd_solver.cpp:106] Iteration 138672, lr = 0.0025
I0526 02:13:01.532387 27551 solver.cpp:237] Iteration 138886, loss = 0.928465
I0526 02:13:01.532426 27551 solver.cpp:253]     Train net output #0: loss = 0.928465 (* 1 = 0.928465 loss)
I0526 02:13:01.532444 27551 sgd_solver.cpp:106] Iteration 138886, lr = 0.0025
I0526 02:13:10.458154 27551 solver.cpp:237] Iteration 139100, loss = 1.13716
I0526 02:13:10.458206 27551 solver.cpp:253]     Train net output #0: loss = 1.13716 (* 1 = 1.13716 loss)
I0526 02:13:10.458231 27551 sgd_solver.cpp:106] Iteration 139100, lr = 0.0025
I0526 02:13:15.835691 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_139230.caffemodel
I0526 02:13:15.902504 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_139230.solverstate
I0526 02:13:19.438794 27551 solver.cpp:237] Iteration 139314, loss = 1.16466
I0526 02:13:19.438844 27551 solver.cpp:253]     Train net output #0: loss = 1.16466 (* 1 = 1.16466 loss)
I0526 02:13:19.438870 27551 sgd_solver.cpp:106] Iteration 139314, lr = 0.0025
I0526 02:13:28.363025 27551 solver.cpp:237] Iteration 139528, loss = 1.18535
I0526 02:13:28.363212 27551 solver.cpp:253]     Train net output #0: loss = 1.18535 (* 1 = 1.18535 loss)
I0526 02:13:28.363230 27551 sgd_solver.cpp:106] Iteration 139528, lr = 0.0025
I0526 02:13:37.271708 27551 solver.cpp:237] Iteration 139742, loss = 1.21611
I0526 02:13:37.271744 27551 solver.cpp:253]     Train net output #0: loss = 1.21611 (* 1 = 1.21611 loss)
I0526 02:13:37.271764 27551 sgd_solver.cpp:106] Iteration 139742, lr = 0.0025
I0526 02:13:46.184109 27551 solver.cpp:237] Iteration 139956, loss = 1.12931
I0526 02:13:46.184146 27551 solver.cpp:253]     Train net output #0: loss = 1.12931 (* 1 = 1.12931 loss)
I0526 02:13:46.184165 27551 sgd_solver.cpp:106] Iteration 139956, lr = 0.0025
I0526 02:14:15.952220 27551 solver.cpp:237] Iteration 140170, loss = 0.96782
I0526 02:14:15.952397 27551 solver.cpp:253]     Train net output #0: loss = 0.96782 (* 1 = 0.96782 loss)
I0526 02:14:15.952415 27551 sgd_solver.cpp:106] Iteration 140170, lr = 0.0025
I0526 02:14:24.862926 27551 solver.cpp:237] Iteration 140384, loss = 1.23045
I0526 02:14:24.862979 27551 solver.cpp:253]     Train net output #0: loss = 1.23045 (* 1 = 1.23045 loss)
I0526 02:14:24.863004 27551 sgd_solver.cpp:106] Iteration 140384, lr = 0.0025
I0526 02:14:33.774431 27551 solver.cpp:237] Iteration 140598, loss = 1.07236
I0526 02:14:33.774469 27551 solver.cpp:253]     Train net output #0: loss = 1.07236 (* 1 = 1.07236 loss)
I0526 02:14:33.774485 27551 sgd_solver.cpp:106] Iteration 140598, lr = 0.0025
I0526 02:14:42.685762 27551 solver.cpp:237] Iteration 140812, loss = 1.13521
I0526 02:14:42.685798 27551 solver.cpp:253]     Train net output #0: loss = 1.13521 (* 1 = 1.13521 loss)
I0526 02:14:42.685817 27551 sgd_solver.cpp:106] Iteration 140812, lr = 0.0025
I0526 02:14:51.602380 27551 solver.cpp:237] Iteration 141026, loss = 1.24475
I0526 02:14:51.602552 27551 solver.cpp:253]     Train net output #0: loss = 1.24475 (* 1 = 1.24475 loss)
I0526 02:14:51.602572 27551 sgd_solver.cpp:106] Iteration 141026, lr = 0.0025
I0526 02:15:00.514407 27551 solver.cpp:237] Iteration 141240, loss = 1.06691
I0526 02:15:00.514446 27551 solver.cpp:253]     Train net output #0: loss = 1.06691 (* 1 = 1.06691 loss)
I0526 02:15:00.514462 27551 sgd_solver.cpp:106] Iteration 141240, lr = 0.0025
I0526 02:15:05.974298 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_141372.caffemodel
I0526 02:15:06.040637 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_141372.solverstate
I0526 02:15:28.251971 27551 solver.cpp:341] Iteration 141405, Testing net (#0)
I0526 02:16:16.222162 27551 solver.cpp:409]     Test net output #0: accuracy = 0.899487
I0526 02:16:16.222337 27551 solver.cpp:409]     Test net output #1: loss = 0.315653 (* 1 = 0.315653 loss)
I0526 02:16:18.267848 27551 solver.cpp:237] Iteration 141454, loss = 0.978786
I0526 02:16:18.267886 27551 solver.cpp:253]     Train net output #0: loss = 0.978786 (* 1 = 0.978786 loss)
I0526 02:16:18.267904 27551 sgd_solver.cpp:106] Iteration 141454, lr = 0.0025
I0526 02:16:27.145683 27551 solver.cpp:237] Iteration 141668, loss = 0.98748
I0526 02:16:27.145735 27551 solver.cpp:253]     Train net output #0: loss = 0.98748 (* 1 = 0.98748 loss)
I0526 02:16:27.145755 27551 sgd_solver.cpp:106] Iteration 141668, lr = 0.0025
I0526 02:16:36.020931 27551 solver.cpp:237] Iteration 141882, loss = 1.17752
I0526 02:16:36.020969 27551 solver.cpp:253]     Train net output #0: loss = 1.17752 (* 1 = 1.17752 loss)
I0526 02:16:36.020987 27551 sgd_solver.cpp:106] Iteration 141882, lr = 0.0025
I0526 02:16:44.896934 27551 solver.cpp:237] Iteration 142096, loss = 1.0435
I0526 02:16:44.896970 27551 solver.cpp:253]     Train net output #0: loss = 1.0435 (* 1 = 1.0435 loss)
I0526 02:16:44.896993 27551 sgd_solver.cpp:106] Iteration 142096, lr = 0.0025
I0526 02:16:53.776366 27551 solver.cpp:237] Iteration 142310, loss = 0.963116
I0526 02:16:53.776542 27551 solver.cpp:253]     Train net output #0: loss = 0.963116 (* 1 = 0.963116 loss)
I0526 02:16:53.776559 27551 sgd_solver.cpp:106] Iteration 142310, lr = 0.0025
I0526 02:17:02.649834 27551 solver.cpp:237] Iteration 142524, loss = 1.05277
I0526 02:17:02.649870 27551 solver.cpp:253]     Train net output #0: loss = 1.05277 (* 1 = 1.05277 loss)
I0526 02:17:02.649889 27551 sgd_solver.cpp:106] Iteration 142524, lr = 0.0025
I0526 02:17:11.531095 27551 solver.cpp:237] Iteration 142738, loss = 1.10191
I0526 02:17:11.531132 27551 solver.cpp:253]     Train net output #0: loss = 1.10191 (* 1 = 1.10191 loss)
I0526 02:17:11.531149 27551 sgd_solver.cpp:106] Iteration 142738, lr = 0.0025
I0526 02:17:41.224735 27551 solver.cpp:237] Iteration 142952, loss = 1.29402
I0526 02:17:41.224917 27551 solver.cpp:253]     Train net output #0: loss = 1.29402 (* 1 = 1.29402 loss)
I0526 02:17:41.224936 27551 sgd_solver.cpp:106] Iteration 142952, lr = 0.0025
I0526 02:17:50.106118 27551 solver.cpp:237] Iteration 143166, loss = 0.9568
I0526 02:17:50.106156 27551 solver.cpp:253]     Train net output #0: loss = 0.9568 (* 1 = 0.9568 loss)
I0526 02:17:50.106174 27551 sgd_solver.cpp:106] Iteration 143166, lr = 0.0025
I0526 02:17:58.990815 27551 solver.cpp:237] Iteration 143380, loss = 1.14852
I0526 02:17:58.990852 27551 solver.cpp:253]     Train net output #0: loss = 1.14852 (* 1 = 1.14852 loss)
I0526 02:17:58.990870 27551 sgd_solver.cpp:106] Iteration 143380, lr = 0.0025
I0526 02:18:04.514020 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_143514.caffemodel
I0526 02:18:04.581923 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_143514.solverstate
I0526 02:18:07.946436 27551 solver.cpp:237] Iteration 143594, loss = 1.29306
I0526 02:18:07.946487 27551 solver.cpp:253]     Train net output #0: loss = 1.29306 (* 1 = 1.29306 loss)
I0526 02:18:07.946514 27551 sgd_solver.cpp:106] Iteration 143594, lr = 0.0025
I0526 02:18:16.831310 27551 solver.cpp:237] Iteration 143808, loss = 1.24767
I0526 02:18:16.831481 27551 solver.cpp:253]     Train net output #0: loss = 1.24767 (* 1 = 1.24767 loss)
I0526 02:18:16.831498 27551 sgd_solver.cpp:106] Iteration 143808, lr = 0.0025
I0526 02:18:25.721910 27551 solver.cpp:237] Iteration 144022, loss = 1.25598
I0526 02:18:25.721948 27551 solver.cpp:253]     Train net output #0: loss = 1.25598 (* 1 = 1.25598 loss)
I0526 02:18:25.721966 27551 sgd_solver.cpp:106] Iteration 144022, lr = 0.0025
I0526 02:18:34.632580 27551 solver.cpp:237] Iteration 144236, loss = 1.0322
I0526 02:18:34.632632 27551 solver.cpp:253]     Train net output #0: loss = 1.0322 (* 1 = 1.0322 loss)
I0526 02:18:34.632661 27551 sgd_solver.cpp:106] Iteration 144236, lr = 0.0025
I0526 02:19:04.388375 27551 solver.cpp:237] Iteration 144450, loss = 1.14371
I0526 02:19:04.388568 27551 solver.cpp:253]     Train net output #0: loss = 1.14371 (* 1 = 1.14371 loss)
I0526 02:19:04.388586 27551 sgd_solver.cpp:106] Iteration 144450, lr = 0.0025
I0526 02:19:13.300451 27551 solver.cpp:237] Iteration 144664, loss = 1.24788
I0526 02:19:13.300487 27551 solver.cpp:253]     Train net output #0: loss = 1.24788 (* 1 = 1.24788 loss)
I0526 02:19:13.300506 27551 sgd_solver.cpp:106] Iteration 144664, lr = 0.0025
I0526 02:19:22.213001 27551 solver.cpp:237] Iteration 144878, loss = 1.13977
I0526 02:19:22.213053 27551 solver.cpp:253]     Train net output #0: loss = 1.13977 (* 1 = 1.13977 loss)
I0526 02:19:22.213080 27551 sgd_solver.cpp:106] Iteration 144878, lr = 0.0025
I0526 02:19:31.123044 27551 solver.cpp:237] Iteration 145092, loss = 0.998545
I0526 02:19:31.123081 27551 solver.cpp:253]     Train net output #0: loss = 0.998545 (* 1 = 0.998545 loss)
I0526 02:19:31.123100 27551 sgd_solver.cpp:106] Iteration 145092, lr = 0.0025
I0526 02:19:40.050848 27551 solver.cpp:237] Iteration 145306, loss = 1.06971
I0526 02:19:40.051009 27551 solver.cpp:253]     Train net output #0: loss = 1.06971 (* 1 = 1.06971 loss)
I0526 02:19:40.051026 27551 sgd_solver.cpp:106] Iteration 145306, lr = 0.0025
I0526 02:19:48.969540 27551 solver.cpp:237] Iteration 145520, loss = 0.979487
I0526 02:19:48.969594 27551 solver.cpp:253]     Train net output #0: loss = 0.979487 (* 1 = 0.979487 loss)
I0526 02:19:48.969619 27551 sgd_solver.cpp:106] Iteration 145520, lr = 0.0025
I0526 02:19:54.594442 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_145656.caffemodel
I0526 02:19:54.663076 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_145656.solverstate
I0526 02:20:16.955322 27551 solver.cpp:341] Iteration 145690, Testing net (#0)
I0526 02:21:25.703717 27551 solver.cpp:409]     Test net output #0: accuracy = 0.899533
I0526 02:21:25.703894 27551 solver.cpp:409]     Test net output #1: loss = 0.318751 (* 1 = 0.318751 loss)
I0526 02:21:27.542819 27551 solver.cpp:237] Iteration 145734, loss = 1.02693
I0526 02:21:27.542855 27551 solver.cpp:253]     Train net output #0: loss = 1.02693 (* 1 = 1.02693 loss)
I0526 02:21:27.542872 27551 sgd_solver.cpp:106] Iteration 145734, lr = 0.0025
I0526 02:21:36.440410 27551 solver.cpp:237] Iteration 145948, loss = 0.819586
I0526 02:21:36.440448 27551 solver.cpp:253]     Train net output #0: loss = 0.819586 (* 1 = 0.819586 loss)
I0526 02:21:36.440466 27551 sgd_solver.cpp:106] Iteration 145948, lr = 0.0025
I0526 02:21:45.325624 27551 solver.cpp:237] Iteration 146162, loss = 0.935178
I0526 02:21:45.325662 27551 solver.cpp:253]     Train net output #0: loss = 0.935178 (* 1 = 0.935178 loss)
I0526 02:21:45.325680 27551 sgd_solver.cpp:106] Iteration 146162, lr = 0.0025
I0526 02:21:54.217365 27551 solver.cpp:237] Iteration 146376, loss = 1.05226
I0526 02:21:54.217414 27551 solver.cpp:253]     Train net output #0: loss = 1.05226 (* 1 = 1.05226 loss)
I0526 02:21:54.217432 27551 sgd_solver.cpp:106] Iteration 146376, lr = 0.0025
I0526 02:22:03.103271 27551 solver.cpp:237] Iteration 146590, loss = 1.13796
I0526 02:22:03.103433 27551 solver.cpp:253]     Train net output #0: loss = 1.13796 (* 1 = 1.13796 loss)
I0526 02:22:03.103451 27551 sgd_solver.cpp:106] Iteration 146590, lr = 0.0025
I0526 02:22:11.985612 27551 solver.cpp:237] Iteration 146804, loss = 1.2409
I0526 02:22:11.985648 27551 solver.cpp:253]     Train net output #0: loss = 1.2409 (* 1 = 1.2409 loss)
I0526 02:22:11.985666 27551 sgd_solver.cpp:106] Iteration 146804, lr = 0.0025
I0526 02:22:20.880436 27551 solver.cpp:237] Iteration 147018, loss = 1.27082
I0526 02:22:20.880491 27551 solver.cpp:253]     Train net output #0: loss = 1.27082 (* 1 = 1.27082 loss)
I0526 02:22:20.880517 27551 sgd_solver.cpp:106] Iteration 147018, lr = 0.0025
I0526 02:22:50.570991 27551 solver.cpp:237] Iteration 147232, loss = 1.31339
I0526 02:22:50.571180 27551 solver.cpp:253]     Train net output #0: loss = 1.31339 (* 1 = 1.31339 loss)
I0526 02:22:50.571197 27551 sgd_solver.cpp:106] Iteration 147232, lr = 0.0025
I0526 02:22:59.460029 27551 solver.cpp:237] Iteration 147446, loss = 0.942101
I0526 02:22:59.460068 27551 solver.cpp:253]     Train net output #0: loss = 0.942101 (* 1 = 0.942101 loss)
I0526 02:22:59.460086 27551 sgd_solver.cpp:106] Iteration 147446, lr = 0.0025
I0526 02:23:08.355545 27551 solver.cpp:237] Iteration 147660, loss = 1.11138
I0526 02:23:08.355598 27551 solver.cpp:253]     Train net output #0: loss = 1.11138 (* 1 = 1.11138 loss)
I0526 02:23:08.355623 27551 sgd_solver.cpp:106] Iteration 147660, lr = 0.0025
I0526 02:23:14.043418 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_147798.caffemodel
I0526 02:23:14.110527 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_147798.solverstate
I0526 02:23:17.305718 27551 solver.cpp:237] Iteration 147874, loss = 1.04244
I0526 02:23:17.305769 27551 solver.cpp:253]     Train net output #0: loss = 1.04244 (* 1 = 1.04244 loss)
I0526 02:23:17.305794 27551 sgd_solver.cpp:106] Iteration 147874, lr = 0.0025
I0526 02:23:26.192950 27551 solver.cpp:237] Iteration 148088, loss = 1.14086
I0526 02:23:26.193112 27551 solver.cpp:253]     Train net output #0: loss = 1.14086 (* 1 = 1.14086 loss)
I0526 02:23:26.193130 27551 sgd_solver.cpp:106] Iteration 148088, lr = 0.0025
I0526 02:23:35.076118 27551 solver.cpp:237] Iteration 148302, loss = 1.03628
I0526 02:23:35.076171 27551 solver.cpp:253]     Train net output #0: loss = 1.03628 (* 1 = 1.03628 loss)
I0526 02:23:35.076195 27551 sgd_solver.cpp:106] Iteration 148302, lr = 0.0025
I0526 02:23:43.958359 27551 solver.cpp:237] Iteration 148516, loss = 1.32885
I0526 02:23:43.958396 27551 solver.cpp:253]     Train net output #0: loss = 1.32885 (* 1 = 1.32885 loss)
I0526 02:23:43.958415 27551 sgd_solver.cpp:106] Iteration 148516, lr = 0.0025
I0526 02:24:13.693589 27551 solver.cpp:237] Iteration 148730, loss = 1.38737
I0526 02:24:13.693773 27551 solver.cpp:253]     Train net output #0: loss = 1.38737 (* 1 = 1.38737 loss)
I0526 02:24:13.693790 27551 sgd_solver.cpp:106] Iteration 148730, lr = 0.0025
I0526 02:24:22.581923 27551 solver.cpp:237] Iteration 148944, loss = 1.09746
I0526 02:24:22.581976 27551 solver.cpp:253]     Train net output #0: loss = 1.09746 (* 1 = 1.09746 loss)
I0526 02:24:22.582001 27551 sgd_solver.cpp:106] Iteration 148944, lr = 0.0025
I0526 02:24:31.472769 27551 solver.cpp:237] Iteration 149158, loss = 0.841226
I0526 02:24:31.472807 27551 solver.cpp:253]     Train net output #0: loss = 0.841226 (* 1 = 0.841226 loss)
I0526 02:24:31.472825 27551 sgd_solver.cpp:106] Iteration 149158, lr = 0.0025
I0526 02:24:40.364120 27551 solver.cpp:237] Iteration 149372, loss = 0.917254
I0526 02:24:40.364156 27551 solver.cpp:253]     Train net output #0: loss = 0.917254 (* 1 = 0.917254 loss)
I0526 02:24:40.364176 27551 sgd_solver.cpp:106] Iteration 149372, lr = 0.0025
I0526 02:24:49.255625 27551 solver.cpp:237] Iteration 149586, loss = 1.17345
I0526 02:24:49.255800 27551 solver.cpp:253]     Train net output #0: loss = 1.17345 (* 1 = 1.17345 loss)
I0526 02:24:49.255818 27551 sgd_solver.cpp:106] Iteration 149586, lr = 0.0025
I0526 02:24:58.154415 27551 solver.cpp:237] Iteration 149800, loss = 1.2182
I0526 02:24:58.154454 27551 solver.cpp:253]     Train net output #0: loss = 1.2182 (* 1 = 1.2182 loss)
I0526 02:24:58.154471 27551 sgd_solver.cpp:106] Iteration 149800, lr = 0.0025
I0526 02:25:03.928992 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_149940.caffemodel
I0526 02:25:03.995811 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_149940.solverstate
I0526 02:25:26.243043 27551 solver.cpp:341] Iteration 149975, Testing net (#0)
I0526 02:26:13.868546 27551 solver.cpp:409]     Test net output #0: accuracy = 0.902874
I0526 02:26:13.868732 27551 solver.cpp:409]     Test net output #1: loss = 0.311514 (* 1 = 0.311514 loss)
I0526 02:26:15.504251 27551 solver.cpp:237] Iteration 150014, loss = 1.05805
I0526 02:26:15.504286 27551 solver.cpp:253]     Train net output #0: loss = 1.05805 (* 1 = 1.05805 loss)
I0526 02:26:15.504303 27551 sgd_solver.cpp:106] Iteration 150014, lr = 0.0025
I0526 02:26:24.396236 27551 solver.cpp:237] Iteration 150228, loss = 0.90728
I0526 02:26:24.396291 27551 solver.cpp:253]     Train net output #0: loss = 0.90728 (* 1 = 0.90728 loss)
I0526 02:26:24.396317 27551 sgd_solver.cpp:106] Iteration 150228, lr = 0.0025
I0526 02:26:33.288446 27551 solver.cpp:237] Iteration 150442, loss = 1.37659
I0526 02:26:33.288483 27551 solver.cpp:253]     Train net output #0: loss = 1.37659 (* 1 = 1.37659 loss)
I0526 02:26:33.288501 27551 sgd_solver.cpp:106] Iteration 150442, lr = 0.0025
I0526 02:26:42.181749 27551 solver.cpp:237] Iteration 150656, loss = 1.05788
I0526 02:26:42.181787 27551 solver.cpp:253]     Train net output #0: loss = 1.05788 (* 1 = 1.05788 loss)
I0526 02:26:42.181804 27551 sgd_solver.cpp:106] Iteration 150656, lr = 0.0025
I0526 02:26:51.073837 27551 solver.cpp:237] Iteration 150870, loss = 1.06337
I0526 02:26:51.074015 27551 solver.cpp:253]     Train net output #0: loss = 1.06337 (* 1 = 1.06337 loss)
I0526 02:26:51.074034 27551 sgd_solver.cpp:106] Iteration 150870, lr = 0.0025
I0526 02:26:59.962231 27551 solver.cpp:237] Iteration 151084, loss = 1.26136
I0526 02:26:59.962268 27551 solver.cpp:253]     Train net output #0: loss = 1.26136 (* 1 = 1.26136 loss)
I0526 02:26:59.962286 27551 sgd_solver.cpp:106] Iteration 151084, lr = 0.0025
I0526 02:27:08.855569 27551 solver.cpp:237] Iteration 151298, loss = 1.01468
I0526 02:27:08.855607 27551 solver.cpp:253]     Train net output #0: loss = 1.01468 (* 1 = 1.01468 loss)
I0526 02:27:08.855623 27551 sgd_solver.cpp:106] Iteration 151298, lr = 0.0025
I0526 02:27:38.567739 27551 solver.cpp:237] Iteration 151512, loss = 1.01386
I0526 02:27:38.567921 27551 solver.cpp:253]     Train net output #0: loss = 1.01386 (* 1 = 1.01386 loss)
I0526 02:27:38.567940 27551 sgd_solver.cpp:106] Iteration 151512, lr = 0.0025
I0526 02:27:47.443742 27551 solver.cpp:237] Iteration 151726, loss = 1.15586
I0526 02:27:47.443778 27551 solver.cpp:253]     Train net output #0: loss = 1.15586 (* 1 = 1.15586 loss)
I0526 02:27:47.443797 27551 sgd_solver.cpp:106] Iteration 151726, lr = 0.0025
I0526 02:27:56.316020 27551 solver.cpp:237] Iteration 151940, loss = 1.01874
I0526 02:27:56.316057 27551 solver.cpp:253]     Train net output #0: loss = 1.01874 (* 1 = 1.01874 loss)
I0526 02:27:56.316074 27551 sgd_solver.cpp:106] Iteration 151940, lr = 0.0025
I0526 02:28:02.168172 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_152082.caffemodel
I0526 02:28:02.234331 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_152082.solverstate
I0526 02:28:05.258769 27551 solver.cpp:237] Iteration 152154, loss = 1.32214
I0526 02:28:05.258821 27551 solver.cpp:253]     Train net output #0: loss = 1.32214 (* 1 = 1.32214 loss)
I0526 02:28:05.258837 27551 sgd_solver.cpp:106] Iteration 152154, lr = 0.0025
I0526 02:28:14.137015 27551 solver.cpp:237] Iteration 152368, loss = 1.09529
I0526 02:28:14.137192 27551 solver.cpp:253]     Train net output #0: loss = 1.09529 (* 1 = 1.09529 loss)
I0526 02:28:14.137209 27551 sgd_solver.cpp:106] Iteration 152368, lr = 0.0025
I0526 02:28:23.010809 27551 solver.cpp:237] Iteration 152582, loss = 1.13944
I0526 02:28:23.010846 27551 solver.cpp:253]     Train net output #0: loss = 1.13944 (* 1 = 1.13944 loss)
I0526 02:28:23.010864 27551 sgd_solver.cpp:106] Iteration 152582, lr = 0.0025
I0526 02:28:31.892685 27551 solver.cpp:237] Iteration 152796, loss = 1.08328
I0526 02:28:31.892742 27551 solver.cpp:253]     Train net output #0: loss = 1.08328 (* 1 = 1.08328 loss)
I0526 02:28:31.892771 27551 sgd_solver.cpp:106] Iteration 152796, lr = 0.0025
I0526 02:29:01.561256 27551 solver.cpp:237] Iteration 153010, loss = 1.16769
I0526 02:29:01.561442 27551 solver.cpp:253]     Train net output #0: loss = 1.16769 (* 1 = 1.16769 loss)
I0526 02:29:01.561460 27551 sgd_solver.cpp:106] Iteration 153010, lr = 0.0025
I0526 02:29:10.447082 27551 solver.cpp:237] Iteration 153224, loss = 1.07136
I0526 02:29:10.447118 27551 solver.cpp:253]     Train net output #0: loss = 1.07136 (* 1 = 1.07136 loss)
I0526 02:29:10.447137 27551 sgd_solver.cpp:106] Iteration 153224, lr = 0.0025
I0526 02:29:19.324300 27551 solver.cpp:237] Iteration 153438, loss = 1.05546
I0526 02:29:19.324353 27551 solver.cpp:253]     Train net output #0: loss = 1.05546 (* 1 = 1.05546 loss)
I0526 02:29:19.324379 27551 sgd_solver.cpp:106] Iteration 153438, lr = 0.0025
I0526 02:29:28.187885 27551 solver.cpp:237] Iteration 153652, loss = 1.31336
I0526 02:29:28.187922 27551 solver.cpp:253]     Train net output #0: loss = 1.31336 (* 1 = 1.31336 loss)
I0526 02:29:28.187940 27551 sgd_solver.cpp:106] Iteration 153652, lr = 0.0025
I0526 02:29:37.057307 27551 solver.cpp:237] Iteration 153866, loss = 1.17974
I0526 02:29:37.057482 27551 solver.cpp:253]     Train net output #0: loss = 1.17974 (* 1 = 1.17974 loss)
I0526 02:29:37.057498 27551 sgd_solver.cpp:106] Iteration 153866, lr = 0.0025
I0526 02:29:45.933478 27551 solver.cpp:237] Iteration 154080, loss = 1.13815
I0526 02:29:45.933532 27551 solver.cpp:253]     Train net output #0: loss = 1.13815 (* 1 = 1.13815 loss)
I0526 02:29:45.933557 27551 sgd_solver.cpp:106] Iteration 154080, lr = 0.0025
I0526 02:29:51.864909 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_154224.caffemodel
I0526 02:29:51.932804 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_154224.solverstate
I0526 02:30:14.246603 27551 solver.cpp:341] Iteration 154260, Testing net (#0)
I0526 02:31:22.983650 27551 solver.cpp:409]     Test net output #0: accuracy = 0.900334
I0526 02:31:22.983834 27551 solver.cpp:409]     Test net output #1: loss = 0.324936 (* 1 = 0.324936 loss)
I0526 02:31:24.411010 27551 solver.cpp:237] Iteration 154294, loss = 1.19682
I0526 02:31:24.411061 27551 solver.cpp:253]     Train net output #0: loss = 1.19682 (* 1 = 1.19682 loss)
I0526 02:31:24.411087 27551 sgd_solver.cpp:106] Iteration 154294, lr = 0.0025
I0526 02:31:33.297652 27551 solver.cpp:237] Iteration 154508, loss = 1.0816
I0526 02:31:33.297689 27551 solver.cpp:253]     Train net output #0: loss = 1.0816 (* 1 = 1.0816 loss)
I0526 02:31:33.297708 27551 sgd_solver.cpp:106] Iteration 154508, lr = 0.0025
I0526 02:31:42.189232 27551 solver.cpp:237] Iteration 154722, loss = 1.15314
I0526 02:31:42.189270 27551 solver.cpp:253]     Train net output #0: loss = 1.15314 (* 1 = 1.15314 loss)
I0526 02:31:42.189287 27551 sgd_solver.cpp:106] Iteration 154722, lr = 0.0025
I0526 02:31:51.079141 27551 solver.cpp:237] Iteration 154936, loss = 1.17008
I0526 02:31:51.079195 27551 solver.cpp:253]     Train net output #0: loss = 1.17008 (* 1 = 1.17008 loss)
I0526 02:31:51.079219 27551 sgd_solver.cpp:106] Iteration 154936, lr = 0.0025
I0526 02:31:59.964612 27551 solver.cpp:237] Iteration 155150, loss = 1.32468
I0526 02:31:59.964804 27551 solver.cpp:253]     Train net output #0: loss = 1.32468 (* 1 = 1.32468 loss)
I0526 02:31:59.964823 27551 sgd_solver.cpp:106] Iteration 155150, lr = 0.0025
I0526 02:32:08.852851 27551 solver.cpp:237] Iteration 155364, loss = 1.09137
I0526 02:32:08.852890 27551 solver.cpp:253]     Train net output #0: loss = 1.09137 (* 1 = 1.09137 loss)
I0526 02:32:08.852906 27551 sgd_solver.cpp:106] Iteration 155364, lr = 0.0025
I0526 02:32:17.738804 27551 solver.cpp:237] Iteration 155578, loss = 1.05867
I0526 02:32:17.738858 27551 solver.cpp:253]     Train net output #0: loss = 1.05867 (* 1 = 1.05867 loss)
I0526 02:32:17.738883 27551 sgd_solver.cpp:106] Iteration 155578, lr = 0.0025
I0526 02:32:47.462272 27551 solver.cpp:237] Iteration 155792, loss = 1.15694
I0526 02:32:47.462469 27551 solver.cpp:253]     Train net output #0: loss = 1.15694 (* 1 = 1.15694 loss)
I0526 02:32:47.462487 27551 sgd_solver.cpp:106] Iteration 155792, lr = 0.0025
I0526 02:32:56.343013 27551 solver.cpp:237] Iteration 156006, loss = 1.15197
I0526 02:32:56.343050 27551 solver.cpp:253]     Train net output #0: loss = 1.15197 (* 1 = 1.15197 loss)
I0526 02:32:56.343067 27551 sgd_solver.cpp:106] Iteration 156006, lr = 0.0025
I0526 02:33:05.230463 27551 solver.cpp:237] Iteration 156220, loss = 0.991022
I0526 02:33:05.230520 27551 solver.cpp:253]     Train net output #0: loss = 0.991022 (* 1 = 0.991022 loss)
I0526 02:33:05.230545 27551 sgd_solver.cpp:106] Iteration 156220, lr = 0.0025
I0526 02:33:11.251307 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_156366.caffemodel
I0526 02:33:11.320648 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_156366.solverstate
I0526 02:33:14.183877 27551 solver.cpp:237] Iteration 156434, loss = 0.995604
I0526 02:33:14.183933 27551 solver.cpp:253]     Train net output #0: loss = 0.995604 (* 1 = 0.995604 loss)
I0526 02:33:14.183957 27551 sgd_solver.cpp:106] Iteration 156434, lr = 0.0025
I0526 02:33:23.073396 27551 solver.cpp:237] Iteration 156648, loss = 1.13913
I0526 02:33:23.073565 27551 solver.cpp:253]     Train net output #0: loss = 1.13913 (* 1 = 1.13913 loss)
I0526 02:33:23.073581 27551 sgd_solver.cpp:106] Iteration 156648, lr = 0.0025
I0526 02:33:31.957304 27551 solver.cpp:237] Iteration 156862, loss = 1.2197
I0526 02:33:31.957356 27551 solver.cpp:253]     Train net output #0: loss = 1.2197 (* 1 = 1.2197 loss)
I0526 02:33:31.957381 27551 sgd_solver.cpp:106] Iteration 156862, lr = 0.0025
I0526 02:33:40.845176 27551 solver.cpp:237] Iteration 157076, loss = 1.00773
I0526 02:33:40.845213 27551 solver.cpp:253]     Train net output #0: loss = 1.00773 (* 1 = 1.00773 loss)
I0526 02:33:40.845232 27551 sgd_solver.cpp:106] Iteration 157076, lr = 0.0025
I0526 02:34:10.521302 27551 solver.cpp:237] Iteration 157290, loss = 1.27356
I0526 02:34:10.521486 27551 solver.cpp:253]     Train net output #0: loss = 1.27356 (* 1 = 1.27356 loss)
I0526 02:34:10.521502 27551 sgd_solver.cpp:106] Iteration 157290, lr = 0.0025
I0526 02:34:19.408113 27551 solver.cpp:237] Iteration 157504, loss = 1.05481
I0526 02:34:19.408164 27551 solver.cpp:253]     Train net output #0: loss = 1.05481 (* 1 = 1.05481 loss)
I0526 02:34:19.408180 27551 sgd_solver.cpp:106] Iteration 157504, lr = 0.0025
I0526 02:34:28.291590 27551 solver.cpp:237] Iteration 157718, loss = 0.956654
I0526 02:34:28.291630 27551 solver.cpp:253]     Train net output #0: loss = 0.956654 (* 1 = 0.956654 loss)
I0526 02:34:28.291646 27551 sgd_solver.cpp:106] Iteration 157718, lr = 0.0025
I0526 02:34:37.174341 27551 solver.cpp:237] Iteration 157932, loss = 1.22789
I0526 02:34:37.174378 27551 solver.cpp:253]     Train net output #0: loss = 1.22789 (* 1 = 1.22789 loss)
I0526 02:34:37.174397 27551 sgd_solver.cpp:106] Iteration 157932, lr = 0.0025
I0526 02:34:46.057473 27551 solver.cpp:237] Iteration 158146, loss = 1.19105
I0526 02:34:46.057664 27551 solver.cpp:253]     Train net output #0: loss = 1.19105 (* 1 = 1.19105 loss)
I0526 02:34:46.057682 27551 sgd_solver.cpp:106] Iteration 158146, lr = 0.0025
I0526 02:34:54.940613 27551 solver.cpp:237] Iteration 158360, loss = 1.11765
I0526 02:34:54.940649 27551 solver.cpp:253]     Train net output #0: loss = 1.11765 (* 1 = 1.11765 loss)
I0526 02:34:54.940667 27551 sgd_solver.cpp:106] Iteration 158360, lr = 0.0025
I0526 02:35:01.041844 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_158508.caffemodel
I0526 02:35:01.109086 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_158508.solverstate
I0526 02:35:23.480407 27551 solver.cpp:341] Iteration 158545, Testing net (#0)
I0526 02:36:11.367929 27551 solver.cpp:409]     Test net output #0: accuracy = 0.901
I0526 02:36:11.368113 27551 solver.cpp:409]     Test net output #1: loss = 0.306642 (* 1 = 0.306642 loss)
I0526 02:36:12.590101 27551 solver.cpp:237] Iteration 158574, loss = 1.1568
I0526 02:36:12.590136 27551 solver.cpp:253]     Train net output #0: loss = 1.1568 (* 1 = 1.1568 loss)
I0526 02:36:12.590154 27551 sgd_solver.cpp:106] Iteration 158574, lr = 0.0025
I0526 02:36:21.502984 27551 solver.cpp:237] Iteration 158788, loss = 1.13897
I0526 02:36:21.503021 27551 solver.cpp:253]     Train net output #0: loss = 1.13897 (* 1 = 1.13897 loss)
I0526 02:36:21.503038 27551 sgd_solver.cpp:106] Iteration 158788, lr = 0.0025
I0526 02:36:30.409412 27551 solver.cpp:237] Iteration 159002, loss = 1.26458
I0526 02:36:30.409461 27551 solver.cpp:253]     Train net output #0: loss = 1.26458 (* 1 = 1.26458 loss)
I0526 02:36:30.409490 27551 sgd_solver.cpp:106] Iteration 159002, lr = 0.0025
I0526 02:36:39.310431 27551 solver.cpp:237] Iteration 159216, loss = 0.960363
I0526 02:36:39.310468 27551 solver.cpp:253]     Train net output #0: loss = 0.960363 (* 1 = 0.960363 loss)
I0526 02:36:39.310485 27551 sgd_solver.cpp:106] Iteration 159216, lr = 0.0025
I0526 02:36:48.219601 27551 solver.cpp:237] Iteration 159430, loss = 1.08091
I0526 02:36:48.219769 27551 solver.cpp:253]     Train net output #0: loss = 1.08091 (* 1 = 1.08091 loss)
I0526 02:36:48.219786 27551 sgd_solver.cpp:106] Iteration 159430, lr = 0.0025
I0526 02:36:57.119904 27551 solver.cpp:237] Iteration 159644, loss = 1.09672
I0526 02:36:57.119953 27551 solver.cpp:253]     Train net output #0: loss = 1.09672 (* 1 = 1.09672 loss)
I0526 02:36:57.119981 27551 sgd_solver.cpp:106] Iteration 159644, lr = 0.0025
I0526 02:37:06.031396 27551 solver.cpp:237] Iteration 159858, loss = 0.954888
I0526 02:37:06.031433 27551 solver.cpp:253]     Train net output #0: loss = 0.954888 (* 1 = 0.954888 loss)
I0526 02:37:06.031451 27551 sgd_solver.cpp:106] Iteration 159858, lr = 0.0025
I0526 02:37:35.733044 27551 solver.cpp:237] Iteration 160072, loss = 1.19148
I0526 02:37:35.733230 27551 solver.cpp:253]     Train net output #0: loss = 1.19148 (* 1 = 1.19148 loss)
I0526 02:37:35.733248 27551 sgd_solver.cpp:106] Iteration 160072, lr = 0.0025
I0526 02:37:44.637837 27551 solver.cpp:237] Iteration 160286, loss = 1.28725
I0526 02:37:44.637892 27551 solver.cpp:253]     Train net output #0: loss = 1.28725 (* 1 = 1.28725 loss)
I0526 02:37:44.637915 27551 sgd_solver.cpp:106] Iteration 160286, lr = 0.0025
I0526 02:37:53.548409 27551 solver.cpp:237] Iteration 160500, loss = 0.95175
I0526 02:37:53.548446 27551 solver.cpp:253]     Train net output #0: loss = 0.95175 (* 1 = 0.95175 loss)
I0526 02:37:53.548465 27551 sgd_solver.cpp:106] Iteration 160500, lr = 0.0025
I0526 02:37:59.749893 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_160650.caffemodel
I0526 02:37:59.816752 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_160650.solverstate
I0526 02:38:02.516549 27551 solver.cpp:237] Iteration 160714, loss = 1.17343
I0526 02:38:02.516602 27551 solver.cpp:253]     Train net output #0: loss = 1.17343 (* 1 = 1.17343 loss)
I0526 02:38:02.516625 27551 sgd_solver.cpp:106] Iteration 160714, lr = 0.0025
I0526 02:38:11.419535 27551 solver.cpp:237] Iteration 160928, loss = 1.22514
I0526 02:38:11.419729 27551 solver.cpp:253]     Train net output #0: loss = 1.22514 (* 1 = 1.22514 loss)
I0526 02:38:11.419747 27551 sgd_solver.cpp:106] Iteration 160928, lr = 0.0025
I0526 02:38:20.327918 27551 solver.cpp:237] Iteration 161142, loss = 0.997127
I0526 02:38:20.327956 27551 solver.cpp:253]     Train net output #0: loss = 0.997127 (* 1 = 0.997127 loss)
I0526 02:38:20.327972 27551 sgd_solver.cpp:106] Iteration 161142, lr = 0.0025
I0526 02:38:29.235354 27551 solver.cpp:237] Iteration 161356, loss = 1.34692
I0526 02:38:29.235410 27551 solver.cpp:253]     Train net output #0: loss = 1.34692 (* 1 = 1.34692 loss)
I0526 02:38:29.235430 27551 sgd_solver.cpp:106] Iteration 161356, lr = 0.0025
I0526 02:38:58.959959 27551 solver.cpp:237] Iteration 161570, loss = 1.10845
I0526 02:38:58.960145 27551 solver.cpp:253]     Train net output #0: loss = 1.10845 (* 1 = 1.10845 loss)
I0526 02:38:58.960163 27551 sgd_solver.cpp:106] Iteration 161570, lr = 0.0025
I0526 02:39:07.863407 27551 solver.cpp:237] Iteration 161784, loss = 1.00978
I0526 02:39:07.863445 27551 solver.cpp:253]     Train net output #0: loss = 1.00978 (* 1 = 1.00978 loss)
I0526 02:39:07.863463 27551 sgd_solver.cpp:106] Iteration 161784, lr = 0.0025
I0526 02:39:16.760619 27551 solver.cpp:237] Iteration 161998, loss = 1.16596
I0526 02:39:16.760656 27551 solver.cpp:253]     Train net output #0: loss = 1.16596 (* 1 = 1.16596 loss)
I0526 02:39:16.760674 27551 sgd_solver.cpp:106] Iteration 161998, lr = 0.0025
I0526 02:39:25.662741 27551 solver.cpp:237] Iteration 162212, loss = 1.06563
I0526 02:39:25.662794 27551 solver.cpp:253]     Train net output #0: loss = 1.06563 (* 1 = 1.06563 loss)
I0526 02:39:25.662812 27551 sgd_solver.cpp:106] Iteration 162212, lr = 0.0025
I0526 02:39:34.567598 27551 solver.cpp:237] Iteration 162426, loss = 1.15476
I0526 02:39:34.567766 27551 solver.cpp:253]     Train net output #0: loss = 1.15476 (* 1 = 1.15476 loss)
I0526 02:39:34.567783 27551 sgd_solver.cpp:106] Iteration 162426, lr = 0.0025
I0526 02:39:43.463063 27551 solver.cpp:237] Iteration 162640, loss = 1.06863
I0526 02:39:43.463114 27551 solver.cpp:253]     Train net output #0: loss = 1.06863 (* 1 = 1.06863 loss)
I0526 02:39:43.463135 27551 sgd_solver.cpp:106] Iteration 162640, lr = 0.0025
I0526 02:39:49.733469 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_162792.caffemodel
I0526 02:39:49.799655 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_162792.solverstate
I0526 02:40:12.166138 27551 solver.cpp:341] Iteration 162830, Testing net (#0)
I0526 02:41:20.921893 27551 solver.cpp:409]     Test net output #0: accuracy = 0.903955
I0526 02:41:20.922078 27551 solver.cpp:409]     Test net output #1: loss = 0.307348 (* 1 = 0.307348 loss)
I0526 02:41:21.931623 27551 solver.cpp:237] Iteration 162854, loss = 0.986278
I0526 02:41:21.931656 27551 solver.cpp:253]     Train net output #0: loss = 0.986278 (* 1 = 0.986278 loss)
I0526 02:41:21.931675 27551 sgd_solver.cpp:106] Iteration 162854, lr = 0.0025
I0526 02:41:30.812172 27551 solver.cpp:237] Iteration 163068, loss = 1.02502
I0526 02:41:30.812221 27551 solver.cpp:253]     Train net output #0: loss = 1.02502 (* 1 = 1.02502 loss)
I0526 02:41:30.812237 27551 sgd_solver.cpp:106] Iteration 163068, lr = 0.0025
I0526 02:41:39.691422 27551 solver.cpp:237] Iteration 163282, loss = 1.16942
I0526 02:41:39.691460 27551 solver.cpp:253]     Train net output #0: loss = 1.16942 (* 1 = 1.16942 loss)
I0526 02:41:39.691478 27551 sgd_solver.cpp:106] Iteration 163282, lr = 0.0025
I0526 02:41:48.578606 27551 solver.cpp:237] Iteration 163496, loss = 1.26128
I0526 02:41:48.578658 27551 solver.cpp:253]     Train net output #0: loss = 1.26128 (* 1 = 1.26128 loss)
I0526 02:41:48.578678 27551 sgd_solver.cpp:106] Iteration 163496, lr = 0.0025
I0526 02:41:57.463632 27551 solver.cpp:237] Iteration 163710, loss = 1.13463
I0526 02:41:57.463822 27551 solver.cpp:253]     Train net output #0: loss = 1.13463 (* 1 = 1.13463 loss)
I0526 02:41:57.463840 27551 sgd_solver.cpp:106] Iteration 163710, lr = 0.0025
I0526 02:42:06.345366 27551 solver.cpp:237] Iteration 163924, loss = 1.30617
I0526 02:42:06.345401 27551 solver.cpp:253]     Train net output #0: loss = 1.30617 (* 1 = 1.30617 loss)
I0526 02:42:06.345418 27551 sgd_solver.cpp:106] Iteration 163924, lr = 0.0025
I0526 02:42:15.215188 27551 solver.cpp:237] Iteration 164138, loss = 1.19111
I0526 02:42:15.215240 27551 solver.cpp:253]     Train net output #0: loss = 1.19111 (* 1 = 1.19111 loss)
I0526 02:42:15.215265 27551 sgd_solver.cpp:106] Iteration 164138, lr = 0.0025
I0526 02:42:44.865473 27551 solver.cpp:237] Iteration 164352, loss = 1.2733
I0526 02:42:44.865663 27551 solver.cpp:253]     Train net output #0: loss = 1.2733 (* 1 = 1.2733 loss)
I0526 02:42:44.865682 27551 sgd_solver.cpp:106] Iteration 164352, lr = 0.0025
I0526 02:42:53.733441 27551 solver.cpp:237] Iteration 164566, loss = 1.10112
I0526 02:42:53.733477 27551 solver.cpp:253]     Train net output #0: loss = 1.10112 (* 1 = 1.10112 loss)
I0526 02:42:53.733496 27551 sgd_solver.cpp:106] Iteration 164566, lr = 0.0025
I0526 02:43:02.606485 27551 solver.cpp:237] Iteration 164780, loss = 0.953988
I0526 02:43:02.606524 27551 solver.cpp:253]     Train net output #0: loss = 0.953988 (* 1 = 0.953988 loss)
I0526 02:43:02.606541 27551 sgd_solver.cpp:106] Iteration 164780, lr = 0.0025
I0526 02:43:08.953390 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_164934.caffemodel
I0526 02:43:09.023602 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_164934.solverstate
I0526 02:43:11.555070 27551 solver.cpp:237] Iteration 164994, loss = 1.06129
I0526 02:43:11.555121 27551 solver.cpp:253]     Train net output #0: loss = 1.06129 (* 1 = 1.06129 loss)
I0526 02:43:11.555150 27551 sgd_solver.cpp:106] Iteration 164994, lr = 0.0025
I0526 02:43:20.428469 27551 solver.cpp:237] Iteration 165208, loss = 1.27949
I0526 02:43:20.428642 27551 solver.cpp:253]     Train net output #0: loss = 1.27949 (* 1 = 1.27949 loss)
I0526 02:43:20.428659 27551 sgd_solver.cpp:106] Iteration 165208, lr = 0.0025
I0526 02:43:29.298029 27551 solver.cpp:237] Iteration 165422, loss = 1.19954
I0526 02:43:29.298084 27551 solver.cpp:253]     Train net output #0: loss = 1.19954 (* 1 = 1.19954 loss)
I0526 02:43:29.298102 27551 sgd_solver.cpp:106] Iteration 165422, lr = 0.0025
I0526 02:43:38.172132 27551 solver.cpp:237] Iteration 165636, loss = 1.45098
I0526 02:43:38.172169 27551 solver.cpp:253]     Train net output #0: loss = 1.45098 (* 1 = 1.45098 loss)
I0526 02:43:38.172188 27551 sgd_solver.cpp:106] Iteration 165636, lr = 0.0025
I0526 02:44:07.858942 27551 solver.cpp:237] Iteration 165850, loss = 0.985559
I0526 02:44:07.859133 27551 solver.cpp:253]     Train net output #0: loss = 0.985559 (* 1 = 0.985559 loss)
I0526 02:44:07.859150 27551 sgd_solver.cpp:106] Iteration 165850, lr = 0.0025
I0526 02:44:16.727583 27551 solver.cpp:237] Iteration 166064, loss = 1.10925
I0526 02:44:16.727619 27551 solver.cpp:253]     Train net output #0: loss = 1.10925 (* 1 = 1.10925 loss)
I0526 02:44:16.727638 27551 sgd_solver.cpp:106] Iteration 166064, lr = 0.0025
I0526 02:44:25.610782 27551 solver.cpp:237] Iteration 166278, loss = 1.14023
I0526 02:44:25.610826 27551 solver.cpp:253]     Train net output #0: loss = 1.14023 (* 1 = 1.14023 loss)
I0526 02:44:25.610844 27551 sgd_solver.cpp:106] Iteration 166278, lr = 0.0025
I0526 02:44:34.483953 27551 solver.cpp:237] Iteration 166492, loss = 1.23589
I0526 02:44:34.483990 27551 solver.cpp:253]     Train net output #0: loss = 1.23589 (* 1 = 1.23589 loss)
I0526 02:44:34.484009 27551 sgd_solver.cpp:106] Iteration 166492, lr = 0.0025
I0526 02:44:43.360244 27551 solver.cpp:237] Iteration 166706, loss = 1.09486
I0526 02:44:43.360435 27551 solver.cpp:253]     Train net output #0: loss = 1.09486 (* 1 = 1.09486 loss)
I0526 02:44:43.360452 27551 sgd_solver.cpp:106] Iteration 166706, lr = 0.0025
I0526 02:44:52.235287 27551 solver.cpp:237] Iteration 166920, loss = 1.01628
I0526 02:44:52.235324 27551 solver.cpp:253]     Train net output #0: loss = 1.01628 (* 1 = 1.01628 loss)
I0526 02:44:52.235343 27551 sgd_solver.cpp:106] Iteration 166920, lr = 0.0025
I0526 02:44:58.665653 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_167076.caffemodel
I0526 02:44:58.734992 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_167076.solverstate
I0526 02:45:21.175460 27551 solver.cpp:341] Iteration 167115, Testing net (#0)
I0526 02:46:08.765311 27551 solver.cpp:409]     Test net output #0: accuracy = 0.903035
I0526 02:46:08.765498 27551 solver.cpp:409]     Test net output #1: loss = 0.314212 (* 1 = 0.314212 loss)
I0526 02:46:09.569174 27551 solver.cpp:237] Iteration 167134, loss = 1.01948
I0526 02:46:09.569207 27551 solver.cpp:253]     Train net output #0: loss = 1.01948 (* 1 = 1.01948 loss)
I0526 02:46:09.569224 27551 sgd_solver.cpp:106] Iteration 167134, lr = 0.0025
I0526 02:46:18.460889 27551 solver.cpp:237] Iteration 167348, loss = 1.02513
I0526 02:46:18.460925 27551 solver.cpp:253]     Train net output #0: loss = 1.02513 (* 1 = 1.02513 loss)
I0526 02:46:18.460943 27551 sgd_solver.cpp:106] Iteration 167348, lr = 0.0025
I0526 02:46:27.362692 27551 solver.cpp:237] Iteration 167562, loss = 1.15601
I0526 02:46:27.362747 27551 solver.cpp:253]     Train net output #0: loss = 1.15601 (* 1 = 1.15601 loss)
I0526 02:46:27.362771 27551 sgd_solver.cpp:106] Iteration 167562, lr = 0.0025
I0526 02:46:36.249963 27551 solver.cpp:237] Iteration 167776, loss = 1.25804
I0526 02:46:36.250000 27551 solver.cpp:253]     Train net output #0: loss = 1.25804 (* 1 = 1.25804 loss)
I0526 02:46:36.250025 27551 sgd_solver.cpp:106] Iteration 167776, lr = 0.0025
I0526 02:46:45.140585 27551 solver.cpp:237] Iteration 167990, loss = 1.00673
I0526 02:46:45.140770 27551 solver.cpp:253]     Train net output #0: loss = 1.00673 (* 1 = 1.00673 loss)
I0526 02:46:45.140787 27551 sgd_solver.cpp:106] Iteration 167990, lr = 0.0025
I0526 02:46:54.028120 27551 solver.cpp:237] Iteration 168204, loss = 1.19613
I0526 02:46:54.028170 27551 solver.cpp:253]     Train net output #0: loss = 1.19613 (* 1 = 1.19613 loss)
I0526 02:46:54.028198 27551 sgd_solver.cpp:106] Iteration 168204, lr = 0.0025
I0526 02:47:02.913003 27551 solver.cpp:237] Iteration 168418, loss = 0.990762
I0526 02:47:02.913040 27551 solver.cpp:253]     Train net output #0: loss = 0.990762 (* 1 = 0.990762 loss)
I0526 02:47:02.913058 27551 sgd_solver.cpp:106] Iteration 168418, lr = 0.0025
I0526 02:47:32.644390 27551 solver.cpp:237] Iteration 168632, loss = 1.23668
I0526 02:47:32.644593 27551 solver.cpp:253]     Train net output #0: loss = 1.23668 (* 1 = 1.23668 loss)
I0526 02:47:32.644610 27551 sgd_solver.cpp:106] Iteration 168632, lr = 0.0025
I0526 02:47:41.533107 27551 solver.cpp:237] Iteration 168846, loss = 0.932344
I0526 02:47:41.533159 27551 solver.cpp:253]     Train net output #0: loss = 0.932344 (* 1 = 0.932344 loss)
I0526 02:47:41.533187 27551 sgd_solver.cpp:106] Iteration 168846, lr = 0.0025
I0526 02:47:50.420812 27551 solver.cpp:237] Iteration 169060, loss = 0.880362
I0526 02:47:50.420850 27551 solver.cpp:253]     Train net output #0: loss = 0.880362 (* 1 = 0.880362 loss)
I0526 02:47:50.420868 27551 sgd_solver.cpp:106] Iteration 169060, lr = 0.0025
I0526 02:47:56.944665 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_169218.caffemodel
I0526 02:47:57.011104 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_169218.solverstate
I0526 02:47:59.374016 27551 solver.cpp:237] Iteration 169274, loss = 1.11568
I0526 02:47:59.374066 27551 solver.cpp:253]     Train net output #0: loss = 1.11568 (* 1 = 1.11568 loss)
I0526 02:47:59.374092 27551 sgd_solver.cpp:106] Iteration 169274, lr = 0.0025
I0526 02:48:08.263978 27551 solver.cpp:237] Iteration 169488, loss = 1.41374
I0526 02:48:08.264176 27551 solver.cpp:253]     Train net output #0: loss = 1.41374 (* 1 = 1.41374 loss)
I0526 02:48:08.264194 27551 sgd_solver.cpp:106] Iteration 169488, lr = 0.0025
I0526 02:48:17.154700 27551 solver.cpp:237] Iteration 169702, loss = 1.02819
I0526 02:48:17.154737 27551 solver.cpp:253]     Train net output #0: loss = 1.02819 (* 1 = 1.02819 loss)
I0526 02:48:17.154755 27551 sgd_solver.cpp:106] Iteration 169702, lr = 0.0025
I0526 02:48:26.046494 27551 solver.cpp:237] Iteration 169916, loss = 1.03724
I0526 02:48:26.046531 27551 solver.cpp:253]     Train net output #0: loss = 1.03724 (* 1 = 1.03724 loss)
I0526 02:48:26.046548 27551 sgd_solver.cpp:106] Iteration 169916, lr = 0.0025
I0526 02:48:55.740097 27551 solver.cpp:237] Iteration 170130, loss = 0.927898
I0526 02:48:55.740289 27551 solver.cpp:253]     Train net output #0: loss = 0.927898 (* 1 = 0.927898 loss)
I0526 02:48:55.740306 27551 sgd_solver.cpp:106] Iteration 170130, lr = 0.0025
I0526 02:49:04.635646 27551 solver.cpp:237] Iteration 170344, loss = 1.32286
I0526 02:49:04.635689 27551 solver.cpp:253]     Train net output #0: loss = 1.32286 (* 1 = 1.32286 loss)
I0526 02:49:04.635704 27551 sgd_solver.cpp:106] Iteration 170344, lr = 0.0025
I0526 02:49:13.521749 27551 solver.cpp:237] Iteration 170558, loss = 1.34285
I0526 02:49:13.521785 27551 solver.cpp:253]     Train net output #0: loss = 1.34285 (* 1 = 1.34285 loss)
I0526 02:49:13.521803 27551 sgd_solver.cpp:106] Iteration 170558, lr = 0.0025
I0526 02:49:22.410344 27551 solver.cpp:237] Iteration 170772, loss = 1.26473
I0526 02:49:22.410397 27551 solver.cpp:253]     Train net output #0: loss = 1.26473 (* 1 = 1.26473 loss)
I0526 02:49:22.410425 27551 sgd_solver.cpp:106] Iteration 170772, lr = 0.0025
I0526 02:49:31.289019 27551 solver.cpp:237] Iteration 170986, loss = 1.06057
I0526 02:49:31.289191 27551 solver.cpp:253]     Train net output #0: loss = 1.06057 (* 1 = 1.06057 loss)
I0526 02:49:31.289207 27551 sgd_solver.cpp:106] Iteration 170986, lr = 0.0025
I0526 02:49:40.167801 27551 solver.cpp:237] Iteration 171200, loss = 1.17722
I0526 02:49:40.167840 27551 solver.cpp:253]     Train net output #0: loss = 1.17722 (* 1 = 1.17722 loss)
I0526 02:49:40.167856 27551 sgd_solver.cpp:106] Iteration 171200, lr = 0.0025
I0526 02:49:46.769353 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_171360.caffemodel
I0526 02:49:46.835608 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_171360.solverstate
I0526 02:50:09.313830 27551 solver.cpp:341] Iteration 171400, Testing net (#0)
I0526 02:51:18.025699 27551 solver.cpp:409]     Test net output #0: accuracy = 0.903388
I0526 02:51:18.025887 27551 solver.cpp:409]     Test net output #1: loss = 0.323486 (* 1 = 0.323486 loss)
I0526 02:51:18.622992 27551 solver.cpp:237] Iteration 171414, loss = 0.924215
I0526 02:51:18.623024 27551 solver.cpp:253]     Train net output #0: loss = 0.924215 (* 1 = 0.924215 loss)
I0526 02:51:18.623044 27551 sgd_solver.cpp:106] Iteration 171414, lr = 0.0025
I0526 02:51:27.531996 27551 solver.cpp:237] Iteration 171628, loss = 1.15091
I0526 02:51:27.532054 27551 solver.cpp:253]     Train net output #0: loss = 1.15091 (* 1 = 1.15091 loss)
I0526 02:51:27.532073 27551 sgd_solver.cpp:106] Iteration 171628, lr = 0.0025
I0526 02:51:36.437782 27551 solver.cpp:237] Iteration 171842, loss = 1.13918
I0526 02:51:36.437818 27551 solver.cpp:253]     Train net output #0: loss = 1.13918 (* 1 = 1.13918 loss)
I0526 02:51:36.437835 27551 sgd_solver.cpp:106] Iteration 171842, lr = 0.0025
I0526 02:51:45.344852 27551 solver.cpp:237] Iteration 172056, loss = 1.19502
I0526 02:51:45.344889 27551 solver.cpp:253]     Train net output #0: loss = 1.19502 (* 1 = 1.19502 loss)
I0526 02:51:45.344907 27551 sgd_solver.cpp:106] Iteration 172056, lr = 0.0025
I0526 02:51:54.258857 27551 solver.cpp:237] Iteration 172270, loss = 1.06749
I0526 02:51:54.259055 27551 solver.cpp:253]     Train net output #0: loss = 1.06749 (* 1 = 1.06749 loss)
I0526 02:51:54.259073 27551 sgd_solver.cpp:106] Iteration 172270, lr = 0.0025
I0526 02:52:03.170022 27551 solver.cpp:237] Iteration 172484, loss = 1.20951
I0526 02:52:03.170058 27551 solver.cpp:253]     Train net output #0: loss = 1.20951 (* 1 = 1.20951 loss)
I0526 02:52:03.170076 27551 sgd_solver.cpp:106] Iteration 172484, lr = 0.0025
I0526 02:52:12.091094 27551 solver.cpp:237] Iteration 172698, loss = 0.989832
I0526 02:52:12.091133 27551 solver.cpp:253]     Train net output #0: loss = 0.989832 (* 1 = 0.989832 loss)
I0526 02:52:12.091150 27551 sgd_solver.cpp:106] Iteration 172698, lr = 0.0025
I0526 02:52:41.788687 27551 solver.cpp:237] Iteration 172912, loss = 0.961224
I0526 02:52:41.788887 27551 solver.cpp:253]     Train net output #0: loss = 0.961224 (* 1 = 0.961224 loss)
I0526 02:52:41.788904 27551 sgd_solver.cpp:106] Iteration 172912, lr = 0.0025
I0526 02:52:50.705447 27551 solver.cpp:237] Iteration 173126, loss = 1.0544
I0526 02:52:50.705483 27551 solver.cpp:253]     Train net output #0: loss = 1.0544 (* 1 = 1.0544 loss)
I0526 02:52:50.705502 27551 sgd_solver.cpp:106] Iteration 173126, lr = 0.0025
I0526 02:52:59.625656 27551 solver.cpp:237] Iteration 173340, loss = 1.02363
I0526 02:52:59.625692 27551 solver.cpp:253]     Train net output #0: loss = 1.02363 (* 1 = 1.02363 loss)
I0526 02:52:59.625711 27551 sgd_solver.cpp:106] Iteration 173340, lr = 0.0025
I0526 02:53:06.339033 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_173502.caffemodel
I0526 02:53:06.405419 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_173502.solverstate
I0526 02:53:08.615314 27551 solver.cpp:237] Iteration 173554, loss = 1.09228
I0526 02:53:08.615365 27551 solver.cpp:253]     Train net output #0: loss = 1.09228 (* 1 = 1.09228 loss)
I0526 02:53:08.615381 27551 sgd_solver.cpp:106] Iteration 173554, lr = 0.0025
I0526 02:53:17.528888 27551 solver.cpp:237] Iteration 173768, loss = 1.0742
I0526 02:53:17.529072 27551 solver.cpp:253]     Train net output #0: loss = 1.0742 (* 1 = 1.0742 loss)
I0526 02:53:17.529088 27551 sgd_solver.cpp:106] Iteration 173768, lr = 0.0025
I0526 02:53:26.435403 27551 solver.cpp:237] Iteration 173982, loss = 1.07558
I0526 02:53:26.435441 27551 solver.cpp:253]     Train net output #0: loss = 1.07558 (* 1 = 1.07558 loss)
I0526 02:53:26.435457 27551 sgd_solver.cpp:106] Iteration 173982, lr = 0.0025
I0526 02:53:35.349613 27551 solver.cpp:237] Iteration 174196, loss = 1.28702
I0526 02:53:35.349658 27551 solver.cpp:253]     Train net output #0: loss = 1.28702 (* 1 = 1.28702 loss)
I0526 02:53:35.349686 27551 sgd_solver.cpp:106] Iteration 174196, lr = 0.0025
I0526 02:54:05.100297 27551 solver.cpp:237] Iteration 174410, loss = 1.19176
I0526 02:54:05.100492 27551 solver.cpp:253]     Train net output #0: loss = 1.19176 (* 1 = 1.19176 loss)
I0526 02:54:05.100508 27551 sgd_solver.cpp:106] Iteration 174410, lr = 0.0025
I0526 02:54:14.021298 27551 solver.cpp:237] Iteration 174624, loss = 1.24538
I0526 02:54:14.021335 27551 solver.cpp:253]     Train net output #0: loss = 1.24538 (* 1 = 1.24538 loss)
I0526 02:54:14.021353 27551 sgd_solver.cpp:106] Iteration 174624, lr = 0.0025
I0526 02:54:22.940897 27551 solver.cpp:237] Iteration 174838, loss = 1.17008
I0526 02:54:22.940943 27551 solver.cpp:253]     Train net output #0: loss = 1.17008 (* 1 = 1.17008 loss)
I0526 02:54:22.940973 27551 sgd_solver.cpp:106] Iteration 174838, lr = 0.0025
I0526 02:54:31.860087 27551 solver.cpp:237] Iteration 175052, loss = 1.21963
I0526 02:54:31.860124 27551 solver.cpp:253]     Train net output #0: loss = 1.21963 (* 1 = 1.21963 loss)
I0526 02:54:31.860142 27551 sgd_solver.cpp:106] Iteration 175052, lr = 0.0025
I0526 02:54:40.780998 27551 solver.cpp:237] Iteration 175266, loss = 0.998273
I0526 02:54:40.781179 27551 solver.cpp:253]     Train net output #0: loss = 0.998273 (* 1 = 0.998273 loss)
I0526 02:54:40.781196 27551 sgd_solver.cpp:106] Iteration 175266, lr = 0.0025
I0526 02:54:49.703672 27551 solver.cpp:237] Iteration 175480, loss = 1.18629
I0526 02:54:49.703718 27551 solver.cpp:253]     Train net output #0: loss = 1.18629 (* 1 = 1.18629 loss)
I0526 02:54:49.703747 27551 sgd_solver.cpp:106] Iteration 175480, lr = 0.0025
I0526 02:54:56.501148 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_175644.caffemodel
I0526 02:54:56.568922 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_175644.solverstate
I0526 02:55:19.068486 27551 solver.cpp:341] Iteration 175685, Testing net (#0)
I0526 02:56:07.012133 27551 solver.cpp:409]     Test net output #0: accuracy = 0.903461
I0526 02:56:07.012325 27551 solver.cpp:409]     Test net output #1: loss = 0.316563 (* 1 = 0.316563 loss)
I0526 02:56:07.398921 27551 solver.cpp:237] Iteration 175694, loss = 1.06593
I0526 02:56:07.398952 27551 solver.cpp:253]     Train net output #0: loss = 1.06593 (* 1 = 1.06593 loss)
I0526 02:56:07.398977 27551 sgd_solver.cpp:106] Iteration 175694, lr = 0.0025
I0526 02:56:16.287101 27551 solver.cpp:237] Iteration 175908, loss = 1.2046
I0526 02:56:16.287138 27551 solver.cpp:253]     Train net output #0: loss = 1.2046 (* 1 = 1.2046 loss)
I0526 02:56:16.287154 27551 sgd_solver.cpp:106] Iteration 175908, lr = 0.0025
I0526 02:56:25.171963 27551 solver.cpp:237] Iteration 176122, loss = 1.266
I0526 02:56:25.172014 27551 solver.cpp:253]     Train net output #0: loss = 1.266 (* 1 = 1.266 loss)
I0526 02:56:25.172044 27551 sgd_solver.cpp:106] Iteration 176122, lr = 0.0025
I0526 02:56:34.054929 27551 solver.cpp:237] Iteration 176336, loss = 1.21555
I0526 02:56:34.054965 27551 solver.cpp:253]     Train net output #0: loss = 1.21555 (* 1 = 1.21555 loss)
I0526 02:56:34.054985 27551 sgd_solver.cpp:106] Iteration 176336, lr = 0.0025
I0526 02:56:42.933405 27551 solver.cpp:237] Iteration 176550, loss = 1.38492
I0526 02:56:42.933588 27551 solver.cpp:253]     Train net output #0: loss = 1.38492 (* 1 = 1.38492 loss)
I0526 02:56:42.933605 27551 sgd_solver.cpp:106] Iteration 176550, lr = 0.0025
I0526 02:56:51.814615 27551 solver.cpp:237] Iteration 176764, loss = 1.16486
I0526 02:56:51.814668 27551 solver.cpp:253]     Train net output #0: loss = 1.16486 (* 1 = 1.16486 loss)
I0526 02:56:51.814692 27551 sgd_solver.cpp:106] Iteration 176764, lr = 0.0025
I0526 02:57:00.691632 27551 solver.cpp:237] Iteration 176978, loss = 1.50758
I0526 02:57:00.691668 27551 solver.cpp:253]     Train net output #0: loss = 1.50758 (* 1 = 1.50758 loss)
I0526 02:57:00.691685 27551 sgd_solver.cpp:106] Iteration 176978, lr = 0.0025
I0526 02:57:30.389817 27551 solver.cpp:237] Iteration 177192, loss = 1.07858
I0526 02:57:30.390022 27551 solver.cpp:253]     Train net output #0: loss = 1.07858 (* 1 = 1.07858 loss)
I0526 02:57:30.390039 27551 sgd_solver.cpp:106] Iteration 177192, lr = 0.0025
I0526 02:57:39.271108 27551 solver.cpp:237] Iteration 177406, loss = 1.17737
I0526 02:57:39.271162 27551 solver.cpp:253]     Train net output #0: loss = 1.17737 (* 1 = 1.17737 loss)
I0526 02:57:39.271189 27551 sgd_solver.cpp:106] Iteration 177406, lr = 0.0025
I0526 02:57:48.152745 27551 solver.cpp:237] Iteration 177620, loss = 0.903277
I0526 02:57:48.152783 27551 solver.cpp:253]     Train net output #0: loss = 0.903277 (* 1 = 0.903277 loss)
I0526 02:57:48.152801 27551 sgd_solver.cpp:106] Iteration 177620, lr = 0.0025
I0526 02:57:55.003108 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_177786.caffemodel
I0526 02:57:55.075754 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_177786.solverstate
I0526 02:57:57.111610 27551 solver.cpp:237] Iteration 177834, loss = 1.24803
I0526 02:57:57.111661 27551 solver.cpp:253]     Train net output #0: loss = 1.24803 (* 1 = 1.24803 loss)
I0526 02:57:57.111688 27551 sgd_solver.cpp:106] Iteration 177834, lr = 0.0025
I0526 02:58:05.991832 27551 solver.cpp:237] Iteration 178048, loss = 1.32645
I0526 02:58:05.992028 27551 solver.cpp:253]     Train net output #0: loss = 1.32645 (* 1 = 1.32645 loss)
I0526 02:58:05.992046 27551 sgd_solver.cpp:106] Iteration 178048, lr = 0.0025
I0526 02:58:14.879194 27551 solver.cpp:237] Iteration 178262, loss = 0.935555
I0526 02:58:14.879232 27551 solver.cpp:253]     Train net output #0: loss = 0.935555 (* 1 = 0.935555 loss)
I0526 02:58:14.879250 27551 sgd_solver.cpp:106] Iteration 178262, lr = 0.0025
I0526 02:58:23.757501 27551 solver.cpp:237] Iteration 178476, loss = 1.11477
I0526 02:58:23.757537 27551 solver.cpp:253]     Train net output #0: loss = 1.11477 (* 1 = 1.11477 loss)
I0526 02:58:23.757555 27551 sgd_solver.cpp:106] Iteration 178476, lr = 0.0025
I0526 02:58:53.446549 27551 solver.cpp:237] Iteration 178690, loss = 1.18875
I0526 02:58:53.446733 27551 solver.cpp:253]     Train net output #0: loss = 1.18875 (* 1 = 1.18875 loss)
I0526 02:58:53.446753 27551 sgd_solver.cpp:106] Iteration 178690, lr = 0.0025
I0526 02:59:02.327734 27551 solver.cpp:237] Iteration 178904, loss = 1.16076
I0526 02:59:02.327770 27551 solver.cpp:253]     Train net output #0: loss = 1.16076 (* 1 = 1.16076 loss)
I0526 02:59:02.327790 27551 sgd_solver.cpp:106] Iteration 178904, lr = 0.0025
I0526 02:59:11.212461 27551 solver.cpp:237] Iteration 179118, loss = 0.941636
I0526 02:59:11.212499 27551 solver.cpp:253]     Train net output #0: loss = 0.941636 (* 1 = 0.941636 loss)
I0526 02:59:11.212517 27551 sgd_solver.cpp:106] Iteration 179118, lr = 0.0025
I0526 02:59:20.100229 27551 solver.cpp:237] Iteration 179332, loss = 1.03301
I0526 02:59:20.100280 27551 solver.cpp:253]     Train net output #0: loss = 1.03301 (* 1 = 1.03301 loss)
I0526 02:59:20.100304 27551 sgd_solver.cpp:106] Iteration 179332, lr = 0.0025
I0526 02:59:28.986773 27551 solver.cpp:237] Iteration 179546, loss = 1.08076
I0526 02:59:28.986949 27551 solver.cpp:253]     Train net output #0: loss = 1.08076 (* 1 = 1.08076 loss)
I0526 02:59:28.986966 27551 sgd_solver.cpp:106] Iteration 179546, lr = 0.0025
I0526 02:59:37.876633 27551 solver.cpp:237] Iteration 179760, loss = 1.25537
I0526 02:59:37.876670 27551 solver.cpp:253]     Train net output #0: loss = 1.25537 (* 1 = 1.25537 loss)
I0526 02:59:37.876689 27551 sgd_solver.cpp:106] Iteration 179760, lr = 0.0025
I0526 02:59:44.812114 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_179928.caffemodel
I0526 02:59:44.884675 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_179928.solverstate
I0526 03:00:07.442745 27551 solver.cpp:341] Iteration 179970, Testing net (#0)
I0526 03:01:16.144912 27551 solver.cpp:409]     Test net output #0: accuracy = 0.905022
I0526 03:01:16.145105 27551 solver.cpp:409]     Test net output #1: loss = 0.299141 (* 1 = 0.299141 loss)
I0526 03:01:16.323803 27551 solver.cpp:237] Iteration 179974, loss = 1.47929
I0526 03:01:16.323834 27551 solver.cpp:253]     Train net output #0: loss = 1.47929 (* 1 = 1.47929 loss)
I0526 03:01:16.323853 27551 sgd_solver.cpp:106] Iteration 179974, lr = 0.0025
I0526 03:01:25.201124 27551 solver.cpp:237] Iteration 180188, loss = 1.18017
I0526 03:01:25.201179 27551 solver.cpp:253]     Train net output #0: loss = 1.18017 (* 1 = 1.18017 loss)
I0526 03:01:25.201205 27551 sgd_solver.cpp:106] Iteration 180188, lr = 0.0025
I0526 03:01:34.077816 27551 solver.cpp:237] Iteration 180402, loss = 1.04369
I0526 03:01:34.077852 27551 solver.cpp:253]     Train net output #0: loss = 1.04369 (* 1 = 1.04369 loss)
I0526 03:01:34.077870 27551 sgd_solver.cpp:106] Iteration 180402, lr = 0.0025
I0526 03:01:42.959337 27551 solver.cpp:237] Iteration 180616, loss = 1.29763
I0526 03:01:42.959373 27551 solver.cpp:253]     Train net output #0: loss = 1.29763 (* 1 = 1.29763 loss)
I0526 03:01:42.959393 27551 sgd_solver.cpp:106] Iteration 180616, lr = 0.0025
I0526 03:01:51.839383 27551 solver.cpp:237] Iteration 180830, loss = 0.980648
I0526 03:01:51.839576 27551 solver.cpp:253]     Train net output #0: loss = 0.980648 (* 1 = 0.980648 loss)
I0526 03:01:51.839593 27551 sgd_solver.cpp:106] Iteration 180830, lr = 0.0025
I0526 03:02:00.723655 27551 solver.cpp:237] Iteration 181044, loss = 1.02968
I0526 03:02:00.723692 27551 solver.cpp:253]     Train net output #0: loss = 1.02968 (* 1 = 1.02968 loss)
I0526 03:02:00.723709 27551 sgd_solver.cpp:106] Iteration 181044, lr = 0.0025
I0526 03:02:09.608047 27551 solver.cpp:237] Iteration 181258, loss = 1.13771
I0526 03:02:09.608083 27551 solver.cpp:253]     Train net output #0: loss = 1.13771 (* 1 = 1.13771 loss)
I0526 03:02:09.608101 27551 sgd_solver.cpp:106] Iteration 181258, lr = 0.0025
I0526 03:02:39.290966 27551 solver.cpp:237] Iteration 181472, loss = 0.926568
I0526 03:02:39.291164 27551 solver.cpp:253]     Train net output #0: loss = 0.926568 (* 1 = 0.926568 loss)
I0526 03:02:39.291182 27551 sgd_solver.cpp:106] Iteration 181472, lr = 0.0025
I0526 03:02:48.183091 27551 solver.cpp:237] Iteration 181686, loss = 1.42482
I0526 03:02:48.183127 27551 solver.cpp:253]     Train net output #0: loss = 1.42482 (* 1 = 1.42482 loss)
I0526 03:02:48.183151 27551 sgd_solver.cpp:106] Iteration 181686, lr = 0.0025
I0526 03:02:57.079068 27551 solver.cpp:237] Iteration 181900, loss = 1.15493
I0526 03:02:57.079104 27551 solver.cpp:253]     Train net output #0: loss = 1.15493 (* 1 = 1.15493 loss)
I0526 03:02:57.079123 27551 sgd_solver.cpp:106] Iteration 181900, lr = 0.0025
I0526 03:03:04.107038 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_182070.caffemodel
I0526 03:03:04.173938 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_182070.solverstate
I0526 03:03:06.042582 27551 solver.cpp:237] Iteration 182114, loss = 1.18134
I0526 03:03:06.042634 27551 solver.cpp:253]     Train net output #0: loss = 1.18134 (* 1 = 1.18134 loss)
I0526 03:03:06.042654 27551 sgd_solver.cpp:106] Iteration 182114, lr = 0.0025
I0526 03:03:14.935214 27551 solver.cpp:237] Iteration 182328, loss = 1.17433
I0526 03:03:14.935392 27551 solver.cpp:253]     Train net output #0: loss = 1.17433 (* 1 = 1.17433 loss)
I0526 03:03:14.935410 27551 sgd_solver.cpp:106] Iteration 182328, lr = 0.0025
I0526 03:03:23.831457 27551 solver.cpp:237] Iteration 182542, loss = 1.38051
I0526 03:03:23.831493 27551 solver.cpp:253]     Train net output #0: loss = 1.38051 (* 1 = 1.38051 loss)
I0526 03:03:23.831512 27551 sgd_solver.cpp:106] Iteration 182542, lr = 0.0025
I0526 03:03:32.725904 27551 solver.cpp:237] Iteration 182756, loss = 1.17498
I0526 03:03:32.725955 27551 solver.cpp:253]     Train net output #0: loss = 1.17498 (* 1 = 1.17498 loss)
I0526 03:03:32.725975 27551 sgd_solver.cpp:106] Iteration 182756, lr = 0.0025
I0526 03:04:02.453418 27551 solver.cpp:237] Iteration 182970, loss = 1.07372
I0526 03:04:02.453636 27551 solver.cpp:253]     Train net output #0: loss = 1.07372 (* 1 = 1.07372 loss)
I0526 03:04:02.453655 27551 sgd_solver.cpp:106] Iteration 182970, lr = 0.0025
I0526 03:04:11.351696 27551 solver.cpp:237] Iteration 183184, loss = 0.977883
I0526 03:04:11.351733 27551 solver.cpp:253]     Train net output #0: loss = 0.977883 (* 1 = 0.977883 loss)
I0526 03:04:11.351752 27551 sgd_solver.cpp:106] Iteration 183184, lr = 0.0025
I0526 03:04:20.246263 27551 solver.cpp:237] Iteration 183398, loss = 0.882332
I0526 03:04:20.246315 27551 solver.cpp:253]     Train net output #0: loss = 0.882332 (* 1 = 0.882332 loss)
I0526 03:04:20.246335 27551 sgd_solver.cpp:106] Iteration 183398, lr = 0.0025
I0526 03:04:29.148434 27551 solver.cpp:237] Iteration 183612, loss = 1.15487
I0526 03:04:29.148471 27551 solver.cpp:253]     Train net output #0: loss = 1.15487 (* 1 = 1.15487 loss)
I0526 03:04:29.148489 27551 sgd_solver.cpp:106] Iteration 183612, lr = 0.0025
I0526 03:04:38.042564 27551 solver.cpp:237] Iteration 183826, loss = 1.12181
I0526 03:04:38.042743 27551 solver.cpp:253]     Train net output #0: loss = 1.12181 (* 1 = 1.12181 loss)
I0526 03:04:38.042762 27551 sgd_solver.cpp:106] Iteration 183826, lr = 0.0025
I0526 03:04:46.932811 27551 solver.cpp:237] Iteration 184040, loss = 1.23708
I0526 03:04:46.932862 27551 solver.cpp:253]     Train net output #0: loss = 1.23708 (* 1 = 1.23708 loss)
I0526 03:04:46.932888 27551 sgd_solver.cpp:106] Iteration 184040, lr = 0.0025
I0526 03:04:54.032495 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_184212.caffemodel
I0526 03:04:54.098752 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_184212.solverstate
I0526 03:05:16.669636 27551 solver.cpp:237] Iteration 184254, loss = 0.974298
I0526 03:05:16.669834 27551 solver.cpp:253]     Train net output #0: loss = 0.974298 (* 1 = 0.974298 loss)
I0526 03:05:16.669852 27551 sgd_solver.cpp:106] Iteration 184254, lr = 0.0025
I0526 03:05:16.670434 27551 solver.cpp:341] Iteration 184255, Testing net (#0)
I0526 03:06:04.277055 27551 solver.cpp:409]     Test net output #0: accuracy = 0.903875
I0526 03:06:04.277252 27551 solver.cpp:409]     Test net output #1: loss = 0.307641 (* 1 = 0.307641 loss)
I0526 03:06:13.136538 27551 solver.cpp:237] Iteration 184468, loss = 1.57538
I0526 03:06:13.136574 27551 solver.cpp:253]     Train net output #0: loss = 1.57538 (* 1 = 1.57538 loss)
I0526 03:06:13.136593 27551 sgd_solver.cpp:106] Iteration 184468, lr = 0.0025
I0526 03:06:22.017437 27551 solver.cpp:237] Iteration 184682, loss = 1.15814
I0526 03:06:22.017474 27551 solver.cpp:253]     Train net output #0: loss = 1.15814 (* 1 = 1.15814 loss)
I0526 03:06:22.017493 27551 sgd_solver.cpp:106] Iteration 184682, lr = 0.0025
I0526 03:06:30.899422 27551 solver.cpp:237] Iteration 184896, loss = 0.963736
I0526 03:06:30.899473 27551 solver.cpp:253]     Train net output #0: loss = 0.963736 (* 1 = 0.963736 loss)
I0526 03:06:30.899493 27551 sgd_solver.cpp:106] Iteration 184896, lr = 0.0025
I0526 03:06:39.773861 27551 solver.cpp:237] Iteration 185110, loss = 1.19094
I0526 03:06:39.774049 27551 solver.cpp:253]     Train net output #0: loss = 1.19094 (* 1 = 1.19094 loss)
I0526 03:06:39.774066 27551 sgd_solver.cpp:106] Iteration 185110, lr = 0.0025
I0526 03:06:48.649610 27551 solver.cpp:237] Iteration 185324, loss = 1.13115
I0526 03:06:48.649665 27551 solver.cpp:253]     Train net output #0: loss = 1.13115 (* 1 = 1.13115 loss)
I0526 03:06:48.649684 27551 sgd_solver.cpp:106] Iteration 185324, lr = 0.0025
I0526 03:06:57.528226 27551 solver.cpp:237] Iteration 185538, loss = 0.944152
I0526 03:06:57.528264 27551 solver.cpp:253]     Train net output #0: loss = 0.944152 (* 1 = 0.944152 loss)
I0526 03:06:57.528281 27551 sgd_solver.cpp:106] Iteration 185538, lr = 0.0025
I0526 03:07:27.167814 27551 solver.cpp:237] Iteration 185752, loss = 1.20334
I0526 03:07:27.168020 27551 solver.cpp:253]     Train net output #0: loss = 1.20334 (* 1 = 1.20334 loss)
I0526 03:07:27.168036 27551 sgd_solver.cpp:106] Iteration 185752, lr = 0.0025
I0526 03:07:36.045644 27551 solver.cpp:237] Iteration 185966, loss = 0.916867
I0526 03:07:36.045681 27551 solver.cpp:253]     Train net output #0: loss = 0.916867 (* 1 = 0.916867 loss)
I0526 03:07:36.045701 27551 sgd_solver.cpp:106] Iteration 185966, lr = 0.0025
I0526 03:07:44.923075 27551 solver.cpp:237] Iteration 186180, loss = 1.11795
I0526 03:07:44.923127 27551 solver.cpp:253]     Train net output #0: loss = 1.11795 (* 1 = 1.11795 loss)
I0526 03:07:44.923153 27551 sgd_solver.cpp:106] Iteration 186180, lr = 0.0025
I0526 03:07:52.099305 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_186354.caffemodel
I0526 03:07:52.167093 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_186354.solverstate
I0526 03:07:53.867967 27551 solver.cpp:237] Iteration 186394, loss = 1.26458
I0526 03:07:53.868017 27551 solver.cpp:253]     Train net output #0: loss = 1.26458 (* 1 = 1.26458 loss)
I0526 03:07:53.868036 27551 sgd_solver.cpp:106] Iteration 186394, lr = 0.0025
I0526 03:08:02.731623 27551 solver.cpp:237] Iteration 186608, loss = 0.954487
I0526 03:08:02.731808 27551 solver.cpp:253]     Train net output #0: loss = 0.954487 (* 1 = 0.954487 loss)
I0526 03:08:02.731824 27551 sgd_solver.cpp:106] Iteration 186608, lr = 0.0025
I0526 03:08:11.612287 27551 solver.cpp:237] Iteration 186822, loss = 1.03911
I0526 03:08:11.612341 27551 solver.cpp:253]     Train net output #0: loss = 1.03911 (* 1 = 1.03911 loss)
I0526 03:08:11.612367 27551 sgd_solver.cpp:106] Iteration 186822, lr = 0.0025
I0526 03:08:20.486330 27551 solver.cpp:237] Iteration 187036, loss = 1.1159
I0526 03:08:20.486366 27551 solver.cpp:253]     Train net output #0: loss = 1.1159 (* 1 = 1.1159 loss)
I0526 03:08:20.486384 27551 sgd_solver.cpp:106] Iteration 187036, lr = 0.0025
I0526 03:08:50.214283 27551 solver.cpp:237] Iteration 187250, loss = 1.21397
I0526 03:08:50.214486 27551 solver.cpp:253]     Train net output #0: loss = 1.21397 (* 1 = 1.21397 loss)
I0526 03:08:50.214504 27551 sgd_solver.cpp:106] Iteration 187250, lr = 0.0025
I0526 03:08:59.097261 27551 solver.cpp:237] Iteration 187464, loss = 1.01012
I0526 03:08:59.097311 27551 solver.cpp:253]     Train net output #0: loss = 1.01012 (* 1 = 1.01012 loss)
I0526 03:08:59.097332 27551 sgd_solver.cpp:106] Iteration 187464, lr = 0.0025
I0526 03:09:07.973458 27551 solver.cpp:237] Iteration 187678, loss = 1.11847
I0526 03:09:07.973495 27551 solver.cpp:253]     Train net output #0: loss = 1.11847 (* 1 = 1.11847 loss)
I0526 03:09:07.973512 27551 sgd_solver.cpp:106] Iteration 187678, lr = 0.0025
I0526 03:09:16.850711 27551 solver.cpp:237] Iteration 187892, loss = 1.24129
I0526 03:09:16.850749 27551 solver.cpp:253]     Train net output #0: loss = 1.24129 (* 1 = 1.24129 loss)
I0526 03:09:16.850766 27551 sgd_solver.cpp:106] Iteration 187892, lr = 0.0025
I0526 03:09:25.742658 27551 solver.cpp:237] Iteration 188106, loss = 0.933289
I0526 03:09:25.742852 27551 solver.cpp:253]     Train net output #0: loss = 0.933289 (* 1 = 0.933289 loss)
I0526 03:09:25.742871 27551 sgd_solver.cpp:106] Iteration 188106, lr = 0.0025
I0526 03:09:34.643031 27551 solver.cpp:237] Iteration 188320, loss = 0.889683
I0526 03:09:34.643069 27551 solver.cpp:253]     Train net output #0: loss = 0.889683 (* 1 = 0.889683 loss)
I0526 03:09:34.643086 27551 sgd_solver.cpp:106] Iteration 188320, lr = 0.0025
I0526 03:09:41.920955 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_188496.caffemodel
I0526 03:09:41.988718 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_188496.solverstate
I0526 03:10:04.475360 27551 solver.cpp:237] Iteration 188534, loss = 1.1184
I0526 03:10:04.475570 27551 solver.cpp:253]     Train net output #0: loss = 1.1184 (* 1 = 1.1184 loss)
I0526 03:10:04.475589 27551 sgd_solver.cpp:106] Iteration 188534, lr = 0.0025
I0526 03:10:04.682492 27551 solver.cpp:341] Iteration 188540, Testing net (#0)
I0526 03:11:13.448144 27551 solver.cpp:409]     Test net output #0: accuracy = 0.904322
I0526 03:11:13.448345 27551 solver.cpp:409]     Test net output #1: loss = 0.295825 (* 1 = 0.295825 loss)
I0526 03:11:22.103003 27551 solver.cpp:237] Iteration 188748, loss = 1.23363
I0526 03:11:22.103039 27551 solver.cpp:253]     Train net output #0: loss = 1.23363 (* 1 = 1.23363 loss)
I0526 03:11:22.103058 27551 sgd_solver.cpp:106] Iteration 188748, lr = 0.0025
I0526 03:11:30.981662 27551 solver.cpp:237] Iteration 188962, loss = 1.21335
I0526 03:11:30.981717 27551 solver.cpp:253]     Train net output #0: loss = 1.21335 (* 1 = 1.21335 loss)
I0526 03:11:30.981736 27551 sgd_solver.cpp:106] Iteration 188962, lr = 0.0025
I0526 03:11:39.855826 27551 solver.cpp:237] Iteration 189176, loss = 0.960712
I0526 03:11:39.855865 27551 solver.cpp:253]     Train net output #0: loss = 0.960712 (* 1 = 0.960712 loss)
I0526 03:11:39.855882 27551 sgd_solver.cpp:106] Iteration 189176, lr = 0.0025
I0526 03:11:48.735129 27551 solver.cpp:237] Iteration 189390, loss = 1.19858
I0526 03:11:48.735321 27551 solver.cpp:253]     Train net output #0: loss = 1.19858 (* 1 = 1.19858 loss)
I0526 03:11:48.735339 27551 sgd_solver.cpp:106] Iteration 189390, lr = 0.0025
I0526 03:11:57.611779 27551 solver.cpp:237] Iteration 189604, loss = 1.12329
I0526 03:11:57.611819 27551 solver.cpp:253]     Train net output #0: loss = 1.12329 (* 1 = 1.12329 loss)
I0526 03:11:57.611835 27551 sgd_solver.cpp:106] Iteration 189604, lr = 0.0025
I0526 03:12:06.489809 27551 solver.cpp:237] Iteration 189818, loss = 1.04031
I0526 03:12:06.489845 27551 solver.cpp:253]     Train net output #0: loss = 1.04031 (* 1 = 1.04031 loss)
I0526 03:12:06.489863 27551 sgd_solver.cpp:106] Iteration 189818, lr = 0.0025
I0526 03:12:36.239240 27551 solver.cpp:237] Iteration 190032, loss = 1.0591
I0526 03:12:36.239439 27551 solver.cpp:253]     Train net output #0: loss = 1.0591 (* 1 = 1.0591 loss)
I0526 03:12:36.239456 27551 sgd_solver.cpp:106] Iteration 190032, lr = 0.0025
I0526 03:12:45.118820 27551 solver.cpp:237] Iteration 190246, loss = 1.30648
I0526 03:12:45.118872 27551 solver.cpp:253]     Train net output #0: loss = 1.30648 (* 1 = 1.30648 loss)
I0526 03:12:45.118898 27551 sgd_solver.cpp:106] Iteration 190246, lr = 0.0025
I0526 03:12:53.988250 27551 solver.cpp:237] Iteration 190460, loss = 1.0898
I0526 03:12:53.988287 27551 solver.cpp:253]     Train net output #0: loss = 1.0898 (* 1 = 1.0898 loss)
I0526 03:12:53.988304 27551 sgd_solver.cpp:106] Iteration 190460, lr = 0.0025
I0526 03:13:01.323484 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_190638.caffemodel
I0526 03:13:01.389997 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_190638.solverstate
I0526 03:13:02.919607 27551 solver.cpp:237] Iteration 190674, loss = 1.07789
I0526 03:13:02.919658 27551 solver.cpp:253]     Train net output #0: loss = 1.07789 (* 1 = 1.07789 loss)
I0526 03:13:02.919683 27551 sgd_solver.cpp:106] Iteration 190674, lr = 0.0025
I0526 03:13:11.789671 27551 solver.cpp:237] Iteration 190888, loss = 1.18938
I0526 03:13:11.789880 27551 solver.cpp:253]     Train net output #0: loss = 1.18938 (* 1 = 1.18938 loss)
I0526 03:13:11.789896 27551 sgd_solver.cpp:106] Iteration 190888, lr = 0.0025
I0526 03:13:20.659633 27551 solver.cpp:237] Iteration 191102, loss = 1.09088
I0526 03:13:20.659670 27551 solver.cpp:253]     Train net output #0: loss = 1.09088 (* 1 = 1.09088 loss)
I0526 03:13:20.659687 27551 sgd_solver.cpp:106] Iteration 191102, lr = 0.0025
I0526 03:13:29.526092 27551 solver.cpp:237] Iteration 191316, loss = 1.22259
I0526 03:13:29.526144 27551 solver.cpp:253]     Train net output #0: loss = 1.22259 (* 1 = 1.22259 loss)
I0526 03:13:29.526170 27551 sgd_solver.cpp:106] Iteration 191316, lr = 0.0025
I0526 03:13:59.205732 27551 solver.cpp:237] Iteration 191530, loss = 1.25665
I0526 03:13:59.205937 27551 solver.cpp:253]     Train net output #0: loss = 1.25665 (* 1 = 1.25665 loss)
I0526 03:13:59.205955 27551 sgd_solver.cpp:106] Iteration 191530, lr = 0.0025
I0526 03:14:08.072860 27551 solver.cpp:237] Iteration 191744, loss = 0.940794
I0526 03:14:08.072896 27551 solver.cpp:253]     Train net output #0: loss = 0.940794 (* 1 = 0.940794 loss)
I0526 03:14:08.072916 27551 sgd_solver.cpp:106] Iteration 191744, lr = 0.0025
I0526 03:14:16.947762 27551 solver.cpp:237] Iteration 191958, loss = 1.11006
I0526 03:14:16.947799 27551 solver.cpp:253]     Train net output #0: loss = 1.11006 (* 1 = 1.11006 loss)
I0526 03:14:16.947815 27551 sgd_solver.cpp:106] Iteration 191958, lr = 0.0025
I0526 03:14:25.818900 27551 solver.cpp:237] Iteration 192172, loss = 1.30331
I0526 03:14:25.818953 27551 solver.cpp:253]     Train net output #0: loss = 1.30331 (* 1 = 1.30331 loss)
I0526 03:14:25.818979 27551 sgd_solver.cpp:106] Iteration 192172, lr = 0.0025
I0526 03:14:34.694105 27551 solver.cpp:237] Iteration 192386, loss = 1.158
I0526 03:14:34.694286 27551 solver.cpp:253]     Train net output #0: loss = 1.158 (* 1 = 1.158 loss)
I0526 03:14:34.694303 27551 sgd_solver.cpp:106] Iteration 192386, lr = 0.0025
I0526 03:14:43.568665 27551 solver.cpp:237] Iteration 192600, loss = 1.31492
I0526 03:14:43.568717 27551 solver.cpp:253]     Train net output #0: loss = 1.31492 (* 1 = 1.31492 loss)
I0526 03:14:43.568742 27551 sgd_solver.cpp:106] Iteration 192600, lr = 0.0025
I0526 03:14:51.000062 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_192780.caffemodel
I0526 03:14:51.066606 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_192780.solverstate
I0526 03:14:52.519176 27551 solver.cpp:237] Iteration 192814, loss = 1.10574
I0526 03:14:52.519227 27551 solver.cpp:253]     Train net output #0: loss = 1.10574 (* 1 = 1.10574 loss)
I0526 03:14:52.519253 27551 sgd_solver.cpp:106] Iteration 192814, lr = 0.0025
I0526 03:15:13.769521 27551 solver.cpp:341] Iteration 192825, Testing net (#0)
I0526 03:16:01.741237 27551 solver.cpp:409]     Test net output #0: accuracy = 0.904982
I0526 03:16:01.741439 27551 solver.cpp:409]     Test net output #1: loss = 0.29419 (* 1 = 0.29419 loss)
I0526 03:16:10.198580 27551 solver.cpp:237] Iteration 193028, loss = 1.25685
I0526 03:16:10.198617 27551 solver.cpp:253]     Train net output #0: loss = 1.25685 (* 1 = 1.25685 loss)
I0526 03:16:10.198637 27551 sgd_solver.cpp:106] Iteration 193028, lr = 0.0025
I0526 03:16:19.096801 27551 solver.cpp:237] Iteration 193242, loss = 1.10869
I0526 03:16:19.096837 27551 solver.cpp:253]     Train net output #0: loss = 1.10869 (* 1 = 1.10869 loss)
I0526 03:16:19.096856 27551 sgd_solver.cpp:106] Iteration 193242, lr = 0.0025
I0526 03:16:27.997936 27551 solver.cpp:237] Iteration 193456, loss = 1.14872
I0526 03:16:27.997984 27551 solver.cpp:253]     Train net output #0: loss = 1.14872 (* 1 = 1.14872 loss)
I0526 03:16:27.998010 27551 sgd_solver.cpp:106] Iteration 193456, lr = 0.0025
I0526 03:16:36.901829 27551 solver.cpp:237] Iteration 193670, loss = 0.995697
I0526 03:16:36.902024 27551 solver.cpp:253]     Train net output #0: loss = 0.995697 (* 1 = 0.995697 loss)
I0526 03:16:36.902041 27551 sgd_solver.cpp:106] Iteration 193670, lr = 0.0025
I0526 03:16:45.803130 27551 solver.cpp:237] Iteration 193884, loss = 0.930778
I0526 03:16:45.803167 27551 solver.cpp:253]     Train net output #0: loss = 0.930778 (* 1 = 0.930778 loss)
I0526 03:16:45.803185 27551 sgd_solver.cpp:106] Iteration 193884, lr = 0.0025
I0526 03:16:54.709246 27551 solver.cpp:237] Iteration 194098, loss = 1.20742
I0526 03:16:54.709303 27551 solver.cpp:253]     Train net output #0: loss = 1.20742 (* 1 = 1.20742 loss)
I0526 03:16:54.709327 27551 sgd_solver.cpp:106] Iteration 194098, lr = 0.0025
I0526 03:17:24.469408 27551 solver.cpp:237] Iteration 194312, loss = 1.16541
I0526 03:17:24.469611 27551 solver.cpp:253]     Train net output #0: loss = 1.16541 (* 1 = 1.16541 loss)
I0526 03:17:24.469630 27551 sgd_solver.cpp:106] Iteration 194312, lr = 0.0025
I0526 03:17:33.372719 27551 solver.cpp:237] Iteration 194526, loss = 0.977171
I0526 03:17:33.372761 27551 solver.cpp:253]     Train net output #0: loss = 0.977171 (* 1 = 0.977171 loss)
I0526 03:17:33.372778 27551 sgd_solver.cpp:106] Iteration 194526, lr = 0.0025
I0526 03:17:42.273948 27551 solver.cpp:237] Iteration 194740, loss = 1.08887
I0526 03:17:42.274000 27551 solver.cpp:253]     Train net output #0: loss = 1.08887 (* 1 = 1.08887 loss)
I0526 03:17:42.274018 27551 sgd_solver.cpp:106] Iteration 194740, lr = 0.0025
I0526 03:17:49.803499 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_194922.caffemodel
I0526 03:17:49.878712 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_194922.solverstate
I0526 03:17:51.246640 27551 solver.cpp:237] Iteration 194954, loss = 1.03086
I0526 03:17:51.246691 27551 solver.cpp:253]     Train net output #0: loss = 1.03086 (* 1 = 1.03086 loss)
I0526 03:17:51.246716 27551 sgd_solver.cpp:106] Iteration 194954, lr = 0.0025
I0526 03:18:00.152266 27551 solver.cpp:237] Iteration 195168, loss = 0.898438
I0526 03:18:00.152448 27551 solver.cpp:253]     Train net output #0: loss = 0.898438 (* 1 = 0.898438 loss)
I0526 03:18:00.152465 27551 sgd_solver.cpp:106] Iteration 195168, lr = 0.0025
I0526 03:18:09.049021 27551 solver.cpp:237] Iteration 195382, loss = 1.08568
I0526 03:18:09.049072 27551 solver.cpp:253]     Train net output #0: loss = 1.08568 (* 1 = 1.08568 loss)
I0526 03:18:09.049096 27551 sgd_solver.cpp:106] Iteration 195382, lr = 0.0025
I0526 03:18:17.947419 27551 solver.cpp:237] Iteration 195596, loss = 1.16749
I0526 03:18:17.947455 27551 solver.cpp:253]     Train net output #0: loss = 1.16749 (* 1 = 1.16749 loss)
I0526 03:18:17.947474 27551 sgd_solver.cpp:106] Iteration 195596, lr = 0.0025
I0526 03:18:47.687274 27551 solver.cpp:237] Iteration 195810, loss = 1.31602
I0526 03:18:47.687480 27551 solver.cpp:253]     Train net output #0: loss = 1.31602 (* 1 = 1.31602 loss)
I0526 03:18:47.687499 27551 sgd_solver.cpp:106] Iteration 195810, lr = 0.0025
I0526 03:18:56.587807 27551 solver.cpp:237] Iteration 196024, loss = 1.1973
I0526 03:18:56.587859 27551 solver.cpp:253]     Train net output #0: loss = 1.1973 (* 1 = 1.1973 loss)
I0526 03:18:56.587885 27551 sgd_solver.cpp:106] Iteration 196024, lr = 0.0025
I0526 03:19:05.492471 27551 solver.cpp:237] Iteration 196238, loss = 1.22064
I0526 03:19:05.492507 27551 solver.cpp:253]     Train net output #0: loss = 1.22064 (* 1 = 1.22064 loss)
I0526 03:19:05.492525 27551 sgd_solver.cpp:106] Iteration 196238, lr = 0.0025
I0526 03:19:14.393934 27551 solver.cpp:237] Iteration 196452, loss = 1.08685
I0526 03:19:14.393972 27551 solver.cpp:253]     Train net output #0: loss = 1.08685 (* 1 = 1.08685 loss)
I0526 03:19:14.393990 27551 sgd_solver.cpp:106] Iteration 196452, lr = 0.0025
I0526 03:19:23.297309 27551 solver.cpp:237] Iteration 196666, loss = 1.30103
I0526 03:19:23.297520 27551 solver.cpp:253]     Train net output #0: loss = 1.30103 (* 1 = 1.30103 loss)
I0526 03:19:23.297538 27551 sgd_solver.cpp:106] Iteration 196666, lr = 0.0025
I0526 03:19:32.192884 27551 solver.cpp:237] Iteration 196880, loss = 1.04493
I0526 03:19:32.192921 27551 solver.cpp:253]     Train net output #0: loss = 1.04493 (* 1 = 1.04493 loss)
I0526 03:19:32.192939 27551 sgd_solver.cpp:106] Iteration 196880, lr = 0.0025
I0526 03:19:39.808475 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_197064.caffemodel
I0526 03:19:39.876965 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_197064.solverstate
I0526 03:19:41.165499 27551 solver.cpp:237] Iteration 197094, loss = 1.38296
I0526 03:19:41.165552 27551 solver.cpp:253]     Train net output #0: loss = 1.38296 (* 1 = 1.38296 loss)
I0526 03:19:41.165570 27551 sgd_solver.cpp:106] Iteration 197094, lr = 0.0025
I0526 03:20:02.614846 27551 solver.cpp:341] Iteration 197110, Testing net (#0)
I0526 03:21:11.397699 27551 solver.cpp:409]     Test net output #0: accuracy = 0.903835
I0526 03:21:11.397902 27551 solver.cpp:409]     Test net output #1: loss = 0.329647 (* 1 = 0.329647 loss)
I0526 03:21:19.624673 27551 solver.cpp:237] Iteration 197308, loss = 1.18537
I0526 03:21:19.624711 27551 solver.cpp:253]     Train net output #0: loss = 1.18537 (* 1 = 1.18537 loss)
I0526 03:21:19.624737 27551 sgd_solver.cpp:106] Iteration 197308, lr = 0.0025
I0526 03:21:28.509552 27551 solver.cpp:237] Iteration 197522, loss = 1.18862
I0526 03:21:28.509596 27551 solver.cpp:253]     Train net output #0: loss = 1.18862 (* 1 = 1.18862 loss)
I0526 03:21:28.509624 27551 sgd_solver.cpp:106] Iteration 197522, lr = 0.0025
I0526 03:21:37.398573 27551 solver.cpp:237] Iteration 197736, loss = 1.10985
I0526 03:21:37.398610 27551 solver.cpp:253]     Train net output #0: loss = 1.10985 (* 1 = 1.10985 loss)
I0526 03:21:37.398628 27551 sgd_solver.cpp:106] Iteration 197736, lr = 0.0025
I0526 03:21:46.286697 27551 solver.cpp:237] Iteration 197950, loss = 0.967506
I0526 03:21:46.286891 27551 solver.cpp:253]     Train net output #0: loss = 0.967506 (* 1 = 0.967506 loss)
I0526 03:21:46.286908 27551 sgd_solver.cpp:106] Iteration 197950, lr = 0.0025
I0526 03:21:55.174033 27551 solver.cpp:237] Iteration 198164, loss = 1.11585
I0526 03:21:55.174075 27551 solver.cpp:253]     Train net output #0: loss = 1.11585 (* 1 = 1.11585 loss)
I0526 03:21:55.174093 27551 sgd_solver.cpp:106] Iteration 198164, lr = 0.0025
I0526 03:22:04.059898 27551 solver.cpp:237] Iteration 198378, loss = 1.04578
I0526 03:22:04.059936 27551 solver.cpp:253]     Train net output #0: loss = 1.04578 (* 1 = 1.04578 loss)
I0526 03:22:04.059952 27551 sgd_solver.cpp:106] Iteration 198378, lr = 0.0025
I0526 03:22:33.765225 27551 solver.cpp:237] Iteration 198592, loss = 1.45419
I0526 03:22:33.765429 27551 solver.cpp:253]     Train net output #0: loss = 1.45419 (* 1 = 1.45419 loss)
I0526 03:22:33.765447 27551 sgd_solver.cpp:106] Iteration 198592, lr = 0.0025
I0526 03:22:42.657383 27551 solver.cpp:237] Iteration 198806, loss = 1.34696
I0526 03:22:42.657434 27551 solver.cpp:253]     Train net output #0: loss = 1.34696 (* 1 = 1.34696 loss)
I0526 03:22:42.657462 27551 sgd_solver.cpp:106] Iteration 198806, lr = 0.0025
I0526 03:22:51.541920 27551 solver.cpp:237] Iteration 199020, loss = 1.27871
I0526 03:22:51.541959 27551 solver.cpp:253]     Train net output #0: loss = 1.27871 (* 1 = 1.27871 loss)
I0526 03:22:51.541975 27551 sgd_solver.cpp:106] Iteration 199020, lr = 0.0025
I0526 03:22:59.224236 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_199206.caffemodel
I0526 03:22:59.292632 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_199206.solverstate
I0526 03:23:00.497931 27551 solver.cpp:237] Iteration 199234, loss = 1.09298
I0526 03:23:00.497988 27551 solver.cpp:253]     Train net output #0: loss = 1.09298 (* 1 = 1.09298 loss)
I0526 03:23:00.498013 27551 sgd_solver.cpp:106] Iteration 199234, lr = 0.0025
I0526 03:23:09.391167 27551 solver.cpp:237] Iteration 199448, loss = 0.937449
I0526 03:23:09.391382 27551 solver.cpp:253]     Train net output #0: loss = 0.937449 (* 1 = 0.937449 loss)
I0526 03:23:09.391401 27551 sgd_solver.cpp:106] Iteration 199448, lr = 0.0025
I0526 03:23:18.277580 27551 solver.cpp:237] Iteration 199662, loss = 1.09498
I0526 03:23:18.277618 27551 solver.cpp:253]     Train net output #0: loss = 1.09498 (* 1 = 1.09498 loss)
I0526 03:23:18.277636 27551 sgd_solver.cpp:106] Iteration 199662, lr = 0.0025
I0526 03:23:27.163643 27551 solver.cpp:237] Iteration 199876, loss = 0.923977
I0526 03:23:27.163681 27551 solver.cpp:253]     Train net output #0: loss = 0.923977 (* 1 = 0.923977 loss)
I0526 03:23:27.163699 27551 sgd_solver.cpp:106] Iteration 199876, lr = 0.0025
I0526 03:23:56.855100 27551 solver.cpp:237] Iteration 200090, loss = 1.26633
I0526 03:23:56.855309 27551 solver.cpp:253]     Train net output #0: loss = 1.26633 (* 1 = 1.26633 loss)
I0526 03:23:56.855329 27551 sgd_solver.cpp:106] Iteration 200090, lr = 0.0025
I0526 03:24:05.740250 27551 solver.cpp:237] Iteration 200304, loss = 1.31857
I0526 03:24:05.740286 27551 solver.cpp:253]     Train net output #0: loss = 1.31857 (* 1 = 1.31857 loss)
I0526 03:24:05.740304 27551 sgd_solver.cpp:106] Iteration 200304, lr = 0.0025
I0526 03:24:14.627763 27551 solver.cpp:237] Iteration 200518, loss = 1.18839
I0526 03:24:14.627801 27551 solver.cpp:253]     Train net output #0: loss = 1.18839 (* 1 = 1.18839 loss)
I0526 03:24:14.627818 27551 sgd_solver.cpp:106] Iteration 200518, lr = 0.0025
I0526 03:24:23.513730 27551 solver.cpp:237] Iteration 200732, loss = 1.16991
I0526 03:24:23.513783 27551 solver.cpp:253]     Train net output #0: loss = 1.16991 (* 1 = 1.16991 loss)
I0526 03:24:23.513809 27551 sgd_solver.cpp:106] Iteration 200732, lr = 0.0025
I0526 03:24:32.398211 27551 solver.cpp:237] Iteration 200946, loss = 1.23437
I0526 03:24:32.398409 27551 solver.cpp:253]     Train net output #0: loss = 1.23437 (* 1 = 1.23437 loss)
I0526 03:24:32.398427 27551 sgd_solver.cpp:106] Iteration 200946, lr = 0.0025
I0526 03:24:41.280333 27551 solver.cpp:237] Iteration 201160, loss = 1.2257
I0526 03:24:41.280370 27551 solver.cpp:253]     Train net output #0: loss = 1.2257 (* 1 = 1.2257 loss)
I0526 03:24:41.280388 27551 sgd_solver.cpp:106] Iteration 201160, lr = 0.0025
I0526 03:24:49.041836 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_201348.caffemodel
I0526 03:24:49.108013 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_201348.solverstate
I0526 03:24:50.226820 27551 solver.cpp:237] Iteration 201374, loss = 1.21615
I0526 03:24:50.226871 27551 solver.cpp:253]     Train net output #0: loss = 1.21615 (* 1 = 1.21615 loss)
I0526 03:24:50.226897 27551 sgd_solver.cpp:106] Iteration 201374, lr = 0.0025
I0526 03:25:11.844277 27551 solver.cpp:341] Iteration 201395, Testing net (#0)
I0526 03:25:59.417937 27551 solver.cpp:409]     Test net output #0: accuracy = 0.905262
I0526 03:25:59.418140 27551 solver.cpp:409]     Test net output #1: loss = 0.304949 (* 1 = 0.304949 loss)
I0526 03:26:07.458179 27551 solver.cpp:237] Iteration 201588, loss = 0.901144
I0526 03:26:07.458220 27551 solver.cpp:253]     Train net output #0: loss = 0.901144 (* 1 = 0.901144 loss)
I0526 03:26:07.458236 27551 sgd_solver.cpp:106] Iteration 201588, lr = 0.0025
I0526 03:26:16.352519 27551 solver.cpp:237] Iteration 201802, loss = 1.12354
I0526 03:26:16.352555 27551 solver.cpp:253]     Train net output #0: loss = 1.12354 (* 1 = 1.12354 loss)
I0526 03:26:16.352573 27551 sgd_solver.cpp:106] Iteration 201802, lr = 0.0025
I0526 03:26:25.246958 27551 solver.cpp:237] Iteration 202016, loss = 1.41211
I0526 03:26:25.247012 27551 solver.cpp:253]     Train net output #0: loss = 1.41211 (* 1 = 1.41211 loss)
I0526 03:26:25.247040 27551 sgd_solver.cpp:106] Iteration 202016, lr = 0.0025
I0526 03:26:34.145912 27551 solver.cpp:237] Iteration 202230, loss = 1.05617
I0526 03:26:34.146109 27551 solver.cpp:253]     Train net output #0: loss = 1.05617 (* 1 = 1.05617 loss)
I0526 03:26:34.146126 27551 sgd_solver.cpp:106] Iteration 202230, lr = 0.0025
I0526 03:26:43.043205 27551 solver.cpp:237] Iteration 202444, loss = 1.28017
I0526 03:26:43.043241 27551 solver.cpp:253]     Train net output #0: loss = 1.28017 (* 1 = 1.28017 loss)
I0526 03:26:43.043259 27551 sgd_solver.cpp:106] Iteration 202444, lr = 0.0025
I0526 03:26:51.948248 27551 solver.cpp:237] Iteration 202658, loss = 1.16198
I0526 03:26:51.948299 27551 solver.cpp:253]     Train net output #0: loss = 1.16198 (* 1 = 1.16198 loss)
I0526 03:26:51.948317 27551 sgd_solver.cpp:106] Iteration 202658, lr = 0.0025
I0526 03:27:21.656518 27551 solver.cpp:237] Iteration 202872, loss = 0.944645
I0526 03:27:21.656731 27551 solver.cpp:253]     Train net output #0: loss = 0.944645 (* 1 = 0.944645 loss)
I0526 03:27:21.656750 27551 sgd_solver.cpp:106] Iteration 202872, lr = 0.0025
I0526 03:27:30.556219 27551 solver.cpp:237] Iteration 203086, loss = 1.14701
I0526 03:27:30.556255 27551 solver.cpp:253]     Train net output #0: loss = 1.14701 (* 1 = 1.14701 loss)
I0526 03:27:30.556279 27551 sgd_solver.cpp:106] Iteration 203086, lr = 0.0025
I0526 03:27:39.452195 27551 solver.cpp:237] Iteration 203300, loss = 0.904301
I0526 03:27:39.452246 27551 solver.cpp:253]     Train net output #0: loss = 0.904301 (* 1 = 0.904301 loss)
I0526 03:27:39.452266 27551 sgd_solver.cpp:106] Iteration 203300, lr = 0.0025
I0526 03:27:47.313038 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_203490.caffemodel
I0526 03:27:47.379487 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_203490.solverstate
I0526 03:27:48.414139 27551 solver.cpp:237] Iteration 203514, loss = 0.964396
I0526 03:27:48.414189 27551 solver.cpp:253]     Train net output #0: loss = 0.964396 (* 1 = 0.964396 loss)
I0526 03:27:48.414209 27551 sgd_solver.cpp:106] Iteration 203514, lr = 0.0025
I0526 03:27:57.321677 27551 solver.cpp:237] Iteration 203728, loss = 1.02624
I0526 03:27:57.321867 27551 solver.cpp:253]     Train net output #0: loss = 1.02624 (* 1 = 1.02624 loss)
I0526 03:27:57.321883 27551 sgd_solver.cpp:106] Iteration 203728, lr = 0.0025
I0526 03:28:06.226646 27551 solver.cpp:237] Iteration 203942, loss = 1.17291
I0526 03:28:06.226699 27551 solver.cpp:253]     Train net output #0: loss = 1.17291 (* 1 = 1.17291 loss)
I0526 03:28:06.226725 27551 sgd_solver.cpp:106] Iteration 203942, lr = 0.0025
I0526 03:28:15.129675 27551 solver.cpp:237] Iteration 204156, loss = 0.982244
I0526 03:28:15.129711 27551 solver.cpp:253]     Train net output #0: loss = 0.982244 (* 1 = 0.982244 loss)
I0526 03:28:15.129730 27551 sgd_solver.cpp:106] Iteration 204156, lr = 0.0025
I0526 03:28:44.809981 27551 solver.cpp:237] Iteration 204370, loss = 1.16937
I0526 03:28:44.810187 27551 solver.cpp:253]     Train net output #0: loss = 1.16937 (* 1 = 1.16937 loss)
I0526 03:28:44.810204 27551 sgd_solver.cpp:106] Iteration 204370, lr = 0.0025
I0526 03:28:53.719285 27551 solver.cpp:237] Iteration 204584, loss = 1.15751
I0526 03:28:53.719336 27551 solver.cpp:253]     Train net output #0: loss = 1.15751 (* 1 = 1.15751 loss)
I0526 03:28:53.719364 27551 sgd_solver.cpp:106] Iteration 204584, lr = 0.0025
I0526 03:29:02.610103 27551 solver.cpp:237] Iteration 204798, loss = 1.01632
I0526 03:29:02.610139 27551 solver.cpp:253]     Train net output #0: loss = 1.01632 (* 1 = 1.01632 loss)
I0526 03:29:02.610157 27551 sgd_solver.cpp:106] Iteration 204798, lr = 0.0025
I0526 03:29:11.499660 27551 solver.cpp:237] Iteration 205012, loss = 0.995824
I0526 03:29:11.499698 27551 solver.cpp:253]     Train net output #0: loss = 0.995824 (* 1 = 0.995824 loss)
I0526 03:29:11.499716 27551 sgd_solver.cpp:106] Iteration 205012, lr = 0.0025
I0526 03:29:20.394415 27551 solver.cpp:237] Iteration 205226, loss = 1.05323
I0526 03:29:20.394629 27551 solver.cpp:253]     Train net output #0: loss = 1.05323 (* 1 = 1.05323 loss)
I0526 03:29:20.394649 27551 sgd_solver.cpp:106] Iteration 205226, lr = 0.0025
I0526 03:29:29.289948 27551 solver.cpp:237] Iteration 205440, loss = 1.02694
I0526 03:29:29.289986 27551 solver.cpp:253]     Train net output #0: loss = 1.02694 (* 1 = 1.02694 loss)
I0526 03:29:29.290002 27551 sgd_solver.cpp:106] Iteration 205440, lr = 0.0025
I0526 03:29:37.233080 27551 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_205632.caffemodel
I0526 03:29:37.300127 27551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_205632.solverstate
I0526 03:29:38.253037 27551 solver.cpp:237] Iteration 205654, loss = 1.26471
I0526 03:29:38.253088 27551 solver.cpp:253]     Train net output #0: loss = 1.26471 (* 1 = 1.26471 loss)
I0526 03:29:38.253105 27551 sgd_solver.cpp:106] Iteration 205654, lr = 0.0025
aprun: Apid 11266481: Caught signal Terminated, sending to application
*** Aborted at 1464247792 (unix time) try "date -d @1464247792" if you are using GNU date ***
aprun: Apid 11266481: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9bb3b (unknown)
aprun: Apid 11266481: Caught signal Terminated, sending to application
*** SIGTERM (@0x6b9c) received by PID 27551 (TID 0x2aaac746f900) from PID 27548; stack trace: ***
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaac5e9bb3b (unknown)
=>> PBS: job killed: walltime 7220 exceeded limit 7200
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11266481: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11266481: Caught signal Terminated, sending to application
aprun: Apid 11266481: Caught signal Terminated, sending to application
aprun: Apid 11266481: Caught signal Terminated, sending to application
