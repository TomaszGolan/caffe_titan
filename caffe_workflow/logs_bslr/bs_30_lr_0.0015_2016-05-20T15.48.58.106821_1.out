2807237
I0522 08:06:38.375318 10501 caffe.cpp:184] Using GPUs 0
I0522 08:06:38.806380 10501 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.0015
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821.prototxt"
I0522 08:06:38.808436 10501 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821.prototxt
I0522 08:06:38.819869 10501 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 08:06:38.819927 10501 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 08:06:38.820276 10501 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 08:06:38.820458 10501 layer_factory.hpp:77] Creating layer data_hdf5
I0522 08:06:38.820482 10501 net.cpp:106] Creating Layer data_hdf5
I0522 08:06:38.820497 10501 net.cpp:411] data_hdf5 -> data
I0522 08:06:38.820529 10501 net.cpp:411] data_hdf5 -> label
I0522 08:06:38.820561 10501 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 08:06:38.821888 10501 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 08:06:38.824203 10501 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 08:07:00.377770 10501 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 08:07:00.383033 10501 net.cpp:150] Setting up data_hdf5
I0522 08:07:00.383077 10501 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 08:07:00.383092 10501 net.cpp:157] Top shape: 30 (30)
I0522 08:07:00.383103 10501 net.cpp:165] Memory required for data: 762120
I0522 08:07:00.383116 10501 layer_factory.hpp:77] Creating layer conv1
I0522 08:07:00.383150 10501 net.cpp:106] Creating Layer conv1
I0522 08:07:00.383162 10501 net.cpp:454] conv1 <- data
I0522 08:07:00.383184 10501 net.cpp:411] conv1 -> conv1
I0522 08:07:00.749903 10501 net.cpp:150] Setting up conv1
I0522 08:07:00.749948 10501 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 08:07:00.749958 10501 net.cpp:165] Memory required for data: 9056520
I0522 08:07:00.749986 10501 layer_factory.hpp:77] Creating layer relu1
I0522 08:07:00.750008 10501 net.cpp:106] Creating Layer relu1
I0522 08:07:00.750020 10501 net.cpp:454] relu1 <- conv1
I0522 08:07:00.750032 10501 net.cpp:397] relu1 -> conv1 (in-place)
I0522 08:07:00.750548 10501 net.cpp:150] Setting up relu1
I0522 08:07:00.750565 10501 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 08:07:00.750576 10501 net.cpp:165] Memory required for data: 17350920
I0522 08:07:00.750586 10501 layer_factory.hpp:77] Creating layer pool1
I0522 08:07:00.750602 10501 net.cpp:106] Creating Layer pool1
I0522 08:07:00.750613 10501 net.cpp:454] pool1 <- conv1
I0522 08:07:00.750627 10501 net.cpp:411] pool1 -> pool1
I0522 08:07:00.750707 10501 net.cpp:150] Setting up pool1
I0522 08:07:00.750721 10501 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 08:07:00.750730 10501 net.cpp:165] Memory required for data: 21498120
I0522 08:07:00.750741 10501 layer_factory.hpp:77] Creating layer conv2
I0522 08:07:00.750764 10501 net.cpp:106] Creating Layer conv2
I0522 08:07:00.750774 10501 net.cpp:454] conv2 <- pool1
I0522 08:07:00.750787 10501 net.cpp:411] conv2 -> conv2
I0522 08:07:00.753486 10501 net.cpp:150] Setting up conv2
I0522 08:07:00.753515 10501 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 08:07:00.753527 10501 net.cpp:165] Memory required for data: 27459720
I0522 08:07:00.753548 10501 layer_factory.hpp:77] Creating layer relu2
I0522 08:07:00.753563 10501 net.cpp:106] Creating Layer relu2
I0522 08:07:00.753573 10501 net.cpp:454] relu2 <- conv2
I0522 08:07:00.753587 10501 net.cpp:397] relu2 -> conv2 (in-place)
I0522 08:07:00.753917 10501 net.cpp:150] Setting up relu2
I0522 08:07:00.753931 10501 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 08:07:00.753942 10501 net.cpp:165] Memory required for data: 33421320
I0522 08:07:00.753952 10501 layer_factory.hpp:77] Creating layer pool2
I0522 08:07:00.753965 10501 net.cpp:106] Creating Layer pool2
I0522 08:07:00.753975 10501 net.cpp:454] pool2 <- conv2
I0522 08:07:00.753988 10501 net.cpp:411] pool2 -> pool2
I0522 08:07:00.754070 10501 net.cpp:150] Setting up pool2
I0522 08:07:00.754082 10501 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 08:07:00.754092 10501 net.cpp:165] Memory required for data: 36402120
I0522 08:07:00.754102 10501 layer_factory.hpp:77] Creating layer conv3
I0522 08:07:00.754118 10501 net.cpp:106] Creating Layer conv3
I0522 08:07:00.754128 10501 net.cpp:454] conv3 <- pool2
I0522 08:07:00.754142 10501 net.cpp:411] conv3 -> conv3
I0522 08:07:00.756114 10501 net.cpp:150] Setting up conv3
I0522 08:07:00.756137 10501 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 08:07:00.756150 10501 net.cpp:165] Memory required for data: 39654600
I0522 08:07:00.756168 10501 layer_factory.hpp:77] Creating layer relu3
I0522 08:07:00.756184 10501 net.cpp:106] Creating Layer relu3
I0522 08:07:00.756194 10501 net.cpp:454] relu3 <- conv3
I0522 08:07:00.756206 10501 net.cpp:397] relu3 -> conv3 (in-place)
I0522 08:07:00.756675 10501 net.cpp:150] Setting up relu3
I0522 08:07:00.756692 10501 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 08:07:00.756702 10501 net.cpp:165] Memory required for data: 42907080
I0522 08:07:00.756713 10501 layer_factory.hpp:77] Creating layer pool3
I0522 08:07:00.756726 10501 net.cpp:106] Creating Layer pool3
I0522 08:07:00.756736 10501 net.cpp:454] pool3 <- conv3
I0522 08:07:00.756748 10501 net.cpp:411] pool3 -> pool3
I0522 08:07:00.756816 10501 net.cpp:150] Setting up pool3
I0522 08:07:00.756829 10501 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 08:07:00.756839 10501 net.cpp:165] Memory required for data: 44533320
I0522 08:07:00.756849 10501 layer_factory.hpp:77] Creating layer conv4
I0522 08:07:00.756863 10501 net.cpp:106] Creating Layer conv4
I0522 08:07:00.756873 10501 net.cpp:454] conv4 <- pool3
I0522 08:07:00.756888 10501 net.cpp:411] conv4 -> conv4
I0522 08:07:00.759603 10501 net.cpp:150] Setting up conv4
I0522 08:07:00.759632 10501 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 08:07:00.759651 10501 net.cpp:165] Memory required for data: 45621960
I0522 08:07:00.759668 10501 layer_factory.hpp:77] Creating layer relu4
I0522 08:07:00.759682 10501 net.cpp:106] Creating Layer relu4
I0522 08:07:00.759693 10501 net.cpp:454] relu4 <- conv4
I0522 08:07:00.759706 10501 net.cpp:397] relu4 -> conv4 (in-place)
I0522 08:07:00.760174 10501 net.cpp:150] Setting up relu4
I0522 08:07:00.760190 10501 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 08:07:00.760200 10501 net.cpp:165] Memory required for data: 46710600
I0522 08:07:00.760210 10501 layer_factory.hpp:77] Creating layer pool4
I0522 08:07:00.760223 10501 net.cpp:106] Creating Layer pool4
I0522 08:07:00.760233 10501 net.cpp:454] pool4 <- conv4
I0522 08:07:00.760246 10501 net.cpp:411] pool4 -> pool4
I0522 08:07:00.760314 10501 net.cpp:150] Setting up pool4
I0522 08:07:00.760329 10501 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 08:07:00.760339 10501 net.cpp:165] Memory required for data: 47254920
I0522 08:07:00.760349 10501 layer_factory.hpp:77] Creating layer ip1
I0522 08:07:00.760370 10501 net.cpp:106] Creating Layer ip1
I0522 08:07:00.760380 10501 net.cpp:454] ip1 <- pool4
I0522 08:07:00.760393 10501 net.cpp:411] ip1 -> ip1
I0522 08:07:00.775842 10501 net.cpp:150] Setting up ip1
I0522 08:07:00.775871 10501 net.cpp:157] Top shape: 30 196 (5880)
I0522 08:07:00.775887 10501 net.cpp:165] Memory required for data: 47278440
I0522 08:07:00.775913 10501 layer_factory.hpp:77] Creating layer relu5
I0522 08:07:00.775928 10501 net.cpp:106] Creating Layer relu5
I0522 08:07:00.775938 10501 net.cpp:454] relu5 <- ip1
I0522 08:07:00.775951 10501 net.cpp:397] relu5 -> ip1 (in-place)
I0522 08:07:00.776293 10501 net.cpp:150] Setting up relu5
I0522 08:07:00.776306 10501 net.cpp:157] Top shape: 30 196 (5880)
I0522 08:07:00.776317 10501 net.cpp:165] Memory required for data: 47301960
I0522 08:07:00.776327 10501 layer_factory.hpp:77] Creating layer drop1
I0522 08:07:00.776348 10501 net.cpp:106] Creating Layer drop1
I0522 08:07:00.776360 10501 net.cpp:454] drop1 <- ip1
I0522 08:07:00.776371 10501 net.cpp:397] drop1 -> ip1 (in-place)
I0522 08:07:00.776430 10501 net.cpp:150] Setting up drop1
I0522 08:07:00.776444 10501 net.cpp:157] Top shape: 30 196 (5880)
I0522 08:07:00.776453 10501 net.cpp:165] Memory required for data: 47325480
I0522 08:07:00.776464 10501 layer_factory.hpp:77] Creating layer ip2
I0522 08:07:00.776481 10501 net.cpp:106] Creating Layer ip2
I0522 08:07:00.776491 10501 net.cpp:454] ip2 <- ip1
I0522 08:07:00.776504 10501 net.cpp:411] ip2 -> ip2
I0522 08:07:00.776995 10501 net.cpp:150] Setting up ip2
I0522 08:07:00.777009 10501 net.cpp:157] Top shape: 30 98 (2940)
I0522 08:07:00.777019 10501 net.cpp:165] Memory required for data: 47337240
I0522 08:07:00.777034 10501 layer_factory.hpp:77] Creating layer relu6
I0522 08:07:00.777046 10501 net.cpp:106] Creating Layer relu6
I0522 08:07:00.777056 10501 net.cpp:454] relu6 <- ip2
I0522 08:07:00.777068 10501 net.cpp:397] relu6 -> ip2 (in-place)
I0522 08:07:00.777590 10501 net.cpp:150] Setting up relu6
I0522 08:07:00.777607 10501 net.cpp:157] Top shape: 30 98 (2940)
I0522 08:07:00.777618 10501 net.cpp:165] Memory required for data: 47349000
I0522 08:07:00.777631 10501 layer_factory.hpp:77] Creating layer drop2
I0522 08:07:00.777643 10501 net.cpp:106] Creating Layer drop2
I0522 08:07:00.777652 10501 net.cpp:454] drop2 <- ip2
I0522 08:07:00.777665 10501 net.cpp:397] drop2 -> ip2 (in-place)
I0522 08:07:00.777707 10501 net.cpp:150] Setting up drop2
I0522 08:07:00.777720 10501 net.cpp:157] Top shape: 30 98 (2940)
I0522 08:07:00.777731 10501 net.cpp:165] Memory required for data: 47360760
I0522 08:07:00.777741 10501 layer_factory.hpp:77] Creating layer ip3
I0522 08:07:00.777755 10501 net.cpp:106] Creating Layer ip3
I0522 08:07:00.777765 10501 net.cpp:454] ip3 <- ip2
I0522 08:07:00.777777 10501 net.cpp:411] ip3 -> ip3
I0522 08:07:00.777987 10501 net.cpp:150] Setting up ip3
I0522 08:07:00.778000 10501 net.cpp:157] Top shape: 30 11 (330)
I0522 08:07:00.778009 10501 net.cpp:165] Memory required for data: 47362080
I0522 08:07:00.778025 10501 layer_factory.hpp:77] Creating layer drop3
I0522 08:07:00.778038 10501 net.cpp:106] Creating Layer drop3
I0522 08:07:00.778048 10501 net.cpp:454] drop3 <- ip3
I0522 08:07:00.778059 10501 net.cpp:397] drop3 -> ip3 (in-place)
I0522 08:07:00.778100 10501 net.cpp:150] Setting up drop3
I0522 08:07:00.778111 10501 net.cpp:157] Top shape: 30 11 (330)
I0522 08:07:00.778121 10501 net.cpp:165] Memory required for data: 47363400
I0522 08:07:00.778131 10501 layer_factory.hpp:77] Creating layer loss
I0522 08:07:00.778149 10501 net.cpp:106] Creating Layer loss
I0522 08:07:00.778159 10501 net.cpp:454] loss <- ip3
I0522 08:07:00.778170 10501 net.cpp:454] loss <- label
I0522 08:07:00.778182 10501 net.cpp:411] loss -> loss
I0522 08:07:00.778199 10501 layer_factory.hpp:77] Creating layer loss
I0522 08:07:00.778842 10501 net.cpp:150] Setting up loss
I0522 08:07:00.778863 10501 net.cpp:157] Top shape: (1)
I0522 08:07:00.778877 10501 net.cpp:160]     with loss weight 1
I0522 08:07:00.778921 10501 net.cpp:165] Memory required for data: 47363404
I0522 08:07:00.778931 10501 net.cpp:226] loss needs backward computation.
I0522 08:07:00.778944 10501 net.cpp:226] drop3 needs backward computation.
I0522 08:07:00.778952 10501 net.cpp:226] ip3 needs backward computation.
I0522 08:07:00.778964 10501 net.cpp:226] drop2 needs backward computation.
I0522 08:07:00.778973 10501 net.cpp:226] relu6 needs backward computation.
I0522 08:07:00.778983 10501 net.cpp:226] ip2 needs backward computation.
I0522 08:07:00.778995 10501 net.cpp:226] drop1 needs backward computation.
I0522 08:07:00.779005 10501 net.cpp:226] relu5 needs backward computation.
I0522 08:07:00.779014 10501 net.cpp:226] ip1 needs backward computation.
I0522 08:07:00.779024 10501 net.cpp:226] pool4 needs backward computation.
I0522 08:07:00.779034 10501 net.cpp:226] relu4 needs backward computation.
I0522 08:07:00.779044 10501 net.cpp:226] conv4 needs backward computation.
I0522 08:07:00.779054 10501 net.cpp:226] pool3 needs backward computation.
I0522 08:07:00.779065 10501 net.cpp:226] relu3 needs backward computation.
I0522 08:07:00.779075 10501 net.cpp:226] conv3 needs backward computation.
I0522 08:07:00.779094 10501 net.cpp:226] pool2 needs backward computation.
I0522 08:07:00.779105 10501 net.cpp:226] relu2 needs backward computation.
I0522 08:07:00.779115 10501 net.cpp:226] conv2 needs backward computation.
I0522 08:07:00.779124 10501 net.cpp:226] pool1 needs backward computation.
I0522 08:07:00.779136 10501 net.cpp:226] relu1 needs backward computation.
I0522 08:07:00.779146 10501 net.cpp:226] conv1 needs backward computation.
I0522 08:07:00.779156 10501 net.cpp:228] data_hdf5 does not need backward computation.
I0522 08:07:00.779165 10501 net.cpp:270] This network produces output loss
I0522 08:07:00.779189 10501 net.cpp:283] Network initialization done.
I0522 08:07:00.780953 10501 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821.prototxt
I0522 08:07:00.781024 10501 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 08:07:00.781381 10501 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 08:07:00.781571 10501 layer_factory.hpp:77] Creating layer data_hdf5
I0522 08:07:00.781587 10501 net.cpp:106] Creating Layer data_hdf5
I0522 08:07:00.781599 10501 net.cpp:411] data_hdf5 -> data
I0522 08:07:00.781615 10501 net.cpp:411] data_hdf5 -> label
I0522 08:07:00.781631 10501 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 08:07:00.783114 10501 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 08:07:22.143524 10501 net.cpp:150] Setting up data_hdf5
I0522 08:07:22.143700 10501 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 08:07:22.143714 10501 net.cpp:157] Top shape: 30 (30)
I0522 08:07:22.143726 10501 net.cpp:165] Memory required for data: 762120
I0522 08:07:22.143740 10501 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 08:07:22.143769 10501 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 08:07:22.143779 10501 net.cpp:454] label_data_hdf5_1_split <- label
I0522 08:07:22.143795 10501 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 08:07:22.143816 10501 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 08:07:22.143890 10501 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 08:07:22.143903 10501 net.cpp:157] Top shape: 30 (30)
I0522 08:07:22.143915 10501 net.cpp:157] Top shape: 30 (30)
I0522 08:07:22.143925 10501 net.cpp:165] Memory required for data: 762360
I0522 08:07:22.143935 10501 layer_factory.hpp:77] Creating layer conv1
I0522 08:07:22.143959 10501 net.cpp:106] Creating Layer conv1
I0522 08:07:22.143968 10501 net.cpp:454] conv1 <- data
I0522 08:07:22.143983 10501 net.cpp:411] conv1 -> conv1
I0522 08:07:22.145922 10501 net.cpp:150] Setting up conv1
I0522 08:07:22.145941 10501 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 08:07:22.145951 10501 net.cpp:165] Memory required for data: 9056760
I0522 08:07:22.145972 10501 layer_factory.hpp:77] Creating layer relu1
I0522 08:07:22.145987 10501 net.cpp:106] Creating Layer relu1
I0522 08:07:22.145997 10501 net.cpp:454] relu1 <- conv1
I0522 08:07:22.146009 10501 net.cpp:397] relu1 -> conv1 (in-place)
I0522 08:07:22.146517 10501 net.cpp:150] Setting up relu1
I0522 08:07:22.146533 10501 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 08:07:22.146543 10501 net.cpp:165] Memory required for data: 17351160
I0522 08:07:22.146553 10501 layer_factory.hpp:77] Creating layer pool1
I0522 08:07:22.146569 10501 net.cpp:106] Creating Layer pool1
I0522 08:07:22.146579 10501 net.cpp:454] pool1 <- conv1
I0522 08:07:22.146592 10501 net.cpp:411] pool1 -> pool1
I0522 08:07:22.146667 10501 net.cpp:150] Setting up pool1
I0522 08:07:22.146682 10501 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 08:07:22.146690 10501 net.cpp:165] Memory required for data: 21498360
I0522 08:07:22.146698 10501 layer_factory.hpp:77] Creating layer conv2
I0522 08:07:22.146718 10501 net.cpp:106] Creating Layer conv2
I0522 08:07:22.146728 10501 net.cpp:454] conv2 <- pool1
I0522 08:07:22.146742 10501 net.cpp:411] conv2 -> conv2
I0522 08:07:22.148659 10501 net.cpp:150] Setting up conv2
I0522 08:07:22.148682 10501 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 08:07:22.148695 10501 net.cpp:165] Memory required for data: 27459960
I0522 08:07:22.148712 10501 layer_factory.hpp:77] Creating layer relu2
I0522 08:07:22.148726 10501 net.cpp:106] Creating Layer relu2
I0522 08:07:22.148736 10501 net.cpp:454] relu2 <- conv2
I0522 08:07:22.148748 10501 net.cpp:397] relu2 -> conv2 (in-place)
I0522 08:07:22.149080 10501 net.cpp:150] Setting up relu2
I0522 08:07:22.149093 10501 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 08:07:22.149103 10501 net.cpp:165] Memory required for data: 33421560
I0522 08:07:22.149113 10501 layer_factory.hpp:77] Creating layer pool2
I0522 08:07:22.149127 10501 net.cpp:106] Creating Layer pool2
I0522 08:07:22.149137 10501 net.cpp:454] pool2 <- conv2
I0522 08:07:22.149148 10501 net.cpp:411] pool2 -> pool2
I0522 08:07:22.149220 10501 net.cpp:150] Setting up pool2
I0522 08:07:22.149233 10501 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 08:07:22.149242 10501 net.cpp:165] Memory required for data: 36402360
I0522 08:07:22.149252 10501 layer_factory.hpp:77] Creating layer conv3
I0522 08:07:22.149271 10501 net.cpp:106] Creating Layer conv3
I0522 08:07:22.149281 10501 net.cpp:454] conv3 <- pool2
I0522 08:07:22.149296 10501 net.cpp:411] conv3 -> conv3
I0522 08:07:22.151265 10501 net.cpp:150] Setting up conv3
I0522 08:07:22.151288 10501 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 08:07:22.151300 10501 net.cpp:165] Memory required for data: 39654840
I0522 08:07:22.151334 10501 layer_factory.hpp:77] Creating layer relu3
I0522 08:07:22.151347 10501 net.cpp:106] Creating Layer relu3
I0522 08:07:22.151357 10501 net.cpp:454] relu3 <- conv3
I0522 08:07:22.151371 10501 net.cpp:397] relu3 -> conv3 (in-place)
I0522 08:07:22.151855 10501 net.cpp:150] Setting up relu3
I0522 08:07:22.151871 10501 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 08:07:22.151882 10501 net.cpp:165] Memory required for data: 42907320
I0522 08:07:22.151892 10501 layer_factory.hpp:77] Creating layer pool3
I0522 08:07:22.151906 10501 net.cpp:106] Creating Layer pool3
I0522 08:07:22.151916 10501 net.cpp:454] pool3 <- conv3
I0522 08:07:22.151929 10501 net.cpp:411] pool3 -> pool3
I0522 08:07:22.152001 10501 net.cpp:150] Setting up pool3
I0522 08:07:22.152015 10501 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 08:07:22.152025 10501 net.cpp:165] Memory required for data: 44533560
I0522 08:07:22.152034 10501 layer_factory.hpp:77] Creating layer conv4
I0522 08:07:22.152051 10501 net.cpp:106] Creating Layer conv4
I0522 08:07:22.152061 10501 net.cpp:454] conv4 <- pool3
I0522 08:07:22.152076 10501 net.cpp:411] conv4 -> conv4
I0522 08:07:22.154131 10501 net.cpp:150] Setting up conv4
I0522 08:07:22.154155 10501 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 08:07:22.154166 10501 net.cpp:165] Memory required for data: 45622200
I0522 08:07:22.154181 10501 layer_factory.hpp:77] Creating layer relu4
I0522 08:07:22.154196 10501 net.cpp:106] Creating Layer relu4
I0522 08:07:22.154206 10501 net.cpp:454] relu4 <- conv4
I0522 08:07:22.154218 10501 net.cpp:397] relu4 -> conv4 (in-place)
I0522 08:07:22.154690 10501 net.cpp:150] Setting up relu4
I0522 08:07:22.154706 10501 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 08:07:22.154716 10501 net.cpp:165] Memory required for data: 46710840
I0522 08:07:22.154726 10501 layer_factory.hpp:77] Creating layer pool4
I0522 08:07:22.154739 10501 net.cpp:106] Creating Layer pool4
I0522 08:07:22.154749 10501 net.cpp:454] pool4 <- conv4
I0522 08:07:22.154762 10501 net.cpp:411] pool4 -> pool4
I0522 08:07:22.154834 10501 net.cpp:150] Setting up pool4
I0522 08:07:22.154847 10501 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 08:07:22.154856 10501 net.cpp:165] Memory required for data: 47255160
I0522 08:07:22.154866 10501 layer_factory.hpp:77] Creating layer ip1
I0522 08:07:22.154881 10501 net.cpp:106] Creating Layer ip1
I0522 08:07:22.154892 10501 net.cpp:454] ip1 <- pool4
I0522 08:07:22.154906 10501 net.cpp:411] ip1 -> ip1
I0522 08:07:22.170388 10501 net.cpp:150] Setting up ip1
I0522 08:07:22.170418 10501 net.cpp:157] Top shape: 30 196 (5880)
I0522 08:07:22.170430 10501 net.cpp:165] Memory required for data: 47278680
I0522 08:07:22.170452 10501 layer_factory.hpp:77] Creating layer relu5
I0522 08:07:22.170467 10501 net.cpp:106] Creating Layer relu5
I0522 08:07:22.170477 10501 net.cpp:454] relu5 <- ip1
I0522 08:07:22.170491 10501 net.cpp:397] relu5 -> ip1 (in-place)
I0522 08:07:22.170837 10501 net.cpp:150] Setting up relu5
I0522 08:07:22.170851 10501 net.cpp:157] Top shape: 30 196 (5880)
I0522 08:07:22.170861 10501 net.cpp:165] Memory required for data: 47302200
I0522 08:07:22.170871 10501 layer_factory.hpp:77] Creating layer drop1
I0522 08:07:22.170891 10501 net.cpp:106] Creating Layer drop1
I0522 08:07:22.170900 10501 net.cpp:454] drop1 <- ip1
I0522 08:07:22.170913 10501 net.cpp:397] drop1 -> ip1 (in-place)
I0522 08:07:22.170959 10501 net.cpp:150] Setting up drop1
I0522 08:07:22.170972 10501 net.cpp:157] Top shape: 30 196 (5880)
I0522 08:07:22.170984 10501 net.cpp:165] Memory required for data: 47325720
I0522 08:07:22.170994 10501 layer_factory.hpp:77] Creating layer ip2
I0522 08:07:22.171007 10501 net.cpp:106] Creating Layer ip2
I0522 08:07:22.171017 10501 net.cpp:454] ip2 <- ip1
I0522 08:07:22.171030 10501 net.cpp:411] ip2 -> ip2
I0522 08:07:22.171506 10501 net.cpp:150] Setting up ip2
I0522 08:07:22.171519 10501 net.cpp:157] Top shape: 30 98 (2940)
I0522 08:07:22.171530 10501 net.cpp:165] Memory required for data: 47337480
I0522 08:07:22.171545 10501 layer_factory.hpp:77] Creating layer relu6
I0522 08:07:22.171571 10501 net.cpp:106] Creating Layer relu6
I0522 08:07:22.171581 10501 net.cpp:454] relu6 <- ip2
I0522 08:07:22.171593 10501 net.cpp:397] relu6 -> ip2 (in-place)
I0522 08:07:22.172132 10501 net.cpp:150] Setting up relu6
I0522 08:07:22.172148 10501 net.cpp:157] Top shape: 30 98 (2940)
I0522 08:07:22.172158 10501 net.cpp:165] Memory required for data: 47349240
I0522 08:07:22.172169 10501 layer_factory.hpp:77] Creating layer drop2
I0522 08:07:22.172183 10501 net.cpp:106] Creating Layer drop2
I0522 08:07:22.172194 10501 net.cpp:454] drop2 <- ip2
I0522 08:07:22.172206 10501 net.cpp:397] drop2 -> ip2 (in-place)
I0522 08:07:22.172250 10501 net.cpp:150] Setting up drop2
I0522 08:07:22.172263 10501 net.cpp:157] Top shape: 30 98 (2940)
I0522 08:07:22.172273 10501 net.cpp:165] Memory required for data: 47361000
I0522 08:07:22.172283 10501 layer_factory.hpp:77] Creating layer ip3
I0522 08:07:22.172298 10501 net.cpp:106] Creating Layer ip3
I0522 08:07:22.172308 10501 net.cpp:454] ip3 <- ip2
I0522 08:07:22.172322 10501 net.cpp:411] ip3 -> ip3
I0522 08:07:22.172547 10501 net.cpp:150] Setting up ip3
I0522 08:07:22.172560 10501 net.cpp:157] Top shape: 30 11 (330)
I0522 08:07:22.172570 10501 net.cpp:165] Memory required for data: 47362320
I0522 08:07:22.172585 10501 layer_factory.hpp:77] Creating layer drop3
I0522 08:07:22.172598 10501 net.cpp:106] Creating Layer drop3
I0522 08:07:22.172608 10501 net.cpp:454] drop3 <- ip3
I0522 08:07:22.172621 10501 net.cpp:397] drop3 -> ip3 (in-place)
I0522 08:07:22.172662 10501 net.cpp:150] Setting up drop3
I0522 08:07:22.172674 10501 net.cpp:157] Top shape: 30 11 (330)
I0522 08:07:22.172684 10501 net.cpp:165] Memory required for data: 47363640
I0522 08:07:22.172693 10501 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 08:07:22.172706 10501 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 08:07:22.172716 10501 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 08:07:22.172729 10501 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 08:07:22.172744 10501 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 08:07:22.172819 10501 net.cpp:150] Setting up ip3_drop3_0_split
I0522 08:07:22.172833 10501 net.cpp:157] Top shape: 30 11 (330)
I0522 08:07:22.172845 10501 net.cpp:157] Top shape: 30 11 (330)
I0522 08:07:22.172855 10501 net.cpp:165] Memory required for data: 47366280
I0522 08:07:22.172863 10501 layer_factory.hpp:77] Creating layer accuracy
I0522 08:07:22.172885 10501 net.cpp:106] Creating Layer accuracy
I0522 08:07:22.172895 10501 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 08:07:22.172906 10501 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 08:07:22.172920 10501 net.cpp:411] accuracy -> accuracy
I0522 08:07:22.172943 10501 net.cpp:150] Setting up accuracy
I0522 08:07:22.172956 10501 net.cpp:157] Top shape: (1)
I0522 08:07:22.172966 10501 net.cpp:165] Memory required for data: 47366284
I0522 08:07:22.172976 10501 layer_factory.hpp:77] Creating layer loss
I0522 08:07:22.172991 10501 net.cpp:106] Creating Layer loss
I0522 08:07:22.173001 10501 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 08:07:22.173012 10501 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 08:07:22.173024 10501 net.cpp:411] loss -> loss
I0522 08:07:22.173043 10501 layer_factory.hpp:77] Creating layer loss
I0522 08:07:22.173537 10501 net.cpp:150] Setting up loss
I0522 08:07:22.173552 10501 net.cpp:157] Top shape: (1)
I0522 08:07:22.173562 10501 net.cpp:160]     with loss weight 1
I0522 08:07:22.173583 10501 net.cpp:165] Memory required for data: 47366288
I0522 08:07:22.173593 10501 net.cpp:226] loss needs backward computation.
I0522 08:07:22.173604 10501 net.cpp:228] accuracy does not need backward computation.
I0522 08:07:22.173615 10501 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 08:07:22.173625 10501 net.cpp:226] drop3 needs backward computation.
I0522 08:07:22.173635 10501 net.cpp:226] ip3 needs backward computation.
I0522 08:07:22.173645 10501 net.cpp:226] drop2 needs backward computation.
I0522 08:07:22.173655 10501 net.cpp:226] relu6 needs backward computation.
I0522 08:07:22.173672 10501 net.cpp:226] ip2 needs backward computation.
I0522 08:07:22.173683 10501 net.cpp:226] drop1 needs backward computation.
I0522 08:07:22.173692 10501 net.cpp:226] relu5 needs backward computation.
I0522 08:07:22.173702 10501 net.cpp:226] ip1 needs backward computation.
I0522 08:07:22.173712 10501 net.cpp:226] pool4 needs backward computation.
I0522 08:07:22.173722 10501 net.cpp:226] relu4 needs backward computation.
I0522 08:07:22.173732 10501 net.cpp:226] conv4 needs backward computation.
I0522 08:07:22.173740 10501 net.cpp:226] pool3 needs backward computation.
I0522 08:07:22.173751 10501 net.cpp:226] relu3 needs backward computation.
I0522 08:07:22.173761 10501 net.cpp:226] conv3 needs backward computation.
I0522 08:07:22.173773 10501 net.cpp:226] pool2 needs backward computation.
I0522 08:07:22.173784 10501 net.cpp:226] relu2 needs backward computation.
I0522 08:07:22.173794 10501 net.cpp:226] conv2 needs backward computation.
I0522 08:07:22.173804 10501 net.cpp:226] pool1 needs backward computation.
I0522 08:07:22.173815 10501 net.cpp:226] relu1 needs backward computation.
I0522 08:07:22.173825 10501 net.cpp:226] conv1 needs backward computation.
I0522 08:07:22.173835 10501 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 08:07:22.173848 10501 net.cpp:228] data_hdf5 does not need backward computation.
I0522 08:07:22.173858 10501 net.cpp:270] This network produces output accuracy
I0522 08:07:22.173869 10501 net.cpp:270] This network produces output loss
I0522 08:07:22.173897 10501 net.cpp:283] Network initialization done.
I0522 08:07:22.174029 10501 solver.cpp:60] Solver scaffolding done.
I0522 08:07:22.175161 10501 caffe.cpp:212] Starting Optimization
I0522 08:07:22.175180 10501 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 08:07:22.175194 10501 solver.cpp:289] Learning Rate Policy: fixed
I0522 08:07:22.176440 10501 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 08:08:12.710721 10501 solver.cpp:409]     Test net output #0: accuracy = 0.134375
I0522 08:08:12.710886 10501 solver.cpp:409]     Test net output #1: loss = 2.39731 (* 1 = 2.39731 loss)
I0522 08:08:12.731694 10501 solver.cpp:237] Iteration 0, loss = 2.39452
I0522 08:08:12.731731 10501 solver.cpp:253]     Train net output #0: loss = 2.39452 (* 1 = 2.39452 loss)
I0522 08:08:12.731813 10501 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0522 08:08:23.262305 10501 solver.cpp:237] Iteration 500, loss = 2.13282
I0522 08:08:23.262356 10501 solver.cpp:253]     Train net output #0: loss = 2.13282 (* 1 = 2.13282 loss)
I0522 08:08:23.262369 10501 sgd_solver.cpp:106] Iteration 500, lr = 0.0015
I0522 08:08:33.800921 10501 solver.cpp:237] Iteration 1000, loss = 2.17046
I0522 08:08:33.800957 10501 solver.cpp:253]     Train net output #0: loss = 2.17046 (* 1 = 2.17046 loss)
I0522 08:08:33.800971 10501 sgd_solver.cpp:106] Iteration 1000, lr = 0.0015
I0522 08:08:44.338521 10501 solver.cpp:237] Iteration 1500, loss = 2.04673
I0522 08:08:44.338670 10501 solver.cpp:253]     Train net output #0: loss = 2.04673 (* 1 = 2.04673 loss)
I0522 08:08:44.338685 10501 sgd_solver.cpp:106] Iteration 1500, lr = 0.0015
I0522 08:08:54.896173 10501 solver.cpp:237] Iteration 2000, loss = 1.8273
I0522 08:08:54.896217 10501 solver.cpp:253]     Train net output #0: loss = 1.8273 (* 1 = 1.8273 loss)
I0522 08:08:54.896234 10501 sgd_solver.cpp:106] Iteration 2000, lr = 0.0015
I0522 08:09:05.431378 10501 solver.cpp:237] Iteration 2500, loss = 1.63077
I0522 08:09:05.431414 10501 solver.cpp:253]     Train net output #0: loss = 1.63077 (* 1 = 1.63077 loss)
I0522 08:09:05.431430 10501 sgd_solver.cpp:106] Iteration 2500, lr = 0.0015
I0522 08:09:15.967236 10501 solver.cpp:237] Iteration 3000, loss = 1.59084
I0522 08:09:15.967382 10501 solver.cpp:253]     Train net output #0: loss = 1.59084 (* 1 = 1.59084 loss)
I0522 08:09:15.967398 10501 sgd_solver.cpp:106] Iteration 3000, lr = 0.0015
I0522 08:09:48.619659 10501 solver.cpp:237] Iteration 3500, loss = 1.58919
I0522 08:09:48.619825 10501 solver.cpp:253]     Train net output #0: loss = 1.58919 (* 1 = 1.58919 loss)
I0522 08:09:48.619840 10501 sgd_solver.cpp:106] Iteration 3500, lr = 0.0015
I0522 08:09:59.175246 10501 solver.cpp:237] Iteration 4000, loss = 1.54594
I0522 08:09:59.175282 10501 solver.cpp:253]     Train net output #0: loss = 1.54594 (* 1 = 1.54594 loss)
I0522 08:09:59.175298 10501 sgd_solver.cpp:106] Iteration 4000, lr = 0.0015
I0522 08:10:09.731498 10501 solver.cpp:237] Iteration 4500, loss = 1.83884
I0522 08:10:09.731546 10501 solver.cpp:253]     Train net output #0: loss = 1.83884 (* 1 = 1.83884 loss)
I0522 08:10:09.731562 10501 sgd_solver.cpp:106] Iteration 4500, lr = 0.0015
I0522 08:10:20.251443 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_5000.caffemodel
I0522 08:10:20.307355 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_5000.solverstate
I0522 08:10:20.339200 10501 solver.cpp:237] Iteration 5000, loss = 1.64413
I0522 08:10:20.339249 10501 solver.cpp:253]     Train net output #0: loss = 1.64413 (* 1 = 1.64413 loss)
I0522 08:10:20.339263 10501 sgd_solver.cpp:106] Iteration 5000, lr = 0.0015
I0522 08:10:30.881124 10501 solver.cpp:237] Iteration 5500, loss = 1.62141
I0522 08:10:30.881172 10501 solver.cpp:253]     Train net output #0: loss = 1.62141 (* 1 = 1.62141 loss)
I0522 08:10:30.881188 10501 sgd_solver.cpp:106] Iteration 5500, lr = 0.0015
I0522 08:10:41.432554 10501 solver.cpp:237] Iteration 6000, loss = 1.27533
I0522 08:10:41.432590 10501 solver.cpp:253]     Train net output #0: loss = 1.27533 (* 1 = 1.27533 loss)
I0522 08:10:41.432605 10501 sgd_solver.cpp:106] Iteration 6000, lr = 0.0015
I0522 08:10:51.972510 10501 solver.cpp:237] Iteration 6500, loss = 1.69929
I0522 08:10:51.972661 10501 solver.cpp:253]     Train net output #0: loss = 1.69929 (* 1 = 1.69929 loss)
I0522 08:10:51.972674 10501 sgd_solver.cpp:106] Iteration 6500, lr = 0.0015
I0522 08:11:24.649598 10501 solver.cpp:237] Iteration 7000, loss = 1.10958
I0522 08:11:24.649757 10501 solver.cpp:253]     Train net output #0: loss = 1.10958 (* 1 = 1.10958 loss)
I0522 08:11:24.649771 10501 sgd_solver.cpp:106] Iteration 7000, lr = 0.0015
I0522 08:11:35.192786 10501 solver.cpp:237] Iteration 7500, loss = 1.22781
I0522 08:11:35.192822 10501 solver.cpp:253]     Train net output #0: loss = 1.22781 (* 1 = 1.22781 loss)
I0522 08:11:35.192839 10501 sgd_solver.cpp:106] Iteration 7500, lr = 0.0015
I0522 08:11:45.735358 10501 solver.cpp:237] Iteration 8000, loss = 1.6547
I0522 08:11:45.735411 10501 solver.cpp:253]     Train net output #0: loss = 1.6547 (* 1 = 1.6547 loss)
I0522 08:11:45.735425 10501 sgd_solver.cpp:106] Iteration 8000, lr = 0.0015
I0522 08:11:56.296703 10501 solver.cpp:237] Iteration 8500, loss = 1.47991
I0522 08:11:56.296854 10501 solver.cpp:253]     Train net output #0: loss = 1.47991 (* 1 = 1.47991 loss)
I0522 08:11:56.296869 10501 sgd_solver.cpp:106] Iteration 8500, lr = 0.0015
I0522 08:12:06.848925 10501 solver.cpp:237] Iteration 9000, loss = 1.37827
I0522 08:12:06.848974 10501 solver.cpp:253]     Train net output #0: loss = 1.37827 (* 1 = 1.37827 loss)
I0522 08:12:06.848991 10501 sgd_solver.cpp:106] Iteration 9000, lr = 0.0015
I0522 08:12:17.402043 10501 solver.cpp:237] Iteration 9500, loss = 1.23862
I0522 08:12:17.402081 10501 solver.cpp:253]     Train net output #0: loss = 1.23862 (* 1 = 1.23862 loss)
I0522 08:12:17.402096 10501 sgd_solver.cpp:106] Iteration 9500, lr = 0.0015
I0522 08:12:27.923894 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_10000.caffemodel
I0522 08:12:27.976708 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_10000.solverstate
I0522 08:12:28.002388 10501 solver.cpp:341] Iteration 10000, Testing net (#0)
I0522 08:13:17.591655 10501 solver.cpp:409]     Test net output #0: accuracy = 0.794419
I0522 08:13:17.591820 10501 solver.cpp:409]     Test net output #1: loss = 0.730388 (* 1 = 0.730388 loss)
I0522 08:13:39.718910 10501 solver.cpp:237] Iteration 10000, loss = 1.67563
I0522 08:13:39.718969 10501 solver.cpp:253]     Train net output #0: loss = 1.67563 (* 1 = 1.67563 loss)
I0522 08:13:39.718984 10501 sgd_solver.cpp:106] Iteration 10000, lr = 0.0015
I0522 08:13:50.237079 10501 solver.cpp:237] Iteration 10500, loss = 1.081
I0522 08:13:50.237246 10501 solver.cpp:253]     Train net output #0: loss = 1.081 (* 1 = 1.081 loss)
I0522 08:13:50.237259 10501 sgd_solver.cpp:106] Iteration 10500, lr = 0.0015
I0522 08:14:00.751392 10501 solver.cpp:237] Iteration 11000, loss = 1.53395
I0522 08:14:00.751428 10501 solver.cpp:253]     Train net output #0: loss = 1.53395 (* 1 = 1.53395 loss)
I0522 08:14:00.751444 10501 sgd_solver.cpp:106] Iteration 11000, lr = 0.0015
I0522 08:14:11.265650 10501 solver.cpp:237] Iteration 11500, loss = 1.37889
I0522 08:14:11.265686 10501 solver.cpp:253]     Train net output #0: loss = 1.37889 (* 1 = 1.37889 loss)
I0522 08:14:11.265703 10501 sgd_solver.cpp:106] Iteration 11500, lr = 0.0015
I0522 08:14:21.777758 10501 solver.cpp:237] Iteration 12000, loss = 1.31407
I0522 08:14:21.777909 10501 solver.cpp:253]     Train net output #0: loss = 1.31407 (* 1 = 1.31407 loss)
I0522 08:14:21.777925 10501 sgd_solver.cpp:106] Iteration 12000, lr = 0.0015
I0522 08:14:32.296399 10501 solver.cpp:237] Iteration 12500, loss = 1.52726
I0522 08:14:32.296437 10501 solver.cpp:253]     Train net output #0: loss = 1.52726 (* 1 = 1.52726 loss)
I0522 08:14:32.296452 10501 sgd_solver.cpp:106] Iteration 12500, lr = 0.0015
I0522 08:14:42.798269 10501 solver.cpp:237] Iteration 13000, loss = 1.29091
I0522 08:14:42.798317 10501 solver.cpp:253]     Train net output #0: loss = 1.29091 (* 1 = 1.29091 loss)
I0522 08:14:42.798333 10501 sgd_solver.cpp:106] Iteration 13000, lr = 0.0015
I0522 08:15:15.422871 10501 solver.cpp:237] Iteration 13500, loss = 1.11507
I0522 08:15:15.423040 10501 solver.cpp:253]     Train net output #0: loss = 1.11507 (* 1 = 1.11507 loss)
I0522 08:15:15.423054 10501 sgd_solver.cpp:106] Iteration 13500, lr = 0.0015
I0522 08:15:25.926584 10501 solver.cpp:237] Iteration 14000, loss = 0.966215
I0522 08:15:25.926621 10501 solver.cpp:253]     Train net output #0: loss = 0.966215 (* 1 = 0.966215 loss)
I0522 08:15:25.926637 10501 sgd_solver.cpp:106] Iteration 14000, lr = 0.0015
I0522 08:15:36.442415 10501 solver.cpp:237] Iteration 14500, loss = 1.38307
I0522 08:15:36.442464 10501 solver.cpp:253]     Train net output #0: loss = 1.38307 (* 1 = 1.38307 loss)
I0522 08:15:36.442479 10501 sgd_solver.cpp:106] Iteration 14500, lr = 0.0015
I0522 08:15:46.939404 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_15000.caffemodel
I0522 08:15:46.994506 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_15000.solverstate
I0522 08:15:47.029261 10501 solver.cpp:237] Iteration 15000, loss = 1.63284
I0522 08:15:47.029315 10501 solver.cpp:253]     Train net output #0: loss = 1.63284 (* 1 = 1.63284 loss)
I0522 08:15:47.029330 10501 sgd_solver.cpp:106] Iteration 15000, lr = 0.0015
I0522 08:15:57.539381 10501 solver.cpp:237] Iteration 15500, loss = 1.40563
I0522 08:15:57.539432 10501 solver.cpp:253]     Train net output #0: loss = 1.40563 (* 1 = 1.40563 loss)
I0522 08:15:57.539446 10501 sgd_solver.cpp:106] Iteration 15500, lr = 0.0015
I0522 08:16:08.051200 10501 solver.cpp:237] Iteration 16000, loss = 1.31101
I0522 08:16:08.051236 10501 solver.cpp:253]     Train net output #0: loss = 1.31101 (* 1 = 1.31101 loss)
I0522 08:16:08.051254 10501 sgd_solver.cpp:106] Iteration 16000, lr = 0.0015
I0522 08:16:18.567214 10501 solver.cpp:237] Iteration 16500, loss = 1.30963
I0522 08:16:18.567378 10501 solver.cpp:253]     Train net output #0: loss = 1.30963 (* 1 = 1.30963 loss)
I0522 08:16:18.567394 10501 sgd_solver.cpp:106] Iteration 16500, lr = 0.0015
I0522 08:16:51.207495 10501 solver.cpp:237] Iteration 17000, loss = 1.31477
I0522 08:16:51.207669 10501 solver.cpp:253]     Train net output #0: loss = 1.31477 (* 1 = 1.31477 loss)
I0522 08:16:51.207685 10501 sgd_solver.cpp:106] Iteration 17000, lr = 0.0015
I0522 08:17:01.725561 10501 solver.cpp:237] Iteration 17500, loss = 1.59441
I0522 08:17:01.725596 10501 solver.cpp:253]     Train net output #0: loss = 1.59441 (* 1 = 1.59441 loss)
I0522 08:17:01.725610 10501 sgd_solver.cpp:106] Iteration 17500, lr = 0.0015
I0522 08:17:12.236330 10501 solver.cpp:237] Iteration 18000, loss = 1.36285
I0522 08:17:12.236379 10501 solver.cpp:253]     Train net output #0: loss = 1.36285 (* 1 = 1.36285 loss)
I0522 08:17:12.236394 10501 sgd_solver.cpp:106] Iteration 18000, lr = 0.0015
I0522 08:17:22.756683 10501 solver.cpp:237] Iteration 18500, loss = 1.62634
I0522 08:17:22.756824 10501 solver.cpp:253]     Train net output #0: loss = 1.62634 (* 1 = 1.62634 loss)
I0522 08:17:22.756839 10501 sgd_solver.cpp:106] Iteration 18500, lr = 0.0015
I0522 08:17:33.265177 10501 solver.cpp:237] Iteration 19000, loss = 1.29131
I0522 08:17:33.265224 10501 solver.cpp:253]     Train net output #0: loss = 1.29131 (* 1 = 1.29131 loss)
I0522 08:17:33.265239 10501 sgd_solver.cpp:106] Iteration 19000, lr = 0.0015
I0522 08:17:43.781085 10501 solver.cpp:237] Iteration 19500, loss = 1.18171
I0522 08:17:43.781121 10501 solver.cpp:253]     Train net output #0: loss = 1.18171 (* 1 = 1.18171 loss)
I0522 08:17:43.781139 10501 sgd_solver.cpp:106] Iteration 19500, lr = 0.0015
I0522 08:17:54.277971 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_20000.caffemodel
I0522 08:17:54.332720 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_20000.solverstate
I0522 08:17:54.361469 10501 solver.cpp:341] Iteration 20000, Testing net (#0)
I0522 08:19:04.749548 10501 solver.cpp:409]     Test net output #0: accuracy = 0.822904
I0522 08:19:04.749723 10501 solver.cpp:409]     Test net output #1: loss = 0.633855 (* 1 = 0.633855 loss)
I0522 08:19:26.891342 10501 solver.cpp:237] Iteration 20000, loss = 1.36652
I0522 08:19:26.891399 10501 solver.cpp:253]     Train net output #0: loss = 1.36652 (* 1 = 1.36652 loss)
I0522 08:19:26.891414 10501 sgd_solver.cpp:106] Iteration 20000, lr = 0.0015
I0522 08:19:37.465814 10501 solver.cpp:237] Iteration 20500, loss = 1.43792
I0522 08:19:37.465983 10501 solver.cpp:253]     Train net output #0: loss = 1.43792 (* 1 = 1.43792 loss)
I0522 08:19:37.465998 10501 sgd_solver.cpp:106] Iteration 20500, lr = 0.0015
I0522 08:19:48.043026 10501 solver.cpp:237] Iteration 21000, loss = 1.17369
I0522 08:19:48.043062 10501 solver.cpp:253]     Train net output #0: loss = 1.17369 (* 1 = 1.17369 loss)
I0522 08:19:48.043079 10501 sgd_solver.cpp:106] Iteration 21000, lr = 0.0015
I0522 08:19:58.621516 10501 solver.cpp:237] Iteration 21500, loss = 1.26652
I0522 08:19:58.621553 10501 solver.cpp:253]     Train net output #0: loss = 1.26652 (* 1 = 1.26652 loss)
I0522 08:19:58.621567 10501 sgd_solver.cpp:106] Iteration 21500, lr = 0.0015
I0522 08:20:09.190279 10501 solver.cpp:237] Iteration 22000, loss = 1.4653
I0522 08:20:09.190430 10501 solver.cpp:253]     Train net output #0: loss = 1.4653 (* 1 = 1.4653 loss)
I0522 08:20:09.190446 10501 sgd_solver.cpp:106] Iteration 22000, lr = 0.0015
I0522 08:20:19.759191 10501 solver.cpp:237] Iteration 22500, loss = 1.32969
I0522 08:20:19.759227 10501 solver.cpp:253]     Train net output #0: loss = 1.32969 (* 1 = 1.32969 loss)
I0522 08:20:19.759243 10501 sgd_solver.cpp:106] Iteration 22500, lr = 0.0015
I0522 08:20:30.328430 10501 solver.cpp:237] Iteration 23000, loss = 1.00097
I0522 08:20:30.328482 10501 solver.cpp:253]     Train net output #0: loss = 1.00097 (* 1 = 1.00097 loss)
I0522 08:20:30.328496 10501 sgd_solver.cpp:106] Iteration 23000, lr = 0.0015
I0522 08:21:03.085345 10501 solver.cpp:237] Iteration 23500, loss = 1.1359
I0522 08:21:03.085515 10501 solver.cpp:253]     Train net output #0: loss = 1.1359 (* 1 = 1.1359 loss)
I0522 08:21:03.085541 10501 sgd_solver.cpp:106] Iteration 23500, lr = 0.0015
I0522 08:21:13.653764 10501 solver.cpp:237] Iteration 24000, loss = 1.23219
I0522 08:21:13.653800 10501 solver.cpp:253]     Train net output #0: loss = 1.23219 (* 1 = 1.23219 loss)
I0522 08:21:13.653815 10501 sgd_solver.cpp:106] Iteration 24000, lr = 0.0015
I0522 08:21:24.221025 10501 solver.cpp:237] Iteration 24500, loss = 1.30336
I0522 08:21:24.221074 10501 solver.cpp:253]     Train net output #0: loss = 1.30336 (* 1 = 1.30336 loss)
I0522 08:21:24.221091 10501 sgd_solver.cpp:106] Iteration 24500, lr = 0.0015
I0522 08:21:34.784196 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_25000.caffemodel
I0522 08:21:34.839208 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_25000.solverstate
I0522 08:21:34.874505 10501 solver.cpp:237] Iteration 25000, loss = 0.951397
I0522 08:21:34.874560 10501 solver.cpp:253]     Train net output #0: loss = 0.951397 (* 1 = 0.951397 loss)
I0522 08:21:34.874574 10501 sgd_solver.cpp:106] Iteration 25000, lr = 0.0015
I0522 08:21:45.453346 10501 solver.cpp:237] Iteration 25500, loss = 1.6971
I0522 08:21:45.453397 10501 solver.cpp:253]     Train net output #0: loss = 1.6971 (* 1 = 1.6971 loss)
I0522 08:21:45.453413 10501 sgd_solver.cpp:106] Iteration 25500, lr = 0.0015
I0522 08:21:56.020550 10501 solver.cpp:237] Iteration 26000, loss = 1.53982
I0522 08:21:56.020586 10501 solver.cpp:253]     Train net output #0: loss = 1.53982 (* 1 = 1.53982 loss)
I0522 08:21:56.020602 10501 sgd_solver.cpp:106] Iteration 26000, lr = 0.0015
I0522 08:22:06.591238 10501 solver.cpp:237] Iteration 26500, loss = 1.39634
I0522 08:22:06.591383 10501 solver.cpp:253]     Train net output #0: loss = 1.39634 (* 1 = 1.39634 loss)
I0522 08:22:06.591398 10501 sgd_solver.cpp:106] Iteration 26500, lr = 0.0015
I0522 08:22:39.292968 10501 solver.cpp:237] Iteration 27000, loss = 1.30737
I0522 08:22:39.293150 10501 solver.cpp:253]     Train net output #0: loss = 1.30737 (* 1 = 1.30737 loss)
I0522 08:22:39.293165 10501 sgd_solver.cpp:106] Iteration 27000, lr = 0.0015
I0522 08:22:49.857897 10501 solver.cpp:237] Iteration 27500, loss = 0.654755
I0522 08:22:49.857933 10501 solver.cpp:253]     Train net output #0: loss = 0.654754 (* 1 = 0.654754 loss)
I0522 08:22:49.857949 10501 sgd_solver.cpp:106] Iteration 27500, lr = 0.0015
I0522 08:23:00.431864 10501 solver.cpp:237] Iteration 28000, loss = 1.16702
I0522 08:23:00.431916 10501 solver.cpp:253]     Train net output #0: loss = 1.16702 (* 1 = 1.16702 loss)
I0522 08:23:00.431931 10501 sgd_solver.cpp:106] Iteration 28000, lr = 0.0015
I0522 08:23:11.019099 10501 solver.cpp:237] Iteration 28500, loss = 1.20447
I0522 08:23:11.019243 10501 solver.cpp:253]     Train net output #0: loss = 1.20447 (* 1 = 1.20447 loss)
I0522 08:23:11.019258 10501 sgd_solver.cpp:106] Iteration 28500, lr = 0.0015
I0522 08:23:21.576207 10501 solver.cpp:237] Iteration 29000, loss = 1.21301
I0522 08:23:21.576243 10501 solver.cpp:253]     Train net output #0: loss = 1.21301 (* 1 = 1.21301 loss)
I0522 08:23:21.576259 10501 sgd_solver.cpp:106] Iteration 29000, lr = 0.0015
I0522 08:23:32.157861 10501 solver.cpp:237] Iteration 29500, loss = 1.11461
I0522 08:23:32.157907 10501 solver.cpp:253]     Train net output #0: loss = 1.11461 (* 1 = 1.11461 loss)
I0522 08:23:32.157920 10501 sgd_solver.cpp:106] Iteration 29500, lr = 0.0015
I0522 08:23:42.701369 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_30000.caffemodel
I0522 08:23:42.754312 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_30000.solverstate
I0522 08:23:42.780788 10501 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 08:24:32.083348 10501 solver.cpp:409]     Test net output #0: accuracy = 0.843708
I0522 08:24:32.083525 10501 solver.cpp:409]     Test net output #1: loss = 0.519973 (* 1 = 0.519973 loss)
I0522 08:24:54.211161 10501 solver.cpp:237] Iteration 30000, loss = 0.970075
I0522 08:24:54.211221 10501 solver.cpp:253]     Train net output #0: loss = 0.970075 (* 1 = 0.970075 loss)
I0522 08:24:54.211236 10501 sgd_solver.cpp:106] Iteration 30000, lr = 0.0015
I0522 08:25:04.740391 10501 solver.cpp:237] Iteration 30500, loss = 1.43894
I0522 08:25:04.740556 10501 solver.cpp:253]     Train net output #0: loss = 1.43894 (* 1 = 1.43894 loss)
I0522 08:25:04.740571 10501 sgd_solver.cpp:106] Iteration 30500, lr = 0.0015
I0522 08:25:15.279572 10501 solver.cpp:237] Iteration 31000, loss = 1.39392
I0522 08:25:15.279608 10501 solver.cpp:253]     Train net output #0: loss = 1.39392 (* 1 = 1.39392 loss)
I0522 08:25:15.279625 10501 sgd_solver.cpp:106] Iteration 31000, lr = 0.0015
I0522 08:25:25.810571 10501 solver.cpp:237] Iteration 31500, loss = 1.55645
I0522 08:25:25.810609 10501 solver.cpp:253]     Train net output #0: loss = 1.55645 (* 1 = 1.55645 loss)
I0522 08:25:25.810622 10501 sgd_solver.cpp:106] Iteration 31500, lr = 0.0015
I0522 08:25:36.399713 10501 solver.cpp:237] Iteration 32000, loss = 1.11788
I0522 08:25:36.399868 10501 solver.cpp:253]     Train net output #0: loss = 1.11788 (* 1 = 1.11788 loss)
I0522 08:25:36.399883 10501 sgd_solver.cpp:106] Iteration 32000, lr = 0.0015
I0522 08:25:46.981477 10501 solver.cpp:237] Iteration 32500, loss = 1.20794
I0522 08:25:46.981513 10501 solver.cpp:253]     Train net output #0: loss = 1.20794 (* 1 = 1.20794 loss)
I0522 08:25:46.981525 10501 sgd_solver.cpp:106] Iteration 32500, lr = 0.0015
I0522 08:25:57.578641 10501 solver.cpp:237] Iteration 33000, loss = 1.01292
I0522 08:25:57.578688 10501 solver.cpp:253]     Train net output #0: loss = 1.01292 (* 1 = 1.01292 loss)
I0522 08:25:57.578704 10501 sgd_solver.cpp:106] Iteration 33000, lr = 0.0015
I0522 08:26:30.308184 10501 solver.cpp:237] Iteration 33500, loss = 1.0567
I0522 08:26:30.308365 10501 solver.cpp:253]     Train net output #0: loss = 1.0567 (* 1 = 1.0567 loss)
I0522 08:26:30.308380 10501 sgd_solver.cpp:106] Iteration 33500, lr = 0.0015
I0522 08:26:40.900974 10501 solver.cpp:237] Iteration 34000, loss = 0.986078
I0522 08:26:40.901010 10501 solver.cpp:253]     Train net output #0: loss = 0.986078 (* 1 = 0.986078 loss)
I0522 08:26:40.901026 10501 sgd_solver.cpp:106] Iteration 34000, lr = 0.0015
I0522 08:26:51.482100 10501 solver.cpp:237] Iteration 34500, loss = 1.17558
I0522 08:26:51.482146 10501 solver.cpp:253]     Train net output #0: loss = 1.17558 (* 1 = 1.17558 loss)
I0522 08:26:51.482161 10501 sgd_solver.cpp:106] Iteration 34500, lr = 0.0015
I0522 08:27:02.058084 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_35000.caffemodel
I0522 08:27:02.110826 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_35000.solverstate
I0522 08:27:02.143730 10501 solver.cpp:237] Iteration 35000, loss = 0.991092
I0522 08:27:02.143780 10501 solver.cpp:253]     Train net output #0: loss = 0.991091 (* 1 = 0.991091 loss)
I0522 08:27:02.143795 10501 sgd_solver.cpp:106] Iteration 35000, lr = 0.0015
I0522 08:27:12.735901 10501 solver.cpp:237] Iteration 35500, loss = 1.28462
I0522 08:27:12.735954 10501 solver.cpp:253]     Train net output #0: loss = 1.28462 (* 1 = 1.28462 loss)
I0522 08:27:12.735967 10501 sgd_solver.cpp:106] Iteration 35500, lr = 0.0015
I0522 08:27:23.314074 10501 solver.cpp:237] Iteration 36000, loss = 1.02275
I0522 08:27:23.314110 10501 solver.cpp:253]     Train net output #0: loss = 1.02275 (* 1 = 1.02275 loss)
I0522 08:27:23.314123 10501 sgd_solver.cpp:106] Iteration 36000, lr = 0.0015
I0522 08:27:33.902570 10501 solver.cpp:237] Iteration 36500, loss = 1.08425
I0522 08:27:33.902734 10501 solver.cpp:253]     Train net output #0: loss = 1.08425 (* 1 = 1.08425 loss)
I0522 08:27:33.902748 10501 sgd_solver.cpp:106] Iteration 36500, lr = 0.0015
I0522 08:28:06.725666 10501 solver.cpp:237] Iteration 37000, loss = 1.48946
I0522 08:28:06.725839 10501 solver.cpp:253]     Train net output #0: loss = 1.48946 (* 1 = 1.48946 loss)
I0522 08:28:06.725853 10501 sgd_solver.cpp:106] Iteration 37000, lr = 0.0015
I0522 08:28:17.359928 10501 solver.cpp:237] Iteration 37500, loss = 1.71859
I0522 08:28:17.359964 10501 solver.cpp:253]     Train net output #0: loss = 1.71859 (* 1 = 1.71859 loss)
I0522 08:28:17.359980 10501 sgd_solver.cpp:106] Iteration 37500, lr = 0.0015
I0522 08:28:27.992651 10501 solver.cpp:237] Iteration 38000, loss = 1.45555
I0522 08:28:27.992703 10501 solver.cpp:253]     Train net output #0: loss = 1.45555 (* 1 = 1.45555 loss)
I0522 08:28:27.992718 10501 sgd_solver.cpp:106] Iteration 38000, lr = 0.0015
I0522 08:28:38.626178 10501 solver.cpp:237] Iteration 38500, loss = 1.24003
I0522 08:28:38.626323 10501 solver.cpp:253]     Train net output #0: loss = 1.24002 (* 1 = 1.24002 loss)
I0522 08:28:38.626338 10501 sgd_solver.cpp:106] Iteration 38500, lr = 0.0015
I0522 08:28:49.261188 10501 solver.cpp:237] Iteration 39000, loss = 1.18026
I0522 08:28:49.261236 10501 solver.cpp:253]     Train net output #0: loss = 1.18026 (* 1 = 1.18026 loss)
I0522 08:28:49.261252 10501 sgd_solver.cpp:106] Iteration 39000, lr = 0.0015
I0522 08:28:59.898329 10501 solver.cpp:237] Iteration 39500, loss = 1.28399
I0522 08:28:59.898365 10501 solver.cpp:253]     Train net output #0: loss = 1.28399 (* 1 = 1.28399 loss)
I0522 08:28:59.898380 10501 sgd_solver.cpp:106] Iteration 39500, lr = 0.0015
I0522 08:29:10.516981 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_40000.caffemodel
I0522 08:29:10.569725 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_40000.solverstate
I0522 08:29:10.596367 10501 solver.cpp:341] Iteration 40000, Testing net (#0)
I0522 08:30:21.159016 10501 solver.cpp:409]     Test net output #0: accuracy = 0.858386
I0522 08:30:21.159193 10501 solver.cpp:409]     Test net output #1: loss = 0.454958 (* 1 = 0.454958 loss)
I0522 08:30:43.294095 10501 solver.cpp:237] Iteration 40000, loss = 1.2393
I0522 08:30:43.294152 10501 solver.cpp:253]     Train net output #0: loss = 1.2393 (* 1 = 1.2393 loss)
I0522 08:30:43.294167 10501 sgd_solver.cpp:106] Iteration 40000, lr = 0.0015
I0522 08:30:53.881819 10501 solver.cpp:237] Iteration 40500, loss = 1.3609
I0522 08:30:53.881989 10501 solver.cpp:253]     Train net output #0: loss = 1.3609 (* 1 = 1.3609 loss)
I0522 08:30:53.882004 10501 sgd_solver.cpp:106] Iteration 40500, lr = 0.0015
I0522 08:31:04.468008 10501 solver.cpp:237] Iteration 41000, loss = 1.12817
I0522 08:31:04.468044 10501 solver.cpp:253]     Train net output #0: loss = 1.12817 (* 1 = 1.12817 loss)
I0522 08:31:04.468058 10501 sgd_solver.cpp:106] Iteration 41000, lr = 0.0015
I0522 08:31:15.047756 10501 solver.cpp:237] Iteration 41500, loss = 1.02985
I0522 08:31:15.047788 10501 solver.cpp:253]     Train net output #0: loss = 1.02985 (* 1 = 1.02985 loss)
I0522 08:31:15.047804 10501 sgd_solver.cpp:106] Iteration 41500, lr = 0.0015
I0522 08:31:25.627226 10501 solver.cpp:237] Iteration 42000, loss = 1.16009
I0522 08:31:25.627385 10501 solver.cpp:253]     Train net output #0: loss = 1.16009 (* 1 = 1.16009 loss)
I0522 08:31:25.627399 10501 sgd_solver.cpp:106] Iteration 42000, lr = 0.0015
I0522 08:31:36.207419 10501 solver.cpp:237] Iteration 42500, loss = 0.868707
I0522 08:31:36.207456 10501 solver.cpp:253]     Train net output #0: loss = 0.868706 (* 1 = 0.868706 loss)
I0522 08:31:36.207473 10501 sgd_solver.cpp:106] Iteration 42500, lr = 0.0015
I0522 08:31:46.777041 10501 solver.cpp:237] Iteration 43000, loss = 1.3746
I0522 08:31:46.777094 10501 solver.cpp:253]     Train net output #0: loss = 1.3746 (* 1 = 1.3746 loss)
I0522 08:31:46.777108 10501 sgd_solver.cpp:106] Iteration 43000, lr = 0.0015
I0522 08:32:19.497526 10501 solver.cpp:237] Iteration 43500, loss = 1.2066
I0522 08:32:19.497701 10501 solver.cpp:253]     Train net output #0: loss = 1.2066 (* 1 = 1.2066 loss)
I0522 08:32:19.497716 10501 sgd_solver.cpp:106] Iteration 43500, lr = 0.0015
I0522 08:32:30.077211 10501 solver.cpp:237] Iteration 44000, loss = 1.16625
I0522 08:32:30.077247 10501 solver.cpp:253]     Train net output #0: loss = 1.16625 (* 1 = 1.16625 loss)
I0522 08:32:30.077260 10501 sgd_solver.cpp:106] Iteration 44000, lr = 0.0015
I0522 08:32:40.665112 10501 solver.cpp:237] Iteration 44500, loss = 1.66229
I0522 08:32:40.665160 10501 solver.cpp:253]     Train net output #0: loss = 1.66229 (* 1 = 1.66229 loss)
I0522 08:32:40.665176 10501 sgd_solver.cpp:106] Iteration 44500, lr = 0.0015
I0522 08:32:51.215695 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_45000.caffemodel
I0522 08:32:51.269933 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_45000.solverstate
I0522 08:32:51.305091 10501 solver.cpp:237] Iteration 45000, loss = 1.25027
I0522 08:32:51.305141 10501 solver.cpp:253]     Train net output #0: loss = 1.25027 (* 1 = 1.25027 loss)
I0522 08:32:51.305155 10501 sgd_solver.cpp:106] Iteration 45000, lr = 0.0015
I0522 08:33:01.885973 10501 solver.cpp:237] Iteration 45500, loss = 1.12818
I0522 08:33:01.886021 10501 solver.cpp:253]     Train net output #0: loss = 1.12818 (* 1 = 1.12818 loss)
I0522 08:33:01.886035 10501 sgd_solver.cpp:106] Iteration 45500, lr = 0.0015
I0522 08:33:12.471040 10501 solver.cpp:237] Iteration 46000, loss = 1.77155
I0522 08:33:12.471076 10501 solver.cpp:253]     Train net output #0: loss = 1.77155 (* 1 = 1.77155 loss)
I0522 08:33:12.471091 10501 sgd_solver.cpp:106] Iteration 46000, lr = 0.0015
I0522 08:33:23.061285 10501 solver.cpp:237] Iteration 46500, loss = 1.20436
I0522 08:33:23.061456 10501 solver.cpp:253]     Train net output #0: loss = 1.20436 (* 1 = 1.20436 loss)
I0522 08:33:23.061470 10501 sgd_solver.cpp:106] Iteration 46500, lr = 0.0015
I0522 08:33:55.822919 10501 solver.cpp:237] Iteration 47000, loss = 1.08135
I0522 08:33:55.823096 10501 solver.cpp:253]     Train net output #0: loss = 1.08135 (* 1 = 1.08135 loss)
I0522 08:33:55.823110 10501 sgd_solver.cpp:106] Iteration 47000, lr = 0.0015
I0522 08:34:06.404069 10501 solver.cpp:237] Iteration 47500, loss = 1.39454
I0522 08:34:06.404106 10501 solver.cpp:253]     Train net output #0: loss = 1.39454 (* 1 = 1.39454 loss)
I0522 08:34:06.404121 10501 sgd_solver.cpp:106] Iteration 47500, lr = 0.0015
I0522 08:34:16.978567 10501 solver.cpp:237] Iteration 48000, loss = 1.43388
I0522 08:34:16.978621 10501 solver.cpp:253]     Train net output #0: loss = 1.43388 (* 1 = 1.43388 loss)
I0522 08:34:16.978636 10501 sgd_solver.cpp:106] Iteration 48000, lr = 0.0015
I0522 08:34:27.560642 10501 solver.cpp:237] Iteration 48500, loss = 1.48166
I0522 08:34:27.560791 10501 solver.cpp:253]     Train net output #0: loss = 1.48166 (* 1 = 1.48166 loss)
I0522 08:34:27.560806 10501 sgd_solver.cpp:106] Iteration 48500, lr = 0.0015
I0522 08:34:38.139979 10501 solver.cpp:237] Iteration 49000, loss = 1.3139
I0522 08:34:38.140027 10501 solver.cpp:253]     Train net output #0: loss = 1.3139 (* 1 = 1.3139 loss)
I0522 08:34:38.140041 10501 sgd_solver.cpp:106] Iteration 49000, lr = 0.0015
I0522 08:34:48.723809 10501 solver.cpp:237] Iteration 49500, loss = 1.28536
I0522 08:34:48.723845 10501 solver.cpp:253]     Train net output #0: loss = 1.28536 (* 1 = 1.28536 loss)
I0522 08:34:48.723860 10501 sgd_solver.cpp:106] Iteration 49500, lr = 0.0015
I0522 08:34:59.292832 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_50000.caffemodel
I0522 08:34:59.348024 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_50000.solverstate
I0522 08:34:59.376842 10501 solver.cpp:341] Iteration 50000, Testing net (#0)
I0522 08:35:48.966462 10501 solver.cpp:409]     Test net output #0: accuracy = 0.867945
I0522 08:35:48.966634 10501 solver.cpp:409]     Test net output #1: loss = 0.429312 (* 1 = 0.429312 loss)
I0522 08:36:09.839622 10501 solver.cpp:237] Iteration 50000, loss = 1.17548
I0522 08:36:09.839684 10501 solver.cpp:253]     Train net output #0: loss = 1.17548 (* 1 = 1.17548 loss)
I0522 08:36:09.839699 10501 sgd_solver.cpp:106] Iteration 50000, lr = 0.0015
I0522 08:36:20.362236 10501 solver.cpp:237] Iteration 50500, loss = 1.51979
I0522 08:36:20.362406 10501 solver.cpp:253]     Train net output #0: loss = 1.51979 (* 1 = 1.51979 loss)
I0522 08:36:20.362421 10501 sgd_solver.cpp:106] Iteration 50500, lr = 0.0015
I0522 08:36:30.891029 10501 solver.cpp:237] Iteration 51000, loss = 1.24292
I0522 08:36:30.891065 10501 solver.cpp:253]     Train net output #0: loss = 1.24292 (* 1 = 1.24292 loss)
I0522 08:36:30.891083 10501 sgd_solver.cpp:106] Iteration 51000, lr = 0.0015
I0522 08:36:41.424646 10501 solver.cpp:237] Iteration 51500, loss = 1.4682
I0522 08:36:41.424684 10501 solver.cpp:253]     Train net output #0: loss = 1.4682 (* 1 = 1.4682 loss)
I0522 08:36:41.424696 10501 sgd_solver.cpp:106] Iteration 51500, lr = 0.0015
I0522 08:36:51.965030 10501 solver.cpp:237] Iteration 52000, loss = 1.28757
I0522 08:36:51.965188 10501 solver.cpp:253]     Train net output #0: loss = 1.28757 (* 1 = 1.28757 loss)
I0522 08:36:51.965204 10501 sgd_solver.cpp:106] Iteration 52000, lr = 0.0015
I0522 08:37:02.501374 10501 solver.cpp:237] Iteration 52500, loss = 1.19951
I0522 08:37:02.501410 10501 solver.cpp:253]     Train net output #0: loss = 1.19951 (* 1 = 1.19951 loss)
I0522 08:37:02.501425 10501 sgd_solver.cpp:106] Iteration 52500, lr = 0.0015
I0522 08:37:13.028712 10501 solver.cpp:237] Iteration 53000, loss = 1.36391
I0522 08:37:13.028762 10501 solver.cpp:253]     Train net output #0: loss = 1.36391 (* 1 = 1.36391 loss)
I0522 08:37:13.028779 10501 sgd_solver.cpp:106] Iteration 53000, lr = 0.0015
I0522 08:37:44.469130 10501 solver.cpp:237] Iteration 53500, loss = 0.90847
I0522 08:37:44.469313 10501 solver.cpp:253]     Train net output #0: loss = 0.908469 (* 1 = 0.908469 loss)
I0522 08:37:44.469329 10501 sgd_solver.cpp:106] Iteration 53500, lr = 0.0015
I0522 08:37:54.983810 10501 solver.cpp:237] Iteration 54000, loss = 1.2127
I0522 08:37:54.983847 10501 solver.cpp:253]     Train net output #0: loss = 1.2127 (* 1 = 1.2127 loss)
I0522 08:37:54.983863 10501 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015
I0522 08:38:05.587469 10501 solver.cpp:237] Iteration 54500, loss = 1.60826
I0522 08:38:05.587524 10501 solver.cpp:253]     Train net output #0: loss = 1.60826 (* 1 = 1.60826 loss)
I0522 08:38:05.587538 10501 sgd_solver.cpp:106] Iteration 54500, lr = 0.0015
I0522 08:38:16.104007 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_55000.caffemodel
I0522 08:38:16.156216 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_55000.solverstate
I0522 08:38:16.189123 10501 solver.cpp:237] Iteration 55000, loss = 1.24882
I0522 08:38:16.189173 10501 solver.cpp:253]     Train net output #0: loss = 1.24882 (* 1 = 1.24882 loss)
I0522 08:38:16.189188 10501 sgd_solver.cpp:106] Iteration 55000, lr = 0.0015
I0522 08:38:26.726197 10501 solver.cpp:237] Iteration 55500, loss = 1.64201
I0522 08:38:26.726248 10501 solver.cpp:253]     Train net output #0: loss = 1.642 (* 1 = 1.642 loss)
I0522 08:38:26.726260 10501 sgd_solver.cpp:106] Iteration 55500, lr = 0.0015
I0522 08:38:37.275768 10501 solver.cpp:237] Iteration 56000, loss = 1.02495
I0522 08:38:37.275804 10501 solver.cpp:253]     Train net output #0: loss = 1.02495 (* 1 = 1.02495 loss)
I0522 08:38:37.275820 10501 sgd_solver.cpp:106] Iteration 56000, lr = 0.0015
I0522 08:38:47.794284 10501 solver.cpp:237] Iteration 56500, loss = 0.844229
I0522 08:38:47.794452 10501 solver.cpp:253]     Train net output #0: loss = 0.844228 (* 1 = 0.844228 loss)
I0522 08:38:47.794469 10501 sgd_solver.cpp:106] Iteration 56500, lr = 0.0015
I0522 08:39:19.183069 10501 solver.cpp:237] Iteration 57000, loss = 1.11419
I0522 08:39:19.183243 10501 solver.cpp:253]     Train net output #0: loss = 1.11419 (* 1 = 1.11419 loss)
I0522 08:39:19.183259 10501 sgd_solver.cpp:106] Iteration 57000, lr = 0.0015
I0522 08:39:29.694900 10501 solver.cpp:237] Iteration 57500, loss = 1.07354
I0522 08:39:29.694936 10501 solver.cpp:253]     Train net output #0: loss = 1.07354 (* 1 = 1.07354 loss)
I0522 08:39:29.694953 10501 sgd_solver.cpp:106] Iteration 57500, lr = 0.0015
I0522 08:39:40.232028 10501 solver.cpp:237] Iteration 58000, loss = 1.07286
I0522 08:39:40.232081 10501 solver.cpp:253]     Train net output #0: loss = 1.07286 (* 1 = 1.07286 loss)
I0522 08:39:40.232096 10501 sgd_solver.cpp:106] Iteration 58000, lr = 0.0015
I0522 08:39:50.760098 10501 solver.cpp:237] Iteration 58500, loss = 1.52427
I0522 08:39:50.760249 10501 solver.cpp:253]     Train net output #0: loss = 1.52427 (* 1 = 1.52427 loss)
I0522 08:39:50.760263 10501 sgd_solver.cpp:106] Iteration 58500, lr = 0.0015
I0522 08:40:01.287859 10501 solver.cpp:237] Iteration 59000, loss = 1.44969
I0522 08:40:01.287895 10501 solver.cpp:253]     Train net output #0: loss = 1.44969 (* 1 = 1.44969 loss)
I0522 08:40:01.287911 10501 sgd_solver.cpp:106] Iteration 59000, lr = 0.0015
I0522 08:40:11.826248 10501 solver.cpp:237] Iteration 59500, loss = 1.5752
I0522 08:40:11.826316 10501 solver.cpp:253]     Train net output #0: loss = 1.5752 (* 1 = 1.5752 loss)
I0522 08:40:11.826330 10501 sgd_solver.cpp:106] Iteration 59500, lr = 0.0015
I0522 08:40:22.346282 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_60000.caffemodel
I0522 08:40:22.398824 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_60000.solverstate
I0522 08:40:22.425189 10501 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 08:41:32.956192 10501 solver.cpp:409]     Test net output #0: accuracy = 0.870797
I0522 08:41:32.956367 10501 solver.cpp:409]     Test net output #1: loss = 0.406766 (* 1 = 0.406766 loss)
I0522 08:41:53.820519 10501 solver.cpp:237] Iteration 60000, loss = 1.12038
I0522 08:41:53.820576 10501 solver.cpp:253]     Train net output #0: loss = 1.12038 (* 1 = 1.12038 loss)
I0522 08:41:53.820591 10501 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0522 08:42:04.360538 10501 solver.cpp:237] Iteration 60500, loss = 1.13595
I0522 08:42:04.360702 10501 solver.cpp:253]     Train net output #0: loss = 1.13595 (* 1 = 1.13595 loss)
I0522 08:42:04.360715 10501 sgd_solver.cpp:106] Iteration 60500, lr = 0.0015
I0522 08:42:14.892217 10501 solver.cpp:237] Iteration 61000, loss = 1.2374
I0522 08:42:14.892264 10501 solver.cpp:253]     Train net output #0: loss = 1.23739 (* 1 = 1.23739 loss)
I0522 08:42:14.892279 10501 sgd_solver.cpp:106] Iteration 61000, lr = 0.0015
I0522 08:42:25.419656 10501 solver.cpp:237] Iteration 61500, loss = 1.24319
I0522 08:42:25.419692 10501 solver.cpp:253]     Train net output #0: loss = 1.24319 (* 1 = 1.24319 loss)
I0522 08:42:25.419708 10501 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0522 08:42:35.960327 10501 solver.cpp:237] Iteration 62000, loss = 1.09765
I0522 08:42:35.960497 10501 solver.cpp:253]     Train net output #0: loss = 1.09765 (* 1 = 1.09765 loss)
I0522 08:42:35.960511 10501 sgd_solver.cpp:106] Iteration 62000, lr = 0.0015
I0522 08:42:46.503726 10501 solver.cpp:237] Iteration 62500, loss = 1.43606
I0522 08:42:46.503762 10501 solver.cpp:253]     Train net output #0: loss = 1.43605 (* 1 = 1.43605 loss)
I0522 08:42:46.503778 10501 sgd_solver.cpp:106] Iteration 62500, lr = 0.0015
I0522 08:42:57.041688 10501 solver.cpp:237] Iteration 63000, loss = 0.970033
I0522 08:42:57.041744 10501 solver.cpp:253]     Train net output #0: loss = 0.970032 (* 1 = 0.970032 loss)
I0522 08:42:57.041759 10501 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0522 08:43:28.484541 10501 solver.cpp:237] Iteration 63500, loss = 1.07195
I0522 08:43:28.484714 10501 solver.cpp:253]     Train net output #0: loss = 1.07195 (* 1 = 1.07195 loss)
I0522 08:43:28.484729 10501 sgd_solver.cpp:106] Iteration 63500, lr = 0.0015
I0522 08:43:39.013432 10501 solver.cpp:237] Iteration 64000, loss = 1.13562
I0522 08:43:39.013466 10501 solver.cpp:253]     Train net output #0: loss = 1.13562 (* 1 = 1.13562 loss)
I0522 08:43:39.013484 10501 sgd_solver.cpp:106] Iteration 64000, lr = 0.0015
I0522 08:43:49.552296 10501 solver.cpp:237] Iteration 64500, loss = 1.07866
I0522 08:43:49.552345 10501 solver.cpp:253]     Train net output #0: loss = 1.07866 (* 1 = 1.07866 loss)
I0522 08:43:49.552358 10501 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0522 08:44:00.072433 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_65000.caffemodel
I0522 08:44:00.124944 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_65000.solverstate
I0522 08:44:00.157922 10501 solver.cpp:237] Iteration 65000, loss = 1.18909
I0522 08:44:00.157971 10501 solver.cpp:253]     Train net output #0: loss = 1.18909 (* 1 = 1.18909 loss)
I0522 08:44:00.157985 10501 sgd_solver.cpp:106] Iteration 65000, lr = 0.0015
I0522 08:44:10.695286 10501 solver.cpp:237] Iteration 65500, loss = 0.86156
I0522 08:44:10.695323 10501 solver.cpp:253]     Train net output #0: loss = 0.861559 (* 1 = 0.861559 loss)
I0522 08:44:10.695338 10501 sgd_solver.cpp:106] Iteration 65500, lr = 0.0015
I0522 08:44:21.231510 10501 solver.cpp:237] Iteration 66000, loss = 1.05496
I0522 08:44:21.231562 10501 solver.cpp:253]     Train net output #0: loss = 1.05496 (* 1 = 1.05496 loss)
I0522 08:44:21.231577 10501 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0522 08:44:31.746986 10501 solver.cpp:237] Iteration 66500, loss = 1.41023
I0522 08:44:31.747151 10501 solver.cpp:253]     Train net output #0: loss = 1.41023 (* 1 = 1.41023 loss)
I0522 08:44:31.747165 10501 sgd_solver.cpp:106] Iteration 66500, lr = 0.0015
I0522 08:45:03.190248 10501 solver.cpp:237] Iteration 67000, loss = 1.56309
I0522 08:45:03.190425 10501 solver.cpp:253]     Train net output #0: loss = 1.56309 (* 1 = 1.56309 loss)
I0522 08:45:03.190440 10501 sgd_solver.cpp:106] Iteration 67000, lr = 0.0015
I0522 08:45:13.723727 10501 solver.cpp:237] Iteration 67500, loss = 1.39012
I0522 08:45:13.723763 10501 solver.cpp:253]     Train net output #0: loss = 1.39012 (* 1 = 1.39012 loss)
I0522 08:45:13.723778 10501 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0522 08:45:24.257975 10501 solver.cpp:237] Iteration 68000, loss = 1.4279
I0522 08:45:24.258013 10501 solver.cpp:253]     Train net output #0: loss = 1.4279 (* 1 = 1.4279 loss)
I0522 08:45:24.258028 10501 sgd_solver.cpp:106] Iteration 68000, lr = 0.0015
I0522 08:45:34.781452 10501 solver.cpp:237] Iteration 68500, loss = 1.22287
I0522 08:45:34.781613 10501 solver.cpp:253]     Train net output #0: loss = 1.22287 (* 1 = 1.22287 loss)
I0522 08:45:34.781630 10501 sgd_solver.cpp:106] Iteration 68500, lr = 0.0015
I0522 08:45:45.317085 10501 solver.cpp:237] Iteration 69000, loss = 1.34849
I0522 08:45:45.317121 10501 solver.cpp:253]     Train net output #0: loss = 1.34848 (* 1 = 1.34848 loss)
I0522 08:45:45.317137 10501 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0522 08:45:55.850813 10501 solver.cpp:237] Iteration 69500, loss = 1.04442
I0522 08:45:55.850864 10501 solver.cpp:253]     Train net output #0: loss = 1.04441 (* 1 = 1.04441 loss)
I0522 08:45:55.850878 10501 sgd_solver.cpp:106] Iteration 69500, lr = 0.0015
I0522 08:46:06.366173 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_70000.caffemodel
I0522 08:46:06.418557 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_70000.solverstate
I0522 08:46:06.445014 10501 solver.cpp:341] Iteration 70000, Testing net (#0)
I0522 08:46:55.779831 10501 solver.cpp:409]     Test net output #0: accuracy = 0.871402
I0522 08:46:55.780004 10501 solver.cpp:409]     Test net output #1: loss = 0.436682 (* 1 = 0.436682 loss)
I0522 08:47:16.684931 10501 solver.cpp:237] Iteration 70000, loss = 1.07581
I0522 08:47:16.684989 10501 solver.cpp:253]     Train net output #0: loss = 1.07581 (* 1 = 1.07581 loss)
I0522 08:47:16.685003 10501 sgd_solver.cpp:106] Iteration 70000, lr = 0.0015
I0522 08:47:27.248121 10501 solver.cpp:237] Iteration 70500, loss = 1.22302
I0522 08:47:27.248289 10501 solver.cpp:253]     Train net output #0: loss = 1.22301 (* 1 = 1.22301 loss)
I0522 08:47:27.248304 10501 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0522 08:47:37.794674 10501 solver.cpp:237] Iteration 71000, loss = 1.05503
I0522 08:47:37.794720 10501 solver.cpp:253]     Train net output #0: loss = 1.05503 (* 1 = 1.05503 loss)
I0522 08:47:37.794736 10501 sgd_solver.cpp:106] Iteration 71000, lr = 0.0015
I0522 08:47:48.349941 10501 solver.cpp:237] Iteration 71500, loss = 1.25711
I0522 08:47:48.349977 10501 solver.cpp:253]     Train net output #0: loss = 1.25711 (* 1 = 1.25711 loss)
I0522 08:47:48.349992 10501 sgd_solver.cpp:106] Iteration 71500, lr = 0.0015
I0522 08:47:58.902879 10501 solver.cpp:237] Iteration 72000, loss = 1.23909
I0522 08:47:58.903059 10501 solver.cpp:253]     Train net output #0: loss = 1.23909 (* 1 = 1.23909 loss)
I0522 08:47:58.903074 10501 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0522 08:48:09.458948 10501 solver.cpp:237] Iteration 72500, loss = 1.26093
I0522 08:48:09.458984 10501 solver.cpp:253]     Train net output #0: loss = 1.26093 (* 1 = 1.26093 loss)
I0522 08:48:09.459000 10501 sgd_solver.cpp:106] Iteration 72500, lr = 0.0015
I0522 08:48:19.996354 10501 solver.cpp:237] Iteration 73000, loss = 1.31135
I0522 08:48:19.996392 10501 solver.cpp:253]     Train net output #0: loss = 1.31135 (* 1 = 1.31135 loss)
I0522 08:48:19.996404 10501 sgd_solver.cpp:106] Iteration 73000, lr = 0.0015
I0522 08:48:51.459730 10501 solver.cpp:237] Iteration 73500, loss = 1.26334
I0522 08:48:51.459916 10501 solver.cpp:253]     Train net output #0: loss = 1.26334 (* 1 = 1.26334 loss)
I0522 08:48:51.459933 10501 sgd_solver.cpp:106] Iteration 73500, lr = 0.0015
I0522 08:49:02.026479 10501 solver.cpp:237] Iteration 74000, loss = 1.27487
I0522 08:49:02.026515 10501 solver.cpp:253]     Train net output #0: loss = 1.27487 (* 1 = 1.27487 loss)
I0522 08:49:02.026531 10501 sgd_solver.cpp:106] Iteration 74000, lr = 0.0015
I0522 08:49:12.576355 10501 solver.cpp:237] Iteration 74500, loss = 1.12227
I0522 08:49:12.576405 10501 solver.cpp:253]     Train net output #0: loss = 1.12227 (* 1 = 1.12227 loss)
I0522 08:49:12.576417 10501 sgd_solver.cpp:106] Iteration 74500, lr = 0.0015
I0522 08:49:23.093513 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_75000.caffemodel
I0522 08:49:23.148344 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_75000.solverstate
I0522 08:49:23.184098 10501 solver.cpp:237] Iteration 75000, loss = 1.31893
I0522 08:49:23.184154 10501 solver.cpp:253]     Train net output #0: loss = 1.31892 (* 1 = 1.31892 loss)
I0522 08:49:23.184167 10501 sgd_solver.cpp:106] Iteration 75000, lr = 0.0015
I0522 08:49:33.738075 10501 solver.cpp:237] Iteration 75500, loss = 1.07634
I0522 08:49:33.738111 10501 solver.cpp:253]     Train net output #0: loss = 1.07634 (* 1 = 1.07634 loss)
I0522 08:49:33.738127 10501 sgd_solver.cpp:106] Iteration 75500, lr = 0.0015
I0522 08:49:44.305027 10501 solver.cpp:237] Iteration 76000, loss = 1.39179
I0522 08:49:44.305083 10501 solver.cpp:253]     Train net output #0: loss = 1.39179 (* 1 = 1.39179 loss)
I0522 08:49:44.305097 10501 sgd_solver.cpp:106] Iteration 76000, lr = 0.0015
I0522 08:49:54.873998 10501 solver.cpp:237] Iteration 76500, loss = 1.14816
I0522 08:49:54.874155 10501 solver.cpp:253]     Train net output #0: loss = 1.14816 (* 1 = 1.14816 loss)
I0522 08:49:54.874171 10501 sgd_solver.cpp:106] Iteration 76500, lr = 0.0015
I0522 08:50:26.303201 10501 solver.cpp:237] Iteration 77000, loss = 1.03248
I0522 08:50:26.303377 10501 solver.cpp:253]     Train net output #0: loss = 1.03248 (* 1 = 1.03248 loss)
I0522 08:50:26.303393 10501 sgd_solver.cpp:106] Iteration 77000, lr = 0.0015
I0522 08:50:36.876452 10501 solver.cpp:237] Iteration 77500, loss = 0.998533
I0522 08:50:36.876502 10501 solver.cpp:253]     Train net output #0: loss = 0.998532 (* 1 = 0.998532 loss)
I0522 08:50:36.876516 10501 sgd_solver.cpp:106] Iteration 77500, lr = 0.0015
I0522 08:50:47.448814 10501 solver.cpp:237] Iteration 78000, loss = 1.3764
I0522 08:50:47.448850 10501 solver.cpp:253]     Train net output #0: loss = 1.3764 (* 1 = 1.3764 loss)
I0522 08:50:47.448868 10501 sgd_solver.cpp:106] Iteration 78000, lr = 0.0015
I0522 08:50:58.022970 10501 solver.cpp:237] Iteration 78500, loss = 1.2736
I0522 08:50:58.023140 10501 solver.cpp:253]     Train net output #0: loss = 1.2736 (* 1 = 1.2736 loss)
I0522 08:50:58.023155 10501 sgd_solver.cpp:106] Iteration 78500, lr = 0.0015
I0522 08:51:08.604214 10501 solver.cpp:237] Iteration 79000, loss = 1.24123
I0522 08:51:08.604250 10501 solver.cpp:253]     Train net output #0: loss = 1.24123 (* 1 = 1.24123 loss)
I0522 08:51:08.604266 10501 sgd_solver.cpp:106] Iteration 79000, lr = 0.0015
I0522 08:51:19.174962 10501 solver.cpp:237] Iteration 79500, loss = 1.02785
I0522 08:51:19.175010 10501 solver.cpp:253]     Train net output #0: loss = 1.02785 (* 1 = 1.02785 loss)
I0522 08:51:19.175026 10501 sgd_solver.cpp:106] Iteration 79500, lr = 0.0015
I0522 08:51:29.723644 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_80000.caffemodel
I0522 08:51:29.776301 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_80000.solverstate
I0522 08:51:29.802811 10501 solver.cpp:341] Iteration 80000, Testing net (#0)
I0522 08:52:40.164250 10501 solver.cpp:409]     Test net output #0: accuracy = 0.881209
I0522 08:52:40.164428 10501 solver.cpp:409]     Test net output #1: loss = 0.38089 (* 1 = 0.38089 loss)
I0522 08:53:01.036834 10501 solver.cpp:237] Iteration 80000, loss = 1.08418
I0522 08:53:01.036890 10501 solver.cpp:253]     Train net output #0: loss = 1.08418 (* 1 = 1.08418 loss)
I0522 08:53:01.036906 10501 sgd_solver.cpp:106] Iteration 80000, lr = 0.0015
I0522 08:53:11.570391 10501 solver.cpp:237] Iteration 80500, loss = 1.00765
I0522 08:53:11.570551 10501 solver.cpp:253]     Train net output #0: loss = 1.00765 (* 1 = 1.00765 loss)
I0522 08:53:11.570565 10501 sgd_solver.cpp:106] Iteration 80500, lr = 0.0015
I0522 08:53:22.094506 10501 solver.cpp:237] Iteration 81000, loss = 1.48288
I0522 08:53:22.094552 10501 solver.cpp:253]     Train net output #0: loss = 1.48288 (* 1 = 1.48288 loss)
I0522 08:53:22.094570 10501 sgd_solver.cpp:106] Iteration 81000, lr = 0.0015
I0522 08:53:32.630022 10501 solver.cpp:237] Iteration 81500, loss = 1.2366
I0522 08:53:32.630058 10501 solver.cpp:253]     Train net output #0: loss = 1.2366 (* 1 = 1.2366 loss)
I0522 08:53:32.630074 10501 sgd_solver.cpp:106] Iteration 81500, lr = 0.0015
I0522 08:53:43.144281 10501 solver.cpp:237] Iteration 82000, loss = 1.40263
I0522 08:53:43.144433 10501 solver.cpp:253]     Train net output #0: loss = 1.40263 (* 1 = 1.40263 loss)
I0522 08:53:43.144448 10501 sgd_solver.cpp:106] Iteration 82000, lr = 0.0015
I0522 08:53:53.678396 10501 solver.cpp:237] Iteration 82500, loss = 0.982849
I0522 08:53:53.678443 10501 solver.cpp:253]     Train net output #0: loss = 0.982848 (* 1 = 0.982848 loss)
I0522 08:53:53.678458 10501 sgd_solver.cpp:106] Iteration 82500, lr = 0.0015
I0522 08:54:04.204856 10501 solver.cpp:237] Iteration 83000, loss = 1.27464
I0522 08:54:04.204891 10501 solver.cpp:253]     Train net output #0: loss = 1.27464 (* 1 = 1.27464 loss)
I0522 08:54:04.204908 10501 sgd_solver.cpp:106] Iteration 83000, lr = 0.0015
I0522 08:54:35.631634 10501 solver.cpp:237] Iteration 83500, loss = 1.48273
I0522 08:54:35.631819 10501 solver.cpp:253]     Train net output #0: loss = 1.48273 (* 1 = 1.48273 loss)
I0522 08:54:35.631835 10501 sgd_solver.cpp:106] Iteration 83500, lr = 0.0015
I0522 08:54:46.150101 10501 solver.cpp:237] Iteration 84000, loss = 1.15383
I0522 08:54:46.150152 10501 solver.cpp:253]     Train net output #0: loss = 1.15383 (* 1 = 1.15383 loss)
I0522 08:54:46.150167 10501 sgd_solver.cpp:106] Iteration 84000, lr = 0.0015
I0522 08:54:56.678426 10501 solver.cpp:237] Iteration 84500, loss = 1.20418
I0522 08:54:56.678463 10501 solver.cpp:253]     Train net output #0: loss = 1.20418 (* 1 = 1.20418 loss)
I0522 08:54:56.678479 10501 sgd_solver.cpp:106] Iteration 84500, lr = 0.0015
I0522 08:55:07.181722 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_85000.caffemodel
I0522 08:55:07.234320 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_85000.solverstate
I0522 08:55:07.267776 10501 solver.cpp:237] Iteration 85000, loss = 1.12909
I0522 08:55:07.267820 10501 solver.cpp:253]     Train net output #0: loss = 1.12908 (* 1 = 1.12908 loss)
I0522 08:55:07.267843 10501 sgd_solver.cpp:106] Iteration 85000, lr = 0.0015
I0522 08:55:17.812686 10501 solver.cpp:237] Iteration 85500, loss = 1.16848
I0522 08:55:17.812722 10501 solver.cpp:253]     Train net output #0: loss = 1.16848 (* 1 = 1.16848 loss)
I0522 08:55:17.812738 10501 sgd_solver.cpp:106] Iteration 85500, lr = 0.0015
I0522 08:55:28.338215 10501 solver.cpp:237] Iteration 86000, loss = 1.15277
I0522 08:55:28.338268 10501 solver.cpp:253]     Train net output #0: loss = 1.15277 (* 1 = 1.15277 loss)
I0522 08:55:28.338284 10501 sgd_solver.cpp:106] Iteration 86000, lr = 0.0015
I0522 08:55:38.864114 10501 solver.cpp:237] Iteration 86500, loss = 0.906327
I0522 08:55:38.864281 10501 solver.cpp:253]     Train net output #0: loss = 0.906326 (* 1 = 0.906326 loss)
I0522 08:55:38.864297 10501 sgd_solver.cpp:106] Iteration 86500, lr = 0.0015
I0522 08:56:10.236536 10501 solver.cpp:237] Iteration 87000, loss = 1.19179
I0522 08:56:10.236714 10501 solver.cpp:253]     Train net output #0: loss = 1.19179 (* 1 = 1.19179 loss)
I0522 08:56:10.236728 10501 sgd_solver.cpp:106] Iteration 87000, lr = 0.0015
I0522 08:56:20.773499 10501 solver.cpp:237] Iteration 87500, loss = 1.70045
I0522 08:56:20.773547 10501 solver.cpp:253]     Train net output #0: loss = 1.70045 (* 1 = 1.70045 loss)
I0522 08:56:20.773563 10501 sgd_solver.cpp:106] Iteration 87500, lr = 0.0015
I0522 08:56:31.306169 10501 solver.cpp:237] Iteration 88000, loss = 1.04101
I0522 08:56:31.306203 10501 solver.cpp:253]     Train net output #0: loss = 1.04101 (* 1 = 1.04101 loss)
I0522 08:56:31.306221 10501 sgd_solver.cpp:106] Iteration 88000, lr = 0.0015
I0522 08:56:41.838482 10501 solver.cpp:237] Iteration 88500, loss = 1.19047
I0522 08:56:41.838639 10501 solver.cpp:253]     Train net output #0: loss = 1.19047 (* 1 = 1.19047 loss)
I0522 08:56:41.838654 10501 sgd_solver.cpp:106] Iteration 88500, lr = 0.0015
I0522 08:56:52.356653 10501 solver.cpp:237] Iteration 89000, loss = 1.19121
I0522 08:56:52.356688 10501 solver.cpp:253]     Train net output #0: loss = 1.19121 (* 1 = 1.19121 loss)
I0522 08:56:52.356703 10501 sgd_solver.cpp:106] Iteration 89000, lr = 0.0015
I0522 08:57:02.876101 10501 solver.cpp:237] Iteration 89500, loss = 0.762686
I0522 08:57:02.876137 10501 solver.cpp:253]     Train net output #0: loss = 0.762686 (* 1 = 0.762686 loss)
I0522 08:57:02.876153 10501 sgd_solver.cpp:106] Iteration 89500, lr = 0.0015
I0522 08:57:13.388685 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_90000.caffemodel
I0522 08:57:13.441442 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_90000.solverstate
I0522 08:57:13.468233 10501 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 08:58:03.086091 10501 solver.cpp:409]     Test net output #0: accuracy = 0.881627
I0522 08:58:03.086267 10501 solver.cpp:409]     Test net output #1: loss = 0.372913 (* 1 = 0.372913 loss)
I0522 08:58:23.976974 10501 solver.cpp:237] Iteration 90000, loss = 1.86332
I0522 08:58:23.977028 10501 solver.cpp:253]     Train net output #0: loss = 1.86332 (* 1 = 1.86332 loss)
I0522 08:58:23.977043 10501 sgd_solver.cpp:106] Iteration 90000, lr = 0.0015
I0522 08:58:34.541122 10501 solver.cpp:237] Iteration 90500, loss = 1.40067
I0522 08:58:34.541280 10501 solver.cpp:253]     Train net output #0: loss = 1.40067 (* 1 = 1.40067 loss)
I0522 08:58:34.541296 10501 sgd_solver.cpp:106] Iteration 90500, lr = 0.0015
I0522 08:58:45.108603 10501 solver.cpp:237] Iteration 91000, loss = 1.23528
I0522 08:58:45.108639 10501 solver.cpp:253]     Train net output #0: loss = 1.23528 (* 1 = 1.23528 loss)
I0522 08:58:45.108654 10501 sgd_solver.cpp:106] Iteration 91000, lr = 0.0015
I0522 08:58:55.667117 10501 solver.cpp:237] Iteration 91500, loss = 1.17626
I0522 08:58:55.667165 10501 solver.cpp:253]     Train net output #0: loss = 1.17626 (* 1 = 1.17626 loss)
I0522 08:58:55.667179 10501 sgd_solver.cpp:106] Iteration 91500, lr = 0.0015
I0522 08:59:06.230767 10501 solver.cpp:237] Iteration 92000, loss = 1.25712
I0522 08:59:06.230932 10501 solver.cpp:253]     Train net output #0: loss = 1.25712 (* 1 = 1.25712 loss)
I0522 08:59:06.230947 10501 sgd_solver.cpp:106] Iteration 92000, lr = 0.0015
I0522 08:59:16.782513 10501 solver.cpp:237] Iteration 92500, loss = 1.17328
I0522 08:59:16.782560 10501 solver.cpp:253]     Train net output #0: loss = 1.17328 (* 1 = 1.17328 loss)
I0522 08:59:16.782577 10501 sgd_solver.cpp:106] Iteration 92500, lr = 0.0015
I0522 08:59:27.341467 10501 solver.cpp:237] Iteration 93000, loss = 1.30064
I0522 08:59:27.341503 10501 solver.cpp:253]     Train net output #0: loss = 1.30063 (* 1 = 1.30063 loss)
I0522 08:59:27.341521 10501 sgd_solver.cpp:106] Iteration 93000, lr = 0.0015
I0522 08:59:58.836205 10501 solver.cpp:237] Iteration 93500, loss = 1.36141
I0522 08:59:58.836387 10501 solver.cpp:253]     Train net output #0: loss = 1.36141 (* 1 = 1.36141 loss)
I0522 08:59:58.836403 10501 sgd_solver.cpp:106] Iteration 93500, lr = 0.0015
I0522 09:00:09.358569 10501 solver.cpp:237] Iteration 94000, loss = 1.585
I0522 09:00:09.358620 10501 solver.cpp:253]     Train net output #0: loss = 1.585 (* 1 = 1.585 loss)
I0522 09:00:09.358635 10501 sgd_solver.cpp:106] Iteration 94000, lr = 0.0015
I0522 09:00:19.878506 10501 solver.cpp:237] Iteration 94500, loss = 1.30548
I0522 09:00:19.878542 10501 solver.cpp:253]     Train net output #0: loss = 1.30548 (* 1 = 1.30548 loss)
I0522 09:00:19.878558 10501 sgd_solver.cpp:106] Iteration 94500, lr = 0.0015
I0522 09:00:30.379120 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_95000.caffemodel
I0522 09:00:30.433948 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_95000.solverstate
I0522 09:00:30.469614 10501 solver.cpp:237] Iteration 95000, loss = 1.22289
I0522 09:00:30.469669 10501 solver.cpp:253]     Train net output #0: loss = 1.22289 (* 1 = 1.22289 loss)
I0522 09:00:30.469686 10501 sgd_solver.cpp:106] Iteration 95000, lr = 0.0015
I0522 09:00:40.988205 10501 solver.cpp:237] Iteration 95500, loss = 1.08817
I0522 09:00:40.988246 10501 solver.cpp:253]     Train net output #0: loss = 1.08817 (* 1 = 1.08817 loss)
I0522 09:00:40.988260 10501 sgd_solver.cpp:106] Iteration 95500, lr = 0.0015
I0522 09:00:51.509081 10501 solver.cpp:237] Iteration 96000, loss = 1.3338
I0522 09:00:51.509117 10501 solver.cpp:253]     Train net output #0: loss = 1.3338 (* 1 = 1.3338 loss)
I0522 09:00:51.509133 10501 sgd_solver.cpp:106] Iteration 96000, lr = 0.0015
I0522 09:01:02.027945 10501 solver.cpp:237] Iteration 96500, loss = 1.03222
I0522 09:01:02.028118 10501 solver.cpp:253]     Train net output #0: loss = 1.03222 (* 1 = 1.03222 loss)
I0522 09:01:02.028132 10501 sgd_solver.cpp:106] Iteration 96500, lr = 0.0015
I0522 09:01:33.413352 10501 solver.cpp:237] Iteration 97000, loss = 1.06019
I0522 09:01:33.413532 10501 solver.cpp:253]     Train net output #0: loss = 1.06018 (* 1 = 1.06018 loss)
I0522 09:01:33.413549 10501 sgd_solver.cpp:106] Iteration 97000, lr = 0.0015
I0522 09:01:43.929734 10501 solver.cpp:237] Iteration 97500, loss = 1.79326
I0522 09:01:43.929780 10501 solver.cpp:253]     Train net output #0: loss = 1.79326 (* 1 = 1.79326 loss)
I0522 09:01:43.929796 10501 sgd_solver.cpp:106] Iteration 97500, lr = 0.0015
I0522 09:01:54.453591 10501 solver.cpp:237] Iteration 98000, loss = 1.30672
I0522 09:01:54.453627 10501 solver.cpp:253]     Train net output #0: loss = 1.30672 (* 1 = 1.30672 loss)
I0522 09:01:54.453644 10501 sgd_solver.cpp:106] Iteration 98000, lr = 0.0015
I0522 09:02:04.976128 10501 solver.cpp:237] Iteration 98500, loss = 1.24062
I0522 09:02:04.976294 10501 solver.cpp:253]     Train net output #0: loss = 1.24062 (* 1 = 1.24062 loss)
I0522 09:02:04.976307 10501 sgd_solver.cpp:106] Iteration 98500, lr = 0.0015
I0522 09:02:15.507613 10501 solver.cpp:237] Iteration 99000, loss = 1.21715
I0522 09:02:15.507668 10501 solver.cpp:253]     Train net output #0: loss = 1.21715 (* 1 = 1.21715 loss)
I0522 09:02:15.507683 10501 sgd_solver.cpp:106] Iteration 99000, lr = 0.0015
I0522 09:02:26.037324 10501 solver.cpp:237] Iteration 99500, loss = 1.62102
I0522 09:02:26.037360 10501 solver.cpp:253]     Train net output #0: loss = 1.62102 (* 1 = 1.62102 loss)
I0522 09:02:26.037374 10501 sgd_solver.cpp:106] Iteration 99500, lr = 0.0015
I0522 09:02:36.528607 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_100000.caffemodel
I0522 09:02:36.584980 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_100000.solverstate
I0522 09:02:36.612716 10501 solver.cpp:341] Iteration 100000, Testing net (#0)
I0522 09:03:47.154707 10501 solver.cpp:409]     Test net output #0: accuracy = 0.8854
I0522 09:03:47.154889 10501 solver.cpp:409]     Test net output #1: loss = 0.394427 (* 1 = 0.394427 loss)
I0522 09:04:08.061538 10501 solver.cpp:237] Iteration 100000, loss = 1.26052
I0522 09:04:08.061594 10501 solver.cpp:253]     Train net output #0: loss = 1.26052 (* 1 = 1.26052 loss)
I0522 09:04:08.061609 10501 sgd_solver.cpp:106] Iteration 100000, lr = 0.0015
I0522 09:04:18.583144 10501 solver.cpp:237] Iteration 100500, loss = 0.975481
I0522 09:04:18.583317 10501 solver.cpp:253]     Train net output #0: loss = 0.975481 (* 1 = 0.975481 loss)
I0522 09:04:18.583331 10501 sgd_solver.cpp:106] Iteration 100500, lr = 0.0015
I0522 09:04:29.097504 10501 solver.cpp:237] Iteration 101000, loss = 1.51506
I0522 09:04:29.097540 10501 solver.cpp:253]     Train net output #0: loss = 1.51506 (* 1 = 1.51506 loss)
I0522 09:04:29.097558 10501 sgd_solver.cpp:106] Iteration 101000, lr = 0.0015
I0522 09:04:39.607537 10501 solver.cpp:237] Iteration 101500, loss = 1.69261
I0522 09:04:39.607585 10501 solver.cpp:253]     Train net output #0: loss = 1.69261 (* 1 = 1.69261 loss)
I0522 09:04:39.607600 10501 sgd_solver.cpp:106] Iteration 101500, lr = 0.0015
I0522 09:04:50.114058 10501 solver.cpp:237] Iteration 102000, loss = 1.05064
I0522 09:04:50.114212 10501 solver.cpp:253]     Train net output #0: loss = 1.05064 (* 1 = 1.05064 loss)
I0522 09:04:50.114225 10501 sgd_solver.cpp:106] Iteration 102000, lr = 0.0015
I0522 09:05:00.608608 10501 solver.cpp:237] Iteration 102500, loss = 1.13745
I0522 09:05:00.608644 10501 solver.cpp:253]     Train net output #0: loss = 1.13745 (* 1 = 1.13745 loss)
I0522 09:05:00.608661 10501 sgd_solver.cpp:106] Iteration 102500, lr = 0.0015
I0522 09:05:11.114152 10501 solver.cpp:237] Iteration 103000, loss = 1.81805
I0522 09:05:11.114204 10501 solver.cpp:253]     Train net output #0: loss = 1.81805 (* 1 = 1.81805 loss)
I0522 09:05:11.114219 10501 sgd_solver.cpp:106] Iteration 103000, lr = 0.0015
I0522 09:05:42.501366 10501 solver.cpp:237] Iteration 103500, loss = 1.12729
I0522 09:05:42.501550 10501 solver.cpp:253]     Train net output #0: loss = 1.12729 (* 1 = 1.12729 loss)
I0522 09:05:42.501566 10501 sgd_solver.cpp:106] Iteration 103500, lr = 0.0015
I0522 09:05:53.006683 10501 solver.cpp:237] Iteration 104000, loss = 0.835855
I0522 09:05:53.006733 10501 solver.cpp:253]     Train net output #0: loss = 0.835855 (* 1 = 0.835855 loss)
I0522 09:05:53.006747 10501 sgd_solver.cpp:106] Iteration 104000, lr = 0.0015
I0522 09:06:03.503361 10501 solver.cpp:237] Iteration 104500, loss = 1.22295
I0522 09:06:03.503398 10501 solver.cpp:253]     Train net output #0: loss = 1.22295 (* 1 = 1.22295 loss)
I0522 09:06:03.503414 10501 sgd_solver.cpp:106] Iteration 104500, lr = 0.0015
I0522 09:06:13.983165 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_105000.caffemodel
I0522 09:06:14.035945 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_105000.solverstate
I0522 09:06:14.068349 10501 solver.cpp:237] Iteration 105000, loss = 1.00655
I0522 09:06:14.068399 10501 solver.cpp:253]     Train net output #0: loss = 1.00655 (* 1 = 1.00655 loss)
I0522 09:06:14.068413 10501 sgd_solver.cpp:106] Iteration 105000, lr = 0.0015
I0522 09:06:24.566995 10501 solver.cpp:237] Iteration 105500, loss = 1.56326
I0522 09:06:24.567044 10501 solver.cpp:253]     Train net output #0: loss = 1.56326 (* 1 = 1.56326 loss)
I0522 09:06:24.567057 10501 sgd_solver.cpp:106] Iteration 105500, lr = 0.0015
I0522 09:06:35.080818 10501 solver.cpp:237] Iteration 106000, loss = 0.956438
I0522 09:06:35.080855 10501 solver.cpp:253]     Train net output #0: loss = 0.956438 (* 1 = 0.956438 loss)
I0522 09:06:35.080871 10501 sgd_solver.cpp:106] Iteration 106000, lr = 0.0015
I0522 09:06:45.578222 10501 solver.cpp:237] Iteration 106500, loss = 1.1353
I0522 09:06:45.578402 10501 solver.cpp:253]     Train net output #0: loss = 1.1353 (* 1 = 1.1353 loss)
I0522 09:06:45.578418 10501 sgd_solver.cpp:106] Iteration 106500, lr = 0.0015
I0522 09:07:16.976073 10501 solver.cpp:237] Iteration 107000, loss = 1.18971
I0522 09:07:16.976258 10501 solver.cpp:253]     Train net output #0: loss = 1.18971 (* 1 = 1.18971 loss)
I0522 09:07:16.976274 10501 sgd_solver.cpp:106] Iteration 107000, lr = 0.0015
I0522 09:07:27.502341 10501 solver.cpp:237] Iteration 107500, loss = 1.31289
I0522 09:07:27.502377 10501 solver.cpp:253]     Train net output #0: loss = 1.31289 (* 1 = 1.31289 loss)
I0522 09:07:27.502393 10501 sgd_solver.cpp:106] Iteration 107500, lr = 0.0015
I0522 09:07:38.005942 10501 solver.cpp:237] Iteration 108000, loss = 0.873656
I0522 09:07:38.005995 10501 solver.cpp:253]     Train net output #0: loss = 0.873656 (* 1 = 0.873656 loss)
I0522 09:07:38.006009 10501 sgd_solver.cpp:106] Iteration 108000, lr = 0.0015
I0522 09:07:48.517899 10501 solver.cpp:237] Iteration 108500, loss = 0.927497
I0522 09:07:48.518057 10501 solver.cpp:253]     Train net output #0: loss = 0.927497 (* 1 = 0.927497 loss)
I0522 09:07:48.518072 10501 sgd_solver.cpp:106] Iteration 108500, lr = 0.0015
I0522 09:07:59.035349 10501 solver.cpp:237] Iteration 109000, loss = 1.51128
I0522 09:07:59.035395 10501 solver.cpp:253]     Train net output #0: loss = 1.51128 (* 1 = 1.51128 loss)
I0522 09:07:59.035411 10501 sgd_solver.cpp:106] Iteration 109000, lr = 0.0015
I0522 09:08:09.553063 10501 solver.cpp:237] Iteration 109500, loss = 1.11087
I0522 09:08:09.553099 10501 solver.cpp:253]     Train net output #0: loss = 1.11087 (* 1 = 1.11087 loss)
I0522 09:08:09.553115 10501 sgd_solver.cpp:106] Iteration 109500, lr = 0.0015
I0522 09:08:20.041299 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_110000.caffemodel
I0522 09:08:20.094156 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_110000.solverstate
I0522 09:08:20.120818 10501 solver.cpp:341] Iteration 110000, Testing net (#0)
I0522 09:09:09.429436 10501 solver.cpp:409]     Test net output #0: accuracy = 0.887081
I0522 09:09:09.429615 10501 solver.cpp:409]     Test net output #1: loss = 0.358253 (* 1 = 0.358253 loss)
I0522 09:09:30.288152 10501 solver.cpp:237] Iteration 110000, loss = 1.30111
I0522 09:09:30.288210 10501 solver.cpp:253]     Train net output #0: loss = 1.30111 (* 1 = 1.30111 loss)
I0522 09:09:30.288225 10501 sgd_solver.cpp:106] Iteration 110000, lr = 0.0015
I0522 09:09:40.789160 10501 solver.cpp:237] Iteration 110500, loss = 1.33023
I0522 09:09:40.789350 10501 solver.cpp:253]     Train net output #0: loss = 1.33023 (* 1 = 1.33023 loss)
I0522 09:09:40.789366 10501 sgd_solver.cpp:106] Iteration 110500, lr = 0.0015
I0522 09:09:51.289997 10501 solver.cpp:237] Iteration 111000, loss = 0.982169
I0522 09:09:51.290035 10501 solver.cpp:253]     Train net output #0: loss = 0.982169 (* 1 = 0.982169 loss)
I0522 09:09:51.290051 10501 sgd_solver.cpp:106] Iteration 111000, lr = 0.0015
I0522 09:10:01.786955 10501 solver.cpp:237] Iteration 111500, loss = 1.54094
I0522 09:10:01.787009 10501 solver.cpp:253]     Train net output #0: loss = 1.54094 (* 1 = 1.54094 loss)
I0522 09:10:01.787024 10501 sgd_solver.cpp:106] Iteration 111500, lr = 0.0015
I0522 09:10:12.283709 10501 solver.cpp:237] Iteration 112000, loss = 1.20639
I0522 09:10:12.283867 10501 solver.cpp:253]     Train net output #0: loss = 1.20639 (* 1 = 1.20639 loss)
I0522 09:10:12.283882 10501 sgd_solver.cpp:106] Iteration 112000, lr = 0.0015
I0522 09:10:22.780167 10501 solver.cpp:237] Iteration 112500, loss = 1.08196
I0522 09:10:22.780203 10501 solver.cpp:253]     Train net output #0: loss = 1.08196 (* 1 = 1.08196 loss)
I0522 09:10:22.780220 10501 sgd_solver.cpp:106] Iteration 112500, lr = 0.0015
I0522 09:10:33.274262 10501 solver.cpp:237] Iteration 113000, loss = 0.941044
I0522 09:10:33.274318 10501 solver.cpp:253]     Train net output #0: loss = 0.941044 (* 1 = 0.941044 loss)
I0522 09:10:33.274333 10501 sgd_solver.cpp:106] Iteration 113000, lr = 0.0015
I0522 09:11:04.671442 10501 solver.cpp:237] Iteration 113500, loss = 1.26938
I0522 09:11:04.671628 10501 solver.cpp:253]     Train net output #0: loss = 1.26938 (* 1 = 1.26938 loss)
I0522 09:11:04.671649 10501 sgd_solver.cpp:106] Iteration 113500, lr = 0.0015
I0522 09:11:15.177899 10501 solver.cpp:237] Iteration 114000, loss = 0.949044
I0522 09:11:15.177937 10501 solver.cpp:253]     Train net output #0: loss = 0.949044 (* 1 = 0.949044 loss)
I0522 09:11:15.177949 10501 sgd_solver.cpp:106] Iteration 114000, lr = 0.0015
I0522 09:11:25.686636 10501 solver.cpp:237] Iteration 114500, loss = 1.16138
I0522 09:11:25.686691 10501 solver.cpp:253]     Train net output #0: loss = 1.16138 (* 1 = 1.16138 loss)
I0522 09:11:25.686707 10501 sgd_solver.cpp:106] Iteration 114500, lr = 0.0015
I0522 09:11:36.165216 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_115000.caffemodel
I0522 09:11:36.218145 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_115000.solverstate
I0522 09:11:36.250532 10501 solver.cpp:237] Iteration 115000, loss = 1.22857
I0522 09:11:36.250583 10501 solver.cpp:253]     Train net output #0: loss = 1.22857 (* 1 = 1.22857 loss)
I0522 09:11:36.250597 10501 sgd_solver.cpp:106] Iteration 115000, lr = 0.0015
I0522 09:11:46.758952 10501 solver.cpp:237] Iteration 115500, loss = 1.16496
I0522 09:11:46.759006 10501 solver.cpp:253]     Train net output #0: loss = 1.16496 (* 1 = 1.16496 loss)
I0522 09:11:46.759021 10501 sgd_solver.cpp:106] Iteration 115500, lr = 0.0015
I0522 09:11:57.254343 10501 solver.cpp:237] Iteration 116000, loss = 1.18369
I0522 09:11:57.254379 10501 solver.cpp:253]     Train net output #0: loss = 1.18369 (* 1 = 1.18369 loss)
I0522 09:11:57.254395 10501 sgd_solver.cpp:106] Iteration 116000, lr = 0.0015
I0522 09:12:07.752195 10501 solver.cpp:237] Iteration 116500, loss = 1.31552
I0522 09:12:07.752377 10501 solver.cpp:253]     Train net output #0: loss = 1.31552 (* 1 = 1.31552 loss)
I0522 09:12:07.752393 10501 sgd_solver.cpp:106] Iteration 116500, lr = 0.0015
I0522 09:12:39.148955 10501 solver.cpp:237] Iteration 117000, loss = 1.29164
I0522 09:12:39.149152 10501 solver.cpp:253]     Train net output #0: loss = 1.29164 (* 1 = 1.29164 loss)
I0522 09:12:39.149168 10501 sgd_solver.cpp:106] Iteration 117000, lr = 0.0015
I0522 09:12:49.645220 10501 solver.cpp:237] Iteration 117500, loss = 1.48347
I0522 09:12:49.645256 10501 solver.cpp:253]     Train net output #0: loss = 1.48347 (* 1 = 1.48347 loss)
I0522 09:12:49.645272 10501 sgd_solver.cpp:106] Iteration 117500, lr = 0.0015
I0522 09:13:00.151187 10501 solver.cpp:237] Iteration 118000, loss = 1.09733
I0522 09:13:00.151238 10501 solver.cpp:253]     Train net output #0: loss = 1.09733 (* 1 = 1.09733 loss)
I0522 09:13:00.151253 10501 sgd_solver.cpp:106] Iteration 118000, lr = 0.0015
I0522 09:13:10.671181 10501 solver.cpp:237] Iteration 118500, loss = 1.08781
I0522 09:13:10.671363 10501 solver.cpp:253]     Train net output #0: loss = 1.08781 (* 1 = 1.08781 loss)
I0522 09:13:10.671378 10501 sgd_solver.cpp:106] Iteration 118500, lr = 0.0015
I0522 09:13:21.254040 10501 solver.cpp:237] Iteration 119000, loss = 1.11671
I0522 09:13:21.254076 10501 solver.cpp:253]     Train net output #0: loss = 1.11671 (* 1 = 1.11671 loss)
I0522 09:13:21.254093 10501 sgd_solver.cpp:106] Iteration 119000, lr = 0.0015
I0522 09:13:31.809161 10501 solver.cpp:237] Iteration 119500, loss = 0.916335
I0522 09:13:31.809211 10501 solver.cpp:253]     Train net output #0: loss = 0.916335 (* 1 = 0.916335 loss)
I0522 09:13:31.809226 10501 sgd_solver.cpp:106] Iteration 119500, lr = 0.0015
I0522 09:13:42.346597 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_120000.caffemodel
I0522 09:13:42.400255 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_120000.solverstate
I0522 09:13:42.425640 10501 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 09:14:52.952987 10501 solver.cpp:409]     Test net output #0: accuracy = 0.886873
I0522 09:14:52.953182 10501 solver.cpp:409]     Test net output #1: loss = 0.374916 (* 1 = 0.374916 loss)
I0522 09:15:13.859458 10501 solver.cpp:237] Iteration 120000, loss = 0.984661
I0522 09:15:13.859518 10501 solver.cpp:253]     Train net output #0: loss = 0.984661 (* 1 = 0.984661 loss)
I0522 09:15:13.859532 10501 sgd_solver.cpp:106] Iteration 120000, lr = 0.0015
I0522 09:15:24.416538 10501 solver.cpp:237] Iteration 120500, loss = 0.701935
I0522 09:15:24.416708 10501 solver.cpp:253]     Train net output #0: loss = 0.701935 (* 1 = 0.701935 loss)
I0522 09:15:24.416723 10501 sgd_solver.cpp:106] Iteration 120500, lr = 0.0015
I0522 09:15:34.985026 10501 solver.cpp:237] Iteration 121000, loss = 1.31654
I0522 09:15:34.985075 10501 solver.cpp:253]     Train net output #0: loss = 1.31654 (* 1 = 1.31654 loss)
I0522 09:15:34.985091 10501 sgd_solver.cpp:106] Iteration 121000, lr = 0.0015
I0522 09:15:45.529808 10501 solver.cpp:237] Iteration 121500, loss = 1.1877
I0522 09:15:45.529842 10501 solver.cpp:253]     Train net output #0: loss = 1.1877 (* 1 = 1.1877 loss)
I0522 09:15:45.529857 10501 sgd_solver.cpp:106] Iteration 121500, lr = 0.0015
I0522 09:15:56.063360 10501 solver.cpp:237] Iteration 122000, loss = 1.38159
I0522 09:15:56.063535 10501 solver.cpp:253]     Train net output #0: loss = 1.38159 (* 1 = 1.38159 loss)
I0522 09:15:56.063549 10501 sgd_solver.cpp:106] Iteration 122000, lr = 0.0015
I0522 09:16:06.604210 10501 solver.cpp:237] Iteration 122500, loss = 1.0289
I0522 09:16:06.604246 10501 solver.cpp:253]     Train net output #0: loss = 1.0289 (* 1 = 1.0289 loss)
I0522 09:16:06.604261 10501 sgd_solver.cpp:106] Iteration 122500, lr = 0.0015
I0522 09:16:17.156741 10501 solver.cpp:237] Iteration 123000, loss = 1.29397
I0522 09:16:17.156785 10501 solver.cpp:253]     Train net output #0: loss = 1.29397 (* 1 = 1.29397 loss)
I0522 09:16:17.156806 10501 sgd_solver.cpp:106] Iteration 123000, lr = 0.0015
I0522 09:16:48.617616 10501 solver.cpp:237] Iteration 123500, loss = 1.32605
I0522 09:16:48.617802 10501 solver.cpp:253]     Train net output #0: loss = 1.32605 (* 1 = 1.32605 loss)
I0522 09:16:48.617818 10501 sgd_solver.cpp:106] Iteration 123500, lr = 0.0015
I0522 09:16:59.164352 10501 solver.cpp:237] Iteration 124000, loss = 1.06198
I0522 09:16:59.164388 10501 solver.cpp:253]     Train net output #0: loss = 1.06198 (* 1 = 1.06198 loss)
I0522 09:16:59.164404 10501 sgd_solver.cpp:106] Iteration 124000, lr = 0.0015
I0522 09:17:09.714609 10501 solver.cpp:237] Iteration 124500, loss = 1.11115
I0522 09:17:09.714656 10501 solver.cpp:253]     Train net output #0: loss = 1.11115 (* 1 = 1.11115 loss)
I0522 09:17:09.714673 10501 sgd_solver.cpp:106] Iteration 124500, lr = 0.0015
I0522 09:17:20.251920 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_125000.caffemodel
I0522 09:17:20.307257 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_125000.solverstate
I0522 09:17:20.342238 10501 solver.cpp:237] Iteration 125000, loss = 1.02099
I0522 09:17:20.342291 10501 solver.cpp:253]     Train net output #0: loss = 1.02099 (* 1 = 1.02099 loss)
I0522 09:17:20.342305 10501 sgd_solver.cpp:106] Iteration 125000, lr = 0.0015
I0522 09:17:30.901154 10501 solver.cpp:237] Iteration 125500, loss = 1.09761
I0522 09:17:30.901190 10501 solver.cpp:253]     Train net output #0: loss = 1.09761 (* 1 = 1.09761 loss)
I0522 09:17:30.901206 10501 sgd_solver.cpp:106] Iteration 125500, lr = 0.0015
I0522 09:17:41.455163 10501 solver.cpp:237] Iteration 126000, loss = 1.21423
I0522 09:17:41.455215 10501 solver.cpp:253]     Train net output #0: loss = 1.21423 (* 1 = 1.21423 loss)
I0522 09:17:41.455229 10501 sgd_solver.cpp:106] Iteration 126000, lr = 0.0015
I0522 09:17:52.007311 10501 solver.cpp:237] Iteration 126500, loss = 0.905179
I0522 09:17:52.007479 10501 solver.cpp:253]     Train net output #0: loss = 0.905179 (* 1 = 0.905179 loss)
I0522 09:17:52.007493 10501 sgd_solver.cpp:106] Iteration 126500, lr = 0.0015
I0522 09:18:23.441424 10501 solver.cpp:237] Iteration 127000, loss = 1.14674
I0522 09:18:23.441611 10501 solver.cpp:253]     Train net output #0: loss = 1.14674 (* 1 = 1.14674 loss)
I0522 09:18:23.441625 10501 sgd_solver.cpp:106] Iteration 127000, lr = 0.0015
I0522 09:18:33.988955 10501 solver.cpp:237] Iteration 127500, loss = 0.859587
I0522 09:18:33.988991 10501 solver.cpp:253]     Train net output #0: loss = 0.859587 (* 1 = 0.859587 loss)
I0522 09:18:33.989007 10501 sgd_solver.cpp:106] Iteration 127500, lr = 0.0015
I0522 09:18:44.518270 10501 solver.cpp:237] Iteration 128000, loss = 1.43807
I0522 09:18:44.518306 10501 solver.cpp:253]     Train net output #0: loss = 1.43807 (* 1 = 1.43807 loss)
I0522 09:18:44.518322 10501 sgd_solver.cpp:106] Iteration 128000, lr = 0.0015
I0522 09:18:55.085722 10501 solver.cpp:237] Iteration 128500, loss = 1.1914
I0522 09:18:55.085889 10501 solver.cpp:253]     Train net output #0: loss = 1.1914 (* 1 = 1.1914 loss)
I0522 09:18:55.085903 10501 sgd_solver.cpp:106] Iteration 128500, lr = 0.0015
I0522 09:19:05.628901 10501 solver.cpp:237] Iteration 129000, loss = 0.946944
I0522 09:19:05.628936 10501 solver.cpp:253]     Train net output #0: loss = 0.946944 (* 1 = 0.946944 loss)
I0522 09:19:05.628952 10501 sgd_solver.cpp:106] Iteration 129000, lr = 0.0015
I0522 09:19:16.165463 10501 solver.cpp:237] Iteration 129500, loss = 0.81651
I0522 09:19:16.165513 10501 solver.cpp:253]     Train net output #0: loss = 0.81651 (* 1 = 0.81651 loss)
I0522 09:19:16.165529 10501 sgd_solver.cpp:106] Iteration 129500, lr = 0.0015
I0522 09:19:26.703637 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_130000.caffemodel
I0522 09:19:26.756207 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_130000.solverstate
I0522 09:19:26.781776 10501 solver.cpp:341] Iteration 130000, Testing net (#0)
I0522 09:20:16.350898 10501 solver.cpp:409]     Test net output #0: accuracy = 0.889641
I0522 09:20:16.351094 10501 solver.cpp:409]     Test net output #1: loss = 0.345543 (* 1 = 0.345543 loss)
I0522 09:20:37.189678 10501 solver.cpp:237] Iteration 130000, loss = 0.93016
I0522 09:20:37.189738 10501 solver.cpp:253]     Train net output #0: loss = 0.93016 (* 1 = 0.93016 loss)
I0522 09:20:37.189752 10501 sgd_solver.cpp:106] Iteration 130000, lr = 0.0015
I0522 09:20:47.713032 10501 solver.cpp:237] Iteration 130500, loss = 1.40611
I0522 09:20:47.713210 10501 solver.cpp:253]     Train net output #0: loss = 1.40611 (* 1 = 1.40611 loss)
I0522 09:20:47.713227 10501 sgd_solver.cpp:106] Iteration 130500, lr = 0.0015
I0522 09:20:58.237534 10501 solver.cpp:237] Iteration 131000, loss = 1.28562
I0522 09:20:58.237577 10501 solver.cpp:253]     Train net output #0: loss = 1.28562 (* 1 = 1.28562 loss)
I0522 09:20:58.237593 10501 sgd_solver.cpp:106] Iteration 131000, lr = 0.0015
I0522 09:21:08.767359 10501 solver.cpp:237] Iteration 131500, loss = 1.16805
I0522 09:21:08.767395 10501 solver.cpp:253]     Train net output #0: loss = 1.16805 (* 1 = 1.16805 loss)
I0522 09:21:08.767412 10501 sgd_solver.cpp:106] Iteration 131500, lr = 0.0015
I0522 09:21:19.302819 10501 solver.cpp:237] Iteration 132000, loss = 0.831902
I0522 09:21:19.303001 10501 solver.cpp:253]     Train net output #0: loss = 0.831902 (* 1 = 0.831902 loss)
I0522 09:21:19.303016 10501 sgd_solver.cpp:106] Iteration 132000, lr = 0.0015
I0522 09:21:29.840359 10501 solver.cpp:237] Iteration 132500, loss = 1.01992
I0522 09:21:29.840395 10501 solver.cpp:253]     Train net output #0: loss = 1.01992 (* 1 = 1.01992 loss)
I0522 09:21:29.840411 10501 sgd_solver.cpp:106] Iteration 132500, lr = 0.0015
I0522 09:21:40.360553 10501 solver.cpp:237] Iteration 133000, loss = 1.29845
I0522 09:21:40.360589 10501 solver.cpp:253]     Train net output #0: loss = 1.29845 (* 1 = 1.29845 loss)
I0522 09:21:40.360605 10501 sgd_solver.cpp:106] Iteration 133000, lr = 0.0015
I0522 09:22:11.782084 10501 solver.cpp:237] Iteration 133500, loss = 0.947585
I0522 09:22:11.782274 10501 solver.cpp:253]     Train net output #0: loss = 0.947585 (* 1 = 0.947585 loss)
I0522 09:22:11.782290 10501 sgd_solver.cpp:106] Iteration 133500, lr = 0.0015
I0522 09:22:22.284662 10501 solver.cpp:237] Iteration 134000, loss = 0.83726
I0522 09:22:22.284698 10501 solver.cpp:253]     Train net output #0: loss = 0.83726 (* 1 = 0.83726 loss)
I0522 09:22:22.284714 10501 sgd_solver.cpp:106] Iteration 134000, lr = 0.0015
I0522 09:22:32.803617 10501 solver.cpp:237] Iteration 134500, loss = 1.32265
I0522 09:22:32.803665 10501 solver.cpp:253]     Train net output #0: loss = 1.32265 (* 1 = 1.32265 loss)
I0522 09:22:32.803683 10501 sgd_solver.cpp:106] Iteration 134500, lr = 0.0015
I0522 09:22:43.295661 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_135000.caffemodel
I0522 09:22:43.349865 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_135000.solverstate
I0522 09:22:43.382225 10501 solver.cpp:237] Iteration 135000, loss = 0.942943
I0522 09:22:43.382274 10501 solver.cpp:253]     Train net output #0: loss = 0.942943 (* 1 = 0.942943 loss)
I0522 09:22:43.382288 10501 sgd_solver.cpp:106] Iteration 135000, lr = 0.0015
I0522 09:22:53.908907 10501 solver.cpp:237] Iteration 135500, loss = 1.09278
I0522 09:22:53.908944 10501 solver.cpp:253]     Train net output #0: loss = 1.09278 (* 1 = 1.09278 loss)
I0522 09:22:53.908962 10501 sgd_solver.cpp:106] Iteration 135500, lr = 0.0015
I0522 09:23:04.437928 10501 solver.cpp:237] Iteration 136000, loss = 0.98009
I0522 09:23:04.437976 10501 solver.cpp:253]     Train net output #0: loss = 0.98009 (* 1 = 0.98009 loss)
I0522 09:23:04.437991 10501 sgd_solver.cpp:106] Iteration 136000, lr = 0.0015
I0522 09:23:14.967581 10501 solver.cpp:237] Iteration 136500, loss = 1.11331
I0522 09:23:14.967762 10501 solver.cpp:253]     Train net output #0: loss = 1.11331 (* 1 = 1.11331 loss)
I0522 09:23:14.967778 10501 sgd_solver.cpp:106] Iteration 136500, lr = 0.0015
I0522 09:23:46.359616 10501 solver.cpp:237] Iteration 137000, loss = 1.12532
I0522 09:23:46.359812 10501 solver.cpp:253]     Train net output #0: loss = 1.12532 (* 1 = 1.12532 loss)
I0522 09:23:46.359827 10501 sgd_solver.cpp:106] Iteration 137000, lr = 0.0015
I0522 09:23:56.899107 10501 solver.cpp:237] Iteration 137500, loss = 1.14467
I0522 09:23:56.899148 10501 solver.cpp:253]     Train net output #0: loss = 1.14467 (* 1 = 1.14467 loss)
I0522 09:23:56.899164 10501 sgd_solver.cpp:106] Iteration 137500, lr = 0.0015
I0522 09:24:07.427094 10501 solver.cpp:237] Iteration 138000, loss = 0.96883
I0522 09:24:07.427131 10501 solver.cpp:253]     Train net output #0: loss = 0.968831 (* 1 = 0.968831 loss)
I0522 09:24:07.427146 10501 sgd_solver.cpp:106] Iteration 138000, lr = 0.0015
I0522 09:24:17.949030 10501 solver.cpp:237] Iteration 138500, loss = 1.01421
I0522 09:24:17.949203 10501 solver.cpp:253]     Train net output #0: loss = 1.01421 (* 1 = 1.01421 loss)
I0522 09:24:17.949218 10501 sgd_solver.cpp:106] Iteration 138500, lr = 0.0015
I0522 09:24:28.465060 10501 solver.cpp:237] Iteration 139000, loss = 1.207
I0522 09:24:28.465096 10501 solver.cpp:253]     Train net output #0: loss = 1.207 (* 1 = 1.207 loss)
I0522 09:24:28.465109 10501 sgd_solver.cpp:106] Iteration 139000, lr = 0.0015
I0522 09:24:38.987905 10501 solver.cpp:237] Iteration 139500, loss = 1.18412
I0522 09:24:38.987948 10501 solver.cpp:253]     Train net output #0: loss = 1.18412 (* 1 = 1.18412 loss)
I0522 09:24:38.987962 10501 sgd_solver.cpp:106] Iteration 139500, lr = 0.0015
I0522 09:24:49.484220 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_140000.caffemodel
I0522 09:24:49.536932 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_140000.solverstate
I0522 09:24:49.562702 10501 solver.cpp:341] Iteration 140000, Testing net (#0)
I0522 09:26:00.020392 10501 solver.cpp:409]     Test net output #0: accuracy = 0.89198
I0522 09:26:00.020577 10501 solver.cpp:409]     Test net output #1: loss = 0.348292 (* 1 = 0.348292 loss)
I0522 09:26:20.879788 10501 solver.cpp:237] Iteration 140000, loss = 1.53127
I0522 09:26:20.879845 10501 solver.cpp:253]     Train net output #0: loss = 1.53127 (* 1 = 1.53127 loss)
I0522 09:26:20.879860 10501 sgd_solver.cpp:106] Iteration 140000, lr = 0.0015
I0522 09:26:31.416472 10501 solver.cpp:237] Iteration 140500, loss = 1.12142
I0522 09:26:31.416641 10501 solver.cpp:253]     Train net output #0: loss = 1.12142 (* 1 = 1.12142 loss)
I0522 09:26:31.416654 10501 sgd_solver.cpp:106] Iteration 140500, lr = 0.0015
I0522 09:26:41.959131 10501 solver.cpp:237] Iteration 141000, loss = 1.07064
I0522 09:26:41.959182 10501 solver.cpp:253]     Train net output #0: loss = 1.07064 (* 1 = 1.07064 loss)
I0522 09:26:41.959198 10501 sgd_solver.cpp:106] Iteration 141000, lr = 0.0015
I0522 09:26:52.494825 10501 solver.cpp:237] Iteration 141500, loss = 1.09539
I0522 09:26:52.494861 10501 solver.cpp:253]     Train net output #0: loss = 1.09539 (* 1 = 1.09539 loss)
I0522 09:26:52.494879 10501 sgd_solver.cpp:106] Iteration 141500, lr = 0.0015
I0522 09:27:03.042636 10501 solver.cpp:237] Iteration 142000, loss = 0.848331
I0522 09:27:03.042801 10501 solver.cpp:253]     Train net output #0: loss = 0.848331 (* 1 = 0.848331 loss)
I0522 09:27:03.042816 10501 sgd_solver.cpp:106] Iteration 142000, lr = 0.0015
I0522 09:27:13.577793 10501 solver.cpp:237] Iteration 142500, loss = 1.17446
I0522 09:27:13.577844 10501 solver.cpp:253]     Train net output #0: loss = 1.17446 (* 1 = 1.17446 loss)
I0522 09:27:13.577859 10501 sgd_solver.cpp:106] Iteration 142500, lr = 0.0015
I0522 09:27:24.107237 10501 solver.cpp:237] Iteration 143000, loss = 1.05953
I0522 09:27:24.107273 10501 solver.cpp:253]     Train net output #0: loss = 1.05953 (* 1 = 1.05953 loss)
I0522 09:27:24.107290 10501 sgd_solver.cpp:106] Iteration 143000, lr = 0.0015
I0522 09:27:55.501055 10501 solver.cpp:237] Iteration 143500, loss = 1.10386
I0522 09:27:55.501251 10501 solver.cpp:253]     Train net output #0: loss = 1.10386 (* 1 = 1.10386 loss)
I0522 09:27:55.501267 10501 sgd_solver.cpp:106] Iteration 143500, lr = 0.0015
I0522 09:28:06.049238 10501 solver.cpp:237] Iteration 144000, loss = 1.10986
I0522 09:28:06.049290 10501 solver.cpp:253]     Train net output #0: loss = 1.10986 (* 1 = 1.10986 loss)
I0522 09:28:06.049305 10501 sgd_solver.cpp:106] Iteration 144000, lr = 0.0015
I0522 09:28:16.592053 10501 solver.cpp:237] Iteration 144500, loss = 1.34068
I0522 09:28:16.592089 10501 solver.cpp:253]     Train net output #0: loss = 1.34068 (* 1 = 1.34068 loss)
I0522 09:28:16.592105 10501 sgd_solver.cpp:106] Iteration 144500, lr = 0.0015
I0522 09:28:27.093098 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_145000.caffemodel
I0522 09:28:27.152804 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_145000.solverstate
I0522 09:28:27.186962 10501 solver.cpp:237] Iteration 145000, loss = 1.73684
I0522 09:28:27.187012 10501 solver.cpp:253]     Train net output #0: loss = 1.73684 (* 1 = 1.73684 loss)
I0522 09:28:27.187032 10501 sgd_solver.cpp:106] Iteration 145000, lr = 0.0015
I0522 09:28:37.731183 10501 solver.cpp:237] Iteration 145500, loss = 1.49956
I0522 09:28:37.731218 10501 solver.cpp:253]     Train net output #0: loss = 1.49956 (* 1 = 1.49956 loss)
I0522 09:28:37.731231 10501 sgd_solver.cpp:106] Iteration 145500, lr = 0.0015
I0522 09:28:48.271265 10501 solver.cpp:237] Iteration 146000, loss = 1.52689
I0522 09:28:48.271314 10501 solver.cpp:253]     Train net output #0: loss = 1.52689 (* 1 = 1.52689 loss)
I0522 09:28:48.271330 10501 sgd_solver.cpp:106] Iteration 146000, lr = 0.0015
I0522 09:28:58.806565 10501 solver.cpp:237] Iteration 146500, loss = 1.02102
I0522 09:28:58.806735 10501 solver.cpp:253]     Train net output #0: loss = 1.02102 (* 1 = 1.02102 loss)
I0522 09:28:58.806749 10501 sgd_solver.cpp:106] Iteration 146500, lr = 0.0015
I0522 09:29:30.186784 10501 solver.cpp:237] Iteration 147000, loss = 1.16614
I0522 09:29:30.186972 10501 solver.cpp:253]     Train net output #0: loss = 1.16614 (* 1 = 1.16614 loss)
I0522 09:29:30.186988 10501 sgd_solver.cpp:106] Iteration 147000, lr = 0.0015
I0522 09:29:40.719578 10501 solver.cpp:237] Iteration 147500, loss = 1.25848
I0522 09:29:40.719621 10501 solver.cpp:253]     Train net output #0: loss = 1.25848 (* 1 = 1.25848 loss)
I0522 09:29:40.719636 10501 sgd_solver.cpp:106] Iteration 147500, lr = 0.0015
I0522 09:29:51.243671 10501 solver.cpp:237] Iteration 148000, loss = 1.34334
I0522 09:29:51.243706 10501 solver.cpp:253]     Train net output #0: loss = 1.34334 (* 1 = 1.34334 loss)
I0522 09:29:51.243723 10501 sgd_solver.cpp:106] Iteration 148000, lr = 0.0015
I0522 09:30:01.781255 10501 solver.cpp:237] Iteration 148500, loss = 1.42603
I0522 09:30:01.781426 10501 solver.cpp:253]     Train net output #0: loss = 1.42603 (* 1 = 1.42603 loss)
I0522 09:30:01.781440 10501 sgd_solver.cpp:106] Iteration 148500, lr = 0.0015
I0522 09:30:12.337618 10501 solver.cpp:237] Iteration 149000, loss = 1.54538
I0522 09:30:12.337654 10501 solver.cpp:253]     Train net output #0: loss = 1.54538 (* 1 = 1.54538 loss)
I0522 09:30:12.337671 10501 sgd_solver.cpp:106] Iteration 149000, lr = 0.0015
I0522 09:30:22.886854 10501 solver.cpp:237] Iteration 149500, loss = 1.59098
I0522 09:30:22.886890 10501 solver.cpp:253]     Train net output #0: loss = 1.59098 (* 1 = 1.59098 loss)
I0522 09:30:22.886906 10501 sgd_solver.cpp:106] Iteration 149500, lr = 0.0015
I0522 09:30:33.402971 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_150000.caffemodel
I0522 09:30:33.458166 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_150000.solverstate
I0522 09:30:33.486423 10501 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 09:31:22.738528 10501 solver.cpp:409]     Test net output #0: accuracy = 0.888499
I0522 09:31:22.738718 10501 solver.cpp:409]     Test net output #1: loss = 0.355857 (* 1 = 0.355857 loss)
I0522 09:31:43.629709 10501 solver.cpp:237] Iteration 150000, loss = 0.877169
I0522 09:31:43.629761 10501 solver.cpp:253]     Train net output #0: loss = 0.877169 (* 1 = 0.877169 loss)
I0522 09:31:43.629777 10501 sgd_solver.cpp:106] Iteration 150000, lr = 0.0015
I0522 09:31:54.116930 10501 solver.cpp:237] Iteration 150500, loss = 1.10253
I0522 09:31:54.117102 10501 solver.cpp:253]     Train net output #0: loss = 1.10253 (* 1 = 1.10253 loss)
I0522 09:31:54.117117 10501 sgd_solver.cpp:106] Iteration 150500, lr = 0.0015
I0522 09:32:04.621263 10501 solver.cpp:237] Iteration 151000, loss = 1.3654
I0522 09:32:04.621299 10501 solver.cpp:253]     Train net output #0: loss = 1.3654 (* 1 = 1.3654 loss)
I0522 09:32:04.621311 10501 sgd_solver.cpp:106] Iteration 151000, lr = 0.0015
I0522 09:32:15.126677 10501 solver.cpp:237] Iteration 151500, loss = 1.00152
I0522 09:32:15.126732 10501 solver.cpp:253]     Train net output #0: loss = 1.00152 (* 1 = 1.00152 loss)
I0522 09:32:15.126747 10501 sgd_solver.cpp:106] Iteration 151500, lr = 0.0015
I0522 09:32:25.620390 10501 solver.cpp:237] Iteration 152000, loss = 0.937215
I0522 09:32:25.620568 10501 solver.cpp:253]     Train net output #0: loss = 0.937215 (* 1 = 0.937215 loss)
I0522 09:32:25.620584 10501 sgd_solver.cpp:106] Iteration 152000, lr = 0.0015
I0522 09:32:36.105347 10501 solver.cpp:237] Iteration 152500, loss = 0.90447
I0522 09:32:36.105401 10501 solver.cpp:253]     Train net output #0: loss = 0.90447 (* 1 = 0.90447 loss)
I0522 09:32:36.105414 10501 sgd_solver.cpp:106] Iteration 152500, lr = 0.0015
I0522 09:32:46.599102 10501 solver.cpp:237] Iteration 153000, loss = 1.3109
I0522 09:32:46.599139 10501 solver.cpp:253]     Train net output #0: loss = 1.3109 (* 1 = 1.3109 loss)
I0522 09:32:46.599155 10501 sgd_solver.cpp:106] Iteration 153000, lr = 0.0015
I0522 09:33:17.944823 10501 solver.cpp:237] Iteration 153500, loss = 1.297
I0522 09:33:17.945014 10501 solver.cpp:253]     Train net output #0: loss = 1.297 (* 1 = 1.297 loss)
I0522 09:33:17.945030 10501 sgd_solver.cpp:106] Iteration 153500, lr = 0.0015
I0522 09:33:28.446467 10501 solver.cpp:237] Iteration 154000, loss = 0.95217
I0522 09:33:28.446517 10501 solver.cpp:253]     Train net output #0: loss = 0.95217 (* 1 = 0.95217 loss)
I0522 09:33:28.446532 10501 sgd_solver.cpp:106] Iteration 154000, lr = 0.0015
I0522 09:33:38.940479 10501 solver.cpp:237] Iteration 154500, loss = 1.47146
I0522 09:33:38.940513 10501 solver.cpp:253]     Train net output #0: loss = 1.47146 (* 1 = 1.47146 loss)
I0522 09:33:38.940531 10501 sgd_solver.cpp:106] Iteration 154500, lr = 0.0015
I0522 09:33:49.422291 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_155000.caffemodel
I0522 09:33:49.474367 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_155000.solverstate
I0522 09:33:49.506243 10501 solver.cpp:237] Iteration 155000, loss = 1.08992
I0522 09:33:49.506289 10501 solver.cpp:253]     Train net output #0: loss = 1.08992 (* 1 = 1.08992 loss)
I0522 09:33:49.506309 10501 sgd_solver.cpp:106] Iteration 155000, lr = 0.0015
I0522 09:34:00.002399 10501 solver.cpp:237] Iteration 155500, loss = 1.29296
I0522 09:34:00.002436 10501 solver.cpp:253]     Train net output #0: loss = 1.29297 (* 1 = 1.29297 loss)
I0522 09:34:00.002452 10501 sgd_solver.cpp:106] Iteration 155500, lr = 0.0015
I0522 09:34:10.490236 10501 solver.cpp:237] Iteration 156000, loss = 1.01707
I0522 09:34:10.490272 10501 solver.cpp:253]     Train net output #0: loss = 1.01707 (* 1 = 1.01707 loss)
I0522 09:34:10.490285 10501 sgd_solver.cpp:106] Iteration 156000, lr = 0.0015
I0522 09:34:20.987406 10501 solver.cpp:237] Iteration 156500, loss = 0.802452
I0522 09:34:20.987601 10501 solver.cpp:253]     Train net output #0: loss = 0.802452 (* 1 = 0.802452 loss)
I0522 09:34:20.987615 10501 sgd_solver.cpp:106] Iteration 156500, lr = 0.0015
I0522 09:34:52.341747 10501 solver.cpp:237] Iteration 157000, loss = 1.19324
I0522 09:34:52.341943 10501 solver.cpp:253]     Train net output #0: loss = 1.19324 (* 1 = 1.19324 loss)
I0522 09:34:52.341958 10501 sgd_solver.cpp:106] Iteration 157000, lr = 0.0015
I0522 09:35:02.837258 10501 solver.cpp:237] Iteration 157500, loss = 0.988109
I0522 09:35:02.837311 10501 solver.cpp:253]     Train net output #0: loss = 0.98811 (* 1 = 0.98811 loss)
I0522 09:35:02.837326 10501 sgd_solver.cpp:106] Iteration 157500, lr = 0.0015
I0522 09:35:13.333355 10501 solver.cpp:237] Iteration 158000, loss = 1.28102
I0522 09:35:13.333391 10501 solver.cpp:253]     Train net output #0: loss = 1.28102 (* 1 = 1.28102 loss)
I0522 09:35:13.333408 10501 sgd_solver.cpp:106] Iteration 158000, lr = 0.0015
I0522 09:35:23.833601 10501 solver.cpp:237] Iteration 158500, loss = 1.25163
I0522 09:35:23.833770 10501 solver.cpp:253]     Train net output #0: loss = 1.25163 (* 1 = 1.25163 loss)
I0522 09:35:23.833784 10501 sgd_solver.cpp:106] Iteration 158500, lr = 0.0015
I0522 09:35:34.324853 10501 solver.cpp:237] Iteration 159000, loss = 1.21821
I0522 09:35:34.324903 10501 solver.cpp:253]     Train net output #0: loss = 1.21821 (* 1 = 1.21821 loss)
I0522 09:35:34.324919 10501 sgd_solver.cpp:106] Iteration 159000, lr = 0.0015
I0522 09:35:44.828316 10501 solver.cpp:237] Iteration 159500, loss = 1.36286
I0522 09:35:44.828352 10501 solver.cpp:253]     Train net output #0: loss = 1.36286 (* 1 = 1.36286 loss)
I0522 09:35:44.828368 10501 sgd_solver.cpp:106] Iteration 159500, lr = 0.0015
I0522 09:35:55.333323 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_160000.caffemodel
I0522 09:35:55.385555 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_160000.solverstate
I0522 09:35:55.411377 10501 solver.cpp:341] Iteration 160000, Testing net (#0)
I0522 09:37:05.954689 10501 solver.cpp:409]     Test net output #0: accuracy = 0.892846
I0522 09:37:05.954884 10501 solver.cpp:409]     Test net output #1: loss = 0.33705 (* 1 = 0.33705 loss)
I0522 09:37:26.847525 10501 solver.cpp:237] Iteration 160000, loss = 1.15419
I0522 09:37:26.847580 10501 solver.cpp:253]     Train net output #0: loss = 1.15419 (* 1 = 1.15419 loss)
I0522 09:37:26.847594 10501 sgd_solver.cpp:106] Iteration 160000, lr = 0.0015
I0522 09:37:37.381603 10501 solver.cpp:237] Iteration 160500, loss = 1.24219
I0522 09:37:37.381790 10501 solver.cpp:253]     Train net output #0: loss = 1.24219 (* 1 = 1.24219 loss)
I0522 09:37:37.381804 10501 sgd_solver.cpp:106] Iteration 160500, lr = 0.0015
I0522 09:37:47.939008 10501 solver.cpp:237] Iteration 161000, loss = 1.23743
I0522 09:37:47.939043 10501 solver.cpp:253]     Train net output #0: loss = 1.23743 (* 1 = 1.23743 loss)
I0522 09:37:47.939060 10501 sgd_solver.cpp:106] Iteration 161000, lr = 0.0015
I0522 09:37:58.487138 10501 solver.cpp:237] Iteration 161500, loss = 1.2462
I0522 09:37:58.487187 10501 solver.cpp:253]     Train net output #0: loss = 1.2462 (* 1 = 1.2462 loss)
I0522 09:37:58.487203 10501 sgd_solver.cpp:106] Iteration 161500, lr = 0.0015
I0522 09:38:09.030287 10501 solver.cpp:237] Iteration 162000, loss = 1.18134
I0522 09:38:09.030465 10501 solver.cpp:253]     Train net output #0: loss = 1.18134 (* 1 = 1.18134 loss)
I0522 09:38:09.030479 10501 sgd_solver.cpp:106] Iteration 162000, lr = 0.0015
I0522 09:38:19.582901 10501 solver.cpp:237] Iteration 162500, loss = 1.18146
I0522 09:38:19.582937 10501 solver.cpp:253]     Train net output #0: loss = 1.18146 (* 1 = 1.18146 loss)
I0522 09:38:19.582952 10501 sgd_solver.cpp:106] Iteration 162500, lr = 0.0015
I0522 09:38:30.120640 10501 solver.cpp:237] Iteration 163000, loss = 1.13736
I0522 09:38:30.120692 10501 solver.cpp:253]     Train net output #0: loss = 1.13736 (* 1 = 1.13736 loss)
I0522 09:38:30.120707 10501 sgd_solver.cpp:106] Iteration 163000, lr = 0.0015
I0522 09:39:01.581643 10501 solver.cpp:237] Iteration 163500, loss = 1.24437
I0522 09:39:01.581841 10501 solver.cpp:253]     Train net output #0: loss = 1.24437 (* 1 = 1.24437 loss)
I0522 09:39:01.581858 10501 sgd_solver.cpp:106] Iteration 163500, lr = 0.0015
I0522 09:39:12.123877 10501 solver.cpp:237] Iteration 164000, loss = 0.922967
I0522 09:39:12.123930 10501 solver.cpp:253]     Train net output #0: loss = 0.922968 (* 1 = 0.922968 loss)
I0522 09:39:12.123946 10501 sgd_solver.cpp:106] Iteration 164000, lr = 0.0015
I0522 09:39:22.671272 10501 solver.cpp:237] Iteration 164500, loss = 1.07042
I0522 09:39:22.671308 10501 solver.cpp:253]     Train net output #0: loss = 1.07042 (* 1 = 1.07042 loss)
I0522 09:39:22.671324 10501 sgd_solver.cpp:106] Iteration 164500, lr = 0.0015
I0522 09:39:33.184897 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_165000.caffemodel
I0522 09:39:33.237936 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_165000.solverstate
I0522 09:39:33.270139 10501 solver.cpp:237] Iteration 165000, loss = 1.32513
I0522 09:39:33.270186 10501 solver.cpp:253]     Train net output #0: loss = 1.32513 (* 1 = 1.32513 loss)
I0522 09:39:33.270200 10501 sgd_solver.cpp:106] Iteration 165000, lr = 0.0015
I0522 09:39:43.815485 10501 solver.cpp:237] Iteration 165500, loss = 0.778706
I0522 09:39:43.815539 10501 solver.cpp:253]     Train net output #0: loss = 0.778707 (* 1 = 0.778707 loss)
I0522 09:39:43.815554 10501 sgd_solver.cpp:106] Iteration 165500, lr = 0.0015
I0522 09:39:54.369212 10501 solver.cpp:237] Iteration 166000, loss = 1.29509
I0522 09:39:54.369248 10501 solver.cpp:253]     Train net output #0: loss = 1.29509 (* 1 = 1.29509 loss)
I0522 09:39:54.369264 10501 sgd_solver.cpp:106] Iteration 166000, lr = 0.0015
I0522 09:40:04.934278 10501 solver.cpp:237] Iteration 166500, loss = 1.18706
I0522 09:40:04.934463 10501 solver.cpp:253]     Train net output #0: loss = 1.18706 (* 1 = 1.18706 loss)
I0522 09:40:04.934478 10501 sgd_solver.cpp:106] Iteration 166500, lr = 0.0015
I0522 09:40:36.362467 10501 solver.cpp:237] Iteration 167000, loss = 1.13503
I0522 09:40:36.362663 10501 solver.cpp:253]     Train net output #0: loss = 1.13503 (* 1 = 1.13503 loss)
I0522 09:40:36.362679 10501 sgd_solver.cpp:106] Iteration 167000, lr = 0.0015
I0522 09:40:46.920032 10501 solver.cpp:237] Iteration 167500, loss = 1.28405
I0522 09:40:46.920068 10501 solver.cpp:253]     Train net output #0: loss = 1.28405 (* 1 = 1.28405 loss)
I0522 09:40:46.920084 10501 sgd_solver.cpp:106] Iteration 167500, lr = 0.0015
I0522 09:40:57.471853 10501 solver.cpp:237] Iteration 168000, loss = 1.3237
I0522 09:40:57.471895 10501 solver.cpp:253]     Train net output #0: loss = 1.3237 (* 1 = 1.3237 loss)
I0522 09:40:57.471912 10501 sgd_solver.cpp:106] Iteration 168000, lr = 0.0015
I0522 09:41:08.011023 10501 solver.cpp:237] Iteration 168500, loss = 1.03398
I0522 09:41:08.011188 10501 solver.cpp:253]     Train net output #0: loss = 1.03398 (* 1 = 1.03398 loss)
I0522 09:41:08.011201 10501 sgd_solver.cpp:106] Iteration 168500, lr = 0.0015
I0522 09:41:18.563026 10501 solver.cpp:237] Iteration 169000, loss = 1.48079
I0522 09:41:18.563072 10501 solver.cpp:253]     Train net output #0: loss = 1.48079 (* 1 = 1.48079 loss)
I0522 09:41:18.563088 10501 sgd_solver.cpp:106] Iteration 169000, lr = 0.0015
I0522 09:41:29.123708 10501 solver.cpp:237] Iteration 169500, loss = 0.949826
I0522 09:41:29.123744 10501 solver.cpp:253]     Train net output #0: loss = 0.949827 (* 1 = 0.949827 loss)
I0522 09:41:29.123759 10501 sgd_solver.cpp:106] Iteration 169500, lr = 0.0015
I0522 09:41:39.654820 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_170000.caffemodel
I0522 09:41:39.707597 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_170000.solverstate
I0522 09:41:39.733391 10501 solver.cpp:341] Iteration 170000, Testing net (#0)
I0522 09:42:29.342986 10501 solver.cpp:409]     Test net output #0: accuracy = 0.893012
I0522 09:42:29.343181 10501 solver.cpp:409]     Test net output #1: loss = 0.361398 (* 1 = 0.361398 loss)
I0522 09:42:50.270480 10501 solver.cpp:237] Iteration 170000, loss = 0.99062
I0522 09:42:50.270539 10501 solver.cpp:253]     Train net output #0: loss = 0.990621 (* 1 = 0.990621 loss)
I0522 09:42:50.270555 10501 sgd_solver.cpp:106] Iteration 170000, lr = 0.0015
I0522 09:43:00.806272 10501 solver.cpp:237] Iteration 170500, loss = 0.928059
I0522 09:43:00.806468 10501 solver.cpp:253]     Train net output #0: loss = 0.92806 (* 1 = 0.92806 loss)
I0522 09:43:00.806484 10501 sgd_solver.cpp:106] Iteration 170500, lr = 0.0015
I0522 09:43:11.335454 10501 solver.cpp:237] Iteration 171000, loss = 1.32603
I0522 09:43:11.335490 10501 solver.cpp:253]     Train net output #0: loss = 1.32603 (* 1 = 1.32603 loss)
I0522 09:43:11.335507 10501 sgd_solver.cpp:106] Iteration 171000, lr = 0.0015
I0522 09:43:21.850584 10501 solver.cpp:237] Iteration 171500, loss = 1.23632
I0522 09:43:21.850632 10501 solver.cpp:253]     Train net output #0: loss = 1.23632 (* 1 = 1.23632 loss)
I0522 09:43:21.850649 10501 sgd_solver.cpp:106] Iteration 171500, lr = 0.0015
I0522 09:43:32.372752 10501 solver.cpp:237] Iteration 172000, loss = 1.32716
I0522 09:43:32.372922 10501 solver.cpp:253]     Train net output #0: loss = 1.32716 (* 1 = 1.32716 loss)
I0522 09:43:32.372936 10501 sgd_solver.cpp:106] Iteration 172000, lr = 0.0015
I0522 09:43:42.894153 10501 solver.cpp:237] Iteration 172500, loss = 1.19646
I0522 09:43:42.894189 10501 solver.cpp:253]     Train net output #0: loss = 1.19646 (* 1 = 1.19646 loss)
I0522 09:43:42.894207 10501 sgd_solver.cpp:106] Iteration 172500, lr = 0.0015
I0522 09:43:53.414495 10501 solver.cpp:237] Iteration 173000, loss = 1.37852
I0522 09:43:53.414541 10501 solver.cpp:253]     Train net output #0: loss = 1.37852 (* 1 = 1.37852 loss)
I0522 09:43:53.414557 10501 sgd_solver.cpp:106] Iteration 173000, lr = 0.0015
I0522 09:44:24.824121 10501 solver.cpp:237] Iteration 173500, loss = 1.21162
I0522 09:44:24.824314 10501 solver.cpp:253]     Train net output #0: loss = 1.21163 (* 1 = 1.21163 loss)
I0522 09:44:24.824331 10501 sgd_solver.cpp:106] Iteration 173500, lr = 0.0015
I0522 09:44:35.351166 10501 solver.cpp:237] Iteration 174000, loss = 1.30032
I0522 09:44:35.351202 10501 solver.cpp:253]     Train net output #0: loss = 1.30032 (* 1 = 1.30032 loss)
I0522 09:44:35.351214 10501 sgd_solver.cpp:106] Iteration 174000, lr = 0.0015
I0522 09:44:45.878301 10501 solver.cpp:237] Iteration 174500, loss = 1.251
I0522 09:44:45.878343 10501 solver.cpp:253]     Train net output #0: loss = 1.251 (* 1 = 1.251 loss)
I0522 09:44:45.878360 10501 sgd_solver.cpp:106] Iteration 174500, lr = 0.0015
I0522 09:44:56.369885 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_175000.caffemodel
I0522 09:44:56.424662 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_175000.solverstate
I0522 09:44:56.458792 10501 solver.cpp:237] Iteration 175000, loss = 1.25037
I0522 09:44:56.458847 10501 solver.cpp:253]     Train net output #0: loss = 1.25037 (* 1 = 1.25037 loss)
I0522 09:44:56.458865 10501 sgd_solver.cpp:106] Iteration 175000, lr = 0.0015
I0522 09:45:06.955796 10501 solver.cpp:237] Iteration 175500, loss = 1.32465
I0522 09:45:06.955842 10501 solver.cpp:253]     Train net output #0: loss = 1.32465 (* 1 = 1.32465 loss)
I0522 09:45:06.955859 10501 sgd_solver.cpp:106] Iteration 175500, lr = 0.0015
I0522 09:45:17.472167 10501 solver.cpp:237] Iteration 176000, loss = 1.40563
I0522 09:45:17.472203 10501 solver.cpp:253]     Train net output #0: loss = 1.40563 (* 1 = 1.40563 loss)
I0522 09:45:17.472220 10501 sgd_solver.cpp:106] Iteration 176000, lr = 0.0015
I0522 09:45:27.997510 10501 solver.cpp:237] Iteration 176500, loss = 1.27985
I0522 09:45:27.997699 10501 solver.cpp:253]     Train net output #0: loss = 1.27986 (* 1 = 1.27986 loss)
I0522 09:45:27.997714 10501 sgd_solver.cpp:106] Iteration 176500, lr = 0.0015
I0522 09:45:59.453150 10501 solver.cpp:237] Iteration 177000, loss = 1.09893
I0522 09:45:59.453351 10501 solver.cpp:253]     Train net output #0: loss = 1.09893 (* 1 = 1.09893 loss)
I0522 09:45:59.453366 10501 sgd_solver.cpp:106] Iteration 177000, lr = 0.0015
I0522 09:46:09.976498 10501 solver.cpp:237] Iteration 177500, loss = 1.1672
I0522 09:46:09.976536 10501 solver.cpp:253]     Train net output #0: loss = 1.1672 (* 1 = 1.1672 loss)
I0522 09:46:09.976552 10501 sgd_solver.cpp:106] Iteration 177500, lr = 0.0015
I0522 09:46:20.504535 10501 solver.cpp:237] Iteration 178000, loss = 1.37732
I0522 09:46:20.504581 10501 solver.cpp:253]     Train net output #0: loss = 1.37732 (* 1 = 1.37732 loss)
I0522 09:46:20.504597 10501 sgd_solver.cpp:106] Iteration 178000, lr = 0.0015
I0522 09:46:31.023669 10501 solver.cpp:237] Iteration 178500, loss = 1.32708
I0522 09:46:31.023840 10501 solver.cpp:253]     Train net output #0: loss = 1.32708 (* 1 = 1.32708 loss)
I0522 09:46:31.023855 10501 sgd_solver.cpp:106] Iteration 178500, lr = 0.0015
I0522 09:46:41.537102 10501 solver.cpp:237] Iteration 179000, loss = 1.02482
I0522 09:46:41.537138 10501 solver.cpp:253]     Train net output #0: loss = 1.02482 (* 1 = 1.02482 loss)
I0522 09:46:41.537154 10501 sgd_solver.cpp:106] Iteration 179000, lr = 0.0015
I0522 09:46:52.059608 10501 solver.cpp:237] Iteration 179500, loss = 0.931036
I0522 09:46:52.059660 10501 solver.cpp:253]     Train net output #0: loss = 0.931037 (* 1 = 0.931037 loss)
I0522 09:46:52.059675 10501 sgd_solver.cpp:106] Iteration 179500, lr = 0.0015
I0522 09:47:02.561012 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_180000.caffemodel
I0522 09:47:02.619446 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_180000.solverstate
I0522 09:47:02.650614 10501 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 09:48:13.270486 10501 solver.cpp:409]     Test net output #0: accuracy = 0.895952
I0522 09:48:13.270683 10501 solver.cpp:409]     Test net output #1: loss = 0.334493 (* 1 = 0.334493 loss)
I0522 09:48:34.189477 10501 solver.cpp:237] Iteration 180000, loss = 1.09163
I0522 09:48:34.189535 10501 solver.cpp:253]     Train net output #0: loss = 1.09163 (* 1 = 1.09163 loss)
I0522 09:48:34.189550 10501 sgd_solver.cpp:106] Iteration 180000, lr = 0.0015
I0522 09:48:44.713002 10501 solver.cpp:237] Iteration 180500, loss = 0.94409
I0522 09:48:44.713182 10501 solver.cpp:253]     Train net output #0: loss = 0.944091 (* 1 = 0.944091 loss)
I0522 09:48:44.713197 10501 sgd_solver.cpp:106] Iteration 180500, lr = 0.0015
I0522 09:48:55.236789 10501 solver.cpp:237] Iteration 181000, loss = 1.81943
I0522 09:48:55.236841 10501 solver.cpp:253]     Train net output #0: loss = 1.81943 (* 1 = 1.81943 loss)
I0522 09:48:55.236855 10501 sgd_solver.cpp:106] Iteration 181000, lr = 0.0015
I0522 09:49:05.754809 10501 solver.cpp:237] Iteration 181500, loss = 0.988512
I0522 09:49:05.754847 10501 solver.cpp:253]     Train net output #0: loss = 0.988513 (* 1 = 0.988513 loss)
I0522 09:49:05.754863 10501 sgd_solver.cpp:106] Iteration 181500, lr = 0.0015
I0522 09:49:16.264727 10501 solver.cpp:237] Iteration 182000, loss = 0.947159
I0522 09:49:16.264932 10501 solver.cpp:253]     Train net output #0: loss = 0.94716 (* 1 = 0.94716 loss)
I0522 09:49:16.264947 10501 sgd_solver.cpp:106] Iteration 182000, lr = 0.0015
I0522 09:49:26.786154 10501 solver.cpp:237] Iteration 182500, loss = 0.819509
I0522 09:49:26.786190 10501 solver.cpp:253]     Train net output #0: loss = 0.81951 (* 1 = 0.81951 loss)
I0522 09:49:26.786206 10501 sgd_solver.cpp:106] Iteration 182500, lr = 0.0015
I0522 09:49:37.305321 10501 solver.cpp:237] Iteration 183000, loss = 1.45127
I0522 09:49:37.305368 10501 solver.cpp:253]     Train net output #0: loss = 1.45127 (* 1 = 1.45127 loss)
I0522 09:49:37.305384 10501 sgd_solver.cpp:106] Iteration 183000, lr = 0.0015
I0522 09:50:08.702786 10501 solver.cpp:237] Iteration 183500, loss = 1.39676
I0522 09:50:08.702989 10501 solver.cpp:253]     Train net output #0: loss = 1.39676 (* 1 = 1.39676 loss)
I0522 09:50:08.703006 10501 sgd_solver.cpp:106] Iteration 183500, lr = 0.0015
I0522 09:50:19.209457 10501 solver.cpp:237] Iteration 184000, loss = 1.3683
I0522 09:50:19.209494 10501 solver.cpp:253]     Train net output #0: loss = 1.3683 (* 1 = 1.3683 loss)
I0522 09:50:19.209511 10501 sgd_solver.cpp:106] Iteration 184000, lr = 0.0015
I0522 09:50:29.726891 10501 solver.cpp:237] Iteration 184500, loss = 1.11514
I0522 09:50:29.726943 10501 solver.cpp:253]     Train net output #0: loss = 1.11515 (* 1 = 1.11515 loss)
I0522 09:50:29.726958 10501 sgd_solver.cpp:106] Iteration 184500, lr = 0.0015
I0522 09:50:40.233191 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_185000.caffemodel
I0522 09:50:40.286403 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_185000.solverstate
I0522 09:50:40.318922 10501 solver.cpp:237] Iteration 185000, loss = 1.32262
I0522 09:50:40.318966 10501 solver.cpp:253]     Train net output #0: loss = 1.32263 (* 1 = 1.32263 loss)
I0522 09:50:40.318984 10501 sgd_solver.cpp:106] Iteration 185000, lr = 0.0015
I0522 09:50:50.831914 10501 solver.cpp:237] Iteration 185500, loss = 1.06753
I0522 09:50:50.831950 10501 solver.cpp:253]     Train net output #0: loss = 1.06754 (* 1 = 1.06754 loss)
I0522 09:50:50.831966 10501 sgd_solver.cpp:106] Iteration 185500, lr = 0.0015
I0522 09:51:01.342341 10501 solver.cpp:237] Iteration 186000, loss = 0.975354
I0522 09:51:01.342394 10501 solver.cpp:253]     Train net output #0: loss = 0.975355 (* 1 = 0.975355 loss)
I0522 09:51:01.342409 10501 sgd_solver.cpp:106] Iteration 186000, lr = 0.0015
I0522 09:51:11.856088 10501 solver.cpp:237] Iteration 186500, loss = 0.951569
I0522 09:51:11.856274 10501 solver.cpp:253]     Train net output #0: loss = 0.95157 (* 1 = 0.95157 loss)
I0522 09:51:11.856290 10501 sgd_solver.cpp:106] Iteration 186500, lr = 0.0015
I0522 09:51:43.279211 10501 solver.cpp:237] Iteration 187000, loss = 1.28893
I0522 09:51:43.279410 10501 solver.cpp:253]     Train net output #0: loss = 1.28893 (* 1 = 1.28893 loss)
I0522 09:51:43.279424 10501 sgd_solver.cpp:106] Iteration 187000, lr = 0.0015
I0522 09:51:53.806607 10501 solver.cpp:237] Iteration 187500, loss = 1.28792
I0522 09:51:53.806643 10501 solver.cpp:253]     Train net output #0: loss = 1.28793 (* 1 = 1.28793 loss)
I0522 09:51:53.806659 10501 sgd_solver.cpp:106] Iteration 187500, lr = 0.0015
I0522 09:52:04.333174 10501 solver.cpp:237] Iteration 188000, loss = 1.11517
I0522 09:52:04.333210 10501 solver.cpp:253]     Train net output #0: loss = 1.11517 (* 1 = 1.11517 loss)
I0522 09:52:04.333226 10501 sgd_solver.cpp:106] Iteration 188000, lr = 0.0015
I0522 09:52:14.862862 10501 solver.cpp:237] Iteration 188500, loss = 1.17291
I0522 09:52:14.863052 10501 solver.cpp:253]     Train net output #0: loss = 1.17291 (* 1 = 1.17291 loss)
I0522 09:52:14.863066 10501 sgd_solver.cpp:106] Iteration 188500, lr = 0.0015
I0522 09:52:25.377765 10501 solver.cpp:237] Iteration 189000, loss = 1.00464
I0522 09:52:25.377801 10501 solver.cpp:253]     Train net output #0: loss = 1.00464 (* 1 = 1.00464 loss)
I0522 09:52:25.377817 10501 sgd_solver.cpp:106] Iteration 189000, lr = 0.0015
I0522 09:52:35.890866 10501 solver.cpp:237] Iteration 189500, loss = 1.00203
I0522 09:52:35.890913 10501 solver.cpp:253]     Train net output #0: loss = 1.00203 (* 1 = 1.00203 loss)
I0522 09:52:35.890928 10501 sgd_solver.cpp:106] Iteration 189500, lr = 0.0015
I0522 09:52:46.399734 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_190000.caffemodel
I0522 09:52:46.452417 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_190000.solverstate
I0522 09:52:46.478027 10501 solver.cpp:341] Iteration 190000, Testing net (#0)
I0522 09:53:35.824687 10501 solver.cpp:409]     Test net output #0: accuracy = 0.894527
I0522 09:53:35.824894 10501 solver.cpp:409]     Test net output #1: loss = 0.328069 (* 1 = 0.328069 loss)
I0522 09:53:56.684041 10501 solver.cpp:237] Iteration 190000, loss = 1.67833
I0522 09:53:56.684098 10501 solver.cpp:253]     Train net output #0: loss = 1.67833 (* 1 = 1.67833 loss)
I0522 09:53:56.684113 10501 sgd_solver.cpp:106] Iteration 190000, lr = 0.0015
I0522 09:54:07.257376 10501 solver.cpp:237] Iteration 190500, loss = 0.91513
I0522 09:54:07.257558 10501 solver.cpp:253]     Train net output #0: loss = 0.915131 (* 1 = 0.915131 loss)
I0522 09:54:07.257573 10501 sgd_solver.cpp:106] Iteration 190500, lr = 0.0015
I0522 09:54:17.849527 10501 solver.cpp:237] Iteration 191000, loss = 0.915772
I0522 09:54:17.849581 10501 solver.cpp:253]     Train net output #0: loss = 0.915773 (* 1 = 0.915773 loss)
I0522 09:54:17.849594 10501 sgd_solver.cpp:106] Iteration 191000, lr = 0.0015
I0522 09:54:28.440515 10501 solver.cpp:237] Iteration 191500, loss = 0.902947
I0522 09:54:28.440552 10501 solver.cpp:253]     Train net output #0: loss = 0.902949 (* 1 = 0.902949 loss)
I0522 09:54:28.440567 10501 sgd_solver.cpp:106] Iteration 191500, lr = 0.0015
I0522 09:54:39.035807 10501 solver.cpp:237] Iteration 192000, loss = 1.07682
I0522 09:54:39.035996 10501 solver.cpp:253]     Train net output #0: loss = 1.07683 (* 1 = 1.07683 loss)
I0522 09:54:39.036012 10501 sgd_solver.cpp:106] Iteration 192000, lr = 0.0015
I0522 09:54:49.648779 10501 solver.cpp:237] Iteration 192500, loss = 1.07561
I0522 09:54:49.648815 10501 solver.cpp:253]     Train net output #0: loss = 1.07561 (* 1 = 1.07561 loss)
I0522 09:54:49.648833 10501 sgd_solver.cpp:106] Iteration 192500, lr = 0.0015
I0522 09:55:00.216395 10501 solver.cpp:237] Iteration 193000, loss = 1.08
I0522 09:55:00.216430 10501 solver.cpp:253]     Train net output #0: loss = 1.08 (* 1 = 1.08 loss)
I0522 09:55:00.216447 10501 sgd_solver.cpp:106] Iteration 193000, lr = 0.0015
I0522 09:55:31.706981 10501 solver.cpp:237] Iteration 193500, loss = 1.1775
I0522 09:55:31.707182 10501 solver.cpp:253]     Train net output #0: loss = 1.1775 (* 1 = 1.1775 loss)
I0522 09:55:31.707198 10501 sgd_solver.cpp:106] Iteration 193500, lr = 0.0015
I0522 09:55:42.290714 10501 solver.cpp:237] Iteration 194000, loss = 1.21861
I0522 09:55:42.290750 10501 solver.cpp:253]     Train net output #0: loss = 1.21861 (* 1 = 1.21861 loss)
I0522 09:55:42.290767 10501 sgd_solver.cpp:106] Iteration 194000, lr = 0.0015
I0522 09:55:52.878741 10501 solver.cpp:237] Iteration 194500, loss = 1.19632
I0522 09:55:52.878793 10501 solver.cpp:253]     Train net output #0: loss = 1.19632 (* 1 = 1.19632 loss)
I0522 09:55:52.878808 10501 sgd_solver.cpp:106] Iteration 194500, lr = 0.0015
I0522 09:56:03.439659 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_195000.caffemodel
I0522 09:56:03.492395 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_195000.solverstate
I0522 09:56:03.524834 10501 solver.cpp:237] Iteration 195000, loss = 1.18622
I0522 09:56:03.524878 10501 solver.cpp:253]     Train net output #0: loss = 1.18623 (* 1 = 1.18623 loss)
I0522 09:56:03.524900 10501 sgd_solver.cpp:106] Iteration 195000, lr = 0.0015
I0522 09:56:14.122074 10501 solver.cpp:237] Iteration 195500, loss = 1.0979
I0522 09:56:14.122110 10501 solver.cpp:253]     Train net output #0: loss = 1.09791 (* 1 = 1.09791 loss)
I0522 09:56:14.122126 10501 sgd_solver.cpp:106] Iteration 195500, lr = 0.0015
I0522 09:56:24.700541 10501 solver.cpp:237] Iteration 196000, loss = 1.01002
I0522 09:56:24.700592 10501 solver.cpp:253]     Train net output #0: loss = 1.01002 (* 1 = 1.01002 loss)
I0522 09:56:24.700608 10501 sgd_solver.cpp:106] Iteration 196000, lr = 0.0015
I0522 09:56:35.291565 10501 solver.cpp:237] Iteration 196500, loss = 1.00929
I0522 09:56:35.291748 10501 solver.cpp:253]     Train net output #0: loss = 1.0093 (* 1 = 1.0093 loss)
I0522 09:56:35.291762 10501 sgd_solver.cpp:106] Iteration 196500, lr = 0.0015
I0522 09:57:06.744117 10501 solver.cpp:237] Iteration 197000, loss = 1.01098
I0522 09:57:06.765398 10501 solver.cpp:253]     Train net output #0: loss = 1.01098 (* 1 = 1.01098 loss)
I0522 09:57:06.765414 10501 sgd_solver.cpp:106] Iteration 197000, lr = 0.0015
I0522 09:57:17.341017 10501 solver.cpp:237] Iteration 197500, loss = 1.42338
I0522 09:57:17.341053 10501 solver.cpp:253]     Train net output #0: loss = 1.42338 (* 1 = 1.42338 loss)
I0522 09:57:17.341069 10501 sgd_solver.cpp:106] Iteration 197500, lr = 0.0015
I0522 09:57:27.915763 10501 solver.cpp:237] Iteration 198000, loss = 1.2279
I0522 09:57:27.915799 10501 solver.cpp:253]     Train net output #0: loss = 1.2279 (* 1 = 1.2279 loss)
I0522 09:57:27.915813 10501 sgd_solver.cpp:106] Iteration 198000, lr = 0.0015
I0522 09:57:38.501085 10501 solver.cpp:237] Iteration 198500, loss = 1.07255
I0522 09:57:38.501272 10501 solver.cpp:253]     Train net output #0: loss = 1.07255 (* 1 = 1.07255 loss)
I0522 09:57:38.501287 10501 sgd_solver.cpp:106] Iteration 198500, lr = 0.0015
I0522 09:57:49.093148 10501 solver.cpp:237] Iteration 199000, loss = 1.34847
I0522 09:57:49.093183 10501 solver.cpp:253]     Train net output #0: loss = 1.34847 (* 1 = 1.34847 loss)
I0522 09:57:49.093200 10501 sgd_solver.cpp:106] Iteration 199000, lr = 0.0015
I0522 09:57:59.692656 10501 solver.cpp:237] Iteration 199500, loss = 1.63912
I0522 09:57:59.692703 10501 solver.cpp:253]     Train net output #0: loss = 1.63912 (* 1 = 1.63912 loss)
I0522 09:57:59.692718 10501 sgd_solver.cpp:106] Iteration 199500, lr = 0.0015
I0522 09:58:10.262864 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_200000.caffemodel
I0522 09:58:10.318929 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_200000.solverstate
I0522 09:58:10.347254 10501 solver.cpp:341] Iteration 200000, Testing net (#0)
I0522 09:59:20.838423 10501 solver.cpp:409]     Test net output #0: accuracy = 0.898405
I0522 09:59:20.838624 10501 solver.cpp:409]     Test net output #1: loss = 0.329408 (* 1 = 0.329408 loss)
I0522 09:59:41.742521 10501 solver.cpp:237] Iteration 200000, loss = 0.889253
I0522 09:59:41.742576 10501 solver.cpp:253]     Train net output #0: loss = 0.889254 (* 1 = 0.889254 loss)
I0522 09:59:41.742594 10501 sgd_solver.cpp:106] Iteration 200000, lr = 0.0015
I0522 09:59:52.283380 10501 solver.cpp:237] Iteration 200500, loss = 1.27271
I0522 09:59:52.283572 10501 solver.cpp:253]     Train net output #0: loss = 1.27271 (* 1 = 1.27271 loss)
I0522 09:59:52.283586 10501 sgd_solver.cpp:106] Iteration 200500, lr = 0.0015
I0522 10:00:02.822419 10501 solver.cpp:237] Iteration 201000, loss = 1.87079
I0522 10:00:02.822474 10501 solver.cpp:253]     Train net output #0: loss = 1.87079 (* 1 = 1.87079 loss)
I0522 10:00:02.822489 10501 sgd_solver.cpp:106] Iteration 201000, lr = 0.0015
I0522 10:00:13.367966 10501 solver.cpp:237] Iteration 201500, loss = 1.05939
I0522 10:00:13.368002 10501 solver.cpp:253]     Train net output #0: loss = 1.05939 (* 1 = 1.05939 loss)
I0522 10:00:13.368021 10501 sgd_solver.cpp:106] Iteration 201500, lr = 0.0015
I0522 10:00:23.905964 10501 solver.cpp:237] Iteration 202000, loss = 0.757344
I0522 10:00:23.906142 10501 solver.cpp:253]     Train net output #0: loss = 0.757345 (* 1 = 0.757345 loss)
I0522 10:00:23.906157 10501 sgd_solver.cpp:106] Iteration 202000, lr = 0.0015
I0522 10:00:34.443827 10501 solver.cpp:237] Iteration 202500, loss = 1.28274
I0522 10:00:34.443877 10501 solver.cpp:253]     Train net output #0: loss = 1.28274 (* 1 = 1.28274 loss)
I0522 10:00:34.443893 10501 sgd_solver.cpp:106] Iteration 202500, lr = 0.0015
I0522 10:00:44.976794 10501 solver.cpp:237] Iteration 203000, loss = 1.52559
I0522 10:00:44.976829 10501 solver.cpp:253]     Train net output #0: loss = 1.52559 (* 1 = 1.52559 loss)
I0522 10:00:44.976842 10501 sgd_solver.cpp:106] Iteration 203000, lr = 0.0015
I0522 10:01:16.392546 10501 solver.cpp:237] Iteration 203500, loss = 1.57056
I0522 10:01:16.392748 10501 solver.cpp:253]     Train net output #0: loss = 1.57056 (* 1 = 1.57056 loss)
I0522 10:01:16.392765 10501 sgd_solver.cpp:106] Iteration 203500, lr = 0.0015
I0522 10:01:26.935348 10501 solver.cpp:237] Iteration 204000, loss = 1.03294
I0522 10:01:26.935397 10501 solver.cpp:253]     Train net output #0: loss = 1.03294 (* 1 = 1.03294 loss)
I0522 10:01:26.935413 10501 sgd_solver.cpp:106] Iteration 204000, lr = 0.0015
I0522 10:01:37.467888 10501 solver.cpp:237] Iteration 204500, loss = 1.46008
I0522 10:01:37.467919 10501 solver.cpp:253]     Train net output #0: loss = 1.46009 (* 1 = 1.46009 loss)
I0522 10:01:37.467933 10501 sgd_solver.cpp:106] Iteration 204500, lr = 0.0015
I0522 10:01:47.993757 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_205000.caffemodel
I0522 10:01:48.046639 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_205000.solverstate
I0522 10:01:48.078912 10501 solver.cpp:237] Iteration 205000, loss = 0.849827
I0522 10:01:48.078958 10501 solver.cpp:253]     Train net output #0: loss = 0.849828 (* 1 = 0.849828 loss)
I0522 10:01:48.078974 10501 sgd_solver.cpp:106] Iteration 205000, lr = 0.0015
I0522 10:01:58.633111 10501 solver.cpp:237] Iteration 205500, loss = 1.27358
I0522 10:01:58.633147 10501 solver.cpp:253]     Train net output #0: loss = 1.27358 (* 1 = 1.27358 loss)
I0522 10:01:58.633160 10501 sgd_solver.cpp:106] Iteration 205500, lr = 0.0015
I0522 10:02:09.173178 10501 solver.cpp:237] Iteration 206000, loss = 1.17283
I0522 10:02:09.173224 10501 solver.cpp:253]     Train net output #0: loss = 1.17283 (* 1 = 1.17283 loss)
I0522 10:02:09.173240 10501 sgd_solver.cpp:106] Iteration 206000, lr = 0.0015
I0522 10:02:19.749507 10501 solver.cpp:237] Iteration 206500, loss = 0.819813
I0522 10:02:19.749698 10501 solver.cpp:253]     Train net output #0: loss = 0.819814 (* 1 = 0.819814 loss)
I0522 10:02:19.749713 10501 sgd_solver.cpp:106] Iteration 206500, lr = 0.0015
I0522 10:02:51.240180 10501 solver.cpp:237] Iteration 207000, loss = 0.925276
I0522 10:02:51.240396 10501 solver.cpp:253]     Train net output #0: loss = 0.925277 (* 1 = 0.925277 loss)
I0522 10:02:51.240411 10501 sgd_solver.cpp:106] Iteration 207000, lr = 0.0015
I0522 10:03:01.823163 10501 solver.cpp:237] Iteration 207500, loss = 1.19134
I0522 10:03:01.823215 10501 solver.cpp:253]     Train net output #0: loss = 1.19134 (* 1 = 1.19134 loss)
I0522 10:03:01.823231 10501 sgd_solver.cpp:106] Iteration 207500, lr = 0.0015
I0522 10:03:12.392388 10501 solver.cpp:237] Iteration 208000, loss = 1.05066
I0522 10:03:12.392426 10501 solver.cpp:253]     Train net output #0: loss = 1.05066 (* 1 = 1.05066 loss)
I0522 10:03:12.392441 10501 sgd_solver.cpp:106] Iteration 208000, lr = 0.0015
I0522 10:03:22.978870 10501 solver.cpp:237] Iteration 208500, loss = 1.28774
I0522 10:03:22.979063 10501 solver.cpp:253]     Train net output #0: loss = 1.28774 (* 1 = 1.28774 loss)
I0522 10:03:22.979077 10501 sgd_solver.cpp:106] Iteration 208500, lr = 0.0015
I0522 10:03:33.572736 10501 solver.cpp:237] Iteration 209000, loss = 1.08692
I0522 10:03:33.572772 10501 solver.cpp:253]     Train net output #0: loss = 1.08692 (* 1 = 1.08692 loss)
I0522 10:03:33.572788 10501 sgd_solver.cpp:106] Iteration 209000, lr = 0.0015
I0522 10:03:44.160856 10501 solver.cpp:237] Iteration 209500, loss = 1.16852
I0522 10:03:44.160892 10501 solver.cpp:253]     Train net output #0: loss = 1.16853 (* 1 = 1.16853 loss)
I0522 10:03:44.160908 10501 sgd_solver.cpp:106] Iteration 209500, lr = 0.0015
I0522 10:03:54.718060 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_210000.caffemodel
I0522 10:03:54.770917 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_210000.solverstate
I0522 10:03:54.796619 10501 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 10:04:44.473137 10501 solver.cpp:409]     Test net output #0: accuracy = 0.897612
I0522 10:04:44.473338 10501 solver.cpp:409]     Test net output #1: loss = 0.323935 (* 1 = 0.323935 loss)
I0522 10:05:05.350066 10501 solver.cpp:237] Iteration 210000, loss = 0.828546
I0522 10:05:05.350123 10501 solver.cpp:253]     Train net output #0: loss = 0.828547 (* 1 = 0.828547 loss)
I0522 10:05:05.350139 10501 sgd_solver.cpp:106] Iteration 210000, lr = 0.0015
I0522 10:05:15.947603 10501 solver.cpp:237] Iteration 210500, loss = 0.979921
I0522 10:05:15.947794 10501 solver.cpp:253]     Train net output #0: loss = 0.979922 (* 1 = 0.979922 loss)
I0522 10:05:15.947809 10501 sgd_solver.cpp:106] Iteration 210500, lr = 0.0015
I0522 10:05:26.554198 10501 solver.cpp:237] Iteration 211000, loss = 1.49846
I0522 10:05:26.554234 10501 solver.cpp:253]     Train net output #0: loss = 1.49846 (* 1 = 1.49846 loss)
I0522 10:05:26.554250 10501 sgd_solver.cpp:106] Iteration 211000, lr = 0.0015
I0522 10:05:37.158295 10501 solver.cpp:237] Iteration 211500, loss = 1.41301
I0522 10:05:37.158342 10501 solver.cpp:253]     Train net output #0: loss = 1.41301 (* 1 = 1.41301 loss)
I0522 10:05:37.158355 10501 sgd_solver.cpp:106] Iteration 211500, lr = 0.0015
I0522 10:05:47.757846 10501 solver.cpp:237] Iteration 212000, loss = 0.884205
I0522 10:05:47.758023 10501 solver.cpp:253]     Train net output #0: loss = 0.884206 (* 1 = 0.884206 loss)
I0522 10:05:47.758038 10501 sgd_solver.cpp:106] Iteration 212000, lr = 0.0015
I0522 10:05:58.346642 10501 solver.cpp:237] Iteration 212500, loss = 1.16173
I0522 10:05:58.346691 10501 solver.cpp:253]     Train net output #0: loss = 1.16173 (* 1 = 1.16173 loss)
I0522 10:05:58.346709 10501 sgd_solver.cpp:106] Iteration 212500, lr = 0.0015
I0522 10:06:08.945349 10501 solver.cpp:237] Iteration 213000, loss = 1.02508
I0522 10:06:08.945385 10501 solver.cpp:253]     Train net output #0: loss = 1.02508 (* 1 = 1.02508 loss)
I0522 10:06:08.945401 10501 sgd_solver.cpp:106] Iteration 213000, lr = 0.0015
I0522 10:06:40.435132 10501 solver.cpp:237] Iteration 213500, loss = 1.12029
I0522 10:06:40.435348 10501 solver.cpp:253]     Train net output #0: loss = 1.12029 (* 1 = 1.12029 loss)
I0522 10:06:40.435364 10501 sgd_solver.cpp:106] Iteration 213500, lr = 0.0015
I0522 10:06:51.038553 10501 solver.cpp:237] Iteration 214000, loss = 1.11939
I0522 10:06:51.038606 10501 solver.cpp:253]     Train net output #0: loss = 1.11939 (* 1 = 1.11939 loss)
I0522 10:06:51.038621 10501 sgd_solver.cpp:106] Iteration 214000, lr = 0.0015
I0522 10:07:01.648813 10501 solver.cpp:237] Iteration 214500, loss = 1.16592
I0522 10:07:01.648849 10501 solver.cpp:253]     Train net output #0: loss = 1.16592 (* 1 = 1.16592 loss)
I0522 10:07:01.648866 10501 sgd_solver.cpp:106] Iteration 214500, lr = 0.0015
I0522 10:07:12.237323 10501 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_215000.caffemodel
I0522 10:07:12.291666 10501 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0015_2016-05-20T15.48.58.106821_iter_215000.solverstate
aprun: Apid 11246960: Caught signal Terminated, sending to application
*** Aborted at 1463926032 (unix time) try "date -d @1463926032" if you are using GNU date ***
aprun: Apid 11246960: Caught signal Terminated, sending to application
PC: @     0x2aaab7f5d268 __writev
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7245 exceeded limit 7200
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
aprun: Apid 11246960: Caught signal Terminated, sending to application
*** SIGTERM (@0x2902) received by PID 10501 (TID 0x2aaac746f900) from PID 10498; stack trace: ***
aprun: Apid 11246960: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab7f5d268 __writev
aprun: Apid 11246960: Caught signal Terminated, sending to application
    @     0x2aaab4496275 std::__basic_file<>::xsputn_2()
aprun: Apid 11246960: Caught signal Terminated, sending to application
    @     0x2aaab44d14d6 std::basic_filebuf<>::xsputn()
    @     0x2aaab44b0f93 std::ostream::write()
