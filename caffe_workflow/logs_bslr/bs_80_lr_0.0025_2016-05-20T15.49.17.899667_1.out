2809718
I0524 20:42:24.007596 14843 caffe.cpp:184] Using GPUs 0
I0524 20:42:24.438681 14843 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1875
test_interval: 3750
base_lr: 0.0025
display: 187
max_iter: 187500
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1875
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667.prototxt"
I0524 20:42:24.440958 14843 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667.prototxt
I0524 20:42:24.461480 14843 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0524 20:42:24.461545 14843 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0524 20:42:24.461923 14843 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 80
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 20:42:24.462132 14843 layer_factory.hpp:77] Creating layer data_hdf5
I0524 20:42:24.462169 14843 net.cpp:106] Creating Layer data_hdf5
I0524 20:42:24.462188 14843 net.cpp:411] data_hdf5 -> data
I0524 20:42:24.462219 14843 net.cpp:411] data_hdf5 -> label
I0524 20:42:24.462256 14843 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0524 20:42:24.463501 14843 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0524 20:42:24.465713 14843 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0524 20:42:45.992775 14843 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0524 20:42:45.997975 14843 net.cpp:150] Setting up data_hdf5
I0524 20:42:45.998016 14843 net.cpp:157] Top shape: 80 1 127 50 (508000)
I0524 20:42:45.998034 14843 net.cpp:157] Top shape: 80 (80)
I0524 20:42:45.998046 14843 net.cpp:165] Memory required for data: 2032320
I0524 20:42:45.998065 14843 layer_factory.hpp:77] Creating layer conv1
I0524 20:42:45.998118 14843 net.cpp:106] Creating Layer conv1
I0524 20:42:45.998145 14843 net.cpp:454] conv1 <- data
I0524 20:42:45.998170 14843 net.cpp:411] conv1 -> conv1
I0524 20:42:46.370687 14843 net.cpp:150] Setting up conv1
I0524 20:42:46.370741 14843 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0524 20:42:46.370765 14843 net.cpp:165] Memory required for data: 24150720
I0524 20:42:46.370795 14843 layer_factory.hpp:77] Creating layer relu1
I0524 20:42:46.370817 14843 net.cpp:106] Creating Layer relu1
I0524 20:42:46.370838 14843 net.cpp:454] relu1 <- conv1
I0524 20:42:46.370873 14843 net.cpp:397] relu1 -> conv1 (in-place)
I0524 20:42:46.371404 14843 net.cpp:150] Setting up relu1
I0524 20:42:46.371428 14843 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0524 20:42:46.371441 14843 net.cpp:165] Memory required for data: 46269120
I0524 20:42:46.371459 14843 layer_factory.hpp:77] Creating layer pool1
I0524 20:42:46.371485 14843 net.cpp:106] Creating Layer pool1
I0524 20:42:46.371500 14843 net.cpp:454] pool1 <- conv1
I0524 20:42:46.371515 14843 net.cpp:411] pool1 -> pool1
I0524 20:42:46.371609 14843 net.cpp:150] Setting up pool1
I0524 20:42:46.371626 14843 net.cpp:157] Top shape: 80 12 60 48 (2764800)
I0524 20:42:46.371641 14843 net.cpp:165] Memory required for data: 57328320
I0524 20:42:46.371662 14843 layer_factory.hpp:77] Creating layer conv2
I0524 20:42:46.371686 14843 net.cpp:106] Creating Layer conv2
I0524 20:42:46.371700 14843 net.cpp:454] conv2 <- pool1
I0524 20:42:46.371716 14843 net.cpp:411] conv2 -> conv2
I0524 20:42:46.374462 14843 net.cpp:150] Setting up conv2
I0524 20:42:46.374493 14843 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0524 20:42:46.374507 14843 net.cpp:165] Memory required for data: 73225920
I0524 20:42:46.374536 14843 layer_factory.hpp:77] Creating layer relu2
I0524 20:42:46.374563 14843 net.cpp:106] Creating Layer relu2
I0524 20:42:46.374578 14843 net.cpp:454] relu2 <- conv2
I0524 20:42:46.374593 14843 net.cpp:397] relu2 -> conv2 (in-place)
I0524 20:42:46.374950 14843 net.cpp:150] Setting up relu2
I0524 20:42:46.374970 14843 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0524 20:42:46.374984 14843 net.cpp:165] Memory required for data: 89123520
I0524 20:42:46.374999 14843 layer_factory.hpp:77] Creating layer pool2
I0524 20:42:46.375021 14843 net.cpp:106] Creating Layer pool2
I0524 20:42:46.375036 14843 net.cpp:454] pool2 <- conv2
I0524 20:42:46.375051 14843 net.cpp:411] pool2 -> pool2
I0524 20:42:46.375145 14843 net.cpp:150] Setting up pool2
I0524 20:42:46.375162 14843 net.cpp:157] Top shape: 80 20 27 46 (1987200)
I0524 20:42:46.375177 14843 net.cpp:165] Memory required for data: 97072320
I0524 20:42:46.375196 14843 layer_factory.hpp:77] Creating layer conv3
I0524 20:42:46.375217 14843 net.cpp:106] Creating Layer conv3
I0524 20:42:46.375237 14843 net.cpp:454] conv3 <- pool2
I0524 20:42:46.375254 14843 net.cpp:411] conv3 -> conv3
I0524 20:42:46.377200 14843 net.cpp:150] Setting up conv3
I0524 20:42:46.377225 14843 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0524 20:42:46.377245 14843 net.cpp:165] Memory required for data: 105745600
I0524 20:42:46.377267 14843 layer_factory.hpp:77] Creating layer relu3
I0524 20:42:46.377290 14843 net.cpp:106] Creating Layer relu3
I0524 20:42:46.377311 14843 net.cpp:454] relu3 <- conv3
I0524 20:42:46.377327 14843 net.cpp:397] relu3 -> conv3 (in-place)
I0524 20:42:46.377815 14843 net.cpp:150] Setting up relu3
I0524 20:42:46.377838 14843 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0524 20:42:46.377851 14843 net.cpp:165] Memory required for data: 114418880
I0524 20:42:46.377867 14843 layer_factory.hpp:77] Creating layer pool3
I0524 20:42:46.377892 14843 net.cpp:106] Creating Layer pool3
I0524 20:42:46.377905 14843 net.cpp:454] pool3 <- conv3
I0524 20:42:46.377921 14843 net.cpp:411] pool3 -> pool3
I0524 20:42:46.378005 14843 net.cpp:150] Setting up pool3
I0524 20:42:46.378021 14843 net.cpp:157] Top shape: 80 28 11 44 (1084160)
I0524 20:42:46.378036 14843 net.cpp:165] Memory required for data: 118755520
I0524 20:42:46.378048 14843 layer_factory.hpp:77] Creating layer conv4
I0524 20:42:46.378075 14843 net.cpp:106] Creating Layer conv4
I0524 20:42:46.378094 14843 net.cpp:454] conv4 <- pool3
I0524 20:42:46.378113 14843 net.cpp:411] conv4 -> conv4
I0524 20:42:46.381089 14843 net.cpp:150] Setting up conv4
I0524 20:42:46.381122 14843 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0524 20:42:46.381139 14843 net.cpp:165] Memory required for data: 121658560
I0524 20:42:46.381158 14843 layer_factory.hpp:77] Creating layer relu4
I0524 20:42:46.381180 14843 net.cpp:106] Creating Layer relu4
I0524 20:42:46.381206 14843 net.cpp:454] relu4 <- conv4
I0524 20:42:46.381222 14843 net.cpp:397] relu4 -> conv4 (in-place)
I0524 20:42:46.381711 14843 net.cpp:150] Setting up relu4
I0524 20:42:46.381734 14843 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0524 20:42:46.381747 14843 net.cpp:165] Memory required for data: 124561600
I0524 20:42:46.381762 14843 layer_factory.hpp:77] Creating layer pool4
I0524 20:42:46.381778 14843 net.cpp:106] Creating Layer pool4
I0524 20:42:46.381800 14843 net.cpp:454] pool4 <- conv4
I0524 20:42:46.381817 14843 net.cpp:411] pool4 -> pool4
I0524 20:42:46.381899 14843 net.cpp:150] Setting up pool4
I0524 20:42:46.381921 14843 net.cpp:157] Top shape: 80 36 3 42 (362880)
I0524 20:42:46.381933 14843 net.cpp:165] Memory required for data: 126013120
I0524 20:42:46.381948 14843 layer_factory.hpp:77] Creating layer ip1
I0524 20:42:46.381975 14843 net.cpp:106] Creating Layer ip1
I0524 20:42:46.381989 14843 net.cpp:454] ip1 <- pool4
I0524 20:42:46.382004 14843 net.cpp:411] ip1 -> ip1
I0524 20:42:46.397428 14843 net.cpp:150] Setting up ip1
I0524 20:42:46.397459 14843 net.cpp:157] Top shape: 80 196 (15680)
I0524 20:42:46.397480 14843 net.cpp:165] Memory required for data: 126075840
I0524 20:42:46.397505 14843 layer_factory.hpp:77] Creating layer relu5
I0524 20:42:46.397527 14843 net.cpp:106] Creating Layer relu5
I0524 20:42:46.397552 14843 net.cpp:454] relu5 <- ip1
I0524 20:42:46.397569 14843 net.cpp:397] relu5 -> ip1 (in-place)
I0524 20:42:46.397925 14843 net.cpp:150] Setting up relu5
I0524 20:42:46.397945 14843 net.cpp:157] Top shape: 80 196 (15680)
I0524 20:42:46.397958 14843 net.cpp:165] Memory required for data: 126138560
I0524 20:42:46.397974 14843 layer_factory.hpp:77] Creating layer drop1
I0524 20:42:46.398005 14843 net.cpp:106] Creating Layer drop1
I0524 20:42:46.398020 14843 net.cpp:454] drop1 <- ip1
I0524 20:42:46.398041 14843 net.cpp:397] drop1 -> ip1 (in-place)
I0524 20:42:46.398123 14843 net.cpp:150] Setting up drop1
I0524 20:42:46.398144 14843 net.cpp:157] Top shape: 80 196 (15680)
I0524 20:42:46.398157 14843 net.cpp:165] Memory required for data: 126201280
I0524 20:42:46.398169 14843 layer_factory.hpp:77] Creating layer ip2
I0524 20:42:46.398195 14843 net.cpp:106] Creating Layer ip2
I0524 20:42:46.398213 14843 net.cpp:454] ip2 <- ip1
I0524 20:42:46.398229 14843 net.cpp:411] ip2 -> ip2
I0524 20:42:46.398716 14843 net.cpp:150] Setting up ip2
I0524 20:42:46.398736 14843 net.cpp:157] Top shape: 80 98 (7840)
I0524 20:42:46.398748 14843 net.cpp:165] Memory required for data: 126232640
I0524 20:42:46.398769 14843 layer_factory.hpp:77] Creating layer relu6
I0524 20:42:46.398784 14843 net.cpp:106] Creating Layer relu6
I0524 20:42:46.398804 14843 net.cpp:454] relu6 <- ip2
I0524 20:42:46.398819 14843 net.cpp:397] relu6 -> ip2 (in-place)
I0524 20:42:46.399379 14843 net.cpp:150] Setting up relu6
I0524 20:42:46.399401 14843 net.cpp:157] Top shape: 80 98 (7840)
I0524 20:42:46.399415 14843 net.cpp:165] Memory required for data: 126264000
I0524 20:42:46.399430 14843 layer_factory.hpp:77] Creating layer drop2
I0524 20:42:46.399454 14843 net.cpp:106] Creating Layer drop2
I0524 20:42:46.399467 14843 net.cpp:454] drop2 <- ip2
I0524 20:42:46.399483 14843 net.cpp:397] drop2 -> ip2 (in-place)
I0524 20:42:46.399533 14843 net.cpp:150] Setting up drop2
I0524 20:42:46.399556 14843 net.cpp:157] Top shape: 80 98 (7840)
I0524 20:42:46.399569 14843 net.cpp:165] Memory required for data: 126295360
I0524 20:42:46.399585 14843 layer_factory.hpp:77] Creating layer ip3
I0524 20:42:46.399601 14843 net.cpp:106] Creating Layer ip3
I0524 20:42:46.399616 14843 net.cpp:454] ip3 <- ip2
I0524 20:42:46.399637 14843 net.cpp:411] ip3 -> ip3
I0524 20:42:46.399862 14843 net.cpp:150] Setting up ip3
I0524 20:42:46.399879 14843 net.cpp:157] Top shape: 80 11 (880)
I0524 20:42:46.399893 14843 net.cpp:165] Memory required for data: 126298880
I0524 20:42:46.399912 14843 layer_factory.hpp:77] Creating layer drop3
I0524 20:42:46.399929 14843 net.cpp:106] Creating Layer drop3
I0524 20:42:46.399947 14843 net.cpp:454] drop3 <- ip3
I0524 20:42:46.399962 14843 net.cpp:397] drop3 -> ip3 (in-place)
I0524 20:42:46.400009 14843 net.cpp:150] Setting up drop3
I0524 20:42:46.400024 14843 net.cpp:157] Top shape: 80 11 (880)
I0524 20:42:46.400037 14843 net.cpp:165] Memory required for data: 126302400
I0524 20:42:46.400055 14843 layer_factory.hpp:77] Creating layer loss
I0524 20:42:46.400077 14843 net.cpp:106] Creating Layer loss
I0524 20:42:46.400092 14843 net.cpp:454] loss <- ip3
I0524 20:42:46.400106 14843 net.cpp:454] loss <- label
I0524 20:42:46.400122 14843 net.cpp:411] loss -> loss
I0524 20:42:46.400141 14843 layer_factory.hpp:77] Creating layer loss
I0524 20:42:46.400816 14843 net.cpp:150] Setting up loss
I0524 20:42:46.400838 14843 net.cpp:157] Top shape: (1)
I0524 20:42:46.400859 14843 net.cpp:160]     with loss weight 1
I0524 20:42:46.400907 14843 net.cpp:165] Memory required for data: 126302404
I0524 20:42:46.400920 14843 net.cpp:226] loss needs backward computation.
I0524 20:42:46.400943 14843 net.cpp:226] drop3 needs backward computation.
I0524 20:42:46.400957 14843 net.cpp:226] ip3 needs backward computation.
I0524 20:42:46.400971 14843 net.cpp:226] drop2 needs backward computation.
I0524 20:42:46.400984 14843 net.cpp:226] relu6 needs backward computation.
I0524 20:42:46.400998 14843 net.cpp:226] ip2 needs backward computation.
I0524 20:42:46.401011 14843 net.cpp:226] drop1 needs backward computation.
I0524 20:42:46.401031 14843 net.cpp:226] relu5 needs backward computation.
I0524 20:42:46.401044 14843 net.cpp:226] ip1 needs backward computation.
I0524 20:42:46.401062 14843 net.cpp:226] pool4 needs backward computation.
I0524 20:42:46.401075 14843 net.cpp:226] relu4 needs backward computation.
I0524 20:42:46.401088 14843 net.cpp:226] conv4 needs backward computation.
I0524 20:42:46.401100 14843 net.cpp:226] pool3 needs backward computation.
I0524 20:42:46.401116 14843 net.cpp:226] relu3 needs backward computation.
I0524 20:42:46.401139 14843 net.cpp:226] conv3 needs backward computation.
I0524 20:42:46.401152 14843 net.cpp:226] pool2 needs backward computation.
I0524 20:42:46.401180 14843 net.cpp:226] relu2 needs backward computation.
I0524 20:42:46.401192 14843 net.cpp:226] conv2 needs backward computation.
I0524 20:42:46.401206 14843 net.cpp:226] pool1 needs backward computation.
I0524 20:42:46.401221 14843 net.cpp:226] relu1 needs backward computation.
I0524 20:42:46.401234 14843 net.cpp:226] conv1 needs backward computation.
I0524 20:42:46.401249 14843 net.cpp:228] data_hdf5 does not need backward computation.
I0524 20:42:46.401262 14843 net.cpp:270] This network produces output loss
I0524 20:42:46.401301 14843 net.cpp:283] Network initialization done.
I0524 20:42:46.403218 14843 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667.prototxt
I0524 20:42:46.403297 14843 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0524 20:42:46.403676 14843 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 80
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 20:42:46.403892 14843 layer_factory.hpp:77] Creating layer data_hdf5
I0524 20:42:46.403918 14843 net.cpp:106] Creating Layer data_hdf5
I0524 20:42:46.403934 14843 net.cpp:411] data_hdf5 -> data
I0524 20:42:46.403959 14843 net.cpp:411] data_hdf5 -> label
I0524 20:42:46.403985 14843 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0524 20:42:46.405218 14843 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0524 20:43:07.736526 14843 net.cpp:150] Setting up data_hdf5
I0524 20:43:07.736696 14843 net.cpp:157] Top shape: 80 1 127 50 (508000)
I0524 20:43:07.736716 14843 net.cpp:157] Top shape: 80 (80)
I0524 20:43:07.736729 14843 net.cpp:165] Memory required for data: 2032320
I0524 20:43:07.736744 14843 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0524 20:43:07.736779 14843 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0524 20:43:07.736793 14843 net.cpp:454] label_data_hdf5_1_split <- label
I0524 20:43:07.736809 14843 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0524 20:43:07.736831 14843 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0524 20:43:07.736909 14843 net.cpp:150] Setting up label_data_hdf5_1_split
I0524 20:43:07.736925 14843 net.cpp:157] Top shape: 80 (80)
I0524 20:43:07.736974 14843 net.cpp:157] Top shape: 80 (80)
I0524 20:43:07.736987 14843 net.cpp:165] Memory required for data: 2032960
I0524 20:43:07.736999 14843 layer_factory.hpp:77] Creating layer conv1
I0524 20:43:07.737022 14843 net.cpp:106] Creating Layer conv1
I0524 20:43:07.737035 14843 net.cpp:454] conv1 <- data
I0524 20:43:07.737066 14843 net.cpp:411] conv1 -> conv1
I0524 20:43:07.739063 14843 net.cpp:150] Setting up conv1
I0524 20:43:07.739090 14843 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0524 20:43:07.739111 14843 net.cpp:165] Memory required for data: 24151360
I0524 20:43:07.739135 14843 layer_factory.hpp:77] Creating layer relu1
I0524 20:43:07.739156 14843 net.cpp:106] Creating Layer relu1
I0524 20:43:07.739178 14843 net.cpp:454] relu1 <- conv1
I0524 20:43:07.739194 14843 net.cpp:397] relu1 -> conv1 (in-place)
I0524 20:43:07.739711 14843 net.cpp:150] Setting up relu1
I0524 20:43:07.739733 14843 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0524 20:43:07.739747 14843 net.cpp:165] Memory required for data: 46269760
I0524 20:43:07.739758 14843 layer_factory.hpp:77] Creating layer pool1
I0524 20:43:07.739789 14843 net.cpp:106] Creating Layer pool1
I0524 20:43:07.739801 14843 net.cpp:454] pool1 <- conv1
I0524 20:43:07.739819 14843 net.cpp:411] pool1 -> pool1
I0524 20:43:07.739907 14843 net.cpp:150] Setting up pool1
I0524 20:43:07.739924 14843 net.cpp:157] Top shape: 80 12 60 48 (2764800)
I0524 20:43:07.739939 14843 net.cpp:165] Memory required for data: 57328960
I0524 20:43:07.739958 14843 layer_factory.hpp:77] Creating layer conv2
I0524 20:43:07.739982 14843 net.cpp:106] Creating Layer conv2
I0524 20:43:07.740005 14843 net.cpp:454] conv2 <- pool1
I0524 20:43:07.740021 14843 net.cpp:411] conv2 -> conv2
I0524 20:43:07.741973 14843 net.cpp:150] Setting up conv2
I0524 20:43:07.741998 14843 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0524 20:43:07.742019 14843 net.cpp:165] Memory required for data: 73226560
I0524 20:43:07.742040 14843 layer_factory.hpp:77] Creating layer relu2
I0524 20:43:07.742060 14843 net.cpp:106] Creating Layer relu2
I0524 20:43:07.742081 14843 net.cpp:454] relu2 <- conv2
I0524 20:43:07.742105 14843 net.cpp:397] relu2 -> conv2 (in-place)
I0524 20:43:07.742458 14843 net.cpp:150] Setting up relu2
I0524 20:43:07.742478 14843 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0524 20:43:07.742491 14843 net.cpp:165] Memory required for data: 89124160
I0524 20:43:07.742507 14843 layer_factory.hpp:77] Creating layer pool2
I0524 20:43:07.742530 14843 net.cpp:106] Creating Layer pool2
I0524 20:43:07.742543 14843 net.cpp:454] pool2 <- conv2
I0524 20:43:07.742559 14843 net.cpp:411] pool2 -> pool2
I0524 20:43:07.742646 14843 net.cpp:150] Setting up pool2
I0524 20:43:07.742663 14843 net.cpp:157] Top shape: 80 20 27 46 (1987200)
I0524 20:43:07.742678 14843 net.cpp:165] Memory required for data: 97072960
I0524 20:43:07.742691 14843 layer_factory.hpp:77] Creating layer conv3
I0524 20:43:07.742714 14843 net.cpp:106] Creating Layer conv3
I0524 20:43:07.742733 14843 net.cpp:454] conv3 <- pool2
I0524 20:43:07.742751 14843 net.cpp:411] conv3 -> conv3
I0524 20:43:07.744770 14843 net.cpp:150] Setting up conv3
I0524 20:43:07.744794 14843 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0524 20:43:07.744813 14843 net.cpp:165] Memory required for data: 105746240
I0524 20:43:07.744853 14843 layer_factory.hpp:77] Creating layer relu3
I0524 20:43:07.744869 14843 net.cpp:106] Creating Layer relu3
I0524 20:43:07.744882 14843 net.cpp:454] relu3 <- conv3
I0524 20:43:07.744909 14843 net.cpp:397] relu3 -> conv3 (in-place)
I0524 20:43:07.745406 14843 net.cpp:150] Setting up relu3
I0524 20:43:07.745429 14843 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0524 20:43:07.745442 14843 net.cpp:165] Memory required for data: 114419520
I0524 20:43:07.745458 14843 layer_factory.hpp:77] Creating layer pool3
I0524 20:43:07.745474 14843 net.cpp:106] Creating Layer pool3
I0524 20:43:07.745488 14843 net.cpp:454] pool3 <- conv3
I0524 20:43:07.745504 14843 net.cpp:411] pool3 -> pool3
I0524 20:43:07.745584 14843 net.cpp:150] Setting up pool3
I0524 20:43:07.745601 14843 net.cpp:157] Top shape: 80 28 11 44 (1084160)
I0524 20:43:07.745615 14843 net.cpp:165] Memory required for data: 118756160
I0524 20:43:07.745626 14843 layer_factory.hpp:77] Creating layer conv4
I0524 20:43:07.745664 14843 net.cpp:106] Creating Layer conv4
I0524 20:43:07.745677 14843 net.cpp:454] conv4 <- pool3
I0524 20:43:07.745694 14843 net.cpp:411] conv4 -> conv4
I0524 20:43:07.747815 14843 net.cpp:150] Setting up conv4
I0524 20:43:07.747839 14843 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0524 20:43:07.747859 14843 net.cpp:165] Memory required for data: 121659200
I0524 20:43:07.747879 14843 layer_factory.hpp:77] Creating layer relu4
I0524 20:43:07.747898 14843 net.cpp:106] Creating Layer relu4
I0524 20:43:07.747910 14843 net.cpp:454] relu4 <- conv4
I0524 20:43:07.747936 14843 net.cpp:397] relu4 -> conv4 (in-place)
I0524 20:43:07.748430 14843 net.cpp:150] Setting up relu4
I0524 20:43:07.748453 14843 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0524 20:43:07.748466 14843 net.cpp:165] Memory required for data: 124562240
I0524 20:43:07.748482 14843 layer_factory.hpp:77] Creating layer pool4
I0524 20:43:07.748498 14843 net.cpp:106] Creating Layer pool4
I0524 20:43:07.748512 14843 net.cpp:454] pool4 <- conv4
I0524 20:43:07.748528 14843 net.cpp:411] pool4 -> pool4
I0524 20:43:07.748608 14843 net.cpp:150] Setting up pool4
I0524 20:43:07.748625 14843 net.cpp:157] Top shape: 80 36 3 42 (362880)
I0524 20:43:07.748638 14843 net.cpp:165] Memory required for data: 126013760
I0524 20:43:07.748651 14843 layer_factory.hpp:77] Creating layer ip1
I0524 20:43:07.748668 14843 net.cpp:106] Creating Layer ip1
I0524 20:43:07.748680 14843 net.cpp:454] ip1 <- pool4
I0524 20:43:07.748697 14843 net.cpp:411] ip1 -> ip1
I0524 20:43:07.764209 14843 net.cpp:150] Setting up ip1
I0524 20:43:07.764241 14843 net.cpp:157] Top shape: 80 196 (15680)
I0524 20:43:07.764263 14843 net.cpp:165] Memory required for data: 126076480
I0524 20:43:07.764289 14843 layer_factory.hpp:77] Creating layer relu5
I0524 20:43:07.764312 14843 net.cpp:106] Creating Layer relu5
I0524 20:43:07.764335 14843 net.cpp:454] relu5 <- ip1
I0524 20:43:07.764353 14843 net.cpp:397] relu5 -> ip1 (in-place)
I0524 20:43:07.764719 14843 net.cpp:150] Setting up relu5
I0524 20:43:07.764739 14843 net.cpp:157] Top shape: 80 196 (15680)
I0524 20:43:07.764752 14843 net.cpp:165] Memory required for data: 126139200
I0524 20:43:07.764767 14843 layer_factory.hpp:77] Creating layer drop1
I0524 20:43:07.764788 14843 net.cpp:106] Creating Layer drop1
I0524 20:43:07.764801 14843 net.cpp:454] drop1 <- ip1
I0524 20:43:07.764817 14843 net.cpp:397] drop1 -> ip1 (in-place)
I0524 20:43:07.764871 14843 net.cpp:150] Setting up drop1
I0524 20:43:07.764889 14843 net.cpp:157] Top shape: 80 196 (15680)
I0524 20:43:07.764902 14843 net.cpp:165] Memory required for data: 126201920
I0524 20:43:07.764914 14843 layer_factory.hpp:77] Creating layer ip2
I0524 20:43:07.764932 14843 net.cpp:106] Creating Layer ip2
I0524 20:43:07.764945 14843 net.cpp:454] ip2 <- ip1
I0524 20:43:07.764961 14843 net.cpp:411] ip2 -> ip2
I0524 20:43:07.765480 14843 net.cpp:150] Setting up ip2
I0524 20:43:07.765498 14843 net.cpp:157] Top shape: 80 98 (7840)
I0524 20:43:07.765511 14843 net.cpp:165] Memory required for data: 126233280
I0524 20:43:07.765533 14843 layer_factory.hpp:77] Creating layer relu6
I0524 20:43:07.765568 14843 net.cpp:106] Creating Layer relu6
I0524 20:43:07.765581 14843 net.cpp:454] relu6 <- ip2
I0524 20:43:07.765597 14843 net.cpp:397] relu6 -> ip2 (in-place)
I0524 20:43:07.766176 14843 net.cpp:150] Setting up relu6
I0524 20:43:07.766198 14843 net.cpp:157] Top shape: 80 98 (7840)
I0524 20:43:07.766212 14843 net.cpp:165] Memory required for data: 126264640
I0524 20:43:07.766225 14843 layer_factory.hpp:77] Creating layer drop2
I0524 20:43:07.766245 14843 net.cpp:106] Creating Layer drop2
I0524 20:43:07.766265 14843 net.cpp:454] drop2 <- ip2
I0524 20:43:07.766283 14843 net.cpp:397] drop2 -> ip2 (in-place)
I0524 20:43:07.766340 14843 net.cpp:150] Setting up drop2
I0524 20:43:07.766362 14843 net.cpp:157] Top shape: 80 98 (7840)
I0524 20:43:07.766376 14843 net.cpp:165] Memory required for data: 126296000
I0524 20:43:07.766387 14843 layer_factory.hpp:77] Creating layer ip3
I0524 20:43:07.766410 14843 net.cpp:106] Creating Layer ip3
I0524 20:43:07.766423 14843 net.cpp:454] ip3 <- ip2
I0524 20:43:07.766443 14843 net.cpp:411] ip3 -> ip3
I0524 20:43:07.766687 14843 net.cpp:150] Setting up ip3
I0524 20:43:07.766707 14843 net.cpp:157] Top shape: 80 11 (880)
I0524 20:43:07.766721 14843 net.cpp:165] Memory required for data: 126299520
I0524 20:43:07.766741 14843 layer_factory.hpp:77] Creating layer drop3
I0524 20:43:07.766763 14843 net.cpp:106] Creating Layer drop3
I0524 20:43:07.766777 14843 net.cpp:454] drop3 <- ip3
I0524 20:43:07.766793 14843 net.cpp:397] drop3 -> ip3 (in-place)
I0524 20:43:07.766847 14843 net.cpp:150] Setting up drop3
I0524 20:43:07.766865 14843 net.cpp:157] Top shape: 80 11 (880)
I0524 20:43:07.766876 14843 net.cpp:165] Memory required for data: 126303040
I0524 20:43:07.766890 14843 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0524 20:43:07.766904 14843 net.cpp:106] Creating Layer ip3_drop3_0_split
I0524 20:43:07.766919 14843 net.cpp:454] ip3_drop3_0_split <- ip3
I0524 20:43:07.766942 14843 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0524 20:43:07.766960 14843 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0524 20:43:07.767047 14843 net.cpp:150] Setting up ip3_drop3_0_split
I0524 20:43:07.767068 14843 net.cpp:157] Top shape: 80 11 (880)
I0524 20:43:07.767083 14843 net.cpp:157] Top shape: 80 11 (880)
I0524 20:43:07.767098 14843 net.cpp:165] Memory required for data: 126310080
I0524 20:43:07.767117 14843 layer_factory.hpp:77] Creating layer accuracy
I0524 20:43:07.767140 14843 net.cpp:106] Creating Layer accuracy
I0524 20:43:07.767160 14843 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0524 20:43:07.767175 14843 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0524 20:43:07.767191 14843 net.cpp:411] accuracy -> accuracy
I0524 20:43:07.767226 14843 net.cpp:150] Setting up accuracy
I0524 20:43:07.767243 14843 net.cpp:157] Top shape: (1)
I0524 20:43:07.767261 14843 net.cpp:165] Memory required for data: 126310084
I0524 20:43:07.767274 14843 layer_factory.hpp:77] Creating layer loss
I0524 20:43:07.767289 14843 net.cpp:106] Creating Layer loss
I0524 20:43:07.767305 14843 net.cpp:454] loss <- ip3_drop3_0_split_1
I0524 20:43:07.767325 14843 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0524 20:43:07.767343 14843 net.cpp:411] loss -> loss
I0524 20:43:07.767364 14843 layer_factory.hpp:77] Creating layer loss
I0524 20:43:07.767881 14843 net.cpp:150] Setting up loss
I0524 20:43:07.767901 14843 net.cpp:157] Top shape: (1)
I0524 20:43:07.767915 14843 net.cpp:160]     with loss weight 1
I0524 20:43:07.767938 14843 net.cpp:165] Memory required for data: 126310088
I0524 20:43:07.767951 14843 net.cpp:226] loss needs backward computation.
I0524 20:43:07.767966 14843 net.cpp:228] accuracy does not need backward computation.
I0524 20:43:07.767987 14843 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0524 20:43:07.767999 14843 net.cpp:226] drop3 needs backward computation.
I0524 20:43:07.768012 14843 net.cpp:226] ip3 needs backward computation.
I0524 20:43:07.768028 14843 net.cpp:226] drop2 needs backward computation.
I0524 20:43:07.768039 14843 net.cpp:226] relu6 needs backward computation.
I0524 20:43:07.768067 14843 net.cpp:226] ip2 needs backward computation.
I0524 20:43:07.768085 14843 net.cpp:226] drop1 needs backward computation.
I0524 20:43:07.768098 14843 net.cpp:226] relu5 needs backward computation.
I0524 20:43:07.768110 14843 net.cpp:226] ip1 needs backward computation.
I0524 20:43:07.768126 14843 net.cpp:226] pool4 needs backward computation.
I0524 20:43:07.768137 14843 net.cpp:226] relu4 needs backward computation.
I0524 20:43:07.768157 14843 net.cpp:226] conv4 needs backward computation.
I0524 20:43:07.768170 14843 net.cpp:226] pool3 needs backward computation.
I0524 20:43:07.768185 14843 net.cpp:226] relu3 needs backward computation.
I0524 20:43:07.768198 14843 net.cpp:226] conv3 needs backward computation.
I0524 20:43:07.768213 14843 net.cpp:226] pool2 needs backward computation.
I0524 20:43:07.768225 14843 net.cpp:226] relu2 needs backward computation.
I0524 20:43:07.768239 14843 net.cpp:226] conv2 needs backward computation.
I0524 20:43:07.768260 14843 net.cpp:226] pool1 needs backward computation.
I0524 20:43:07.768276 14843 net.cpp:226] relu1 needs backward computation.
I0524 20:43:07.768290 14843 net.cpp:226] conv1 needs backward computation.
I0524 20:43:07.768303 14843 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0524 20:43:07.768321 14843 net.cpp:228] data_hdf5 does not need backward computation.
I0524 20:43:07.768332 14843 net.cpp:270] This network produces output accuracy
I0524 20:43:07.768352 14843 net.cpp:270] This network produces output loss
I0524 20:43:07.768383 14843 net.cpp:283] Network initialization done.
I0524 20:43:07.768522 14843 solver.cpp:60] Solver scaffolding done.
I0524 20:43:07.769695 14843 caffe.cpp:212] Starting Optimization
I0524 20:43:07.769712 14843 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0524 20:43:07.769729 14843 solver.cpp:289] Learning Rate Policy: fixed
I0524 20:43:07.770845 14843 solver.cpp:341] Iteration 0, Testing net (#0)
I0524 20:43:56.073948 14843 solver.cpp:409]     Test net output #0: accuracy = 0.0956666
I0524 20:43:56.074117 14843 solver.cpp:409]     Test net output #1: loss = 2.39807 (* 1 = 2.39807 loss)
I0524 20:43:56.103611 14843 solver.cpp:237] Iteration 0, loss = 2.40245
I0524 20:43:56.103649 14843 solver.cpp:253]     Train net output #0: loss = 2.40245 (* 1 = 2.40245 loss)
I0524 20:43:56.103670 14843 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0524 20:44:04.756281 14843 solver.cpp:237] Iteration 187, loss = 2.27029
I0524 20:44:04.756319 14843 solver.cpp:253]     Train net output #0: loss = 2.27029 (* 1 = 2.27029 loss)
I0524 20:44:04.756342 14843 sgd_solver.cpp:106] Iteration 187, lr = 0.0025
I0524 20:44:13.409301 14843 solver.cpp:237] Iteration 374, loss = 2.13948
I0524 20:44:13.409351 14843 solver.cpp:253]     Train net output #0: loss = 2.13948 (* 1 = 2.13948 loss)
I0524 20:44:13.409375 14843 sgd_solver.cpp:106] Iteration 374, lr = 0.0025
I0524 20:44:22.064956 14843 solver.cpp:237] Iteration 561, loss = 1.82584
I0524 20:44:22.064993 14843 solver.cpp:253]     Train net output #0: loss = 1.82584 (* 1 = 1.82584 loss)
I0524 20:44:22.065012 14843 sgd_solver.cpp:106] Iteration 561, lr = 0.0025
I0524 20:44:30.721810 14843 solver.cpp:237] Iteration 748, loss = 1.95567
I0524 20:44:30.721963 14843 solver.cpp:253]     Train net output #0: loss = 1.95567 (* 1 = 1.95567 loss)
I0524 20:44:30.721981 14843 sgd_solver.cpp:106] Iteration 748, lr = 0.0025
I0524 20:44:39.382035 14843 solver.cpp:237] Iteration 935, loss = 1.89304
I0524 20:44:39.382091 14843 solver.cpp:253]     Train net output #0: loss = 1.89304 (* 1 = 1.89304 loss)
I0524 20:44:39.382110 14843 sgd_solver.cpp:106] Iteration 935, lr = 0.0025
I0524 20:44:48.039647 14843 solver.cpp:237] Iteration 1122, loss = 2.01099
I0524 20:44:48.039690 14843 solver.cpp:253]     Train net output #0: loss = 2.01099 (* 1 = 2.01099 loss)
I0524 20:44:48.039706 14843 sgd_solver.cpp:106] Iteration 1122, lr = 0.0025
I0524 20:45:18.817251 14843 solver.cpp:237] Iteration 1309, loss = 1.73912
I0524 20:45:18.817415 14843 solver.cpp:253]     Train net output #0: loss = 1.73912 (* 1 = 1.73912 loss)
I0524 20:45:18.817432 14843 sgd_solver.cpp:106] Iteration 1309, lr = 0.0025
I0524 20:45:27.484031 14843 solver.cpp:237] Iteration 1496, loss = 1.75357
I0524 20:45:27.484078 14843 solver.cpp:253]     Train net output #0: loss = 1.75357 (* 1 = 1.75357 loss)
I0524 20:45:27.484103 14843 sgd_solver.cpp:106] Iteration 1496, lr = 0.0025
I0524 20:45:36.151116 14843 solver.cpp:237] Iteration 1683, loss = 1.74361
I0524 20:45:36.151154 14843 solver.cpp:253]     Train net output #0: loss = 1.74361 (* 1 = 1.74361 loss)
I0524 20:45:36.151172 14843 sgd_solver.cpp:106] Iteration 1683, lr = 0.0025
I0524 20:45:44.820164 14843 solver.cpp:237] Iteration 1870, loss = 1.75232
I0524 20:45:44.820200 14843 solver.cpp:253]     Train net output #0: loss = 1.75232 (* 1 = 1.75232 loss)
I0524 20:45:44.820224 14843 sgd_solver.cpp:106] Iteration 1870, lr = 0.0025
I0524 20:45:45.005882 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_1875.caffemodel
I0524 20:45:45.079449 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_1875.solverstate
I0524 20:45:53.541154 14843 solver.cpp:237] Iteration 2057, loss = 1.64359
I0524 20:45:53.541316 14843 solver.cpp:253]     Train net output #0: loss = 1.64359 (* 1 = 1.64359 loss)
I0524 20:45:53.541335 14843 sgd_solver.cpp:106] Iteration 2057, lr = 0.0025
I0524 20:46:02.189503 14843 solver.cpp:237] Iteration 2244, loss = 1.70914
I0524 20:46:02.189540 14843 solver.cpp:253]     Train net output #0: loss = 1.70914 (* 1 = 1.70914 loss)
I0524 20:46:02.189563 14843 sgd_solver.cpp:106] Iteration 2244, lr = 0.0025
I0524 20:46:10.836182 14843 solver.cpp:237] Iteration 2431, loss = 1.63625
I0524 20:46:10.836239 14843 solver.cpp:253]     Train net output #0: loss = 1.63625 (* 1 = 1.63625 loss)
I0524 20:46:10.836268 14843 sgd_solver.cpp:106] Iteration 2431, lr = 0.0025
I0524 20:46:41.609174 14843 solver.cpp:237] Iteration 2618, loss = 1.64197
I0524 20:46:41.609333 14843 solver.cpp:253]     Train net output #0: loss = 1.64197 (* 1 = 1.64197 loss)
I0524 20:46:41.609350 14843 sgd_solver.cpp:106] Iteration 2618, lr = 0.0025
I0524 20:46:50.256688 14843 solver.cpp:237] Iteration 2805, loss = 1.6106
I0524 20:46:50.256724 14843 solver.cpp:253]     Train net output #0: loss = 1.6106 (* 1 = 1.6106 loss)
I0524 20:46:50.256748 14843 sgd_solver.cpp:106] Iteration 2805, lr = 0.0025
I0524 20:46:58.906384 14843 solver.cpp:237] Iteration 2992, loss = 1.68122
I0524 20:46:58.906421 14843 solver.cpp:253]     Train net output #0: loss = 1.68122 (* 1 = 1.68122 loss)
I0524 20:46:58.906440 14843 sgd_solver.cpp:106] Iteration 2992, lr = 0.0025
I0524 20:47:07.556290 14843 solver.cpp:237] Iteration 3179, loss = 1.6146
I0524 20:47:07.556339 14843 solver.cpp:253]     Train net output #0: loss = 1.6146 (* 1 = 1.6146 loss)
I0524 20:47:07.556361 14843 sgd_solver.cpp:106] Iteration 3179, lr = 0.0025
I0524 20:47:16.205256 14843 solver.cpp:237] Iteration 3366, loss = 1.64457
I0524 20:47:16.205410 14843 solver.cpp:253]     Train net output #0: loss = 1.64457 (* 1 = 1.64457 loss)
I0524 20:47:16.205425 14843 sgd_solver.cpp:106] Iteration 3366, lr = 0.0025
I0524 20:47:24.855135 14843 solver.cpp:237] Iteration 3553, loss = 1.46303
I0524 20:47:24.855171 14843 solver.cpp:253]     Train net output #0: loss = 1.46303 (* 1 = 1.46303 loss)
I0524 20:47:24.855195 14843 sgd_solver.cpp:106] Iteration 3553, lr = 0.0025
I0524 20:47:33.503682 14843 solver.cpp:237] Iteration 3740, loss = 1.61851
I0524 20:47:33.503725 14843 solver.cpp:253]     Train net output #0: loss = 1.61851 (* 1 = 1.61851 loss)
I0524 20:47:33.503741 14843 sgd_solver.cpp:106] Iteration 3740, lr = 0.0025
I0524 20:47:33.919795 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_3750.caffemodel
I0524 20:47:33.989797 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_3750.solverstate
I0524 20:47:34.015573 14843 solver.cpp:341] Iteration 3750, Testing net (#0)
I0524 20:48:21.385277 14843 solver.cpp:409]     Test net output #0: accuracy = 0.746074
I0524 20:48:21.385438 14843 solver.cpp:409]     Test net output #1: loss = 0.91752 (* 1 = 0.91752 loss)
I0524 20:48:51.674583 14843 solver.cpp:237] Iteration 3927, loss = 1.44987
I0524 20:48:51.674741 14843 solver.cpp:253]     Train net output #0: loss = 1.44987 (* 1 = 1.44987 loss)
I0524 20:48:51.674759 14843 sgd_solver.cpp:106] Iteration 3927, lr = 0.0025
I0524 20:49:00.331744 14843 solver.cpp:237] Iteration 4114, loss = 1.21385
I0524 20:49:00.331782 14843 solver.cpp:253]     Train net output #0: loss = 1.21385 (* 1 = 1.21385 loss)
I0524 20:49:00.331801 14843 sgd_solver.cpp:106] Iteration 4114, lr = 0.0025
I0524 20:49:08.984546 14843 solver.cpp:237] Iteration 4301, loss = 1.57139
I0524 20:49:08.984599 14843 solver.cpp:253]     Train net output #0: loss = 1.57139 (* 1 = 1.57139 loss)
I0524 20:49:08.984625 14843 sgd_solver.cpp:106] Iteration 4301, lr = 0.0025
I0524 20:49:17.636358 14843 solver.cpp:237] Iteration 4488, loss = 1.40665
I0524 20:49:17.636396 14843 solver.cpp:253]     Train net output #0: loss = 1.40665 (* 1 = 1.40665 loss)
I0524 20:49:17.636415 14843 sgd_solver.cpp:106] Iteration 4488, lr = 0.0025
I0524 20:49:26.296748 14843 solver.cpp:237] Iteration 4675, loss = 1.48848
I0524 20:49:26.296885 14843 solver.cpp:253]     Train net output #0: loss = 1.48848 (* 1 = 1.48848 loss)
I0524 20:49:26.296902 14843 sgd_solver.cpp:106] Iteration 4675, lr = 0.0025
I0524 20:49:34.950022 14843 solver.cpp:237] Iteration 4862, loss = 1.41314
I0524 20:49:34.950070 14843 solver.cpp:253]     Train net output #0: loss = 1.41314 (* 1 = 1.41314 loss)
I0524 20:49:34.950093 14843 sgd_solver.cpp:106] Iteration 4862, lr = 0.0025
I0524 20:50:05.750952 14843 solver.cpp:237] Iteration 5049, loss = 1.36164
I0524 20:50:05.751118 14843 solver.cpp:253]     Train net output #0: loss = 1.36164 (* 1 = 1.36164 loss)
I0524 20:50:05.751137 14843 sgd_solver.cpp:106] Iteration 5049, lr = 0.0025
I0524 20:50:14.404732 14843 solver.cpp:237] Iteration 5236, loss = 1.59291
I0524 20:50:14.404769 14843 solver.cpp:253]     Train net output #0: loss = 1.59291 (* 1 = 1.59291 loss)
I0524 20:50:14.404788 14843 sgd_solver.cpp:106] Iteration 5236, lr = 0.0025
I0524 20:50:23.061987 14843 solver.cpp:237] Iteration 5423, loss = 1.29633
I0524 20:50:23.062041 14843 solver.cpp:253]     Train net output #0: loss = 1.29633 (* 1 = 1.29633 loss)
I0524 20:50:23.062064 14843 sgd_solver.cpp:106] Iteration 5423, lr = 0.0025
I0524 20:50:31.714793 14843 solver.cpp:237] Iteration 5610, loss = 1.34618
I0524 20:50:31.714833 14843 solver.cpp:253]     Train net output #0: loss = 1.34618 (* 1 = 1.34618 loss)
I0524 20:50:31.714850 14843 sgd_solver.cpp:106] Iteration 5610, lr = 0.0025
I0524 20:50:32.362172 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_5625.caffemodel
I0524 20:50:32.434654 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_5625.solverstate
I0524 20:50:40.433114 14843 solver.cpp:237] Iteration 5797, loss = 1.40621
I0524 20:50:40.433284 14843 solver.cpp:253]     Train net output #0: loss = 1.40621 (* 1 = 1.40621 loss)
I0524 20:50:40.433301 14843 sgd_solver.cpp:106] Iteration 5797, lr = 0.0025
I0524 20:50:49.084799 14843 solver.cpp:237] Iteration 5984, loss = 1.62075
I0524 20:50:49.084851 14843 solver.cpp:253]     Train net output #0: loss = 1.62075 (* 1 = 1.62075 loss)
I0524 20:50:49.084879 14843 sgd_solver.cpp:106] Iteration 5984, lr = 0.0025
I0524 20:50:57.737406 14843 solver.cpp:237] Iteration 6171, loss = 1.56315
I0524 20:50:57.737442 14843 solver.cpp:253]     Train net output #0: loss = 1.56315 (* 1 = 1.56315 loss)
I0524 20:50:57.737465 14843 sgd_solver.cpp:106] Iteration 6171, lr = 0.0025
I0524 20:51:28.584332 14843 solver.cpp:237] Iteration 6358, loss = 1.34258
I0524 20:51:28.584496 14843 solver.cpp:253]     Train net output #0: loss = 1.34258 (* 1 = 1.34258 loss)
I0524 20:51:28.584513 14843 sgd_solver.cpp:106] Iteration 6358, lr = 0.0025
I0524 20:51:37.244298 14843 solver.cpp:237] Iteration 6545, loss = 1.18068
I0524 20:51:37.244354 14843 solver.cpp:253]     Train net output #0: loss = 1.18068 (* 1 = 1.18068 loss)
I0524 20:51:37.244379 14843 sgd_solver.cpp:106] Iteration 6545, lr = 0.0025
I0524 20:51:45.903659 14843 solver.cpp:237] Iteration 6732, loss = 1.22999
I0524 20:51:45.903699 14843 solver.cpp:253]     Train net output #0: loss = 1.22999 (* 1 = 1.22999 loss)
I0524 20:51:45.903717 14843 sgd_solver.cpp:106] Iteration 6732, lr = 0.0025
I0524 20:51:54.560297 14843 solver.cpp:237] Iteration 6919, loss = 1.32563
I0524 20:51:54.560334 14843 solver.cpp:253]     Train net output #0: loss = 1.32563 (* 1 = 1.32563 loss)
I0524 20:51:54.560353 14843 sgd_solver.cpp:106] Iteration 6919, lr = 0.0025
I0524 20:52:03.221508 14843 solver.cpp:237] Iteration 7106, loss = 1.3941
I0524 20:52:03.221665 14843 solver.cpp:253]     Train net output #0: loss = 1.3941 (* 1 = 1.3941 loss)
I0524 20:52:03.221683 14843 sgd_solver.cpp:106] Iteration 7106, lr = 0.0025
I0524 20:52:11.878116 14843 solver.cpp:237] Iteration 7293, loss = 1.21539
I0524 20:52:11.878151 14843 solver.cpp:253]     Train net output #0: loss = 1.21539 (* 1 = 1.21539 loss)
I0524 20:52:11.878175 14843 sgd_solver.cpp:106] Iteration 7293, lr = 0.0025
I0524 20:52:20.537889 14843 solver.cpp:237] Iteration 7480, loss = 1.31919
I0524 20:52:20.537926 14843 solver.cpp:253]     Train net output #0: loss = 1.31919 (* 1 = 1.31919 loss)
I0524 20:52:20.537950 14843 sgd_solver.cpp:106] Iteration 7480, lr = 0.0025
I0524 20:52:21.418431 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_7500.caffemodel
I0524 20:52:21.490819 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_7500.solverstate
I0524 20:52:21.518046 14843 solver.cpp:341] Iteration 7500, Testing net (#0)
I0524 20:53:29.868624 14843 solver.cpp:409]     Test net output #0: accuracy = 0.819047
I0524 20:53:29.868798 14843 solver.cpp:409]     Test net output #1: loss = 0.664433 (* 1 = 0.664433 loss)
I0524 20:53:59.749622 14843 solver.cpp:237] Iteration 7667, loss = 1.44844
I0524 20:53:59.749676 14843 solver.cpp:253]     Train net output #0: loss = 1.44844 (* 1 = 1.44844 loss)
I0524 20:53:59.749701 14843 sgd_solver.cpp:106] Iteration 7667, lr = 0.0025
I0524 20:54:08.415073 14843 solver.cpp:237] Iteration 7854, loss = 1.11826
I0524 20:54:08.415233 14843 solver.cpp:253]     Train net output #0: loss = 1.11826 (* 1 = 1.11826 loss)
I0524 20:54:08.415251 14843 sgd_solver.cpp:106] Iteration 7854, lr = 0.0025
I0524 20:54:17.061403 14843 solver.cpp:237] Iteration 8041, loss = 1.43533
I0524 20:54:17.061440 14843 solver.cpp:253]     Train net output #0: loss = 1.43533 (* 1 = 1.43533 loss)
I0524 20:54:17.061458 14843 sgd_solver.cpp:106] Iteration 8041, lr = 0.0025
I0524 20:54:25.708137 14843 solver.cpp:237] Iteration 8228, loss = 1.27198
I0524 20:54:25.708173 14843 solver.cpp:253]     Train net output #0: loss = 1.27198 (* 1 = 1.27198 loss)
I0524 20:54:25.708197 14843 sgd_solver.cpp:106] Iteration 8228, lr = 0.0025
I0524 20:54:34.356535 14843 solver.cpp:237] Iteration 8415, loss = 1.4061
I0524 20:54:34.356585 14843 solver.cpp:253]     Train net output #0: loss = 1.4061 (* 1 = 1.4061 loss)
I0524 20:54:34.356603 14843 sgd_solver.cpp:106] Iteration 8415, lr = 0.0025
I0524 20:54:42.999883 14843 solver.cpp:237] Iteration 8602, loss = 1.08443
I0524 20:54:43.000030 14843 solver.cpp:253]     Train net output #0: loss = 1.08443 (* 1 = 1.08443 loss)
I0524 20:54:43.000046 14843 sgd_solver.cpp:106] Iteration 8602, lr = 0.0025
I0524 20:55:13.807399 14843 solver.cpp:237] Iteration 8789, loss = 1.2962
I0524 20:55:13.807562 14843 solver.cpp:253]     Train net output #0: loss = 1.2962 (* 1 = 1.2962 loss)
I0524 20:55:13.807580 14843 sgd_solver.cpp:106] Iteration 8789, lr = 0.0025
I0524 20:55:22.455215 14843 solver.cpp:237] Iteration 8976, loss = 1.10323
I0524 20:55:22.455271 14843 solver.cpp:253]     Train net output #0: loss = 1.10323 (* 1 = 1.10323 loss)
I0524 20:55:22.455296 14843 sgd_solver.cpp:106] Iteration 8976, lr = 0.0025
I0524 20:55:31.103044 14843 solver.cpp:237] Iteration 9163, loss = 1.37912
I0524 20:55:31.103081 14843 solver.cpp:253]     Train net output #0: loss = 1.37912 (* 1 = 1.37912 loss)
I0524 20:55:31.103101 14843 sgd_solver.cpp:106] Iteration 9163, lr = 0.0025
I0524 20:55:39.745291 14843 solver.cpp:237] Iteration 9350, loss = 1.17747
I0524 20:55:39.745329 14843 solver.cpp:253]     Train net output #0: loss = 1.17747 (* 1 = 1.17747 loss)
I0524 20:55:39.745347 14843 sgd_solver.cpp:106] Iteration 9350, lr = 0.0025
I0524 20:55:40.854288 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_9375.caffemodel
I0524 20:55:40.926043 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_9375.solverstate
I0524 20:55:48.598479 14843 solver.cpp:237] Iteration 9537, loss = 1.37805
I0524 20:55:48.598644 14843 solver.cpp:253]     Train net output #0: loss = 1.37805 (* 1 = 1.37805 loss)
I0524 20:55:48.598662 14843 sgd_solver.cpp:106] Iteration 9537, lr = 0.0025
I0524 20:55:57.260757 14843 solver.cpp:237] Iteration 9724, loss = 1.359
I0524 20:55:57.260794 14843 solver.cpp:253]     Train net output #0: loss = 1.359 (* 1 = 1.359 loss)
I0524 20:55:57.260813 14843 sgd_solver.cpp:106] Iteration 9724, lr = 0.0025
I0524 20:56:05.926412 14843 solver.cpp:237] Iteration 9911, loss = 1.43155
I0524 20:56:05.926450 14843 solver.cpp:253]     Train net output #0: loss = 1.43155 (* 1 = 1.43155 loss)
I0524 20:56:05.926468 14843 sgd_solver.cpp:106] Iteration 9911, lr = 0.0025
I0524 20:56:36.778900 14843 solver.cpp:237] Iteration 10098, loss = 1.30862
I0524 20:56:36.779080 14843 solver.cpp:253]     Train net output #0: loss = 1.30862 (* 1 = 1.30862 loss)
I0524 20:56:36.779098 14843 sgd_solver.cpp:106] Iteration 10098, lr = 0.0025
I0524 20:56:45.457031 14843 solver.cpp:237] Iteration 10285, loss = 1.34121
I0524 20:56:45.457068 14843 solver.cpp:253]     Train net output #0: loss = 1.34121 (* 1 = 1.34121 loss)
I0524 20:56:45.457087 14843 sgd_solver.cpp:106] Iteration 10285, lr = 0.0025
I0524 20:56:54.135505 14843 solver.cpp:237] Iteration 10472, loss = 1.54351
I0524 20:56:54.135541 14843 solver.cpp:253]     Train net output #0: loss = 1.54351 (* 1 = 1.54351 loss)
I0524 20:56:54.135565 14843 sgd_solver.cpp:106] Iteration 10472, lr = 0.0025
I0524 20:57:02.811779 14843 solver.cpp:237] Iteration 10659, loss = 1.27239
I0524 20:57:02.811835 14843 solver.cpp:253]     Train net output #0: loss = 1.27239 (* 1 = 1.27239 loss)
I0524 20:57:02.811853 14843 sgd_solver.cpp:106] Iteration 10659, lr = 0.0025
I0524 20:57:11.485043 14843 solver.cpp:237] Iteration 10846, loss = 1.1542
I0524 20:57:11.485193 14843 solver.cpp:253]     Train net output #0: loss = 1.1542 (* 1 = 1.1542 loss)
I0524 20:57:11.485209 14843 sgd_solver.cpp:106] Iteration 10846, lr = 0.0025
I0524 20:57:20.157112 14843 solver.cpp:237] Iteration 11033, loss = 1.25826
I0524 20:57:20.157150 14843 solver.cpp:253]     Train net output #0: loss = 1.25826 (* 1 = 1.25826 loss)
I0524 20:57:20.157168 14843 sgd_solver.cpp:106] Iteration 11033, lr = 0.0025
I0524 20:57:28.829776 14843 solver.cpp:237] Iteration 11220, loss = 1.17536
I0524 20:57:28.829829 14843 solver.cpp:253]     Train net output #0: loss = 1.17536 (* 1 = 1.17536 loss)
I0524 20:57:28.829854 14843 sgd_solver.cpp:106] Iteration 11220, lr = 0.0025
I0524 20:57:30.172256 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_11250.caffemodel
I0524 20:57:30.243600 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_11250.solverstate
I0524 20:57:30.269690 14843 solver.cpp:341] Iteration 11250, Testing net (#0)
I0524 20:58:17.375289 14843 solver.cpp:409]     Test net output #0: accuracy = 0.837333
I0524 20:58:17.375453 14843 solver.cpp:409]     Test net output #1: loss = 0.553729 (* 1 = 0.553729 loss)
I0524 20:58:46.778900 14843 solver.cpp:237] Iteration 11407, loss = 1.08796
I0524 20:58:46.778956 14843 solver.cpp:253]     Train net output #0: loss = 1.08796 (* 1 = 1.08796 loss)
I0524 20:58:46.778980 14843 sgd_solver.cpp:106] Iteration 11407, lr = 0.0025
I0524 20:58:55.439283 14843 solver.cpp:237] Iteration 11594, loss = 1.30983
I0524 20:58:55.439435 14843 solver.cpp:253]     Train net output #0: loss = 1.30983 (* 1 = 1.30983 loss)
I0524 20:58:55.439451 14843 sgd_solver.cpp:106] Iteration 11594, lr = 0.0025
I0524 20:59:04.095497 14843 solver.cpp:237] Iteration 11781, loss = 1.23684
I0524 20:59:04.095535 14843 solver.cpp:253]     Train net output #0: loss = 1.23684 (* 1 = 1.23684 loss)
I0524 20:59:04.095558 14843 sgd_solver.cpp:106] Iteration 11781, lr = 0.0025
I0524 20:59:12.759433 14843 solver.cpp:237] Iteration 11968, loss = 1.2295
I0524 20:59:12.759485 14843 solver.cpp:253]     Train net output #0: loss = 1.2295 (* 1 = 1.2295 loss)
I0524 20:59:12.759510 14843 sgd_solver.cpp:106] Iteration 11968, lr = 0.0025
I0524 20:59:21.422520 14843 solver.cpp:237] Iteration 12155, loss = 1.14916
I0524 20:59:21.422556 14843 solver.cpp:253]     Train net output #0: loss = 1.14916 (* 1 = 1.14916 loss)
I0524 20:59:21.422580 14843 sgd_solver.cpp:106] Iteration 12155, lr = 0.0025
I0524 20:59:30.084765 14843 solver.cpp:237] Iteration 12342, loss = 1.15625
I0524 20:59:30.084913 14843 solver.cpp:253]     Train net output #0: loss = 1.15625 (* 1 = 1.15625 loss)
I0524 20:59:30.084929 14843 sgd_solver.cpp:106] Iteration 12342, lr = 0.0025
I0524 21:00:00.862691 14843 solver.cpp:237] Iteration 12529, loss = 1.16516
I0524 21:00:00.862869 14843 solver.cpp:253]     Train net output #0: loss = 1.16516 (* 1 = 1.16516 loss)
I0524 21:00:00.862887 14843 sgd_solver.cpp:106] Iteration 12529, lr = 0.0025
I0524 21:00:09.518672 14843 solver.cpp:237] Iteration 12716, loss = 1.43906
I0524 21:00:09.518712 14843 solver.cpp:253]     Train net output #0: loss = 1.43906 (* 1 = 1.43906 loss)
I0524 21:00:09.518729 14843 sgd_solver.cpp:106] Iteration 12716, lr = 0.0025
I0524 21:00:18.175652 14843 solver.cpp:237] Iteration 12903, loss = 1.30504
I0524 21:00:18.175690 14843 solver.cpp:253]     Train net output #0: loss = 1.30504 (* 1 = 1.30504 loss)
I0524 21:00:18.175709 14843 sgd_solver.cpp:106] Iteration 12903, lr = 0.0025
I0524 21:00:26.837471 14843 solver.cpp:237] Iteration 13090, loss = 1.21026
I0524 21:00:26.837524 14843 solver.cpp:253]     Train net output #0: loss = 1.21026 (* 1 = 1.21026 loss)
I0524 21:00:26.837550 14843 sgd_solver.cpp:106] Iteration 13090, lr = 0.0025
I0524 21:00:28.409556 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_13125.caffemodel
I0524 21:00:28.480027 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_13125.solverstate
I0524 21:00:35.558573 14843 solver.cpp:237] Iteration 13277, loss = 1.25884
I0524 21:00:35.558739 14843 solver.cpp:253]     Train net output #0: loss = 1.25884 (* 1 = 1.25884 loss)
I0524 21:00:35.558756 14843 sgd_solver.cpp:106] Iteration 13277, lr = 0.0025
I0524 21:00:44.216625 14843 solver.cpp:237] Iteration 13464, loss = 1.44606
I0524 21:00:44.216662 14843 solver.cpp:253]     Train net output #0: loss = 1.44606 (* 1 = 1.44606 loss)
I0524 21:00:44.216686 14843 sgd_solver.cpp:106] Iteration 13464, lr = 0.0025
I0524 21:00:52.872330 14843 solver.cpp:237] Iteration 13651, loss = 1.45566
I0524 21:00:52.872377 14843 solver.cpp:253]     Train net output #0: loss = 1.45566 (* 1 = 1.45566 loss)
I0524 21:00:52.872405 14843 sgd_solver.cpp:106] Iteration 13651, lr = 0.0025
I0524 21:01:23.697897 14843 solver.cpp:237] Iteration 13838, loss = 1.18974
I0524 21:01:23.698071 14843 solver.cpp:253]     Train net output #0: loss = 1.18974 (* 1 = 1.18974 loss)
I0524 21:01:23.698094 14843 sgd_solver.cpp:106] Iteration 13838, lr = 0.0025
I0524 21:01:32.358484 14843 solver.cpp:237] Iteration 14025, loss = 1.35387
I0524 21:01:32.358521 14843 solver.cpp:253]     Train net output #0: loss = 1.35387 (* 1 = 1.35387 loss)
I0524 21:01:32.358537 14843 sgd_solver.cpp:106] Iteration 14025, lr = 0.0025
I0524 21:01:41.020900 14843 solver.cpp:237] Iteration 14212, loss = 1.41362
I0524 21:01:41.020953 14843 solver.cpp:253]     Train net output #0: loss = 1.41362 (* 1 = 1.41362 loss)
I0524 21:01:41.020979 14843 sgd_solver.cpp:106] Iteration 14212, lr = 0.0025
I0524 21:01:49.679574 14843 solver.cpp:237] Iteration 14399, loss = 1.2171
I0524 21:01:49.679611 14843 solver.cpp:253]     Train net output #0: loss = 1.2171 (* 1 = 1.2171 loss)
I0524 21:01:49.679630 14843 sgd_solver.cpp:106] Iteration 14399, lr = 0.0025
I0524 21:01:58.341178 14843 solver.cpp:237] Iteration 14586, loss = 1.57131
I0524 21:01:58.341326 14843 solver.cpp:253]     Train net output #0: loss = 1.57131 (* 1 = 1.57131 loss)
I0524 21:01:58.341342 14843 sgd_solver.cpp:106] Iteration 14586, lr = 0.0025
I0524 21:02:07.005333 14843 solver.cpp:237] Iteration 14773, loss = 1.6878
I0524 21:02:07.005383 14843 solver.cpp:253]     Train net output #0: loss = 1.6878 (* 1 = 1.6878 loss)
I0524 21:02:07.005401 14843 sgd_solver.cpp:106] Iteration 14773, lr = 0.0025
I0524 21:02:15.664064 14843 solver.cpp:237] Iteration 14960, loss = 1.19285
I0524 21:02:15.664103 14843 solver.cpp:253]     Train net output #0: loss = 1.19285 (* 1 = 1.19285 loss)
I0524 21:02:15.664126 14843 sgd_solver.cpp:106] Iteration 14960, lr = 0.0025
I0524 21:02:17.468106 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_15000.caffemodel
I0524 21:02:17.538111 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_15000.solverstate
I0524 21:02:17.564132 14843 solver.cpp:341] Iteration 15000, Testing net (#0)
I0524 21:03:25.760107 14843 solver.cpp:409]     Test net output #0: accuracy = 0.85246
I0524 21:03:25.760282 14843 solver.cpp:409]     Test net output #1: loss = 0.478984 (* 1 = 0.478984 loss)
I0524 21:03:54.737344 14843 solver.cpp:237] Iteration 15147, loss = 1.28329
I0524 21:03:54.737399 14843 solver.cpp:253]     Train net output #0: loss = 1.28329 (* 1 = 1.28329 loss)
I0524 21:03:54.737424 14843 sgd_solver.cpp:106] Iteration 15147, lr = 0.0025
I0524 21:04:03.407960 14843 solver.cpp:237] Iteration 15334, loss = 1.27968
I0524 21:04:03.408129 14843 solver.cpp:253]     Train net output #0: loss = 1.27968 (* 1 = 1.27968 loss)
I0524 21:04:03.408146 14843 sgd_solver.cpp:106] Iteration 15334, lr = 0.0025
I0524 21:04:12.059607 14843 solver.cpp:237] Iteration 15521, loss = 1.23084
I0524 21:04:12.059656 14843 solver.cpp:253]     Train net output #0: loss = 1.23084 (* 1 = 1.23084 loss)
I0524 21:04:12.059684 14843 sgd_solver.cpp:106] Iteration 15521, lr = 0.0025
I0524 21:04:20.710216 14843 solver.cpp:237] Iteration 15708, loss = 1.21934
I0524 21:04:20.710253 14843 solver.cpp:253]     Train net output #0: loss = 1.21934 (* 1 = 1.21934 loss)
I0524 21:04:20.710275 14843 sgd_solver.cpp:106] Iteration 15708, lr = 0.0025
I0524 21:04:29.358978 14843 solver.cpp:237] Iteration 15895, loss = 1.31033
I0524 21:04:29.359014 14843 solver.cpp:253]     Train net output #0: loss = 1.31033 (* 1 = 1.31033 loss)
I0524 21:04:29.359038 14843 sgd_solver.cpp:106] Iteration 15895, lr = 0.0025
I0524 21:04:38.006788 14843 solver.cpp:237] Iteration 16082, loss = 1.31956
I0524 21:04:38.006942 14843 solver.cpp:253]     Train net output #0: loss = 1.31956 (* 1 = 1.31956 loss)
I0524 21:04:38.006958 14843 sgd_solver.cpp:106] Iteration 16082, lr = 0.0025
I0524 21:05:08.797216 14843 solver.cpp:237] Iteration 16269, loss = 1.35084
I0524 21:05:08.797392 14843 solver.cpp:253]     Train net output #0: loss = 1.35084 (* 1 = 1.35084 loss)
I0524 21:05:08.797410 14843 sgd_solver.cpp:106] Iteration 16269, lr = 0.0025
I0524 21:05:17.444705 14843 solver.cpp:237] Iteration 16456, loss = 1.30736
I0524 21:05:17.444741 14843 solver.cpp:253]     Train net output #0: loss = 1.30736 (* 1 = 1.30736 loss)
I0524 21:05:17.444766 14843 sgd_solver.cpp:106] Iteration 16456, lr = 0.0025
I0524 21:05:26.094574 14843 solver.cpp:237] Iteration 16643, loss = 0.891729
I0524 21:05:26.094624 14843 solver.cpp:253]     Train net output #0: loss = 0.891729 (* 1 = 0.891729 loss)
I0524 21:05:26.094650 14843 sgd_solver.cpp:106] Iteration 16643, lr = 0.0025
I0524 21:05:34.742120 14843 solver.cpp:237] Iteration 16830, loss = 1.29025
I0524 21:05:34.742157 14843 solver.cpp:253]     Train net output #0: loss = 1.29025 (* 1 = 1.29025 loss)
I0524 21:05:34.742175 14843 sgd_solver.cpp:106] Iteration 16830, lr = 0.0025
I0524 21:05:36.777462 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_16875.caffemodel
I0524 21:05:36.847182 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_16875.solverstate
I0524 21:05:43.456341 14843 solver.cpp:237] Iteration 17017, loss = 1.08528
I0524 21:05:43.456508 14843 solver.cpp:253]     Train net output #0: loss = 1.08528 (* 1 = 1.08528 loss)
I0524 21:05:43.456526 14843 sgd_solver.cpp:106] Iteration 17017, lr = 0.0025
I0524 21:05:52.104035 14843 solver.cpp:237] Iteration 17204, loss = 1.28902
I0524 21:05:52.104084 14843 solver.cpp:253]     Train net output #0: loss = 1.28902 (* 1 = 1.28902 loss)
I0524 21:05:52.104110 14843 sgd_solver.cpp:106] Iteration 17204, lr = 0.0025
I0524 21:06:00.751588 14843 solver.cpp:237] Iteration 17391, loss = 1.11884
I0524 21:06:00.751624 14843 solver.cpp:253]     Train net output #0: loss = 1.11884 (* 1 = 1.11884 loss)
I0524 21:06:00.751647 14843 sgd_solver.cpp:106] Iteration 17391, lr = 0.0025
I0524 21:06:31.571949 14843 solver.cpp:237] Iteration 17578, loss = 1.25488
I0524 21:06:31.572139 14843 solver.cpp:253]     Train net output #0: loss = 1.25488 (* 1 = 1.25488 loss)
I0524 21:06:31.572156 14843 sgd_solver.cpp:106] Iteration 17578, lr = 0.0025
I0524 21:06:40.224309 14843 solver.cpp:237] Iteration 17765, loss = 1.13172
I0524 21:06:40.224364 14843 solver.cpp:253]     Train net output #0: loss = 1.13172 (* 1 = 1.13172 loss)
I0524 21:06:40.224390 14843 sgd_solver.cpp:106] Iteration 17765, lr = 0.0025
I0524 21:06:48.876869 14843 solver.cpp:237] Iteration 17952, loss = 1.10666
I0524 21:06:48.876907 14843 solver.cpp:253]     Train net output #0: loss = 1.10666 (* 1 = 1.10666 loss)
I0524 21:06:48.876925 14843 sgd_solver.cpp:106] Iteration 17952, lr = 0.0025
I0524 21:06:57.524833 14843 solver.cpp:237] Iteration 18139, loss = 1.38162
I0524 21:06:57.524870 14843 solver.cpp:253]     Train net output #0: loss = 1.38162 (* 1 = 1.38162 loss)
I0524 21:06:57.524893 14843 sgd_solver.cpp:106] Iteration 18139, lr = 0.0025
I0524 21:07:06.178833 14843 solver.cpp:237] Iteration 18326, loss = 1.13479
I0524 21:07:06.179002 14843 solver.cpp:253]     Train net output #0: loss = 1.13479 (* 1 = 1.13479 loss)
I0524 21:07:06.179018 14843 sgd_solver.cpp:106] Iteration 18326, lr = 0.0025
I0524 21:07:14.841116 14843 solver.cpp:237] Iteration 18513, loss = 1.1259
I0524 21:07:14.841158 14843 solver.cpp:253]     Train net output #0: loss = 1.1259 (* 1 = 1.1259 loss)
I0524 21:07:14.841174 14843 sgd_solver.cpp:106] Iteration 18513, lr = 0.0025
I0524 21:07:23.497109 14843 solver.cpp:237] Iteration 18700, loss = 1.59322
I0524 21:07:23.497146 14843 solver.cpp:253]     Train net output #0: loss = 1.59322 (* 1 = 1.59322 loss)
I0524 21:07:23.497164 14843 sgd_solver.cpp:106] Iteration 18700, lr = 0.0025
I0524 21:07:25.768069 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_18750.caffemodel
I0524 21:07:25.859470 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_18750.solverstate
I0524 21:07:25.888584 14843 solver.cpp:341] Iteration 18750, Testing net (#0)
I0524 21:08:13.303755 14843 solver.cpp:409]     Test net output #0: accuracy = 0.862219
I0524 21:08:13.303921 14843 solver.cpp:409]     Test net output #1: loss = 0.453404 (* 1 = 0.453404 loss)
I0524 21:08:40.535825 14843 solver.cpp:237] Iteration 18887, loss = 1.02624
I0524 21:08:40.535881 14843 solver.cpp:253]     Train net output #0: loss = 1.02624 (* 1 = 1.02624 loss)
I0524 21:08:40.535905 14843 sgd_solver.cpp:106] Iteration 18887, lr = 0.0025
I0524 21:08:49.188267 14843 solver.cpp:237] Iteration 19074, loss = 1.04995
I0524 21:08:49.188436 14843 solver.cpp:253]     Train net output #0: loss = 1.04995 (* 1 = 1.04995 loss)
I0524 21:08:49.188455 14843 sgd_solver.cpp:106] Iteration 19074, lr = 0.0025
I0524 21:08:57.838989 14843 solver.cpp:237] Iteration 19261, loss = 1.28779
I0524 21:08:57.839025 14843 solver.cpp:253]     Train net output #0: loss = 1.28779 (* 1 = 1.28779 loss)
I0524 21:08:57.839043 14843 sgd_solver.cpp:106] Iteration 19261, lr = 0.0025
I0524 21:09:06.494411 14843 solver.cpp:237] Iteration 19448, loss = 1.25279
I0524 21:09:06.494467 14843 solver.cpp:253]     Train net output #0: loss = 1.25279 (* 1 = 1.25279 loss)
I0524 21:09:06.494491 14843 sgd_solver.cpp:106] Iteration 19448, lr = 0.0025
I0524 21:09:15.148732 14843 solver.cpp:237] Iteration 19635, loss = 1.2517
I0524 21:09:15.148769 14843 solver.cpp:253]     Train net output #0: loss = 1.2517 (* 1 = 1.2517 loss)
I0524 21:09:15.148792 14843 sgd_solver.cpp:106] Iteration 19635, lr = 0.0025
I0524 21:09:23.802503 14843 solver.cpp:237] Iteration 19822, loss = 1.21006
I0524 21:09:23.802665 14843 solver.cpp:253]     Train net output #0: loss = 1.21006 (* 1 = 1.21006 loss)
I0524 21:09:23.802682 14843 sgd_solver.cpp:106] Iteration 19822, lr = 0.0025
I0524 21:09:53.352105 14843 solver.cpp:237] Iteration 20009, loss = 1.27503
I0524 21:09:53.352162 14843 solver.cpp:253]     Train net output #0: loss = 1.27503 (* 1 = 1.27503 loss)
I0524 21:09:53.352188 14843 sgd_solver.cpp:106] Iteration 20009, lr = 0.0025
I0524 21:10:02.007328 14843 solver.cpp:237] Iteration 20196, loss = 1.10814
I0524 21:10:02.007499 14843 solver.cpp:253]     Train net output #0: loss = 1.10814 (* 1 = 1.10814 loss)
I0524 21:10:02.007519 14843 sgd_solver.cpp:106] Iteration 20196, lr = 0.0025
I0524 21:10:10.668014 14843 solver.cpp:237] Iteration 20383, loss = 1.21307
I0524 21:10:10.668050 14843 solver.cpp:253]     Train net output #0: loss = 1.21307 (* 1 = 1.21307 loss)
I0524 21:10:10.668073 14843 sgd_solver.cpp:106] Iteration 20383, lr = 0.0025
I0524 21:10:19.328541 14843 solver.cpp:237] Iteration 20570, loss = 1.35098
I0524 21:10:19.328578 14843 solver.cpp:253]     Train net output #0: loss = 1.35098 (* 1 = 1.35098 loss)
I0524 21:10:19.328596 14843 sgd_solver.cpp:106] Iteration 20570, lr = 0.0025
I0524 21:10:21.827569 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_20625.caffemodel
I0524 21:10:21.896950 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_20625.solverstate
I0524 21:10:28.038516 14843 solver.cpp:237] Iteration 20757, loss = 1.39318
I0524 21:10:28.038568 14843 solver.cpp:253]     Train net output #0: loss = 1.39318 (* 1 = 1.39318 loss)
I0524 21:10:28.038585 14843 sgd_solver.cpp:106] Iteration 20757, lr = 0.0025
I0524 21:10:36.686092 14843 solver.cpp:237] Iteration 20944, loss = 1.34168
I0524 21:10:36.686245 14843 solver.cpp:253]     Train net output #0: loss = 1.34168 (* 1 = 1.34168 loss)
I0524 21:10:36.686262 14843 sgd_solver.cpp:106] Iteration 20944, lr = 0.0025
I0524 21:10:45.329430 14843 solver.cpp:237] Iteration 21131, loss = 1.22091
I0524 21:10:45.329468 14843 solver.cpp:253]     Train net output #0: loss = 1.22091 (* 1 = 1.22091 loss)
I0524 21:10:45.329490 14843 sgd_solver.cpp:106] Iteration 21131, lr = 0.0025
I0524 21:11:14.892426 14843 solver.cpp:237] Iteration 21318, loss = 1.11219
I0524 21:11:14.892596 14843 solver.cpp:253]     Train net output #0: loss = 1.11219 (* 1 = 1.11219 loss)
I0524 21:11:14.892616 14843 sgd_solver.cpp:106] Iteration 21318, lr = 0.0025
I0524 21:11:23.540135 14843 solver.cpp:237] Iteration 21505, loss = 1.24344
I0524 21:11:23.540172 14843 solver.cpp:253]     Train net output #0: loss = 1.24344 (* 1 = 1.24344 loss)
I0524 21:11:23.540191 14843 sgd_solver.cpp:106] Iteration 21505, lr = 0.0025
I0524 21:11:32.185495 14843 solver.cpp:237] Iteration 21692, loss = 1.25439
I0524 21:11:32.185534 14843 solver.cpp:253]     Train net output #0: loss = 1.25439 (* 1 = 1.25439 loss)
I0524 21:11:32.185550 14843 sgd_solver.cpp:106] Iteration 21692, lr = 0.0025
I0524 21:11:40.833586 14843 solver.cpp:237] Iteration 21879, loss = 1.09577
I0524 21:11:40.833639 14843 solver.cpp:253]     Train net output #0: loss = 1.09577 (* 1 = 1.09577 loss)
I0524 21:11:40.833664 14843 sgd_solver.cpp:106] Iteration 21879, lr = 0.0025
I0524 21:11:49.478914 14843 solver.cpp:237] Iteration 22066, loss = 1.41081
I0524 21:11:49.479063 14843 solver.cpp:253]     Train net output #0: loss = 1.41081 (* 1 = 1.41081 loss)
I0524 21:11:49.479079 14843 sgd_solver.cpp:106] Iteration 22066, lr = 0.0025
I0524 21:11:58.123576 14843 solver.cpp:237] Iteration 22253, loss = 1.44932
I0524 21:11:58.123615 14843 solver.cpp:253]     Train net output #0: loss = 1.44932 (* 1 = 1.44932 loss)
I0524 21:11:58.123632 14843 sgd_solver.cpp:106] Iteration 22253, lr = 0.0025
I0524 21:12:06.768980 14843 solver.cpp:237] Iteration 22440, loss = 1.5386
I0524 21:12:06.769032 14843 solver.cpp:253]     Train net output #0: loss = 1.5386 (* 1 = 1.5386 loss)
I0524 21:12:06.769057 14843 sgd_solver.cpp:106] Iteration 22440, lr = 0.0025
I0524 21:12:09.496057 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_22500.caffemodel
I0524 21:12:09.566882 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_22500.solverstate
I0524 21:12:09.593776 14843 solver.cpp:341] Iteration 22500, Testing net (#0)
I0524 21:13:17.967099 14843 solver.cpp:409]     Test net output #0: accuracy = 0.863533
I0524 21:13:17.967278 14843 solver.cpp:409]     Test net output #1: loss = 0.433354 (* 1 = 0.433354 loss)
I0524 21:13:44.780973 14843 solver.cpp:237] Iteration 22627, loss = 1.14065
I0524 21:13:44.781029 14843 solver.cpp:253]     Train net output #0: loss = 1.14065 (* 1 = 1.14065 loss)
I0524 21:13:44.781054 14843 sgd_solver.cpp:106] Iteration 22627, lr = 0.0025
I0524 21:13:53.433290 14843 solver.cpp:237] Iteration 22814, loss = 1.23612
I0524 21:13:53.433450 14843 solver.cpp:253]     Train net output #0: loss = 1.23612 (* 1 = 1.23612 loss)
I0524 21:13:53.433466 14843 sgd_solver.cpp:106] Iteration 22814, lr = 0.0025
I0524 21:14:02.085628 14843 solver.cpp:237] Iteration 23001, loss = 0.978768
I0524 21:14:02.085664 14843 solver.cpp:253]     Train net output #0: loss = 0.978768 (* 1 = 0.978768 loss)
I0524 21:14:02.085688 14843 sgd_solver.cpp:106] Iteration 23001, lr = 0.0025
I0524 21:14:10.738665 14843 solver.cpp:237] Iteration 23188, loss = 1.21035
I0524 21:14:10.738716 14843 solver.cpp:253]     Train net output #0: loss = 1.21035 (* 1 = 1.21035 loss)
I0524 21:14:10.738734 14843 sgd_solver.cpp:106] Iteration 23188, lr = 0.0025
I0524 21:14:19.385490 14843 solver.cpp:237] Iteration 23375, loss = 1.16002
I0524 21:14:19.385527 14843 solver.cpp:253]     Train net output #0: loss = 1.16002 (* 1 = 1.16002 loss)
I0524 21:14:19.385551 14843 sgd_solver.cpp:106] Iteration 23375, lr = 0.0025
I0524 21:14:28.036252 14843 solver.cpp:237] Iteration 23562, loss = 1.24154
I0524 21:14:28.036415 14843 solver.cpp:253]     Train net output #0: loss = 1.24154 (* 1 = 1.24154 loss)
I0524 21:14:28.036433 14843 sgd_solver.cpp:106] Iteration 23562, lr = 0.0025
I0524 21:14:36.686898 14843 solver.cpp:237] Iteration 23749, loss = 1.17271
I0524 21:14:36.686950 14843 solver.cpp:253]     Train net output #0: loss = 1.17271 (* 1 = 1.17271 loss)
I0524 21:14:36.686975 14843 sgd_solver.cpp:106] Iteration 23749, lr = 0.0025
I0524 21:15:06.255306 14843 solver.cpp:237] Iteration 23936, loss = 1.0968
I0524 21:15:06.255477 14843 solver.cpp:253]     Train net output #0: loss = 1.0968 (* 1 = 1.0968 loss)
I0524 21:15:06.255494 14843 sgd_solver.cpp:106] Iteration 23936, lr = 0.0025
I0524 21:15:14.903717 14843 solver.cpp:237] Iteration 24123, loss = 1.39545
I0524 21:15:14.903753 14843 solver.cpp:253]     Train net output #0: loss = 1.39545 (* 1 = 1.39545 loss)
I0524 21:15:14.903776 14843 sgd_solver.cpp:106] Iteration 24123, lr = 0.0025
I0524 21:15:23.554571 14843 solver.cpp:237] Iteration 24310, loss = 1.27712
I0524 21:15:23.554625 14843 solver.cpp:253]     Train net output #0: loss = 1.27712 (* 1 = 1.27712 loss)
I0524 21:15:23.554649 14843 sgd_solver.cpp:106] Iteration 24310, lr = 0.0025
I0524 21:15:26.515161 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_24375.caffemodel
I0524 21:15:26.585330 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_24375.solverstate
I0524 21:15:32.274369 14843 solver.cpp:237] Iteration 24497, loss = 1.27717
I0524 21:15:32.274420 14843 solver.cpp:253]     Train net output #0: loss = 1.27717 (* 1 = 1.27717 loss)
I0524 21:15:32.274447 14843 sgd_solver.cpp:106] Iteration 24497, lr = 0.0025
I0524 21:15:40.923167 14843 solver.cpp:237] Iteration 24684, loss = 1.2075
I0524 21:15:40.923334 14843 solver.cpp:253]     Train net output #0: loss = 1.2075 (* 1 = 1.2075 loss)
I0524 21:15:40.923352 14843 sgd_solver.cpp:106] Iteration 24684, lr = 0.0025
I0524 21:15:49.574664 14843 solver.cpp:237] Iteration 24871, loss = 1.34198
I0524 21:15:49.574713 14843 solver.cpp:253]     Train net output #0: loss = 1.34198 (* 1 = 1.34198 loss)
I0524 21:15:49.574740 14843 sgd_solver.cpp:106] Iteration 24871, lr = 0.0025
I0524 21:16:19.147753 14843 solver.cpp:237] Iteration 25058, loss = 1.1714
I0524 21:16:19.147929 14843 solver.cpp:253]     Train net output #0: loss = 1.1714 (* 1 = 1.1714 loss)
I0524 21:16:19.147954 14843 sgd_solver.cpp:106] Iteration 25058, lr = 0.0025
I0524 21:16:27.801169 14843 solver.cpp:237] Iteration 25245, loss = 1.08941
I0524 21:16:27.801206 14843 solver.cpp:253]     Train net output #0: loss = 1.08941 (* 1 = 1.08941 loss)
I0524 21:16:27.801223 14843 sgd_solver.cpp:106] Iteration 25245, lr = 0.0025
I0524 21:16:36.457828 14843 solver.cpp:237] Iteration 25432, loss = 1.51453
I0524 21:16:36.457878 14843 solver.cpp:253]     Train net output #0: loss = 1.51453 (* 1 = 1.51453 loss)
I0524 21:16:36.457896 14843 sgd_solver.cpp:106] Iteration 25432, lr = 0.0025
I0524 21:16:45.107538 14843 solver.cpp:237] Iteration 25619, loss = 1.10789
I0524 21:16:45.107575 14843 solver.cpp:253]     Train net output #0: loss = 1.10789 (* 1 = 1.10789 loss)
I0524 21:16:45.107599 14843 sgd_solver.cpp:106] Iteration 25619, lr = 0.0025
I0524 21:16:53.757055 14843 solver.cpp:237] Iteration 25806, loss = 1.24418
I0524 21:16:53.757210 14843 solver.cpp:253]     Train net output #0: loss = 1.24418 (* 1 = 1.24418 loss)
I0524 21:16:53.757226 14843 sgd_solver.cpp:106] Iteration 25806, lr = 0.0025
I0524 21:17:02.407557 14843 solver.cpp:237] Iteration 25993, loss = 1.2601
I0524 21:17:02.407611 14843 solver.cpp:253]     Train net output #0: loss = 1.2601 (* 1 = 1.2601 loss)
I0524 21:17:02.407636 14843 sgd_solver.cpp:106] Iteration 25993, lr = 0.0025
I0524 21:17:11.060088 14843 solver.cpp:237] Iteration 26180, loss = 1.05051
I0524 21:17:11.060124 14843 solver.cpp:253]     Train net output #0: loss = 1.05051 (* 1 = 1.05051 loss)
I0524 21:17:11.060150 14843 sgd_solver.cpp:106] Iteration 26180, lr = 0.0025
I0524 21:17:14.250952 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_26250.caffemodel
I0524 21:17:14.321760 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_26250.solverstate
I0524 21:17:14.348464 14843 solver.cpp:341] Iteration 26250, Testing net (#0)
I0524 21:18:01.414089 14843 solver.cpp:409]     Test net output #0: accuracy = 0.871787
I0524 21:18:01.414258 14843 solver.cpp:409]     Test net output #1: loss = 0.432634 (* 1 = 0.432634 loss)
I0524 21:18:27.734910 14843 solver.cpp:237] Iteration 26367, loss = 1.20446
I0524 21:18:27.734967 14843 solver.cpp:253]     Train net output #0: loss = 1.20446 (* 1 = 1.20446 loss)
I0524 21:18:27.734987 14843 sgd_solver.cpp:106] Iteration 26367, lr = 0.0025
I0524 21:18:36.401983 14843 solver.cpp:237] Iteration 26554, loss = 1.35249
I0524 21:18:36.402160 14843 solver.cpp:253]     Train net output #0: loss = 1.35249 (* 1 = 1.35249 loss)
I0524 21:18:36.402178 14843 sgd_solver.cpp:106] Iteration 26554, lr = 0.0025
I0524 21:18:45.065513 14843 solver.cpp:237] Iteration 26741, loss = 1.23738
I0524 21:18:45.065562 14843 solver.cpp:253]     Train net output #0: loss = 1.23738 (* 1 = 1.23738 loss)
I0524 21:18:45.065579 14843 sgd_solver.cpp:106] Iteration 26741, lr = 0.0025
I0524 21:18:53.725298 14843 solver.cpp:237] Iteration 26928, loss = 1.2887
I0524 21:18:53.725337 14843 solver.cpp:253]     Train net output #0: loss = 1.2887 (* 1 = 1.2887 loss)
I0524 21:18:53.725353 14843 sgd_solver.cpp:106] Iteration 26928, lr = 0.0025
I0524 21:19:02.384012 14843 solver.cpp:237] Iteration 27115, loss = 1.19876
I0524 21:19:02.384049 14843 solver.cpp:253]     Train net output #0: loss = 1.19876 (* 1 = 1.19876 loss)
I0524 21:19:02.384073 14843 sgd_solver.cpp:106] Iteration 27115, lr = 0.0025
I0524 21:19:11.042641 14843 solver.cpp:237] Iteration 27302, loss = 1.23516
I0524 21:19:11.042821 14843 solver.cpp:253]     Train net output #0: loss = 1.23516 (* 1 = 1.23516 loss)
I0524 21:19:11.042841 14843 sgd_solver.cpp:106] Iteration 27302, lr = 0.0025
I0524 21:19:19.695472 14843 solver.cpp:237] Iteration 27489, loss = 1.00115
I0524 21:19:19.695508 14843 solver.cpp:253]     Train net output #0: loss = 1.00115 (* 1 = 1.00115 loss)
I0524 21:19:19.695533 14843 sgd_solver.cpp:106] Iteration 27489, lr = 0.0025
I0524 21:19:49.249547 14843 solver.cpp:237] Iteration 27676, loss = 1.12173
I0524 21:19:49.249737 14843 solver.cpp:253]     Train net output #0: loss = 1.12173 (* 1 = 1.12173 loss)
I0524 21:19:49.249754 14843 sgd_solver.cpp:106] Iteration 27676, lr = 0.0025
I0524 21:19:57.905948 14843 solver.cpp:237] Iteration 27863, loss = 1.52822
I0524 21:19:57.905999 14843 solver.cpp:253]     Train net output #0: loss = 1.52822 (* 1 = 1.52822 loss)
I0524 21:19:57.906016 14843 sgd_solver.cpp:106] Iteration 27863, lr = 0.0025
I0524 21:20:06.550335 14843 solver.cpp:237] Iteration 28050, loss = 1.18009
I0524 21:20:06.550374 14843 solver.cpp:253]     Train net output #0: loss = 1.18009 (* 1 = 1.18009 loss)
I0524 21:20:06.550392 14843 sgd_solver.cpp:106] Iteration 28050, lr = 0.0025
I0524 21:20:09.974994 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_28125.caffemodel
I0524 21:20:10.048586 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_28125.solverstate
I0524 21:20:15.274698 14843 solver.cpp:237] Iteration 28237, loss = 1.29215
I0524 21:20:15.274754 14843 solver.cpp:253]     Train net output #0: loss = 1.29215 (* 1 = 1.29215 loss)
I0524 21:20:15.274777 14843 sgd_solver.cpp:106] Iteration 28237, lr = 0.0025
I0524 21:20:23.926934 14843 solver.cpp:237] Iteration 28424, loss = 1.22397
I0524 21:20:23.927119 14843 solver.cpp:253]     Train net output #0: loss = 1.22397 (* 1 = 1.22397 loss)
I0524 21:20:23.927136 14843 sgd_solver.cpp:106] Iteration 28424, lr = 0.0025
I0524 21:20:32.574776 14843 solver.cpp:237] Iteration 28611, loss = 1.26048
I0524 21:20:32.574815 14843 solver.cpp:253]     Train net output #0: loss = 1.26048 (* 1 = 1.26048 loss)
I0524 21:20:32.574837 14843 sgd_solver.cpp:106] Iteration 28611, lr = 0.0025
I0524 21:21:02.143952 14843 solver.cpp:237] Iteration 28798, loss = 1.35971
I0524 21:21:02.144134 14843 solver.cpp:253]     Train net output #0: loss = 1.35971 (* 1 = 1.35971 loss)
I0524 21:21:02.144150 14843 sgd_solver.cpp:106] Iteration 28798, lr = 0.0025
I0524 21:21:10.797863 14843 solver.cpp:237] Iteration 28985, loss = 1.06163
I0524 21:21:10.797899 14843 solver.cpp:253]     Train net output #0: loss = 1.06163 (* 1 = 1.06163 loss)
I0524 21:21:10.797922 14843 sgd_solver.cpp:106] Iteration 28985, lr = 0.0025
I0524 21:21:19.451721 14843 solver.cpp:237] Iteration 29172, loss = 1.08796
I0524 21:21:19.451763 14843 solver.cpp:253]     Train net output #0: loss = 1.08796 (* 1 = 1.08796 loss)
I0524 21:21:19.451781 14843 sgd_solver.cpp:106] Iteration 29172, lr = 0.0025
I0524 21:21:28.102272 14843 solver.cpp:237] Iteration 29359, loss = 1.12044
I0524 21:21:28.102308 14843 solver.cpp:253]     Train net output #0: loss = 1.12044 (* 1 = 1.12044 loss)
I0524 21:21:28.102326 14843 sgd_solver.cpp:106] Iteration 29359, lr = 0.0025
I0524 21:21:36.756019 14843 solver.cpp:237] Iteration 29546, loss = 1.35833
I0524 21:21:36.756212 14843 solver.cpp:253]     Train net output #0: loss = 1.35833 (* 1 = 1.35833 loss)
I0524 21:21:36.756232 14843 sgd_solver.cpp:106] Iteration 29546, lr = 0.0025
I0524 21:21:45.408538 14843 solver.cpp:237] Iteration 29733, loss = 1.42051
I0524 21:21:45.408576 14843 solver.cpp:253]     Train net output #0: loss = 1.42051 (* 1 = 1.42051 loss)
I0524 21:21:45.408594 14843 sgd_solver.cpp:106] Iteration 29733, lr = 0.0025
I0524 21:21:54.060075 14843 solver.cpp:237] Iteration 29920, loss = 1.33843
I0524 21:21:54.060111 14843 solver.cpp:253]     Train net output #0: loss = 1.33843 (* 1 = 1.33843 loss)
I0524 21:21:54.060129 14843 sgd_solver.cpp:106] Iteration 29920, lr = 0.0025
I0524 21:21:57.713781 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_30000.caffemodel
I0524 21:21:57.784165 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_30000.solverstate
I0524 21:21:57.810956 14843 solver.cpp:341] Iteration 30000, Testing net (#0)
I0524 21:23:06.076119 14843 solver.cpp:409]     Test net output #0: accuracy = 0.875533
I0524 21:23:06.076294 14843 solver.cpp:409]     Test net output #1: loss = 0.441678 (* 1 = 0.441678 loss)
I0524 21:23:31.914664 14843 solver.cpp:237] Iteration 30107, loss = 1.12475
I0524 21:23:31.914721 14843 solver.cpp:253]     Train net output #0: loss = 1.12475 (* 1 = 1.12475 loss)
I0524 21:23:31.914744 14843 sgd_solver.cpp:106] Iteration 30107, lr = 0.0025
I0524 21:23:40.569890 14843 solver.cpp:237] Iteration 30294, loss = 1.02318
I0524 21:23:40.570047 14843 solver.cpp:253]     Train net output #0: loss = 1.02318 (* 1 = 1.02318 loss)
I0524 21:23:40.570065 14843 sgd_solver.cpp:106] Iteration 30294, lr = 0.0025
I0524 21:23:49.220775 14843 solver.cpp:237] Iteration 30481, loss = 1.10871
I0524 21:23:49.220821 14843 solver.cpp:253]     Train net output #0: loss = 1.10871 (* 1 = 1.10871 loss)
I0524 21:23:49.220841 14843 sgd_solver.cpp:106] Iteration 30481, lr = 0.0025
I0524 21:23:57.872051 14843 solver.cpp:237] Iteration 30668, loss = 1.1028
I0524 21:23:57.872087 14843 solver.cpp:253]     Train net output #0: loss = 1.1028 (* 1 = 1.1028 loss)
I0524 21:23:57.872105 14843 sgd_solver.cpp:106] Iteration 30668, lr = 0.0025
I0524 21:24:06.526731 14843 solver.cpp:237] Iteration 30855, loss = 1.05719
I0524 21:24:06.526784 14843 solver.cpp:253]     Train net output #0: loss = 1.05719 (* 1 = 1.05719 loss)
I0524 21:24:06.526810 14843 sgd_solver.cpp:106] Iteration 30855, lr = 0.0025
I0524 21:24:15.179211 14843 solver.cpp:237] Iteration 31042, loss = 1.21238
I0524 21:24:15.179369 14843 solver.cpp:253]     Train net output #0: loss = 1.21238 (* 1 = 1.21238 loss)
I0524 21:24:15.179386 14843 sgd_solver.cpp:106] Iteration 31042, lr = 0.0025
I0524 21:24:23.829025 14843 solver.cpp:237] Iteration 31229, loss = 1.4895
I0524 21:24:23.829063 14843 solver.cpp:253]     Train net output #0: loss = 1.4895 (* 1 = 1.4895 loss)
I0524 21:24:23.829080 14843 sgd_solver.cpp:106] Iteration 31229, lr = 0.0025
I0524 21:24:53.339586 14843 solver.cpp:237] Iteration 31416, loss = 1.03335
I0524 21:24:53.339764 14843 solver.cpp:253]     Train net output #0: loss = 1.03335 (* 1 = 1.03335 loss)
I0524 21:24:53.339784 14843 sgd_solver.cpp:106] Iteration 31416, lr = 0.0025
I0524 21:25:01.994262 14843 solver.cpp:237] Iteration 31603, loss = 1.23243
I0524 21:25:01.994313 14843 solver.cpp:253]     Train net output #0: loss = 1.23243 (* 1 = 1.23243 loss)
I0524 21:25:01.994339 14843 sgd_solver.cpp:106] Iteration 31603, lr = 0.0025
I0524 21:25:10.648913 14843 solver.cpp:237] Iteration 31790, loss = 1.12151
I0524 21:25:10.648949 14843 solver.cpp:253]     Train net output #0: loss = 1.12151 (* 1 = 1.12151 loss)
I0524 21:25:10.648972 14843 sgd_solver.cpp:106] Iteration 31790, lr = 0.0025
I0524 21:25:14.536324 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_31875.caffemodel
I0524 21:25:14.605981 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_31875.solverstate
I0524 21:25:19.368063 14843 solver.cpp:237] Iteration 31977, loss = 1.19582
I0524 21:25:19.368116 14843 solver.cpp:253]     Train net output #0: loss = 1.19582 (* 1 = 1.19582 loss)
I0524 21:25:19.368134 14843 sgd_solver.cpp:106] Iteration 31977, lr = 0.0025
I0524 21:25:28.025964 14843 solver.cpp:237] Iteration 32164, loss = 1.50058
I0524 21:25:28.026157 14843 solver.cpp:253]     Train net output #0: loss = 1.50058 (* 1 = 1.50058 loss)
I0524 21:25:28.026175 14843 sgd_solver.cpp:106] Iteration 32164, lr = 0.0025
I0524 21:25:36.682132 14843 solver.cpp:237] Iteration 32351, loss = 1.07894
I0524 21:25:36.682168 14843 solver.cpp:253]     Train net output #0: loss = 1.07894 (* 1 = 1.07894 loss)
I0524 21:25:36.682186 14843 sgd_solver.cpp:106] Iteration 32351, lr = 0.0025
I0524 21:26:06.244575 14843 solver.cpp:237] Iteration 32538, loss = 1.20659
I0524 21:26:06.244751 14843 solver.cpp:253]     Train net output #0: loss = 1.20659 (* 1 = 1.20659 loss)
I0524 21:26:06.244771 14843 sgd_solver.cpp:106] Iteration 32538, lr = 0.0025
I0524 21:26:14.899673 14843 solver.cpp:237] Iteration 32725, loss = 1.18862
I0524 21:26:14.899727 14843 solver.cpp:253]     Train net output #0: loss = 1.18862 (* 1 = 1.18862 loss)
I0524 21:26:14.899752 14843 sgd_solver.cpp:106] Iteration 32725, lr = 0.0025
I0524 21:26:23.557420 14843 solver.cpp:237] Iteration 32912, loss = 1.14914
I0524 21:26:23.557456 14843 solver.cpp:253]     Train net output #0: loss = 1.14914 (* 1 = 1.14914 loss)
I0524 21:26:23.557476 14843 sgd_solver.cpp:106] Iteration 32912, lr = 0.0025
I0524 21:26:32.209686 14843 solver.cpp:237] Iteration 33099, loss = 1.06985
I0524 21:26:32.209722 14843 solver.cpp:253]     Train net output #0: loss = 1.06985 (* 1 = 1.06985 loss)
I0524 21:26:32.209746 14843 sgd_solver.cpp:106] Iteration 33099, lr = 0.0025
I0524 21:26:40.868859 14843 solver.cpp:237] Iteration 33286, loss = 1.54611
I0524 21:26:40.869032 14843 solver.cpp:253]     Train net output #0: loss = 1.54611 (* 1 = 1.54611 loss)
I0524 21:26:40.869051 14843 sgd_solver.cpp:106] Iteration 33286, lr = 0.0025
I0524 21:26:49.522575 14843 solver.cpp:237] Iteration 33473, loss = 1.11102
I0524 21:26:49.522614 14843 solver.cpp:253]     Train net output #0: loss = 1.11102 (* 1 = 1.11102 loss)
I0524 21:26:49.522630 14843 sgd_solver.cpp:106] Iteration 33473, lr = 0.0025
I0524 21:26:58.179831 14843 solver.cpp:237] Iteration 33660, loss = 1.25071
I0524 21:26:58.179867 14843 solver.cpp:253]     Train net output #0: loss = 1.25071 (* 1 = 1.25071 loss)
I0524 21:26:58.179885 14843 sgd_solver.cpp:106] Iteration 33660, lr = 0.0025
I0524 21:27:02.302129 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_33750.caffemodel
I0524 21:27:02.372138 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_33750.solverstate
I0524 21:27:02.398851 14843 solver.cpp:341] Iteration 33750, Testing net (#0)
I0524 21:27:49.811714 14843 solver.cpp:409]     Test net output #0: accuracy = 0.878493
I0524 21:27:49.811892 14843 solver.cpp:409]     Test net output #1: loss = 0.404631 (* 1 = 0.404631 loss)
I0524 21:28:15.188769 14843 solver.cpp:237] Iteration 33847, loss = 1.1117
I0524 21:28:15.188824 14843 solver.cpp:253]     Train net output #0: loss = 1.1117 (* 1 = 1.1117 loss)
I0524 21:28:15.188843 14843 sgd_solver.cpp:106] Iteration 33847, lr = 0.0025
I0524 21:28:23.843523 14843 solver.cpp:237] Iteration 34034, loss = 1.28446
I0524 21:28:23.843699 14843 solver.cpp:253]     Train net output #0: loss = 1.28446 (* 1 = 1.28446 loss)
I0524 21:28:23.843719 14843 sgd_solver.cpp:106] Iteration 34034, lr = 0.0025
I0524 21:28:32.501384 14843 solver.cpp:237] Iteration 34221, loss = 1.17577
I0524 21:28:32.501422 14843 solver.cpp:253]     Train net output #0: loss = 1.17577 (* 1 = 1.17577 loss)
I0524 21:28:32.501440 14843 sgd_solver.cpp:106] Iteration 34221, lr = 0.0025
I0524 21:28:41.158264 14843 solver.cpp:237] Iteration 34408, loss = 1.3661
I0524 21:28:41.158318 14843 solver.cpp:253]     Train net output #0: loss = 1.3661 (* 1 = 1.3661 loss)
I0524 21:28:41.158344 14843 sgd_solver.cpp:106] Iteration 34408, lr = 0.0025
I0524 21:28:49.814606 14843 solver.cpp:237] Iteration 34595, loss = 1.12646
I0524 21:28:49.814642 14843 solver.cpp:253]     Train net output #0: loss = 1.12646 (* 1 = 1.12646 loss)
I0524 21:28:49.814666 14843 sgd_solver.cpp:106] Iteration 34595, lr = 0.0025
I0524 21:28:58.472867 14843 solver.cpp:237] Iteration 34782, loss = 1.13782
I0524 21:28:58.473031 14843 solver.cpp:253]     Train net output #0: loss = 1.13782 (* 1 = 1.13782 loss)
I0524 21:28:58.473048 14843 sgd_solver.cpp:106] Iteration 34782, lr = 0.0025
I0524 21:29:07.127794 14843 solver.cpp:237] Iteration 34969, loss = 1.11901
I0524 21:29:07.127846 14843 solver.cpp:253]     Train net output #0: loss = 1.11901 (* 1 = 1.11901 loss)
I0524 21:29:07.127873 14843 sgd_solver.cpp:106] Iteration 34969, lr = 0.0025
I0524 21:29:36.620146 14843 solver.cpp:237] Iteration 35156, loss = 1.00575
I0524 21:29:36.620324 14843 solver.cpp:253]     Train net output #0: loss = 1.00575 (* 1 = 1.00575 loss)
I0524 21:29:36.620343 14843 sgd_solver.cpp:106] Iteration 35156, lr = 0.0025
I0524 21:29:45.279520 14843 solver.cpp:237] Iteration 35343, loss = 1.06016
I0524 21:29:45.279556 14843 solver.cpp:253]     Train net output #0: loss = 1.06016 (* 1 = 1.06016 loss)
I0524 21:29:45.279575 14843 sgd_solver.cpp:106] Iteration 35343, lr = 0.0025
I0524 21:29:53.938632 14843 solver.cpp:237] Iteration 35530, loss = 1.07599
I0524 21:29:53.938668 14843 solver.cpp:253]     Train net output #0: loss = 1.07599 (* 1 = 1.07599 loss)
I0524 21:29:53.938691 14843 sgd_solver.cpp:106] Iteration 35530, lr = 0.0025
I0524 21:29:58.293789 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_35625.caffemodel
I0524 21:29:58.366308 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_35625.solverstate
I0524 21:30:02.670754 14843 solver.cpp:237] Iteration 35717, loss = 1.23613
I0524 21:30:02.670807 14843 solver.cpp:253]     Train net output #0: loss = 1.23613 (* 1 = 1.23613 loss)
I0524 21:30:02.670824 14843 sgd_solver.cpp:106] Iteration 35717, lr = 0.0025
I0524 21:30:11.330276 14843 solver.cpp:237] Iteration 35904, loss = 1.31615
I0524 21:30:11.330427 14843 solver.cpp:253]     Train net output #0: loss = 1.31615 (* 1 = 1.31615 loss)
I0524 21:30:11.330445 14843 sgd_solver.cpp:106] Iteration 35904, lr = 0.0025
I0524 21:30:19.988091 14843 solver.cpp:237] Iteration 36091, loss = 1.34332
I0524 21:30:19.988129 14843 solver.cpp:253]     Train net output #0: loss = 1.34332 (* 1 = 1.34332 loss)
I0524 21:30:19.988147 14843 sgd_solver.cpp:106] Iteration 36091, lr = 0.0025
I0524 21:30:49.518843 14843 solver.cpp:237] Iteration 36278, loss = 1.2467
I0524 21:30:49.519026 14843 solver.cpp:253]     Train net output #0: loss = 1.2467 (* 1 = 1.2467 loss)
I0524 21:30:49.519052 14843 sgd_solver.cpp:106] Iteration 36278, lr = 0.0025
I0524 21:30:58.191296 14843 solver.cpp:237] Iteration 36465, loss = 1.1692
I0524 21:30:58.191334 14843 solver.cpp:253]     Train net output #0: loss = 1.1692 (* 1 = 1.1692 loss)
I0524 21:30:58.191352 14843 sgd_solver.cpp:106] Iteration 36465, lr = 0.0025
I0524 21:31:06.863137 14843 solver.cpp:237] Iteration 36652, loss = 1.09464
I0524 21:31:06.863173 14843 solver.cpp:253]     Train net output #0: loss = 1.09464 (* 1 = 1.09464 loss)
I0524 21:31:06.863193 14843 sgd_solver.cpp:106] Iteration 36652, lr = 0.0025
I0524 21:31:15.521316 14843 solver.cpp:237] Iteration 36839, loss = 1.17887
I0524 21:31:15.521370 14843 solver.cpp:253]     Train net output #0: loss = 1.17887 (* 1 = 1.17887 loss)
I0524 21:31:15.521394 14843 sgd_solver.cpp:106] Iteration 36839, lr = 0.0025
I0524 21:31:24.169812 14843 solver.cpp:237] Iteration 37026, loss = 1.2081
I0524 21:31:24.169981 14843 solver.cpp:253]     Train net output #0: loss = 1.2081 (* 1 = 1.2081 loss)
I0524 21:31:24.169997 14843 sgd_solver.cpp:106] Iteration 37026, lr = 0.0025
I0524 21:31:32.815335 14843 solver.cpp:237] Iteration 37213, loss = 1.3723
I0524 21:31:32.815371 14843 solver.cpp:253]     Train net output #0: loss = 1.3723 (* 1 = 1.3723 loss)
I0524 21:31:32.815393 14843 sgd_solver.cpp:106] Iteration 37213, lr = 0.0025
I0524 21:31:41.462749 14843 solver.cpp:237] Iteration 37400, loss = 1.20971
I0524 21:31:41.462800 14843 solver.cpp:253]     Train net output #0: loss = 1.20971 (* 1 = 1.20971 loss)
I0524 21:31:41.462826 14843 sgd_solver.cpp:106] Iteration 37400, lr = 0.0025
I0524 21:31:46.039855 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_37500.caffemodel
I0524 21:31:46.111326 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_37500.solverstate
I0524 21:31:46.139230 14843 solver.cpp:341] Iteration 37500, Testing net (#0)
I0524 21:32:54.421183 14843 solver.cpp:409]     Test net output #0: accuracy = 0.880834
I0524 21:32:54.421358 14843 solver.cpp:409]     Test net output #1: loss = 0.391437 (* 1 = 0.391437 loss)
I0524 21:33:19.350219 14843 solver.cpp:237] Iteration 37587, loss = 1.16478
I0524 21:33:19.350275 14843 solver.cpp:253]     Train net output #0: loss = 1.16478 (* 1 = 1.16478 loss)
I0524 21:33:19.350299 14843 sgd_solver.cpp:106] Iteration 37587, lr = 0.0025
I0524 21:33:28.012986 14843 solver.cpp:237] Iteration 37774, loss = 0.937973
I0524 21:33:28.013147 14843 solver.cpp:253]     Train net output #0: loss = 0.937973 (* 1 = 0.937973 loss)
I0524 21:33:28.013164 14843 sgd_solver.cpp:106] Iteration 37774, lr = 0.0025
I0524 21:33:36.678896 14843 solver.cpp:237] Iteration 37961, loss = 1.22536
I0524 21:33:36.678932 14843 solver.cpp:253]     Train net output #0: loss = 1.22536 (* 1 = 1.22536 loss)
I0524 21:33:36.678951 14843 sgd_solver.cpp:106] Iteration 37961, lr = 0.0025
I0524 21:33:45.342949 14843 solver.cpp:237] Iteration 38148, loss = 1.23151
I0524 21:33:45.343003 14843 solver.cpp:253]     Train net output #0: loss = 1.23151 (* 1 = 1.23151 loss)
I0524 21:33:45.343027 14843 sgd_solver.cpp:106] Iteration 38148, lr = 0.0025
I0524 21:33:54.004228 14843 solver.cpp:237] Iteration 38335, loss = 1.13168
I0524 21:33:54.004266 14843 solver.cpp:253]     Train net output #0: loss = 1.13168 (* 1 = 1.13168 loss)
I0524 21:33:54.004283 14843 sgd_solver.cpp:106] Iteration 38335, lr = 0.0025
I0524 21:34:02.661571 14843 solver.cpp:237] Iteration 38522, loss = 1.48383
I0524 21:34:02.661731 14843 solver.cpp:253]     Train net output #0: loss = 1.48383 (* 1 = 1.48383 loss)
I0524 21:34:02.661748 14843 sgd_solver.cpp:106] Iteration 38522, lr = 0.0025
I0524 21:34:11.307813 14843 solver.cpp:237] Iteration 38709, loss = 1.07374
I0524 21:34:11.307867 14843 solver.cpp:253]     Train net output #0: loss = 1.07374 (* 1 = 1.07374 loss)
I0524 21:34:11.307891 14843 sgd_solver.cpp:106] Iteration 38709, lr = 0.0025
I0524 21:34:40.832564 14843 solver.cpp:237] Iteration 38896, loss = 1.07652
I0524 21:34:40.832746 14843 solver.cpp:253]     Train net output #0: loss = 1.07652 (* 1 = 1.07652 loss)
I0524 21:34:40.832762 14843 sgd_solver.cpp:106] Iteration 38896, lr = 0.0025
I0524 21:34:49.470557 14843 solver.cpp:237] Iteration 39083, loss = 1.25412
I0524 21:34:49.470593 14843 solver.cpp:253]     Train net output #0: loss = 1.25412 (* 1 = 1.25412 loss)
I0524 21:34:49.470613 14843 sgd_solver.cpp:106] Iteration 39083, lr = 0.0025
I0524 21:34:58.109827 14843 solver.cpp:237] Iteration 39270, loss = 1.06462
I0524 21:34:58.109880 14843 solver.cpp:253]     Train net output #0: loss = 1.06462 (* 1 = 1.06462 loss)
I0524 21:34:58.109905 14843 sgd_solver.cpp:106] Iteration 39270, lr = 0.0025
I0524 21:35:02.914408 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_39375.caffemodel
I0524 21:35:02.984326 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_39375.solverstate
I0524 21:35:06.814060 14843 solver.cpp:237] Iteration 39457, loss = 1.1194
I0524 21:35:06.814116 14843 solver.cpp:253]     Train net output #0: loss = 1.1194 (* 1 = 1.1194 loss)
I0524 21:35:06.814141 14843 sgd_solver.cpp:106] Iteration 39457, lr = 0.0025
I0524 21:35:15.455965 14843 solver.cpp:237] Iteration 39644, loss = 1.38789
I0524 21:35:15.456135 14843 solver.cpp:253]     Train net output #0: loss = 1.38789 (* 1 = 1.38789 loss)
I0524 21:35:15.456151 14843 sgd_solver.cpp:106] Iteration 39644, lr = 0.0025
I0524 21:35:24.091009 14843 solver.cpp:237] Iteration 39831, loss = 1.31499
I0524 21:35:24.091064 14843 solver.cpp:253]     Train net output #0: loss = 1.31499 (* 1 = 1.31499 loss)
I0524 21:35:24.091087 14843 sgd_solver.cpp:106] Iteration 39831, lr = 0.0025
I0524 21:35:53.590380 14843 solver.cpp:237] Iteration 40018, loss = 1.18196
I0524 21:35:53.590549 14843 solver.cpp:253]     Train net output #0: loss = 1.18196 (* 1 = 1.18196 loss)
I0524 21:35:53.590569 14843 sgd_solver.cpp:106] Iteration 40018, lr = 0.0025
I0524 21:36:02.230370 14843 solver.cpp:237] Iteration 40205, loss = 0.948112
I0524 21:36:02.230406 14843 solver.cpp:253]     Train net output #0: loss = 0.948112 (* 1 = 0.948112 loss)
I0524 21:36:02.230425 14843 sgd_solver.cpp:106] Iteration 40205, lr = 0.0025
I0524 21:36:10.869356 14843 solver.cpp:237] Iteration 40392, loss = 1.1552
I0524 21:36:10.869413 14843 solver.cpp:253]     Train net output #0: loss = 1.1552 (* 1 = 1.1552 loss)
I0524 21:36:10.869441 14843 sgd_solver.cpp:106] Iteration 40392, lr = 0.0025
I0524 21:36:19.510020 14843 solver.cpp:237] Iteration 40579, loss = 1.39968
I0524 21:36:19.510059 14843 solver.cpp:253]     Train net output #0: loss = 1.39968 (* 1 = 1.39968 loss)
I0524 21:36:19.510076 14843 sgd_solver.cpp:106] Iteration 40579, lr = 0.0025
I0524 21:36:28.146443 14843 solver.cpp:237] Iteration 40766, loss = 1.24267
I0524 21:36:28.146605 14843 solver.cpp:253]     Train net output #0: loss = 1.24267 (* 1 = 1.24267 loss)
I0524 21:36:28.146621 14843 sgd_solver.cpp:106] Iteration 40766, lr = 0.0025
I0524 21:36:36.790331 14843 solver.cpp:237] Iteration 40953, loss = 1.24266
I0524 21:36:36.790385 14843 solver.cpp:253]     Train net output #0: loss = 1.24266 (* 1 = 1.24266 loss)
I0524 21:36:36.790410 14843 sgd_solver.cpp:106] Iteration 40953, lr = 0.0025
I0524 21:36:45.451161 14843 solver.cpp:237] Iteration 41140, loss = 1.30436
I0524 21:36:45.451198 14843 solver.cpp:253]     Train net output #0: loss = 1.30436 (* 1 = 1.30436 loss)
I0524 21:36:45.451216 14843 sgd_solver.cpp:106] Iteration 41140, lr = 0.0025
I0524 21:36:50.498528 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_41250.caffemodel
I0524 21:36:50.568472 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_41250.solverstate
I0524 21:36:50.595118 14843 solver.cpp:341] Iteration 41250, Testing net (#0)
I0524 21:37:37.679003 14843 solver.cpp:409]     Test net output #0: accuracy = 0.879586
I0524 21:37:37.679183 14843 solver.cpp:409]     Test net output #1: loss = 0.376306 (* 1 = 0.376306 loss)
I0524 21:38:02.111570 14843 solver.cpp:237] Iteration 41327, loss = 1.22458
I0524 21:38:02.111625 14843 solver.cpp:253]     Train net output #0: loss = 1.22458 (* 1 = 1.22458 loss)
I0524 21:38:02.111645 14843 sgd_solver.cpp:106] Iteration 41327, lr = 0.0025
I0524 21:38:10.760892 14843 solver.cpp:237] Iteration 41514, loss = 1.21962
I0524 21:38:10.761065 14843 solver.cpp:253]     Train net output #0: loss = 1.21962 (* 1 = 1.21962 loss)
I0524 21:38:10.761080 14843 sgd_solver.cpp:106] Iteration 41514, lr = 0.0025
I0524 21:38:19.442854 14843 solver.cpp:237] Iteration 41701, loss = 1.55115
I0524 21:38:19.442910 14843 solver.cpp:253]     Train net output #0: loss = 1.55115 (* 1 = 1.55115 loss)
I0524 21:38:19.442934 14843 sgd_solver.cpp:106] Iteration 41701, lr = 0.0025
I0524 21:38:28.087479 14843 solver.cpp:237] Iteration 41888, loss = 1.36761
I0524 21:38:28.087515 14843 solver.cpp:253]     Train net output #0: loss = 1.36761 (* 1 = 1.36761 loss)
I0524 21:38:28.087533 14843 sgd_solver.cpp:106] Iteration 41888, lr = 0.0025
I0524 21:38:36.733455 14843 solver.cpp:237] Iteration 42075, loss = 1.31411
I0524 21:38:36.733494 14843 solver.cpp:253]     Train net output #0: loss = 1.31411 (* 1 = 1.31411 loss)
I0524 21:38:36.733510 14843 sgd_solver.cpp:106] Iteration 42075, lr = 0.0025
I0524 21:38:45.381069 14843 solver.cpp:237] Iteration 42262, loss = 1.2522
I0524 21:38:45.381245 14843 solver.cpp:253]     Train net output #0: loss = 1.2522 (* 1 = 1.2522 loss)
I0524 21:38:45.381263 14843 sgd_solver.cpp:106] Iteration 42262, lr = 0.0025
I0524 21:38:54.030601 14843 solver.cpp:237] Iteration 42449, loss = 1.23951
I0524 21:38:54.030637 14843 solver.cpp:253]     Train net output #0: loss = 1.23951 (* 1 = 1.23951 loss)
I0524 21:38:54.030655 14843 sgd_solver.cpp:106] Iteration 42449, lr = 0.0025
I0524 21:39:23.535145 14843 solver.cpp:237] Iteration 42636, loss = 1.0403
I0524 21:39:23.535326 14843 solver.cpp:253]     Train net output #0: loss = 1.0403 (* 1 = 1.0403 loss)
I0524 21:39:23.535343 14843 sgd_solver.cpp:106] Iteration 42636, lr = 0.0025
I0524 21:39:32.185442 14843 solver.cpp:237] Iteration 42823, loss = 1.44277
I0524 21:39:32.185493 14843 solver.cpp:253]     Train net output #0: loss = 1.44277 (* 1 = 1.44277 loss)
I0524 21:39:32.185519 14843 sgd_solver.cpp:106] Iteration 42823, lr = 0.0025
I0524 21:39:40.836241 14843 solver.cpp:237] Iteration 43010, loss = 1.17541
I0524 21:39:40.836277 14843 solver.cpp:253]     Train net output #0: loss = 1.17541 (* 1 = 1.17541 loss)
I0524 21:39:40.836295 14843 sgd_solver.cpp:106] Iteration 43010, lr = 0.0025
I0524 21:39:46.110360 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_43125.caffemodel
I0524 21:39:46.180166 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_43125.solverstate
I0524 21:39:49.550216 14843 solver.cpp:237] Iteration 43197, loss = 1.15199
I0524 21:39:49.550267 14843 solver.cpp:253]     Train net output #0: loss = 1.15199 (* 1 = 1.15199 loss)
I0524 21:39:49.550292 14843 sgd_solver.cpp:106] Iteration 43197, lr = 0.0025
I0524 21:39:58.200322 14843 solver.cpp:237] Iteration 43384, loss = 1.14063
I0524 21:39:58.200500 14843 solver.cpp:253]     Train net output #0: loss = 1.14063 (* 1 = 1.14063 loss)
I0524 21:39:58.200516 14843 sgd_solver.cpp:106] Iteration 43384, lr = 0.0025
I0524 21:40:06.845145 14843 solver.cpp:237] Iteration 43571, loss = 1.25688
I0524 21:40:06.845183 14843 solver.cpp:253]     Train net output #0: loss = 1.25688 (* 1 = 1.25688 loss)
I0524 21:40:06.845201 14843 sgd_solver.cpp:106] Iteration 43571, lr = 0.0025
I0524 21:40:36.344303 14843 solver.cpp:237] Iteration 43758, loss = 1.13474
I0524 21:40:36.344486 14843 solver.cpp:253]     Train net output #0: loss = 1.13474 (* 1 = 1.13474 loss)
I0524 21:40:36.344504 14843 sgd_solver.cpp:106] Iteration 43758, lr = 0.0025
I0524 21:40:44.991919 14843 solver.cpp:237] Iteration 43945, loss = 1.16345
I0524 21:40:44.991955 14843 solver.cpp:253]     Train net output #0: loss = 1.16345 (* 1 = 1.16345 loss)
I0524 21:40:44.991973 14843 sgd_solver.cpp:106] Iteration 43945, lr = 0.0025
I0524 21:40:53.638622 14843 solver.cpp:237] Iteration 44132, loss = 1.0882
I0524 21:40:53.638672 14843 solver.cpp:253]     Train net output #0: loss = 1.0882 (* 1 = 1.0882 loss)
I0524 21:40:53.638696 14843 sgd_solver.cpp:106] Iteration 44132, lr = 0.0025
I0524 21:41:02.289170 14843 solver.cpp:237] Iteration 44319, loss = 1.15143
I0524 21:41:02.289207 14843 solver.cpp:253]     Train net output #0: loss = 1.15143 (* 1 = 1.15143 loss)
I0524 21:41:02.289227 14843 sgd_solver.cpp:106] Iteration 44319, lr = 0.0025
I0524 21:41:10.939909 14843 solver.cpp:237] Iteration 44506, loss = 1.06891
I0524 21:41:10.940090 14843 solver.cpp:253]     Train net output #0: loss = 1.06891 (* 1 = 1.06891 loss)
I0524 21:41:10.940107 14843 sgd_solver.cpp:106] Iteration 44506, lr = 0.0025
I0524 21:41:19.590692 14843 solver.cpp:237] Iteration 44693, loss = 1.33086
I0524 21:41:19.590728 14843 solver.cpp:253]     Train net output #0: loss = 1.33086 (* 1 = 1.33086 loss)
I0524 21:41:19.590747 14843 sgd_solver.cpp:106] Iteration 44693, lr = 0.0025
I0524 21:41:28.241750 14843 solver.cpp:237] Iteration 44880, loss = 1.08052
I0524 21:41:28.241786 14843 solver.cpp:253]     Train net output #0: loss = 1.08052 (* 1 = 1.08052 loss)
I0524 21:41:28.241804 14843 sgd_solver.cpp:106] Iteration 44880, lr = 0.0025
I0524 21:41:33.748473 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_45000.caffemodel
I0524 21:41:33.818331 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_45000.solverstate
I0524 21:41:33.845180 14843 solver.cpp:341] Iteration 45000, Testing net (#0)
I0524 21:42:42.163502 14843 solver.cpp:409]     Test net output #0: accuracy = 0.883592
I0524 21:42:42.163688 14843 solver.cpp:409]     Test net output #1: loss = 0.403971 (* 1 = 0.403971 loss)
I0524 21:43:06.189962 14843 solver.cpp:237] Iteration 45067, loss = 1.2937
I0524 21:43:06.190017 14843 solver.cpp:253]     Train net output #0: loss = 1.2937 (* 1 = 1.2937 loss)
I0524 21:43:06.190037 14843 sgd_solver.cpp:106] Iteration 45067, lr = 0.0025
I0524 21:43:14.844344 14843 solver.cpp:237] Iteration 45254, loss = 0.971432
I0524 21:43:14.844511 14843 solver.cpp:253]     Train net output #0: loss = 0.971432 (* 1 = 0.971432 loss)
I0524 21:43:14.844528 14843 sgd_solver.cpp:106] Iteration 45254, lr = 0.0025
I0524 21:43:23.486361 14843 solver.cpp:237] Iteration 45441, loss = 1.34343
I0524 21:43:23.486410 14843 solver.cpp:253]     Train net output #0: loss = 1.34343 (* 1 = 1.34343 loss)
I0524 21:43:23.486438 14843 sgd_solver.cpp:106] Iteration 45441, lr = 0.0025
I0524 21:43:32.129448 14843 solver.cpp:237] Iteration 45628, loss = 1.07512
I0524 21:43:32.129484 14843 solver.cpp:253]     Train net output #0: loss = 1.07512 (* 1 = 1.07512 loss)
I0524 21:43:32.129503 14843 sgd_solver.cpp:106] Iteration 45628, lr = 0.0025
I0524 21:43:40.774530 14843 solver.cpp:237] Iteration 45815, loss = 1.3402
I0524 21:43:40.774566 14843 solver.cpp:253]     Train net output #0: loss = 1.3402 (* 1 = 1.3402 loss)
I0524 21:43:40.774585 14843 sgd_solver.cpp:106] Iteration 45815, lr = 0.0025
I0524 21:43:49.422619 14843 solver.cpp:237] Iteration 46002, loss = 1.04738
I0524 21:43:49.422791 14843 solver.cpp:253]     Train net output #0: loss = 1.04738 (* 1 = 1.04738 loss)
I0524 21:43:49.422809 14843 sgd_solver.cpp:106] Iteration 46002, lr = 0.0025
I0524 21:43:58.066285 14843 solver.cpp:237] Iteration 46189, loss = 1.02151
I0524 21:43:58.066323 14843 solver.cpp:253]     Train net output #0: loss = 1.02151 (* 1 = 1.02151 loss)
I0524 21:43:58.066339 14843 sgd_solver.cpp:106] Iteration 46189, lr = 0.0025
I0524 21:44:27.588230 14843 solver.cpp:237] Iteration 46376, loss = 1.03641
I0524 21:44:27.588423 14843 solver.cpp:253]     Train net output #0: loss = 1.03641 (* 1 = 1.03641 loss)
I0524 21:44:27.588440 14843 sgd_solver.cpp:106] Iteration 46376, lr = 0.0025
I0524 21:44:36.243407 14843 solver.cpp:237] Iteration 46563, loss = 1.12408
I0524 21:44:36.243461 14843 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0524 21:44:36.243485 14843 sgd_solver.cpp:106] Iteration 46563, lr = 0.0025
I0524 21:44:44.909912 14843 solver.cpp:237] Iteration 46750, loss = 1.11909
I0524 21:44:44.909950 14843 solver.cpp:253]     Train net output #0: loss = 1.11909 (* 1 = 1.11909 loss)
I0524 21:44:44.909967 14843 sgd_solver.cpp:106] Iteration 46750, lr = 0.0025
I0524 21:44:50.652683 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_46875.caffemodel
I0524 21:44:50.724203 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_46875.solverstate
I0524 21:44:53.639582 14843 solver.cpp:237] Iteration 46937, loss = 1.14559
I0524 21:44:53.639634 14843 solver.cpp:253]     Train net output #0: loss = 1.14559 (* 1 = 1.14559 loss)
I0524 21:44:53.639660 14843 sgd_solver.cpp:106] Iteration 46937, lr = 0.0025
I0524 21:45:02.307107 14843 solver.cpp:237] Iteration 47124, loss = 1.20079
I0524 21:45:02.307283 14843 solver.cpp:253]     Train net output #0: loss = 1.20079 (* 1 = 1.20079 loss)
I0524 21:45:02.307301 14843 sgd_solver.cpp:106] Iteration 47124, lr = 0.0025
I0524 21:45:10.980803 14843 solver.cpp:237] Iteration 47311, loss = 1.53277
I0524 21:45:10.980839 14843 solver.cpp:253]     Train net output #0: loss = 1.53277 (* 1 = 1.53277 loss)
I0524 21:45:10.980859 14843 sgd_solver.cpp:106] Iteration 47311, lr = 0.0025
I0524 21:45:19.653856 14843 solver.cpp:237] Iteration 47498, loss = 0.966856
I0524 21:45:19.653893 14843 solver.cpp:253]     Train net output #0: loss = 0.966856 (* 1 = 0.966856 loss)
I0524 21:45:19.653913 14843 sgd_solver.cpp:106] Iteration 47498, lr = 0.0025
I0524 21:45:49.241161 14843 solver.cpp:237] Iteration 47685, loss = 1.34687
I0524 21:45:49.241348 14843 solver.cpp:253]     Train net output #0: loss = 1.34687 (* 1 = 1.34687 loss)
I0524 21:45:49.241364 14843 sgd_solver.cpp:106] Iteration 47685, lr = 0.0025
I0524 21:45:57.909338 14843 solver.cpp:237] Iteration 47872, loss = 1.04653
I0524 21:45:57.909378 14843 solver.cpp:253]     Train net output #0: loss = 1.04653 (* 1 = 1.04653 loss)
I0524 21:45:57.909394 14843 sgd_solver.cpp:106] Iteration 47872, lr = 0.0025
I0524 21:46:06.583453 14843 solver.cpp:237] Iteration 48059, loss = 1.19412
I0524 21:46:06.583492 14843 solver.cpp:253]     Train net output #0: loss = 1.19412 (* 1 = 1.19412 loss)
I0524 21:46:06.583508 14843 sgd_solver.cpp:106] Iteration 48059, lr = 0.0025
I0524 21:46:15.255542 14843 solver.cpp:237] Iteration 48246, loss = 1.37922
I0524 21:46:15.255592 14843 solver.cpp:253]     Train net output #0: loss = 1.37922 (* 1 = 1.37922 loss)
I0524 21:46:15.255612 14843 sgd_solver.cpp:106] Iteration 48246, lr = 0.0025
I0524 21:46:23.929906 14843 solver.cpp:237] Iteration 48433, loss = 1.29252
I0524 21:46:23.930070 14843 solver.cpp:253]     Train net output #0: loss = 1.29252 (* 1 = 1.29252 loss)
I0524 21:46:23.930093 14843 sgd_solver.cpp:106] Iteration 48433, lr = 0.0025
I0524 21:46:32.603960 14843 solver.cpp:237] Iteration 48620, loss = 1.44066
I0524 21:46:32.603996 14843 solver.cpp:253]     Train net output #0: loss = 1.44066 (* 1 = 1.44066 loss)
I0524 21:46:32.604015 14843 sgd_solver.cpp:106] Iteration 48620, lr = 0.0025
I0524 21:46:38.582170 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_48750.caffemodel
I0524 21:46:38.652359 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_48750.solverstate
I0524 21:46:38.679364 14843 solver.cpp:341] Iteration 48750, Testing net (#0)
I0524 21:47:26.142211 14843 solver.cpp:409]     Test net output #0: accuracy = 0.883747
I0524 21:47:26.142417 14843 solver.cpp:409]     Test net output #1: loss = 0.359848 (* 1 = 0.359848 loss)
I0524 21:47:49.667400 14843 solver.cpp:237] Iteration 48807, loss = 1.21106
I0524 21:47:49.667457 14843 solver.cpp:253]     Train net output #0: loss = 1.21106 (* 1 = 1.21106 loss)
I0524 21:47:49.667476 14843 sgd_solver.cpp:106] Iteration 48807, lr = 0.0025
I0524 21:47:58.329545 14843 solver.cpp:237] Iteration 48994, loss = 1.02561
I0524 21:47:58.329730 14843 solver.cpp:253]     Train net output #0: loss = 1.02561 (* 1 = 1.02561 loss)
I0524 21:47:58.329748 14843 sgd_solver.cpp:106] Iteration 48994, lr = 0.0025
I0524 21:48:06.987478 14843 solver.cpp:237] Iteration 49181, loss = 1.13717
I0524 21:48:06.987514 14843 solver.cpp:253]     Train net output #0: loss = 1.13717 (* 1 = 1.13717 loss)
I0524 21:48:06.987534 14843 sgd_solver.cpp:106] Iteration 49181, lr = 0.0025
I0524 21:48:15.645606 14843 solver.cpp:237] Iteration 49368, loss = 1.09674
I0524 21:48:15.645642 14843 solver.cpp:253]     Train net output #0: loss = 1.09674 (* 1 = 1.09674 loss)
I0524 21:48:15.645661 14843 sgd_solver.cpp:106] Iteration 49368, lr = 0.0025
I0524 21:48:24.307421 14843 solver.cpp:237] Iteration 49555, loss = 1.13754
I0524 21:48:24.307472 14843 solver.cpp:253]     Train net output #0: loss = 1.13754 (* 1 = 1.13754 loss)
I0524 21:48:24.307497 14843 sgd_solver.cpp:106] Iteration 49555, lr = 0.0025
I0524 21:48:32.966562 14843 solver.cpp:237] Iteration 49742, loss = 1.09363
I0524 21:48:32.966729 14843 solver.cpp:253]     Train net output #0: loss = 1.09363 (* 1 = 1.09363 loss)
I0524 21:48:32.966745 14843 sgd_solver.cpp:106] Iteration 49742, lr = 0.0025
I0524 21:48:41.626328 14843 solver.cpp:237] Iteration 49929, loss = 1.284
I0524 21:48:41.626382 14843 solver.cpp:253]     Train net output #0: loss = 1.284 (* 1 = 1.284 loss)
I0524 21:48:41.626407 14843 sgd_solver.cpp:106] Iteration 49929, lr = 0.0025
I0524 21:49:11.170805 14843 solver.cpp:237] Iteration 50116, loss = 1.16874
I0524 21:49:11.170989 14843 solver.cpp:253]     Train net output #0: loss = 1.16874 (* 1 = 1.16874 loss)
I0524 21:49:11.171006 14843 sgd_solver.cpp:106] Iteration 50116, lr = 0.0025
I0524 21:49:19.834316 14843 solver.cpp:237] Iteration 50303, loss = 1.29223
I0524 21:49:19.834353 14843 solver.cpp:253]     Train net output #0: loss = 1.29223 (* 1 = 1.29223 loss)
I0524 21:49:19.834372 14843 sgd_solver.cpp:106] Iteration 50303, lr = 0.0025
I0524 21:49:28.491425 14843 solver.cpp:237] Iteration 50490, loss = 1.04259
I0524 21:49:28.491466 14843 solver.cpp:253]     Train net output #0: loss = 1.04259 (* 1 = 1.04259 loss)
I0524 21:49:28.491482 14843 sgd_solver.cpp:106] Iteration 50490, lr = 0.0025
I0524 21:49:34.696652 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_50625.caffemodel
I0524 21:49:34.767091 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_50625.solverstate
I0524 21:49:37.217119 14843 solver.cpp:237] Iteration 50677, loss = 1.01076
I0524 21:49:37.217170 14843 solver.cpp:253]     Train net output #0: loss = 1.01076 (* 1 = 1.01076 loss)
I0524 21:49:37.217195 14843 sgd_solver.cpp:106] Iteration 50677, lr = 0.0025
I0524 21:49:45.878720 14843 solver.cpp:237] Iteration 50864, loss = 1.16969
I0524 21:49:45.878901 14843 solver.cpp:253]     Train net output #0: loss = 1.16969 (* 1 = 1.16969 loss)
I0524 21:49:45.878917 14843 sgd_solver.cpp:106] Iteration 50864, lr = 0.0025
I0524 21:49:54.538157 14843 solver.cpp:237] Iteration 51051, loss = 1.1032
I0524 21:49:54.538194 14843 solver.cpp:253]     Train net output #0: loss = 1.1032 (* 1 = 1.1032 loss)
I0524 21:49:54.538213 14843 sgd_solver.cpp:106] Iteration 51051, lr = 0.0025
I0524 21:50:03.201213 14843 solver.cpp:237] Iteration 51238, loss = 1.19308
I0524 21:50:03.201267 14843 solver.cpp:253]     Train net output #0: loss = 1.19308 (* 1 = 1.19308 loss)
I0524 21:50:03.201287 14843 sgd_solver.cpp:106] Iteration 51238, lr = 0.0025
I0524 21:50:32.794153 14843 solver.cpp:237] Iteration 51425, loss = 1.36484
I0524 21:50:32.794347 14843 solver.cpp:253]     Train net output #0: loss = 1.36484 (* 1 = 1.36484 loss)
I0524 21:50:32.794371 14843 sgd_solver.cpp:106] Iteration 51425, lr = 0.0025
I0524 21:50:41.451931 14843 solver.cpp:237] Iteration 51612, loss = 1.12359
I0524 21:50:41.451968 14843 solver.cpp:253]     Train net output #0: loss = 1.12359 (* 1 = 1.12359 loss)
I0524 21:50:41.451992 14843 sgd_solver.cpp:106] Iteration 51612, lr = 0.0025
I0524 21:50:50.111697 14843 solver.cpp:237] Iteration 51799, loss = 1.27146
I0524 21:50:50.111748 14843 solver.cpp:253]     Train net output #0: loss = 1.27146 (* 1 = 1.27146 loss)
I0524 21:50:50.111774 14843 sgd_solver.cpp:106] Iteration 51799, lr = 0.0025
I0524 21:50:58.772598 14843 solver.cpp:237] Iteration 51986, loss = 1.04437
I0524 21:50:58.772635 14843 solver.cpp:253]     Train net output #0: loss = 1.04437 (* 1 = 1.04437 loss)
I0524 21:50:58.772651 14843 sgd_solver.cpp:106] Iteration 51986, lr = 0.0025
I0524 21:51:07.429440 14843 solver.cpp:237] Iteration 52173, loss = 1.30966
I0524 21:51:07.429608 14843 solver.cpp:253]     Train net output #0: loss = 1.30966 (* 1 = 1.30966 loss)
I0524 21:51:07.429625 14843 sgd_solver.cpp:106] Iteration 52173, lr = 0.0025
I0524 21:51:16.082015 14843 solver.cpp:237] Iteration 52360, loss = 1.26673
I0524 21:51:16.082067 14843 solver.cpp:253]     Train net output #0: loss = 1.26673 (* 1 = 1.26673 loss)
I0524 21:51:16.082103 14843 sgd_solver.cpp:106] Iteration 52360, lr = 0.0025
I0524 21:51:22.513741 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_52500.caffemodel
I0524 21:51:22.583359 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_52500.solverstate
I0524 21:51:22.610133 14843 solver.cpp:341] Iteration 52500, Testing net (#0)
I0524 21:52:30.977535 14843 solver.cpp:409]     Test net output #0: accuracy = 0.888112
I0524 21:52:30.977721 14843 solver.cpp:409]     Test net output #1: loss = 0.35905 (* 1 = 0.35905 loss)
I0524 21:52:54.025575 14843 solver.cpp:237] Iteration 52547, loss = 1.10567
I0524 21:52:54.025629 14843 solver.cpp:253]     Train net output #0: loss = 1.10567 (* 1 = 1.10567 loss)
I0524 21:52:54.025653 14843 sgd_solver.cpp:106] Iteration 52547, lr = 0.0025
I0524 21:53:02.704761 14843 solver.cpp:237] Iteration 52734, loss = 0.839308
I0524 21:53:02.704941 14843 solver.cpp:253]     Train net output #0: loss = 0.839308 (* 1 = 0.839308 loss)
I0524 21:53:02.704958 14843 sgd_solver.cpp:106] Iteration 52734, lr = 0.0025
I0524 21:53:11.382264 14843 solver.cpp:237] Iteration 52921, loss = 1.08267
I0524 21:53:11.382300 14843 solver.cpp:253]     Train net output #0: loss = 1.08267 (* 1 = 1.08267 loss)
I0524 21:53:11.382319 14843 sgd_solver.cpp:106] Iteration 52921, lr = 0.0025
I0524 21:53:20.059134 14843 solver.cpp:237] Iteration 53108, loss = 1.24208
I0524 21:53:20.059188 14843 solver.cpp:253]     Train net output #0: loss = 1.24208 (* 1 = 1.24208 loss)
I0524 21:53:20.059213 14843 sgd_solver.cpp:106] Iteration 53108, lr = 0.0025
I0524 21:53:28.735568 14843 solver.cpp:237] Iteration 53295, loss = 1.25385
I0524 21:53:28.735604 14843 solver.cpp:253]     Train net output #0: loss = 1.25385 (* 1 = 1.25385 loss)
I0524 21:53:28.735622 14843 sgd_solver.cpp:106] Iteration 53295, lr = 0.0025
I0524 21:53:37.411654 14843 solver.cpp:237] Iteration 53482, loss = 1.14132
I0524 21:53:37.411824 14843 solver.cpp:253]     Train net output #0: loss = 1.14132 (* 1 = 1.14132 loss)
I0524 21:53:37.411840 14843 sgd_solver.cpp:106] Iteration 53482, lr = 0.0025
I0524 21:53:46.086383 14843 solver.cpp:237] Iteration 53669, loss = 1.18846
I0524 21:53:46.086437 14843 solver.cpp:253]     Train net output #0: loss = 1.18846 (* 1 = 1.18846 loss)
I0524 21:53:46.086462 14843 sgd_solver.cpp:106] Iteration 53669, lr = 0.0025
I0524 21:54:15.678164 14843 solver.cpp:237] Iteration 53856, loss = 1.08698
I0524 21:54:15.678364 14843 solver.cpp:253]     Train net output #0: loss = 1.08698 (* 1 = 1.08698 loss)
I0524 21:54:15.678381 14843 sgd_solver.cpp:106] Iteration 53856, lr = 0.0025
I0524 21:54:24.357292 14843 solver.cpp:237] Iteration 54043, loss = 1.15042
I0524 21:54:24.357331 14843 solver.cpp:253]     Train net output #0: loss = 1.15042 (* 1 = 1.15042 loss)
I0524 21:54:24.357348 14843 sgd_solver.cpp:106] Iteration 54043, lr = 0.0025
I0524 21:54:33.031352 14843 solver.cpp:237] Iteration 54230, loss = 1.10846
I0524 21:54:33.031404 14843 solver.cpp:253]     Train net output #0: loss = 1.10846 (* 1 = 1.10846 loss)
I0524 21:54:33.031430 14843 sgd_solver.cpp:106] Iteration 54230, lr = 0.0025
I0524 21:54:39.714522 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_54375.caffemodel
I0524 21:54:39.786274 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_54375.solverstate
I0524 21:54:41.776532 14843 solver.cpp:237] Iteration 54417, loss = 1.17464
I0524 21:54:41.776587 14843 solver.cpp:253]     Train net output #0: loss = 1.17464 (* 1 = 1.17464 loss)
I0524 21:54:41.776610 14843 sgd_solver.cpp:106] Iteration 54417, lr = 0.0025
I0524 21:54:50.451267 14843 solver.cpp:237] Iteration 54604, loss = 1.16501
I0524 21:54:50.451449 14843 solver.cpp:253]     Train net output #0: loss = 1.16501 (* 1 = 1.16501 loss)
I0524 21:54:50.451467 14843 sgd_solver.cpp:106] Iteration 54604, lr = 0.0025
I0524 21:54:59.130666 14843 solver.cpp:237] Iteration 54791, loss = 1.23588
I0524 21:54:59.130720 14843 solver.cpp:253]     Train net output #0: loss = 1.23588 (* 1 = 1.23588 loss)
I0524 21:54:59.130745 14843 sgd_solver.cpp:106] Iteration 54791, lr = 0.0025
I0524 21:55:07.807188 14843 solver.cpp:237] Iteration 54978, loss = 1.21712
I0524 21:55:07.807225 14843 solver.cpp:253]     Train net output #0: loss = 1.21712 (* 1 = 1.21712 loss)
I0524 21:55:07.807248 14843 sgd_solver.cpp:106] Iteration 54978, lr = 0.0025
I0524 21:55:37.367790 14843 solver.cpp:237] Iteration 55165, loss = 1.08683
I0524 21:55:37.367976 14843 solver.cpp:253]     Train net output #0: loss = 1.08683 (* 1 = 1.08683 loss)
I0524 21:55:37.367995 14843 sgd_solver.cpp:106] Iteration 55165, lr = 0.0025
I0524 21:55:46.042172 14843 solver.cpp:237] Iteration 55352, loss = 0.895027
I0524 21:55:46.042228 14843 solver.cpp:253]     Train net output #0: loss = 0.895027 (* 1 = 0.895027 loss)
I0524 21:55:46.042254 14843 sgd_solver.cpp:106] Iteration 55352, lr = 0.0025
I0524 21:55:54.701534 14843 solver.cpp:237] Iteration 55539, loss = 1.21527
I0524 21:55:54.701571 14843 solver.cpp:253]     Train net output #0: loss = 1.21527 (* 1 = 1.21527 loss)
I0524 21:55:54.701589 14843 sgd_solver.cpp:106] Iteration 55539, lr = 0.0025
I0524 21:56:03.360436 14843 solver.cpp:237] Iteration 55726, loss = 1.42554
I0524 21:56:03.360472 14843 solver.cpp:253]     Train net output #0: loss = 1.42554 (* 1 = 1.42554 loss)
I0524 21:56:03.360491 14843 sgd_solver.cpp:106] Iteration 55726, lr = 0.0025
I0524 21:56:12.023874 14843 solver.cpp:237] Iteration 55913, loss = 1.12001
I0524 21:56:12.024058 14843 solver.cpp:253]     Train net output #0: loss = 1.12001 (* 1 = 1.12001 loss)
I0524 21:56:12.024075 14843 sgd_solver.cpp:106] Iteration 55913, lr = 0.0025
I0524 21:56:20.688797 14843 solver.cpp:237] Iteration 56100, loss = 1.24454
I0524 21:56:20.688834 14843 solver.cpp:253]     Train net output #0: loss = 1.24454 (* 1 = 1.24454 loss)
I0524 21:56:20.688853 14843 sgd_solver.cpp:106] Iteration 56100, lr = 0.0025
I0524 21:56:27.591641 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_56250.caffemodel
I0524 21:56:27.662688 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_56250.solverstate
I0524 21:56:27.693423 14843 solver.cpp:341] Iteration 56250, Testing net (#0)
I0524 21:57:14.803114 14843 solver.cpp:409]     Test net output #0: accuracy = 0.888893
I0524 21:57:14.803318 14843 solver.cpp:409]     Test net output #1: loss = 0.368533 (* 1 = 0.368533 loss)
I0524 21:57:37.412797 14843 solver.cpp:237] Iteration 56287, loss = 1.2578
I0524 21:57:37.412848 14843 solver.cpp:253]     Train net output #0: loss = 1.2578 (* 1 = 1.2578 loss)
I0524 21:57:37.412873 14843 sgd_solver.cpp:106] Iteration 56287, lr = 0.0025
I0524 21:57:46.065685 14843 solver.cpp:237] Iteration 56474, loss = 1.05444
I0524 21:57:46.065868 14843 solver.cpp:253]     Train net output #0: loss = 1.05444 (* 1 = 1.05444 loss)
I0524 21:57:46.065886 14843 sgd_solver.cpp:106] Iteration 56474, lr = 0.0025
I0524 21:57:54.718230 14843 solver.cpp:237] Iteration 56661, loss = 1.13334
I0524 21:57:54.718279 14843 solver.cpp:253]     Train net output #0: loss = 1.13334 (* 1 = 1.13334 loss)
I0524 21:57:54.718307 14843 sgd_solver.cpp:106] Iteration 56661, lr = 0.0025
I0524 21:58:03.373215 14843 solver.cpp:237] Iteration 56848, loss = 1.25817
I0524 21:58:03.373252 14843 solver.cpp:253]     Train net output #0: loss = 1.25817 (* 1 = 1.25817 loss)
I0524 21:58:03.373270 14843 sgd_solver.cpp:106] Iteration 56848, lr = 0.0025
I0524 21:58:12.030781 14843 solver.cpp:237] Iteration 57035, loss = 1.08897
I0524 21:58:12.030817 14843 solver.cpp:253]     Train net output #0: loss = 1.08897 (* 1 = 1.08897 loss)
I0524 21:58:12.030835 14843 sgd_solver.cpp:106] Iteration 57035, lr = 0.0025
I0524 21:58:20.688171 14843 solver.cpp:237] Iteration 57222, loss = 1.21114
I0524 21:58:20.688356 14843 solver.cpp:253]     Train net output #0: loss = 1.21114 (* 1 = 1.21114 loss)
I0524 21:58:20.688374 14843 sgd_solver.cpp:106] Iteration 57222, lr = 0.0025
I0524 21:58:29.347007 14843 solver.cpp:237] Iteration 57409, loss = 1.27258
I0524 21:58:29.347044 14843 solver.cpp:253]     Train net output #0: loss = 1.27258 (* 1 = 1.27258 loss)
I0524 21:58:29.347064 14843 sgd_solver.cpp:106] Iteration 57409, lr = 0.0025
I0524 21:58:58.858383 14843 solver.cpp:237] Iteration 57596, loss = 1.02962
I0524 21:58:58.858568 14843 solver.cpp:253]     Train net output #0: loss = 1.02962 (* 1 = 1.02962 loss)
I0524 21:58:58.858587 14843 sgd_solver.cpp:106] Iteration 57596, lr = 0.0025
I0524 21:59:07.517761 14843 solver.cpp:237] Iteration 57783, loss = 1.16604
I0524 21:59:07.517815 14843 solver.cpp:253]     Train net output #0: loss = 1.16604 (* 1 = 1.16604 loss)
I0524 21:59:07.517839 14843 sgd_solver.cpp:106] Iteration 57783, lr = 0.0025
I0524 21:59:16.179199 14843 solver.cpp:237] Iteration 57970, loss = 1.1936
I0524 21:59:16.179236 14843 solver.cpp:253]     Train net output #0: loss = 1.1936 (* 1 = 1.1936 loss)
I0524 21:59:16.179255 14843 sgd_solver.cpp:106] Iteration 57970, lr = 0.0025
I0524 21:59:23.314682 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_58125.caffemodel
I0524 21:59:23.384805 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_58125.solverstate
I0524 21:59:24.907032 14843 solver.cpp:237] Iteration 58157, loss = 1.27716
I0524 21:59:24.907083 14843 solver.cpp:253]     Train net output #0: loss = 1.27716 (* 1 = 1.27716 loss)
I0524 21:59:24.907109 14843 sgd_solver.cpp:106] Iteration 58157, lr = 0.0025
I0524 21:59:33.566474 14843 solver.cpp:237] Iteration 58344, loss = 1.22209
I0524 21:59:33.566673 14843 solver.cpp:253]     Train net output #0: loss = 1.22209 (* 1 = 1.22209 loss)
I0524 21:59:33.566691 14843 sgd_solver.cpp:106] Iteration 58344, lr = 0.0025
I0524 21:59:42.225612 14843 solver.cpp:237] Iteration 58531, loss = 1.3566
I0524 21:59:42.225649 14843 solver.cpp:253]     Train net output #0: loss = 1.3566 (* 1 = 1.3566 loss)
I0524 21:59:42.225668 14843 sgd_solver.cpp:106] Iteration 58531, lr = 0.0025
I0524 21:59:50.886165 14843 solver.cpp:237] Iteration 58718, loss = 1.12201
I0524 21:59:50.886206 14843 solver.cpp:253]     Train net output #0: loss = 1.12201 (* 1 = 1.12201 loss)
I0524 21:59:50.886224 14843 sgd_solver.cpp:106] Iteration 58718, lr = 0.0025
I0524 22:00:20.400908 14843 solver.cpp:237] Iteration 58905, loss = 1.07073
I0524 22:00:20.401104 14843 solver.cpp:253]     Train net output #0: loss = 1.07073 (* 1 = 1.07073 loss)
I0524 22:00:20.401123 14843 sgd_solver.cpp:106] Iteration 58905, lr = 0.0025
I0524 22:00:29.052870 14843 solver.cpp:237] Iteration 59092, loss = 1.17161
I0524 22:00:29.052923 14843 solver.cpp:253]     Train net output #0: loss = 1.17161 (* 1 = 1.17161 loss)
I0524 22:00:29.052948 14843 sgd_solver.cpp:106] Iteration 59092, lr = 0.0025
I0524 22:00:37.702158 14843 solver.cpp:237] Iteration 59279, loss = 0.977784
I0524 22:00:37.702195 14843 solver.cpp:253]     Train net output #0: loss = 0.977784 (* 1 = 0.977784 loss)
I0524 22:00:37.702214 14843 sgd_solver.cpp:106] Iteration 59279, lr = 0.0025
I0524 22:00:46.352308 14843 solver.cpp:237] Iteration 59466, loss = 1.1266
I0524 22:00:46.352361 14843 solver.cpp:253]     Train net output #0: loss = 1.1266 (* 1 = 1.1266 loss)
I0524 22:00:46.352386 14843 sgd_solver.cpp:106] Iteration 59466, lr = 0.0025
I0524 22:00:55.008337 14843 solver.cpp:237] Iteration 59653, loss = 1.20518
I0524 22:00:55.008508 14843 solver.cpp:253]     Train net output #0: loss = 1.20518 (* 1 = 1.20518 loss)
I0524 22:00:55.008525 14843 sgd_solver.cpp:106] Iteration 59653, lr = 0.0025
I0524 22:01:03.657399 14843 solver.cpp:237] Iteration 59840, loss = 1.20434
I0524 22:01:03.657436 14843 solver.cpp:253]     Train net output #0: loss = 1.20434 (* 1 = 1.20434 loss)
I0524 22:01:03.657455 14843 sgd_solver.cpp:106] Iteration 59840, lr = 0.0025
I0524 22:01:11.014098 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_60000.caffemodel
I0524 22:01:11.084164 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_60000.solverstate
I0524 22:01:11.111078 14843 solver.cpp:341] Iteration 60000, Testing net (#0)
I0524 22:02:19.421182 14843 solver.cpp:409]     Test net output #0: accuracy = 0.889652
I0524 22:02:19.421373 14843 solver.cpp:409]     Test net output #1: loss = 0.348464 (* 1 = 0.348464 loss)
I0524 22:02:41.550740 14843 solver.cpp:237] Iteration 60027, loss = 0.988298
I0524 22:02:41.550793 14843 solver.cpp:253]     Train net output #0: loss = 0.988298 (* 1 = 0.988298 loss)
I0524 22:02:41.550817 14843 sgd_solver.cpp:106] Iteration 60027, lr = 0.0025
I0524 22:02:50.198762 14843 solver.cpp:237] Iteration 60214, loss = 0.996834
I0524 22:02:50.198935 14843 solver.cpp:253]     Train net output #0: loss = 0.996834 (* 1 = 0.996834 loss)
I0524 22:02:50.198951 14843 sgd_solver.cpp:106] Iteration 60214, lr = 0.0025
I0524 22:02:58.850155 14843 solver.cpp:237] Iteration 60401, loss = 1.31765
I0524 22:02:58.850203 14843 solver.cpp:253]     Train net output #0: loss = 1.31765 (* 1 = 1.31765 loss)
I0524 22:02:58.850227 14843 sgd_solver.cpp:106] Iteration 60401, lr = 0.0025
I0524 22:03:07.499047 14843 solver.cpp:237] Iteration 60588, loss = 1.07276
I0524 22:03:07.499083 14843 solver.cpp:253]     Train net output #0: loss = 1.07276 (* 1 = 1.07276 loss)
I0524 22:03:07.499102 14843 sgd_solver.cpp:106] Iteration 60588, lr = 0.0025
I0524 22:03:16.147594 14843 solver.cpp:237] Iteration 60775, loss = 0.982624
I0524 22:03:16.147649 14843 solver.cpp:253]     Train net output #0: loss = 0.982624 (* 1 = 0.982624 loss)
I0524 22:03:16.147673 14843 sgd_solver.cpp:106] Iteration 60775, lr = 0.0025
I0524 22:03:24.794751 14843 solver.cpp:237] Iteration 60962, loss = 1.11505
I0524 22:03:24.794934 14843 solver.cpp:253]     Train net output #0: loss = 1.11505 (* 1 = 1.11505 loss)
I0524 22:03:24.794951 14843 sgd_solver.cpp:106] Iteration 60962, lr = 0.0025
I0524 22:03:33.446283 14843 solver.cpp:237] Iteration 61149, loss = 1.18066
I0524 22:03:33.446321 14843 solver.cpp:253]     Train net output #0: loss = 1.18066 (* 1 = 1.18066 loss)
I0524 22:03:33.446338 14843 sgd_solver.cpp:106] Iteration 61149, lr = 0.0025
I0524 22:04:03.009165 14843 solver.cpp:237] Iteration 61336, loss = 1.33774
I0524 22:04:03.009354 14843 solver.cpp:253]     Train net output #0: loss = 1.33774 (* 1 = 1.33774 loss)
I0524 22:04:03.009371 14843 sgd_solver.cpp:106] Iteration 61336, lr = 0.0025
I0524 22:04:11.662839 14843 solver.cpp:237] Iteration 61523, loss = 1.28534
I0524 22:04:11.662890 14843 solver.cpp:253]     Train net output #0: loss = 1.28534 (* 1 = 1.28534 loss)
I0524 22:04:11.662915 14843 sgd_solver.cpp:106] Iteration 61523, lr = 0.0025
I0524 22:04:20.310261 14843 solver.cpp:237] Iteration 61710, loss = 1.19698
I0524 22:04:20.310297 14843 solver.cpp:253]     Train net output #0: loss = 1.19698 (* 1 = 1.19698 loss)
I0524 22:04:20.310317 14843 sgd_solver.cpp:106] Iteration 61710, lr = 0.0025
I0524 22:04:27.893512 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_61875.caffemodel
I0524 22:04:27.964470 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_61875.solverstate
I0524 22:04:29.023344 14843 solver.cpp:237] Iteration 61897, loss = 0.892306
I0524 22:04:29.023398 14843 solver.cpp:253]     Train net output #0: loss = 0.892306 (* 1 = 0.892306 loss)
I0524 22:04:29.023418 14843 sgd_solver.cpp:106] Iteration 61897, lr = 0.0025
I0524 22:04:37.673635 14843 solver.cpp:237] Iteration 62084, loss = 1.0112
I0524 22:04:37.673820 14843 solver.cpp:253]     Train net output #0: loss = 1.0112 (* 1 = 1.0112 loss)
I0524 22:04:37.673836 14843 sgd_solver.cpp:106] Iteration 62084, lr = 0.0025
I0524 22:04:46.327582 14843 solver.cpp:237] Iteration 62271, loss = 1.18865
I0524 22:04:46.327620 14843 solver.cpp:253]     Train net output #0: loss = 1.18865 (* 1 = 1.18865 loss)
I0524 22:04:46.327639 14843 sgd_solver.cpp:106] Iteration 62271, lr = 0.0025
I0524 22:04:54.980907 14843 solver.cpp:237] Iteration 62458, loss = 1.06488
I0524 22:04:54.980943 14843 solver.cpp:253]     Train net output #0: loss = 1.06488 (* 1 = 1.06488 loss)
I0524 22:04:54.980962 14843 sgd_solver.cpp:106] Iteration 62458, lr = 0.0025
I0524 22:05:24.525683 14843 solver.cpp:237] Iteration 62645, loss = 1.14928
I0524 22:05:24.525869 14843 solver.cpp:253]     Train net output #0: loss = 1.14928 (* 1 = 1.14928 loss)
I0524 22:05:24.525887 14843 sgd_solver.cpp:106] Iteration 62645, lr = 0.0025
I0524 22:05:33.174767 14843 solver.cpp:237] Iteration 62832, loss = 0.965472
I0524 22:05:33.174804 14843 solver.cpp:253]     Train net output #0: loss = 0.965472 (* 1 = 0.965472 loss)
I0524 22:05:33.174821 14843 sgd_solver.cpp:106] Iteration 62832, lr = 0.0025
I0524 22:05:41.821157 14843 solver.cpp:237] Iteration 63019, loss = 1.20894
I0524 22:05:41.821193 14843 solver.cpp:253]     Train net output #0: loss = 1.20894 (* 1 = 1.20894 loss)
I0524 22:05:41.821213 14843 sgd_solver.cpp:106] Iteration 63019, lr = 0.0025
I0524 22:05:50.474580 14843 solver.cpp:237] Iteration 63206, loss = 1.06149
I0524 22:05:50.474632 14843 solver.cpp:253]     Train net output #0: loss = 1.06149 (* 1 = 1.06149 loss)
I0524 22:05:50.474656 14843 sgd_solver.cpp:106] Iteration 63206, lr = 0.0025
I0524 22:05:59.124507 14843 solver.cpp:237] Iteration 63393, loss = 1.06798
I0524 22:05:59.124680 14843 solver.cpp:253]     Train net output #0: loss = 1.06798 (* 1 = 1.06798 loss)
I0524 22:05:59.124697 14843 sgd_solver.cpp:106] Iteration 63393, lr = 0.0025
I0524 22:06:07.773303 14843 solver.cpp:237] Iteration 63580, loss = 1.19122
I0524 22:06:07.773339 14843 solver.cpp:253]     Train net output #0: loss = 1.19122 (* 1 = 1.19122 loss)
I0524 22:06:07.773357 14843 sgd_solver.cpp:106] Iteration 63580, lr = 0.0025
I0524 22:06:15.590953 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_63750.caffemodel
I0524 22:06:15.660986 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_63750.solverstate
I0524 22:06:15.690914 14843 solver.cpp:341] Iteration 63750, Testing net (#0)
I0524 22:07:03.123592 14843 solver.cpp:409]     Test net output #0: accuracy = 0.8928
I0524 22:07:03.123791 14843 solver.cpp:409]     Test net output #1: loss = 0.374075 (* 1 = 0.374075 loss)
I0524 22:07:24.795708 14843 solver.cpp:237] Iteration 63767, loss = 1.09716
I0524 22:07:24.795765 14843 solver.cpp:253]     Train net output #0: loss = 1.09716 (* 1 = 1.09716 loss)
I0524 22:07:24.795785 14843 sgd_solver.cpp:106] Iteration 63767, lr = 0.0025
I0524 22:07:33.454387 14843 solver.cpp:237] Iteration 63954, loss = 1.13844
I0524 22:07:33.454576 14843 solver.cpp:253]     Train net output #0: loss = 1.13844 (* 1 = 1.13844 loss)
I0524 22:07:33.454593 14843 sgd_solver.cpp:106] Iteration 63954, lr = 0.0025
I0524 22:07:42.088927 14843 solver.cpp:237] Iteration 64141, loss = 1.01462
I0524 22:07:42.088964 14843 solver.cpp:253]     Train net output #0: loss = 1.01462 (* 1 = 1.01462 loss)
I0524 22:07:42.088981 14843 sgd_solver.cpp:106] Iteration 64141, lr = 0.0025
I0524 22:07:50.726215 14843 solver.cpp:237] Iteration 64328, loss = 1.06119
I0524 22:07:50.726253 14843 solver.cpp:253]     Train net output #0: loss = 1.06119 (* 1 = 1.06119 loss)
I0524 22:07:50.726271 14843 sgd_solver.cpp:106] Iteration 64328, lr = 0.0025
I0524 22:07:59.366518 14843 solver.cpp:237] Iteration 64515, loss = 1.25009
I0524 22:07:59.366571 14843 solver.cpp:253]     Train net output #0: loss = 1.25009 (* 1 = 1.25009 loss)
I0524 22:07:59.366590 14843 sgd_solver.cpp:106] Iteration 64515, lr = 0.0025
I0524 22:08:08.003252 14843 solver.cpp:237] Iteration 64702, loss = 1.13369
I0524 22:08:08.003427 14843 solver.cpp:253]     Train net output #0: loss = 1.13369 (* 1 = 1.13369 loss)
I0524 22:08:08.003443 14843 sgd_solver.cpp:106] Iteration 64702, lr = 0.0025
I0524 22:08:16.638623 14843 solver.cpp:237] Iteration 64889, loss = 1.0747
I0524 22:08:16.638677 14843 solver.cpp:253]     Train net output #0: loss = 1.0747 (* 1 = 1.0747 loss)
I0524 22:08:16.638696 14843 sgd_solver.cpp:106] Iteration 64889, lr = 0.0025
I0524 22:08:46.172224 14843 solver.cpp:237] Iteration 65076, loss = 1.24972
I0524 22:08:46.172416 14843 solver.cpp:253]     Train net output #0: loss = 1.24972 (* 1 = 1.24972 loss)
I0524 22:08:46.172435 14843 sgd_solver.cpp:106] Iteration 65076, lr = 0.0025
I0524 22:08:54.809664 14843 solver.cpp:237] Iteration 65263, loss = 1.22584
I0524 22:08:54.809701 14843 solver.cpp:253]     Train net output #0: loss = 1.22584 (* 1 = 1.22584 loss)
I0524 22:08:54.809720 14843 sgd_solver.cpp:106] Iteration 65263, lr = 0.0025
I0524 22:09:03.450013 14843 solver.cpp:237] Iteration 65450, loss = 1.30148
I0524 22:09:03.450050 14843 solver.cpp:253]     Train net output #0: loss = 1.30148 (* 1 = 1.30148 loss)
I0524 22:09:03.450069 14843 sgd_solver.cpp:106] Iteration 65450, lr = 0.0025
I0524 22:09:11.489337 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_65625.caffemodel
I0524 22:09:11.562837 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_65625.solverstate
I0524 22:09:12.160877 14843 solver.cpp:237] Iteration 65637, loss = 1.15978
I0524 22:09:12.160928 14843 solver.cpp:253]     Train net output #0: loss = 1.15978 (* 1 = 1.15978 loss)
I0524 22:09:12.160953 14843 sgd_solver.cpp:106] Iteration 65637, lr = 0.0025
I0524 22:09:20.797516 14843 solver.cpp:237] Iteration 65824, loss = 1.11552
I0524 22:09:20.797706 14843 solver.cpp:253]     Train net output #0: loss = 1.11552 (* 1 = 1.11552 loss)
I0524 22:09:20.797724 14843 sgd_solver.cpp:106] Iteration 65824, lr = 0.0025
I0524 22:09:29.434793 14843 solver.cpp:237] Iteration 66011, loss = 1.09982
I0524 22:09:29.434830 14843 solver.cpp:253]     Train net output #0: loss = 1.09982 (* 1 = 1.09982 loss)
I0524 22:09:29.434849 14843 sgd_solver.cpp:106] Iteration 66011, lr = 0.0025
I0524 22:09:38.075896 14843 solver.cpp:237] Iteration 66198, loss = 1.41075
I0524 22:09:38.075948 14843 solver.cpp:253]     Train net output #0: loss = 1.41075 (* 1 = 1.41075 loss)
I0524 22:09:38.075971 14843 sgd_solver.cpp:106] Iteration 66198, lr = 0.0025
I0524 22:10:07.574504 14843 solver.cpp:237] Iteration 66385, loss = 1.15068
I0524 22:10:07.574702 14843 solver.cpp:253]     Train net output #0: loss = 1.15068 (* 1 = 1.15068 loss)
I0524 22:10:07.574720 14843 sgd_solver.cpp:106] Iteration 66385, lr = 0.0025
I0524 22:10:16.216174 14843 solver.cpp:237] Iteration 66572, loss = 1.07939
I0524 22:10:16.216213 14843 solver.cpp:253]     Train net output #0: loss = 1.07939 (* 1 = 1.07939 loss)
I0524 22:10:16.216229 14843 sgd_solver.cpp:106] Iteration 66572, lr = 0.0025
I0524 22:10:24.858597 14843 solver.cpp:237] Iteration 66759, loss = 1.18091
I0524 22:10:24.858651 14843 solver.cpp:253]     Train net output #0: loss = 1.18091 (* 1 = 1.18091 loss)
I0524 22:10:24.858676 14843 sgd_solver.cpp:106] Iteration 66759, lr = 0.0025
I0524 22:10:33.499472 14843 solver.cpp:237] Iteration 66946, loss = 1.20572
I0524 22:10:33.499510 14843 solver.cpp:253]     Train net output #0: loss = 1.20572 (* 1 = 1.20572 loss)
I0524 22:10:33.499528 14843 sgd_solver.cpp:106] Iteration 66946, lr = 0.0025
I0524 22:10:42.137253 14843 solver.cpp:237] Iteration 67133, loss = 1.41453
I0524 22:10:42.137428 14843 solver.cpp:253]     Train net output #0: loss = 1.41453 (* 1 = 1.41453 loss)
I0524 22:10:42.137444 14843 sgd_solver.cpp:106] Iteration 67133, lr = 0.0025
I0524 22:10:50.777091 14843 solver.cpp:237] Iteration 67320, loss = 1.26693
I0524 22:10:50.777144 14843 solver.cpp:253]     Train net output #0: loss = 1.26693 (* 1 = 1.26693 loss)
I0524 22:10:50.777163 14843 sgd_solver.cpp:106] Iteration 67320, lr = 0.0025
I0524 22:10:59.045478 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_67500.caffemodel
I0524 22:10:59.117785 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_67500.solverstate
I0524 22:10:59.147056 14843 solver.cpp:341] Iteration 67500, Testing net (#0)
I0524 22:12:07.424391 14843 solver.cpp:409]     Test net output #0: accuracy = 0.891241
I0524 22:12:07.424581 14843 solver.cpp:409]     Test net output #1: loss = 0.348041 (* 1 = 0.348041 loss)
I0524 22:12:28.617746 14843 solver.cpp:237] Iteration 67507, loss = 1.25024
I0524 22:12:28.617804 14843 solver.cpp:253]     Train net output #0: loss = 1.25024 (* 1 = 1.25024 loss)
I0524 22:12:28.617821 14843 sgd_solver.cpp:106] Iteration 67507, lr = 0.0025
I0524 22:12:37.277120 14843 solver.cpp:237] Iteration 67694, loss = 1.0453
I0524 22:12:37.277156 14843 solver.cpp:253]     Train net output #0: loss = 1.0453 (* 1 = 1.0453 loss)
I0524 22:12:37.277175 14843 sgd_solver.cpp:106] Iteration 67694, lr = 0.0025
I0524 22:12:45.934039 14843 solver.cpp:237] Iteration 67881, loss = 1.12027
I0524 22:12:45.934233 14843 solver.cpp:253]     Train net output #0: loss = 1.12027 (* 1 = 1.12027 loss)
I0524 22:12:45.934249 14843 sgd_solver.cpp:106] Iteration 67881, lr = 0.0025
I0524 22:12:54.592058 14843 solver.cpp:237] Iteration 68068, loss = 1.22675
I0524 22:12:54.592113 14843 solver.cpp:253]     Train net output #0: loss = 1.22675 (* 1 = 1.22675 loss)
I0524 22:12:54.592139 14843 sgd_solver.cpp:106] Iteration 68068, lr = 0.0025
I0524 22:13:03.255061 14843 solver.cpp:237] Iteration 68255, loss = 1.09567
I0524 22:13:03.255100 14843 solver.cpp:253]     Train net output #0: loss = 1.09567 (* 1 = 1.09567 loss)
I0524 22:13:03.255115 14843 sgd_solver.cpp:106] Iteration 68255, lr = 0.0025
I0524 22:13:11.912407 14843 solver.cpp:237] Iteration 68442, loss = 1.35065
I0524 22:13:11.912446 14843 solver.cpp:253]     Train net output #0: loss = 1.35065 (* 1 = 1.35065 loss)
I0524 22:13:11.912462 14843 sgd_solver.cpp:106] Iteration 68442, lr = 0.0025
I0524 22:13:20.567407 14843 solver.cpp:237] Iteration 68629, loss = 1.03141
I0524 22:13:20.567606 14843 solver.cpp:253]     Train net output #0: loss = 1.03141 (* 1 = 1.03141 loss)
I0524 22:13:20.567623 14843 sgd_solver.cpp:106] Iteration 68629, lr = 0.0025
I0524 22:13:50.117202 14843 solver.cpp:237] Iteration 68816, loss = 1.16247
I0524 22:13:50.117259 14843 solver.cpp:253]     Train net output #0: loss = 1.16247 (* 1 = 1.16247 loss)
I0524 22:13:50.117283 14843 sgd_solver.cpp:106] Iteration 68816, lr = 0.0025
I0524 22:13:58.767220 14843 solver.cpp:237] Iteration 69003, loss = 1.19407
I0524 22:13:58.767402 14843 solver.cpp:253]     Train net output #0: loss = 1.19407 (* 1 = 1.19407 loss)
I0524 22:13:58.767419 14843 sgd_solver.cpp:106] Iteration 69003, lr = 0.0025
I0524 22:14:07.418503 14843 solver.cpp:237] Iteration 69190, loss = 1.07294
I0524 22:14:07.418552 14843 solver.cpp:253]     Train net output #0: loss = 1.07294 (* 1 = 1.07294 loss)
I0524 22:14:07.418581 14843 sgd_solver.cpp:106] Iteration 69190, lr = 0.0025
I0524 22:14:15.928763 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_69375.caffemodel
I0524 22:14:15.999383 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_69375.solverstate
I0524 22:14:16.133121 14843 solver.cpp:237] Iteration 69377, loss = 1.10499
I0524 22:14:16.133173 14843 solver.cpp:253]     Train net output #0: loss = 1.10499 (* 1 = 1.10499 loss)
I0524 22:14:16.133198 14843 sgd_solver.cpp:106] Iteration 69377, lr = 0.0025
I0524 22:14:24.783574 14843 solver.cpp:237] Iteration 69564, loss = 1.1743
I0524 22:14:24.783612 14843 solver.cpp:253]     Train net output #0: loss = 1.1743 (* 1 = 1.1743 loss)
I0524 22:14:24.783637 14843 sgd_solver.cpp:106] Iteration 69564, lr = 0.0025
I0524 22:14:33.434834 14843 solver.cpp:237] Iteration 69751, loss = 1.29574
I0524 22:14:33.435024 14843 solver.cpp:253]     Train net output #0: loss = 1.29574 (* 1 = 1.29574 loss)
I0524 22:14:33.435041 14843 sgd_solver.cpp:106] Iteration 69751, lr = 0.0025
I0524 22:14:42.084887 14843 solver.cpp:237] Iteration 69938, loss = 1.22376
I0524 22:14:42.084923 14843 solver.cpp:253]     Train net output #0: loss = 1.22376 (* 1 = 1.22376 loss)
I0524 22:14:42.084942 14843 sgd_solver.cpp:106] Iteration 69938, lr = 0.0025
I0524 22:15:11.655678 14843 solver.cpp:237] Iteration 70125, loss = 1.12738
I0524 22:15:11.655874 14843 solver.cpp:253]     Train net output #0: loss = 1.12738 (* 1 = 1.12738 loss)
I0524 22:15:11.655892 14843 sgd_solver.cpp:106] Iteration 70125, lr = 0.0025
I0524 22:15:20.306394 14843 solver.cpp:237] Iteration 70312, loss = 1.4242
I0524 22:15:20.306432 14843 solver.cpp:253]     Train net output #0: loss = 1.4242 (* 1 = 1.4242 loss)
I0524 22:15:20.306450 14843 sgd_solver.cpp:106] Iteration 70312, lr = 0.0025
I0524 22:15:28.973083 14843 solver.cpp:237] Iteration 70499, loss = 1.07184
I0524 22:15:28.973136 14843 solver.cpp:253]     Train net output #0: loss = 1.07184 (* 1 = 1.07184 loss)
I0524 22:15:28.973155 14843 sgd_solver.cpp:106] Iteration 70499, lr = 0.0025
I0524 22:15:37.633111 14843 solver.cpp:237] Iteration 70686, loss = 0.94802
I0524 22:15:37.633150 14843 solver.cpp:253]     Train net output #0: loss = 0.94802 (* 1 = 0.94802 loss)
I0524 22:15:37.633167 14843 sgd_solver.cpp:106] Iteration 70686, lr = 0.0025
I0524 22:15:46.296800 14843 solver.cpp:237] Iteration 70873, loss = 1.05247
I0524 22:15:46.297004 14843 solver.cpp:253]     Train net output #0: loss = 1.05247 (* 1 = 1.05247 loss)
I0524 22:15:46.297021 14843 sgd_solver.cpp:106] Iteration 70873, lr = 0.0025
I0524 22:15:54.960149 14843 solver.cpp:237] Iteration 71060, loss = 1.11164
I0524 22:15:54.960186 14843 solver.cpp:253]     Train net output #0: loss = 1.11164 (* 1 = 1.11164 loss)
I0524 22:15:54.960204 14843 sgd_solver.cpp:106] Iteration 71060, lr = 0.0025
I0524 22:16:03.622927 14843 solver.cpp:237] Iteration 71247, loss = 1.38125
I0524 22:16:03.622964 14843 solver.cpp:253]     Train net output #0: loss = 1.38125 (* 1 = 1.38125 loss)
I0524 22:16:03.622983 14843 sgd_solver.cpp:106] Iteration 71247, lr = 0.0025
I0524 22:16:03.715760 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_71250.caffemodel
I0524 22:16:03.785694 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_71250.solverstate
I0524 22:16:03.813235 14843 solver.cpp:341] Iteration 71250, Testing net (#0)
I0524 22:16:50.917074 14843 solver.cpp:409]     Test net output #0: accuracy = 0.89064
I0524 22:16:50.917275 14843 solver.cpp:409]     Test net output #1: loss = 0.341964 (* 1 = 0.341964 loss)
I0524 22:17:20.290313 14843 solver.cpp:237] Iteration 71434, loss = 1.33186
I0524 22:17:20.290369 14843 solver.cpp:253]     Train net output #0: loss = 1.33186 (* 1 = 1.33186 loss)
I0524 22:17:20.290392 14843 sgd_solver.cpp:106] Iteration 71434, lr = 0.0025
I0524 22:17:28.951695 14843 solver.cpp:237] Iteration 71621, loss = 1.11325
I0524 22:17:28.951903 14843 solver.cpp:253]     Train net output #0: loss = 1.11325 (* 1 = 1.11325 loss)
I0524 22:17:28.951921 14843 sgd_solver.cpp:106] Iteration 71621, lr = 0.0025
I0524 22:17:37.610430 14843 solver.cpp:237] Iteration 71808, loss = 1.21575
I0524 22:17:37.610466 14843 solver.cpp:253]     Train net output #0: loss = 1.21575 (* 1 = 1.21575 loss)
I0524 22:17:37.610483 14843 sgd_solver.cpp:106] Iteration 71808, lr = 0.0025
I0524 22:17:46.270313 14843 solver.cpp:237] Iteration 71995, loss = 1.21639
I0524 22:17:46.270350 14843 solver.cpp:253]     Train net output #0: loss = 1.21639 (* 1 = 1.21639 loss)
I0524 22:17:46.270369 14843 sgd_solver.cpp:106] Iteration 71995, lr = 0.0025
I0524 22:17:54.933151 14843 solver.cpp:237] Iteration 72182, loss = 1.21911
I0524 22:17:54.933202 14843 solver.cpp:253]     Train net output #0: loss = 1.21911 (* 1 = 1.21911 loss)
I0524 22:17:54.933228 14843 sgd_solver.cpp:106] Iteration 72182, lr = 0.0025
I0524 22:18:03.593642 14843 solver.cpp:237] Iteration 72369, loss = 1.20724
I0524 22:18:03.593817 14843 solver.cpp:253]     Train net output #0: loss = 1.20724 (* 1 = 1.20724 loss)
I0524 22:18:03.593833 14843 sgd_solver.cpp:106] Iteration 72369, lr = 0.0025
I0524 22:18:33.115244 14843 solver.cpp:237] Iteration 72556, loss = 1.00623
I0524 22:18:33.115303 14843 solver.cpp:253]     Train net output #0: loss = 1.00623 (* 1 = 1.00623 loss)
I0524 22:18:33.115326 14843 sgd_solver.cpp:106] Iteration 72556, lr = 0.0025
I0524 22:18:41.773711 14843 solver.cpp:237] Iteration 72743, loss = 1.16232
I0524 22:18:41.773905 14843 solver.cpp:253]     Train net output #0: loss = 1.16232 (* 1 = 1.16232 loss)
I0524 22:18:41.773923 14843 sgd_solver.cpp:106] Iteration 72743, lr = 0.0025
I0524 22:18:50.433126 14843 solver.cpp:237] Iteration 72930, loss = 1.19245
I0524 22:18:50.433164 14843 solver.cpp:253]     Train net output #0: loss = 1.19245 (* 1 = 1.19245 loss)
I0524 22:18:50.433183 14843 sgd_solver.cpp:106] Iteration 72930, lr = 0.0025
I0524 22:18:59.091501 14843 solver.cpp:237] Iteration 73117, loss = 1.11141
I0524 22:18:59.091537 14843 solver.cpp:253]     Train net output #0: loss = 1.11141 (* 1 = 1.11141 loss)
I0524 22:18:59.091562 14843 sgd_solver.cpp:106] Iteration 73117, lr = 0.0025
I0524 22:18:59.415828 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_73125.caffemodel
I0524 22:18:59.485877 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_73125.solverstate
I0524 22:19:07.818342 14843 solver.cpp:237] Iteration 73304, loss = 1.28731
I0524 22:19:07.818398 14843 solver.cpp:253]     Train net output #0: loss = 1.28731 (* 1 = 1.28731 loss)
I0524 22:19:07.818424 14843 sgd_solver.cpp:106] Iteration 73304, lr = 0.0025
I0524 22:19:16.476774 14843 solver.cpp:237] Iteration 73491, loss = 1.23789
I0524 22:19:16.476963 14843 solver.cpp:253]     Train net output #0: loss = 1.23789 (* 1 = 1.23789 loss)
I0524 22:19:16.476979 14843 sgd_solver.cpp:106] Iteration 73491, lr = 0.0025
I0524 22:19:25.137027 14843 solver.cpp:237] Iteration 73678, loss = 1.24334
I0524 22:19:25.137070 14843 solver.cpp:253]     Train net output #0: loss = 1.24334 (* 1 = 1.24334 loss)
I0524 22:19:25.137087 14843 sgd_solver.cpp:106] Iteration 73678, lr = 0.0025
I0524 22:19:54.722687 14843 solver.cpp:237] Iteration 73865, loss = 1.12759
I0524 22:19:54.722887 14843 solver.cpp:253]     Train net output #0: loss = 1.12759 (* 1 = 1.12759 loss)
I0524 22:19:54.722908 14843 sgd_solver.cpp:106] Iteration 73865, lr = 0.0025
I0524 22:20:03.382133 14843 solver.cpp:237] Iteration 74052, loss = 0.94807
I0524 22:20:03.382189 14843 solver.cpp:253]     Train net output #0: loss = 0.94807 (* 1 = 0.94807 loss)
I0524 22:20:03.382213 14843 sgd_solver.cpp:106] Iteration 74052, lr = 0.0025
I0524 22:20:12.038862 14843 solver.cpp:237] Iteration 74239, loss = 1.49015
I0524 22:20:12.038899 14843 solver.cpp:253]     Train net output #0: loss = 1.49015 (* 1 = 1.49015 loss)
I0524 22:20:12.038924 14843 sgd_solver.cpp:106] Iteration 74239, lr = 0.0025
I0524 22:20:20.697677 14843 solver.cpp:237] Iteration 74426, loss = 1.39678
I0524 22:20:20.697715 14843 solver.cpp:253]     Train net output #0: loss = 1.39678 (* 1 = 1.39678 loss)
I0524 22:20:20.697737 14843 sgd_solver.cpp:106] Iteration 74426, lr = 0.0025
I0524 22:20:29.357333 14843 solver.cpp:237] Iteration 74613, loss = 1.00497
I0524 22:20:29.357524 14843 solver.cpp:253]     Train net output #0: loss = 1.00497 (* 1 = 1.00497 loss)
I0524 22:20:29.357542 14843 sgd_solver.cpp:106] Iteration 74613, lr = 0.0025
I0524 22:20:38.014420 14843 solver.cpp:237] Iteration 74800, loss = 1.08601
I0524 22:20:38.014457 14843 solver.cpp:253]     Train net output #0: loss = 1.08601 (* 1 = 1.08601 loss)
I0524 22:20:38.014473 14843 sgd_solver.cpp:106] Iteration 74800, lr = 0.0025
I0524 22:20:46.674926 14843 solver.cpp:237] Iteration 74987, loss = 0.958748
I0524 22:20:46.674981 14843 solver.cpp:253]     Train net output #0: loss = 0.958748 (* 1 = 0.958748 loss)
I0524 22:20:46.675009 14843 sgd_solver.cpp:106] Iteration 74987, lr = 0.0025
I0524 22:20:47.230429 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_75000.caffemodel
I0524 22:20:47.300017 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_75000.solverstate
I0524 22:20:47.329725 14843 solver.cpp:341] Iteration 75000, Testing net (#0)
I0524 22:21:55.722870 14843 solver.cpp:409]     Test net output #0: accuracy = 0.89136
I0524 22:21:55.723076 14843 solver.cpp:409]     Test net output #1: loss = 0.366613 (* 1 = 0.366613 loss)
I0524 22:22:24.712054 14843 solver.cpp:237] Iteration 75174, loss = 1.23103
I0524 22:22:24.712111 14843 solver.cpp:253]     Train net output #0: loss = 1.23103 (* 1 = 1.23103 loss)
I0524 22:22:24.712136 14843 sgd_solver.cpp:106] Iteration 75174, lr = 0.0025
I0524 22:22:33.383375 14843 solver.cpp:237] Iteration 75361, loss = 1.12461
I0524 22:22:33.383572 14843 solver.cpp:253]     Train net output #0: loss = 1.12461 (* 1 = 1.12461 loss)
I0524 22:22:33.383591 14843 sgd_solver.cpp:106] Iteration 75361, lr = 0.0025
I0524 22:22:42.046341 14843 solver.cpp:237] Iteration 75548, loss = 1.1515
I0524 22:22:42.046377 14843 solver.cpp:253]     Train net output #0: loss = 1.1515 (* 1 = 1.1515 loss)
I0524 22:22:42.046401 14843 sgd_solver.cpp:106] Iteration 75548, lr = 0.0025
I0524 22:22:50.713181 14843 solver.cpp:237] Iteration 75735, loss = 1.09925
I0524 22:22:50.713217 14843 solver.cpp:253]     Train net output #0: loss = 1.09925 (* 1 = 1.09925 loss)
I0524 22:22:50.713237 14843 sgd_solver.cpp:106] Iteration 75735, lr = 0.0025
I0524 22:22:59.374884 14843 solver.cpp:237] Iteration 75922, loss = 1.09612
I0524 22:22:59.374923 14843 solver.cpp:253]     Train net output #0: loss = 1.09612 (* 1 = 1.09612 loss)
I0524 22:22:59.374939 14843 sgd_solver.cpp:106] Iteration 75922, lr = 0.0025
I0524 22:23:08.043149 14843 solver.cpp:237] Iteration 76109, loss = 1.3229
I0524 22:23:08.043328 14843 solver.cpp:253]     Train net output #0: loss = 1.3229 (* 1 = 1.3229 loss)
I0524 22:23:08.043344 14843 sgd_solver.cpp:106] Iteration 76109, lr = 0.0025
I0524 22:23:37.627538 14843 solver.cpp:237] Iteration 76296, loss = 1.07572
I0524 22:23:37.627595 14843 solver.cpp:253]     Train net output #0: loss = 1.07572 (* 1 = 1.07572 loss)
I0524 22:23:37.627621 14843 sgd_solver.cpp:106] Iteration 76296, lr = 0.0025
I0524 22:23:46.301602 14843 solver.cpp:237] Iteration 76483, loss = 1.2795
I0524 22:23:46.301800 14843 solver.cpp:253]     Train net output #0: loss = 1.2795 (* 1 = 1.2795 loss)
I0524 22:23:46.301818 14843 sgd_solver.cpp:106] Iteration 76483, lr = 0.0025
I0524 22:23:54.980972 14843 solver.cpp:237] Iteration 76670, loss = 1.06942
I0524 22:23:54.981009 14843 solver.cpp:253]     Train net output #0: loss = 1.06942 (* 1 = 1.06942 loss)
I0524 22:23:54.981032 14843 sgd_solver.cpp:106] Iteration 76670, lr = 0.0025
I0524 22:24:03.660110 14843 solver.cpp:237] Iteration 76857, loss = 1.22789
I0524 22:24:03.660150 14843 solver.cpp:253]     Train net output #0: loss = 1.22789 (* 1 = 1.22789 loss)
I0524 22:24:03.660167 14843 sgd_solver.cpp:106] Iteration 76857, lr = 0.0025
I0524 22:24:04.450639 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_76875.caffemodel
I0524 22:24:04.520786 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_76875.solverstate
I0524 22:24:12.394243 14843 solver.cpp:237] Iteration 77044, loss = 1.22829
I0524 22:24:12.394299 14843 solver.cpp:253]     Train net output #0: loss = 1.22829 (* 1 = 1.22829 loss)
I0524 22:24:12.394323 14843 sgd_solver.cpp:106] Iteration 77044, lr = 0.0025
I0524 22:24:21.058503 14843 solver.cpp:237] Iteration 77231, loss = 1.27064
I0524 22:24:21.058683 14843 solver.cpp:253]     Train net output #0: loss = 1.27064 (* 1 = 1.27064 loss)
I0524 22:24:21.058701 14843 sgd_solver.cpp:106] Iteration 77231, lr = 0.0025
I0524 22:24:29.719326 14843 solver.cpp:237] Iteration 77418, loss = 1.28588
I0524 22:24:29.719363 14843 solver.cpp:253]     Train net output #0: loss = 1.28588 (* 1 = 1.28588 loss)
I0524 22:24:29.719382 14843 sgd_solver.cpp:106] Iteration 77418, lr = 0.0025
I0524 22:24:59.225706 14843 solver.cpp:237] Iteration 77605, loss = 1.04917
I0524 22:24:59.225905 14843 solver.cpp:253]     Train net output #0: loss = 1.04917 (* 1 = 1.04917 loss)
I0524 22:24:59.225924 14843 sgd_solver.cpp:106] Iteration 77605, lr = 0.0025
I0524 22:25:07.888767 14843 solver.cpp:237] Iteration 77792, loss = 1.0904
I0524 22:25:07.888806 14843 solver.cpp:253]     Train net output #0: loss = 1.0904 (* 1 = 1.0904 loss)
I0524 22:25:07.888823 14843 sgd_solver.cpp:106] Iteration 77792, lr = 0.0025
I0524 22:25:16.549163 14843 solver.cpp:237] Iteration 77979, loss = 1.04092
I0524 22:25:16.549201 14843 solver.cpp:253]     Train net output #0: loss = 1.04092 (* 1 = 1.04092 loss)
I0524 22:25:16.549219 14843 sgd_solver.cpp:106] Iteration 77979, lr = 0.0025
I0524 22:25:25.210444 14843 solver.cpp:237] Iteration 78166, loss = 0.983718
I0524 22:25:25.210499 14843 solver.cpp:253]     Train net output #0: loss = 0.983718 (* 1 = 0.983718 loss)
I0524 22:25:25.210523 14843 sgd_solver.cpp:106] Iteration 78166, lr = 0.0025
I0524 22:25:33.877431 14843 solver.cpp:237] Iteration 78353, loss = 1.02228
I0524 22:25:33.877620 14843 solver.cpp:253]     Train net output #0: loss = 1.02228 (* 1 = 1.02228 loss)
I0524 22:25:33.877636 14843 sgd_solver.cpp:106] Iteration 78353, lr = 0.0025
I0524 22:25:42.536995 14843 solver.cpp:237] Iteration 78540, loss = 1.28328
I0524 22:25:42.537031 14843 solver.cpp:253]     Train net output #0: loss = 1.28328 (* 1 = 1.28328 loss)
I0524 22:25:42.537055 14843 sgd_solver.cpp:106] Iteration 78540, lr = 0.0025
I0524 22:25:51.198423 14843 solver.cpp:237] Iteration 78727, loss = 1.18958
I0524 22:25:51.198470 14843 solver.cpp:253]     Train net output #0: loss = 1.18958 (* 1 = 1.18958 loss)
I0524 22:25:51.198495 14843 sgd_solver.cpp:106] Iteration 78727, lr = 0.0025
I0524 22:25:52.218953 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_78750.caffemodel
I0524 22:25:52.288893 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_78750.solverstate
I0524 22:25:52.315678 14843 solver.cpp:341] Iteration 78750, Testing net (#0)
I0524 22:26:39.751782 14843 solver.cpp:409]     Test net output #0: accuracy = 0.892539
I0524 22:26:39.751979 14843 solver.cpp:409]     Test net output #1: loss = 0.344131 (* 1 = 0.344131 loss)
I0524 22:27:08.186434 14843 solver.cpp:237] Iteration 78914, loss = 1.23176
I0524 22:27:08.186488 14843 solver.cpp:253]     Train net output #0: loss = 1.23176 (* 1 = 1.23176 loss)
I0524 22:27:08.186516 14843 sgd_solver.cpp:106] Iteration 78914, lr = 0.0025
I0524 22:27:16.840833 14843 solver.cpp:237] Iteration 79101, loss = 1.20523
I0524 22:27:16.841014 14843 solver.cpp:253]     Train net output #0: loss = 1.20523 (* 1 = 1.20523 loss)
I0524 22:27:16.841032 14843 sgd_solver.cpp:106] Iteration 79101, lr = 0.0025
I0524 22:27:25.494107 14843 solver.cpp:237] Iteration 79288, loss = 1.26433
I0524 22:27:25.494144 14843 solver.cpp:253]     Train net output #0: loss = 1.26433 (* 1 = 1.26433 loss)
I0524 22:27:25.494168 14843 sgd_solver.cpp:106] Iteration 79288, lr = 0.0025
I0524 22:27:34.151269 14843 solver.cpp:237] Iteration 79475, loss = 1.03946
I0524 22:27:34.151314 14843 solver.cpp:253]     Train net output #0: loss = 1.03946 (* 1 = 1.03946 loss)
I0524 22:27:34.151331 14843 sgd_solver.cpp:106] Iteration 79475, lr = 0.0025
I0524 22:27:42.799890 14843 solver.cpp:237] Iteration 79662, loss = 0.837744
I0524 22:27:42.799928 14843 solver.cpp:253]     Train net output #0: loss = 0.837744 (* 1 = 0.837744 loss)
I0524 22:27:42.799947 14843 sgd_solver.cpp:106] Iteration 79662, lr = 0.0025
I0524 22:27:51.452380 14843 solver.cpp:237] Iteration 79849, loss = 1.31063
I0524 22:27:51.452574 14843 solver.cpp:253]     Train net output #0: loss = 1.31063 (* 1 = 1.31063 loss)
I0524 22:27:51.452594 14843 sgd_solver.cpp:106] Iteration 79849, lr = 0.0025
I0524 22:28:20.963639 14843 solver.cpp:237] Iteration 80036, loss = 1.11878
I0524 22:28:20.963691 14843 solver.cpp:253]     Train net output #0: loss = 1.11878 (* 1 = 1.11878 loss)
I0524 22:28:20.963708 14843 sgd_solver.cpp:106] Iteration 80036, lr = 0.0025
I0524 22:28:29.612545 14843 solver.cpp:237] Iteration 80223, loss = 1.09088
I0524 22:28:29.612725 14843 solver.cpp:253]     Train net output #0: loss = 1.09088 (* 1 = 1.09088 loss)
I0524 22:28:29.612742 14843 sgd_solver.cpp:106] Iteration 80223, lr = 0.0025
I0524 22:28:38.263787 14843 solver.cpp:237] Iteration 80410, loss = 1.15408
I0524 22:28:38.263823 14843 solver.cpp:253]     Train net output #0: loss = 1.15408 (* 1 = 1.15408 loss)
I0524 22:28:38.263842 14843 sgd_solver.cpp:106] Iteration 80410, lr = 0.0025
I0524 22:28:46.909744 14843 solver.cpp:237] Iteration 80597, loss = 1.20556
I0524 22:28:46.909800 14843 solver.cpp:253]     Train net output #0: loss = 1.20556 (* 1 = 1.20556 loss)
I0524 22:28:46.909826 14843 sgd_solver.cpp:106] Iteration 80597, lr = 0.0025
I0524 22:28:48.158387 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_80625.caffemodel
I0524 22:28:48.228312 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_80625.solverstate
I0524 22:28:55.621457 14843 solver.cpp:237] Iteration 80784, loss = 1.55726
I0524 22:28:55.621510 14843 solver.cpp:253]     Train net output #0: loss = 1.55726 (* 1 = 1.55726 loss)
I0524 22:28:55.621536 14843 sgd_solver.cpp:106] Iteration 80784, lr = 0.0025
I0524 22:29:04.271054 14843 solver.cpp:237] Iteration 80971, loss = 1.24898
I0524 22:29:04.271245 14843 solver.cpp:253]     Train net output #0: loss = 1.24898 (* 1 = 1.24898 loss)
I0524 22:29:04.271261 14843 sgd_solver.cpp:106] Iteration 80971, lr = 0.0025
I0524 22:29:12.921152 14843 solver.cpp:237] Iteration 81158, loss = 1.06692
I0524 22:29:12.921205 14843 solver.cpp:253]     Train net output #0: loss = 1.06692 (* 1 = 1.06692 loss)
I0524 22:29:12.921231 14843 sgd_solver.cpp:106] Iteration 81158, lr = 0.0025
I0524 22:29:42.478895 14843 solver.cpp:237] Iteration 81345, loss = 1.14578
I0524 22:29:42.479094 14843 solver.cpp:253]     Train net output #0: loss = 1.14578 (* 1 = 1.14578 loss)
I0524 22:29:42.479112 14843 sgd_solver.cpp:106] Iteration 81345, lr = 0.0025
I0524 22:29:51.126359 14843 solver.cpp:237] Iteration 81532, loss = 1.3405
I0524 22:29:51.126396 14843 solver.cpp:253]     Train net output #0: loss = 1.3405 (* 1 = 1.3405 loss)
I0524 22:29:51.126420 14843 sgd_solver.cpp:106] Iteration 81532, lr = 0.0025
I0524 22:29:59.776429 14843 solver.cpp:237] Iteration 81719, loss = 1.06934
I0524 22:29:59.776484 14843 solver.cpp:253]     Train net output #0: loss = 1.06934 (* 1 = 1.06934 loss)
I0524 22:29:59.776507 14843 sgd_solver.cpp:106] Iteration 81719, lr = 0.0025
I0524 22:30:08.423065 14843 solver.cpp:237] Iteration 81906, loss = 1.08101
I0524 22:30:08.423101 14843 solver.cpp:253]     Train net output #0: loss = 1.08101 (* 1 = 1.08101 loss)
I0524 22:30:08.423120 14843 sgd_solver.cpp:106] Iteration 81906, lr = 0.0025
I0524 22:30:17.069110 14843 solver.cpp:237] Iteration 82093, loss = 1.18058
I0524 22:30:17.069300 14843 solver.cpp:253]     Train net output #0: loss = 1.18058 (* 1 = 1.18058 loss)
I0524 22:30:17.069317 14843 sgd_solver.cpp:106] Iteration 82093, lr = 0.0025
I0524 22:30:25.719185 14843 solver.cpp:237] Iteration 82280, loss = 1.18272
I0524 22:30:25.719238 14843 solver.cpp:253]     Train net output #0: loss = 1.18272 (* 1 = 1.18272 loss)
I0524 22:30:25.719264 14843 sgd_solver.cpp:106] Iteration 82280, lr = 0.0025
I0524 22:30:34.367198 14843 solver.cpp:237] Iteration 82467, loss = 1.25848
I0524 22:30:34.367235 14843 solver.cpp:253]     Train net output #0: loss = 1.25848 (* 1 = 1.25848 loss)
I0524 22:30:34.367257 14843 sgd_solver.cpp:106] Iteration 82467, lr = 0.0025
I0524 22:30:35.846307 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_82500.caffemodel
I0524 22:30:35.916630 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_82500.solverstate
I0524 22:30:35.943434 14843 solver.cpp:341] Iteration 82500, Testing net (#0)
I0524 22:31:44.283026 14843 solver.cpp:409]     Test net output #0: accuracy = 0.895626
I0524 22:31:44.283244 14843 solver.cpp:409]     Test net output #1: loss = 0.349671 (* 1 = 0.349671 loss)
I0524 22:32:12.284524 14843 solver.cpp:237] Iteration 82654, loss = 1.26334
I0524 22:32:12.284579 14843 solver.cpp:253]     Train net output #0: loss = 1.26334 (* 1 = 1.26334 loss)
I0524 22:32:12.284597 14843 sgd_solver.cpp:106] Iteration 82654, lr = 0.0025
I0524 22:32:20.925025 14843 solver.cpp:237] Iteration 82841, loss = 1.26289
I0524 22:32:20.925212 14843 solver.cpp:253]     Train net output #0: loss = 1.26289 (* 1 = 1.26289 loss)
I0524 22:32:20.925230 14843 sgd_solver.cpp:106] Iteration 82841, lr = 0.0025
I0524 22:32:29.568164 14843 solver.cpp:237] Iteration 83028, loss = 1.20401
I0524 22:32:29.568218 14843 solver.cpp:253]     Train net output #0: loss = 1.20401 (* 1 = 1.20401 loss)
I0524 22:32:29.568243 14843 sgd_solver.cpp:106] Iteration 83028, lr = 0.0025
I0524 22:32:38.209602 14843 solver.cpp:237] Iteration 83215, loss = 1.34926
I0524 22:32:38.209640 14843 solver.cpp:253]     Train net output #0: loss = 1.34926 (* 1 = 1.34926 loss)
I0524 22:32:38.209658 14843 sgd_solver.cpp:106] Iteration 83215, lr = 0.0025
I0524 22:32:46.851702 14843 solver.cpp:237] Iteration 83402, loss = 1.19812
I0524 22:32:46.851739 14843 solver.cpp:253]     Train net output #0: loss = 1.19812 (* 1 = 1.19812 loss)
I0524 22:32:46.851763 14843 sgd_solver.cpp:106] Iteration 83402, lr = 0.0025
I0524 22:32:55.500402 14843 solver.cpp:237] Iteration 83589, loss = 1.00973
I0524 22:32:55.500600 14843 solver.cpp:253]     Train net output #0: loss = 1.00973 (* 1 = 1.00973 loss)
I0524 22:32:55.500619 14843 sgd_solver.cpp:106] Iteration 83589, lr = 0.0025
I0524 22:33:25.011029 14843 solver.cpp:237] Iteration 83776, loss = 1.07475
I0524 22:33:25.011086 14843 solver.cpp:253]     Train net output #0: loss = 1.07475 (* 1 = 1.07475 loss)
I0524 22:33:25.011106 14843 sgd_solver.cpp:106] Iteration 83776, lr = 0.0025
I0524 22:33:33.654971 14843 solver.cpp:237] Iteration 83963, loss = 1.06298
I0524 22:33:33.655164 14843 solver.cpp:253]     Train net output #0: loss = 1.06298 (* 1 = 1.06298 loss)
I0524 22:33:33.655180 14843 sgd_solver.cpp:106] Iteration 83963, lr = 0.0025
I0524 22:33:42.300608 14843 solver.cpp:237] Iteration 84150, loss = 1.23174
I0524 22:33:42.300662 14843 solver.cpp:253]     Train net output #0: loss = 1.23174 (* 1 = 1.23174 loss)
I0524 22:33:42.300689 14843 sgd_solver.cpp:106] Iteration 84150, lr = 0.0025
I0524 22:33:50.960469 14843 solver.cpp:237] Iteration 84337, loss = 1.0258
I0524 22:33:50.960505 14843 solver.cpp:253]     Train net output #0: loss = 1.0258 (* 1 = 1.0258 loss)
I0524 22:33:50.960528 14843 sgd_solver.cpp:106] Iteration 84337, lr = 0.0025
I0524 22:33:52.672508 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_84375.caffemodel
I0524 22:33:52.745262 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_84375.solverstate
I0524 22:33:59.692353 14843 solver.cpp:237] Iteration 84524, loss = 1.20547
I0524 22:33:59.692409 14843 solver.cpp:253]     Train net output #0: loss = 1.20547 (* 1 = 1.20547 loss)
I0524 22:33:59.692432 14843 sgd_solver.cpp:106] Iteration 84524, lr = 0.0025
I0524 22:34:08.348909 14843 solver.cpp:237] Iteration 84711, loss = 1.02442
I0524 22:34:08.349108 14843 solver.cpp:253]     Train net output #0: loss = 1.02442 (* 1 = 1.02442 loss)
I0524 22:34:08.349126 14843 sgd_solver.cpp:106] Iteration 84711, lr = 0.0025
I0524 22:34:16.997277 14843 solver.cpp:237] Iteration 84898, loss = 1.32983
I0524 22:34:16.997314 14843 solver.cpp:253]     Train net output #0: loss = 1.32983 (* 1 = 1.32983 loss)
I0524 22:34:16.997337 14843 sgd_solver.cpp:106] Iteration 84898, lr = 0.0025
I0524 22:34:46.539291 14843 solver.cpp:237] Iteration 85085, loss = 1.22395
I0524 22:34:46.539499 14843 solver.cpp:253]     Train net output #0: loss = 1.22395 (* 1 = 1.22395 loss)
I0524 22:34:46.539517 14843 sgd_solver.cpp:106] Iteration 85085, lr = 0.0025
I0524 22:34:55.188823 14843 solver.cpp:237] Iteration 85272, loss = 1.59996
I0524 22:34:55.188860 14843 solver.cpp:253]     Train net output #0: loss = 1.59996 (* 1 = 1.59996 loss)
I0524 22:34:55.188884 14843 sgd_solver.cpp:106] Iteration 85272, lr = 0.0025
I0524 22:35:03.842491 14843 solver.cpp:237] Iteration 85459, loss = 1.20818
I0524 22:35:03.842545 14843 solver.cpp:253]     Train net output #0: loss = 1.20818 (* 1 = 1.20818 loss)
I0524 22:35:03.842568 14843 sgd_solver.cpp:106] Iteration 85459, lr = 0.0025
I0524 22:35:12.494325 14843 solver.cpp:237] Iteration 85646, loss = 1.34057
I0524 22:35:12.494361 14843 solver.cpp:253]     Train net output #0: loss = 1.34057 (* 1 = 1.34057 loss)
I0524 22:35:12.494385 14843 sgd_solver.cpp:106] Iteration 85646, lr = 0.0025
I0524 22:35:21.144246 14843 solver.cpp:237] Iteration 85833, loss = 1.44991
I0524 22:35:21.144448 14843 solver.cpp:253]     Train net output #0: loss = 1.44991 (* 1 = 1.44991 loss)
I0524 22:35:21.144464 14843 sgd_solver.cpp:106] Iteration 85833, lr = 0.0025
I0524 22:35:29.793798 14843 solver.cpp:237] Iteration 86020, loss = 1.38023
I0524 22:35:29.793836 14843 solver.cpp:253]     Train net output #0: loss = 1.38023 (* 1 = 1.38023 loss)
I0524 22:35:29.793855 14843 sgd_solver.cpp:106] Iteration 86020, lr = 0.0025
I0524 22:35:38.440881 14843 solver.cpp:237] Iteration 86207, loss = 0.931798
I0524 22:35:38.440920 14843 solver.cpp:253]     Train net output #0: loss = 0.931798 (* 1 = 0.931798 loss)
I0524 22:35:38.440937 14843 sgd_solver.cpp:106] Iteration 86207, lr = 0.0025
I0524 22:35:40.383239 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_86250.caffemodel
I0524 22:35:40.452905 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_86250.solverstate
I0524 22:35:40.479768 14843 solver.cpp:341] Iteration 86250, Testing net (#0)
I0524 22:36:27.550499 14843 solver.cpp:409]     Test net output #0: accuracy = 0.897073
I0524 22:36:27.550711 14843 solver.cpp:409]     Test net output #1: loss = 0.323546 (* 1 = 0.323546 loss)
I0524 22:36:55.090626 14843 solver.cpp:237] Iteration 86394, loss = 1.06375
I0524 22:36:55.090683 14843 solver.cpp:253]     Train net output #0: loss = 1.06375 (* 1 = 1.06375 loss)
I0524 22:36:55.090708 14843 sgd_solver.cpp:106] Iteration 86394, lr = 0.0025
I0524 22:37:03.746369 14843 solver.cpp:237] Iteration 86581, loss = 1.14983
I0524 22:37:03.746570 14843 solver.cpp:253]     Train net output #0: loss = 1.14983 (* 1 = 1.14983 loss)
I0524 22:37:03.746590 14843 sgd_solver.cpp:106] Iteration 86581, lr = 0.0025
I0524 22:37:12.398597 14843 solver.cpp:237] Iteration 86768, loss = 0.982838
I0524 22:37:12.398634 14843 solver.cpp:253]     Train net output #0: loss = 0.982838 (* 1 = 0.982838 loss)
I0524 22:37:12.398658 14843 sgd_solver.cpp:106] Iteration 86768, lr = 0.0025
I0524 22:37:21.052954 14843 solver.cpp:237] Iteration 86955, loss = 1.06806
I0524 22:37:21.052991 14843 solver.cpp:253]     Train net output #0: loss = 1.06806 (* 1 = 1.06806 loss)
I0524 22:37:21.053014 14843 sgd_solver.cpp:106] Iteration 86955, lr = 0.0025
I0524 22:37:29.709542 14843 solver.cpp:237] Iteration 87142, loss = 1.11404
I0524 22:37:29.709595 14843 solver.cpp:253]     Train net output #0: loss = 1.11404 (* 1 = 1.11404 loss)
I0524 22:37:29.709619 14843 sgd_solver.cpp:106] Iteration 87142, lr = 0.0025
I0524 22:37:38.367162 14843 solver.cpp:237] Iteration 87329, loss = 1.38175
I0524 22:37:38.367339 14843 solver.cpp:253]     Train net output #0: loss = 1.38175 (* 1 = 1.38175 loss)
I0524 22:37:38.367357 14843 sgd_solver.cpp:106] Iteration 87329, lr = 0.0025
I0524 22:38:07.905082 14843 solver.cpp:237] Iteration 87516, loss = 1.06163
I0524 22:38:07.905138 14843 solver.cpp:253]     Train net output #0: loss = 1.06163 (* 1 = 1.06163 loss)
I0524 22:38:07.905164 14843 sgd_solver.cpp:106] Iteration 87516, lr = 0.0025
I0524 22:38:16.560186 14843 solver.cpp:237] Iteration 87703, loss = 1.3122
I0524 22:38:16.560394 14843 solver.cpp:253]     Train net output #0: loss = 1.3122 (* 1 = 1.3122 loss)
I0524 22:38:16.560412 14843 sgd_solver.cpp:106] Iteration 87703, lr = 0.0025
I0524 22:38:25.212673 14843 solver.cpp:237] Iteration 87890, loss = 1.00174
I0524 22:38:25.212710 14843 solver.cpp:253]     Train net output #0: loss = 1.00174 (* 1 = 1.00174 loss)
I0524 22:38:25.212734 14843 sgd_solver.cpp:106] Iteration 87890, lr = 0.0025
I0524 22:38:33.862453 14843 solver.cpp:237] Iteration 88077, loss = 1.00542
I0524 22:38:33.862489 14843 solver.cpp:253]     Train net output #0: loss = 1.00542 (* 1 = 1.00542 loss)
I0524 22:38:33.862512 14843 sgd_solver.cpp:106] Iteration 88077, lr = 0.0025
I0524 22:38:36.035861 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_88125.caffemodel
I0524 22:38:36.105090 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_88125.solverstate
I0524 22:38:42.579802 14843 solver.cpp:237] Iteration 88264, loss = 0.921495
I0524 22:38:42.579859 14843 solver.cpp:253]     Train net output #0: loss = 0.921495 (* 1 = 0.921495 loss)
I0524 22:38:42.579879 14843 sgd_solver.cpp:106] Iteration 88264, lr = 0.0025
I0524 22:38:51.232950 14843 solver.cpp:237] Iteration 88451, loss = 1.10819
I0524 22:38:51.233136 14843 solver.cpp:253]     Train net output #0: loss = 1.10819 (* 1 = 1.10819 loss)
I0524 22:38:51.233153 14843 sgd_solver.cpp:106] Iteration 88451, lr = 0.0025
I0524 22:38:59.880534 14843 solver.cpp:237] Iteration 88638, loss = 1.31481
I0524 22:38:59.880573 14843 solver.cpp:253]     Train net output #0: loss = 1.31481 (* 1 = 1.31481 loss)
I0524 22:38:59.880590 14843 sgd_solver.cpp:106] Iteration 88638, lr = 0.0025
I0524 22:39:29.398033 14843 solver.cpp:237] Iteration 88825, loss = 1.03067
I0524 22:39:29.398242 14843 solver.cpp:253]     Train net output #0: loss = 1.03067 (* 1 = 1.03067 loss)
I0524 22:39:29.398260 14843 sgd_solver.cpp:106] Iteration 88825, lr = 0.0025
I0524 22:39:38.047811 14843 solver.cpp:237] Iteration 89012, loss = 0.872613
I0524 22:39:38.047868 14843 solver.cpp:253]     Train net output #0: loss = 0.872613 (* 1 = 0.872613 loss)
I0524 22:39:38.047896 14843 sgd_solver.cpp:106] Iteration 89012, lr = 0.0025
I0524 22:39:46.697286 14843 solver.cpp:237] Iteration 89199, loss = 1.10843
I0524 22:39:46.697324 14843 solver.cpp:253]     Train net output #0: loss = 1.10843 (* 1 = 1.10843 loss)
I0524 22:39:46.697342 14843 sgd_solver.cpp:106] Iteration 89199, lr = 0.0025
I0524 22:39:55.345336 14843 solver.cpp:237] Iteration 89386, loss = 1.11043
I0524 22:39:55.345372 14843 solver.cpp:253]     Train net output #0: loss = 1.11043 (* 1 = 1.11043 loss)
I0524 22:39:55.345396 14843 sgd_solver.cpp:106] Iteration 89386, lr = 0.0025
I0524 22:40:04.009799 14843 solver.cpp:237] Iteration 89573, loss = 1.23283
I0524 22:40:04.009995 14843 solver.cpp:253]     Train net output #0: loss = 1.23283 (* 1 = 1.23283 loss)
I0524 22:40:04.010015 14843 sgd_solver.cpp:106] Iteration 89573, lr = 0.0025
I0524 22:40:12.679718 14843 solver.cpp:237] Iteration 89760, loss = 1.03524
I0524 22:40:12.679754 14843 solver.cpp:253]     Train net output #0: loss = 1.03524 (* 1 = 1.03524 loss)
I0524 22:40:12.679777 14843 sgd_solver.cpp:106] Iteration 89760, lr = 0.0025
I0524 22:40:21.351547 14843 solver.cpp:237] Iteration 89947, loss = 1.2459
I0524 22:40:21.351603 14843 solver.cpp:253]     Train net output #0: loss = 1.2459 (* 1 = 1.2459 loss)
I0524 22:40:21.351629 14843 sgd_solver.cpp:106] Iteration 89947, lr = 0.0025
I0524 22:40:23.761824 14843 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_90000.caffemodel
I0524 22:40:23.832244 14843 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0025_2016-05-20T15.49.17.899667_iter_90000.solverstate
I0524 22:40:23.859151 14843 solver.cpp:341] Iteration 90000, Testing net (#0)
I0524 22:41:32.159394 14843 solver.cpp:409]     Test net output #0: accuracy = 0.896467
I0524 22:41:32.159610 14843 solver.cpp:409]     Test net output #1: loss = 0.325135 (* 1 = 0.325135 loss)
I0524 22:41:59.261730 14843 solver.cpp:237] Iteration 90134, loss = 1.11081
I0524 22:41:59.261786 14843 solver.cpp:253]     Train net output #0: loss = 1.11081 (* 1 = 1.11081 loss)
I0524 22:41:59.261806 14843 sgd_solver.cpp:106] Iteration 90134, lr = 0.0025
I0524 22:42:07.923794 14843 solver.cpp:237] Iteration 90321, loss = 1.08616
I0524 22:42:07.923998 14843 solver.cpp:253]     Train net output #0: loss = 1.08616 (* 1 = 1.08616 loss)
I0524 22:42:07.924018 14843 sgd_solver.cpp:106] Iteration 90321, lr = 0.0025
I0524 22:42:16.583452 14843 solver.cpp:237] Iteration 90508, loss = 1.1997
I0524 22:42:16.583490 14843 solver.cpp:253]     Train net output #0: loss = 1.1997 (* 1 = 1.1997 loss)
I0524 22:42:16.583508 14843 sgd_solver.cpp:106] Iteration 90508, lr = 0.0025
I0524 22:42:25.241672 14843 solver.cpp:237] Iteration 90695, loss = 1.06849
I0524 22:42:25.241710 14843 solver.cpp:253]     Train net output #0: loss = 1.06849 (* 1 = 1.06849 loss)
I0524 22:42:25.241729 14843 sgd_solver.cpp:106] Iteration 90695, lr = 0.0025
I0524 22:42:33.903404 14843 solver.cpp:237] Iteration 90882, loss = 0.960179
I0524 22:42:33.903457 14843 solver.cpp:253]     Train net output #0: loss = 0.960179 (* 1 = 0.960179 loss)
I0524 22:42:33.903482 14843 sgd_solver.cpp:106] Iteration 90882, lr = 0.0025
I0524 22:42:42.569430 14843 solver.cpp:237] Iteration 91069, loss = 1.19474
I0524 22:42:42.569617 14843 solver.cpp:253]     Train net output #0: loss = 1.19474 (* 1 = 1.19474 loss)
I0524 22:42:42.569634 14843 sgd_solver.cpp:106] Iteration 91069, lr = 0.0025
aprun: Apid 11261635: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7237 exceeded limit 7200
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
aprun: Apid 11261635: Caught signal Terminated, sending to application
*** Aborted at 1464144171 (unix time) try "date -d @1464144171" if you are using GNU date ***
PC: @     0x2aaab7f6156a __GI_mmap
*** SIGTERM (@0x39f8) received by PID 14843 (TID 0x2aaac746f900) from PID 14840; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab7f6156a __GI_mmap
    @     0x2aaab930c652 (unknown)
    @     0x2aaab930e5b8 (unknown)
    @     0x2aaab930e5e5 (unknown)
    @     0x2aaab9283556 (unknown)
    @     0x2aaab9286878 (unknown)
    @     0x2aaab92868f9 (unknown)
    @     0x2aaab91d3618 (unknown)
    @     0x2aaab91a0aa2 cuMemFreeHost
    @     0x2aaaaacf825d (unknown)
    @     0x2aaaaacdb31c (unknown)
    @     0x2aaaaad07d11 cudaFreeHost
    @           0x5ea897 caffe::SyncedMemory::~SyncedMemory()
    @           0x49ab62 boost::detail::sp_counted_impl_p<>::dispose()
    @           0x43d769 boost::detail::shared_count::~shared_count()
    @           0x4afef8 boost::detail::sp_counted_impl_p<>::dispose()
    @           0x5b8e61 caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 00815] [c2-1c0s7n3] [Tue May 24 22:42:52 2016] PE RANK 0 exit signal Terminated
Application 11261635 exit codes: 143
Application 11261635 resources: utime ~6237s, stime ~991s, Rss ~5329828, inblocks ~16609017, outblocks ~740505
