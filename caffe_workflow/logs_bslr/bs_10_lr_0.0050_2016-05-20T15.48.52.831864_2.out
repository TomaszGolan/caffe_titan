2811673
I0526 11:05:50.170640 26867 caffe.cpp:184] Using GPUs 0
I0526 11:05:50.598733 26867 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.005
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864.prototxt"
I0526 11:05:50.600486 26867 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864.prototxt
I0526 11:05:50.616538 26867 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 11:05:50.616601 26867 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 11:05:50.616979 26867 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 11:05:50.617190 26867 layer_factory.hpp:77] Creating layer data_hdf5
I0526 11:05:50.617228 26867 net.cpp:106] Creating Layer data_hdf5
I0526 11:05:50.617245 26867 net.cpp:411] data_hdf5 -> data
I0526 11:05:50.617279 26867 net.cpp:411] data_hdf5 -> label
I0526 11:05:50.617322 26867 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 11:05:50.634737 26867 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 11:05:50.648187 26867 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 11:06:12.247086 26867 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 11:06:12.252251 26867 net.cpp:150] Setting up data_hdf5
I0526 11:06:12.252293 26867 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 11:06:12.252310 26867 net.cpp:157] Top shape: 10 (10)
I0526 11:06:12.252323 26867 net.cpp:165] Memory required for data: 254040
I0526 11:06:12.252342 26867 layer_factory.hpp:77] Creating layer conv1
I0526 11:06:12.252389 26867 net.cpp:106] Creating Layer conv1
I0526 11:06:12.252403 26867 net.cpp:454] conv1 <- data
I0526 11:06:12.252429 26867 net.cpp:411] conv1 -> conv1
I0526 11:06:14.932085 26867 net.cpp:150] Setting up conv1
I0526 11:06:14.932134 26867 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 11:06:14.932149 26867 net.cpp:165] Memory required for data: 3018840
I0526 11:06:14.932179 26867 layer_factory.hpp:77] Creating layer relu1
I0526 11:06:14.932202 26867 net.cpp:106] Creating Layer relu1
I0526 11:06:14.932222 26867 net.cpp:454] relu1 <- conv1
I0526 11:06:14.932260 26867 net.cpp:397] relu1 -> conv1 (in-place)
I0526 11:06:14.932796 26867 net.cpp:150] Setting up relu1
I0526 11:06:14.932821 26867 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 11:06:14.932834 26867 net.cpp:165] Memory required for data: 5783640
I0526 11:06:14.932850 26867 layer_factory.hpp:77] Creating layer pool1
I0526 11:06:14.932878 26867 net.cpp:106] Creating Layer pool1
I0526 11:06:14.932891 26867 net.cpp:454] pool1 <- conv1
I0526 11:06:14.932907 26867 net.cpp:411] pool1 -> pool1
I0526 11:06:14.933001 26867 net.cpp:150] Setting up pool1
I0526 11:06:14.933018 26867 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 11:06:14.933039 26867 net.cpp:165] Memory required for data: 7166040
I0526 11:06:14.933053 26867 layer_factory.hpp:77] Creating layer conv2
I0526 11:06:14.933076 26867 net.cpp:106] Creating Layer conv2
I0526 11:06:14.933091 26867 net.cpp:454] conv2 <- pool1
I0526 11:06:14.933107 26867 net.cpp:411] conv2 -> conv2
I0526 11:06:14.935817 26867 net.cpp:150] Setting up conv2
I0526 11:06:14.935850 26867 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 11:06:14.935864 26867 net.cpp:165] Memory required for data: 9153240
I0526 11:06:14.935892 26867 layer_factory.hpp:77] Creating layer relu2
I0526 11:06:14.935920 26867 net.cpp:106] Creating Layer relu2
I0526 11:06:14.935933 26867 net.cpp:454] relu2 <- conv2
I0526 11:06:14.935950 26867 net.cpp:397] relu2 -> conv2 (in-place)
I0526 11:06:14.936310 26867 net.cpp:150] Setting up relu2
I0526 11:06:14.936331 26867 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 11:06:14.936343 26867 net.cpp:165] Memory required for data: 11140440
I0526 11:06:14.936355 26867 layer_factory.hpp:77] Creating layer pool2
I0526 11:06:14.936381 26867 net.cpp:106] Creating Layer pool2
I0526 11:06:14.936395 26867 net.cpp:454] pool2 <- conv2
I0526 11:06:14.936411 26867 net.cpp:411] pool2 -> pool2
I0526 11:06:14.936506 26867 net.cpp:150] Setting up pool2
I0526 11:06:14.936523 26867 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 11:06:14.936538 26867 net.cpp:165] Memory required for data: 12134040
I0526 11:06:14.936558 26867 layer_factory.hpp:77] Creating layer conv3
I0526 11:06:14.936579 26867 net.cpp:106] Creating Layer conv3
I0526 11:06:14.936601 26867 net.cpp:454] conv3 <- pool2
I0526 11:06:14.936617 26867 net.cpp:411] conv3 -> conv3
I0526 11:06:14.938755 26867 net.cpp:150] Setting up conv3
I0526 11:06:14.938781 26867 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 11:06:14.938802 26867 net.cpp:165] Memory required for data: 13218200
I0526 11:06:14.938824 26867 layer_factory.hpp:77] Creating layer relu3
I0526 11:06:14.938856 26867 net.cpp:106] Creating Layer relu3
I0526 11:06:14.938870 26867 net.cpp:454] relu3 <- conv3
I0526 11:06:14.938886 26867 net.cpp:397] relu3 -> conv3 (in-place)
I0526 11:06:14.939369 26867 net.cpp:150] Setting up relu3
I0526 11:06:14.939394 26867 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 11:06:14.939407 26867 net.cpp:165] Memory required for data: 14302360
I0526 11:06:14.939424 26867 layer_factory.hpp:77] Creating layer pool3
I0526 11:06:14.939447 26867 net.cpp:106] Creating Layer pool3
I0526 11:06:14.939461 26867 net.cpp:454] pool3 <- conv3
I0526 11:06:14.939477 26867 net.cpp:411] pool3 -> pool3
I0526 11:06:14.939559 26867 net.cpp:150] Setting up pool3
I0526 11:06:14.939577 26867 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 11:06:14.939592 26867 net.cpp:165] Memory required for data: 14844440
I0526 11:06:14.939604 26867 layer_factory.hpp:77] Creating layer conv4
I0526 11:06:14.939630 26867 net.cpp:106] Creating Layer conv4
I0526 11:06:14.939643 26867 net.cpp:454] conv4 <- pool3
I0526 11:06:14.939661 26867 net.cpp:411] conv4 -> conv4
I0526 11:06:14.942412 26867 net.cpp:150] Setting up conv4
I0526 11:06:14.942443 26867 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 11:06:14.942457 26867 net.cpp:165] Memory required for data: 15207320
I0526 11:06:14.942481 26867 layer_factory.hpp:77] Creating layer relu4
I0526 11:06:14.942508 26867 net.cpp:106] Creating Layer relu4
I0526 11:06:14.942523 26867 net.cpp:454] relu4 <- conv4
I0526 11:06:14.942538 26867 net.cpp:397] relu4 -> conv4 (in-place)
I0526 11:06:14.943032 26867 net.cpp:150] Setting up relu4
I0526 11:06:14.943056 26867 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 11:06:14.943069 26867 net.cpp:165] Memory required for data: 15570200
I0526 11:06:14.943085 26867 layer_factory.hpp:77] Creating layer pool4
I0526 11:06:14.943110 26867 net.cpp:106] Creating Layer pool4
I0526 11:06:14.943123 26867 net.cpp:454] pool4 <- conv4
I0526 11:06:14.943140 26867 net.cpp:411] pool4 -> pool4
I0526 11:06:14.943223 26867 net.cpp:150] Setting up pool4
I0526 11:06:14.943240 26867 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 11:06:14.943255 26867 net.cpp:165] Memory required for data: 15751640
I0526 11:06:14.943267 26867 layer_factory.hpp:77] Creating layer ip1
I0526 11:06:14.943295 26867 net.cpp:106] Creating Layer ip1
I0526 11:06:14.943308 26867 net.cpp:454] ip1 <- pool4
I0526 11:06:14.943325 26867 net.cpp:411] ip1 -> ip1
I0526 11:06:14.958770 26867 net.cpp:150] Setting up ip1
I0526 11:06:14.958808 26867 net.cpp:157] Top shape: 10 196 (1960)
I0526 11:06:14.958822 26867 net.cpp:165] Memory required for data: 15759480
I0526 11:06:14.958852 26867 layer_factory.hpp:77] Creating layer relu5
I0526 11:06:14.958868 26867 net.cpp:106] Creating Layer relu5
I0526 11:06:14.958894 26867 net.cpp:454] relu5 <- ip1
I0526 11:06:14.958911 26867 net.cpp:397] relu5 -> ip1 (in-place)
I0526 11:06:14.959282 26867 net.cpp:150] Setting up relu5
I0526 11:06:14.959302 26867 net.cpp:157] Top shape: 10 196 (1960)
I0526 11:06:14.959316 26867 net.cpp:165] Memory required for data: 15767320
I0526 11:06:14.959331 26867 layer_factory.hpp:77] Creating layer drop1
I0526 11:06:14.959362 26867 net.cpp:106] Creating Layer drop1
I0526 11:06:14.959375 26867 net.cpp:454] drop1 <- ip1
I0526 11:06:14.959390 26867 net.cpp:397] drop1 -> ip1 (in-place)
I0526 11:06:14.959463 26867 net.cpp:150] Setting up drop1
I0526 11:06:14.959480 26867 net.cpp:157] Top shape: 10 196 (1960)
I0526 11:06:14.959492 26867 net.cpp:165] Memory required for data: 15775160
I0526 11:06:14.959507 26867 layer_factory.hpp:77] Creating layer ip2
I0526 11:06:14.959528 26867 net.cpp:106] Creating Layer ip2
I0526 11:06:14.959542 26867 net.cpp:454] ip2 <- ip1
I0526 11:06:14.959563 26867 net.cpp:411] ip2 -> ip2
I0526 11:06:14.960052 26867 net.cpp:150] Setting up ip2
I0526 11:06:14.960072 26867 net.cpp:157] Top shape: 10 98 (980)
I0526 11:06:14.960084 26867 net.cpp:165] Memory required for data: 15779080
I0526 11:06:14.960105 26867 layer_factory.hpp:77] Creating layer relu6
I0526 11:06:14.960127 26867 net.cpp:106] Creating Layer relu6
I0526 11:06:14.960140 26867 net.cpp:454] relu6 <- ip2
I0526 11:06:14.960155 26867 net.cpp:397] relu6 -> ip2 (in-place)
I0526 11:06:14.960705 26867 net.cpp:150] Setting up relu6
I0526 11:06:14.960727 26867 net.cpp:157] Top shape: 10 98 (980)
I0526 11:06:14.960741 26867 net.cpp:165] Memory required for data: 15783000
I0526 11:06:14.960757 26867 layer_factory.hpp:77] Creating layer drop2
I0526 11:06:14.960779 26867 net.cpp:106] Creating Layer drop2
I0526 11:06:14.960793 26867 net.cpp:454] drop2 <- ip2
I0526 11:06:14.960808 26867 net.cpp:397] drop2 -> ip2 (in-place)
I0526 11:06:14.960858 26867 net.cpp:150] Setting up drop2
I0526 11:06:14.960881 26867 net.cpp:157] Top shape: 10 98 (980)
I0526 11:06:14.960894 26867 net.cpp:165] Memory required for data: 15786920
I0526 11:06:14.960913 26867 layer_factory.hpp:77] Creating layer ip3
I0526 11:06:14.960929 26867 net.cpp:106] Creating Layer ip3
I0526 11:06:14.960947 26867 net.cpp:454] ip3 <- ip2
I0526 11:06:14.960968 26867 net.cpp:411] ip3 -> ip3
I0526 11:06:14.961191 26867 net.cpp:150] Setting up ip3
I0526 11:06:14.961210 26867 net.cpp:157] Top shape: 10 11 (110)
I0526 11:06:14.961222 26867 net.cpp:165] Memory required for data: 15787360
I0526 11:06:14.961243 26867 layer_factory.hpp:77] Creating layer drop3
I0526 11:06:14.961264 26867 net.cpp:106] Creating Layer drop3
I0526 11:06:14.961277 26867 net.cpp:454] drop3 <- ip3
I0526 11:06:14.961293 26867 net.cpp:397] drop3 -> ip3 (in-place)
I0526 11:06:14.961340 26867 net.cpp:150] Setting up drop3
I0526 11:06:14.961362 26867 net.cpp:157] Top shape: 10 11 (110)
I0526 11:06:14.961374 26867 net.cpp:165] Memory required for data: 15787800
I0526 11:06:14.961392 26867 layer_factory.hpp:77] Creating layer loss
I0526 11:06:14.961413 26867 net.cpp:106] Creating Layer loss
I0526 11:06:14.961428 26867 net.cpp:454] loss <- ip3
I0526 11:06:14.961442 26867 net.cpp:454] loss <- label
I0526 11:06:14.961464 26867 net.cpp:411] loss -> loss
I0526 11:06:14.961484 26867 layer_factory.hpp:77] Creating layer loss
I0526 11:06:14.962158 26867 net.cpp:150] Setting up loss
I0526 11:06:14.962180 26867 net.cpp:157] Top shape: (1)
I0526 11:06:14.962198 26867 net.cpp:160]     with loss weight 1
I0526 11:06:14.962246 26867 net.cpp:165] Memory required for data: 15787804
I0526 11:06:14.962267 26867 net.cpp:226] loss needs backward computation.
I0526 11:06:14.962282 26867 net.cpp:226] drop3 needs backward computation.
I0526 11:06:14.962294 26867 net.cpp:226] ip3 needs backward computation.
I0526 11:06:14.962311 26867 net.cpp:226] drop2 needs backward computation.
I0526 11:06:14.962323 26867 net.cpp:226] relu6 needs backward computation.
I0526 11:06:14.962335 26867 net.cpp:226] ip2 needs backward computation.
I0526 11:06:14.962350 26867 net.cpp:226] drop1 needs backward computation.
I0526 11:06:14.962363 26867 net.cpp:226] relu5 needs backward computation.
I0526 11:06:14.962383 26867 net.cpp:226] ip1 needs backward computation.
I0526 11:06:14.962395 26867 net.cpp:226] pool4 needs backward computation.
I0526 11:06:14.962411 26867 net.cpp:226] relu4 needs backward computation.
I0526 11:06:14.962424 26867 net.cpp:226] conv4 needs backward computation.
I0526 11:06:14.962437 26867 net.cpp:226] pool3 needs backward computation.
I0526 11:06:14.962450 26867 net.cpp:226] relu3 needs backward computation.
I0526 11:06:14.962466 26867 net.cpp:226] conv3 needs backward computation.
I0526 11:06:14.962494 26867 net.cpp:226] pool2 needs backward computation.
I0526 11:06:14.962507 26867 net.cpp:226] relu2 needs backward computation.
I0526 11:06:14.962524 26867 net.cpp:226] conv2 needs backward computation.
I0526 11:06:14.962538 26867 net.cpp:226] pool1 needs backward computation.
I0526 11:06:14.962550 26867 net.cpp:226] relu1 needs backward computation.
I0526 11:06:14.962566 26867 net.cpp:226] conv1 needs backward computation.
I0526 11:06:14.962587 26867 net.cpp:228] data_hdf5 does not need backward computation.
I0526 11:06:14.962601 26867 net.cpp:270] This network produces output loss
I0526 11:06:14.962628 26867 net.cpp:283] Network initialization done.
I0526 11:06:14.964514 26867 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864.prototxt
I0526 11:06:14.964593 26867 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 11:06:14.964972 26867 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 11:06:14.965198 26867 layer_factory.hpp:77] Creating layer data_hdf5
I0526 11:06:14.965217 26867 net.cpp:106] Creating Layer data_hdf5
I0526 11:06:14.965234 26867 net.cpp:411] data_hdf5 -> data
I0526 11:06:14.965253 26867 net.cpp:411] data_hdf5 -> label
I0526 11:06:14.965275 26867 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 11:06:14.977661 26867 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 11:06:36.425410 26867 net.cpp:150] Setting up data_hdf5
I0526 11:06:36.425578 26867 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 11:06:36.425606 26867 net.cpp:157] Top shape: 10 (10)
I0526 11:06:36.425618 26867 net.cpp:165] Memory required for data: 254040
I0526 11:06:36.425633 26867 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 11:06:36.425662 26867 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 11:06:36.425675 26867 net.cpp:454] label_data_hdf5_1_split <- label
I0526 11:06:36.425717 26867 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 11:06:36.425740 26867 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 11:06:36.425817 26867 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 11:06:36.425838 26867 net.cpp:157] Top shape: 10 (10)
I0526 11:06:36.425859 26867 net.cpp:157] Top shape: 10 (10)
I0526 11:06:36.425873 26867 net.cpp:165] Memory required for data: 254120
I0526 11:06:36.425885 26867 layer_factory.hpp:77] Creating layer conv1
I0526 11:06:36.425916 26867 net.cpp:106] Creating Layer conv1
I0526 11:06:36.425930 26867 net.cpp:454] conv1 <- data
I0526 11:06:36.425948 26867 net.cpp:411] conv1 -> conv1
I0526 11:06:36.427948 26867 net.cpp:150] Setting up conv1
I0526 11:06:36.427975 26867 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 11:06:36.427995 26867 net.cpp:165] Memory required for data: 3018920
I0526 11:06:36.428020 26867 layer_factory.hpp:77] Creating layer relu1
I0526 11:06:36.428040 26867 net.cpp:106] Creating Layer relu1
I0526 11:06:36.428063 26867 net.cpp:454] relu1 <- conv1
I0526 11:06:36.428079 26867 net.cpp:397] relu1 -> conv1 (in-place)
I0526 11:06:36.428604 26867 net.cpp:150] Setting up relu1
I0526 11:06:36.428627 26867 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 11:06:36.428640 26867 net.cpp:165] Memory required for data: 5783720
I0526 11:06:36.428653 26867 layer_factory.hpp:77] Creating layer pool1
I0526 11:06:36.428683 26867 net.cpp:106] Creating Layer pool1
I0526 11:06:36.428696 26867 net.cpp:454] pool1 <- conv1
I0526 11:06:36.428712 26867 net.cpp:411] pool1 -> pool1
I0526 11:06:36.428802 26867 net.cpp:150] Setting up pool1
I0526 11:06:36.428820 26867 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 11:06:36.428835 26867 net.cpp:165] Memory required for data: 7166120
I0526 11:06:36.428853 26867 layer_factory.hpp:77] Creating layer conv2
I0526 11:06:36.428874 26867 net.cpp:106] Creating Layer conv2
I0526 11:06:36.428887 26867 net.cpp:454] conv2 <- pool1
I0526 11:06:36.428903 26867 net.cpp:411] conv2 -> conv2
I0526 11:06:36.430846 26867 net.cpp:150] Setting up conv2
I0526 11:06:36.430871 26867 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 11:06:36.430891 26867 net.cpp:165] Memory required for data: 9153320
I0526 11:06:36.430913 26867 layer_factory.hpp:77] Creating layer relu2
I0526 11:06:36.430933 26867 net.cpp:106] Creating Layer relu2
I0526 11:06:36.430955 26867 net.cpp:454] relu2 <- conv2
I0526 11:06:36.430972 26867 net.cpp:397] relu2 -> conv2 (in-place)
I0526 11:06:36.431321 26867 net.cpp:150] Setting up relu2
I0526 11:06:36.431341 26867 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 11:06:36.431354 26867 net.cpp:165] Memory required for data: 11140520
I0526 11:06:36.431370 26867 layer_factory.hpp:77] Creating layer pool2
I0526 11:06:36.431392 26867 net.cpp:106] Creating Layer pool2
I0526 11:06:36.431406 26867 net.cpp:454] pool2 <- conv2
I0526 11:06:36.431422 26867 net.cpp:411] pool2 -> pool2
I0526 11:06:36.431509 26867 net.cpp:150] Setting up pool2
I0526 11:06:36.431526 26867 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 11:06:36.431541 26867 net.cpp:165] Memory required for data: 12134120
I0526 11:06:36.431560 26867 layer_factory.hpp:77] Creating layer conv3
I0526 11:06:36.431583 26867 net.cpp:106] Creating Layer conv3
I0526 11:06:36.431596 26867 net.cpp:454] conv3 <- pool2
I0526 11:06:36.431613 26867 net.cpp:411] conv3 -> conv3
I0526 11:06:36.433646 26867 net.cpp:150] Setting up conv3
I0526 11:06:36.433672 26867 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 11:06:36.433691 26867 net.cpp:165] Memory required for data: 13218280
I0526 11:06:36.433714 26867 layer_factory.hpp:77] Creating layer relu3
I0526 11:06:36.433756 26867 net.cpp:106] Creating Layer relu3
I0526 11:06:36.433770 26867 net.cpp:454] relu3 <- conv3
I0526 11:06:36.433786 26867 net.cpp:397] relu3 -> conv3 (in-place)
I0526 11:06:36.434299 26867 net.cpp:150] Setting up relu3
I0526 11:06:36.434322 26867 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 11:06:36.434336 26867 net.cpp:165] Memory required for data: 14302440
I0526 11:06:36.434352 26867 layer_factory.hpp:77] Creating layer pool3
I0526 11:06:36.434376 26867 net.cpp:106] Creating Layer pool3
I0526 11:06:36.434391 26867 net.cpp:454] pool3 <- conv3
I0526 11:06:36.434406 26867 net.cpp:411] pool3 -> pool3
I0526 11:06:36.434494 26867 net.cpp:150] Setting up pool3
I0526 11:06:36.434517 26867 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 11:06:36.434530 26867 net.cpp:165] Memory required for data: 14844520
I0526 11:06:36.434542 26867 layer_factory.hpp:77] Creating layer conv4
I0526 11:06:36.434572 26867 net.cpp:106] Creating Layer conv4
I0526 11:06:36.434586 26867 net.cpp:454] conv4 <- pool3
I0526 11:06:36.434602 26867 net.cpp:411] conv4 -> conv4
I0526 11:06:36.436684 26867 net.cpp:150] Setting up conv4
I0526 11:06:36.436708 26867 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 11:06:36.436728 26867 net.cpp:165] Memory required for data: 15207400
I0526 11:06:36.436748 26867 layer_factory.hpp:77] Creating layer relu4
I0526 11:06:36.436767 26867 net.cpp:106] Creating Layer relu4
I0526 11:06:36.436789 26867 net.cpp:454] relu4 <- conv4
I0526 11:06:36.436806 26867 net.cpp:397] relu4 -> conv4 (in-place)
I0526 11:06:36.437293 26867 net.cpp:150] Setting up relu4
I0526 11:06:36.437316 26867 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 11:06:36.437330 26867 net.cpp:165] Memory required for data: 15570280
I0526 11:06:36.437345 26867 layer_factory.hpp:77] Creating layer pool4
I0526 11:06:36.437369 26867 net.cpp:106] Creating Layer pool4
I0526 11:06:36.437383 26867 net.cpp:454] pool4 <- conv4
I0526 11:06:36.437399 26867 net.cpp:411] pool4 -> pool4
I0526 11:06:36.437486 26867 net.cpp:150] Setting up pool4
I0526 11:06:36.437503 26867 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 11:06:36.437518 26867 net.cpp:165] Memory required for data: 15751720
I0526 11:06:36.437530 26867 layer_factory.hpp:77] Creating layer ip1
I0526 11:06:36.437554 26867 net.cpp:106] Creating Layer ip1
I0526 11:06:36.437568 26867 net.cpp:454] ip1 <- pool4
I0526 11:06:36.437585 26867 net.cpp:411] ip1 -> ip1
I0526 11:06:36.452975 26867 net.cpp:150] Setting up ip1
I0526 11:06:36.453004 26867 net.cpp:157] Top shape: 10 196 (1960)
I0526 11:06:36.453025 26867 net.cpp:165] Memory required for data: 15759560
I0526 11:06:36.453052 26867 layer_factory.hpp:77] Creating layer relu5
I0526 11:06:36.453073 26867 net.cpp:106] Creating Layer relu5
I0526 11:06:36.453099 26867 net.cpp:454] relu5 <- ip1
I0526 11:06:36.453116 26867 net.cpp:397] relu5 -> ip1 (in-place)
I0526 11:06:36.453480 26867 net.cpp:150] Setting up relu5
I0526 11:06:36.453501 26867 net.cpp:157] Top shape: 10 196 (1960)
I0526 11:06:36.453515 26867 net.cpp:165] Memory required for data: 15767400
I0526 11:06:36.453529 26867 layer_factory.hpp:77] Creating layer drop1
I0526 11:06:36.453558 26867 net.cpp:106] Creating Layer drop1
I0526 11:06:36.453572 26867 net.cpp:454] drop1 <- ip1
I0526 11:06:36.453588 26867 net.cpp:397] drop1 -> ip1 (in-place)
I0526 11:06:36.453647 26867 net.cpp:150] Setting up drop1
I0526 11:06:36.453663 26867 net.cpp:157] Top shape: 10 196 (1960)
I0526 11:06:36.453675 26867 net.cpp:165] Memory required for data: 15775240
I0526 11:06:36.453688 26867 layer_factory.hpp:77] Creating layer ip2
I0526 11:06:36.453708 26867 net.cpp:106] Creating Layer ip2
I0526 11:06:36.453721 26867 net.cpp:454] ip2 <- ip1
I0526 11:06:36.453743 26867 net.cpp:411] ip2 -> ip2
I0526 11:06:36.454244 26867 net.cpp:150] Setting up ip2
I0526 11:06:36.454263 26867 net.cpp:157] Top shape: 10 98 (980)
I0526 11:06:36.454277 26867 net.cpp:165] Memory required for data: 15779160
I0526 11:06:36.454298 26867 layer_factory.hpp:77] Creating layer relu6
I0526 11:06:36.454334 26867 net.cpp:106] Creating Layer relu6
I0526 11:06:36.454346 26867 net.cpp:454] relu6 <- ip2
I0526 11:06:36.454362 26867 net.cpp:397] relu6 -> ip2 (in-place)
I0526 11:06:36.454941 26867 net.cpp:150] Setting up relu6
I0526 11:06:36.454964 26867 net.cpp:157] Top shape: 10 98 (980)
I0526 11:06:36.454977 26867 net.cpp:165] Memory required for data: 15783080
I0526 11:06:36.454989 26867 layer_factory.hpp:77] Creating layer drop2
I0526 11:06:36.455009 26867 net.cpp:106] Creating Layer drop2
I0526 11:06:36.455031 26867 net.cpp:454] drop2 <- ip2
I0526 11:06:36.455047 26867 net.cpp:397] drop2 -> ip2 (in-place)
I0526 11:06:36.455099 26867 net.cpp:150] Setting up drop2
I0526 11:06:36.455122 26867 net.cpp:157] Top shape: 10 98 (980)
I0526 11:06:36.455135 26867 net.cpp:165] Memory required for data: 15787000
I0526 11:06:36.455153 26867 layer_factory.hpp:77] Creating layer ip3
I0526 11:06:36.455170 26867 net.cpp:106] Creating Layer ip3
I0526 11:06:36.455185 26867 net.cpp:454] ip3 <- ip2
I0526 11:06:36.455209 26867 net.cpp:411] ip3 -> ip3
I0526 11:06:36.455445 26867 net.cpp:150] Setting up ip3
I0526 11:06:36.455463 26867 net.cpp:157] Top shape: 10 11 (110)
I0526 11:06:36.455476 26867 net.cpp:165] Memory required for data: 15787440
I0526 11:06:36.455497 26867 layer_factory.hpp:77] Creating layer drop3
I0526 11:06:36.455520 26867 net.cpp:106] Creating Layer drop3
I0526 11:06:36.455534 26867 net.cpp:454] drop3 <- ip3
I0526 11:06:36.455549 26867 net.cpp:397] drop3 -> ip3 (in-place)
I0526 11:06:36.455605 26867 net.cpp:150] Setting up drop3
I0526 11:06:36.455621 26867 net.cpp:157] Top shape: 10 11 (110)
I0526 11:06:36.455632 26867 net.cpp:165] Memory required for data: 15787880
I0526 11:06:36.455646 26867 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 11:06:36.455662 26867 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 11:06:36.455677 26867 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 11:06:36.455698 26867 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 11:06:36.455718 26867 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 11:06:36.455811 26867 net.cpp:150] Setting up ip3_drop3_0_split
I0526 11:06:36.455827 26867 net.cpp:157] Top shape: 10 11 (110)
I0526 11:06:36.455842 26867 net.cpp:157] Top shape: 10 11 (110)
I0526 11:06:36.455857 26867 net.cpp:165] Memory required for data: 15788760
I0526 11:06:36.455869 26867 layer_factory.hpp:77] Creating layer accuracy
I0526 11:06:36.455899 26867 net.cpp:106] Creating Layer accuracy
I0526 11:06:36.455916 26867 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 11:06:36.455931 26867 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 11:06:36.455947 26867 net.cpp:411] accuracy -> accuracy
I0526 11:06:36.455982 26867 net.cpp:150] Setting up accuracy
I0526 11:06:36.455997 26867 net.cpp:157] Top shape: (1)
I0526 11:06:36.456009 26867 net.cpp:165] Memory required for data: 15788764
I0526 11:06:36.456022 26867 layer_factory.hpp:77] Creating layer loss
I0526 11:06:36.456038 26867 net.cpp:106] Creating Layer loss
I0526 11:06:36.456053 26867 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 11:06:36.456075 26867 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 11:06:36.456091 26867 net.cpp:411] loss -> loss
I0526 11:06:36.456116 26867 layer_factory.hpp:77] Creating layer loss
I0526 11:06:36.456625 26867 net.cpp:150] Setting up loss
I0526 11:06:36.456645 26867 net.cpp:157] Top shape: (1)
I0526 11:06:36.456658 26867 net.cpp:160]     with loss weight 1
I0526 11:06:36.456681 26867 net.cpp:165] Memory required for data: 15788768
I0526 11:06:36.456701 26867 net.cpp:226] loss needs backward computation.
I0526 11:06:36.456715 26867 net.cpp:228] accuracy does not need backward computation.
I0526 11:06:36.456729 26867 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 11:06:36.456743 26867 net.cpp:226] drop3 needs backward computation.
I0526 11:06:36.456755 26867 net.cpp:226] ip3 needs backward computation.
I0526 11:06:36.456771 26867 net.cpp:226] drop2 needs backward computation.
I0526 11:06:36.456789 26867 net.cpp:226] relu6 needs backward computation.
I0526 11:06:36.456814 26867 net.cpp:226] ip2 needs backward computation.
I0526 11:06:36.456830 26867 net.cpp:226] drop1 needs backward computation.
I0526 11:06:36.456843 26867 net.cpp:226] relu5 needs backward computation.
I0526 11:06:36.456856 26867 net.cpp:226] ip1 needs backward computation.
I0526 11:06:36.456871 26867 net.cpp:226] pool4 needs backward computation.
I0526 11:06:36.456889 26867 net.cpp:226] relu4 needs backward computation.
I0526 11:06:36.456902 26867 net.cpp:226] conv4 needs backward computation.
I0526 11:06:36.456917 26867 net.cpp:226] pool3 needs backward computation.
I0526 11:06:36.456933 26867 net.cpp:226] relu3 needs backward computation.
I0526 11:06:36.456945 26867 net.cpp:226] conv3 needs backward computation.
I0526 11:06:36.456957 26867 net.cpp:226] pool2 needs backward computation.
I0526 11:06:36.456970 26867 net.cpp:226] relu2 needs backward computation.
I0526 11:06:36.456985 26867 net.cpp:226] conv2 needs backward computation.
I0526 11:06:36.457003 26867 net.cpp:226] pool1 needs backward computation.
I0526 11:06:36.457017 26867 net.cpp:226] relu1 needs backward computation.
I0526 11:06:36.457031 26867 net.cpp:226] conv1 needs backward computation.
I0526 11:06:36.457046 26867 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 11:06:36.457059 26867 net.cpp:228] data_hdf5 does not need backward computation.
I0526 11:06:36.457070 26867 net.cpp:270] This network produces output accuracy
I0526 11:06:36.457087 26867 net.cpp:270] This network produces output loss
I0526 11:06:36.457118 26867 net.cpp:283] Network initialization done.
I0526 11:06:36.457252 26867 solver.cpp:60] Solver scaffolding done.
I0526 11:06:36.458405 26867 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_450000.solverstate
I0526 11:06:36.683212 26867 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 11:06:36.688688 26867 caffe.cpp:212] Starting Optimization
I0526 11:06:36.688732 26867 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 11:06:36.688755 26867 solver.cpp:289] Learning Rate Policy: fixed
I0526 11:06:36.690021 26867 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 11:07:37.407320 26867 solver.cpp:409]     Test net output #0: accuracy = 0.877825
I0526 11:07:37.407479 26867 solver.cpp:409]     Test net output #1: loss = 0.398914 (* 1 = 0.398914 loss)
I0526 11:07:37.425268 26867 solver.cpp:237] Iteration 450000, loss = 1.23579
I0526 11:07:37.425308 26867 solver.cpp:253]     Train net output #0: loss = 1.23579 (* 1 = 1.23579 loss)
I0526 11:07:37.425330 26867 sgd_solver.cpp:106] Iteration 450000, lr = 0.005
I0526 11:07:54.189345 26867 solver.cpp:237] Iteration 451500, loss = 0.84506
I0526 11:07:54.189398 26867 solver.cpp:253]     Train net output #0: loss = 0.84506 (* 1 = 0.84506 loss)
I0526 11:07:54.189415 26867 sgd_solver.cpp:106] Iteration 451500, lr = 0.005
I0526 11:08:10.809002 26867 solver.cpp:237] Iteration 453000, loss = 1.29958
I0526 11:08:10.809157 26867 solver.cpp:253]     Train net output #0: loss = 1.29958 (* 1 = 1.29958 loss)
I0526 11:08:10.809175 26867 sgd_solver.cpp:106] Iteration 453000, lr = 0.005
I0526 11:08:27.581274 26867 solver.cpp:237] Iteration 454500, loss = 1.48896
I0526 11:08:27.581322 26867 solver.cpp:253]     Train net output #0: loss = 1.48896 (* 1 = 1.48896 loss)
I0526 11:08:27.581339 26867 sgd_solver.cpp:106] Iteration 454500, lr = 0.005
I0526 11:08:44.344009 26867 solver.cpp:237] Iteration 456000, loss = 0.926758
I0526 11:08:44.344161 26867 solver.cpp:253]     Train net output #0: loss = 0.926758 (* 1 = 0.926758 loss)
I0526 11:08:44.344177 26867 sgd_solver.cpp:106] Iteration 456000, lr = 0.005
I0526 11:09:00.985173 26867 solver.cpp:237] Iteration 457500, loss = 1.1611
I0526 11:09:00.985213 26867 solver.cpp:253]     Train net output #0: loss = 1.1611 (* 1 = 1.1611 loss)
I0526 11:09:00.985229 26867 sgd_solver.cpp:106] Iteration 457500, lr = 0.005
I0526 11:09:17.626889 26867 solver.cpp:237] Iteration 459000, loss = 1.73123
I0526 11:09:17.627064 26867 solver.cpp:253]     Train net output #0: loss = 1.73123 (* 1 = 1.73123 loss)
I0526 11:09:17.627081 26867 sgd_solver.cpp:106] Iteration 459000, lr = 0.005
I0526 11:09:56.502985 26867 solver.cpp:237] Iteration 460500, loss = 0.678811
I0526 11:09:56.503151 26867 solver.cpp:253]     Train net output #0: loss = 0.678812 (* 1 = 0.678812 loss)
I0526 11:09:56.503170 26867 sgd_solver.cpp:106] Iteration 460500, lr = 0.005
I0526 11:10:13.113135 26867 solver.cpp:237] Iteration 462000, loss = 1.20309
I0526 11:10:13.113175 26867 solver.cpp:253]     Train net output #0: loss = 1.20309 (* 1 = 1.20309 loss)
I0526 11:10:13.113193 26867 sgd_solver.cpp:106] Iteration 462000, lr = 0.005
I0526 11:10:29.747203 26867 solver.cpp:237] Iteration 463500, loss = 1.0224
I0526 11:10:29.747359 26867 solver.cpp:253]     Train net output #0: loss = 1.02239 (* 1 = 1.02239 loss)
I0526 11:10:29.747377 26867 sgd_solver.cpp:106] Iteration 463500, lr = 0.005
I0526 11:10:46.402830 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_465000.caffemodel
I0526 11:10:46.449548 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_465000.solverstate
I0526 11:10:46.478679 26867 solver.cpp:237] Iteration 465000, loss = 1.23066
I0526 11:10:46.478734 26867 solver.cpp:253]     Train net output #0: loss = 1.23066 (* 1 = 1.23066 loss)
I0526 11:10:46.478751 26867 sgd_solver.cpp:106] Iteration 465000, lr = 0.005
I0526 11:11:03.669047 26867 solver.cpp:237] Iteration 466500, loss = 0.971124
I0526 11:11:03.669208 26867 solver.cpp:253]     Train net output #0: loss = 0.971123 (* 1 = 0.971123 loss)
I0526 11:11:03.669224 26867 sgd_solver.cpp:106] Iteration 466500, lr = 0.005
I0526 11:11:20.619159 26867 solver.cpp:237] Iteration 468000, loss = 0.608846
I0526 11:11:20.619215 26867 solver.cpp:253]     Train net output #0: loss = 0.608846 (* 1 = 0.608846 loss)
I0526 11:11:20.619233 26867 sgd_solver.cpp:106] Iteration 468000, lr = 0.005
I0526 11:11:37.422421 26867 solver.cpp:237] Iteration 469500, loss = 1.14118
I0526 11:11:37.422580 26867 solver.cpp:253]     Train net output #0: loss = 1.14118 (* 1 = 1.14118 loss)
I0526 11:11:37.422596 26867 sgd_solver.cpp:106] Iteration 469500, lr = 0.005
I0526 11:12:16.521726 26867 solver.cpp:237] Iteration 471000, loss = 1.26589
I0526 11:12:16.521903 26867 solver.cpp:253]     Train net output #0: loss = 1.26589 (* 1 = 1.26589 loss)
I0526 11:12:16.521919 26867 sgd_solver.cpp:106] Iteration 471000, lr = 0.005
I0526 11:12:33.369611 26867 solver.cpp:237] Iteration 472500, loss = 1.3998
I0526 11:12:33.369663 26867 solver.cpp:253]     Train net output #0: loss = 1.3998 (* 1 = 1.3998 loss)
I0526 11:12:33.369680 26867 sgd_solver.cpp:106] Iteration 472500, lr = 0.005
I0526 11:12:50.125828 26867 solver.cpp:237] Iteration 474000, loss = 1.22788
I0526 11:12:50.125974 26867 solver.cpp:253]     Train net output #0: loss = 1.22788 (* 1 = 1.22788 loss)
I0526 11:12:50.125991 26867 sgd_solver.cpp:106] Iteration 474000, lr = 0.005
I0526 11:13:07.008615 26867 solver.cpp:237] Iteration 475500, loss = 1.2024
I0526 11:13:07.008664 26867 solver.cpp:253]     Train net output #0: loss = 1.2024 (* 1 = 1.2024 loss)
I0526 11:13:07.008683 26867 sgd_solver.cpp:106] Iteration 475500, lr = 0.005
I0526 11:13:23.995632 26867 solver.cpp:237] Iteration 477000, loss = 0.969975
I0526 11:13:23.995791 26867 solver.cpp:253]     Train net output #0: loss = 0.969975 (* 1 = 0.969975 loss)
I0526 11:13:23.995810 26867 sgd_solver.cpp:106] Iteration 477000, lr = 0.005
I0526 11:13:41.033265 26867 solver.cpp:237] Iteration 478500, loss = 1.47939
I0526 11:13:41.033319 26867 solver.cpp:253]     Train net output #0: loss = 1.47939 (* 1 = 1.47939 loss)
I0526 11:13:41.033345 26867 sgd_solver.cpp:106] Iteration 478500, lr = 0.005
I0526 11:13:57.990962 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_480000.caffemodel
I0526 11:13:58.037187 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_480000.solverstate
I0526 11:13:58.065731 26867 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 11:14:57.676260 26867 solver.cpp:409]     Test net output #0: accuracy = 0.882901
I0526 11:14:57.676420 26867 solver.cpp:409]     Test net output #1: loss = 0.404894 (* 1 = 0.404894 loss)
I0526 11:15:19.873679 26867 solver.cpp:237] Iteration 480000, loss = 0.971304
I0526 11:15:19.873739 26867 solver.cpp:253]     Train net output #0: loss = 0.971304 (* 1 = 0.971304 loss)
I0526 11:15:19.873759 26867 sgd_solver.cpp:106] Iteration 480000, lr = 0.005
I0526 11:15:36.521766 26867 solver.cpp:237] Iteration 481500, loss = 1.2862
I0526 11:15:36.521930 26867 solver.cpp:253]     Train net output #0: loss = 1.2862 (* 1 = 1.2862 loss)
I0526 11:15:36.521947 26867 sgd_solver.cpp:106] Iteration 481500, lr = 0.005
I0526 11:15:53.275884 26867 solver.cpp:237] Iteration 483000, loss = 1.07074
I0526 11:15:53.275935 26867 solver.cpp:253]     Train net output #0: loss = 1.07074 (* 1 = 1.07074 loss)
I0526 11:15:53.275954 26867 sgd_solver.cpp:106] Iteration 483000, lr = 0.005
I0526 11:16:10.177151 26867 solver.cpp:237] Iteration 484500, loss = 1.0035
I0526 11:16:10.177297 26867 solver.cpp:253]     Train net output #0: loss = 1.0035 (* 1 = 1.0035 loss)
I0526 11:16:10.177314 26867 sgd_solver.cpp:106] Iteration 484500, lr = 0.005
I0526 11:16:27.341230 26867 solver.cpp:237] Iteration 486000, loss = 1.26815
I0526 11:16:27.341279 26867 solver.cpp:253]     Train net output #0: loss = 1.26815 (* 1 = 1.26815 loss)
I0526 11:16:27.341298 26867 sgd_solver.cpp:106] Iteration 486000, lr = 0.005
I0526 11:16:44.394501 26867 solver.cpp:237] Iteration 487500, loss = 1.61805
I0526 11:16:44.394660 26867 solver.cpp:253]     Train net output #0: loss = 1.61805 (* 1 = 1.61805 loss)
I0526 11:16:44.394677 26867 sgd_solver.cpp:106] Iteration 487500, lr = 0.005
I0526 11:17:01.358742 26867 solver.cpp:237] Iteration 489000, loss = 0.665419
I0526 11:17:01.358798 26867 solver.cpp:253]     Train net output #0: loss = 0.665418 (* 1 = 0.665418 loss)
I0526 11:17:01.358824 26867 sgd_solver.cpp:106] Iteration 489000, lr = 0.005
I0526 11:17:40.259744 26867 solver.cpp:237] Iteration 490500, loss = 0.936422
I0526 11:17:40.259922 26867 solver.cpp:253]     Train net output #0: loss = 0.93642 (* 1 = 0.93642 loss)
I0526 11:17:40.259940 26867 sgd_solver.cpp:106] Iteration 490500, lr = 0.005
I0526 11:17:56.982823 26867 solver.cpp:237] Iteration 492000, loss = 0.773226
I0526 11:17:56.982874 26867 solver.cpp:253]     Train net output #0: loss = 0.773225 (* 1 = 0.773225 loss)
I0526 11:17:56.982894 26867 sgd_solver.cpp:106] Iteration 492000, lr = 0.005
I0526 11:18:13.944524 26867 solver.cpp:237] Iteration 493500, loss = 0.920143
I0526 11:18:13.944671 26867 solver.cpp:253]     Train net output #0: loss = 0.920142 (* 1 = 0.920142 loss)
I0526 11:18:13.944689 26867 sgd_solver.cpp:106] Iteration 493500, lr = 0.005
I0526 11:18:30.579686 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_495000.caffemodel
I0526 11:18:30.628621 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_495000.solverstate
I0526 11:18:30.659642 26867 solver.cpp:237] Iteration 495000, loss = 0.570874
I0526 11:18:30.659700 26867 solver.cpp:253]     Train net output #0: loss = 0.570872 (* 1 = 0.570872 loss)
I0526 11:18:30.659726 26867 sgd_solver.cpp:106] Iteration 495000, lr = 0.005
I0526 11:18:47.346675 26867 solver.cpp:237] Iteration 496500, loss = 0.992519
I0526 11:18:47.346840 26867 solver.cpp:253]     Train net output #0: loss = 0.992518 (* 1 = 0.992518 loss)
I0526 11:18:47.346858 26867 sgd_solver.cpp:106] Iteration 496500, lr = 0.005
I0526 11:19:04.126430 26867 solver.cpp:237] Iteration 498000, loss = 1.10912
I0526 11:19:04.126468 26867 solver.cpp:253]     Train net output #0: loss = 1.10912 (* 1 = 1.10912 loss)
I0526 11:19:04.126487 26867 sgd_solver.cpp:106] Iteration 498000, lr = 0.005
I0526 11:19:20.735929 26867 solver.cpp:237] Iteration 499500, loss = 1.48347
I0526 11:19:20.736084 26867 solver.cpp:253]     Train net output #0: loss = 1.48346 (* 1 = 1.48346 loss)
I0526 11:19:20.736102 26867 sgd_solver.cpp:106] Iteration 499500, lr = 0.005
I0526 11:19:59.622723 26867 solver.cpp:237] Iteration 501000, loss = 1.11676
I0526 11:19:59.622895 26867 solver.cpp:253]     Train net output #0: loss = 1.11676 (* 1 = 1.11676 loss)
I0526 11:19:59.622911 26867 sgd_solver.cpp:106] Iteration 501000, lr = 0.005
I0526 11:20:16.259793 26867 solver.cpp:237] Iteration 502500, loss = 0.964339
I0526 11:20:16.259835 26867 solver.cpp:253]     Train net output #0: loss = 0.964335 (* 1 = 0.964335 loss)
I0526 11:20:16.259852 26867 sgd_solver.cpp:106] Iteration 502500, lr = 0.005
I0526 11:20:33.324615 26867 solver.cpp:237] Iteration 504000, loss = 1.23544
I0526 11:20:33.324789 26867 solver.cpp:253]     Train net output #0: loss = 1.23544 (* 1 = 1.23544 loss)
I0526 11:20:33.324805 26867 sgd_solver.cpp:106] Iteration 504000, lr = 0.005
I0526 11:20:50.421139 26867 solver.cpp:237] Iteration 505500, loss = 0.930376
I0526 11:20:50.421191 26867 solver.cpp:253]     Train net output #0: loss = 0.930372 (* 1 = 0.930372 loss)
I0526 11:20:50.421218 26867 sgd_solver.cpp:106] Iteration 505500, lr = 0.005
I0526 11:21:07.300760 26867 solver.cpp:237] Iteration 507000, loss = 1.56526
I0526 11:21:07.300906 26867 solver.cpp:253]     Train net output #0: loss = 1.56525 (* 1 = 1.56525 loss)
I0526 11:21:07.300922 26867 sgd_solver.cpp:106] Iteration 507000, lr = 0.005
I0526 11:21:24.241448 26867 solver.cpp:237] Iteration 508500, loss = 1.09083
I0526 11:21:24.241500 26867 solver.cpp:253]     Train net output #0: loss = 1.09082 (* 1 = 1.09082 loss)
I0526 11:21:24.241518 26867 sgd_solver.cpp:106] Iteration 508500, lr = 0.005
I0526 11:21:41.226717 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_510000.caffemodel
I0526 11:21:41.275825 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_510000.solverstate
I0526 11:21:41.303658 26867 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 11:23:01.974828 26867 solver.cpp:409]     Test net output #0: accuracy = 0.880399
I0526 11:23:01.975005 26867 solver.cpp:409]     Test net output #1: loss = 0.410916 (* 1 = 0.410916 loss)
I0526 11:23:24.239169 26867 solver.cpp:237] Iteration 510000, loss = 1.49333
I0526 11:23:24.239229 26867 solver.cpp:253]     Train net output #0: loss = 1.49333 (* 1 = 1.49333 loss)
I0526 11:23:24.239258 26867 sgd_solver.cpp:106] Iteration 510000, lr = 0.005
I0526 11:23:40.879684 26867 solver.cpp:237] Iteration 511500, loss = 0.736048
I0526 11:23:40.879850 26867 solver.cpp:253]     Train net output #0: loss = 0.736044 (* 1 = 0.736044 loss)
I0526 11:23:40.879868 26867 sgd_solver.cpp:106] Iteration 511500, lr = 0.005
I0526 11:23:57.926594 26867 solver.cpp:237] Iteration 513000, loss = 0.935539
I0526 11:23:57.926635 26867 solver.cpp:253]     Train net output #0: loss = 0.935536 (* 1 = 0.935536 loss)
I0526 11:23:57.926651 26867 sgd_solver.cpp:106] Iteration 513000, lr = 0.005
I0526 11:24:14.722683 26867 solver.cpp:237] Iteration 514500, loss = 1.64306
I0526 11:24:14.722844 26867 solver.cpp:253]     Train net output #0: loss = 1.64306 (* 1 = 1.64306 loss)
I0526 11:24:14.722862 26867 sgd_solver.cpp:106] Iteration 514500, lr = 0.005
I0526 11:24:31.371346 26867 solver.cpp:237] Iteration 516000, loss = 1.32178
I0526 11:24:31.371400 26867 solver.cpp:253]     Train net output #0: loss = 1.32177 (* 1 = 1.32177 loss)
I0526 11:24:31.371426 26867 sgd_solver.cpp:106] Iteration 516000, lr = 0.005
I0526 11:24:48.326460 26867 solver.cpp:237] Iteration 517500, loss = 0.945841
I0526 11:24:48.326607 26867 solver.cpp:253]     Train net output #0: loss = 0.945838 (* 1 = 0.945838 loss)
I0526 11:24:48.326624 26867 sgd_solver.cpp:106] Iteration 517500, lr = 0.005
I0526 11:25:05.223490 26867 solver.cpp:237] Iteration 519000, loss = 1.04319
I0526 11:25:05.223541 26867 solver.cpp:253]     Train net output #0: loss = 1.04319 (* 1 = 1.04319 loss)
I0526 11:25:05.223559 26867 sgd_solver.cpp:106] Iteration 519000, lr = 0.005
I0526 11:25:44.330624 26867 solver.cpp:237] Iteration 520500, loss = 1.56545
I0526 11:25:44.330796 26867 solver.cpp:253]     Train net output #0: loss = 1.56544 (* 1 = 1.56544 loss)
I0526 11:25:44.330813 26867 sgd_solver.cpp:106] Iteration 520500, lr = 0.005
I0526 11:26:00.977972 26867 solver.cpp:237] Iteration 522000, loss = 1.253
I0526 11:26:00.978030 26867 solver.cpp:253]     Train net output #0: loss = 1.253 (* 1 = 1.253 loss)
I0526 11:26:00.978047 26867 sgd_solver.cpp:106] Iteration 522000, lr = 0.005
I0526 11:26:17.755040 26867 solver.cpp:237] Iteration 523500, loss = 1.21346
I0526 11:26:17.755201 26867 solver.cpp:253]     Train net output #0: loss = 1.21346 (* 1 = 1.21346 loss)
I0526 11:26:17.755218 26867 sgd_solver.cpp:106] Iteration 523500, lr = 0.005
I0526 11:26:34.717852 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_525000.caffemodel
I0526 11:26:34.766388 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_525000.solverstate
I0526 11:26:34.797449 26867 solver.cpp:237] Iteration 525000, loss = 1.41161
I0526 11:26:34.797510 26867 solver.cpp:253]     Train net output #0: loss = 1.4116 (* 1 = 1.4116 loss)
I0526 11:26:34.797530 26867 sgd_solver.cpp:106] Iteration 525000, lr = 0.005
I0526 11:26:51.670436 26867 solver.cpp:237] Iteration 526500, loss = 1.44314
I0526 11:26:51.670598 26867 solver.cpp:253]     Train net output #0: loss = 1.44314 (* 1 = 1.44314 loss)
I0526 11:26:51.670616 26867 sgd_solver.cpp:106] Iteration 526500, lr = 0.005
I0526 11:27:08.496141 26867 solver.cpp:237] Iteration 528000, loss = 1.36354
I0526 11:27:08.496193 26867 solver.cpp:253]     Train net output #0: loss = 1.36354 (* 1 = 1.36354 loss)
I0526 11:27:08.496211 26867 sgd_solver.cpp:106] Iteration 528000, lr = 0.005
I0526 11:27:25.323439 26867 solver.cpp:237] Iteration 529500, loss = 0.991535
I0526 11:27:25.323609 26867 solver.cpp:253]     Train net output #0: loss = 0.991533 (* 1 = 0.991533 loss)
I0526 11:27:25.323628 26867 sgd_solver.cpp:106] Iteration 529500, lr = 0.005
I0526 11:28:04.817262 26867 solver.cpp:237] Iteration 531000, loss = 0.521613
I0526 11:28:04.817438 26867 solver.cpp:253]     Train net output #0: loss = 0.521611 (* 1 = 0.521611 loss)
I0526 11:28:04.817456 26867 sgd_solver.cpp:106] Iteration 531000, lr = 0.005
I0526 11:28:21.772976 26867 solver.cpp:237] Iteration 532500, loss = 1.04777
I0526 11:28:21.773028 26867 solver.cpp:253]     Train net output #0: loss = 1.04776 (* 1 = 1.04776 loss)
I0526 11:28:21.773048 26867 sgd_solver.cpp:106] Iteration 532500, lr = 0.005
I0526 11:28:38.419796 26867 solver.cpp:237] Iteration 534000, loss = 1.56577
I0526 11:28:38.419944 26867 solver.cpp:253]     Train net output #0: loss = 1.56576 (* 1 = 1.56576 loss)
I0526 11:28:38.419961 26867 sgd_solver.cpp:106] Iteration 534000, lr = 0.005
I0526 11:28:55.427744 26867 solver.cpp:237] Iteration 535500, loss = 1.31411
I0526 11:28:55.427796 26867 solver.cpp:253]     Train net output #0: loss = 1.3141 (* 1 = 1.3141 loss)
I0526 11:28:55.427814 26867 sgd_solver.cpp:106] Iteration 535500, lr = 0.005
I0526 11:29:12.440945 26867 solver.cpp:237] Iteration 537000, loss = 1.23233
I0526 11:29:12.441123 26867 solver.cpp:253]     Train net output #0: loss = 1.23233 (* 1 = 1.23233 loss)
I0526 11:29:12.441140 26867 sgd_solver.cpp:106] Iteration 537000, lr = 0.005
I0526 11:29:29.331264 26867 solver.cpp:237] Iteration 538500, loss = 0.856677
I0526 11:29:29.331303 26867 solver.cpp:253]     Train net output #0: loss = 0.856673 (* 1 = 0.856673 loss)
I0526 11:29:29.331321 26867 sgd_solver.cpp:106] Iteration 538500, lr = 0.005
I0526 11:29:46.287829 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_540000.caffemodel
I0526 11:29:46.333698 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_540000.solverstate
I0526 11:29:46.359042 26867 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 11:30:45.599149 26867 solver.cpp:409]     Test net output #0: accuracy = 0.883857
I0526 11:30:45.599308 26867 solver.cpp:409]     Test net output #1: loss = 0.382989 (* 1 = 0.382989 loss)
I0526 11:31:07.806766 26867 solver.cpp:237] Iteration 540000, loss = 1.0192
I0526 11:31:07.806824 26867 solver.cpp:253]     Train net output #0: loss = 1.0192 (* 1 = 1.0192 loss)
I0526 11:31:07.806849 26867 sgd_solver.cpp:106] Iteration 540000, lr = 0.005
I0526 11:31:24.425961 26867 solver.cpp:237] Iteration 541500, loss = 0.848729
I0526 11:31:24.426151 26867 solver.cpp:253]     Train net output #0: loss = 0.848726 (* 1 = 0.848726 loss)
I0526 11:31:24.426169 26867 sgd_solver.cpp:106] Iteration 541500, lr = 0.005
I0526 11:31:41.143072 26867 solver.cpp:237] Iteration 543000, loss = 1.21893
I0526 11:31:41.143124 26867 solver.cpp:253]     Train net output #0: loss = 1.21893 (* 1 = 1.21893 loss)
I0526 11:31:41.143151 26867 sgd_solver.cpp:106] Iteration 543000, lr = 0.005
I0526 11:31:58.038391 26867 solver.cpp:237] Iteration 544500, loss = 1.6603
I0526 11:31:58.038537 26867 solver.cpp:253]     Train net output #0: loss = 1.66029 (* 1 = 1.66029 loss)
I0526 11:31:58.038553 26867 sgd_solver.cpp:106] Iteration 544500, lr = 0.005
I0526 11:32:14.955302 26867 solver.cpp:237] Iteration 546000, loss = 1.48953
I0526 11:32:14.955354 26867 solver.cpp:253]     Train net output #0: loss = 1.48952 (* 1 = 1.48952 loss)
I0526 11:32:14.955373 26867 sgd_solver.cpp:106] Iteration 546000, lr = 0.005
I0526 11:32:31.872514 26867 solver.cpp:237] Iteration 547500, loss = 0.815376
I0526 11:32:31.872690 26867 solver.cpp:253]     Train net output #0: loss = 0.815373 (* 1 = 0.815373 loss)
I0526 11:32:31.872709 26867 sgd_solver.cpp:106] Iteration 547500, lr = 0.005
I0526 11:32:48.770519 26867 solver.cpp:237] Iteration 549000, loss = 1.34201
I0526 11:32:48.770557 26867 solver.cpp:253]     Train net output #0: loss = 1.342 (* 1 = 1.342 loss)
I0526 11:32:48.770576 26867 sgd_solver.cpp:106] Iteration 549000, lr = 0.005
I0526 11:33:27.648042 26867 solver.cpp:237] Iteration 550500, loss = 0.68183
I0526 11:33:27.648210 26867 solver.cpp:253]     Train net output #0: loss = 0.681827 (* 1 = 0.681827 loss)
I0526 11:33:27.648227 26867 sgd_solver.cpp:106] Iteration 550500, lr = 0.005
I0526 11:33:44.416090 26867 solver.cpp:237] Iteration 552000, loss = 0.926257
I0526 11:33:44.416146 26867 solver.cpp:253]     Train net output #0: loss = 0.926255 (* 1 = 0.926255 loss)
I0526 11:33:44.416170 26867 sgd_solver.cpp:106] Iteration 552000, lr = 0.005
I0526 11:34:01.609220 26867 solver.cpp:237] Iteration 553500, loss = 0.94283
I0526 11:34:01.609374 26867 solver.cpp:253]     Train net output #0: loss = 0.942829 (* 1 = 0.942829 loss)
I0526 11:34:01.609390 26867 sgd_solver.cpp:106] Iteration 553500, lr = 0.005
I0526 11:34:18.595201 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_555000.caffemodel
I0526 11:34:18.641645 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_555000.solverstate
I0526 11:34:18.670833 26867 solver.cpp:237] Iteration 555000, loss = 1.87149
I0526 11:34:18.670886 26867 solver.cpp:253]     Train net output #0: loss = 1.87149 (* 1 = 1.87149 loss)
I0526 11:34:18.670912 26867 sgd_solver.cpp:106] Iteration 555000, lr = 0.005
I0526 11:34:35.710285 26867 solver.cpp:237] Iteration 556500, loss = 0.794817
I0526 11:34:35.710453 26867 solver.cpp:253]     Train net output #0: loss = 0.794815 (* 1 = 0.794815 loss)
I0526 11:34:35.710472 26867 sgd_solver.cpp:106] Iteration 556500, lr = 0.005
I0526 11:34:52.922319 26867 solver.cpp:237] Iteration 558000, loss = 0.98143
I0526 11:34:52.922359 26867 solver.cpp:253]     Train net output #0: loss = 0.981429 (* 1 = 0.981429 loss)
I0526 11:34:52.922379 26867 sgd_solver.cpp:106] Iteration 558000, lr = 0.005
I0526 11:35:09.635241 26867 solver.cpp:237] Iteration 559500, loss = 1.26345
I0526 11:35:09.635404 26867 solver.cpp:253]     Train net output #0: loss = 1.26345 (* 1 = 1.26345 loss)
I0526 11:35:09.635422 26867 sgd_solver.cpp:106] Iteration 559500, lr = 0.005
I0526 11:35:48.641767 26867 solver.cpp:237] Iteration 561000, loss = 1.23829
I0526 11:35:48.641934 26867 solver.cpp:253]     Train net output #0: loss = 1.23829 (* 1 = 1.23829 loss)
I0526 11:35:48.641952 26867 sgd_solver.cpp:106] Iteration 561000, lr = 0.005
I0526 11:36:05.849436 26867 solver.cpp:237] Iteration 562500, loss = 1.65283
I0526 11:36:05.849474 26867 solver.cpp:253]     Train net output #0: loss = 1.65283 (* 1 = 1.65283 loss)
I0526 11:36:05.849491 26867 sgd_solver.cpp:106] Iteration 562500, lr = 0.005
I0526 11:36:22.869773 26867 solver.cpp:237] Iteration 564000, loss = 1.65482
I0526 11:36:22.869935 26867 solver.cpp:253]     Train net output #0: loss = 1.65482 (* 1 = 1.65482 loss)
I0526 11:36:22.869952 26867 sgd_solver.cpp:106] Iteration 564000, lr = 0.005
I0526 11:36:39.890821 26867 solver.cpp:237] Iteration 565500, loss = 1.37208
I0526 11:36:39.890874 26867 solver.cpp:253]     Train net output #0: loss = 1.37208 (* 1 = 1.37208 loss)
I0526 11:36:39.890900 26867 sgd_solver.cpp:106] Iteration 565500, lr = 0.005
I0526 11:36:56.934836 26867 solver.cpp:237] Iteration 567000, loss = 0.958704
I0526 11:36:56.934988 26867 solver.cpp:253]     Train net output #0: loss = 0.958703 (* 1 = 0.958703 loss)
I0526 11:36:56.935006 26867 sgd_solver.cpp:106] Iteration 567000, lr = 0.005
I0526 11:37:13.926190 26867 solver.cpp:237] Iteration 568500, loss = 1.64729
I0526 11:37:13.926239 26867 solver.cpp:253]     Train net output #0: loss = 1.64729 (* 1 = 1.64729 loss)
I0526 11:37:13.926257 26867 sgd_solver.cpp:106] Iteration 568500, lr = 0.005
I0526 11:37:30.971761 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_570000.caffemodel
I0526 11:37:31.018450 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_570000.solverstate
I0526 11:37:31.044076 26867 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 11:38:51.351454 26867 solver.cpp:409]     Test net output #0: accuracy = 0.878185
I0526 11:38:51.351630 26867 solver.cpp:409]     Test net output #1: loss = 0.393126 (* 1 = 0.393126 loss)
I0526 11:39:13.600555 26867 solver.cpp:237] Iteration 570000, loss = 1.41124
I0526 11:39:13.600616 26867 solver.cpp:253]     Train net output #0: loss = 1.41124 (* 1 = 1.41124 loss)
I0526 11:39:13.600636 26867 sgd_solver.cpp:106] Iteration 570000, lr = 0.005
I0526 11:39:30.242996 26867 solver.cpp:237] Iteration 571500, loss = 1.81908
I0526 11:39:30.243163 26867 solver.cpp:253]     Train net output #0: loss = 1.81908 (* 1 = 1.81908 loss)
I0526 11:39:30.243180 26867 sgd_solver.cpp:106] Iteration 571500, lr = 0.005
I0526 11:39:47.199411 26867 solver.cpp:237] Iteration 573000, loss = 0.404506
I0526 11:39:47.199455 26867 solver.cpp:253]     Train net output #0: loss = 0.404506 (* 1 = 0.404506 loss)
I0526 11:39:47.199471 26867 sgd_solver.cpp:106] Iteration 573000, lr = 0.005
I0526 11:40:04.304922 26867 solver.cpp:237] Iteration 574500, loss = 1.20425
I0526 11:40:04.305085 26867 solver.cpp:253]     Train net output #0: loss = 1.20425 (* 1 = 1.20425 loss)
I0526 11:40:04.305104 26867 sgd_solver.cpp:106] Iteration 574500, lr = 0.005
I0526 11:40:21.475813 26867 solver.cpp:237] Iteration 576000, loss = 1.03339
I0526 11:40:21.475863 26867 solver.cpp:253]     Train net output #0: loss = 1.03339 (* 1 = 1.03339 loss)
I0526 11:40:21.475890 26867 sgd_solver.cpp:106] Iteration 576000, lr = 0.005
I0526 11:40:38.098258 26867 solver.cpp:237] Iteration 577500, loss = 1.4807
I0526 11:40:38.098409 26867 solver.cpp:253]     Train net output #0: loss = 1.4807 (* 1 = 1.4807 loss)
I0526 11:40:38.098426 26867 sgd_solver.cpp:106] Iteration 577500, lr = 0.005
I0526 11:40:54.782461 26867 solver.cpp:237] Iteration 579000, loss = 1.35991
I0526 11:40:54.782511 26867 solver.cpp:253]     Train net output #0: loss = 1.35991 (* 1 = 1.35991 loss)
I0526 11:40:54.782528 26867 sgd_solver.cpp:106] Iteration 579000, lr = 0.005
I0526 11:41:33.839679 26867 solver.cpp:237] Iteration 580500, loss = 1.31197
I0526 11:41:33.839850 26867 solver.cpp:253]     Train net output #0: loss = 1.31197 (* 1 = 1.31197 loss)
I0526 11:41:33.839867 26867 sgd_solver.cpp:106] Iteration 580500, lr = 0.005
I0526 11:41:50.521430 26867 solver.cpp:237] Iteration 582000, loss = 1.14052
I0526 11:41:50.521481 26867 solver.cpp:253]     Train net output #0: loss = 1.14052 (* 1 = 1.14052 loss)
I0526 11:41:50.521499 26867 sgd_solver.cpp:106] Iteration 582000, lr = 0.005
I0526 11:42:07.263535 26867 solver.cpp:237] Iteration 583500, loss = 1.05074
I0526 11:42:07.263700 26867 solver.cpp:253]     Train net output #0: loss = 1.05074 (* 1 = 1.05074 loss)
I0526 11:42:07.263716 26867 sgd_solver.cpp:106] Iteration 583500, lr = 0.005
I0526 11:42:24.223572 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_585000.caffemodel
I0526 11:42:24.271723 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_585000.solverstate
I0526 11:42:24.301723 26867 solver.cpp:237] Iteration 585000, loss = 3.56751
I0526 11:42:24.301779 26867 solver.cpp:253]     Train net output #0: loss = 3.56751 (* 1 = 3.56751 loss)
I0526 11:42:24.301806 26867 sgd_solver.cpp:106] Iteration 585000, lr = 0.005
I0526 11:42:41.319110 26867 solver.cpp:237] Iteration 586500, loss = 1.12412
I0526 11:42:41.319291 26867 solver.cpp:253]     Train net output #0: loss = 1.12412 (* 1 = 1.12412 loss)
I0526 11:42:41.319308 26867 sgd_solver.cpp:106] Iteration 586500, lr = 0.005
I0526 11:42:58.437973 26867 solver.cpp:237] Iteration 588000, loss = 1.41125
I0526 11:42:58.438032 26867 solver.cpp:253]     Train net output #0: loss = 1.41125 (* 1 = 1.41125 loss)
I0526 11:42:58.438050 26867 sgd_solver.cpp:106] Iteration 588000, lr = 0.005
I0526 11:43:15.606680 26867 solver.cpp:237] Iteration 589500, loss = 1.04047
I0526 11:43:15.606848 26867 solver.cpp:253]     Train net output #0: loss = 1.04047 (* 1 = 1.04047 loss)
I0526 11:43:15.606866 26867 sgd_solver.cpp:106] Iteration 589500, lr = 0.005
I0526 11:43:54.873019 26867 solver.cpp:237] Iteration 591000, loss = 0.956912
I0526 11:43:54.873193 26867 solver.cpp:253]     Train net output #0: loss = 0.956911 (* 1 = 0.956911 loss)
I0526 11:43:54.873211 26867 sgd_solver.cpp:106] Iteration 591000, lr = 0.005
I0526 11:44:11.767789 26867 solver.cpp:237] Iteration 592500, loss = 1.07766
I0526 11:44:11.767840 26867 solver.cpp:253]     Train net output #0: loss = 1.07766 (* 1 = 1.07766 loss)
I0526 11:44:11.767860 26867 sgd_solver.cpp:106] Iteration 592500, lr = 0.005
I0526 11:44:28.406658 26867 solver.cpp:237] Iteration 594000, loss = 0.574743
I0526 11:44:28.406810 26867 solver.cpp:253]     Train net output #0: loss = 0.574741 (* 1 = 0.574741 loss)
I0526 11:44:28.406827 26867 sgd_solver.cpp:106] Iteration 594000, lr = 0.005
I0526 11:44:45.376394 26867 solver.cpp:237] Iteration 595500, loss = 1.53018
I0526 11:44:45.376447 26867 solver.cpp:253]     Train net output #0: loss = 1.53018 (* 1 = 1.53018 loss)
I0526 11:44:45.376464 26867 sgd_solver.cpp:106] Iteration 595500, lr = 0.005
I0526 11:45:02.455713 26867 solver.cpp:237] Iteration 597000, loss = 1.19226
I0526 11:45:02.455895 26867 solver.cpp:253]     Train net output #0: loss = 1.19226 (* 1 = 1.19226 loss)
I0526 11:45:02.455912 26867 sgd_solver.cpp:106] Iteration 597000, lr = 0.005
I0526 11:45:19.668738 26867 solver.cpp:237] Iteration 598500, loss = 0.83879
I0526 11:45:19.668779 26867 solver.cpp:253]     Train net output #0: loss = 0.838788 (* 1 = 0.838788 loss)
I0526 11:45:19.668797 26867 sgd_solver.cpp:106] Iteration 598500, lr = 0.005
I0526 11:45:36.438375 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_600000.caffemodel
I0526 11:45:36.495575 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_600000.solverstate
I0526 11:45:36.524421 26867 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 11:46:36.180022 26867 solver.cpp:409]     Test net output #0: accuracy = 0.882059
I0526 11:46:36.180188 26867 solver.cpp:409]     Test net output #1: loss = 0.384374 (* 1 = 0.384374 loss)
I0526 11:46:57.115057 26867 solver.cpp:237] Iteration 600000, loss = 1.11221
I0526 11:46:57.115118 26867 solver.cpp:253]     Train net output #0: loss = 1.11221 (* 1 = 1.11221 loss)
I0526 11:46:57.115144 26867 sgd_solver.cpp:106] Iteration 600000, lr = 0.005
I0526 11:47:14.088251 26867 solver.cpp:237] Iteration 601500, loss = 0.615311
I0526 11:47:14.088423 26867 solver.cpp:253]     Train net output #0: loss = 0.615309 (* 1 = 0.615309 loss)
I0526 11:47:14.088440 26867 sgd_solver.cpp:106] Iteration 601500, lr = 0.005
I0526 11:47:31.118619 26867 solver.cpp:237] Iteration 603000, loss = 0.97696
I0526 11:47:31.118674 26867 solver.cpp:253]     Train net output #0: loss = 0.976958 (* 1 = 0.976958 loss)
I0526 11:47:31.118700 26867 sgd_solver.cpp:106] Iteration 603000, lr = 0.005
I0526 11:47:48.283469 26867 solver.cpp:237] Iteration 604500, loss = 0.957876
I0526 11:47:48.283644 26867 solver.cpp:253]     Train net output #0: loss = 0.957875 (* 1 = 0.957875 loss)
I0526 11:47:48.283661 26867 sgd_solver.cpp:106] Iteration 604500, lr = 0.005
I0526 11:48:04.961606 26867 solver.cpp:237] Iteration 606000, loss = 0.678108
I0526 11:48:04.961660 26867 solver.cpp:253]     Train net output #0: loss = 0.678107 (* 1 = 0.678107 loss)
I0526 11:48:04.961678 26867 sgd_solver.cpp:106] Iteration 606000, lr = 0.005
I0526 11:48:21.634429 26867 solver.cpp:237] Iteration 607500, loss = 0.983282
I0526 11:48:21.634603 26867 solver.cpp:253]     Train net output #0: loss = 0.983282 (* 1 = 0.983282 loss)
I0526 11:48:21.634619 26867 sgd_solver.cpp:106] Iteration 607500, lr = 0.005
I0526 11:48:38.430961 26867 solver.cpp:237] Iteration 609000, loss = 2.4508
I0526 11:48:38.431001 26867 solver.cpp:253]     Train net output #0: loss = 2.4508 (* 1 = 2.4508 loss)
I0526 11:48:38.431017 26867 sgd_solver.cpp:106] Iteration 609000, lr = 0.005
I0526 11:49:16.283614 26867 solver.cpp:237] Iteration 610500, loss = 1.35201
I0526 11:49:16.283798 26867 solver.cpp:253]     Train net output #0: loss = 1.35201 (* 1 = 1.35201 loss)
I0526 11:49:16.283817 26867 sgd_solver.cpp:106] Iteration 610500, lr = 0.005
I0526 11:49:32.938102 26867 solver.cpp:237] Iteration 612000, loss = 1.31515
I0526 11:49:32.938158 26867 solver.cpp:253]     Train net output #0: loss = 1.31515 (* 1 = 1.31515 loss)
I0526 11:49:32.938184 26867 sgd_solver.cpp:106] Iteration 612000, lr = 0.005
I0526 11:49:49.810240 26867 solver.cpp:237] Iteration 613500, loss = 1.08584
I0526 11:49:49.810394 26867 solver.cpp:253]     Train net output #0: loss = 1.08584 (* 1 = 1.08584 loss)
I0526 11:49:49.810410 26867 sgd_solver.cpp:106] Iteration 613500, lr = 0.005
I0526 11:50:06.779980 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_615000.caffemodel
I0526 11:50:06.826154 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_615000.solverstate
I0526 11:50:06.855072 26867 solver.cpp:237] Iteration 615000, loss = 0.939052
I0526 11:50:06.855125 26867 solver.cpp:253]     Train net output #0: loss = 0.939052 (* 1 = 0.939052 loss)
I0526 11:50:06.855146 26867 sgd_solver.cpp:106] Iteration 615000, lr = 0.005
I0526 11:50:23.979876 26867 solver.cpp:237] Iteration 616500, loss = 0.894182
I0526 11:50:23.980048 26867 solver.cpp:253]     Train net output #0: loss = 0.894183 (* 1 = 0.894183 loss)
I0526 11:50:23.980067 26867 sgd_solver.cpp:106] Iteration 616500, lr = 0.005
I0526 11:50:41.207792 26867 solver.cpp:237] Iteration 618000, loss = 1.29204
I0526 11:50:41.207834 26867 solver.cpp:253]     Train net output #0: loss = 1.29204 (* 1 = 1.29204 loss)
I0526 11:50:41.207851 26867 sgd_solver.cpp:106] Iteration 618000, lr = 0.005
I0526 11:50:57.971621 26867 solver.cpp:237] Iteration 619500, loss = 1.51462
I0526 11:50:57.971796 26867 solver.cpp:253]     Train net output #0: loss = 1.51462 (* 1 = 1.51462 loss)
I0526 11:50:57.971814 26867 sgd_solver.cpp:106] Iteration 619500, lr = 0.005
I0526 11:51:35.488052 26867 solver.cpp:237] Iteration 621000, loss = 0.799073
I0526 11:51:35.488221 26867 solver.cpp:253]     Train net output #0: loss = 0.799074 (* 1 = 0.799074 loss)
I0526 11:51:35.488239 26867 sgd_solver.cpp:106] Iteration 621000, lr = 0.005
I0526 11:51:52.262959 26867 solver.cpp:237] Iteration 622500, loss = 0.630624
I0526 11:51:52.262997 26867 solver.cpp:253]     Train net output #0: loss = 0.630626 (* 1 = 0.630626 loss)
I0526 11:51:52.263016 26867 sgd_solver.cpp:106] Iteration 622500, lr = 0.005
I0526 11:52:09.142537 26867 solver.cpp:237] Iteration 624000, loss = 1.43707
I0526 11:52:09.142704 26867 solver.cpp:253]     Train net output #0: loss = 1.43707 (* 1 = 1.43707 loss)
I0526 11:52:09.142721 26867 sgd_solver.cpp:106] Iteration 624000, lr = 0.005
I0526 11:52:26.127596 26867 solver.cpp:237] Iteration 625500, loss = 1.26346
I0526 11:52:26.127651 26867 solver.cpp:253]     Train net output #0: loss = 1.26346 (* 1 = 1.26346 loss)
I0526 11:52:26.127670 26867 sgd_solver.cpp:106] Iteration 625500, lr = 0.005
I0526 11:52:43.329306 26867 solver.cpp:237] Iteration 627000, loss = 1.34195
I0526 11:52:43.329469 26867 solver.cpp:253]     Train net output #0: loss = 1.34195 (* 1 = 1.34195 loss)
I0526 11:52:43.329486 26867 sgd_solver.cpp:106] Iteration 627000, lr = 0.005
I0526 11:53:00.208330 26867 solver.cpp:237] Iteration 628500, loss = 1.30984
I0526 11:53:00.208384 26867 solver.cpp:253]     Train net output #0: loss = 1.30984 (* 1 = 1.30984 loss)
I0526 11:53:00.208402 26867 sgd_solver.cpp:106] Iteration 628500, lr = 0.005
I0526 11:53:16.862902 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_630000.caffemodel
I0526 11:53:16.909343 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_630000.solverstate
I0526 11:53:16.935132 26867 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 11:54:37.269112 26867 solver.cpp:409]     Test net output #0: accuracy = 0.880107
I0526 11:54:37.269281 26867 solver.cpp:409]     Test net output #1: loss = 0.401074 (* 1 = 0.401074 loss)
I0526 11:54:58.151250 26867 solver.cpp:237] Iteration 630000, loss = 1.34799
I0526 11:54:58.151305 26867 solver.cpp:253]     Train net output #0: loss = 1.34799 (* 1 = 1.34799 loss)
I0526 11:54:58.151336 26867 sgd_solver.cpp:106] Iteration 630000, lr = 0.005
I0526 11:55:15.230111 26867 solver.cpp:237] Iteration 631500, loss = 1.40474
I0526 11:55:15.230269 26867 solver.cpp:253]     Train net output #0: loss = 1.40474 (* 1 = 1.40474 loss)
I0526 11:55:15.230285 26867 sgd_solver.cpp:106] Iteration 631500, lr = 0.005
I0526 11:55:32.212021 26867 solver.cpp:237] Iteration 633000, loss = 1.44012
I0526 11:55:32.212075 26867 solver.cpp:253]     Train net output #0: loss = 1.44012 (* 1 = 1.44012 loss)
I0526 11:55:32.212092 26867 sgd_solver.cpp:106] Iteration 633000, lr = 0.005
I0526 11:55:49.156790 26867 solver.cpp:237] Iteration 634500, loss = 1.66403
I0526 11:55:49.156960 26867 solver.cpp:253]     Train net output #0: loss = 1.66403 (* 1 = 1.66403 loss)
I0526 11:55:49.156977 26867 sgd_solver.cpp:106] Iteration 634500, lr = 0.005
I0526 11:56:05.996126 26867 solver.cpp:237] Iteration 636000, loss = 1.00341
I0526 11:56:05.996167 26867 solver.cpp:253]     Train net output #0: loss = 1.00341 (* 1 = 1.00341 loss)
I0526 11:56:05.996184 26867 sgd_solver.cpp:106] Iteration 636000, lr = 0.005
I0526 11:56:22.900202 26867 solver.cpp:237] Iteration 637500, loss = 1.14557
I0526 11:56:22.900364 26867 solver.cpp:253]     Train net output #0: loss = 1.14557 (* 1 = 1.14557 loss)
I0526 11:56:22.900382 26867 sgd_solver.cpp:106] Iteration 637500, lr = 0.005
I0526 11:56:39.798250 26867 solver.cpp:237] Iteration 639000, loss = 1.28354
I0526 11:56:39.798300 26867 solver.cpp:253]     Train net output #0: loss = 1.28354 (* 1 = 1.28354 loss)
I0526 11:56:39.798318 26867 sgd_solver.cpp:106] Iteration 639000, lr = 0.005
I0526 11:57:17.599315 26867 solver.cpp:237] Iteration 640500, loss = 1.20059
I0526 11:57:17.599491 26867 solver.cpp:253]     Train net output #0: loss = 1.20059 (* 1 = 1.20059 loss)
I0526 11:57:17.599509 26867 sgd_solver.cpp:106] Iteration 640500, lr = 0.005
I0526 11:57:34.517655 26867 solver.cpp:237] Iteration 642000, loss = 0.915045
I0526 11:57:34.517710 26867 solver.cpp:253]     Train net output #0: loss = 0.915046 (* 1 = 0.915046 loss)
I0526 11:57:34.517727 26867 sgd_solver.cpp:106] Iteration 642000, lr = 0.005
I0526 11:57:51.449609 26867 solver.cpp:237] Iteration 643500, loss = 1.25505
I0526 11:57:51.449777 26867 solver.cpp:253]     Train net output #0: loss = 1.25505 (* 1 = 1.25505 loss)
I0526 11:57:51.449795 26867 sgd_solver.cpp:106] Iteration 643500, lr = 0.005
I0526 11:58:08.234562 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_645000.caffemodel
I0526 11:58:08.280071 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_645000.solverstate
I0526 11:58:08.308990 26867 solver.cpp:237] Iteration 645000, loss = 0.838956
I0526 11:58:08.309046 26867 solver.cpp:253]     Train net output #0: loss = 0.838956 (* 1 = 0.838956 loss)
I0526 11:58:08.309067 26867 sgd_solver.cpp:106] Iteration 645000, lr = 0.005
I0526 11:58:24.997928 26867 solver.cpp:237] Iteration 646500, loss = 0.943895
I0526 11:58:24.998116 26867 solver.cpp:253]     Train net output #0: loss = 0.943895 (* 1 = 0.943895 loss)
I0526 11:58:24.998133 26867 sgd_solver.cpp:106] Iteration 646500, lr = 0.005
I0526 11:58:41.646380 26867 solver.cpp:237] Iteration 648000, loss = 1.0736
I0526 11:58:41.646435 26867 solver.cpp:253]     Train net output #0: loss = 1.0736 (* 1 = 1.0736 loss)
I0526 11:58:41.646461 26867 sgd_solver.cpp:106] Iteration 648000, lr = 0.005
I0526 11:58:58.633484 26867 solver.cpp:237] Iteration 649500, loss = 1.01104
I0526 11:58:58.633642 26867 solver.cpp:253]     Train net output #0: loss = 1.01103 (* 1 = 1.01103 loss)
I0526 11:58:58.633659 26867 sgd_solver.cpp:106] Iteration 649500, lr = 0.005
I0526 11:59:36.442144 26867 solver.cpp:237] Iteration 651000, loss = 1.02159
I0526 11:59:36.442323 26867 solver.cpp:253]     Train net output #0: loss = 1.02159 (* 1 = 1.02159 loss)
I0526 11:59:36.442342 26867 sgd_solver.cpp:106] Iteration 651000, lr = 0.005
I0526 11:59:53.365814 26867 solver.cpp:237] Iteration 652500, loss = 0.991973
I0526 11:59:53.365855 26867 solver.cpp:253]     Train net output #0: loss = 0.991973 (* 1 = 0.991973 loss)
I0526 11:59:53.365872 26867 sgd_solver.cpp:106] Iteration 652500, lr = 0.005
I0526 12:00:09.999794 26867 solver.cpp:237] Iteration 654000, loss = 1.51108
I0526 12:00:09.999963 26867 solver.cpp:253]     Train net output #0: loss = 1.51108 (* 1 = 1.51108 loss)
I0526 12:00:09.999981 26867 sgd_solver.cpp:106] Iteration 654000, lr = 0.005
I0526 12:00:26.808109 26867 solver.cpp:237] Iteration 655500, loss = 0.777971
I0526 12:00:26.808161 26867 solver.cpp:253]     Train net output #0: loss = 0.77797 (* 1 = 0.77797 loss)
I0526 12:00:26.808187 26867 sgd_solver.cpp:106] Iteration 655500, lr = 0.005
I0526 12:00:43.850320 26867 solver.cpp:237] Iteration 657000, loss = 1.34201
I0526 12:00:43.850476 26867 solver.cpp:253]     Train net output #0: loss = 1.34201 (* 1 = 1.34201 loss)
I0526 12:00:43.850492 26867 sgd_solver.cpp:106] Iteration 657000, lr = 0.005
I0526 12:01:00.527942 26867 solver.cpp:237] Iteration 658500, loss = 1.09886
I0526 12:01:00.527990 26867 solver.cpp:253]     Train net output #0: loss = 1.09886 (* 1 = 1.09886 loss)
I0526 12:01:00.528007 26867 sgd_solver.cpp:106] Iteration 658500, lr = 0.005
I0526 12:01:17.249423 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_660000.caffemodel
I0526 12:01:17.295382 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_660000.solverstate
I0526 12:01:17.321094 26867 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 12:02:16.755378 26867 solver.cpp:409]     Test net output #0: accuracy = 0.881653
I0526 12:02:16.755547 26867 solver.cpp:409]     Test net output #1: loss = 0.384818 (* 1 = 0.384818 loss)
I0526 12:02:37.647876 26867 solver.cpp:237] Iteration 660000, loss = 1.01565
I0526 12:02:37.647941 26867 solver.cpp:253]     Train net output #0: loss = 1.01565 (* 1 = 1.01565 loss)
I0526 12:02:37.647960 26867 sgd_solver.cpp:106] Iteration 660000, lr = 0.005
I0526 12:02:54.544594 26867 solver.cpp:237] Iteration 661500, loss = 0.824925
I0526 12:02:54.544770 26867 solver.cpp:253]     Train net output #0: loss = 0.824925 (* 1 = 0.824925 loss)
I0526 12:02:54.544788 26867 sgd_solver.cpp:106] Iteration 661500, lr = 0.005
I0526 12:03:11.783645 26867 solver.cpp:237] Iteration 663000, loss = 0.954806
I0526 12:03:11.783686 26867 solver.cpp:253]     Train net output #0: loss = 0.954806 (* 1 = 0.954806 loss)
I0526 12:03:11.783704 26867 sgd_solver.cpp:106] Iteration 663000, lr = 0.005
I0526 12:03:28.545658 26867 solver.cpp:237] Iteration 664500, loss = 1.20315
I0526 12:03:28.545836 26867 solver.cpp:253]     Train net output #0: loss = 1.20315 (* 1 = 1.20315 loss)
I0526 12:03:28.545853 26867 sgd_solver.cpp:106] Iteration 664500, lr = 0.005
I0526 12:03:45.167376 26867 solver.cpp:237] Iteration 666000, loss = 0.762496
I0526 12:03:45.167428 26867 solver.cpp:253]     Train net output #0: loss = 0.762497 (* 1 = 0.762497 loss)
I0526 12:03:45.167448 26867 sgd_solver.cpp:106] Iteration 666000, lr = 0.005
I0526 12:04:01.795377 26867 solver.cpp:237] Iteration 667500, loss = 1.02566
I0526 12:04:01.795549 26867 solver.cpp:253]     Train net output #0: loss = 1.02566 (* 1 = 1.02566 loss)
I0526 12:04:01.795567 26867 sgd_solver.cpp:106] Iteration 667500, lr = 0.005
I0526 12:04:18.601785 26867 solver.cpp:237] Iteration 669000, loss = 1.18607
I0526 12:04:18.601840 26867 solver.cpp:253]     Train net output #0: loss = 1.18607 (* 1 = 1.18607 loss)
I0526 12:04:18.601857 26867 sgd_solver.cpp:106] Iteration 669000, lr = 0.005
I0526 12:04:56.441529 26867 solver.cpp:237] Iteration 670500, loss = 1.50629
I0526 12:04:56.441707 26867 solver.cpp:253]     Train net output #0: loss = 1.50629 (* 1 = 1.50629 loss)
I0526 12:04:56.441727 26867 sgd_solver.cpp:106] Iteration 670500, lr = 0.005
I0526 12:05:13.326493 26867 solver.cpp:237] Iteration 672000, loss = 0.926148
I0526 12:05:13.326532 26867 solver.cpp:253]     Train net output #0: loss = 0.92615 (* 1 = 0.92615 loss)
I0526 12:05:13.326550 26867 sgd_solver.cpp:106] Iteration 672000, lr = 0.005
I0526 12:05:30.117503 26867 solver.cpp:237] Iteration 673500, loss = 0.853536
I0526 12:05:30.117669 26867 solver.cpp:253]     Train net output #0: loss = 0.853537 (* 1 = 0.853537 loss)
I0526 12:05:30.117687 26867 sgd_solver.cpp:106] Iteration 673500, lr = 0.005
I0526 12:05:46.908902 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_675000.caffemodel
I0526 12:05:46.965025 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_675000.solverstate
I0526 12:05:46.997400 26867 solver.cpp:237] Iteration 675000, loss = 1.44136
I0526 12:05:46.997462 26867 solver.cpp:253]     Train net output #0: loss = 1.44136 (* 1 = 1.44136 loss)
I0526 12:05:46.997478 26867 sgd_solver.cpp:106] Iteration 675000, lr = 0.005
I0526 12:06:03.851847 26867 solver.cpp:237] Iteration 676500, loss = 1.50501
I0526 12:06:03.852008 26867 solver.cpp:253]     Train net output #0: loss = 1.50502 (* 1 = 1.50502 loss)
I0526 12:06:03.852025 26867 sgd_solver.cpp:106] Iteration 676500, lr = 0.005
I0526 12:06:20.685096 26867 solver.cpp:237] Iteration 678000, loss = 1.30931
I0526 12:06:20.685148 26867 solver.cpp:253]     Train net output #0: loss = 1.30931 (* 1 = 1.30931 loss)
I0526 12:06:20.685168 26867 sgd_solver.cpp:106] Iteration 678000, lr = 0.005
I0526 12:06:37.499691 26867 solver.cpp:237] Iteration 679500, loss = 0.907504
I0526 12:06:37.499866 26867 solver.cpp:253]     Train net output #0: loss = 0.907507 (* 1 = 0.907507 loss)
I0526 12:06:37.499884 26867 sgd_solver.cpp:106] Iteration 679500, lr = 0.005
I0526 12:07:15.416252 26867 solver.cpp:237] Iteration 681000, loss = 0.434628
I0526 12:07:15.416432 26867 solver.cpp:253]     Train net output #0: loss = 0.434631 (* 1 = 0.434631 loss)
I0526 12:07:15.416450 26867 sgd_solver.cpp:106] Iteration 681000, lr = 0.005
I0526 12:07:32.467509 26867 solver.cpp:237] Iteration 682500, loss = 0.535273
I0526 12:07:32.467561 26867 solver.cpp:253]     Train net output #0: loss = 0.535275 (* 1 = 0.535275 loss)
I0526 12:07:32.467579 26867 sgd_solver.cpp:106] Iteration 682500, lr = 0.005
I0526 12:07:49.429877 26867 solver.cpp:237] Iteration 684000, loss = 1.53119
I0526 12:07:49.430063 26867 solver.cpp:253]     Train net output #0: loss = 1.5312 (* 1 = 1.5312 loss)
I0526 12:07:49.430079 26867 sgd_solver.cpp:106] Iteration 684000, lr = 0.005
I0526 12:08:06.635232 26867 solver.cpp:237] Iteration 685500, loss = 1.09206
I0526 12:08:06.635282 26867 solver.cpp:253]     Train net output #0: loss = 1.09207 (* 1 = 1.09207 loss)
I0526 12:08:06.635301 26867 sgd_solver.cpp:106] Iteration 685500, lr = 0.005
I0526 12:08:23.699290 26867 solver.cpp:237] Iteration 687000, loss = 0.930413
I0526 12:08:23.699465 26867 solver.cpp:253]     Train net output #0: loss = 0.930416 (* 1 = 0.930416 loss)
I0526 12:08:23.699482 26867 sgd_solver.cpp:106] Iteration 687000, lr = 0.005
I0526 12:08:40.652590 26867 solver.cpp:237] Iteration 688500, loss = 0.696889
I0526 12:08:40.652643 26867 solver.cpp:253]     Train net output #0: loss = 0.696892 (* 1 = 0.696892 loss)
I0526 12:08:40.652669 26867 sgd_solver.cpp:106] Iteration 688500, lr = 0.005
I0526 12:08:57.545742 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_690000.caffemodel
I0526 12:08:57.591500 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_690000.solverstate
I0526 12:08:57.617563 26867 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 12:10:17.963197 26867 solver.cpp:409]     Test net output #0: accuracy = 0.882855
I0526 12:10:17.963372 26867 solver.cpp:409]     Test net output #1: loss = 0.411068 (* 1 = 0.411068 loss)
I0526 12:10:38.853173 26867 solver.cpp:237] Iteration 690000, loss = 1.32836
I0526 12:10:38.853232 26867 solver.cpp:253]     Train net output #0: loss = 1.32837 (* 1 = 1.32837 loss)
I0526 12:10:38.853253 26867 sgd_solver.cpp:106] Iteration 690000, lr = 0.005
I0526 12:10:55.894795 26867 solver.cpp:237] Iteration 691500, loss = 0.704687
I0526 12:10:55.894971 26867 solver.cpp:253]     Train net output #0: loss = 0.70469 (* 1 = 0.70469 loss)
I0526 12:10:55.894989 26867 sgd_solver.cpp:106] Iteration 691500, lr = 0.005
I0526 12:11:13.098439 26867 solver.cpp:237] Iteration 693000, loss = 1.49675
I0526 12:11:13.098489 26867 solver.cpp:253]     Train net output #0: loss = 1.49675 (* 1 = 1.49675 loss)
I0526 12:11:13.098513 26867 sgd_solver.cpp:106] Iteration 693000, lr = 0.005
I0526 12:11:30.167122 26867 solver.cpp:237] Iteration 694500, loss = 1.17875
I0526 12:11:30.167280 26867 solver.cpp:253]     Train net output #0: loss = 1.17875 (* 1 = 1.17875 loss)
I0526 12:11:30.167297 26867 sgd_solver.cpp:106] Iteration 694500, lr = 0.005
I0526 12:11:47.104953 26867 solver.cpp:237] Iteration 696000, loss = 0.519259
I0526 12:11:47.105005 26867 solver.cpp:253]     Train net output #0: loss = 0.519262 (* 1 = 0.519262 loss)
I0526 12:11:47.105021 26867 sgd_solver.cpp:106] Iteration 696000, lr = 0.005
I0526 12:12:03.917759 26867 solver.cpp:237] Iteration 697500, loss = 1.00418
I0526 12:12:03.917932 26867 solver.cpp:253]     Train net output #0: loss = 1.00418 (* 1 = 1.00418 loss)
I0526 12:12:03.917950 26867 sgd_solver.cpp:106] Iteration 697500, lr = 0.005
I0526 12:12:20.695513 26867 solver.cpp:237] Iteration 699000, loss = 1.1314
I0526 12:12:20.695552 26867 solver.cpp:253]     Train net output #0: loss = 1.1314 (* 1 = 1.1314 loss)
I0526 12:12:20.695569 26867 sgd_solver.cpp:106] Iteration 699000, lr = 0.005
I0526 12:12:58.434749 26867 solver.cpp:237] Iteration 700500, loss = 1.02403
I0526 12:12:58.434926 26867 solver.cpp:253]     Train net output #0: loss = 1.02403 (* 1 = 1.02403 loss)
I0526 12:12:58.434943 26867 sgd_solver.cpp:106] Iteration 700500, lr = 0.005
I0526 12:13:15.268442 26867 solver.cpp:237] Iteration 702000, loss = 1.15134
I0526 12:13:15.268497 26867 solver.cpp:253]     Train net output #0: loss = 1.15134 (* 1 = 1.15134 loss)
I0526 12:13:15.268514 26867 sgd_solver.cpp:106] Iteration 702000, lr = 0.005
I0526 12:13:31.905323 26867 solver.cpp:237] Iteration 703500, loss = 1.41704
I0526 12:13:31.905495 26867 solver.cpp:253]     Train net output #0: loss = 1.41704 (* 1 = 1.41704 loss)
I0526 12:13:31.905513 26867 sgd_solver.cpp:106] Iteration 703500, lr = 0.005
I0526 12:13:48.528838 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_705000.caffemodel
I0526 12:13:48.574538 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_705000.solverstate
I0526 12:13:48.603277 26867 solver.cpp:237] Iteration 705000, loss = 0.997908
I0526 12:13:48.603333 26867 solver.cpp:253]     Train net output #0: loss = 0.99791 (* 1 = 0.99791 loss)
I0526 12:13:48.603353 26867 sgd_solver.cpp:106] Iteration 705000, lr = 0.005
I0526 12:14:05.224014 26867 solver.cpp:237] Iteration 706500, loss = 1.2641
I0526 12:14:05.224189 26867 solver.cpp:253]     Train net output #0: loss = 1.2641 (* 1 = 1.2641 loss)
I0526 12:14:05.224208 26867 sgd_solver.cpp:106] Iteration 706500, lr = 0.005
I0526 12:14:22.458241 26867 solver.cpp:237] Iteration 708000, loss = 1.34471
I0526 12:14:22.458281 26867 solver.cpp:253]     Train net output #0: loss = 1.34471 (* 1 = 1.34471 loss)
I0526 12:14:22.458300 26867 sgd_solver.cpp:106] Iteration 708000, lr = 0.005
I0526 12:14:39.381294 26867 solver.cpp:237] Iteration 709500, loss = 1.08883
I0526 12:14:39.381464 26867 solver.cpp:253]     Train net output #0: loss = 1.08884 (* 1 = 1.08884 loss)
I0526 12:14:39.381481 26867 sgd_solver.cpp:106] Iteration 709500, lr = 0.005
I0526 12:15:17.096529 26867 solver.cpp:237] Iteration 711000, loss = 1.12521
I0526 12:15:17.096709 26867 solver.cpp:253]     Train net output #0: loss = 1.12521 (* 1 = 1.12521 loss)
I0526 12:15:17.096726 26867 sgd_solver.cpp:106] Iteration 711000, lr = 0.005
I0526 12:15:34.095665 26867 solver.cpp:237] Iteration 712500, loss = 2.17456
I0526 12:15:34.095716 26867 solver.cpp:253]     Train net output #0: loss = 2.17456 (* 1 = 2.17456 loss)
I0526 12:15:34.095736 26867 sgd_solver.cpp:106] Iteration 712500, lr = 0.005
I0526 12:15:51.195669 26867 solver.cpp:237] Iteration 714000, loss = 1.15999
I0526 12:15:51.195845 26867 solver.cpp:253]     Train net output #0: loss = 1.15999 (* 1 = 1.15999 loss)
I0526 12:15:51.195863 26867 sgd_solver.cpp:106] Iteration 714000, lr = 0.005
I0526 12:16:08.398949 26867 solver.cpp:237] Iteration 715500, loss = 1.07869
I0526 12:16:08.398988 26867 solver.cpp:253]     Train net output #0: loss = 1.0787 (* 1 = 1.0787 loss)
I0526 12:16:08.399006 26867 sgd_solver.cpp:106] Iteration 715500, lr = 0.005
I0526 12:16:25.255465 26867 solver.cpp:237] Iteration 717000, loss = 0.975541
I0526 12:16:25.255635 26867 solver.cpp:253]     Train net output #0: loss = 0.975543 (* 1 = 0.975543 loss)
I0526 12:16:25.255653 26867 sgd_solver.cpp:106] Iteration 717000, lr = 0.005
I0526 12:16:41.979223 26867 solver.cpp:237] Iteration 718500, loss = 1.16722
I0526 12:16:41.979274 26867 solver.cpp:253]     Train net output #0: loss = 1.16723 (* 1 = 1.16723 loss)
I0526 12:16:41.979292 26867 sgd_solver.cpp:106] Iteration 718500, lr = 0.005
I0526 12:16:58.603842 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_720000.caffemodel
I0526 12:16:58.650846 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_720000.solverstate
I0526 12:16:58.676298 26867 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 12:17:58.469631 26867 solver.cpp:409]     Test net output #0: accuracy = 0.877438
I0526 12:17:58.469805 26867 solver.cpp:409]     Test net output #1: loss = 0.395263 (* 1 = 0.395263 loss)
I0526 12:18:19.377941 26867 solver.cpp:237] Iteration 720000, loss = 1.42733
I0526 12:18:19.378007 26867 solver.cpp:253]     Train net output #0: loss = 1.42733 (* 1 = 1.42733 loss)
I0526 12:18:19.378026 26867 sgd_solver.cpp:106] Iteration 720000, lr = 0.005
I0526 12:18:36.164855 26867 solver.cpp:237] Iteration 721500, loss = 1.37988
I0526 12:18:36.165033 26867 solver.cpp:253]     Train net output #0: loss = 1.37988 (* 1 = 1.37988 loss)
I0526 12:18:36.165050 26867 sgd_solver.cpp:106] Iteration 721500, lr = 0.005
I0526 12:18:52.822590 26867 solver.cpp:237] Iteration 723000, loss = 1.03771
I0526 12:18:52.822641 26867 solver.cpp:253]     Train net output #0: loss = 1.03771 (* 1 = 1.03771 loss)
I0526 12:18:52.822661 26867 sgd_solver.cpp:106] Iteration 723000, lr = 0.005
I0526 12:19:09.556149 26867 solver.cpp:237] Iteration 724500, loss = 0.800042
I0526 12:19:09.556330 26867 solver.cpp:253]     Train net output #0: loss = 0.800043 (* 1 = 0.800043 loss)
I0526 12:19:09.556347 26867 sgd_solver.cpp:106] Iteration 724500, lr = 0.005
I0526 12:19:26.540210 26867 solver.cpp:237] Iteration 726000, loss = 1.4505
I0526 12:19:26.540247 26867 solver.cpp:253]     Train net output #0: loss = 1.4505 (* 1 = 1.4505 loss)
I0526 12:19:26.540271 26867 sgd_solver.cpp:106] Iteration 726000, lr = 0.005
I0526 12:19:43.607513 26867 solver.cpp:237] Iteration 727500, loss = 1.56471
I0526 12:19:43.607698 26867 solver.cpp:253]     Train net output #0: loss = 1.56471 (* 1 = 1.56471 loss)
I0526 12:19:43.607717 26867 sgd_solver.cpp:106] Iteration 727500, lr = 0.005
I0526 12:20:00.698904 26867 solver.cpp:237] Iteration 729000, loss = 1.45421
I0526 12:20:00.698954 26867 solver.cpp:253]     Train net output #0: loss = 1.45421 (* 1 = 1.45421 loss)
I0526 12:20:00.698974 26867 sgd_solver.cpp:106] Iteration 729000, lr = 0.005
I0526 12:20:38.792212 26867 solver.cpp:237] Iteration 730500, loss = 1.35841
I0526 12:20:38.792395 26867 solver.cpp:253]     Train net output #0: loss = 1.35841 (* 1 = 1.35841 loss)
I0526 12:20:38.792413 26867 sgd_solver.cpp:106] Iteration 730500, lr = 0.005
I0526 12:20:55.908336 26867 solver.cpp:237] Iteration 732000, loss = 0.790944
I0526 12:20:55.908388 26867 solver.cpp:253]     Train net output #0: loss = 0.790944 (* 1 = 0.790944 loss)
I0526 12:20:55.908406 26867 sgd_solver.cpp:106] Iteration 732000, lr = 0.005
I0526 12:21:12.954562 26867 solver.cpp:237] Iteration 733500, loss = 0.858207
I0526 12:21:12.954737 26867 solver.cpp:253]     Train net output #0: loss = 0.858207 (* 1 = 0.858207 loss)
I0526 12:21:12.954756 26867 sgd_solver.cpp:106] Iteration 733500, lr = 0.005
I0526 12:21:29.721814 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_735000.caffemodel
I0526 12:21:29.769433 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_735000.solverstate
I0526 12:21:29.800014 26867 solver.cpp:237] Iteration 735000, loss = 1.26252
I0526 12:21:29.800071 26867 solver.cpp:253]     Train net output #0: loss = 1.26252 (* 1 = 1.26252 loss)
I0526 12:21:29.800089 26867 sgd_solver.cpp:106] Iteration 735000, lr = 0.005
I0526 12:21:46.780230 26867 solver.cpp:237] Iteration 736500, loss = 1.04987
I0526 12:21:46.780406 26867 solver.cpp:253]     Train net output #0: loss = 1.04987 (* 1 = 1.04987 loss)
I0526 12:21:46.780424 26867 sgd_solver.cpp:106] Iteration 736500, lr = 0.005
I0526 12:22:03.752909 26867 solver.cpp:237] Iteration 738000, loss = 1.55948
I0526 12:22:03.752962 26867 solver.cpp:253]     Train net output #0: loss = 1.55949 (* 1 = 1.55949 loss)
I0526 12:22:03.752982 26867 sgd_solver.cpp:106] Iteration 738000, lr = 0.005
I0526 12:22:20.362776 26867 solver.cpp:237] Iteration 739500, loss = 2.02344
I0526 12:22:20.362938 26867 solver.cpp:253]     Train net output #0: loss = 2.02344 (* 1 = 2.02344 loss)
I0526 12:22:20.362957 26867 sgd_solver.cpp:106] Iteration 739500, lr = 0.005
I0526 12:22:58.075268 26867 solver.cpp:237] Iteration 741000, loss = 1.19734
I0526 12:22:58.075461 26867 solver.cpp:253]     Train net output #0: loss = 1.19734 (* 1 = 1.19734 loss)
I0526 12:22:58.075479 26867 sgd_solver.cpp:106] Iteration 741000, lr = 0.005
I0526 12:23:14.867130 26867 solver.cpp:237] Iteration 742500, loss = 1.88811
I0526 12:23:14.867168 26867 solver.cpp:253]     Train net output #0: loss = 1.88811 (* 1 = 1.88811 loss)
I0526 12:23:14.867187 26867 sgd_solver.cpp:106] Iteration 742500, lr = 0.005
I0526 12:23:31.847514 26867 solver.cpp:237] Iteration 744000, loss = 1.96998
I0526 12:23:31.847702 26867 solver.cpp:253]     Train net output #0: loss = 1.96998 (* 1 = 1.96998 loss)
I0526 12:23:31.847718 26867 sgd_solver.cpp:106] Iteration 744000, lr = 0.005
I0526 12:23:48.910017 26867 solver.cpp:237] Iteration 745500, loss = 1.12699
I0526 12:23:48.910069 26867 solver.cpp:253]     Train net output #0: loss = 1.12699 (* 1 = 1.12699 loss)
I0526 12:23:48.910089 26867 sgd_solver.cpp:106] Iteration 745500, lr = 0.005
I0526 12:24:06.109395 26867 solver.cpp:237] Iteration 747000, loss = 1.66457
I0526 12:24:06.109570 26867 solver.cpp:253]     Train net output #0: loss = 1.66457 (* 1 = 1.66457 loss)
I0526 12:24:06.109588 26867 sgd_solver.cpp:106] Iteration 747000, lr = 0.005
I0526 12:24:22.909608 26867 solver.cpp:237] Iteration 748500, loss = 1.14315
I0526 12:24:22.909646 26867 solver.cpp:253]     Train net output #0: loss = 1.14315 (* 1 = 1.14315 loss)
I0526 12:24:22.909665 26867 sgd_solver.cpp:106] Iteration 748500, lr = 0.005
I0526 12:24:39.600088 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_750000.caffemodel
I0526 12:24:39.647063 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_750000.solverstate
I0526 12:24:39.675845 26867 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 12:26:00.249167 26867 solver.cpp:409]     Test net output #0: accuracy = 0.883673
I0526 12:26:00.249359 26867 solver.cpp:409]     Test net output #1: loss = 0.367138 (* 1 = 0.367138 loss)
I0526 12:26:21.181058 26867 solver.cpp:237] Iteration 750000, loss = 0.830183
I0526 12:26:21.181119 26867 solver.cpp:253]     Train net output #0: loss = 0.830184 (* 1 = 0.830184 loss)
I0526 12:26:21.181149 26867 sgd_solver.cpp:106] Iteration 750000, lr = 0.005
I0526 12:26:38.231128 26867 solver.cpp:237] Iteration 751500, loss = 1.42706
I0526 12:26:38.231310 26867 solver.cpp:253]     Train net output #0: loss = 1.42706 (* 1 = 1.42706 loss)
I0526 12:26:38.231328 26867 sgd_solver.cpp:106] Iteration 751500, lr = 0.005
I0526 12:26:55.211958 26867 solver.cpp:237] Iteration 753000, loss = 0.937401
I0526 12:26:55.212002 26867 solver.cpp:253]     Train net output #0: loss = 0.937402 (* 1 = 0.937402 loss)
I0526 12:26:55.212019 26867 sgd_solver.cpp:106] Iteration 753000, lr = 0.005
I0526 12:27:12.062655 26867 solver.cpp:237] Iteration 754500, loss = 1.45489
I0526 12:27:12.062830 26867 solver.cpp:253]     Train net output #0: loss = 1.45489 (* 1 = 1.45489 loss)
I0526 12:27:12.062849 26867 sgd_solver.cpp:106] Iteration 754500, lr = 0.005
I0526 12:27:28.822286 26867 solver.cpp:237] Iteration 756000, loss = 1.30598
I0526 12:27:28.822340 26867 solver.cpp:253]     Train net output #0: loss = 1.30599 (* 1 = 1.30599 loss)
I0526 12:27:28.822365 26867 sgd_solver.cpp:106] Iteration 756000, lr = 0.005
I0526 12:27:45.450390 26867 solver.cpp:237] Iteration 757500, loss = 1.43354
I0526 12:27:45.450553 26867 solver.cpp:253]     Train net output #0: loss = 1.43354 (* 1 = 1.43354 loss)
I0526 12:27:45.450569 26867 sgd_solver.cpp:106] Iteration 757500, lr = 0.005
I0526 12:28:02.405851 26867 solver.cpp:237] Iteration 759000, loss = 1.2472
I0526 12:28:02.405905 26867 solver.cpp:253]     Train net output #0: loss = 1.2472 (* 1 = 1.2472 loss)
I0526 12:28:02.405923 26867 sgd_solver.cpp:106] Iteration 759000, lr = 0.005
I0526 12:28:40.326105 26867 solver.cpp:237] Iteration 760500, loss = 1.24458
I0526 12:28:40.326300 26867 solver.cpp:253]     Train net output #0: loss = 1.24458 (* 1 = 1.24458 loss)
I0526 12:28:40.326320 26867 sgd_solver.cpp:106] Iteration 760500, lr = 0.005
I0526 12:28:57.111598 26867 solver.cpp:237] Iteration 762000, loss = 1.83612
I0526 12:28:57.111639 26867 solver.cpp:253]     Train net output #0: loss = 1.83612 (* 1 = 1.83612 loss)
I0526 12:28:57.111656 26867 sgd_solver.cpp:106] Iteration 762000, lr = 0.005
I0526 12:29:14.086699 26867 solver.cpp:237] Iteration 763500, loss = 1.09136
I0526 12:29:14.086879 26867 solver.cpp:253]     Train net output #0: loss = 1.09136 (* 1 = 1.09136 loss)
I0526 12:29:14.086897 26867 sgd_solver.cpp:106] Iteration 763500, lr = 0.005
I0526 12:29:31.137420 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_765000.caffemodel
I0526 12:29:31.184129 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_765000.solverstate
I0526 12:29:31.213598 26867 solver.cpp:237] Iteration 765000, loss = 0.45965
I0526 12:29:31.213654 26867 solver.cpp:253]     Train net output #0: loss = 0.459652 (* 1 = 0.459652 loss)
I0526 12:29:31.213673 26867 sgd_solver.cpp:106] Iteration 765000, lr = 0.005
I0526 12:29:47.979092 26867 solver.cpp:237] Iteration 766500, loss = 0.840774
I0526 12:29:47.979259 26867 solver.cpp:253]     Train net output #0: loss = 0.840776 (* 1 = 0.840776 loss)
I0526 12:29:47.979276 26867 sgd_solver.cpp:106] Iteration 766500, lr = 0.005
I0526 12:30:04.880136 26867 solver.cpp:237] Iteration 768000, loss = 0.530534
I0526 12:30:04.880192 26867 solver.cpp:253]     Train net output #0: loss = 0.530536 (* 1 = 0.530536 loss)
I0526 12:30:04.880209 26867 sgd_solver.cpp:106] Iteration 768000, lr = 0.005
I0526 12:30:21.814911 26867 solver.cpp:237] Iteration 769500, loss = 1.23248
I0526 12:30:21.815089 26867 solver.cpp:253]     Train net output #0: loss = 1.23248 (* 1 = 1.23248 loss)
I0526 12:30:21.815106 26867 sgd_solver.cpp:106] Iteration 769500, lr = 0.005
I0526 12:30:59.489284 26867 solver.cpp:237] Iteration 771000, loss = 1.11523
I0526 12:30:59.489465 26867 solver.cpp:253]     Train net output #0: loss = 1.11523 (* 1 = 1.11523 loss)
I0526 12:30:59.489482 26867 sgd_solver.cpp:106] Iteration 771000, lr = 0.005
I0526 12:31:16.454807 26867 solver.cpp:237] Iteration 772500, loss = 1.01027
I0526 12:31:16.454861 26867 solver.cpp:253]     Train net output #0: loss = 1.01027 (* 1 = 1.01027 loss)
I0526 12:31:16.454886 26867 sgd_solver.cpp:106] Iteration 772500, lr = 0.005
I0526 12:31:33.482410 26867 solver.cpp:237] Iteration 774000, loss = 1.20746
I0526 12:31:33.482584 26867 solver.cpp:253]     Train net output #0: loss = 1.20746 (* 1 = 1.20746 loss)
I0526 12:31:33.482601 26867 sgd_solver.cpp:106] Iteration 774000, lr = 0.005
I0526 12:31:50.433356 26867 solver.cpp:237] Iteration 775500, loss = 1.3428
I0526 12:31:50.433408 26867 solver.cpp:253]     Train net output #0: loss = 1.3428 (* 1 = 1.3428 loss)
I0526 12:31:50.433425 26867 sgd_solver.cpp:106] Iteration 775500, lr = 0.005
I0526 12:32:07.253726 26867 solver.cpp:237] Iteration 777000, loss = 1.0319
I0526 12:32:07.253916 26867 solver.cpp:253]     Train net output #0: loss = 1.03191 (* 1 = 1.03191 loss)
I0526 12:32:07.253932 26867 sgd_solver.cpp:106] Iteration 777000, lr = 0.005
I0526 12:32:23.899144 26867 solver.cpp:237] Iteration 778500, loss = 1.4651
I0526 12:32:23.899181 26867 solver.cpp:253]     Train net output #0: loss = 1.4651 (* 1 = 1.4651 loss)
I0526 12:32:23.899205 26867 sgd_solver.cpp:106] Iteration 778500, lr = 0.005
I0526 12:32:40.819448 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_780000.caffemodel
I0526 12:32:40.865770 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_780000.solverstate
I0526 12:32:40.891405 26867 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 12:33:40.099719 26867 solver.cpp:409]     Test net output #0: accuracy = 0.876324
I0526 12:33:40.099898 26867 solver.cpp:409]     Test net output #1: loss = 0.403913 (* 1 = 0.403913 loss)
I0526 12:34:01.032730 26867 solver.cpp:237] Iteration 780000, loss = 1.18788
I0526 12:34:01.032791 26867 solver.cpp:253]     Train net output #0: loss = 1.18788 (* 1 = 1.18788 loss)
I0526 12:34:01.032811 26867 sgd_solver.cpp:106] Iteration 780000, lr = 0.005
I0526 12:34:18.080520 26867 solver.cpp:237] Iteration 781500, loss = 1.56852
I0526 12:34:18.080700 26867 solver.cpp:253]     Train net output #0: loss = 1.56852 (* 1 = 1.56852 loss)
I0526 12:34:18.080718 26867 sgd_solver.cpp:106] Iteration 781500, lr = 0.005
I0526 12:34:35.168284 26867 solver.cpp:237] Iteration 783000, loss = 1.08441
I0526 12:34:35.168336 26867 solver.cpp:253]     Train net output #0: loss = 1.08441 (* 1 = 1.08441 loss)
I0526 12:34:35.168354 26867 sgd_solver.cpp:106] Iteration 783000, lr = 0.005
I0526 12:34:51.948077 26867 solver.cpp:237] Iteration 784500, loss = 1.8418
I0526 12:34:51.948245 26867 solver.cpp:253]     Train net output #0: loss = 1.8418 (* 1 = 1.8418 loss)
I0526 12:34:51.948261 26867 sgd_solver.cpp:106] Iteration 784500, lr = 0.005
I0526 12:35:08.963376 26867 solver.cpp:237] Iteration 786000, loss = 1.06615
I0526 12:35:08.963425 26867 solver.cpp:253]     Train net output #0: loss = 1.06615 (* 1 = 1.06615 loss)
I0526 12:35:08.963444 26867 sgd_solver.cpp:106] Iteration 786000, lr = 0.005
I0526 12:35:25.859211 26867 solver.cpp:237] Iteration 787500, loss = 1.03958
I0526 12:35:25.859391 26867 solver.cpp:253]     Train net output #0: loss = 1.03958 (* 1 = 1.03958 loss)
I0526 12:35:25.859411 26867 sgd_solver.cpp:106] Iteration 787500, lr = 0.005
I0526 12:35:42.480948 26867 solver.cpp:237] Iteration 789000, loss = 1.32809
I0526 12:35:42.480988 26867 solver.cpp:253]     Train net output #0: loss = 1.32809 (* 1 = 1.32809 loss)
I0526 12:35:42.481006 26867 sgd_solver.cpp:106] Iteration 789000, lr = 0.005
I0526 12:36:20.004611 26867 solver.cpp:237] Iteration 790500, loss = 1.50185
I0526 12:36:20.004794 26867 solver.cpp:253]     Train net output #0: loss = 1.50185 (* 1 = 1.50185 loss)
I0526 12:36:20.004812 26867 sgd_solver.cpp:106] Iteration 790500, lr = 0.005
I0526 12:36:36.606039 26867 solver.cpp:237] Iteration 792000, loss = 0.86109
I0526 12:36:36.606096 26867 solver.cpp:253]     Train net output #0: loss = 0.86109 (* 1 = 0.86109 loss)
I0526 12:36:36.606123 26867 sgd_solver.cpp:106] Iteration 792000, lr = 0.005
I0526 12:36:53.207752 26867 solver.cpp:237] Iteration 793500, loss = 1.22382
I0526 12:36:53.207919 26867 solver.cpp:253]     Train net output #0: loss = 1.22382 (* 1 = 1.22382 loss)
I0526 12:36:53.207937 26867 sgd_solver.cpp:106] Iteration 793500, lr = 0.005
I0526 12:37:09.816288 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_795000.caffemodel
I0526 12:37:09.862006 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_795000.solverstate
I0526 12:37:09.890589 26867 solver.cpp:237] Iteration 795000, loss = 1.13305
I0526 12:37:09.890645 26867 solver.cpp:253]     Train net output #0: loss = 1.13305 (* 1 = 1.13305 loss)
I0526 12:37:09.890661 26867 sgd_solver.cpp:106] Iteration 795000, lr = 0.005
I0526 12:37:26.552934 26867 solver.cpp:237] Iteration 796500, loss = 1.76682
I0526 12:37:26.553118 26867 solver.cpp:253]     Train net output #0: loss = 1.76682 (* 1 = 1.76682 loss)
I0526 12:37:26.553138 26867 sgd_solver.cpp:106] Iteration 796500, lr = 0.005
I0526 12:37:43.761857 26867 solver.cpp:237] Iteration 798000, loss = 1.00456
I0526 12:37:43.761898 26867 solver.cpp:253]     Train net output #0: loss = 1.00456 (* 1 = 1.00456 loss)
I0526 12:37:43.761922 26867 sgd_solver.cpp:106] Iteration 798000, lr = 0.005
I0526 12:38:00.781895 26867 solver.cpp:237] Iteration 799500, loss = 1.12216
I0526 12:38:00.782097 26867 solver.cpp:253]     Train net output #0: loss = 1.12215 (* 1 = 1.12215 loss)
I0526 12:38:00.782115 26867 sgd_solver.cpp:106] Iteration 799500, lr = 0.005
I0526 12:38:38.422263 26867 solver.cpp:237] Iteration 801000, loss = 0.941327
I0526 12:38:38.422448 26867 solver.cpp:253]     Train net output #0: loss = 0.941327 (* 1 = 0.941327 loss)
I0526 12:38:38.422466 26867 sgd_solver.cpp:106] Iteration 801000, lr = 0.005
I0526 12:38:55.205109 26867 solver.cpp:237] Iteration 802500, loss = 0.768213
I0526 12:38:55.205163 26867 solver.cpp:253]     Train net output #0: loss = 0.768212 (* 1 = 0.768212 loss)
I0526 12:38:55.205180 26867 sgd_solver.cpp:106] Iteration 802500, lr = 0.005
I0526 12:39:11.955873 26867 solver.cpp:237] Iteration 804000, loss = 1.0851
I0526 12:39:11.956049 26867 solver.cpp:253]     Train net output #0: loss = 1.0851 (* 1 = 1.0851 loss)
I0526 12:39:11.956068 26867 sgd_solver.cpp:106] Iteration 804000, lr = 0.005
I0526 12:39:28.598563 26867 solver.cpp:237] Iteration 805500, loss = 1.03157
I0526 12:39:28.598601 26867 solver.cpp:253]     Train net output #0: loss = 1.03157 (* 1 = 1.03157 loss)
I0526 12:39:28.598620 26867 sgd_solver.cpp:106] Iteration 805500, lr = 0.005
I0526 12:39:45.364562 26867 solver.cpp:237] Iteration 807000, loss = 1.15679
I0526 12:39:45.364742 26867 solver.cpp:253]     Train net output #0: loss = 1.15679 (* 1 = 1.15679 loss)
I0526 12:39:45.364758 26867 sgd_solver.cpp:106] Iteration 807000, lr = 0.005
I0526 12:40:02.238173 26867 solver.cpp:237] Iteration 808500, loss = 1.33559
I0526 12:40:02.238224 26867 solver.cpp:253]     Train net output #0: loss = 1.33559 (* 1 = 1.33559 loss)
I0526 12:40:02.238243 26867 sgd_solver.cpp:106] Iteration 808500, lr = 0.005
I0526 12:40:19.204207 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_810000.caffemodel
I0526 12:40:19.250216 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_810000.solverstate
I0526 12:40:19.275820 26867 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 12:41:39.734012 26867 solver.cpp:409]     Test net output #0: accuracy = 0.876145
I0526 12:41:39.734197 26867 solver.cpp:409]     Test net output #1: loss = 0.412484 (* 1 = 0.412484 loss)
I0526 12:42:00.647300 26867 solver.cpp:237] Iteration 810000, loss = 1.16979
I0526 12:42:00.647361 26867 solver.cpp:253]     Train net output #0: loss = 1.16979 (* 1 = 1.16979 loss)
I0526 12:42:00.647380 26867 sgd_solver.cpp:106] Iteration 810000, lr = 0.005
I0526 12:42:17.693758 26867 solver.cpp:237] Iteration 811500, loss = 0.810023
I0526 12:42:17.693928 26867 solver.cpp:253]     Train net output #0: loss = 0.810024 (* 1 = 0.810024 loss)
I0526 12:42:17.693944 26867 sgd_solver.cpp:106] Iteration 811500, lr = 0.005
I0526 12:42:34.827971 26867 solver.cpp:237] Iteration 813000, loss = 0.917274
I0526 12:42:34.828022 26867 solver.cpp:253]     Train net output #0: loss = 0.917275 (* 1 = 0.917275 loss)
I0526 12:42:34.828040 26867 sgd_solver.cpp:106] Iteration 813000, lr = 0.005
I0526 12:42:51.936568 26867 solver.cpp:237] Iteration 814500, loss = 1.64543
I0526 12:42:51.936748 26867 solver.cpp:253]     Train net output #0: loss = 1.64543 (* 1 = 1.64543 loss)
I0526 12:42:51.936764 26867 sgd_solver.cpp:106] Iteration 814500, lr = 0.005
I0526 12:43:08.586244 26867 solver.cpp:237] Iteration 816000, loss = 1.69703
I0526 12:43:08.586283 26867 solver.cpp:253]     Train net output #0: loss = 1.69703 (* 1 = 1.69703 loss)
I0526 12:43:08.586302 26867 sgd_solver.cpp:106] Iteration 816000, lr = 0.005
I0526 12:43:25.197649 26867 solver.cpp:237] Iteration 817500, loss = 1.27997
I0526 12:43:25.197839 26867 solver.cpp:253]     Train net output #0: loss = 1.27997 (* 1 = 1.27997 loss)
I0526 12:43:25.197857 26867 sgd_solver.cpp:106] Iteration 817500, lr = 0.005
I0526 12:43:41.881959 26867 solver.cpp:237] Iteration 819000, loss = 1.05969
I0526 12:43:41.882020 26867 solver.cpp:253]     Train net output #0: loss = 1.05969 (* 1 = 1.05969 loss)
I0526 12:43:41.882047 26867 sgd_solver.cpp:106] Iteration 819000, lr = 0.005
I0526 12:44:19.975792 26867 solver.cpp:237] Iteration 820500, loss = 1.41892
I0526 12:44:19.975982 26867 solver.cpp:253]     Train net output #0: loss = 1.41892 (* 1 = 1.41892 loss)
I0526 12:44:19.976001 26867 sgd_solver.cpp:106] Iteration 820500, lr = 0.005
I0526 12:44:36.937947 26867 solver.cpp:237] Iteration 822000, loss = 1.22912
I0526 12:44:36.938004 26867 solver.cpp:253]     Train net output #0: loss = 1.22912 (* 1 = 1.22912 loss)
I0526 12:44:36.938022 26867 sgd_solver.cpp:106] Iteration 822000, lr = 0.005
I0526 12:44:53.578913 26867 solver.cpp:237] Iteration 823500, loss = 0.931083
I0526 12:44:53.579082 26867 solver.cpp:253]     Train net output #0: loss = 0.931083 (* 1 = 0.931083 loss)
I0526 12:44:53.579098 26867 sgd_solver.cpp:106] Iteration 823500, lr = 0.005
I0526 12:45:10.313812 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_825000.caffemodel
I0526 12:45:10.361588 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_825000.solverstate
I0526 12:45:10.393888 26867 solver.cpp:237] Iteration 825000, loss = 1.47287
I0526 12:45:10.393950 26867 solver.cpp:253]     Train net output #0: loss = 1.47287 (* 1 = 1.47287 loss)
I0526 12:45:10.393967 26867 sgd_solver.cpp:106] Iteration 825000, lr = 0.005
I0526 12:45:27.195588 26867 solver.cpp:237] Iteration 826500, loss = 1.9064
I0526 12:45:27.195772 26867 solver.cpp:253]     Train net output #0: loss = 1.9064 (* 1 = 1.9064 loss)
I0526 12:45:27.195790 26867 sgd_solver.cpp:106] Iteration 826500, lr = 0.005
I0526 12:45:44.100878 26867 solver.cpp:237] Iteration 828000, loss = 1.63261
I0526 12:45:44.100919 26867 solver.cpp:253]     Train net output #0: loss = 1.63261 (* 1 = 1.63261 loss)
I0526 12:45:44.100939 26867 sgd_solver.cpp:106] Iteration 828000, lr = 0.005
I0526 12:46:00.734141 26867 solver.cpp:237] Iteration 829500, loss = 1.41828
I0526 12:46:00.734321 26867 solver.cpp:253]     Train net output #0: loss = 1.41828 (* 1 = 1.41828 loss)
I0526 12:46:00.734338 26867 sgd_solver.cpp:106] Iteration 829500, lr = 0.005
I0526 12:46:38.391553 26867 solver.cpp:237] Iteration 831000, loss = 1.32884
I0526 12:46:38.391741 26867 solver.cpp:253]     Train net output #0: loss = 1.32884 (* 1 = 1.32884 loss)
I0526 12:46:38.391760 26867 sgd_solver.cpp:106] Iteration 831000, lr = 0.005
I0526 12:46:55.460274 26867 solver.cpp:237] Iteration 832500, loss = 1.01348
I0526 12:46:55.460312 26867 solver.cpp:253]     Train net output #0: loss = 1.01348 (* 1 = 1.01348 loss)
I0526 12:46:55.460335 26867 sgd_solver.cpp:106] Iteration 832500, lr = 0.005
I0526 12:47:12.225114 26867 solver.cpp:237] Iteration 834000, loss = 1.00973
I0526 12:47:12.225291 26867 solver.cpp:253]     Train net output #0: loss = 1.00973 (* 1 = 1.00973 loss)
I0526 12:47:12.225309 26867 sgd_solver.cpp:106] Iteration 834000, lr = 0.005
I0526 12:47:28.899236 26867 solver.cpp:237] Iteration 835500, loss = 1.13513
I0526 12:47:28.899284 26867 solver.cpp:253]     Train net output #0: loss = 1.13513 (* 1 = 1.13513 loss)
I0526 12:47:28.899304 26867 sgd_solver.cpp:106] Iteration 835500, lr = 0.005
I0526 12:47:45.783782 26867 solver.cpp:237] Iteration 837000, loss = 1.056
I0526 12:47:45.783949 26867 solver.cpp:253]     Train net output #0: loss = 1.056 (* 1 = 1.056 loss)
I0526 12:47:45.783967 26867 sgd_solver.cpp:106] Iteration 837000, lr = 0.005
I0526 12:48:02.595959 26867 solver.cpp:237] Iteration 838500, loss = 1.04024
I0526 12:48:02.596007 26867 solver.cpp:253]     Train net output #0: loss = 1.04024 (* 1 = 1.04024 loss)
I0526 12:48:02.596025 26867 sgd_solver.cpp:106] Iteration 838500, lr = 0.005
I0526 12:48:19.340668 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_840000.caffemodel
I0526 12:48:19.386562 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_840000.solverstate
I0526 12:48:19.412119 26867 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 12:49:18.999975 26867 solver.cpp:409]     Test net output #0: accuracy = 0.879405
I0526 12:49:19.000162 26867 solver.cpp:409]     Test net output #1: loss = 0.405001 (* 1 = 0.405001 loss)
I0526 12:49:39.901340 26867 solver.cpp:237] Iteration 840000, loss = 1.38671
I0526 12:49:39.901399 26867 solver.cpp:253]     Train net output #0: loss = 1.38671 (* 1 = 1.38671 loss)
I0526 12:49:39.901419 26867 sgd_solver.cpp:106] Iteration 840000, lr = 0.005
I0526 12:49:56.738179 26867 solver.cpp:237] Iteration 841500, loss = 0.976147
I0526 12:49:56.738368 26867 solver.cpp:253]     Train net output #0: loss = 0.976148 (* 1 = 0.976148 loss)
I0526 12:49:56.738396 26867 sgd_solver.cpp:106] Iteration 841500, lr = 0.005
I0526 12:50:13.641968 26867 solver.cpp:237] Iteration 843000, loss = 1.70697
I0526 12:50:13.642014 26867 solver.cpp:253]     Train net output #0: loss = 1.70697 (* 1 = 1.70697 loss)
I0526 12:50:13.642032 26867 sgd_solver.cpp:106] Iteration 843000, lr = 0.005
I0526 12:50:30.495131 26867 solver.cpp:237] Iteration 844500, loss = 2.15106
I0526 12:50:30.495312 26867 solver.cpp:253]     Train net output #0: loss = 2.15106 (* 1 = 2.15106 loss)
I0526 12:50:30.495331 26867 sgd_solver.cpp:106] Iteration 844500, lr = 0.005
I0526 12:50:47.263882 26867 solver.cpp:237] Iteration 846000, loss = 0.849498
I0526 12:50:47.263939 26867 solver.cpp:253]     Train net output #0: loss = 0.849499 (* 1 = 0.849499 loss)
I0526 12:50:47.263965 26867 sgd_solver.cpp:106] Iteration 846000, lr = 0.005
I0526 12:51:04.409514 26867 solver.cpp:237] Iteration 847500, loss = 0.894552
I0526 12:51:04.409685 26867 solver.cpp:253]     Train net output #0: loss = 0.894552 (* 1 = 0.894552 loss)
I0526 12:51:04.409703 26867 sgd_solver.cpp:106] Iteration 847500, lr = 0.005
I0526 12:51:21.461318 26867 solver.cpp:237] Iteration 849000, loss = 0.798445
I0526 12:51:21.461370 26867 solver.cpp:253]     Train net output #0: loss = 0.798447 (* 1 = 0.798447 loss)
I0526 12:51:21.461388 26867 sgd_solver.cpp:106] Iteration 849000, lr = 0.005
I0526 12:51:59.287096 26867 solver.cpp:237] Iteration 850500, loss = 1.10491
I0526 12:51:59.287286 26867 solver.cpp:253]     Train net output #0: loss = 1.10491 (* 1 = 1.10491 loss)
I0526 12:51:59.287305 26867 sgd_solver.cpp:106] Iteration 850500, lr = 0.005
I0526 12:52:15.920281 26867 solver.cpp:237] Iteration 852000, loss = 1.02066
I0526 12:52:15.920331 26867 solver.cpp:253]     Train net output #0: loss = 1.02066 (* 1 = 1.02066 loss)
I0526 12:52:15.920349 26867 sgd_solver.cpp:106] Iteration 852000, lr = 0.005
I0526 12:52:32.814795 26867 solver.cpp:237] Iteration 853500, loss = 0.8186
I0526 12:52:32.814978 26867 solver.cpp:253]     Train net output #0: loss = 0.818604 (* 1 = 0.818604 loss)
I0526 12:52:32.814996 26867 sgd_solver.cpp:106] Iteration 853500, lr = 0.005
I0526 12:52:49.994669 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_855000.caffemodel
I0526 12:52:50.040783 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_855000.solverstate
I0526 12:52:50.069527 26867 solver.cpp:237] Iteration 855000, loss = 1.7756
I0526 12:52:50.069586 26867 solver.cpp:253]     Train net output #0: loss = 1.7756 (* 1 = 1.7756 loss)
I0526 12:52:50.069604 26867 sgd_solver.cpp:106] Iteration 855000, lr = 0.005
I0526 12:53:06.871011 26867 solver.cpp:237] Iteration 856500, loss = 0.696751
I0526 12:53:06.871206 26867 solver.cpp:253]     Train net output #0: loss = 0.696754 (* 1 = 0.696754 loss)
I0526 12:53:06.871224 26867 sgd_solver.cpp:106] Iteration 856500, lr = 0.005
I0526 12:53:23.854010 26867 solver.cpp:237] Iteration 858000, loss = 1.09434
I0526 12:53:23.854065 26867 solver.cpp:253]     Train net output #0: loss = 1.09434 (* 1 = 1.09434 loss)
I0526 12:53:23.854084 26867 sgd_solver.cpp:106] Iteration 858000, lr = 0.005
I0526 12:53:41.006824 26867 solver.cpp:237] Iteration 859500, loss = 1.27658
I0526 12:53:41.007009 26867 solver.cpp:253]     Train net output #0: loss = 1.27659 (* 1 = 1.27659 loss)
I0526 12:53:41.007028 26867 sgd_solver.cpp:106] Iteration 859500, lr = 0.005
I0526 12:54:18.517783 26867 solver.cpp:237] Iteration 861000, loss = 1.0975
I0526 12:54:18.517967 26867 solver.cpp:253]     Train net output #0: loss = 1.0975 (* 1 = 1.0975 loss)
I0526 12:54:18.517985 26867 sgd_solver.cpp:106] Iteration 861000, lr = 0.005
I0526 12:54:35.197582 26867 solver.cpp:237] Iteration 862500, loss = 2.17964
I0526 12:54:35.197634 26867 solver.cpp:253]     Train net output #0: loss = 2.17964 (* 1 = 2.17964 loss)
I0526 12:54:35.197654 26867 sgd_solver.cpp:106] Iteration 862500, lr = 0.005
I0526 12:54:52.025693 26867 solver.cpp:237] Iteration 864000, loss = 1.29218
I0526 12:54:52.025864 26867 solver.cpp:253]     Train net output #0: loss = 1.29218 (* 1 = 1.29218 loss)
I0526 12:54:52.025882 26867 sgd_solver.cpp:106] Iteration 864000, lr = 0.005
I0526 12:55:08.962265 26867 solver.cpp:237] Iteration 865500, loss = 1.03964
I0526 12:55:08.962316 26867 solver.cpp:253]     Train net output #0: loss = 1.03964 (* 1 = 1.03964 loss)
I0526 12:55:08.962335 26867 sgd_solver.cpp:106] Iteration 865500, lr = 0.005
I0526 12:55:25.787762 26867 solver.cpp:237] Iteration 867000, loss = 1.21602
I0526 12:55:25.787948 26867 solver.cpp:253]     Train net output #0: loss = 1.21603 (* 1 = 1.21603 loss)
I0526 12:55:25.787966 26867 sgd_solver.cpp:106] Iteration 867000, lr = 0.005
I0526 12:55:42.407294 26867 solver.cpp:237] Iteration 868500, loss = 0.90434
I0526 12:55:42.407335 26867 solver.cpp:253]     Train net output #0: loss = 0.904343 (* 1 = 0.904343 loss)
I0526 12:55:42.407352 26867 sgd_solver.cpp:106] Iteration 868500, lr = 0.005
I0526 12:55:59.018116 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_870000.caffemodel
I0526 12:55:59.064419 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_870000.solverstate
I0526 12:55:59.090437 26867 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 12:57:19.439234 26867 solver.cpp:409]     Test net output #0: accuracy = 0.885627
I0526 12:57:19.439429 26867 solver.cpp:409]     Test net output #1: loss = 0.385916 (* 1 = 0.385916 loss)
I0526 12:57:40.309372 26867 solver.cpp:237] Iteration 870000, loss = 1.23346
I0526 12:57:40.309437 26867 solver.cpp:253]     Train net output #0: loss = 1.23346 (* 1 = 1.23346 loss)
I0526 12:57:40.309454 26867 sgd_solver.cpp:106] Iteration 870000, lr = 0.005
I0526 12:57:57.342700 26867 solver.cpp:237] Iteration 871500, loss = 1.4175
I0526 12:57:57.342880 26867 solver.cpp:253]     Train net output #0: loss = 1.4175 (* 1 = 1.4175 loss)
I0526 12:57:57.342897 26867 sgd_solver.cpp:106] Iteration 871500, lr = 0.005
I0526 12:58:14.213112 26867 solver.cpp:237] Iteration 873000, loss = 0.919554
I0526 12:58:14.213153 26867 solver.cpp:253]     Train net output #0: loss = 0.919557 (* 1 = 0.919557 loss)
I0526 12:58:14.213171 26867 sgd_solver.cpp:106] Iteration 873000, lr = 0.005
I0526 12:58:31.038627 26867 solver.cpp:237] Iteration 874500, loss = 1.01395
I0526 12:58:31.038823 26867 solver.cpp:253]     Train net output #0: loss = 1.01396 (* 1 = 1.01396 loss)
I0526 12:58:31.038841 26867 sgd_solver.cpp:106] Iteration 874500, lr = 0.005
I0526 12:58:48.006031 26867 solver.cpp:237] Iteration 876000, loss = 0.85975
I0526 12:58:48.006083 26867 solver.cpp:253]     Train net output #0: loss = 0.859753 (* 1 = 0.859753 loss)
I0526 12:58:48.006101 26867 sgd_solver.cpp:106] Iteration 876000, lr = 0.005
I0526 12:59:05.231889 26867 solver.cpp:237] Iteration 877500, loss = 0.849119
I0526 12:59:05.232067 26867 solver.cpp:253]     Train net output #0: loss = 0.849122 (* 1 = 0.849122 loss)
I0526 12:59:05.232085 26867 sgd_solver.cpp:106] Iteration 877500, lr = 0.005
I0526 12:59:22.203225 26867 solver.cpp:237] Iteration 879000, loss = 1.21436
I0526 12:59:22.203263 26867 solver.cpp:253]     Train net output #0: loss = 1.21436 (* 1 = 1.21436 loss)
I0526 12:59:22.203282 26867 sgd_solver.cpp:106] Iteration 879000, lr = 0.005
I0526 13:00:00.022864 26867 solver.cpp:237] Iteration 880500, loss = 0.653876
I0526 13:00:00.023056 26867 solver.cpp:253]     Train net output #0: loss = 0.65388 (* 1 = 0.65388 loss)
I0526 13:00:00.023074 26867 sgd_solver.cpp:106] Iteration 880500, lr = 0.005
I0526 13:00:17.181578 26867 solver.cpp:237] Iteration 882000, loss = 0.795263
I0526 13:00:17.181617 26867 solver.cpp:253]     Train net output #0: loss = 0.795266 (* 1 = 0.795266 loss)
I0526 13:00:17.181637 26867 sgd_solver.cpp:106] Iteration 882000, lr = 0.005
I0526 13:00:34.018995 26867 solver.cpp:237] Iteration 883500, loss = 0.677588
I0526 13:00:34.019181 26867 solver.cpp:253]     Train net output #0: loss = 0.677592 (* 1 = 0.677592 loss)
I0526 13:00:34.019199 26867 sgd_solver.cpp:106] Iteration 883500, lr = 0.005
I0526 13:00:50.958096 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_885000.caffemodel
I0526 13:00:51.005573 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_885000.solverstate
I0526 13:00:51.035930 26867 solver.cpp:237] Iteration 885000, loss = 2.45617
I0526 13:00:51.035984 26867 solver.cpp:253]     Train net output #0: loss = 2.45618 (* 1 = 2.45618 loss)
I0526 13:00:51.036010 26867 sgd_solver.cpp:106] Iteration 885000, lr = 0.005
I0526 13:01:08.198907 26867 solver.cpp:237] Iteration 886500, loss = 1.00906
I0526 13:01:08.199082 26867 solver.cpp:253]     Train net output #0: loss = 1.00906 (* 1 = 1.00906 loss)
I0526 13:01:08.199100 26867 sgd_solver.cpp:106] Iteration 886500, lr = 0.005
I0526 13:01:25.256098 26867 solver.cpp:237] Iteration 888000, loss = 3.77115
I0526 13:01:25.256155 26867 solver.cpp:253]     Train net output #0: loss = 3.77116 (* 1 = 3.77116 loss)
I0526 13:01:25.256172 26867 sgd_solver.cpp:106] Iteration 888000, lr = 0.005
I0526 13:01:42.281318 26867 solver.cpp:237] Iteration 889500, loss = 1.49961
I0526 13:01:42.281504 26867 solver.cpp:253]     Train net output #0: loss = 1.49961 (* 1 = 1.49961 loss)
I0526 13:01:42.281522 26867 sgd_solver.cpp:106] Iteration 889500, lr = 0.005
I0526 13:02:20.137655 26867 solver.cpp:237] Iteration 891000, loss = 1.09474
I0526 13:02:20.137856 26867 solver.cpp:253]     Train net output #0: loss = 1.09474 (* 1 = 1.09474 loss)
I0526 13:02:20.137873 26867 sgd_solver.cpp:106] Iteration 891000, lr = 0.005
I0526 13:02:37.246800 26867 solver.cpp:237] Iteration 892500, loss = 1.62403
I0526 13:02:37.246853 26867 solver.cpp:253]     Train net output #0: loss = 1.62404 (* 1 = 1.62404 loss)
I0526 13:02:37.246871 26867 sgd_solver.cpp:106] Iteration 892500, lr = 0.005
I0526 13:02:54.369602 26867 solver.cpp:237] Iteration 894000, loss = 1.11676
I0526 13:02:54.369787 26867 solver.cpp:253]     Train net output #0: loss = 1.11676 (* 1 = 1.11676 loss)
I0526 13:02:54.369807 26867 sgd_solver.cpp:106] Iteration 894000, lr = 0.005
I0526 13:03:11.259960 26867 solver.cpp:237] Iteration 895500, loss = 1.44136
I0526 13:03:11.259999 26867 solver.cpp:253]     Train net output #0: loss = 1.44137 (* 1 = 1.44137 loss)
I0526 13:03:11.260018 26867 sgd_solver.cpp:106] Iteration 895500, lr = 0.005
I0526 13:03:28.061327 26867 solver.cpp:237] Iteration 897000, loss = 0.630984
I0526 13:03:28.061525 26867 solver.cpp:253]     Train net output #0: loss = 0.630989 (* 1 = 0.630989 loss)
I0526 13:03:28.061542 26867 sgd_solver.cpp:106] Iteration 897000, lr = 0.005
I0526 13:03:44.776753 26867 solver.cpp:237] Iteration 898500, loss = 0.822899
I0526 13:03:44.776805 26867 solver.cpp:253]     Train net output #0: loss = 0.822904 (* 1 = 0.822904 loss)
I0526 13:03:44.776834 26867 sgd_solver.cpp:106] Iteration 898500, lr = 0.005
I0526 13:04:01.391074 26867 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_900000.caffemodel
I0526 13:04:01.438707 26867 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_900000.solverstate
I0526 13:04:01.468371 26867 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 13:05:00.626515 26867 solver.cpp:409]     Test net output #0: accuracy = 0.880832
I0526 13:05:00.626703 26867 solver.cpp:409]     Test net output #1: loss = 0.39246 (* 1 = 0.39246 loss)
I0526 13:05:21.522934 26867 solver.cpp:237] Iteration 900000, loss = 0.951342
I0526 13:05:21.522994 26867 solver.cpp:253]     Train net output #0: loss = 0.951347 (* 1 = 0.951347 loss)
I0526 13:05:21.523023 26867 sgd_solver.cpp:106] Iteration 900000, lr = 0.005
I0526 13:05:38.568025 26867 solver.cpp:237] Iteration 901500, loss = 0.86631
I0526 13:05:38.568204 26867 solver.cpp:253]     Train net output #0: loss = 0.866316 (* 1 = 0.866316 loss)
I0526 13:05:38.568222 26867 sgd_solver.cpp:106] Iteration 901500, lr = 0.005
aprun: Apid 11268232: Caught signal Terminated, sending to application
*** Aborted at 1464282346 (unix time) try "date -d @1464282346" if you are using GNU date ***
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7208 exceeded limit 7200
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
aprun: Apid 11268232: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x68f0) received by PID 26867 (TID 0x2aaac746f900) from PID 26864; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 00796] [c2-1c1s1n2] [Thu May 26 13:05:49 2016] PE RANK 0 exit signal Terminated
Application 11268232 exit codes: 143
Application 11268232 resources: utime ~6306s, stime ~888s, Rss ~5329892, inblocks ~10491400, outblocks ~474917
