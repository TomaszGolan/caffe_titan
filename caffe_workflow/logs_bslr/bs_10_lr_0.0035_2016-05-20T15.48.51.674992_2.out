2811364
I0526 07:31:59.003069 23331 caffe.cpp:184] Using GPUs 0
I0526 07:31:59.436458 23331 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0035
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992.prototxt"
I0526 07:31:59.438009 23331 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992.prototxt
I0526 07:31:59.454155 23331 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 07:31:59.454218 23331 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 07:31:59.454598 23331 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 07:31:59.454810 23331 layer_factory.hpp:77] Creating layer data_hdf5
I0526 07:31:59.454848 23331 net.cpp:106] Creating Layer data_hdf5
I0526 07:31:59.454864 23331 net.cpp:411] data_hdf5 -> data
I0526 07:31:59.454898 23331 net.cpp:411] data_hdf5 -> label
I0526 07:31:59.454941 23331 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 07:31:59.456220 23331 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 07:31:59.458452 23331 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 07:32:21.055950 23331 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 07:32:21.061158 23331 net.cpp:150] Setting up data_hdf5
I0526 07:32:21.061200 23331 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 07:32:21.061218 23331 net.cpp:157] Top shape: 10 (10)
I0526 07:32:21.061229 23331 net.cpp:165] Memory required for data: 254040
I0526 07:32:21.061249 23331 layer_factory.hpp:77] Creating layer conv1
I0526 07:32:21.061295 23331 net.cpp:106] Creating Layer conv1
I0526 07:32:21.061311 23331 net.cpp:454] conv1 <- data
I0526 07:32:21.061336 23331 net.cpp:411] conv1 -> conv1
I0526 07:32:21.421557 23331 net.cpp:150] Setting up conv1
I0526 07:32:21.421609 23331 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:32:21.421632 23331 net.cpp:165] Memory required for data: 3018840
I0526 07:32:21.421663 23331 layer_factory.hpp:77] Creating layer relu1
I0526 07:32:21.421685 23331 net.cpp:106] Creating Layer relu1
I0526 07:32:21.421725 23331 net.cpp:454] relu1 <- conv1
I0526 07:32:21.421741 23331 net.cpp:397] relu1 -> conv1 (in-place)
I0526 07:32:21.422284 23331 net.cpp:150] Setting up relu1
I0526 07:32:21.422308 23331 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:32:21.422322 23331 net.cpp:165] Memory required for data: 5783640
I0526 07:32:21.422334 23331 layer_factory.hpp:77] Creating layer pool1
I0526 07:32:21.422366 23331 net.cpp:106] Creating Layer pool1
I0526 07:32:21.422379 23331 net.cpp:454] pool1 <- conv1
I0526 07:32:21.422396 23331 net.cpp:411] pool1 -> pool1
I0526 07:32:21.422489 23331 net.cpp:150] Setting up pool1
I0526 07:32:21.422507 23331 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 07:32:21.422521 23331 net.cpp:165] Memory required for data: 7166040
I0526 07:32:21.422543 23331 layer_factory.hpp:77] Creating layer conv2
I0526 07:32:21.422565 23331 net.cpp:106] Creating Layer conv2
I0526 07:32:21.422580 23331 net.cpp:454] conv2 <- pool1
I0526 07:32:21.422595 23331 net.cpp:411] conv2 -> conv2
I0526 07:32:21.425345 23331 net.cpp:150] Setting up conv2
I0526 07:32:21.425380 23331 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:32:21.425395 23331 net.cpp:165] Memory required for data: 9153240
I0526 07:32:21.425421 23331 layer_factory.hpp:77] Creating layer relu2
I0526 07:32:21.425449 23331 net.cpp:106] Creating Layer relu2
I0526 07:32:21.425462 23331 net.cpp:454] relu2 <- conv2
I0526 07:32:21.425479 23331 net.cpp:397] relu2 -> conv2 (in-place)
I0526 07:32:21.425838 23331 net.cpp:150] Setting up relu2
I0526 07:32:21.425858 23331 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:32:21.425873 23331 net.cpp:165] Memory required for data: 11140440
I0526 07:32:21.425887 23331 layer_factory.hpp:77] Creating layer pool2
I0526 07:32:21.425910 23331 net.cpp:106] Creating Layer pool2
I0526 07:32:21.425923 23331 net.cpp:454] pool2 <- conv2
I0526 07:32:21.425940 23331 net.cpp:411] pool2 -> pool2
I0526 07:32:21.426034 23331 net.cpp:150] Setting up pool2
I0526 07:32:21.426053 23331 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 07:32:21.426067 23331 net.cpp:165] Memory required for data: 12134040
I0526 07:32:21.426087 23331 layer_factory.hpp:77] Creating layer conv3
I0526 07:32:21.426107 23331 net.cpp:106] Creating Layer conv3
I0526 07:32:21.426122 23331 net.cpp:454] conv3 <- pool2
I0526 07:32:21.426137 23331 net.cpp:411] conv3 -> conv3
I0526 07:32:21.428282 23331 net.cpp:150] Setting up conv3
I0526 07:32:21.428306 23331 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:32:21.428326 23331 net.cpp:165] Memory required for data: 13218200
I0526 07:32:21.428349 23331 layer_factory.hpp:77] Creating layer relu3
I0526 07:32:21.428372 23331 net.cpp:106] Creating Layer relu3
I0526 07:32:21.428395 23331 net.cpp:454] relu3 <- conv3
I0526 07:32:21.428411 23331 net.cpp:397] relu3 -> conv3 (in-place)
I0526 07:32:21.428895 23331 net.cpp:150] Setting up relu3
I0526 07:32:21.428920 23331 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:32:21.428933 23331 net.cpp:165] Memory required for data: 14302360
I0526 07:32:21.428949 23331 layer_factory.hpp:77] Creating layer pool3
I0526 07:32:21.428966 23331 net.cpp:106] Creating Layer pool3
I0526 07:32:21.428987 23331 net.cpp:454] pool3 <- conv3
I0526 07:32:21.429003 23331 net.cpp:411] pool3 -> pool3
I0526 07:32:21.429085 23331 net.cpp:150] Setting up pool3
I0526 07:32:21.429106 23331 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 07:32:21.429118 23331 net.cpp:165] Memory required for data: 14844440
I0526 07:32:21.429133 23331 layer_factory.hpp:77] Creating layer conv4
I0526 07:32:21.429159 23331 net.cpp:106] Creating Layer conv4
I0526 07:32:21.429172 23331 net.cpp:454] conv4 <- pool3
I0526 07:32:21.429188 23331 net.cpp:411] conv4 -> conv4
I0526 07:32:21.431947 23331 net.cpp:150] Setting up conv4
I0526 07:32:21.431979 23331 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:32:21.431993 23331 net.cpp:165] Memory required for data: 15207320
I0526 07:32:21.432016 23331 layer_factory.hpp:77] Creating layer relu4
I0526 07:32:21.432044 23331 net.cpp:106] Creating Layer relu4
I0526 07:32:21.432057 23331 net.cpp:454] relu4 <- conv4
I0526 07:32:21.432073 23331 net.cpp:397] relu4 -> conv4 (in-place)
I0526 07:32:21.432574 23331 net.cpp:150] Setting up relu4
I0526 07:32:21.432597 23331 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:32:21.432610 23331 net.cpp:165] Memory required for data: 15570200
I0526 07:32:21.432626 23331 layer_factory.hpp:77] Creating layer pool4
I0526 07:32:21.432642 23331 net.cpp:106] Creating Layer pool4
I0526 07:32:21.432662 23331 net.cpp:454] pool4 <- conv4
I0526 07:32:21.432679 23331 net.cpp:411] pool4 -> pool4
I0526 07:32:21.432762 23331 net.cpp:150] Setting up pool4
I0526 07:32:21.432781 23331 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 07:32:21.432796 23331 net.cpp:165] Memory required for data: 15751640
I0526 07:32:21.432808 23331 layer_factory.hpp:77] Creating layer ip1
I0526 07:32:21.432835 23331 net.cpp:106] Creating Layer ip1
I0526 07:32:21.432848 23331 net.cpp:454] ip1 <- pool4
I0526 07:32:21.432865 23331 net.cpp:411] ip1 -> ip1
I0526 07:32:21.448307 23331 net.cpp:150] Setting up ip1
I0526 07:32:21.448338 23331 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:32:21.448359 23331 net.cpp:165] Memory required for data: 15759480
I0526 07:32:21.448385 23331 layer_factory.hpp:77] Creating layer relu5
I0526 07:32:21.448407 23331 net.cpp:106] Creating Layer relu5
I0526 07:32:21.448431 23331 net.cpp:454] relu5 <- ip1
I0526 07:32:21.448448 23331 net.cpp:397] relu5 -> ip1 (in-place)
I0526 07:32:21.448810 23331 net.cpp:150] Setting up relu5
I0526 07:32:21.448830 23331 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:32:21.448843 23331 net.cpp:165] Memory required for data: 15767320
I0526 07:32:21.448858 23331 layer_factory.hpp:77] Creating layer drop1
I0526 07:32:21.448889 23331 net.cpp:106] Creating Layer drop1
I0526 07:32:21.448904 23331 net.cpp:454] drop1 <- ip1
I0526 07:32:21.448926 23331 net.cpp:397] drop1 -> ip1 (in-place)
I0526 07:32:21.449000 23331 net.cpp:150] Setting up drop1
I0526 07:32:21.449017 23331 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:32:21.449029 23331 net.cpp:165] Memory required for data: 15775160
I0526 07:32:21.449043 23331 layer_factory.hpp:77] Creating layer ip2
I0526 07:32:21.449064 23331 net.cpp:106] Creating Layer ip2
I0526 07:32:21.449084 23331 net.cpp:454] ip2 <- ip1
I0526 07:32:21.449100 23331 net.cpp:411] ip2 -> ip2
I0526 07:32:21.449590 23331 net.cpp:150] Setting up ip2
I0526 07:32:21.449609 23331 net.cpp:157] Top shape: 10 98 (980)
I0526 07:32:21.449622 23331 net.cpp:165] Memory required for data: 15779080
I0526 07:32:21.449643 23331 layer_factory.hpp:77] Creating layer relu6
I0526 07:32:21.449666 23331 net.cpp:106] Creating Layer relu6
I0526 07:32:21.449678 23331 net.cpp:454] relu6 <- ip2
I0526 07:32:21.449693 23331 net.cpp:397] relu6 -> ip2 (in-place)
I0526 07:32:21.450248 23331 net.cpp:150] Setting up relu6
I0526 07:32:21.450271 23331 net.cpp:157] Top shape: 10 98 (980)
I0526 07:32:21.450284 23331 net.cpp:165] Memory required for data: 15783000
I0526 07:32:21.450300 23331 layer_factory.hpp:77] Creating layer drop2
I0526 07:32:21.450315 23331 net.cpp:106] Creating Layer drop2
I0526 07:32:21.450336 23331 net.cpp:454] drop2 <- ip2
I0526 07:32:21.450352 23331 net.cpp:397] drop2 -> ip2 (in-place)
I0526 07:32:21.450403 23331 net.cpp:150] Setting up drop2
I0526 07:32:21.450425 23331 net.cpp:157] Top shape: 10 98 (980)
I0526 07:32:21.450438 23331 net.cpp:165] Memory required for data: 15786920
I0526 07:32:21.450451 23331 layer_factory.hpp:77] Creating layer ip3
I0526 07:32:21.450470 23331 net.cpp:106] Creating Layer ip3
I0526 07:32:21.450482 23331 net.cpp:454] ip3 <- ip2
I0526 07:32:21.450505 23331 net.cpp:411] ip3 -> ip3
I0526 07:32:21.450726 23331 net.cpp:150] Setting up ip3
I0526 07:32:21.450745 23331 net.cpp:157] Top shape: 10 11 (110)
I0526 07:32:21.450758 23331 net.cpp:165] Memory required for data: 15787360
I0526 07:32:21.450778 23331 layer_factory.hpp:77] Creating layer drop3
I0526 07:32:21.450800 23331 net.cpp:106] Creating Layer drop3
I0526 07:32:21.450814 23331 net.cpp:454] drop3 <- ip3
I0526 07:32:21.450829 23331 net.cpp:397] drop3 -> ip3 (in-place)
I0526 07:32:21.450875 23331 net.cpp:150] Setting up drop3
I0526 07:32:21.450896 23331 net.cpp:157] Top shape: 10 11 (110)
I0526 07:32:21.450909 23331 net.cpp:165] Memory required for data: 15787800
I0526 07:32:21.450928 23331 layer_factory.hpp:77] Creating layer loss
I0526 07:32:21.450949 23331 net.cpp:106] Creating Layer loss
I0526 07:32:21.450964 23331 net.cpp:454] loss <- ip3
I0526 07:32:21.450978 23331 net.cpp:454] loss <- label
I0526 07:32:21.451000 23331 net.cpp:411] loss -> loss
I0526 07:32:21.451020 23331 layer_factory.hpp:77] Creating layer loss
I0526 07:32:21.451699 23331 net.cpp:150] Setting up loss
I0526 07:32:21.451721 23331 net.cpp:157] Top shape: (1)
I0526 07:32:21.451735 23331 net.cpp:160]     with loss weight 1
I0526 07:32:21.451797 23331 net.cpp:165] Memory required for data: 15787804
I0526 07:32:21.451809 23331 net.cpp:226] loss needs backward computation.
I0526 07:32:21.451823 23331 net.cpp:226] drop3 needs backward computation.
I0526 07:32:21.451835 23331 net.cpp:226] ip3 needs backward computation.
I0526 07:32:21.451848 23331 net.cpp:226] drop2 needs backward computation.
I0526 07:32:21.451864 23331 net.cpp:226] relu6 needs backward computation.
I0526 07:32:21.451881 23331 net.cpp:226] ip2 needs backward computation.
I0526 07:32:21.451894 23331 net.cpp:226] drop1 needs backward computation.
I0526 07:32:21.451906 23331 net.cpp:226] relu5 needs backward computation.
I0526 07:32:21.451920 23331 net.cpp:226] ip1 needs backward computation.
I0526 07:32:21.451932 23331 net.cpp:226] pool4 needs backward computation.
I0526 07:32:21.451946 23331 net.cpp:226] relu4 needs backward computation.
I0526 07:32:21.451961 23331 net.cpp:226] conv4 needs backward computation.
I0526 07:32:21.451982 23331 net.cpp:226] pool3 needs backward computation.
I0526 07:32:21.451997 23331 net.cpp:226] relu3 needs backward computation.
I0526 07:32:21.452013 23331 net.cpp:226] conv3 needs backward computation.
I0526 07:32:21.452036 23331 net.cpp:226] pool2 needs backward computation.
I0526 07:32:21.452049 23331 net.cpp:226] relu2 needs backward computation.
I0526 07:32:21.452064 23331 net.cpp:226] conv2 needs backward computation.
I0526 07:32:21.452085 23331 net.cpp:226] pool1 needs backward computation.
I0526 07:32:21.452100 23331 net.cpp:226] relu1 needs backward computation.
I0526 07:32:21.452113 23331 net.cpp:226] conv1 needs backward computation.
I0526 07:32:21.452127 23331 net.cpp:228] data_hdf5 does not need backward computation.
I0526 07:32:21.452138 23331 net.cpp:270] This network produces output loss
I0526 07:32:21.452167 23331 net.cpp:283] Network initialization done.
I0526 07:32:21.453759 23331 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992.prototxt
I0526 07:32:21.453838 23331 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 07:32:21.454217 23331 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 07:32:21.454439 23331 layer_factory.hpp:77] Creating layer data_hdf5
I0526 07:32:21.454459 23331 net.cpp:106] Creating Layer data_hdf5
I0526 07:32:21.454474 23331 net.cpp:411] data_hdf5 -> data
I0526 07:32:21.454494 23331 net.cpp:411] data_hdf5 -> label
I0526 07:32:21.454515 23331 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 07:32:21.455687 23331 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 07:32:42.825094 23331 net.cpp:150] Setting up data_hdf5
I0526 07:32:42.825266 23331 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 07:32:42.825286 23331 net.cpp:157] Top shape: 10 (10)
I0526 07:32:42.825299 23331 net.cpp:165] Memory required for data: 254040
I0526 07:32:42.825314 23331 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 07:32:42.825350 23331 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 07:32:42.825363 23331 net.cpp:454] label_data_hdf5_1_split <- label
I0526 07:32:42.825399 23331 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 07:32:42.825423 23331 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 07:32:42.825510 23331 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 07:32:42.825526 23331 net.cpp:157] Top shape: 10 (10)
I0526 07:32:42.825542 23331 net.cpp:157] Top shape: 10 (10)
I0526 07:32:42.825554 23331 net.cpp:165] Memory required for data: 254120
I0526 07:32:42.825567 23331 layer_factory.hpp:77] Creating layer conv1
I0526 07:32:42.825600 23331 net.cpp:106] Creating Layer conv1
I0526 07:32:42.825614 23331 net.cpp:454] conv1 <- data
I0526 07:32:42.825631 23331 net.cpp:411] conv1 -> conv1
I0526 07:32:42.827638 23331 net.cpp:150] Setting up conv1
I0526 07:32:42.827663 23331 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:32:42.827677 23331 net.cpp:165] Memory required for data: 3018920
I0526 07:32:42.827702 23331 layer_factory.hpp:77] Creating layer relu1
I0526 07:32:42.827723 23331 net.cpp:106] Creating Layer relu1
I0526 07:32:42.827745 23331 net.cpp:454] relu1 <- conv1
I0526 07:32:42.827762 23331 net.cpp:397] relu1 -> conv1 (in-place)
I0526 07:32:42.828291 23331 net.cpp:150] Setting up relu1
I0526 07:32:42.828315 23331 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:32:42.828327 23331 net.cpp:165] Memory required for data: 5783720
I0526 07:32:42.828341 23331 layer_factory.hpp:77] Creating layer pool1
I0526 07:32:42.828371 23331 net.cpp:106] Creating Layer pool1
I0526 07:32:42.828383 23331 net.cpp:454] pool1 <- conv1
I0526 07:32:42.828400 23331 net.cpp:411] pool1 -> pool1
I0526 07:32:42.828497 23331 net.cpp:150] Setting up pool1
I0526 07:32:42.828515 23331 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 07:32:42.828527 23331 net.cpp:165] Memory required for data: 7166120
I0526 07:32:42.828539 23331 layer_factory.hpp:77] Creating layer conv2
I0526 07:32:42.828568 23331 net.cpp:106] Creating Layer conv2
I0526 07:32:42.828583 23331 net.cpp:454] conv2 <- pool1
I0526 07:32:42.828599 23331 net.cpp:411] conv2 -> conv2
I0526 07:32:42.830545 23331 net.cpp:150] Setting up conv2
I0526 07:32:42.830570 23331 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:32:42.830590 23331 net.cpp:165] Memory required for data: 9153320
I0526 07:32:42.830612 23331 layer_factory.hpp:77] Creating layer relu2
I0526 07:32:42.830631 23331 net.cpp:106] Creating Layer relu2
I0526 07:32:42.830653 23331 net.cpp:454] relu2 <- conv2
I0526 07:32:42.830670 23331 net.cpp:397] relu2 -> conv2 (in-place)
I0526 07:32:42.831019 23331 net.cpp:150] Setting up relu2
I0526 07:32:42.831040 23331 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:32:42.831053 23331 net.cpp:165] Memory required for data: 11140520
I0526 07:32:42.831068 23331 layer_factory.hpp:77] Creating layer pool2
I0526 07:32:42.831090 23331 net.cpp:106] Creating Layer pool2
I0526 07:32:42.831104 23331 net.cpp:454] pool2 <- conv2
I0526 07:32:42.831120 23331 net.cpp:411] pool2 -> pool2
I0526 07:32:42.831207 23331 net.cpp:150] Setting up pool2
I0526 07:32:42.831225 23331 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 07:32:42.831236 23331 net.cpp:165] Memory required for data: 12134120
I0526 07:32:42.831251 23331 layer_factory.hpp:77] Creating layer conv3
I0526 07:32:42.831281 23331 net.cpp:106] Creating Layer conv3
I0526 07:32:42.831295 23331 net.cpp:454] conv3 <- pool2
I0526 07:32:42.831311 23331 net.cpp:411] conv3 -> conv3
I0526 07:32:42.833353 23331 net.cpp:150] Setting up conv3
I0526 07:32:42.833380 23331 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:32:42.833400 23331 net.cpp:165] Memory required for data: 13218280
I0526 07:32:42.833422 23331 layer_factory.hpp:77] Creating layer relu3
I0526 07:32:42.833464 23331 net.cpp:106] Creating Layer relu3
I0526 07:32:42.833478 23331 net.cpp:454] relu3 <- conv3
I0526 07:32:42.833494 23331 net.cpp:397] relu3 -> conv3 (in-place)
I0526 07:32:42.833991 23331 net.cpp:150] Setting up relu3
I0526 07:32:42.834013 23331 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:32:42.834027 23331 net.cpp:165] Memory required for data: 14302440
I0526 07:32:42.834043 23331 layer_factory.hpp:77] Creating layer pool3
I0526 07:32:42.834059 23331 net.cpp:106] Creating Layer pool3
I0526 07:32:42.834080 23331 net.cpp:454] pool3 <- conv3
I0526 07:32:42.834096 23331 net.cpp:411] pool3 -> pool3
I0526 07:32:42.834183 23331 net.cpp:150] Setting up pool3
I0526 07:32:42.834203 23331 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 07:32:42.834214 23331 net.cpp:165] Memory required for data: 14844520
I0526 07:32:42.834229 23331 layer_factory.hpp:77] Creating layer conv4
I0526 07:32:42.834255 23331 net.cpp:106] Creating Layer conv4
I0526 07:32:42.834270 23331 net.cpp:454] conv4 <- pool3
I0526 07:32:42.834287 23331 net.cpp:411] conv4 -> conv4
I0526 07:32:42.836386 23331 net.cpp:150] Setting up conv4
I0526 07:32:42.836410 23331 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:32:42.836431 23331 net.cpp:165] Memory required for data: 15207400
I0526 07:32:42.836449 23331 layer_factory.hpp:77] Creating layer relu4
I0526 07:32:42.836469 23331 net.cpp:106] Creating Layer relu4
I0526 07:32:42.836483 23331 net.cpp:454] relu4 <- conv4
I0526 07:32:42.836508 23331 net.cpp:397] relu4 -> conv4 (in-place)
I0526 07:32:42.836997 23331 net.cpp:150] Setting up relu4
I0526 07:32:42.837020 23331 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:32:42.837033 23331 net.cpp:165] Memory required for data: 15570280
I0526 07:32:42.837049 23331 layer_factory.hpp:77] Creating layer pool4
I0526 07:32:42.837074 23331 net.cpp:106] Creating Layer pool4
I0526 07:32:42.837086 23331 net.cpp:454] pool4 <- conv4
I0526 07:32:42.837102 23331 net.cpp:411] pool4 -> pool4
I0526 07:32:42.837190 23331 net.cpp:150] Setting up pool4
I0526 07:32:42.837208 23331 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 07:32:42.837222 23331 net.cpp:165] Memory required for data: 15751720
I0526 07:32:42.837235 23331 layer_factory.hpp:77] Creating layer ip1
I0526 07:32:42.837261 23331 net.cpp:106] Creating Layer ip1
I0526 07:32:42.837275 23331 net.cpp:454] ip1 <- pool4
I0526 07:32:42.837291 23331 net.cpp:411] ip1 -> ip1
I0526 07:32:42.852768 23331 net.cpp:150] Setting up ip1
I0526 07:32:42.852808 23331 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:32:42.852823 23331 net.cpp:165] Memory required for data: 15759560
I0526 07:32:42.852851 23331 layer_factory.hpp:77] Creating layer relu5
I0526 07:32:42.852881 23331 net.cpp:106] Creating Layer relu5
I0526 07:32:42.852895 23331 net.cpp:454] relu5 <- ip1
I0526 07:32:42.852911 23331 net.cpp:397] relu5 -> ip1 (in-place)
I0526 07:32:42.853289 23331 net.cpp:150] Setting up relu5
I0526 07:32:42.853309 23331 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:32:42.853322 23331 net.cpp:165] Memory required for data: 15767400
I0526 07:32:42.853337 23331 layer_factory.hpp:77] Creating layer drop1
I0526 07:32:42.853366 23331 net.cpp:106] Creating Layer drop1
I0526 07:32:42.853380 23331 net.cpp:454] drop1 <- ip1
I0526 07:32:42.853396 23331 net.cpp:397] drop1 -> ip1 (in-place)
I0526 07:32:42.853454 23331 net.cpp:150] Setting up drop1
I0526 07:32:42.853471 23331 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:32:42.853483 23331 net.cpp:165] Memory required for data: 15775240
I0526 07:32:42.853497 23331 layer_factory.hpp:77] Creating layer ip2
I0526 07:32:42.853515 23331 net.cpp:106] Creating Layer ip2
I0526 07:32:42.853528 23331 net.cpp:454] ip2 <- ip1
I0526 07:32:42.853551 23331 net.cpp:411] ip2 -> ip2
I0526 07:32:42.854048 23331 net.cpp:150] Setting up ip2
I0526 07:32:42.854068 23331 net.cpp:157] Top shape: 10 98 (980)
I0526 07:32:42.854080 23331 net.cpp:165] Memory required for data: 15779160
I0526 07:32:42.854101 23331 layer_factory.hpp:77] Creating layer relu6
I0526 07:32:42.854136 23331 net.cpp:106] Creating Layer relu6
I0526 07:32:42.854151 23331 net.cpp:454] relu6 <- ip2
I0526 07:32:42.854166 23331 net.cpp:397] relu6 -> ip2 (in-place)
I0526 07:32:42.854739 23331 net.cpp:150] Setting up relu6
I0526 07:32:42.854763 23331 net.cpp:157] Top shape: 10 98 (980)
I0526 07:32:42.854776 23331 net.cpp:165] Memory required for data: 15783080
I0526 07:32:42.854789 23331 layer_factory.hpp:77] Creating layer drop2
I0526 07:32:42.854809 23331 net.cpp:106] Creating Layer drop2
I0526 07:32:42.854830 23331 net.cpp:454] drop2 <- ip2
I0526 07:32:42.854846 23331 net.cpp:397] drop2 -> ip2 (in-place)
I0526 07:32:42.854897 23331 net.cpp:150] Setting up drop2
I0526 07:32:42.854920 23331 net.cpp:157] Top shape: 10 98 (980)
I0526 07:32:42.854933 23331 net.cpp:165] Memory required for data: 15787000
I0526 07:32:42.854946 23331 layer_factory.hpp:77] Creating layer ip3
I0526 07:32:42.854964 23331 net.cpp:106] Creating Layer ip3
I0526 07:32:42.854979 23331 net.cpp:454] ip3 <- ip2
I0526 07:32:42.855000 23331 net.cpp:411] ip3 -> ip3
I0526 07:32:42.855234 23331 net.cpp:150] Setting up ip3
I0526 07:32:42.855253 23331 net.cpp:157] Top shape: 10 11 (110)
I0526 07:32:42.855267 23331 net.cpp:165] Memory required for data: 15787440
I0526 07:32:42.855288 23331 layer_factory.hpp:77] Creating layer drop3
I0526 07:32:42.855310 23331 net.cpp:106] Creating Layer drop3
I0526 07:32:42.855324 23331 net.cpp:454] drop3 <- ip3
I0526 07:32:42.855340 23331 net.cpp:397] drop3 -> ip3 (in-place)
I0526 07:32:42.855387 23331 net.cpp:150] Setting up drop3
I0526 07:32:42.855411 23331 net.cpp:157] Top shape: 10 11 (110)
I0526 07:32:42.855428 23331 net.cpp:165] Memory required for data: 15787880
I0526 07:32:42.855440 23331 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 07:32:42.855459 23331 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 07:32:42.855471 23331 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 07:32:42.855494 23331 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 07:32:42.855512 23331 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 07:32:42.855600 23331 net.cpp:150] Setting up ip3_drop3_0_split
I0526 07:32:42.855623 23331 net.cpp:157] Top shape: 10 11 (110)
I0526 07:32:42.855639 23331 net.cpp:157] Top shape: 10 11 (110)
I0526 07:32:42.855654 23331 net.cpp:165] Memory required for data: 15788760
I0526 07:32:42.855665 23331 layer_factory.hpp:77] Creating layer accuracy
I0526 07:32:42.855700 23331 net.cpp:106] Creating Layer accuracy
I0526 07:32:42.855713 23331 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 07:32:42.855736 23331 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 07:32:42.855753 23331 net.cpp:411] accuracy -> accuracy
I0526 07:32:42.855782 23331 net.cpp:150] Setting up accuracy
I0526 07:32:42.855797 23331 net.cpp:157] Top shape: (1)
I0526 07:32:42.855815 23331 net.cpp:165] Memory required for data: 15788764
I0526 07:32:42.855829 23331 layer_factory.hpp:77] Creating layer loss
I0526 07:32:42.855849 23331 net.cpp:106] Creating Layer loss
I0526 07:32:42.855862 23331 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 07:32:42.855875 23331 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 07:32:42.855893 23331 net.cpp:411] loss -> loss
I0526 07:32:42.855921 23331 layer_factory.hpp:77] Creating layer loss
I0526 07:32:42.856420 23331 net.cpp:150] Setting up loss
I0526 07:32:42.856441 23331 net.cpp:157] Top shape: (1)
I0526 07:32:42.856452 23331 net.cpp:160]     with loss weight 1
I0526 07:32:42.856478 23331 net.cpp:165] Memory required for data: 15788768
I0526 07:32:42.856498 23331 net.cpp:226] loss needs backward computation.
I0526 07:32:42.856514 23331 net.cpp:228] accuracy does not need backward computation.
I0526 07:32:42.856531 23331 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 07:32:42.856545 23331 net.cpp:226] drop3 needs backward computation.
I0526 07:32:42.856557 23331 net.cpp:226] ip3 needs backward computation.
I0526 07:32:42.856572 23331 net.cpp:226] drop2 needs backward computation.
I0526 07:32:42.856585 23331 net.cpp:226] relu6 needs backward computation.
I0526 07:32:42.856612 23331 net.cpp:226] ip2 needs backward computation.
I0526 07:32:42.856626 23331 net.cpp:226] drop1 needs backward computation.
I0526 07:32:42.856638 23331 net.cpp:226] relu5 needs backward computation.
I0526 07:32:42.856649 23331 net.cpp:226] ip1 needs backward computation.
I0526 07:32:42.856665 23331 net.cpp:226] pool4 needs backward computation.
I0526 07:32:42.856678 23331 net.cpp:226] relu4 needs backward computation.
I0526 07:32:42.856696 23331 net.cpp:226] conv4 needs backward computation.
I0526 07:32:42.856710 23331 net.cpp:226] pool3 needs backward computation.
I0526 07:32:42.856726 23331 net.cpp:226] relu3 needs backward computation.
I0526 07:32:42.856739 23331 net.cpp:226] conv3 needs backward computation.
I0526 07:32:42.856752 23331 net.cpp:226] pool2 needs backward computation.
I0526 07:32:42.856765 23331 net.cpp:226] relu2 needs backward computation.
I0526 07:32:42.856780 23331 net.cpp:226] conv2 needs backward computation.
I0526 07:32:42.856799 23331 net.cpp:226] pool1 needs backward computation.
I0526 07:32:42.856812 23331 net.cpp:226] relu1 needs backward computation.
I0526 07:32:42.856825 23331 net.cpp:226] conv1 needs backward computation.
I0526 07:32:42.856840 23331 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 07:32:42.856853 23331 net.cpp:228] data_hdf5 does not need backward computation.
I0526 07:32:42.856865 23331 net.cpp:270] This network produces output accuracy
I0526 07:32:42.856880 23331 net.cpp:270] This network produces output loss
I0526 07:32:42.856911 23331 net.cpp:283] Network initialization done.
I0526 07:32:42.857048 23331 solver.cpp:60] Solver scaffolding done.
I0526 07:32:42.858192 23331 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_450000.solverstate
I0526 07:32:43.168059 23331 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 07:32:43.173555 23331 caffe.cpp:212] Starting Optimization
I0526 07:32:43.173601 23331 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 07:32:43.173624 23331 solver.cpp:289] Learning Rate Policy: fixed
I0526 07:32:43.174890 23331 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 07:33:43.785254 23331 solver.cpp:409]     Test net output #0: accuracy = 0.894169
I0526 07:33:43.785426 23331 solver.cpp:409]     Test net output #1: loss = 0.338401 (* 1 = 0.338401 loss)
I0526 07:33:43.803310 23331 solver.cpp:237] Iteration 450000, loss = 1.21898
I0526 07:33:43.803349 23331 solver.cpp:253]     Train net output #0: loss = 1.21898 (* 1 = 1.21898 loss)
I0526 07:33:43.803370 23331 sgd_solver.cpp:106] Iteration 450000, lr = 0.0035
I0526 07:34:00.588300 23331 solver.cpp:237] Iteration 451500, loss = 1.64578
I0526 07:34:00.588341 23331 solver.cpp:253]     Train net output #0: loss = 1.64578 (* 1 = 1.64578 loss)
I0526 07:34:00.588359 23331 sgd_solver.cpp:106] Iteration 451500, lr = 0.0035
I0526 07:34:17.282657 23331 solver.cpp:237] Iteration 453000, loss = 1.39459
I0526 07:34:17.282829 23331 solver.cpp:253]     Train net output #0: loss = 1.39458 (* 1 = 1.39458 loss)
I0526 07:34:17.282845 23331 sgd_solver.cpp:106] Iteration 453000, lr = 0.0035
I0526 07:34:34.003363 23331 solver.cpp:237] Iteration 454500, loss = 1.25855
I0526 07:34:34.003430 23331 solver.cpp:253]     Train net output #0: loss = 1.25855 (* 1 = 1.25855 loss)
I0526 07:34:34.003448 23331 sgd_solver.cpp:106] Iteration 454500, lr = 0.0035
I0526 07:34:51.214098 23331 solver.cpp:237] Iteration 456000, loss = 0.809298
I0526 07:34:51.214242 23331 solver.cpp:253]     Train net output #0: loss = 0.809296 (* 1 = 0.809296 loss)
I0526 07:34:51.214259 23331 sgd_solver.cpp:106] Iteration 456000, lr = 0.0035
I0526 07:35:08.011061 23331 solver.cpp:237] Iteration 457500, loss = 0.881804
I0526 07:35:08.011119 23331 solver.cpp:253]     Train net output #0: loss = 0.881802 (* 1 = 0.881802 loss)
I0526 07:35:08.011137 23331 sgd_solver.cpp:106] Iteration 457500, lr = 0.0035
I0526 07:35:24.622812 23331 solver.cpp:237] Iteration 459000, loss = 1.7339
I0526 07:35:24.622972 23331 solver.cpp:253]     Train net output #0: loss = 1.73389 (* 1 = 1.73389 loss)
I0526 07:35:24.622989 23331 sgd_solver.cpp:106] Iteration 459000, lr = 0.0035
I0526 07:36:03.364771 23331 solver.cpp:237] Iteration 460500, loss = 1.20401
I0526 07:36:03.364940 23331 solver.cpp:253]     Train net output #0: loss = 1.20401 (* 1 = 1.20401 loss)
I0526 07:36:03.364959 23331 sgd_solver.cpp:106] Iteration 460500, lr = 0.0035
I0526 07:36:20.307845 23331 solver.cpp:237] Iteration 462000, loss = 0.824545
I0526 07:36:20.307904 23331 solver.cpp:253]     Train net output #0: loss = 0.824543 (* 1 = 0.824543 loss)
I0526 07:36:20.307922 23331 sgd_solver.cpp:106] Iteration 462000, lr = 0.0035
I0526 07:36:37.521569 23331 solver.cpp:237] Iteration 463500, loss = 1.66722
I0526 07:36:37.521724 23331 solver.cpp:253]     Train net output #0: loss = 1.66722 (* 1 = 1.66722 loss)
I0526 07:36:37.521742 23331 sgd_solver.cpp:106] Iteration 463500, lr = 0.0035
I0526 07:36:54.547646 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_465000.caffemodel
I0526 07:36:54.593646 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_465000.solverstate
I0526 07:36:54.622638 23331 solver.cpp:237] Iteration 465000, loss = 1.07708
I0526 07:36:54.622695 23331 solver.cpp:253]     Train net output #0: loss = 1.07708 (* 1 = 1.07708 loss)
I0526 07:36:54.622714 23331 sgd_solver.cpp:106] Iteration 465000, lr = 0.0035
I0526 07:37:11.736100 23331 solver.cpp:237] Iteration 466500, loss = 1.39644
I0526 07:37:11.736265 23331 solver.cpp:253]     Train net output #0: loss = 1.39644 (* 1 = 1.39644 loss)
I0526 07:37:11.736284 23331 sgd_solver.cpp:106] Iteration 466500, lr = 0.0035
I0526 07:37:28.719825 23331 solver.cpp:237] Iteration 468000, loss = 0.899316
I0526 07:37:28.719883 23331 solver.cpp:253]     Train net output #0: loss = 0.899315 (* 1 = 0.899315 loss)
I0526 07:37:28.719908 23331 sgd_solver.cpp:106] Iteration 468000, lr = 0.0035
I0526 07:37:45.942073 23331 solver.cpp:237] Iteration 469500, loss = 1.40873
I0526 07:37:45.942217 23331 solver.cpp:253]     Train net output #0: loss = 1.40873 (* 1 = 1.40873 loss)
I0526 07:37:45.942234 23331 sgd_solver.cpp:106] Iteration 469500, lr = 0.0035
I0526 07:38:24.992261 23331 solver.cpp:237] Iteration 471000, loss = 0.958686
I0526 07:38:24.992441 23331 solver.cpp:253]     Train net output #0: loss = 0.958685 (* 1 = 0.958685 loss)
I0526 07:38:24.992458 23331 sgd_solver.cpp:106] Iteration 471000, lr = 0.0035
I0526 07:38:41.825021 23331 solver.cpp:237] Iteration 472500, loss = 1.02168
I0526 07:38:41.825075 23331 solver.cpp:253]     Train net output #0: loss = 1.02167 (* 1 = 1.02167 loss)
I0526 07:38:41.825093 23331 sgd_solver.cpp:106] Iteration 472500, lr = 0.0035
I0526 07:38:58.476873 23331 solver.cpp:237] Iteration 474000, loss = 1.7678
I0526 07:38:58.477021 23331 solver.cpp:253]     Train net output #0: loss = 1.7678 (* 1 = 1.7678 loss)
I0526 07:38:58.477038 23331 sgd_solver.cpp:106] Iteration 474000, lr = 0.0035
I0526 07:39:15.417912 23331 solver.cpp:237] Iteration 475500, loss = 1.35838
I0526 07:39:15.417966 23331 solver.cpp:253]     Train net output #0: loss = 1.35838 (* 1 = 1.35838 loss)
I0526 07:39:15.417986 23331 sgd_solver.cpp:106] Iteration 475500, lr = 0.0035
I0526 07:39:32.592624 23331 solver.cpp:237] Iteration 477000, loss = 1.7002
I0526 07:39:32.592787 23331 solver.cpp:253]     Train net output #0: loss = 1.7002 (* 1 = 1.7002 loss)
I0526 07:39:32.592805 23331 sgd_solver.cpp:106] Iteration 477000, lr = 0.0035
I0526 07:39:49.549396 23331 solver.cpp:237] Iteration 478500, loss = 1.34134
I0526 07:39:49.549437 23331 solver.cpp:253]     Train net output #0: loss = 1.34134 (* 1 = 1.34134 loss)
I0526 07:39:49.549455 23331 sgd_solver.cpp:106] Iteration 478500, lr = 0.0035
I0526 07:40:06.689390 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_480000.caffemodel
I0526 07:40:06.735677 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_480000.solverstate
I0526 07:40:06.763913 23331 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 07:41:06.121139 23331 solver.cpp:409]     Test net output #0: accuracy = 0.898624
I0526 07:41:06.121299 23331 solver.cpp:409]     Test net output #1: loss = 0.320699 (* 1 = 0.320699 loss)
I0526 07:41:28.240389 23331 solver.cpp:237] Iteration 480000, loss = 0.988392
I0526 07:41:28.240453 23331 solver.cpp:253]     Train net output #0: loss = 0.988391 (* 1 = 0.988391 loss)
I0526 07:41:28.240473 23331 sgd_solver.cpp:106] Iteration 480000, lr = 0.0035
I0526 07:41:44.999193 23331 solver.cpp:237] Iteration 481500, loss = 1.30148
I0526 07:41:44.999362 23331 solver.cpp:253]     Train net output #0: loss = 1.30148 (* 1 = 1.30148 loss)
I0526 07:41:44.999379 23331 sgd_solver.cpp:106] Iteration 481500, lr = 0.0035
I0526 07:42:01.657716 23331 solver.cpp:237] Iteration 483000, loss = 1.23858
I0526 07:42:01.657775 23331 solver.cpp:253]     Train net output #0: loss = 1.23858 (* 1 = 1.23858 loss)
I0526 07:42:01.657801 23331 sgd_solver.cpp:106] Iteration 483000, lr = 0.0035
I0526 07:42:18.547984 23331 solver.cpp:237] Iteration 484500, loss = 0.74244
I0526 07:42:18.548131 23331 solver.cpp:253]     Train net output #0: loss = 0.742437 (* 1 = 0.742437 loss)
I0526 07:42:18.548148 23331 sgd_solver.cpp:106] Iteration 484500, lr = 0.0035
I0526 07:42:35.324137 23331 solver.cpp:237] Iteration 486000, loss = 1.64739
I0526 07:42:35.324194 23331 solver.cpp:253]     Train net output #0: loss = 1.64739 (* 1 = 1.64739 loss)
I0526 07:42:35.324211 23331 sgd_solver.cpp:106] Iteration 486000, lr = 0.0035
I0526 07:42:51.987076 23331 solver.cpp:237] Iteration 487500, loss = 0.92352
I0526 07:42:51.987241 23331 solver.cpp:253]     Train net output #0: loss = 0.923518 (* 1 = 0.923518 loss)
I0526 07:42:51.987260 23331 sgd_solver.cpp:106] Iteration 487500, lr = 0.0035
I0526 07:43:08.961258 23331 solver.cpp:237] Iteration 489000, loss = 1.05857
I0526 07:43:08.961297 23331 solver.cpp:253]     Train net output #0: loss = 1.05856 (* 1 = 1.05856 loss)
I0526 07:43:08.961330 23331 sgd_solver.cpp:106] Iteration 489000, lr = 0.0035
I0526 07:43:47.923171 23331 solver.cpp:237] Iteration 490500, loss = 1.36685
I0526 07:43:47.923354 23331 solver.cpp:253]     Train net output #0: loss = 1.36684 (* 1 = 1.36684 loss)
I0526 07:43:47.923373 23331 sgd_solver.cpp:106] Iteration 490500, lr = 0.0035
I0526 07:44:04.540102 23331 solver.cpp:237] Iteration 492000, loss = 1.25553
I0526 07:44:04.540139 23331 solver.cpp:253]     Train net output #0: loss = 1.25552 (* 1 = 1.25552 loss)
I0526 07:44:04.540161 23331 sgd_solver.cpp:106] Iteration 492000, lr = 0.0035
I0526 07:44:21.488875 23331 solver.cpp:237] Iteration 493500, loss = 1.29521
I0526 07:44:21.489032 23331 solver.cpp:253]     Train net output #0: loss = 1.29521 (* 1 = 1.29521 loss)
I0526 07:44:21.489048 23331 sgd_solver.cpp:106] Iteration 493500, lr = 0.0035
I0526 07:44:38.557059 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_495000.caffemodel
I0526 07:44:38.604805 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_495000.solverstate
I0526 07:44:38.636080 23331 solver.cpp:237] Iteration 495000, loss = 1.18725
I0526 07:44:38.636145 23331 solver.cpp:253]     Train net output #0: loss = 1.18725 (* 1 = 1.18725 loss)
I0526 07:44:38.636162 23331 sgd_solver.cpp:106] Iteration 495000, lr = 0.0035
I0526 07:44:55.862979 23331 solver.cpp:237] Iteration 496500, loss = 2.33782
I0526 07:44:55.863131 23331 solver.cpp:253]     Train net output #0: loss = 2.33782 (* 1 = 2.33782 loss)
I0526 07:44:55.863147 23331 sgd_solver.cpp:106] Iteration 496500, lr = 0.0035
I0526 07:45:12.809912 23331 solver.cpp:237] Iteration 498000, loss = 1.28438
I0526 07:45:12.809965 23331 solver.cpp:253]     Train net output #0: loss = 1.28438 (* 1 = 1.28438 loss)
I0526 07:45:12.809985 23331 sgd_solver.cpp:106] Iteration 498000, lr = 0.0035
I0526 07:45:29.593662 23331 solver.cpp:237] Iteration 499500, loss = 0.979824
I0526 07:45:29.593827 23331 solver.cpp:253]     Train net output #0: loss = 0.979823 (* 1 = 0.979823 loss)
I0526 07:45:29.593844 23331 sgd_solver.cpp:106] Iteration 499500, lr = 0.0035
I0526 07:46:08.361054 23331 solver.cpp:237] Iteration 501000, loss = 1.58689
I0526 07:46:08.361220 23331 solver.cpp:253]     Train net output #0: loss = 1.58689 (* 1 = 1.58689 loss)
I0526 07:46:08.361238 23331 sgd_solver.cpp:106] Iteration 501000, lr = 0.0035
I0526 07:46:25.280429 23331 solver.cpp:237] Iteration 502500, loss = 1.59042
I0526 07:46:25.280488 23331 solver.cpp:253]     Train net output #0: loss = 1.59042 (* 1 = 1.59042 loss)
I0526 07:46:25.280505 23331 sgd_solver.cpp:106] Iteration 502500, lr = 0.0035
I0526 07:46:42.186985 23331 solver.cpp:237] Iteration 504000, loss = 0.845725
I0526 07:46:42.187168 23331 solver.cpp:253]     Train net output #0: loss = 0.845724 (* 1 = 0.845724 loss)
I0526 07:46:42.187186 23331 sgd_solver.cpp:106] Iteration 504000, lr = 0.0035
I0526 07:46:58.962317 23331 solver.cpp:237] Iteration 505500, loss = 0.855023
I0526 07:46:58.962357 23331 solver.cpp:253]     Train net output #0: loss = 0.855021 (* 1 = 0.855021 loss)
I0526 07:46:58.962375 23331 sgd_solver.cpp:106] Iteration 505500, lr = 0.0035
I0526 07:47:15.873237 23331 solver.cpp:237] Iteration 507000, loss = 1.68778
I0526 07:47:15.873399 23331 solver.cpp:253]     Train net output #0: loss = 1.68778 (* 1 = 1.68778 loss)
I0526 07:47:15.873416 23331 sgd_solver.cpp:106] Iteration 507000, lr = 0.0035
I0526 07:47:32.715488 23331 solver.cpp:237] Iteration 508500, loss = 0.646326
I0526 07:47:32.715548 23331 solver.cpp:253]     Train net output #0: loss = 0.646325 (* 1 = 0.646325 loss)
I0526 07:47:32.715572 23331 sgd_solver.cpp:106] Iteration 508500, lr = 0.0035
I0526 07:47:49.477001 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_510000.caffemodel
I0526 07:47:49.526199 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_510000.solverstate
I0526 07:47:49.554186 23331 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 07:49:09.902402 23331 solver.cpp:409]     Test net output #0: accuracy = 0.886849
I0526 07:49:09.902573 23331 solver.cpp:409]     Test net output #1: loss = 0.389948 (* 1 = 0.389948 loss)
I0526 07:49:32.081889 23331 solver.cpp:237] Iteration 510000, loss = 1.01253
I0526 07:49:32.081956 23331 solver.cpp:253]     Train net output #0: loss = 1.01253 (* 1 = 1.01253 loss)
I0526 07:49:32.081979 23331 sgd_solver.cpp:106] Iteration 510000, lr = 0.0035
I0526 07:49:48.698462 23331 solver.cpp:237] Iteration 511500, loss = 0.570608
I0526 07:49:48.698618 23331 solver.cpp:253]     Train net output #0: loss = 0.570606 (* 1 = 0.570606 loss)
I0526 07:49:48.698635 23331 sgd_solver.cpp:106] Iteration 511500, lr = 0.0035
I0526 07:50:05.513013 23331 solver.cpp:237] Iteration 513000, loss = 1.36381
I0526 07:50:05.513068 23331 solver.cpp:253]     Train net output #0: loss = 1.36381 (* 1 = 1.36381 loss)
I0526 07:50:05.513087 23331 sgd_solver.cpp:106] Iteration 513000, lr = 0.0035
I0526 07:50:22.435047 23331 solver.cpp:237] Iteration 514500, loss = 1.24153
I0526 07:50:22.435214 23331 solver.cpp:253]     Train net output #0: loss = 1.24152 (* 1 = 1.24152 loss)
I0526 07:50:22.435230 23331 sgd_solver.cpp:106] Iteration 514500, lr = 0.0035
I0526 07:50:39.078915 23331 solver.cpp:237] Iteration 516000, loss = 0.60273
I0526 07:50:39.078955 23331 solver.cpp:253]     Train net output #0: loss = 0.602728 (* 1 = 0.602728 loss)
I0526 07:50:39.078972 23331 sgd_solver.cpp:106] Iteration 516000, lr = 0.0035
I0526 07:50:55.832376 23331 solver.cpp:237] Iteration 517500, loss = 1.23945
I0526 07:50:55.832541 23331 solver.cpp:253]     Train net output #0: loss = 1.23945 (* 1 = 1.23945 loss)
I0526 07:50:55.832558 23331 sgd_solver.cpp:106] Iteration 517500, lr = 0.0035
I0526 07:51:12.714561 23331 solver.cpp:237] Iteration 519000, loss = 1.10043
I0526 07:51:12.714618 23331 solver.cpp:253]     Train net output #0: loss = 1.10043 (* 1 = 1.10043 loss)
I0526 07:51:12.714645 23331 sgd_solver.cpp:106] Iteration 519000, lr = 0.0035
I0526 07:51:52.194048 23331 solver.cpp:237] Iteration 520500, loss = 1.62308
I0526 07:51:52.194226 23331 solver.cpp:253]     Train net output #0: loss = 1.62307 (* 1 = 1.62307 loss)
I0526 07:51:52.194245 23331 sgd_solver.cpp:106] Iteration 520500, lr = 0.0035
I0526 07:52:09.223172 23331 solver.cpp:237] Iteration 522000, loss = 1.11126
I0526 07:52:09.223230 23331 solver.cpp:253]     Train net output #0: loss = 1.11126 (* 1 = 1.11126 loss)
I0526 07:52:09.223249 23331 sgd_solver.cpp:106] Iteration 522000, lr = 0.0035
I0526 07:52:26.148324 23331 solver.cpp:237] Iteration 523500, loss = 1.38963
I0526 07:52:26.148483 23331 solver.cpp:253]     Train net output #0: loss = 1.38963 (* 1 = 1.38963 loss)
I0526 07:52:26.148500 23331 sgd_solver.cpp:106] Iteration 523500, lr = 0.0035
I0526 07:52:42.778372 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_525000.caffemodel
I0526 07:52:42.826643 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_525000.solverstate
I0526 07:52:42.857867 23331 solver.cpp:237] Iteration 525000, loss = 0.743655
I0526 07:52:42.857926 23331 solver.cpp:253]     Train net output #0: loss = 0.743651 (* 1 = 0.743651 loss)
I0526 07:52:42.857952 23331 sgd_solver.cpp:106] Iteration 525000, lr = 0.0035
I0526 07:52:59.483250 23331 solver.cpp:237] Iteration 526500, loss = 1.40992
I0526 07:52:59.483419 23331 solver.cpp:253]     Train net output #0: loss = 1.40992 (* 1 = 1.40992 loss)
I0526 07:52:59.483443 23331 sgd_solver.cpp:106] Iteration 526500, lr = 0.0035
I0526 07:53:16.111919 23331 solver.cpp:237] Iteration 528000, loss = 1.16066
I0526 07:53:16.111977 23331 solver.cpp:253]     Train net output #0: loss = 1.16066 (* 1 = 1.16066 loss)
I0526 07:53:16.111996 23331 sgd_solver.cpp:106] Iteration 528000, lr = 0.0035
I0526 07:53:33.032418 23331 solver.cpp:237] Iteration 529500, loss = 0.775258
I0526 07:53:33.032579 23331 solver.cpp:253]     Train net output #0: loss = 0.775255 (* 1 = 0.775255 loss)
I0526 07:53:33.032596 23331 sgd_solver.cpp:106] Iteration 529500, lr = 0.0035
I0526 07:54:12.076962 23331 solver.cpp:237] Iteration 531000, loss = 0.778358
I0526 07:54:12.077139 23331 solver.cpp:253]     Train net output #0: loss = 0.778355 (* 1 = 0.778355 loss)
I0526 07:54:12.077157 23331 sgd_solver.cpp:106] Iteration 531000, lr = 0.0035
I0526 07:54:29.136628 23331 solver.cpp:237] Iteration 532500, loss = 1.28163
I0526 07:54:29.136667 23331 solver.cpp:253]     Train net output #0: loss = 1.28163 (* 1 = 1.28163 loss)
I0526 07:54:29.136687 23331 sgd_solver.cpp:106] Iteration 532500, lr = 0.0035
I0526 07:54:45.801859 23331 solver.cpp:237] Iteration 534000, loss = 1.26811
I0526 07:54:45.802019 23331 solver.cpp:253]     Train net output #0: loss = 1.26811 (* 1 = 1.26811 loss)
I0526 07:54:45.802037 23331 sgd_solver.cpp:106] Iteration 534000, lr = 0.0035
I0526 07:55:02.479305 23331 solver.cpp:237] Iteration 535500, loss = 0.982213
I0526 07:55:02.479362 23331 solver.cpp:253]     Train net output #0: loss = 0.982209 (* 1 = 0.982209 loss)
I0526 07:55:02.479378 23331 sgd_solver.cpp:106] Iteration 535500, lr = 0.0035
I0526 07:55:19.296483 23331 solver.cpp:237] Iteration 537000, loss = 1.71726
I0526 07:55:19.296633 23331 solver.cpp:253]     Train net output #0: loss = 1.71726 (* 1 = 1.71726 loss)
I0526 07:55:19.296648 23331 sgd_solver.cpp:106] Iteration 537000, lr = 0.0035
I0526 07:55:36.448997 23331 solver.cpp:237] Iteration 538500, loss = 1.04758
I0526 07:55:36.449050 23331 solver.cpp:253]     Train net output #0: loss = 1.04758 (* 1 = 1.04758 loss)
I0526 07:55:36.449067 23331 sgd_solver.cpp:106] Iteration 538500, lr = 0.0035
I0526 07:55:53.396692 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_540000.caffemodel
I0526 07:55:53.442724 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_540000.solverstate
I0526 07:55:53.468449 23331 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 07:56:52.877882 23331 solver.cpp:409]     Test net output #0: accuracy = 0.891877
I0526 07:56:52.878049 23331 solver.cpp:409]     Test net output #1: loss = 0.384461 (* 1 = 0.384461 loss)
I0526 07:57:15.073593 23331 solver.cpp:237] Iteration 540000, loss = 0.801002
I0526 07:57:15.073657 23331 solver.cpp:253]     Train net output #0: loss = 0.801 (* 1 = 0.801 loss)
I0526 07:57:15.073683 23331 sgd_solver.cpp:106] Iteration 540000, lr = 0.0035
I0526 07:57:31.863978 23331 solver.cpp:237] Iteration 541500, loss = 0.937599
I0526 07:57:31.864153 23331 solver.cpp:253]     Train net output #0: loss = 0.937598 (* 1 = 0.937598 loss)
I0526 07:57:31.864171 23331 sgd_solver.cpp:106] Iteration 541500, lr = 0.0035
I0526 07:57:48.508121 23331 solver.cpp:237] Iteration 543000, loss = 1.60931
I0526 07:57:48.508159 23331 solver.cpp:253]     Train net output #0: loss = 1.60931 (* 1 = 1.60931 loss)
I0526 07:57:48.508177 23331 sgd_solver.cpp:106] Iteration 543000, lr = 0.0035
I0526 07:58:05.144274 23331 solver.cpp:237] Iteration 544500, loss = 1.31906
I0526 07:58:05.144439 23331 solver.cpp:253]     Train net output #0: loss = 1.31906 (* 1 = 1.31906 loss)
I0526 07:58:05.144455 23331 sgd_solver.cpp:106] Iteration 544500, lr = 0.0035
I0526 07:58:21.971765 23331 solver.cpp:237] Iteration 546000, loss = 0.949351
I0526 07:58:21.971822 23331 solver.cpp:253]     Train net output #0: loss = 0.949349 (* 1 = 0.949349 loss)
I0526 07:58:21.971838 23331 sgd_solver.cpp:106] Iteration 546000, lr = 0.0035
I0526 07:58:39.174814 23331 solver.cpp:237] Iteration 547500, loss = 1.26251
I0526 07:58:39.174981 23331 solver.cpp:253]     Train net output #0: loss = 1.2625 (* 1 = 1.2625 loss)
I0526 07:58:39.174998 23331 sgd_solver.cpp:106] Iteration 547500, lr = 0.0035
I0526 07:58:56.278488 23331 solver.cpp:237] Iteration 549000, loss = 1.13165
I0526 07:58:56.278545 23331 solver.cpp:253]     Train net output #0: loss = 1.13165 (* 1 = 1.13165 loss)
I0526 07:58:56.278563 23331 sgd_solver.cpp:106] Iteration 549000, lr = 0.0035
I0526 07:59:35.477618 23331 solver.cpp:237] Iteration 550500, loss = 0.745381
I0526 07:59:35.477793 23331 solver.cpp:253]     Train net output #0: loss = 0.74538 (* 1 = 0.74538 loss)
I0526 07:59:35.477813 23331 sgd_solver.cpp:106] Iteration 550500, lr = 0.0035
I0526 07:59:52.428637 23331 solver.cpp:237] Iteration 552000, loss = 0.646181
I0526 07:59:52.428678 23331 solver.cpp:253]     Train net output #0: loss = 0.64618 (* 1 = 0.64618 loss)
I0526 07:59:52.428701 23331 sgd_solver.cpp:106] Iteration 552000, lr = 0.0035
I0526 08:00:09.594656 23331 solver.cpp:237] Iteration 553500, loss = 1.14485
I0526 08:00:09.594825 23331 solver.cpp:253]     Train net output #0: loss = 1.14485 (* 1 = 1.14485 loss)
I0526 08:00:09.594842 23331 sgd_solver.cpp:106] Iteration 553500, lr = 0.0035
I0526 08:00:26.737625 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_555000.caffemodel
I0526 08:00:26.783478 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_555000.solverstate
I0526 08:00:26.812402 23331 solver.cpp:237] Iteration 555000, loss = 1.24229
I0526 08:00:26.812459 23331 solver.cpp:253]     Train net output #0: loss = 1.24229 (* 1 = 1.24229 loss)
I0526 08:00:26.812484 23331 sgd_solver.cpp:106] Iteration 555000, lr = 0.0035
I0526 08:00:43.888428 23331 solver.cpp:237] Iteration 556500, loss = 0.849937
I0526 08:00:43.888591 23331 solver.cpp:253]     Train net output #0: loss = 0.849937 (* 1 = 0.849937 loss)
I0526 08:00:43.888607 23331 sgd_solver.cpp:106] Iteration 556500, lr = 0.0035
I0526 08:01:00.557482 23331 solver.cpp:237] Iteration 558000, loss = 1.61147
I0526 08:01:00.557539 23331 solver.cpp:253]     Train net output #0: loss = 1.61147 (* 1 = 1.61147 loss)
I0526 08:01:00.557556 23331 sgd_solver.cpp:106] Iteration 558000, lr = 0.0035
I0526 08:01:17.361302 23331 solver.cpp:237] Iteration 559500, loss = 0.601354
I0526 08:01:17.361474 23331 solver.cpp:253]     Train net output #0: loss = 0.601354 (* 1 = 0.601354 loss)
I0526 08:01:17.361492 23331 sgd_solver.cpp:106] Iteration 559500, lr = 0.0035
I0526 08:01:56.578176 23331 solver.cpp:237] Iteration 561000, loss = 1.11191
I0526 08:01:56.578367 23331 solver.cpp:253]     Train net output #0: loss = 1.11191 (* 1 = 1.11191 loss)
I0526 08:01:56.578385 23331 sgd_solver.cpp:106] Iteration 561000, lr = 0.0035
I0526 08:02:13.561321 23331 solver.cpp:237] Iteration 562500, loss = 3.33881
I0526 08:02:13.561375 23331 solver.cpp:253]     Train net output #0: loss = 3.33881 (* 1 = 3.33881 loss)
I0526 08:02:13.561394 23331 sgd_solver.cpp:106] Iteration 562500, lr = 0.0035
I0526 08:02:30.576702 23331 solver.cpp:237] Iteration 564000, loss = 0.797814
I0526 08:02:30.576869 23331 solver.cpp:253]     Train net output #0: loss = 0.797814 (* 1 = 0.797814 loss)
I0526 08:02:30.576886 23331 sgd_solver.cpp:106] Iteration 564000, lr = 0.0035
I0526 08:02:47.794236 23331 solver.cpp:237] Iteration 565500, loss = 1.60841
I0526 08:02:47.794276 23331 solver.cpp:253]     Train net output #0: loss = 1.60841 (* 1 = 1.60841 loss)
I0526 08:02:47.794293 23331 sgd_solver.cpp:106] Iteration 565500, lr = 0.0035
I0526 08:03:04.866452 23331 solver.cpp:237] Iteration 567000, loss = 0.846536
I0526 08:03:04.866617 23331 solver.cpp:253]     Train net output #0: loss = 0.846536 (* 1 = 0.846536 loss)
I0526 08:03:04.866636 23331 sgd_solver.cpp:106] Iteration 567000, lr = 0.0035
I0526 08:03:21.891315 23331 solver.cpp:237] Iteration 568500, loss = 0.761724
I0526 08:03:21.891376 23331 solver.cpp:253]     Train net output #0: loss = 0.761725 (* 1 = 0.761725 loss)
I0526 08:03:21.891401 23331 sgd_solver.cpp:106] Iteration 568500, lr = 0.0035
I0526 08:03:38.818353 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_570000.caffemodel
I0526 08:03:38.868913 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_570000.solverstate
I0526 08:03:38.894529 23331 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 08:04:59.361253 23331 solver.cpp:409]     Test net output #0: accuracy = 0.888328
I0526 08:04:59.361433 23331 solver.cpp:409]     Test net output #1: loss = 0.348434 (* 1 = 0.348434 loss)
I0526 08:05:21.540076 23331 solver.cpp:237] Iteration 570000, loss = 1.5259
I0526 08:05:21.540138 23331 solver.cpp:253]     Train net output #0: loss = 1.5259 (* 1 = 1.5259 loss)
I0526 08:05:21.540156 23331 sgd_solver.cpp:106] Iteration 570000, lr = 0.0035
I0526 08:05:38.313753 23331 solver.cpp:237] Iteration 571500, loss = 0.849601
I0526 08:05:38.313912 23331 solver.cpp:253]     Train net output #0: loss = 0.849601 (* 1 = 0.849601 loss)
I0526 08:05:38.313930 23331 sgd_solver.cpp:106] Iteration 571500, lr = 0.0035
I0526 08:05:55.273041 23331 solver.cpp:237] Iteration 573000, loss = 1.20267
I0526 08:05:55.273097 23331 solver.cpp:253]     Train net output #0: loss = 1.20267 (* 1 = 1.20267 loss)
I0526 08:05:55.273115 23331 sgd_solver.cpp:106] Iteration 573000, lr = 0.0035
I0526 08:06:12.299073 23331 solver.cpp:237] Iteration 574500, loss = 0.77502
I0526 08:06:12.299243 23331 solver.cpp:253]     Train net output #0: loss = 0.77502 (* 1 = 0.77502 loss)
I0526 08:06:12.299262 23331 sgd_solver.cpp:106] Iteration 574500, lr = 0.0035
I0526 08:06:28.909380 23331 solver.cpp:237] Iteration 576000, loss = 1.1175
I0526 08:06:28.909420 23331 solver.cpp:253]     Train net output #0: loss = 1.11751 (* 1 = 1.11751 loss)
I0526 08:06:28.909436 23331 sgd_solver.cpp:106] Iteration 576000, lr = 0.0035
I0526 08:06:45.548611 23331 solver.cpp:237] Iteration 577500, loss = 1.32737
I0526 08:06:45.548779 23331 solver.cpp:253]     Train net output #0: loss = 1.32737 (* 1 = 1.32737 loss)
I0526 08:06:45.548795 23331 sgd_solver.cpp:106] Iteration 577500, lr = 0.0035
I0526 08:07:02.229161 23331 solver.cpp:237] Iteration 579000, loss = 0.403167
I0526 08:07:02.229217 23331 solver.cpp:253]     Train net output #0: loss = 0.403168 (* 1 = 0.403168 loss)
I0526 08:07:02.229246 23331 sgd_solver.cpp:106] Iteration 579000, lr = 0.0035
I0526 08:07:41.331953 23331 solver.cpp:237] Iteration 580500, loss = 1.15762
I0526 08:07:41.332134 23331 solver.cpp:253]     Train net output #0: loss = 1.15762 (* 1 = 1.15762 loss)
I0526 08:07:41.332151 23331 sgd_solver.cpp:106] Iteration 580500, lr = 0.0035
I0526 08:07:58.337884 23331 solver.cpp:237] Iteration 582000, loss = 0.84543
I0526 08:07:58.337940 23331 solver.cpp:253]     Train net output #0: loss = 0.845431 (* 1 = 0.845431 loss)
I0526 08:07:58.337960 23331 sgd_solver.cpp:106] Iteration 582000, lr = 0.0035
I0526 08:08:15.568379 23331 solver.cpp:237] Iteration 583500, loss = 1.06919
I0526 08:08:15.568526 23331 solver.cpp:253]     Train net output #0: loss = 1.06919 (* 1 = 1.06919 loss)
I0526 08:08:15.568543 23331 sgd_solver.cpp:106] Iteration 583500, lr = 0.0035
I0526 08:08:32.193775 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_585000.caffemodel
I0526 08:08:32.240767 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_585000.solverstate
I0526 08:08:32.271152 23331 solver.cpp:237] Iteration 585000, loss = 2.05666
I0526 08:08:32.271209 23331 solver.cpp:253]     Train net output #0: loss = 2.05666 (* 1 = 2.05666 loss)
I0526 08:08:32.271229 23331 sgd_solver.cpp:106] Iteration 585000, lr = 0.0035
I0526 08:08:48.925765 23331 solver.cpp:237] Iteration 586500, loss = 0.344753
I0526 08:08:48.925950 23331 solver.cpp:253]     Train net output #0: loss = 0.344755 (* 1 = 0.344755 loss)
I0526 08:08:48.925968 23331 sgd_solver.cpp:106] Iteration 586500, lr = 0.0035
I0526 08:09:05.574108 23331 solver.cpp:237] Iteration 588000, loss = 1.50821
I0526 08:09:05.574151 23331 solver.cpp:253]     Train net output #0: loss = 1.50821 (* 1 = 1.50821 loss)
I0526 08:09:05.574174 23331 sgd_solver.cpp:106] Iteration 588000, lr = 0.0035
I0526 08:09:22.406688 23331 solver.cpp:237] Iteration 589500, loss = 1.04876
I0526 08:09:22.406858 23331 solver.cpp:253]     Train net output #0: loss = 1.04876 (* 1 = 1.04876 loss)
I0526 08:09:22.406877 23331 sgd_solver.cpp:106] Iteration 589500, lr = 0.0035
I0526 08:10:01.492210 23331 solver.cpp:237] Iteration 591000, loss = 1.50784
I0526 08:10:01.492386 23331 solver.cpp:253]     Train net output #0: loss = 1.50784 (* 1 = 1.50784 loss)
I0526 08:10:01.492404 23331 sgd_solver.cpp:106] Iteration 591000, lr = 0.0035
I0526 08:10:18.594496 23331 solver.cpp:237] Iteration 592500, loss = 1.11316
I0526 08:10:18.594534 23331 solver.cpp:253]     Train net output #0: loss = 1.11317 (* 1 = 1.11317 loss)
I0526 08:10:18.594553 23331 sgd_solver.cpp:106] Iteration 592500, lr = 0.0035
I0526 08:10:35.294647 23331 solver.cpp:237] Iteration 594000, loss = 1.54398
I0526 08:10:35.294809 23331 solver.cpp:253]     Train net output #0: loss = 1.54398 (* 1 = 1.54398 loss)
I0526 08:10:35.294826 23331 sgd_solver.cpp:106] Iteration 594000, lr = 0.0035
I0526 08:10:52.166702 23331 solver.cpp:237] Iteration 595500, loss = 1.60079
I0526 08:10:52.166759 23331 solver.cpp:253]     Train net output #0: loss = 1.6008 (* 1 = 1.6008 loss)
I0526 08:10:52.166784 23331 sgd_solver.cpp:106] Iteration 595500, lr = 0.0035
I0526 08:11:09.361755 23331 solver.cpp:237] Iteration 597000, loss = 1.58946
I0526 08:11:09.361908 23331 solver.cpp:253]     Train net output #0: loss = 1.58946 (* 1 = 1.58946 loss)
I0526 08:11:09.361924 23331 sgd_solver.cpp:106] Iteration 597000, lr = 0.0035
I0526 08:11:26.351913 23331 solver.cpp:237] Iteration 598500, loss = 0.432841
I0526 08:11:26.351969 23331 solver.cpp:253]     Train net output #0: loss = 0.432844 (* 1 = 0.432844 loss)
I0526 08:11:26.351989 23331 sgd_solver.cpp:106] Iteration 598500, lr = 0.0035
I0526 08:11:43.229347 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_600000.caffemodel
I0526 08:11:43.276741 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_600000.solverstate
I0526 08:11:43.305337 23331 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 08:12:42.818435 23331 solver.cpp:409]     Test net output #0: accuracy = 0.897992
I0526 08:12:42.818609 23331 solver.cpp:409]     Test net output #1: loss = 0.331933 (* 1 = 0.331933 loss)
I0526 08:13:03.748109 23331 solver.cpp:237] Iteration 600000, loss = 0.882221
I0526 08:13:03.748175 23331 solver.cpp:253]     Train net output #0: loss = 0.882224 (* 1 = 0.882224 loss)
I0526 08:13:03.748194 23331 sgd_solver.cpp:106] Iteration 600000, lr = 0.0035
I0526 08:13:20.760591 23331 solver.cpp:237] Iteration 601500, loss = 0.565039
I0526 08:13:20.760766 23331 solver.cpp:253]     Train net output #0: loss = 0.565042 (* 1 = 0.565042 loss)
I0526 08:13:20.760787 23331 sgd_solver.cpp:106] Iteration 601500, lr = 0.0035
I0526 08:13:37.620998 23331 solver.cpp:237] Iteration 603000, loss = 0.971268
I0526 08:13:37.621037 23331 solver.cpp:253]     Train net output #0: loss = 0.971272 (* 1 = 0.971272 loss)
I0526 08:13:37.621055 23331 sgd_solver.cpp:106] Iteration 603000, lr = 0.0035
I0526 08:13:54.334553 23331 solver.cpp:237] Iteration 604500, loss = 0.822841
I0526 08:13:54.334736 23331 solver.cpp:253]     Train net output #0: loss = 0.822846 (* 1 = 0.822846 loss)
I0526 08:13:54.334753 23331 sgd_solver.cpp:106] Iteration 604500, lr = 0.0035
I0526 08:14:11.049269 23331 solver.cpp:237] Iteration 606000, loss = 1.21594
I0526 08:14:11.049327 23331 solver.cpp:253]     Train net output #0: loss = 1.21594 (* 1 = 1.21594 loss)
I0526 08:14:11.049353 23331 sgd_solver.cpp:106] Iteration 606000, lr = 0.0035
I0526 08:14:27.945035 23331 solver.cpp:237] Iteration 607500, loss = 0.820431
I0526 08:14:27.945194 23331 solver.cpp:253]     Train net output #0: loss = 0.820435 (* 1 = 0.820435 loss)
I0526 08:14:27.945212 23331 sgd_solver.cpp:106] Iteration 607500, lr = 0.0035
I0526 08:14:44.981892 23331 solver.cpp:237] Iteration 609000, loss = 1.06344
I0526 08:14:44.981950 23331 solver.cpp:253]     Train net output #0: loss = 1.06345 (* 1 = 1.06345 loss)
I0526 08:14:44.981967 23331 sgd_solver.cpp:106] Iteration 609000, lr = 0.0035
I0526 08:15:22.859695 23331 solver.cpp:237] Iteration 610500, loss = 1.02413
I0526 08:15:22.859871 23331 solver.cpp:253]     Train net output #0: loss = 1.02413 (* 1 = 1.02413 loss)
I0526 08:15:22.859890 23331 sgd_solver.cpp:106] Iteration 610500, lr = 0.0035
I0526 08:15:39.721627 23331 solver.cpp:237] Iteration 612000, loss = 1.50241
I0526 08:15:39.721668 23331 solver.cpp:253]     Train net output #0: loss = 1.50242 (* 1 = 1.50242 loss)
I0526 08:15:39.721685 23331 sgd_solver.cpp:106] Iteration 612000, lr = 0.0035
I0526 08:15:56.539496 23331 solver.cpp:237] Iteration 613500, loss = 1.79026
I0526 08:15:56.539669 23331 solver.cpp:253]     Train net output #0: loss = 1.79026 (* 1 = 1.79026 loss)
I0526 08:15:56.539686 23331 sgd_solver.cpp:106] Iteration 613500, lr = 0.0035
I0526 08:16:13.338630 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_615000.caffemodel
I0526 08:16:13.384528 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_615000.solverstate
I0526 08:16:13.413717 23331 solver.cpp:237] Iteration 615000, loss = 0.721688
I0526 08:16:13.413775 23331 solver.cpp:253]     Train net output #0: loss = 0.721693 (* 1 = 0.721693 loss)
I0526 08:16:13.413794 23331 sgd_solver.cpp:106] Iteration 615000, lr = 0.0035
I0526 08:16:30.492844 23331 solver.cpp:237] Iteration 616500, loss = 1.0057
I0526 08:16:30.493002 23331 solver.cpp:253]     Train net output #0: loss = 1.00571 (* 1 = 1.00571 loss)
I0526 08:16:30.493019 23331 sgd_solver.cpp:106] Iteration 616500, lr = 0.0035
I0526 08:16:47.421404 23331 solver.cpp:237] Iteration 618000, loss = 0.460861
I0526 08:16:47.421464 23331 solver.cpp:253]     Train net output #0: loss = 0.460866 (* 1 = 0.460866 loss)
I0526 08:16:47.421483 23331 sgd_solver.cpp:106] Iteration 618000, lr = 0.0035
I0526 08:17:04.315482 23331 solver.cpp:237] Iteration 619500, loss = 1.11018
I0526 08:17:04.315655 23331 solver.cpp:253]     Train net output #0: loss = 1.11018 (* 1 = 1.11018 loss)
I0526 08:17:04.315675 23331 sgd_solver.cpp:106] Iteration 619500, lr = 0.0035
I0526 08:17:41.995750 23331 solver.cpp:237] Iteration 621000, loss = 1.10111
I0526 08:17:41.995930 23331 solver.cpp:253]     Train net output #0: loss = 1.10112 (* 1 = 1.10112 loss)
I0526 08:17:41.995949 23331 sgd_solver.cpp:106] Iteration 621000, lr = 0.0035
I0526 08:17:58.692901 23331 solver.cpp:237] Iteration 622500, loss = 1.32481
I0526 08:17:58.692960 23331 solver.cpp:253]     Train net output #0: loss = 1.32481 (* 1 = 1.32481 loss)
I0526 08:17:58.692977 23331 sgd_solver.cpp:106] Iteration 622500, lr = 0.0035
I0526 08:18:15.316162 23331 solver.cpp:237] Iteration 624000, loss = 1.6269
I0526 08:18:15.316318 23331 solver.cpp:253]     Train net output #0: loss = 1.62691 (* 1 = 1.62691 loss)
I0526 08:18:15.316335 23331 sgd_solver.cpp:106] Iteration 624000, lr = 0.0035
I0526 08:18:32.173362 23331 solver.cpp:237] Iteration 625500, loss = 1.13025
I0526 08:18:32.173410 23331 solver.cpp:253]     Train net output #0: loss = 1.13025 (* 1 = 1.13025 loss)
I0526 08:18:32.173429 23331 sgd_solver.cpp:106] Iteration 625500, lr = 0.0035
I0526 08:18:49.222759 23331 solver.cpp:237] Iteration 627000, loss = 1.13924
I0526 08:18:49.222934 23331 solver.cpp:253]     Train net output #0: loss = 1.13925 (* 1 = 1.13925 loss)
I0526 08:18:49.222951 23331 sgd_solver.cpp:106] Iteration 627000, lr = 0.0035
I0526 08:19:06.449439 23331 solver.cpp:237] Iteration 628500, loss = 1.29136
I0526 08:19:06.449494 23331 solver.cpp:253]     Train net output #0: loss = 1.29136 (* 1 = 1.29136 loss)
I0526 08:19:06.449512 23331 sgd_solver.cpp:106] Iteration 628500, lr = 0.0035
I0526 08:19:23.371845 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_630000.caffemodel
I0526 08:19:23.420502 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_630000.solverstate
I0526 08:19:23.446146 23331 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 08:20:43.889325 23331 solver.cpp:409]     Test net output #0: accuracy = 0.890895
I0526 08:20:43.889502 23331 solver.cpp:409]     Test net output #1: loss = 0.35731 (* 1 = 0.35731 loss)
I0526 08:21:04.788758 23331 solver.cpp:237] Iteration 630000, loss = 1.12565
I0526 08:21:04.788817 23331 solver.cpp:253]     Train net output #0: loss = 1.12565 (* 1 = 1.12565 loss)
I0526 08:21:04.788846 23331 sgd_solver.cpp:106] Iteration 630000, lr = 0.0035
I0526 08:21:21.643302 23331 solver.cpp:237] Iteration 631500, loss = 1.40865
I0526 08:21:21.643481 23331 solver.cpp:253]     Train net output #0: loss = 1.40866 (* 1 = 1.40866 loss)
I0526 08:21:21.643497 23331 sgd_solver.cpp:106] Iteration 631500, lr = 0.0035
I0526 08:21:38.374500 23331 solver.cpp:237] Iteration 633000, loss = 0.694973
I0526 08:21:38.374557 23331 solver.cpp:253]     Train net output #0: loss = 0.694978 (* 1 = 0.694978 loss)
I0526 08:21:38.374577 23331 sgd_solver.cpp:106] Iteration 633000, lr = 0.0035
I0526 08:21:55.552932 23331 solver.cpp:237] Iteration 634500, loss = 1.37126
I0526 08:21:55.553104 23331 solver.cpp:253]     Train net output #0: loss = 1.37126 (* 1 = 1.37126 loss)
I0526 08:21:55.553122 23331 sgd_solver.cpp:106] Iteration 634500, lr = 0.0035
I0526 08:22:12.657491 23331 solver.cpp:237] Iteration 636000, loss = 1.35952
I0526 08:22:12.657546 23331 solver.cpp:253]     Train net output #0: loss = 1.35952 (* 1 = 1.35952 loss)
I0526 08:22:12.657570 23331 sgd_solver.cpp:106] Iteration 636000, lr = 0.0035
I0526 08:22:29.627625 23331 solver.cpp:237] Iteration 637500, loss = 1.67494
I0526 08:22:29.627799 23331 solver.cpp:253]     Train net output #0: loss = 1.67495 (* 1 = 1.67495 loss)
I0526 08:22:29.627816 23331 sgd_solver.cpp:106] Iteration 637500, lr = 0.0035
I0526 08:22:46.254372 23331 solver.cpp:237] Iteration 639000, loss = 0.456029
I0526 08:22:46.254410 23331 solver.cpp:253]     Train net output #0: loss = 0.456034 (* 1 = 0.456034 loss)
I0526 08:22:46.254429 23331 sgd_solver.cpp:106] Iteration 639000, lr = 0.0035
I0526 08:23:24.177498 23331 solver.cpp:237] Iteration 640500, loss = 1.43665
I0526 08:23:24.177677 23331 solver.cpp:253]     Train net output #0: loss = 1.43666 (* 1 = 1.43666 loss)
I0526 08:23:24.177695 23331 sgd_solver.cpp:106] Iteration 640500, lr = 0.0035
I0526 08:23:41.032994 23331 solver.cpp:237] Iteration 642000, loss = 0.87822
I0526 08:23:41.033053 23331 solver.cpp:253]     Train net output #0: loss = 0.878224 (* 1 = 0.878224 loss)
I0526 08:23:41.033080 23331 sgd_solver.cpp:106] Iteration 642000, lr = 0.0035
I0526 08:23:57.674597 23331 solver.cpp:237] Iteration 643500, loss = 1.31038
I0526 08:23:57.674753 23331 solver.cpp:253]     Train net output #0: loss = 1.31039 (* 1 = 1.31039 loss)
I0526 08:23:57.674770 23331 sgd_solver.cpp:106] Iteration 643500, lr = 0.0035
I0526 08:24:14.595391 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_645000.caffemodel
I0526 08:24:14.677167 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_645000.solverstate
I0526 08:24:14.754801 23331 solver.cpp:237] Iteration 645000, loss = 0.940892
I0526 08:24:14.754859 23331 solver.cpp:253]     Train net output #0: loss = 0.940897 (* 1 = 0.940897 loss)
I0526 08:24:14.754884 23331 sgd_solver.cpp:106] Iteration 645000, lr = 0.0035
I0526 08:24:31.916959 23331 solver.cpp:237] Iteration 646500, loss = 0.953781
I0526 08:24:31.917146 23331 solver.cpp:253]     Train net output #0: loss = 0.953786 (* 1 = 0.953786 loss)
I0526 08:24:31.917166 23331 sgd_solver.cpp:106] Iteration 646500, lr = 0.0035
I0526 08:24:48.551131 23331 solver.cpp:237] Iteration 648000, loss = 0.67901
I0526 08:24:48.551170 23331 solver.cpp:253]     Train net output #0: loss = 0.679015 (* 1 = 0.679015 loss)
I0526 08:24:48.551189 23331 sgd_solver.cpp:106] Iteration 648000, lr = 0.0035
I0526 08:25:05.193014 23331 solver.cpp:237] Iteration 649500, loss = 1.09295
I0526 08:25:05.193203 23331 solver.cpp:253]     Train net output #0: loss = 1.09296 (* 1 = 1.09296 loss)
I0526 08:25:05.193220 23331 sgd_solver.cpp:106] Iteration 649500, lr = 0.0035
I0526 08:25:42.713497 23331 solver.cpp:237] Iteration 651000, loss = 1.24947
I0526 08:25:42.713681 23331 solver.cpp:253]     Train net output #0: loss = 1.24947 (* 1 = 1.24947 loss)
I0526 08:25:42.713698 23331 sgd_solver.cpp:106] Iteration 651000, lr = 0.0035
I0526 08:25:59.794663 23331 solver.cpp:237] Iteration 652500, loss = 1.1903
I0526 08:25:59.794719 23331 solver.cpp:253]     Train net output #0: loss = 1.19031 (* 1 = 1.19031 loss)
I0526 08:25:59.794736 23331 sgd_solver.cpp:106] Iteration 652500, lr = 0.0035
I0526 08:26:16.953866 23331 solver.cpp:237] Iteration 654000, loss = 1.21736
I0526 08:26:16.954043 23331 solver.cpp:253]     Train net output #0: loss = 1.21737 (* 1 = 1.21737 loss)
I0526 08:26:16.954061 23331 sgd_solver.cpp:106] Iteration 654000, lr = 0.0035
I0526 08:26:34.012676 23331 solver.cpp:237] Iteration 655500, loss = 1.12488
I0526 08:26:34.012713 23331 solver.cpp:253]     Train net output #0: loss = 1.12488 (* 1 = 1.12488 loss)
I0526 08:26:34.012732 23331 sgd_solver.cpp:106] Iteration 655500, lr = 0.0035
I0526 08:26:50.832466 23331 solver.cpp:237] Iteration 657000, loss = 0.619713
I0526 08:26:50.832636 23331 solver.cpp:253]     Train net output #0: loss = 0.619716 (* 1 = 0.619716 loss)
I0526 08:26:50.832653 23331 sgd_solver.cpp:106] Iteration 657000, lr = 0.0035
I0526 08:27:07.668917 23331 solver.cpp:237] Iteration 658500, loss = 1.06859
I0526 08:27:07.668974 23331 solver.cpp:253]     Train net output #0: loss = 1.06859 (* 1 = 1.06859 loss)
I0526 08:27:07.669004 23331 sgd_solver.cpp:106] Iteration 658500, lr = 0.0035
I0526 08:27:24.620432 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_660000.caffemodel
I0526 08:27:24.690892 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_660000.solverstate
I0526 08:27:24.718601 23331 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 08:28:25.035665 23331 solver.cpp:409]     Test net output #0: accuracy = 0.894113
I0526 08:28:25.035842 23331 solver.cpp:409]     Test net output #1: loss = 0.370765 (* 1 = 0.370765 loss)
I0526 08:28:46.303557 23331 solver.cpp:237] Iteration 660000, loss = 1.06815
I0526 08:28:46.303619 23331 solver.cpp:253]     Train net output #0: loss = 1.06816 (* 1 = 1.06816 loss)
I0526 08:28:46.303640 23331 sgd_solver.cpp:106] Iteration 660000, lr = 0.0035
I0526 08:29:03.212764 23331 solver.cpp:237] Iteration 661500, loss = 0.847893
I0526 08:29:03.212932 23331 solver.cpp:253]     Train net output #0: loss = 0.847897 (* 1 = 0.847897 loss)
I0526 08:29:03.212949 23331 sgd_solver.cpp:106] Iteration 661500, lr = 0.0035
I0526 08:29:19.876032 23331 solver.cpp:237] Iteration 663000, loss = 1.24843
I0526 08:29:19.876091 23331 solver.cpp:253]     Train net output #0: loss = 1.24843 (* 1 = 1.24843 loss)
I0526 08:29:19.876108 23331 sgd_solver.cpp:106] Iteration 663000, lr = 0.0035
I0526 08:29:36.691208 23331 solver.cpp:237] Iteration 664500, loss = 1.25208
I0526 08:29:36.691386 23331 solver.cpp:253]     Train net output #0: loss = 1.25208 (* 1 = 1.25208 loss)
I0526 08:29:36.691404 23331 sgd_solver.cpp:106] Iteration 664500, lr = 0.0035
I0526 08:29:53.895490 23331 solver.cpp:237] Iteration 666000, loss = 0.642101
I0526 08:29:53.895530 23331 solver.cpp:253]     Train net output #0: loss = 0.642103 (* 1 = 0.642103 loss)
I0526 08:29:53.895550 23331 sgd_solver.cpp:106] Iteration 666000, lr = 0.0035
I0526 08:30:10.815971 23331 solver.cpp:237] Iteration 667500, loss = 2.09257
I0526 08:30:10.816144 23331 solver.cpp:253]     Train net output #0: loss = 2.09257 (* 1 = 2.09257 loss)
I0526 08:30:10.816162 23331 sgd_solver.cpp:106] Iteration 667500, lr = 0.0035
I0526 08:30:27.644155 23331 solver.cpp:237] Iteration 669000, loss = 1.07134
I0526 08:30:27.644212 23331 solver.cpp:253]     Train net output #0: loss = 1.07134 (* 1 = 1.07134 loss)
I0526 08:30:27.644238 23331 sgd_solver.cpp:106] Iteration 669000, lr = 0.0035
I0526 08:31:05.423828 23331 solver.cpp:237] Iteration 670500, loss = 1.29099
I0526 08:31:05.424016 23331 solver.cpp:253]     Train net output #0: loss = 1.29099 (* 1 = 1.29099 loss)
I0526 08:31:05.424036 23331 sgd_solver.cpp:106] Iteration 670500, lr = 0.0035
I0526 08:31:22.383254 23331 solver.cpp:237] Iteration 672000, loss = 0.993784
I0526 08:31:22.383312 23331 solver.cpp:253]     Train net output #0: loss = 0.993786 (* 1 = 0.993786 loss)
I0526 08:31:22.383329 23331 sgd_solver.cpp:106] Iteration 672000, lr = 0.0035
I0526 08:31:39.400672 23331 solver.cpp:237] Iteration 673500, loss = 1.07963
I0526 08:31:39.400848 23331 solver.cpp:253]     Train net output #0: loss = 1.07964 (* 1 = 1.07964 loss)
I0526 08:31:39.400866 23331 sgd_solver.cpp:106] Iteration 673500, lr = 0.0035
I0526 08:31:56.157328 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_675000.caffemodel
I0526 08:31:56.770984 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_675000.solverstate
I0526 08:31:56.866600 23331 solver.cpp:237] Iteration 675000, loss = 0.598965
I0526 08:31:56.866662 23331 solver.cpp:253]     Train net output #0: loss = 0.598967 (* 1 = 0.598967 loss)
I0526 08:31:56.866688 23331 sgd_solver.cpp:106] Iteration 675000, lr = 0.0035
I0526 08:32:13.613365 23331 solver.cpp:237] Iteration 676500, loss = 2.4432
I0526 08:32:13.613543 23331 solver.cpp:253]     Train net output #0: loss = 2.44321 (* 1 = 2.44321 loss)
I0526 08:32:13.613561 23331 sgd_solver.cpp:106] Iteration 676500, lr = 0.0035
I0526 08:32:30.312413 23331 solver.cpp:237] Iteration 678000, loss = 1.45738
I0526 08:32:30.312470 23331 solver.cpp:253]     Train net output #0: loss = 1.45739 (* 1 = 1.45739 loss)
I0526 08:32:30.312489 23331 sgd_solver.cpp:106] Iteration 678000, lr = 0.0035
I0526 08:32:47.099519 23331 solver.cpp:237] Iteration 679500, loss = 1.05183
I0526 08:32:47.099678 23331 solver.cpp:253]     Train net output #0: loss = 1.05183 (* 1 = 1.05183 loss)
I0526 08:32:47.099697 23331 sgd_solver.cpp:106] Iteration 679500, lr = 0.0035
I0526 08:33:26.602816 23331 solver.cpp:237] Iteration 681000, loss = 1.29974
I0526 08:33:26.602998 23331 solver.cpp:253]     Train net output #0: loss = 1.29975 (* 1 = 1.29975 loss)
I0526 08:33:26.603015 23331 sgd_solver.cpp:106] Iteration 681000, lr = 0.0035
I0526 08:33:43.262445 23331 solver.cpp:237] Iteration 682500, loss = 1.23578
I0526 08:33:43.262503 23331 solver.cpp:253]     Train net output #0: loss = 1.23579 (* 1 = 1.23579 loss)
I0526 08:33:43.262529 23331 sgd_solver.cpp:106] Iteration 682500, lr = 0.0035
I0526 08:34:00.014303 23331 solver.cpp:237] Iteration 684000, loss = 1.43581
I0526 08:34:00.014472 23331 solver.cpp:253]     Train net output #0: loss = 1.43581 (* 1 = 1.43581 loss)
I0526 08:34:00.014489 23331 sgd_solver.cpp:106] Iteration 684000, lr = 0.0035
I0526 08:34:16.908730 23331 solver.cpp:237] Iteration 685500, loss = 1.68036
I0526 08:34:16.908787 23331 solver.cpp:253]     Train net output #0: loss = 1.68036 (* 1 = 1.68036 loss)
I0526 08:34:16.908804 23331 sgd_solver.cpp:106] Iteration 685500, lr = 0.0035
I0526 08:34:33.884335 23331 solver.cpp:237] Iteration 687000, loss = 0.649714
I0526 08:34:33.884515 23331 solver.cpp:253]     Train net output #0: loss = 0.649716 (* 1 = 0.649716 loss)
I0526 08:34:33.884533 23331 sgd_solver.cpp:106] Iteration 687000, lr = 0.0035
I0526 08:34:50.833411 23331 solver.cpp:237] Iteration 688500, loss = 1.10016
I0526 08:34:50.833449 23331 solver.cpp:253]     Train net output #0: loss = 1.10016 (* 1 = 1.10016 loss)
I0526 08:34:50.833467 23331 sgd_solver.cpp:106] Iteration 688500, lr = 0.0035
I0526 08:35:07.714526 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_690000.caffemodel
I0526 08:35:08.639447 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_690000.solverstate
I0526 08:35:08.729585 23331 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 08:36:30.907510 23331 solver.cpp:409]     Test net output #0: accuracy = 0.895931
I0526 08:36:30.907706 23331 solver.cpp:409]     Test net output #1: loss = 0.378992 (* 1 = 0.378992 loss)
I0526 08:36:53.943877 23331 solver.cpp:237] Iteration 690000, loss = 0.455237
I0526 08:36:53.943938 23331 solver.cpp:253]     Train net output #0: loss = 0.455239 (* 1 = 0.455239 loss)
I0526 08:36:53.943964 23331 sgd_solver.cpp:106] Iteration 690000, lr = 0.0035
I0526 08:37:10.909387 23331 solver.cpp:237] Iteration 691500, loss = 0.863675
I0526 08:37:10.909567 23331 solver.cpp:253]     Train net output #0: loss = 0.863678 (* 1 = 0.863678 loss)
I0526 08:37:10.909584 23331 sgd_solver.cpp:106] Iteration 691500, lr = 0.0035
I0526 08:37:27.755408 23331 solver.cpp:237] Iteration 693000, loss = 0.395468
I0526 08:37:27.755470 23331 solver.cpp:253]     Train net output #0: loss = 0.395471 (* 1 = 0.395471 loss)
I0526 08:37:27.755488 23331 sgd_solver.cpp:106] Iteration 693000, lr = 0.0035
I0526 08:37:44.538090 23331 solver.cpp:237] Iteration 694500, loss = 1.60843
I0526 08:37:44.538249 23331 solver.cpp:253]     Train net output #0: loss = 1.60844 (* 1 = 1.60844 loss)
I0526 08:37:44.538265 23331 sgd_solver.cpp:106] Iteration 694500, lr = 0.0035
I0526 08:38:01.265393 23331 solver.cpp:237] Iteration 696000, loss = 0.9839
I0526 08:38:01.265449 23331 solver.cpp:253]     Train net output #0: loss = 0.983901 (* 1 = 0.983901 loss)
I0526 08:38:01.265466 23331 sgd_solver.cpp:106] Iteration 696000, lr = 0.0035
I0526 08:38:17.967173 23331 solver.cpp:237] Iteration 697500, loss = 0.804617
I0526 08:38:17.967352 23331 solver.cpp:253]     Train net output #0: loss = 0.804618 (* 1 = 0.804618 loss)
I0526 08:38:17.967370 23331 sgd_solver.cpp:106] Iteration 697500, lr = 0.0035
I0526 08:38:34.797051 23331 solver.cpp:237] Iteration 699000, loss = 0.671833
I0526 08:38:34.797091 23331 solver.cpp:253]     Train net output #0: loss = 0.671835 (* 1 = 0.671835 loss)
I0526 08:38:34.797109 23331 sgd_solver.cpp:106] Iteration 699000, lr = 0.0035
I0526 08:39:12.399287 23331 solver.cpp:237] Iteration 700500, loss = 1.67381
I0526 08:39:12.399489 23331 solver.cpp:253]     Train net output #0: loss = 1.67382 (* 1 = 1.67382 loss)
I0526 08:39:12.399509 23331 sgd_solver.cpp:106] Iteration 700500, lr = 0.0035
I0526 08:39:29.025807 23331 solver.cpp:237] Iteration 702000, loss = 1.22965
I0526 08:39:29.025846 23331 solver.cpp:253]     Train net output #0: loss = 1.22965 (* 1 = 1.22965 loss)
I0526 08:39:29.025864 23331 sgd_solver.cpp:106] Iteration 702000, lr = 0.0035
I0526 08:39:46.168632 23331 solver.cpp:237] Iteration 703500, loss = 1.03762
I0526 08:39:46.168818 23331 solver.cpp:253]     Train net output #0: loss = 1.03762 (* 1 = 1.03762 loss)
I0526 08:39:46.168835 23331 sgd_solver.cpp:106] Iteration 703500, lr = 0.0035
I0526 08:40:03.177688 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_705000.caffemodel
I0526 08:40:03.223767 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_705000.solverstate
I0526 08:40:03.252866 23331 solver.cpp:237] Iteration 705000, loss = 1.65277
I0526 08:40:03.252921 23331 solver.cpp:253]     Train net output #0: loss = 1.65277 (* 1 = 1.65277 loss)
I0526 08:40:03.252939 23331 sgd_solver.cpp:106] Iteration 705000, lr = 0.0035
I0526 08:40:20.037019 23331 solver.cpp:237] Iteration 706500, loss = 1.13889
I0526 08:40:20.037184 23331 solver.cpp:253]     Train net output #0: loss = 1.13889 (* 1 = 1.13889 loss)
I0526 08:40:20.037201 23331 sgd_solver.cpp:106] Iteration 706500, lr = 0.0035
I0526 08:40:36.998081 23331 solver.cpp:237] Iteration 708000, loss = 1.078
I0526 08:40:36.998138 23331 solver.cpp:253]     Train net output #0: loss = 1.078 (* 1 = 1.078 loss)
I0526 08:40:36.998155 23331 sgd_solver.cpp:106] Iteration 708000, lr = 0.0035
I0526 08:40:53.796310 23331 solver.cpp:237] Iteration 709500, loss = 1.20135
I0526 08:40:53.796489 23331 solver.cpp:253]     Train net output #0: loss = 1.20135 (* 1 = 1.20135 loss)
I0526 08:40:53.796505 23331 sgd_solver.cpp:106] Iteration 709500, lr = 0.0035
I0526 08:41:31.353008 23331 solver.cpp:237] Iteration 711000, loss = 1.70619
I0526 08:41:31.353186 23331 solver.cpp:253]     Train net output #0: loss = 1.70619 (* 1 = 1.70619 loss)
I0526 08:41:31.353204 23331 sgd_solver.cpp:106] Iteration 711000, lr = 0.0035
I0526 08:41:48.386443 23331 solver.cpp:237] Iteration 712500, loss = 2.56874
I0526 08:41:48.386499 23331 solver.cpp:253]     Train net output #0: loss = 2.56874 (* 1 = 2.56874 loss)
I0526 08:41:48.386518 23331 sgd_solver.cpp:106] Iteration 712500, lr = 0.0035
I0526 08:42:05.442483 23331 solver.cpp:237] Iteration 714000, loss = 1.31479
I0526 08:42:05.442664 23331 solver.cpp:253]     Train net output #0: loss = 1.31479 (* 1 = 1.31479 loss)
I0526 08:42:05.442683 23331 sgd_solver.cpp:106] Iteration 714000, lr = 0.0035
I0526 08:42:22.048912 23331 solver.cpp:237] Iteration 715500, loss = 1.39179
I0526 08:42:22.048951 23331 solver.cpp:253]     Train net output #0: loss = 1.39179 (* 1 = 1.39179 loss)
I0526 08:42:22.048969 23331 sgd_solver.cpp:106] Iteration 715500, lr = 0.0035
I0526 08:42:38.979195 23331 solver.cpp:237] Iteration 717000, loss = 1.1512
I0526 08:42:38.979373 23331 solver.cpp:253]     Train net output #0: loss = 1.1512 (* 1 = 1.1512 loss)
I0526 08:42:38.979390 23331 sgd_solver.cpp:106] Iteration 717000, lr = 0.0035
I0526 08:42:56.005465 23331 solver.cpp:237] Iteration 718500, loss = 1.18523
I0526 08:42:56.005520 23331 solver.cpp:253]     Train net output #0: loss = 1.18523 (* 1 = 1.18523 loss)
I0526 08:42:56.005538 23331 sgd_solver.cpp:106] Iteration 718500, lr = 0.0035
I0526 08:43:12.956579 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_720000.caffemodel
I0526 08:43:13.011620 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_720000.solverstate
I0526 08:43:13.045101 23331 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 08:44:12.493860 23331 solver.cpp:409]     Test net output #0: accuracy = 0.892675
I0526 08:44:12.494050 23331 solver.cpp:409]     Test net output #1: loss = 0.341444 (* 1 = 0.341444 loss)
I0526 08:44:33.416697 23331 solver.cpp:237] Iteration 720000, loss = 1.7015
I0526 08:44:33.416757 23331 solver.cpp:253]     Train net output #0: loss = 1.7015 (* 1 = 1.7015 loss)
I0526 08:44:33.416777 23331 sgd_solver.cpp:106] Iteration 720000, lr = 0.0035
I0526 08:44:50.486201 23331 solver.cpp:237] Iteration 721500, loss = 1.07916
I0526 08:44:50.486366 23331 solver.cpp:253]     Train net output #0: loss = 1.07916 (* 1 = 1.07916 loss)
I0526 08:44:50.486382 23331 sgd_solver.cpp:106] Iteration 721500, lr = 0.0035
I0526 08:45:07.466219 23331 solver.cpp:237] Iteration 723000, loss = 1.26487
I0526 08:45:07.466274 23331 solver.cpp:253]     Train net output #0: loss = 1.26487 (* 1 = 1.26487 loss)
I0526 08:45:07.466294 23331 sgd_solver.cpp:106] Iteration 723000, lr = 0.0035
I0526 08:45:24.407245 23331 solver.cpp:237] Iteration 724500, loss = 1.09262
I0526 08:45:24.407433 23331 solver.cpp:253]     Train net output #0: loss = 1.09262 (* 1 = 1.09262 loss)
I0526 08:45:24.407450 23331 sgd_solver.cpp:106] Iteration 724500, lr = 0.0035
I0526 08:45:41.193095 23331 solver.cpp:237] Iteration 726000, loss = 0.591395
I0526 08:45:41.193135 23331 solver.cpp:253]     Train net output #0: loss = 0.591398 (* 1 = 0.591398 loss)
I0526 08:45:41.193151 23331 sgd_solver.cpp:106] Iteration 726000, lr = 0.0035
I0526 08:45:58.200889 23331 solver.cpp:237] Iteration 727500, loss = 0.950419
I0526 08:45:58.201069 23331 solver.cpp:253]     Train net output #0: loss = 0.950422 (* 1 = 0.950422 loss)
I0526 08:45:58.201086 23331 sgd_solver.cpp:106] Iteration 727500, lr = 0.0035
I0526 08:46:15.207188 23331 solver.cpp:237] Iteration 729000, loss = 0.835445
I0526 08:46:15.207249 23331 solver.cpp:253]     Train net output #0: loss = 0.835448 (* 1 = 0.835448 loss)
I0526 08:46:15.207274 23331 sgd_solver.cpp:106] Iteration 729000, lr = 0.0035
I0526 08:46:52.922294 23331 solver.cpp:237] Iteration 730500, loss = 0.634375
I0526 08:46:52.922483 23331 solver.cpp:253]     Train net output #0: loss = 0.634378 (* 1 = 0.634378 loss)
I0526 08:46:52.922502 23331 sgd_solver.cpp:106] Iteration 730500, lr = 0.0035
I0526 08:47:09.834184 23331 solver.cpp:237] Iteration 732000, loss = 0.604429
I0526 08:47:09.834244 23331 solver.cpp:253]     Train net output #0: loss = 0.604433 (* 1 = 0.604433 loss)
I0526 08:47:09.834262 23331 sgd_solver.cpp:106] Iteration 732000, lr = 0.0035
I0526 08:47:26.778242 23331 solver.cpp:237] Iteration 733500, loss = 1.10999
I0526 08:47:26.778414 23331 solver.cpp:253]     Train net output #0: loss = 1.10999 (* 1 = 1.10999 loss)
I0526 08:47:26.778432 23331 sgd_solver.cpp:106] Iteration 733500, lr = 0.0035
I0526 08:47:43.846490 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_735000.caffemodel
I0526 08:47:43.904106 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_735000.solverstate
I0526 08:47:43.943996 23331 solver.cpp:237] Iteration 735000, loss = 1.85745
I0526 08:47:43.944054 23331 solver.cpp:253]     Train net output #0: loss = 1.85746 (* 1 = 1.85746 loss)
I0526 08:47:43.944072 23331 sgd_solver.cpp:106] Iteration 735000, lr = 0.0035
I0526 08:48:00.896782 23331 solver.cpp:237] Iteration 736500, loss = 0.640634
I0526 08:48:00.896981 23331 solver.cpp:253]     Train net output #0: loss = 0.640638 (* 1 = 0.640638 loss)
I0526 08:48:00.896999 23331 sgd_solver.cpp:106] Iteration 736500, lr = 0.0035
I0526 08:48:17.849629 23331 solver.cpp:237] Iteration 738000, loss = 1.91025
I0526 08:48:17.849689 23331 solver.cpp:253]     Train net output #0: loss = 1.91025 (* 1 = 1.91025 loss)
I0526 08:48:17.849706 23331 sgd_solver.cpp:106] Iteration 738000, lr = 0.0035
I0526 08:48:35.068511 23331 solver.cpp:237] Iteration 739500, loss = 1.22987
I0526 08:48:35.068683 23331 solver.cpp:253]     Train net output #0: loss = 1.22987 (* 1 = 1.22987 loss)
I0526 08:48:35.068701 23331 sgd_solver.cpp:106] Iteration 739500, lr = 0.0035
I0526 08:49:12.978253 23331 solver.cpp:237] Iteration 741000, loss = 0.836101
I0526 08:49:12.978437 23331 solver.cpp:253]     Train net output #0: loss = 0.836106 (* 1 = 0.836106 loss)
I0526 08:49:12.978456 23331 sgd_solver.cpp:106] Iteration 741000, lr = 0.0035
I0526 08:49:29.767168 23331 solver.cpp:237] Iteration 742500, loss = 1.4838
I0526 08:49:29.767207 23331 solver.cpp:253]     Train net output #0: loss = 1.4838 (* 1 = 1.4838 loss)
I0526 08:49:29.767225 23331 sgd_solver.cpp:106] Iteration 742500, lr = 0.0035
I0526 08:49:46.813133 23331 solver.cpp:237] Iteration 744000, loss = 1.00984
I0526 08:49:46.813310 23331 solver.cpp:253]     Train net output #0: loss = 1.00984 (* 1 = 1.00984 loss)
I0526 08:49:46.813328 23331 sgd_solver.cpp:106] Iteration 744000, lr = 0.0035
I0526 08:50:03.657768 23331 solver.cpp:237] Iteration 745500, loss = 1.86899
I0526 08:50:03.657824 23331 solver.cpp:253]     Train net output #0: loss = 1.86899 (* 1 = 1.86899 loss)
I0526 08:50:03.657841 23331 sgd_solver.cpp:106] Iteration 745500, lr = 0.0035
I0526 08:50:20.272869 23331 solver.cpp:237] Iteration 747000, loss = 2.17352
I0526 08:50:20.273030 23331 solver.cpp:253]     Train net output #0: loss = 2.17352 (* 1 = 2.17352 loss)
I0526 08:50:20.273047 23331 sgd_solver.cpp:106] Iteration 747000, lr = 0.0035
I0526 08:50:36.882199 23331 solver.cpp:237] Iteration 748500, loss = 1.0388
I0526 08:50:36.882247 23331 solver.cpp:253]     Train net output #0: loss = 1.03881 (* 1 = 1.03881 loss)
I0526 08:50:36.882266 23331 sgd_solver.cpp:106] Iteration 748500, lr = 0.0035
I0526 08:50:53.515796 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_750000.caffemodel
I0526 08:50:53.578374 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_750000.solverstate
I0526 08:50:53.613605 23331 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 08:52:14.059140 23331 solver.cpp:409]     Test net output #0: accuracy = 0.893603
I0526 08:52:14.059324 23331 solver.cpp:409]     Test net output #1: loss = 0.337293 (* 1 = 0.337293 loss)
I0526 08:52:35.012869 23331 solver.cpp:237] Iteration 750000, loss = 1.30924
I0526 08:52:35.012930 23331 solver.cpp:253]     Train net output #0: loss = 1.30924 (* 1 = 1.30924 loss)
I0526 08:52:35.012958 23331 sgd_solver.cpp:106] Iteration 750000, lr = 0.0035
I0526 08:52:51.679210 23331 solver.cpp:237] Iteration 751500, loss = 1.16272
I0526 08:52:51.679394 23331 solver.cpp:253]     Train net output #0: loss = 1.16272 (* 1 = 1.16272 loss)
I0526 08:52:51.679411 23331 sgd_solver.cpp:106] Iteration 751500, lr = 0.0035
I0526 08:53:08.257496 23331 solver.cpp:237] Iteration 753000, loss = 1.31718
I0526 08:53:08.257534 23331 solver.cpp:253]     Train net output #0: loss = 1.31719 (* 1 = 1.31719 loss)
I0526 08:53:08.257557 23331 sgd_solver.cpp:106] Iteration 753000, lr = 0.0035
I0526 08:53:24.974225 23331 solver.cpp:237] Iteration 754500, loss = 1.49227
I0526 08:53:24.974406 23331 solver.cpp:253]     Train net output #0: loss = 1.49227 (* 1 = 1.49227 loss)
I0526 08:53:24.974422 23331 sgd_solver.cpp:106] Iteration 754500, lr = 0.0035
I0526 08:53:41.903127 23331 solver.cpp:237] Iteration 756000, loss = 0.818202
I0526 08:53:41.903189 23331 solver.cpp:253]     Train net output #0: loss = 0.818209 (* 1 = 0.818209 loss)
I0526 08:53:41.903208 23331 sgd_solver.cpp:106] Iteration 756000, lr = 0.0035
I0526 08:53:59.087604 23331 solver.cpp:237] Iteration 757500, loss = 0.807804
I0526 08:53:59.087769 23331 solver.cpp:253]     Train net output #0: loss = 0.807812 (* 1 = 0.807812 loss)
I0526 08:53:59.087785 23331 sgd_solver.cpp:106] Iteration 757500, lr = 0.0035
I0526 08:54:16.216323 23331 solver.cpp:237] Iteration 759000, loss = 1.36384
I0526 08:54:16.216382 23331 solver.cpp:253]     Train net output #0: loss = 1.36385 (* 1 = 1.36385 loss)
I0526 08:54:16.216399 23331 sgd_solver.cpp:106] Iteration 759000, lr = 0.0035
I0526 08:54:54.178989 23331 solver.cpp:237] Iteration 760500, loss = 0.752232
I0526 08:54:54.179185 23331 solver.cpp:253]     Train net output #0: loss = 0.752241 (* 1 = 0.752241 loss)
I0526 08:54:54.179203 23331 sgd_solver.cpp:106] Iteration 760500, lr = 0.0035
I0526 08:55:10.948782 23331 solver.cpp:237] Iteration 762000, loss = 1.33741
I0526 08:55:10.948840 23331 solver.cpp:253]     Train net output #0: loss = 1.33742 (* 1 = 1.33742 loss)
I0526 08:55:10.948858 23331 sgd_solver.cpp:106] Iteration 762000, lr = 0.0035
I0526 08:55:27.762826 23331 solver.cpp:237] Iteration 763500, loss = 1.45965
I0526 08:55:27.763010 23331 solver.cpp:253]     Train net output #0: loss = 1.45966 (* 1 = 1.45966 loss)
I0526 08:55:27.763027 23331 sgd_solver.cpp:106] Iteration 763500, lr = 0.0035
I0526 08:55:44.570890 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_765000.caffemodel
I0526 08:55:44.626636 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_765000.solverstate
I0526 08:55:44.668305 23331 solver.cpp:237] Iteration 765000, loss = 0.944363
I0526 08:55:44.668365 23331 solver.cpp:253]     Train net output #0: loss = 0.944371 (* 1 = 0.944371 loss)
I0526 08:55:44.668390 23331 sgd_solver.cpp:106] Iteration 765000, lr = 0.0035
I0526 08:56:01.310060 23331 solver.cpp:237] Iteration 766500, loss = 1.05099
I0526 08:56:01.310241 23331 solver.cpp:253]     Train net output #0: loss = 1.051 (* 1 = 1.051 loss)
I0526 08:56:01.310258 23331 sgd_solver.cpp:106] Iteration 766500, lr = 0.0035
I0526 08:56:18.016736 23331 solver.cpp:237] Iteration 768000, loss = 0.772652
I0526 08:56:18.016794 23331 solver.cpp:253]     Train net output #0: loss = 0.77266 (* 1 = 0.77266 loss)
I0526 08:56:18.016813 23331 sgd_solver.cpp:106] Iteration 768000, lr = 0.0035
I0526 08:56:34.939528 23331 solver.cpp:237] Iteration 769500, loss = 1.67354
I0526 08:56:34.939688 23331 solver.cpp:253]     Train net output #0: loss = 1.67355 (* 1 = 1.67355 loss)
I0526 08:56:34.939705 23331 sgd_solver.cpp:106] Iteration 769500, lr = 0.0035
I0526 08:57:12.810647 23331 solver.cpp:237] Iteration 771000, loss = 1.47673
I0526 08:57:12.810829 23331 solver.cpp:253]     Train net output #0: loss = 1.47674 (* 1 = 1.47674 loss)
I0526 08:57:12.810847 23331 sgd_solver.cpp:106] Iteration 771000, lr = 0.0035
I0526 08:57:29.762848 23331 solver.cpp:237] Iteration 772500, loss = 0.670578
I0526 08:57:29.762909 23331 solver.cpp:253]     Train net output #0: loss = 0.670585 (* 1 = 0.670585 loss)
I0526 08:57:29.762933 23331 sgd_solver.cpp:106] Iteration 772500, lr = 0.0035
I0526 08:57:46.818804 23331 solver.cpp:237] Iteration 774000, loss = 1.47171
I0526 08:57:46.818959 23331 solver.cpp:253]     Train net output #0: loss = 1.47172 (* 1 = 1.47172 loss)
I0526 08:57:46.818976 23331 sgd_solver.cpp:106] Iteration 774000, lr = 0.0035
I0526 08:58:03.809286 23331 solver.cpp:237] Iteration 775500, loss = 1.31889
I0526 08:58:03.809343 23331 solver.cpp:253]     Train net output #0: loss = 1.3189 (* 1 = 1.3189 loss)
I0526 08:58:03.809360 23331 sgd_solver.cpp:106] Iteration 775500, lr = 0.0035
I0526 08:58:20.793678 23331 solver.cpp:237] Iteration 777000, loss = 0.769927
I0526 08:58:20.793859 23331 solver.cpp:253]     Train net output #0: loss = 0.769935 (* 1 = 0.769935 loss)
I0526 08:58:20.793876 23331 sgd_solver.cpp:106] Iteration 777000, lr = 0.0035
I0526 08:58:37.859993 23331 solver.cpp:237] Iteration 778500, loss = 2.00779
I0526 08:58:37.860031 23331 solver.cpp:253]     Train net output #0: loss = 2.0078 (* 1 = 2.0078 loss)
I0526 08:58:37.860049 23331 sgd_solver.cpp:106] Iteration 778500, lr = 0.0035
I0526 08:58:54.801419 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_780000.caffemodel
I0526 08:58:54.854233 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_780000.solverstate
I0526 08:58:54.892098 23331 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 08:59:53.949254 23331 solver.cpp:409]     Test net output #0: accuracy = 0.893762
I0526 08:59:53.949440 23331 solver.cpp:409]     Test net output #1: loss = 0.343983 (* 1 = 0.343983 loss)
I0526 09:00:14.852028 23331 solver.cpp:237] Iteration 780000, loss = 1.04777
I0526 09:00:14.852087 23331 solver.cpp:253]     Train net output #0: loss = 1.04778 (* 1 = 1.04778 loss)
I0526 09:00:14.852111 23331 sgd_solver.cpp:106] Iteration 780000, lr = 0.0035
I0526 09:00:31.674291 23331 solver.cpp:237] Iteration 781500, loss = 1.1179
I0526 09:00:31.674476 23331 solver.cpp:253]     Train net output #0: loss = 1.11791 (* 1 = 1.11791 loss)
I0526 09:00:31.674494 23331 sgd_solver.cpp:106] Iteration 781500, lr = 0.0035
I0526 09:00:48.611660 23331 solver.cpp:237] Iteration 783000, loss = 1.76791
I0526 09:00:48.611716 23331 solver.cpp:253]     Train net output #0: loss = 1.76792 (* 1 = 1.76792 loss)
I0526 09:00:48.611742 23331 sgd_solver.cpp:106] Iteration 783000, lr = 0.0035
I0526 09:01:05.532570 23331 solver.cpp:237] Iteration 784500, loss = 1.6526
I0526 09:01:05.532734 23331 solver.cpp:253]     Train net output #0: loss = 1.65261 (* 1 = 1.65261 loss)
I0526 09:01:05.532752 23331 sgd_solver.cpp:106] Iteration 784500, lr = 0.0035
I0526 09:01:22.327666 23331 solver.cpp:237] Iteration 786000, loss = 1.38234
I0526 09:01:22.327725 23331 solver.cpp:253]     Train net output #0: loss = 1.38235 (* 1 = 1.38235 loss)
I0526 09:01:22.327744 23331 sgd_solver.cpp:106] Iteration 786000, lr = 0.0035
I0526 09:01:39.112293 23331 solver.cpp:237] Iteration 787500, loss = 1.26025
I0526 09:01:39.112476 23331 solver.cpp:253]     Train net output #0: loss = 1.26025 (* 1 = 1.26025 loss)
I0526 09:01:39.112494 23331 sgd_solver.cpp:106] Iteration 787500, lr = 0.0035
I0526 09:01:55.778353 23331 solver.cpp:237] Iteration 789000, loss = 0.881088
I0526 09:01:55.778394 23331 solver.cpp:253]     Train net output #0: loss = 0.881093 (* 1 = 0.881093 loss)
I0526 09:01:55.778411 23331 sgd_solver.cpp:106] Iteration 789000, lr = 0.0035
I0526 09:02:33.309540 23331 solver.cpp:237] Iteration 790500, loss = 1.32077
I0526 09:02:33.309730 23331 solver.cpp:253]     Train net output #0: loss = 1.32078 (* 1 = 1.32078 loss)
I0526 09:02:33.309748 23331 sgd_solver.cpp:106] Iteration 790500, lr = 0.0035
I0526 09:02:49.917875 23331 solver.cpp:237] Iteration 792000, loss = 1.0858
I0526 09:02:49.917914 23331 solver.cpp:253]     Train net output #0: loss = 1.0858 (* 1 = 1.0858 loss)
I0526 09:02:49.917932 23331 sgd_solver.cpp:106] Iteration 792000, lr = 0.0035
I0526 09:03:06.976569 23331 solver.cpp:237] Iteration 793500, loss = 1.09806
I0526 09:03:06.976749 23331 solver.cpp:253]     Train net output #0: loss = 1.09807 (* 1 = 1.09807 loss)
I0526 09:03:06.976766 23331 sgd_solver.cpp:106] Iteration 793500, lr = 0.0035
I0526 09:03:23.988724 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_795000.caffemodel
I0526 09:03:24.042095 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_795000.solverstate
I0526 09:03:24.081197 23331 solver.cpp:237] Iteration 795000, loss = 1.28002
I0526 09:03:24.081254 23331 solver.cpp:253]     Train net output #0: loss = 1.28003 (* 1 = 1.28003 loss)
I0526 09:03:24.081272 23331 sgd_solver.cpp:106] Iteration 795000, lr = 0.0035
I0526 09:03:41.026620 23331 solver.cpp:237] Iteration 796500, loss = 1.02917
I0526 09:03:41.026815 23331 solver.cpp:253]     Train net output #0: loss = 1.02917 (* 1 = 1.02917 loss)
I0526 09:03:41.026835 23331 sgd_solver.cpp:106] Iteration 796500, lr = 0.0035
I0526 09:03:57.817235 23331 solver.cpp:237] Iteration 798000, loss = 1.10962
I0526 09:03:57.817276 23331 solver.cpp:253]     Train net output #0: loss = 1.10962 (* 1 = 1.10962 loss)
I0526 09:03:57.817298 23331 sgd_solver.cpp:106] Iteration 798000, lr = 0.0035
I0526 09:04:14.758572 23331 solver.cpp:237] Iteration 799500, loss = 1.0375
I0526 09:04:14.758755 23331 solver.cpp:253]     Train net output #0: loss = 1.0375 (* 1 = 1.0375 loss)
I0526 09:04:14.758772 23331 sgd_solver.cpp:106] Iteration 799500, lr = 0.0035
I0526 09:04:52.739442 23331 solver.cpp:237] Iteration 801000, loss = 1.07937
I0526 09:04:52.739634 23331 solver.cpp:253]     Train net output #0: loss = 1.07937 (* 1 = 1.07937 loss)
I0526 09:04:52.739650 23331 sgd_solver.cpp:106] Iteration 801000, lr = 0.0035
I0526 09:05:09.807799 23331 solver.cpp:237] Iteration 802500, loss = 1.45561
I0526 09:05:09.807857 23331 solver.cpp:253]     Train net output #0: loss = 1.45562 (* 1 = 1.45562 loss)
I0526 09:05:09.807875 23331 sgd_solver.cpp:106] Iteration 802500, lr = 0.0035
I0526 09:05:26.820580 23331 solver.cpp:237] Iteration 804000, loss = 1.37573
I0526 09:05:26.820763 23331 solver.cpp:253]     Train net output #0: loss = 1.37573 (* 1 = 1.37573 loss)
I0526 09:05:26.820780 23331 sgd_solver.cpp:106] Iteration 804000, lr = 0.0035
I0526 09:05:43.662991 23331 solver.cpp:237] Iteration 805500, loss = 1.41806
I0526 09:05:43.663030 23331 solver.cpp:253]     Train net output #0: loss = 1.41806 (* 1 = 1.41806 loss)
I0526 09:05:43.663048 23331 sgd_solver.cpp:106] Iteration 805500, lr = 0.0035
I0526 09:06:00.436955 23331 solver.cpp:237] Iteration 807000, loss = 1.3019
I0526 09:06:00.437139 23331 solver.cpp:253]     Train net output #0: loss = 1.30191 (* 1 = 1.30191 loss)
I0526 09:06:00.437156 23331 sgd_solver.cpp:106] Iteration 807000, lr = 0.0035
I0526 09:06:17.377130 23331 solver.cpp:237] Iteration 808500, loss = 1.27153
I0526 09:06:17.377184 23331 solver.cpp:253]     Train net output #0: loss = 1.27153 (* 1 = 1.27153 loss)
I0526 09:06:17.377213 23331 sgd_solver.cpp:106] Iteration 808500, lr = 0.0035
I0526 09:06:34.589612 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_810000.caffemodel
I0526 09:06:34.635380 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_810000.solverstate
I0526 09:06:34.660531 23331 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 09:07:55.305588 23331 solver.cpp:409]     Test net output #0: accuracy = 0.885641
I0526 09:07:55.305784 23331 solver.cpp:409]     Test net output #1: loss = 0.370617 (* 1 = 0.370617 loss)
I0526 09:08:16.218765 23331 solver.cpp:237] Iteration 810000, loss = 1.06923
I0526 09:08:16.218829 23331 solver.cpp:253]     Train net output #0: loss = 1.06923 (* 1 = 1.06923 loss)
I0526 09:08:16.218848 23331 sgd_solver.cpp:106] Iteration 810000, lr = 0.0035
I0526 09:08:32.862869 23331 solver.cpp:237] Iteration 811500, loss = 1.1734
I0526 09:08:32.863039 23331 solver.cpp:253]     Train net output #0: loss = 1.1734 (* 1 = 1.1734 loss)
I0526 09:08:32.863055 23331 sgd_solver.cpp:106] Iteration 811500, lr = 0.0035
I0526 09:08:49.587381 23331 solver.cpp:237] Iteration 813000, loss = 0.958201
I0526 09:08:49.587451 23331 solver.cpp:253]     Train net output #0: loss = 0.958203 (* 1 = 0.958203 loss)
I0526 09:08:49.587469 23331 sgd_solver.cpp:106] Iteration 813000, lr = 0.0035
I0526 09:09:06.370730 23331 solver.cpp:237] Iteration 814500, loss = 1.24411
I0526 09:09:06.370915 23331 solver.cpp:253]     Train net output #0: loss = 1.24411 (* 1 = 1.24411 loss)
I0526 09:09:06.370932 23331 sgd_solver.cpp:106] Iteration 814500, lr = 0.0035
I0526 09:09:23.334447 23331 solver.cpp:237] Iteration 816000, loss = 1.08039
I0526 09:09:23.334486 23331 solver.cpp:253]     Train net output #0: loss = 1.08039 (* 1 = 1.08039 loss)
I0526 09:09:23.334506 23331 sgd_solver.cpp:106] Iteration 816000, lr = 0.0035
I0526 09:09:40.408277 23331 solver.cpp:237] Iteration 817500, loss = 1.54084
I0526 09:09:40.408470 23331 solver.cpp:253]     Train net output #0: loss = 1.54084 (* 1 = 1.54084 loss)
I0526 09:09:40.408488 23331 sgd_solver.cpp:106] Iteration 817500, lr = 0.0035
I0526 09:09:57.544541 23331 solver.cpp:237] Iteration 819000, loss = 1.12438
I0526 09:09:57.544601 23331 solver.cpp:253]     Train net output #0: loss = 1.12439 (* 1 = 1.12439 loss)
I0526 09:09:57.544627 23331 sgd_solver.cpp:106] Iteration 819000, lr = 0.0035
I0526 09:10:35.281493 23331 solver.cpp:237] Iteration 820500, loss = 1.33669
I0526 09:10:35.281687 23331 solver.cpp:253]     Train net output #0: loss = 1.33669 (* 1 = 1.33669 loss)
I0526 09:10:35.281703 23331 sgd_solver.cpp:106] Iteration 820500, lr = 0.0035
I0526 09:10:52.122094 23331 solver.cpp:237] Iteration 822000, loss = 1.34876
I0526 09:10:52.122150 23331 solver.cpp:253]     Train net output #0: loss = 1.34876 (* 1 = 1.34876 loss)
I0526 09:10:52.122176 23331 sgd_solver.cpp:106] Iteration 822000, lr = 0.0035
I0526 09:11:09.108117 23331 solver.cpp:237] Iteration 823500, loss = 1.10038
I0526 09:11:09.108283 23331 solver.cpp:253]     Train net output #0: loss = 1.10038 (* 1 = 1.10038 loss)
I0526 09:11:09.108300 23331 sgd_solver.cpp:106] Iteration 823500, lr = 0.0035
I0526 09:11:25.897883 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_825000.caffemodel
I0526 09:11:25.945873 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_825000.solverstate
I0526 09:11:25.976064 23331 solver.cpp:237] Iteration 825000, loss = 1.1701
I0526 09:11:25.976125 23331 solver.cpp:253]     Train net output #0: loss = 1.17011 (* 1 = 1.17011 loss)
I0526 09:11:25.976141 23331 sgd_solver.cpp:106] Iteration 825000, lr = 0.0035
I0526 09:11:42.912664 23331 solver.cpp:237] Iteration 826500, loss = 1.21765
I0526 09:11:42.912861 23331 solver.cpp:253]     Train net output #0: loss = 1.21765 (* 1 = 1.21765 loss)
I0526 09:11:42.912878 23331 sgd_solver.cpp:106] Iteration 826500, lr = 0.0035
I0526 09:12:00.158871 23331 solver.cpp:237] Iteration 828000, loss = 0.491349
I0526 09:12:00.158911 23331 solver.cpp:253]     Train net output #0: loss = 0.491351 (* 1 = 0.491351 loss)
I0526 09:12:00.158934 23331 sgd_solver.cpp:106] Iteration 828000, lr = 0.0035
I0526 09:12:16.845758 23331 solver.cpp:237] Iteration 829500, loss = 1.32204
I0526 09:12:16.845945 23331 solver.cpp:253]     Train net output #0: loss = 1.32205 (* 1 = 1.32205 loss)
I0526 09:12:16.845963 23331 sgd_solver.cpp:106] Iteration 829500, lr = 0.0035
I0526 09:12:54.441476 23331 solver.cpp:237] Iteration 831000, loss = 1.57392
I0526 09:12:54.441665 23331 solver.cpp:253]     Train net output #0: loss = 1.57392 (* 1 = 1.57392 loss)
I0526 09:12:54.441684 23331 sgd_solver.cpp:106] Iteration 831000, lr = 0.0035
I0526 09:13:11.325737 23331 solver.cpp:237] Iteration 832500, loss = 0.967413
I0526 09:13:11.325778 23331 solver.cpp:253]     Train net output #0: loss = 0.967416 (* 1 = 0.967416 loss)
I0526 09:13:11.325795 23331 sgd_solver.cpp:106] Iteration 832500, lr = 0.0035
I0526 09:13:28.362884 23331 solver.cpp:237] Iteration 834000, loss = 1.00538
I0526 09:13:28.363068 23331 solver.cpp:253]     Train net output #0: loss = 1.00538 (* 1 = 1.00538 loss)
I0526 09:13:28.363086 23331 sgd_solver.cpp:106] Iteration 834000, lr = 0.0035
I0526 09:13:45.500263 23331 solver.cpp:237] Iteration 835500, loss = 0.892689
I0526 09:13:45.500321 23331 solver.cpp:253]     Train net output #0: loss = 0.892693 (* 1 = 0.892693 loss)
I0526 09:13:45.500346 23331 sgd_solver.cpp:106] Iteration 835500, lr = 0.0035
I0526 09:14:02.734004 23331 solver.cpp:237] Iteration 837000, loss = 1.61417
I0526 09:14:02.734181 23331 solver.cpp:253]     Train net output #0: loss = 1.61418 (* 1 = 1.61418 loss)
I0526 09:14:02.734199 23331 sgd_solver.cpp:106] Iteration 837000, lr = 0.0035
I0526 09:14:19.469290 23331 solver.cpp:237] Iteration 838500, loss = 0.804131
I0526 09:14:19.469348 23331 solver.cpp:253]     Train net output #0: loss = 0.804136 (* 1 = 0.804136 loss)
I0526 09:14:19.469367 23331 sgd_solver.cpp:106] Iteration 838500, lr = 0.0035
I0526 09:14:36.228099 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_840000.caffemodel
I0526 09:14:36.274731 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_840000.solverstate
I0526 09:14:36.300870 23331 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 09:15:36.086735 23331 solver.cpp:409]     Test net output #0: accuracy = 0.890468
I0526 09:15:36.086933 23331 solver.cpp:409]     Test net output #1: loss = 0.341177 (* 1 = 0.341177 loss)
I0526 09:15:57.017259 23331 solver.cpp:237] Iteration 840000, loss = 1.18555
I0526 09:15:57.017326 23331 solver.cpp:253]     Train net output #0: loss = 1.18555 (* 1 = 1.18555 loss)
I0526 09:15:57.017355 23331 sgd_solver.cpp:106] Iteration 840000, lr = 0.0035
I0526 09:16:13.657158 23331 solver.cpp:237] Iteration 841500, loss = 0.955355
I0526 09:16:13.657351 23331 solver.cpp:253]     Train net output #0: loss = 0.955361 (* 1 = 0.955361 loss)
I0526 09:16:13.657368 23331 sgd_solver.cpp:106] Iteration 841500, lr = 0.0035
I0526 09:16:30.311436 23331 solver.cpp:237] Iteration 843000, loss = 2.02845
I0526 09:16:30.311475 23331 solver.cpp:253]     Train net output #0: loss = 2.02846 (* 1 = 2.02846 loss)
I0526 09:16:30.311491 23331 sgd_solver.cpp:106] Iteration 843000, lr = 0.0035
I0526 09:16:46.943810 23331 solver.cpp:237] Iteration 844500, loss = 0.923959
I0526 09:16:46.944000 23331 solver.cpp:253]     Train net output #0: loss = 0.923963 (* 1 = 0.923963 loss)
I0526 09:16:46.944016 23331 sgd_solver.cpp:106] Iteration 844500, lr = 0.0035
I0526 09:17:03.653365 23331 solver.cpp:237] Iteration 846000, loss = 0.888878
I0526 09:17:03.653426 23331 solver.cpp:253]     Train net output #0: loss = 0.888882 (* 1 = 0.888882 loss)
I0526 09:17:03.653451 23331 sgd_solver.cpp:106] Iteration 846000, lr = 0.0035
I0526 09:17:20.722650 23331 solver.cpp:237] Iteration 847500, loss = 1.33958
I0526 09:17:20.722820 23331 solver.cpp:253]     Train net output #0: loss = 1.33959 (* 1 = 1.33959 loss)
I0526 09:17:20.722836 23331 sgd_solver.cpp:106] Iteration 847500, lr = 0.0035
I0526 09:17:37.574792 23331 solver.cpp:237] Iteration 849000, loss = 0.837631
I0526 09:17:37.574851 23331 solver.cpp:253]     Train net output #0: loss = 0.837634 (* 1 = 0.837634 loss)
I0526 09:17:37.574869 23331 sgd_solver.cpp:106] Iteration 849000, lr = 0.0035
I0526 09:18:15.353410 23331 solver.cpp:237] Iteration 850500, loss = 0.876575
I0526 09:18:15.353607 23331 solver.cpp:253]     Train net output #0: loss = 0.876578 (* 1 = 0.876578 loss)
I0526 09:18:15.353626 23331 sgd_solver.cpp:106] Iteration 850500, lr = 0.0035
I0526 09:18:32.295560 23331 solver.cpp:237] Iteration 852000, loss = 1.12576
I0526 09:18:32.295608 23331 solver.cpp:253]     Train net output #0: loss = 1.12576 (* 1 = 1.12576 loss)
I0526 09:18:32.295626 23331 sgd_solver.cpp:106] Iteration 852000, lr = 0.0035
I0526 09:18:49.172541 23331 solver.cpp:237] Iteration 853500, loss = 0.900844
I0526 09:18:49.172742 23331 solver.cpp:253]     Train net output #0: loss = 0.900847 (* 1 = 0.900847 loss)
I0526 09:18:49.172760 23331 sgd_solver.cpp:106] Iteration 853500, lr = 0.0035
I0526 09:19:06.103492 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_855000.caffemodel
I0526 09:19:06.149755 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_855000.solverstate
I0526 09:19:06.178160 23331 solver.cpp:237] Iteration 855000, loss = 1.19973
I0526 09:19:06.178223 23331 solver.cpp:253]     Train net output #0: loss = 1.19974 (* 1 = 1.19974 loss)
I0526 09:19:06.178243 23331 sgd_solver.cpp:106] Iteration 855000, lr = 0.0035
I0526 09:19:22.835791 23331 solver.cpp:237] Iteration 856500, loss = 1.01569
I0526 09:19:22.835973 23331 solver.cpp:253]     Train net output #0: loss = 1.01569 (* 1 = 1.01569 loss)
I0526 09:19:22.835989 23331 sgd_solver.cpp:106] Iteration 856500, lr = 0.0035
I0526 09:19:39.595186 23331 solver.cpp:237] Iteration 858000, loss = 0.771109
I0526 09:19:39.595245 23331 solver.cpp:253]     Train net output #0: loss = 0.771113 (* 1 = 0.771113 loss)
I0526 09:19:39.595263 23331 sgd_solver.cpp:106] Iteration 858000, lr = 0.0035
I0526 09:19:56.525339 23331 solver.cpp:237] Iteration 859500, loss = 0.862202
I0526 09:19:56.525533 23331 solver.cpp:253]     Train net output #0: loss = 0.862205 (* 1 = 0.862205 loss)
I0526 09:19:56.525552 23331 sgd_solver.cpp:106] Iteration 859500, lr = 0.0035
I0526 09:20:34.178867 23331 solver.cpp:237] Iteration 861000, loss = 1.57294
I0526 09:20:34.179059 23331 solver.cpp:253]     Train net output #0: loss = 1.57294 (* 1 = 1.57294 loss)
I0526 09:20:34.179075 23331 sgd_solver.cpp:106] Iteration 861000, lr = 0.0035
I0526 09:20:51.004961 23331 solver.cpp:237] Iteration 862500, loss = 2.86832
I0526 09:20:51.005019 23331 solver.cpp:253]     Train net output #0: loss = 2.86832 (* 1 = 2.86832 loss)
I0526 09:20:51.005048 23331 sgd_solver.cpp:106] Iteration 862500, lr = 0.0035
I0526 09:21:07.879673 23331 solver.cpp:237] Iteration 864000, loss = 2.33007
I0526 09:21:07.879848 23331 solver.cpp:253]     Train net output #0: loss = 2.33007 (* 1 = 2.33007 loss)
I0526 09:21:07.879865 23331 sgd_solver.cpp:106] Iteration 864000, lr = 0.0035
I0526 09:21:24.734174 23331 solver.cpp:237] Iteration 865500, loss = 1.06388
I0526 09:21:24.734230 23331 solver.cpp:253]     Train net output #0: loss = 1.06389 (* 1 = 1.06389 loss)
I0526 09:21:24.734247 23331 sgd_solver.cpp:106] Iteration 865500, lr = 0.0035
I0526 09:21:41.731003 23331 solver.cpp:237] Iteration 867000, loss = 1.02306
I0526 09:21:41.731189 23331 solver.cpp:253]     Train net output #0: loss = 1.02306 (* 1 = 1.02306 loss)
I0526 09:21:41.731207 23331 sgd_solver.cpp:106] Iteration 867000, lr = 0.0035
I0526 09:21:58.837888 23331 solver.cpp:237] Iteration 868500, loss = 1.65776
I0526 09:21:58.837926 23331 solver.cpp:253]     Train net output #0: loss = 1.65776 (* 1 = 1.65776 loss)
I0526 09:21:58.837945 23331 sgd_solver.cpp:106] Iteration 868500, lr = 0.0035
I0526 09:22:16.024256 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_870000.caffemodel
I0526 09:22:16.079412 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_870000.solverstate
I0526 09:22:16.104786 23331 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 09:23:36.450227 23331 solver.cpp:409]     Test net output #0: accuracy = 0.891329
I0526 09:23:36.450417 23331 solver.cpp:409]     Test net output #1: loss = 0.340513 (* 1 = 0.340513 loss)
I0526 09:23:57.332883 23331 solver.cpp:237] Iteration 870000, loss = 1.76046
I0526 09:23:57.332944 23331 solver.cpp:253]     Train net output #0: loss = 1.76047 (* 1 = 1.76047 loss)
I0526 09:23:57.332972 23331 sgd_solver.cpp:106] Iteration 870000, lr = 0.0035
I0526 09:24:14.272783 23331 solver.cpp:237] Iteration 871500, loss = 1.32129
I0526 09:24:14.272974 23331 solver.cpp:253]     Train net output #0: loss = 1.3213 (* 1 = 1.3213 loss)
I0526 09:24:14.272990 23331 sgd_solver.cpp:106] Iteration 871500, lr = 0.0035
I0526 09:24:31.472731 23331 solver.cpp:237] Iteration 873000, loss = 0.783027
I0526 09:24:31.472790 23331 solver.cpp:253]     Train net output #0: loss = 0.783029 (* 1 = 0.783029 loss)
I0526 09:24:31.472810 23331 sgd_solver.cpp:106] Iteration 873000, lr = 0.0035
I0526 09:24:48.123728 23331 solver.cpp:237] Iteration 874500, loss = 0.846039
I0526 09:24:48.123920 23331 solver.cpp:253]     Train net output #0: loss = 0.846041 (* 1 = 0.846041 loss)
I0526 09:24:48.123937 23331 sgd_solver.cpp:106] Iteration 874500, lr = 0.0035
I0526 09:25:05.086678 23331 solver.cpp:237] Iteration 876000, loss = 0.963295
I0526 09:25:05.086735 23331 solver.cpp:253]     Train net output #0: loss = 0.963296 (* 1 = 0.963296 loss)
I0526 09:25:05.086751 23331 sgd_solver.cpp:106] Iteration 876000, lr = 0.0035
I0526 09:25:22.249487 23331 solver.cpp:237] Iteration 877500, loss = 0.722165
I0526 09:25:22.249682 23331 solver.cpp:253]     Train net output #0: loss = 0.722167 (* 1 = 0.722167 loss)
I0526 09:25:22.249699 23331 sgd_solver.cpp:106] Iteration 877500, lr = 0.0035
I0526 09:25:38.875716 23331 solver.cpp:237] Iteration 879000, loss = 0.965025
I0526 09:25:38.875757 23331 solver.cpp:253]     Train net output #0: loss = 0.965027 (* 1 = 0.965027 loss)
I0526 09:25:38.875774 23331 sgd_solver.cpp:106] Iteration 879000, lr = 0.0035
I0526 09:26:16.597031 23331 solver.cpp:237] Iteration 880500, loss = 1.11694
I0526 09:26:16.597236 23331 solver.cpp:253]     Train net output #0: loss = 1.11694 (* 1 = 1.11694 loss)
I0526 09:26:16.597254 23331 sgd_solver.cpp:106] Iteration 880500, lr = 0.0035
I0526 09:26:33.538527 23331 solver.cpp:237] Iteration 882000, loss = 0.838058
I0526 09:26:33.538568 23331 solver.cpp:253]     Train net output #0: loss = 0.83806 (* 1 = 0.83806 loss)
I0526 09:26:33.538586 23331 sgd_solver.cpp:106] Iteration 882000, lr = 0.0035
I0526 09:26:50.587821 23331 solver.cpp:237] Iteration 883500, loss = 0.622473
I0526 09:26:50.588012 23331 solver.cpp:253]     Train net output #0: loss = 0.622476 (* 1 = 0.622476 loss)
I0526 09:26:50.588029 23331 sgd_solver.cpp:106] Iteration 883500, lr = 0.0035
I0526 09:27:07.538874 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_885000.caffemodel
I0526 09:27:07.586367 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_885000.solverstate
I0526 09:27:07.617075 23331 solver.cpp:237] Iteration 885000, loss = 1.70248
I0526 09:27:07.617133 23331 solver.cpp:253]     Train net output #0: loss = 1.70248 (* 1 = 1.70248 loss)
I0526 09:27:07.617161 23331 sgd_solver.cpp:106] Iteration 885000, lr = 0.0035
I0526 09:27:24.404250 23331 solver.cpp:237] Iteration 886500, loss = 0.868824
I0526 09:27:24.404425 23331 solver.cpp:253]     Train net output #0: loss = 0.868826 (* 1 = 0.868826 loss)
I0526 09:27:24.404443 23331 sgd_solver.cpp:106] Iteration 886500, lr = 0.0035
I0526 09:27:41.057528 23331 solver.cpp:237] Iteration 888000, loss = 2.2833
I0526 09:27:41.057585 23331 solver.cpp:253]     Train net output #0: loss = 2.2833 (* 1 = 2.2833 loss)
I0526 09:27:41.057603 23331 sgd_solver.cpp:106] Iteration 888000, lr = 0.0035
I0526 09:27:57.689301 23331 solver.cpp:237] Iteration 889500, loss = 0.83439
I0526 09:27:57.689492 23331 solver.cpp:253]     Train net output #0: loss = 0.834392 (* 1 = 0.834392 loss)
I0526 09:27:57.689510 23331 sgd_solver.cpp:106] Iteration 889500, lr = 0.0035
I0526 09:28:35.364751 23331 solver.cpp:237] Iteration 891000, loss = 0.560867
I0526 09:28:35.364948 23331 solver.cpp:253]     Train net output #0: loss = 0.560868 (* 1 = 0.560868 loss)
I0526 09:28:35.364966 23331 sgd_solver.cpp:106] Iteration 891000, lr = 0.0035
I0526 09:28:52.142477 23331 solver.cpp:237] Iteration 892500, loss = 1.03277
I0526 09:28:52.142532 23331 solver.cpp:253]     Train net output #0: loss = 1.03278 (* 1 = 1.03278 loss)
I0526 09:28:52.142549 23331 sgd_solver.cpp:106] Iteration 892500, lr = 0.0035
I0526 09:29:09.009539 23331 solver.cpp:237] Iteration 894000, loss = 0.928392
I0526 09:29:09.009744 23331 solver.cpp:253]     Train net output #0: loss = 0.928393 (* 1 = 0.928393 loss)
I0526 09:29:09.009762 23331 sgd_solver.cpp:106] Iteration 894000, lr = 0.0035
I0526 09:29:26.183634 23331 solver.cpp:237] Iteration 895500, loss = 1.13413
I0526 09:29:26.183673 23331 solver.cpp:253]     Train net output #0: loss = 1.13413 (* 1 = 1.13413 loss)
I0526 09:29:26.183691 23331 sgd_solver.cpp:106] Iteration 895500, lr = 0.0035
I0526 09:29:43.086678 23331 solver.cpp:237] Iteration 897000, loss = 1.36196
I0526 09:29:43.086869 23331 solver.cpp:253]     Train net output #0: loss = 1.36196 (* 1 = 1.36196 loss)
I0526 09:29:43.086885 23331 sgd_solver.cpp:106] Iteration 897000, lr = 0.0035
I0526 09:29:59.963098 23331 solver.cpp:237] Iteration 898500, loss = 0.89335
I0526 09:29:59.963157 23331 solver.cpp:253]     Train net output #0: loss = 0.89335 (* 1 = 0.89335 loss)
I0526 09:29:59.963181 23331 sgd_solver.cpp:106] Iteration 898500, lr = 0.0035
I0526 09:30:17.118782 23331 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_900000.caffemodel
I0526 09:30:17.166535 23331 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_900000.solverstate
I0526 09:30:17.195657 23331 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 09:31:16.370872 23331 solver.cpp:409]     Test net output #0: accuracy = 0.893516
I0526 09:31:16.371068 23331 solver.cpp:409]     Test net output #1: loss = 0.371986 (* 1 = 0.371986 loss)
I0526 09:31:37.308135 23331 solver.cpp:237] Iteration 900000, loss = 0.951369
I0526 09:31:37.308187 23331 solver.cpp:253]     Train net output #0: loss = 0.95137 (* 1 = 0.95137 loss)
I0526 09:31:37.308199 23331 sgd_solver.cpp:106] Iteration 900000, lr = 0.0035
I0526 09:31:54.272070 23331 solver.cpp:237] Iteration 901500, loss = 0.972511
I0526 09:31:54.272248 23331 solver.cpp:253]     Train net output #0: loss = 0.972513 (* 1 = 0.972513 loss)
I0526 09:31:54.272264 23331 sgd_solver.cpp:106] Iteration 901500, lr = 0.0035
I0526 09:32:11.035495 23331 solver.cpp:237] Iteration 903000, loss = 1.10266
I0526 09:32:11.035552 23331 solver.cpp:253]     Train net output #0: loss = 1.10266 (* 1 = 1.10266 loss)
I0526 09:32:11.035568 23331 sgd_solver.cpp:106] Iteration 903000, lr = 0.0035
aprun: Apid 11267265: Caught signal Terminated, sending to application
*** Aborted at 1464269535 (unix time) try "date -d @1464269535" if you are using GNU date ***
aprun: Apid 11267265: Caught signal Terminated, sending to application
PC: @     0x2aaab928d1d1 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
*** SIGTERM (@0x5b20) received by PID 23331 (TID 0x2aaac746f900) from PID 23328; stack trace: ***
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab928d1d1 (unknown)
    @     0x2aaab9288a91 (unknown)
=>> PBS: job killed: walltime 7226 exceeded limit 7200
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab9288d63 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab9261342 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab927da66 (unknown)
    @     0x2aaab91d1cf6 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab91d1f13 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab91bab60 cuLaunchKernel
    @     0x2aaaaace01b0 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaaaacfa6bd cudaLaunch
    @           0x636733 __device_stub__ZN5caffe9SGDUpdateIfEEviPT_S2_S1_S1_()
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @           0x6368f9 caffe::sgd_update_gpu<>()
    @           0x5e1fc8 caffe::SGDSolver<>::ComputeUpdateValue()
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @           0x5e28f3 caffe::SGDSolver<>::ApplyUpdate()
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @           0x5ca245 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11267265: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11267265: Caught signal Terminated, sending to application
aprun: Apid 11267265: Caught signal Terminated, sending to application
aprun: Apid 11267265: Caught signal Terminated, sending to application
aprun: Apid 11267265: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02372] [c6-1c1s2n0] [Thu May 26 09:32:17 2016] PE RANK 0 exit signal Terminated
Application 11267265 exit codes: 143
Application 11267265 resources: utime ~6320s, stime ~887s, Rss ~5330004, inblocks ~10491045, outblocks ~474919
