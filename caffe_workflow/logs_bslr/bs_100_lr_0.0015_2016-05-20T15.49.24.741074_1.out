2810617
I0525 14:55:46.027268 23721 caffe.cpp:184] Using GPUs 0
I0525 14:55:46.453682 23721 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.0015
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074.prototxt"
I0525 14:55:46.455263 23721 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074.prototxt
I0525 14:55:46.467059 23721 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 14:55:46.467119 23721 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 14:55:46.467463 23721 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 14:55:46.467640 23721 layer_factory.hpp:77] Creating layer data_hdf5
I0525 14:55:46.467664 23721 net.cpp:106] Creating Layer data_hdf5
I0525 14:55:46.467679 23721 net.cpp:411] data_hdf5 -> data
I0525 14:55:46.467711 23721 net.cpp:411] data_hdf5 -> label
I0525 14:55:46.467743 23721 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 14:55:46.469004 23721 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 14:55:46.471213 23721 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 14:56:07.957137 23721 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 14:56:07.962211 23721 net.cpp:150] Setting up data_hdf5
I0525 14:56:07.962252 23721 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 14:56:07.962266 23721 net.cpp:157] Top shape: 100 (100)
I0525 14:56:07.962280 23721 net.cpp:165] Memory required for data: 2540400
I0525 14:56:07.962292 23721 layer_factory.hpp:77] Creating layer conv1
I0525 14:56:07.962327 23721 net.cpp:106] Creating Layer conv1
I0525 14:56:07.962337 23721 net.cpp:454] conv1 <- data
I0525 14:56:07.962359 23721 net.cpp:411] conv1 -> conv1
I0525 14:56:08.333720 23721 net.cpp:150] Setting up conv1
I0525 14:56:08.333765 23721 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:56:08.333776 23721 net.cpp:165] Memory required for data: 30188400
I0525 14:56:08.333806 23721 layer_factory.hpp:77] Creating layer relu1
I0525 14:56:08.333827 23721 net.cpp:106] Creating Layer relu1
I0525 14:56:08.333838 23721 net.cpp:454] relu1 <- conv1
I0525 14:56:08.333853 23721 net.cpp:397] relu1 -> conv1 (in-place)
I0525 14:56:08.334369 23721 net.cpp:150] Setting up relu1
I0525 14:56:08.334386 23721 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:56:08.334398 23721 net.cpp:165] Memory required for data: 57836400
I0525 14:56:08.334408 23721 layer_factory.hpp:77] Creating layer pool1
I0525 14:56:08.334424 23721 net.cpp:106] Creating Layer pool1
I0525 14:56:08.334434 23721 net.cpp:454] pool1 <- conv1
I0525 14:56:08.334449 23721 net.cpp:411] pool1 -> pool1
I0525 14:56:08.334529 23721 net.cpp:150] Setting up pool1
I0525 14:56:08.334544 23721 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 14:56:08.334554 23721 net.cpp:165] Memory required for data: 71660400
I0525 14:56:08.334565 23721 layer_factory.hpp:77] Creating layer conv2
I0525 14:56:08.334588 23721 net.cpp:106] Creating Layer conv2
I0525 14:56:08.334597 23721 net.cpp:454] conv2 <- pool1
I0525 14:56:08.334621 23721 net.cpp:411] conv2 -> conv2
I0525 14:56:08.337340 23721 net.cpp:150] Setting up conv2
I0525 14:56:08.337368 23721 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:56:08.337378 23721 net.cpp:165] Memory required for data: 91532400
I0525 14:56:08.337399 23721 layer_factory.hpp:77] Creating layer relu2
I0525 14:56:08.337412 23721 net.cpp:106] Creating Layer relu2
I0525 14:56:08.337424 23721 net.cpp:454] relu2 <- conv2
I0525 14:56:08.337435 23721 net.cpp:397] relu2 -> conv2 (in-place)
I0525 14:56:08.337767 23721 net.cpp:150] Setting up relu2
I0525 14:56:08.337781 23721 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:56:08.337792 23721 net.cpp:165] Memory required for data: 111404400
I0525 14:56:08.337803 23721 layer_factory.hpp:77] Creating layer pool2
I0525 14:56:08.337815 23721 net.cpp:106] Creating Layer pool2
I0525 14:56:08.337826 23721 net.cpp:454] pool2 <- conv2
I0525 14:56:08.337838 23721 net.cpp:411] pool2 -> pool2
I0525 14:56:08.337919 23721 net.cpp:150] Setting up pool2
I0525 14:56:08.337934 23721 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 14:56:08.337944 23721 net.cpp:165] Memory required for data: 121340400
I0525 14:56:08.337954 23721 layer_factory.hpp:77] Creating layer conv3
I0525 14:56:08.337972 23721 net.cpp:106] Creating Layer conv3
I0525 14:56:08.337982 23721 net.cpp:454] conv3 <- pool2
I0525 14:56:08.337997 23721 net.cpp:411] conv3 -> conv3
I0525 14:56:08.339926 23721 net.cpp:150] Setting up conv3
I0525 14:56:08.339948 23721 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:56:08.339962 23721 net.cpp:165] Memory required for data: 132182000
I0525 14:56:08.339979 23721 layer_factory.hpp:77] Creating layer relu3
I0525 14:56:08.339995 23721 net.cpp:106] Creating Layer relu3
I0525 14:56:08.340006 23721 net.cpp:454] relu3 <- conv3
I0525 14:56:08.340018 23721 net.cpp:397] relu3 -> conv3 (in-place)
I0525 14:56:08.340487 23721 net.cpp:150] Setting up relu3
I0525 14:56:08.340504 23721 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:56:08.340515 23721 net.cpp:165] Memory required for data: 143023600
I0525 14:56:08.340525 23721 layer_factory.hpp:77] Creating layer pool3
I0525 14:56:08.340538 23721 net.cpp:106] Creating Layer pool3
I0525 14:56:08.340548 23721 net.cpp:454] pool3 <- conv3
I0525 14:56:08.340561 23721 net.cpp:411] pool3 -> pool3
I0525 14:56:08.340628 23721 net.cpp:150] Setting up pool3
I0525 14:56:08.340641 23721 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 14:56:08.340651 23721 net.cpp:165] Memory required for data: 148444400
I0525 14:56:08.340662 23721 layer_factory.hpp:77] Creating layer conv4
I0525 14:56:08.340677 23721 net.cpp:106] Creating Layer conv4
I0525 14:56:08.340687 23721 net.cpp:454] conv4 <- pool3
I0525 14:56:08.340701 23721 net.cpp:411] conv4 -> conv4
I0525 14:56:08.343649 23721 net.cpp:150] Setting up conv4
I0525 14:56:08.343678 23721 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:56:08.343688 23721 net.cpp:165] Memory required for data: 152073200
I0525 14:56:08.343704 23721 layer_factory.hpp:77] Creating layer relu4
I0525 14:56:08.343719 23721 net.cpp:106] Creating Layer relu4
I0525 14:56:08.343729 23721 net.cpp:454] relu4 <- conv4
I0525 14:56:08.343741 23721 net.cpp:397] relu4 -> conv4 (in-place)
I0525 14:56:08.344207 23721 net.cpp:150] Setting up relu4
I0525 14:56:08.344223 23721 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:56:08.344233 23721 net.cpp:165] Memory required for data: 155702000
I0525 14:56:08.344243 23721 layer_factory.hpp:77] Creating layer pool4
I0525 14:56:08.344255 23721 net.cpp:106] Creating Layer pool4
I0525 14:56:08.344265 23721 net.cpp:454] pool4 <- conv4
I0525 14:56:08.344277 23721 net.cpp:411] pool4 -> pool4
I0525 14:56:08.344346 23721 net.cpp:150] Setting up pool4
I0525 14:56:08.344359 23721 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 14:56:08.344368 23721 net.cpp:165] Memory required for data: 157516400
I0525 14:56:08.344378 23721 layer_factory.hpp:77] Creating layer ip1
I0525 14:56:08.344399 23721 net.cpp:106] Creating Layer ip1
I0525 14:56:08.344409 23721 net.cpp:454] ip1 <- pool4
I0525 14:56:08.344424 23721 net.cpp:411] ip1 -> ip1
I0525 14:56:08.359805 23721 net.cpp:150] Setting up ip1
I0525 14:56:08.359833 23721 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:56:08.359849 23721 net.cpp:165] Memory required for data: 157594800
I0525 14:56:08.359875 23721 layer_factory.hpp:77] Creating layer relu5
I0525 14:56:08.359891 23721 net.cpp:106] Creating Layer relu5
I0525 14:56:08.359902 23721 net.cpp:454] relu5 <- ip1
I0525 14:56:08.359916 23721 net.cpp:397] relu5 -> ip1 (in-place)
I0525 14:56:08.360256 23721 net.cpp:150] Setting up relu5
I0525 14:56:08.360270 23721 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:56:08.360280 23721 net.cpp:165] Memory required for data: 157673200
I0525 14:56:08.360291 23721 layer_factory.hpp:77] Creating layer drop1
I0525 14:56:08.360311 23721 net.cpp:106] Creating Layer drop1
I0525 14:56:08.360321 23721 net.cpp:454] drop1 <- ip1
I0525 14:56:08.360333 23721 net.cpp:397] drop1 -> ip1 (in-place)
I0525 14:56:08.360393 23721 net.cpp:150] Setting up drop1
I0525 14:56:08.360406 23721 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:56:08.360415 23721 net.cpp:165] Memory required for data: 157751600
I0525 14:56:08.360425 23721 layer_factory.hpp:77] Creating layer ip2
I0525 14:56:08.360442 23721 net.cpp:106] Creating Layer ip2
I0525 14:56:08.360453 23721 net.cpp:454] ip2 <- ip1
I0525 14:56:08.360466 23721 net.cpp:411] ip2 -> ip2
I0525 14:56:08.360932 23721 net.cpp:150] Setting up ip2
I0525 14:56:08.360945 23721 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:56:08.360955 23721 net.cpp:165] Memory required for data: 157790800
I0525 14:56:08.360971 23721 layer_factory.hpp:77] Creating layer relu6
I0525 14:56:08.360983 23721 net.cpp:106] Creating Layer relu6
I0525 14:56:08.360993 23721 net.cpp:454] relu6 <- ip2
I0525 14:56:08.361004 23721 net.cpp:397] relu6 -> ip2 (in-place)
I0525 14:56:08.361529 23721 net.cpp:150] Setting up relu6
I0525 14:56:08.361546 23721 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:56:08.361555 23721 net.cpp:165] Memory required for data: 157830000
I0525 14:56:08.361565 23721 layer_factory.hpp:77] Creating layer drop2
I0525 14:56:08.361578 23721 net.cpp:106] Creating Layer drop2
I0525 14:56:08.361588 23721 net.cpp:454] drop2 <- ip2
I0525 14:56:08.361600 23721 net.cpp:397] drop2 -> ip2 (in-place)
I0525 14:56:08.361644 23721 net.cpp:150] Setting up drop2
I0525 14:56:08.361656 23721 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:56:08.361666 23721 net.cpp:165] Memory required for data: 157869200
I0525 14:56:08.361676 23721 layer_factory.hpp:77] Creating layer ip3
I0525 14:56:08.361690 23721 net.cpp:106] Creating Layer ip3
I0525 14:56:08.361699 23721 net.cpp:454] ip3 <- ip2
I0525 14:56:08.361709 23721 net.cpp:411] ip3 -> ip3
I0525 14:56:08.361920 23721 net.cpp:150] Setting up ip3
I0525 14:56:08.361933 23721 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:56:08.361943 23721 net.cpp:165] Memory required for data: 157873600
I0525 14:56:08.361958 23721 layer_factory.hpp:77] Creating layer drop3
I0525 14:56:08.361971 23721 net.cpp:106] Creating Layer drop3
I0525 14:56:08.361981 23721 net.cpp:454] drop3 <- ip3
I0525 14:56:08.361994 23721 net.cpp:397] drop3 -> ip3 (in-place)
I0525 14:56:08.362032 23721 net.cpp:150] Setting up drop3
I0525 14:56:08.362046 23721 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:56:08.362056 23721 net.cpp:165] Memory required for data: 157878000
I0525 14:56:08.362063 23721 layer_factory.hpp:77] Creating layer loss
I0525 14:56:08.362082 23721 net.cpp:106] Creating Layer loss
I0525 14:56:08.362092 23721 net.cpp:454] loss <- ip3
I0525 14:56:08.362103 23721 net.cpp:454] loss <- label
I0525 14:56:08.362115 23721 net.cpp:411] loss -> loss
I0525 14:56:08.362131 23721 layer_factory.hpp:77] Creating layer loss
I0525 14:56:08.362835 23721 net.cpp:150] Setting up loss
I0525 14:56:08.362856 23721 net.cpp:157] Top shape: (1)
I0525 14:56:08.362870 23721 net.cpp:160]     with loss weight 1
I0525 14:56:08.362912 23721 net.cpp:165] Memory required for data: 157878004
I0525 14:56:08.362922 23721 net.cpp:226] loss needs backward computation.
I0525 14:56:08.362933 23721 net.cpp:226] drop3 needs backward computation.
I0525 14:56:08.362943 23721 net.cpp:226] ip3 needs backward computation.
I0525 14:56:08.362954 23721 net.cpp:226] drop2 needs backward computation.
I0525 14:56:08.362964 23721 net.cpp:226] relu6 needs backward computation.
I0525 14:56:08.362972 23721 net.cpp:226] ip2 needs backward computation.
I0525 14:56:08.362982 23721 net.cpp:226] drop1 needs backward computation.
I0525 14:56:08.362993 23721 net.cpp:226] relu5 needs backward computation.
I0525 14:56:08.363003 23721 net.cpp:226] ip1 needs backward computation.
I0525 14:56:08.363013 23721 net.cpp:226] pool4 needs backward computation.
I0525 14:56:08.363023 23721 net.cpp:226] relu4 needs backward computation.
I0525 14:56:08.363031 23721 net.cpp:226] conv4 needs backward computation.
I0525 14:56:08.363042 23721 net.cpp:226] pool3 needs backward computation.
I0525 14:56:08.363052 23721 net.cpp:226] relu3 needs backward computation.
I0525 14:56:08.363071 23721 net.cpp:226] conv3 needs backward computation.
I0525 14:56:08.363082 23721 net.cpp:226] pool2 needs backward computation.
I0525 14:56:08.363093 23721 net.cpp:226] relu2 needs backward computation.
I0525 14:56:08.363103 23721 net.cpp:226] conv2 needs backward computation.
I0525 14:56:08.363114 23721 net.cpp:226] pool1 needs backward computation.
I0525 14:56:08.363124 23721 net.cpp:226] relu1 needs backward computation.
I0525 14:56:08.363134 23721 net.cpp:226] conv1 needs backward computation.
I0525 14:56:08.363145 23721 net.cpp:228] data_hdf5 does not need backward computation.
I0525 14:56:08.363155 23721 net.cpp:270] This network produces output loss
I0525 14:56:08.363178 23721 net.cpp:283] Network initialization done.
I0525 14:56:08.364894 23721 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074.prototxt
I0525 14:56:08.364966 23721 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 14:56:08.365319 23721 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 14:56:08.365509 23721 layer_factory.hpp:77] Creating layer data_hdf5
I0525 14:56:08.365523 23721 net.cpp:106] Creating Layer data_hdf5
I0525 14:56:08.365536 23721 net.cpp:411] data_hdf5 -> data
I0525 14:56:08.365553 23721 net.cpp:411] data_hdf5 -> label
I0525 14:56:08.365567 23721 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 14:56:08.366925 23721 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 14:56:29.661111 23721 net.cpp:150] Setting up data_hdf5
I0525 14:56:29.661276 23721 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 14:56:29.661290 23721 net.cpp:157] Top shape: 100 (100)
I0525 14:56:29.661301 23721 net.cpp:165] Memory required for data: 2540400
I0525 14:56:29.661315 23721 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 14:56:29.661344 23721 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 14:56:29.661355 23721 net.cpp:454] label_data_hdf5_1_split <- label
I0525 14:56:29.661370 23721 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 14:56:29.661391 23721 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 14:56:29.661463 23721 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 14:56:29.661476 23721 net.cpp:157] Top shape: 100 (100)
I0525 14:56:29.661489 23721 net.cpp:157] Top shape: 100 (100)
I0525 14:56:29.661497 23721 net.cpp:165] Memory required for data: 2541200
I0525 14:56:29.661505 23721 layer_factory.hpp:77] Creating layer conv1
I0525 14:56:29.661526 23721 net.cpp:106] Creating Layer conv1
I0525 14:56:29.661535 23721 net.cpp:454] conv1 <- data
I0525 14:56:29.661550 23721 net.cpp:411] conv1 -> conv1
I0525 14:56:29.663511 23721 net.cpp:150] Setting up conv1
I0525 14:56:29.663530 23721 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:56:29.663545 23721 net.cpp:165] Memory required for data: 30189200
I0525 14:56:29.663566 23721 layer_factory.hpp:77] Creating layer relu1
I0525 14:56:29.663581 23721 net.cpp:106] Creating Layer relu1
I0525 14:56:29.663591 23721 net.cpp:454] relu1 <- conv1
I0525 14:56:29.663604 23721 net.cpp:397] relu1 -> conv1 (in-place)
I0525 14:56:29.664100 23721 net.cpp:150] Setting up relu1
I0525 14:56:29.664116 23721 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:56:29.664127 23721 net.cpp:165] Memory required for data: 57837200
I0525 14:56:29.664139 23721 layer_factory.hpp:77] Creating layer pool1
I0525 14:56:29.664155 23721 net.cpp:106] Creating Layer pool1
I0525 14:56:29.664165 23721 net.cpp:454] pool1 <- conv1
I0525 14:56:29.664177 23721 net.cpp:411] pool1 -> pool1
I0525 14:56:29.664252 23721 net.cpp:150] Setting up pool1
I0525 14:56:29.664266 23721 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 14:56:29.664275 23721 net.cpp:165] Memory required for data: 71661200
I0525 14:56:29.664286 23721 layer_factory.hpp:77] Creating layer conv2
I0525 14:56:29.664304 23721 net.cpp:106] Creating Layer conv2
I0525 14:56:29.664314 23721 net.cpp:454] conv2 <- pool1
I0525 14:56:29.664326 23721 net.cpp:411] conv2 -> conv2
I0525 14:56:29.666244 23721 net.cpp:150] Setting up conv2
I0525 14:56:29.666267 23721 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:56:29.666280 23721 net.cpp:165] Memory required for data: 91533200
I0525 14:56:29.666297 23721 layer_factory.hpp:77] Creating layer relu2
I0525 14:56:29.666311 23721 net.cpp:106] Creating Layer relu2
I0525 14:56:29.666321 23721 net.cpp:454] relu2 <- conv2
I0525 14:56:29.666332 23721 net.cpp:397] relu2 -> conv2 (in-place)
I0525 14:56:29.666676 23721 net.cpp:150] Setting up relu2
I0525 14:56:29.666690 23721 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:56:29.666700 23721 net.cpp:165] Memory required for data: 111405200
I0525 14:56:29.666710 23721 layer_factory.hpp:77] Creating layer pool2
I0525 14:56:29.666723 23721 net.cpp:106] Creating Layer pool2
I0525 14:56:29.666733 23721 net.cpp:454] pool2 <- conv2
I0525 14:56:29.666745 23721 net.cpp:411] pool2 -> pool2
I0525 14:56:29.666818 23721 net.cpp:150] Setting up pool2
I0525 14:56:29.666831 23721 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 14:56:29.666841 23721 net.cpp:165] Memory required for data: 121341200
I0525 14:56:29.666851 23721 layer_factory.hpp:77] Creating layer conv3
I0525 14:56:29.666870 23721 net.cpp:106] Creating Layer conv3
I0525 14:56:29.666882 23721 net.cpp:454] conv3 <- pool2
I0525 14:56:29.666894 23721 net.cpp:411] conv3 -> conv3
I0525 14:56:29.668875 23721 net.cpp:150] Setting up conv3
I0525 14:56:29.668895 23721 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:56:29.668907 23721 net.cpp:165] Memory required for data: 132182800
I0525 14:56:29.668939 23721 layer_factory.hpp:77] Creating layer relu3
I0525 14:56:29.668953 23721 net.cpp:106] Creating Layer relu3
I0525 14:56:29.668963 23721 net.cpp:454] relu3 <- conv3
I0525 14:56:29.668977 23721 net.cpp:397] relu3 -> conv3 (in-place)
I0525 14:56:29.669450 23721 net.cpp:150] Setting up relu3
I0525 14:56:29.669466 23721 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:56:29.669476 23721 net.cpp:165] Memory required for data: 143024400
I0525 14:56:29.669486 23721 layer_factory.hpp:77] Creating layer pool3
I0525 14:56:29.669499 23721 net.cpp:106] Creating Layer pool3
I0525 14:56:29.669508 23721 net.cpp:454] pool3 <- conv3
I0525 14:56:29.669523 23721 net.cpp:411] pool3 -> pool3
I0525 14:56:29.669594 23721 net.cpp:150] Setting up pool3
I0525 14:56:29.669606 23721 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 14:56:29.669616 23721 net.cpp:165] Memory required for data: 148445200
I0525 14:56:29.669625 23721 layer_factory.hpp:77] Creating layer conv4
I0525 14:56:29.669643 23721 net.cpp:106] Creating Layer conv4
I0525 14:56:29.669653 23721 net.cpp:454] conv4 <- pool3
I0525 14:56:29.669667 23721 net.cpp:411] conv4 -> conv4
I0525 14:56:29.671761 23721 net.cpp:150] Setting up conv4
I0525 14:56:29.671782 23721 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:56:29.671795 23721 net.cpp:165] Memory required for data: 152074000
I0525 14:56:29.671809 23721 layer_factory.hpp:77] Creating layer relu4
I0525 14:56:29.671823 23721 net.cpp:106] Creating Layer relu4
I0525 14:56:29.671833 23721 net.cpp:454] relu4 <- conv4
I0525 14:56:29.671846 23721 net.cpp:397] relu4 -> conv4 (in-place)
I0525 14:56:29.672322 23721 net.cpp:150] Setting up relu4
I0525 14:56:29.672338 23721 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:56:29.672348 23721 net.cpp:165] Memory required for data: 155702800
I0525 14:56:29.672358 23721 layer_factory.hpp:77] Creating layer pool4
I0525 14:56:29.672371 23721 net.cpp:106] Creating Layer pool4
I0525 14:56:29.672380 23721 net.cpp:454] pool4 <- conv4
I0525 14:56:29.672394 23721 net.cpp:411] pool4 -> pool4
I0525 14:56:29.672464 23721 net.cpp:150] Setting up pool4
I0525 14:56:29.672477 23721 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 14:56:29.672487 23721 net.cpp:165] Memory required for data: 157517200
I0525 14:56:29.672497 23721 layer_factory.hpp:77] Creating layer ip1
I0525 14:56:29.672513 23721 net.cpp:106] Creating Layer ip1
I0525 14:56:29.672523 23721 net.cpp:454] ip1 <- pool4
I0525 14:56:29.672538 23721 net.cpp:411] ip1 -> ip1
I0525 14:56:29.687937 23721 net.cpp:150] Setting up ip1
I0525 14:56:29.687963 23721 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:56:29.687976 23721 net.cpp:165] Memory required for data: 157595600
I0525 14:56:29.687999 23721 layer_factory.hpp:77] Creating layer relu5
I0525 14:56:29.688014 23721 net.cpp:106] Creating Layer relu5
I0525 14:56:29.688024 23721 net.cpp:454] relu5 <- ip1
I0525 14:56:29.688037 23721 net.cpp:397] relu5 -> ip1 (in-place)
I0525 14:56:29.688386 23721 net.cpp:150] Setting up relu5
I0525 14:56:29.688401 23721 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:56:29.688410 23721 net.cpp:165] Memory required for data: 157674000
I0525 14:56:29.688421 23721 layer_factory.hpp:77] Creating layer drop1
I0525 14:56:29.688439 23721 net.cpp:106] Creating Layer drop1
I0525 14:56:29.688448 23721 net.cpp:454] drop1 <- ip1
I0525 14:56:29.688462 23721 net.cpp:397] drop1 -> ip1 (in-place)
I0525 14:56:29.688506 23721 net.cpp:150] Setting up drop1
I0525 14:56:29.688519 23721 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:56:29.688529 23721 net.cpp:165] Memory required for data: 157752400
I0525 14:56:29.688539 23721 layer_factory.hpp:77] Creating layer ip2
I0525 14:56:29.688554 23721 net.cpp:106] Creating Layer ip2
I0525 14:56:29.688562 23721 net.cpp:454] ip2 <- ip1
I0525 14:56:29.688576 23721 net.cpp:411] ip2 -> ip2
I0525 14:56:29.689054 23721 net.cpp:150] Setting up ip2
I0525 14:56:29.689067 23721 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:56:29.689077 23721 net.cpp:165] Memory required for data: 157791600
I0525 14:56:29.689093 23721 layer_factory.hpp:77] Creating layer relu6
I0525 14:56:29.689119 23721 net.cpp:106] Creating Layer relu6
I0525 14:56:29.689129 23721 net.cpp:454] relu6 <- ip2
I0525 14:56:29.689142 23721 net.cpp:397] relu6 -> ip2 (in-place)
I0525 14:56:29.689682 23721 net.cpp:150] Setting up relu6
I0525 14:56:29.689697 23721 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:56:29.689707 23721 net.cpp:165] Memory required for data: 157830800
I0525 14:56:29.689718 23721 layer_factory.hpp:77] Creating layer drop2
I0525 14:56:29.689731 23721 net.cpp:106] Creating Layer drop2
I0525 14:56:29.689741 23721 net.cpp:454] drop2 <- ip2
I0525 14:56:29.689754 23721 net.cpp:397] drop2 -> ip2 (in-place)
I0525 14:56:29.689798 23721 net.cpp:150] Setting up drop2
I0525 14:56:29.689811 23721 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:56:29.689821 23721 net.cpp:165] Memory required for data: 157870000
I0525 14:56:29.689831 23721 layer_factory.hpp:77] Creating layer ip3
I0525 14:56:29.689846 23721 net.cpp:106] Creating Layer ip3
I0525 14:56:29.689856 23721 net.cpp:454] ip3 <- ip2
I0525 14:56:29.689868 23721 net.cpp:411] ip3 -> ip3
I0525 14:56:29.690094 23721 net.cpp:150] Setting up ip3
I0525 14:56:29.690107 23721 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:56:29.690117 23721 net.cpp:165] Memory required for data: 157874400
I0525 14:56:29.690134 23721 layer_factory.hpp:77] Creating layer drop3
I0525 14:56:29.690146 23721 net.cpp:106] Creating Layer drop3
I0525 14:56:29.690155 23721 net.cpp:454] drop3 <- ip3
I0525 14:56:29.690168 23721 net.cpp:397] drop3 -> ip3 (in-place)
I0525 14:56:29.690210 23721 net.cpp:150] Setting up drop3
I0525 14:56:29.690223 23721 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:56:29.690232 23721 net.cpp:165] Memory required for data: 157878800
I0525 14:56:29.690240 23721 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 14:56:29.690255 23721 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 14:56:29.690265 23721 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 14:56:29.690277 23721 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 14:56:29.690294 23721 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 14:56:29.690366 23721 net.cpp:150] Setting up ip3_drop3_0_split
I0525 14:56:29.690378 23721 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:56:29.690390 23721 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:56:29.690400 23721 net.cpp:165] Memory required for data: 157887600
I0525 14:56:29.690410 23721 layer_factory.hpp:77] Creating layer accuracy
I0525 14:56:29.690431 23721 net.cpp:106] Creating Layer accuracy
I0525 14:56:29.690441 23721 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 14:56:29.690453 23721 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 14:56:29.690466 23721 net.cpp:411] accuracy -> accuracy
I0525 14:56:29.690488 23721 net.cpp:150] Setting up accuracy
I0525 14:56:29.690500 23721 net.cpp:157] Top shape: (1)
I0525 14:56:29.690510 23721 net.cpp:165] Memory required for data: 157887604
I0525 14:56:29.690520 23721 layer_factory.hpp:77] Creating layer loss
I0525 14:56:29.690533 23721 net.cpp:106] Creating Layer loss
I0525 14:56:29.690543 23721 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 14:56:29.690554 23721 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 14:56:29.690567 23721 net.cpp:411] loss -> loss
I0525 14:56:29.690585 23721 layer_factory.hpp:77] Creating layer loss
I0525 14:56:29.691078 23721 net.cpp:150] Setting up loss
I0525 14:56:29.691092 23721 net.cpp:157] Top shape: (1)
I0525 14:56:29.691102 23721 net.cpp:160]     with loss weight 1
I0525 14:56:29.691120 23721 net.cpp:165] Memory required for data: 157887608
I0525 14:56:29.691131 23721 net.cpp:226] loss needs backward computation.
I0525 14:56:29.691143 23721 net.cpp:228] accuracy does not need backward computation.
I0525 14:56:29.691154 23721 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 14:56:29.691164 23721 net.cpp:226] drop3 needs backward computation.
I0525 14:56:29.691172 23721 net.cpp:226] ip3 needs backward computation.
I0525 14:56:29.691184 23721 net.cpp:226] drop2 needs backward computation.
I0525 14:56:29.691202 23721 net.cpp:226] relu6 needs backward computation.
I0525 14:56:29.691212 23721 net.cpp:226] ip2 needs backward computation.
I0525 14:56:29.691222 23721 net.cpp:226] drop1 needs backward computation.
I0525 14:56:29.691231 23721 net.cpp:226] relu5 needs backward computation.
I0525 14:56:29.691241 23721 net.cpp:226] ip1 needs backward computation.
I0525 14:56:29.691251 23721 net.cpp:226] pool4 needs backward computation.
I0525 14:56:29.691262 23721 net.cpp:226] relu4 needs backward computation.
I0525 14:56:29.691272 23721 net.cpp:226] conv4 needs backward computation.
I0525 14:56:29.691280 23721 net.cpp:226] pool3 needs backward computation.
I0525 14:56:29.691292 23721 net.cpp:226] relu3 needs backward computation.
I0525 14:56:29.691301 23721 net.cpp:226] conv3 needs backward computation.
I0525 14:56:29.691313 23721 net.cpp:226] pool2 needs backward computation.
I0525 14:56:29.691323 23721 net.cpp:226] relu2 needs backward computation.
I0525 14:56:29.691332 23721 net.cpp:226] conv2 needs backward computation.
I0525 14:56:29.691342 23721 net.cpp:226] pool1 needs backward computation.
I0525 14:56:29.691352 23721 net.cpp:226] relu1 needs backward computation.
I0525 14:56:29.691362 23721 net.cpp:226] conv1 needs backward computation.
I0525 14:56:29.691375 23721 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 14:56:29.691385 23721 net.cpp:228] data_hdf5 does not need backward computation.
I0525 14:56:29.691395 23721 net.cpp:270] This network produces output accuracy
I0525 14:56:29.691407 23721 net.cpp:270] This network produces output loss
I0525 14:56:29.691436 23721 net.cpp:283] Network initialization done.
I0525 14:56:29.691568 23721 solver.cpp:60] Solver scaffolding done.
I0525 14:56:29.692703 23721 caffe.cpp:212] Starting Optimization
I0525 14:56:29.692718 23721 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 14:56:29.692729 23721 solver.cpp:289] Learning Rate Policy: fixed
I0525 14:56:29.693802 23721 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 14:57:17.428804 23721 solver.cpp:409]     Test net output #0: accuracy = 0.0554934
I0525 14:57:17.428971 23721 solver.cpp:409]     Test net output #1: loss = 2.40037 (* 1 = 2.40037 loss)
I0525 14:57:17.461881 23721 solver.cpp:237] Iteration 0, loss = 2.39868
I0525 14:57:17.461918 23721 solver.cpp:253]     Train net output #0: loss = 2.39868 (* 1 = 2.39868 loss)
I0525 14:57:17.461936 23721 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0525 14:57:26.179345 23721 solver.cpp:237] Iteration 150, loss = 2.34714
I0525 14:57:26.179381 23721 solver.cpp:253]     Train net output #0: loss = 2.34714 (* 1 = 2.34714 loss)
I0525 14:57:26.179395 23721 sgd_solver.cpp:106] Iteration 150, lr = 0.0015
I0525 14:57:34.898493 23721 solver.cpp:237] Iteration 300, loss = 2.28117
I0525 14:57:34.898527 23721 solver.cpp:253]     Train net output #0: loss = 2.28117 (* 1 = 2.28117 loss)
I0525 14:57:34.898543 23721 sgd_solver.cpp:106] Iteration 300, lr = 0.0015
I0525 14:57:43.620842 23721 solver.cpp:237] Iteration 450, loss = 2.15727
I0525 14:57:43.620888 23721 solver.cpp:253]     Train net output #0: loss = 2.15727 (* 1 = 2.15727 loss)
I0525 14:57:43.620908 23721 sgd_solver.cpp:106] Iteration 450, lr = 0.0015
I0525 14:57:52.346627 23721 solver.cpp:237] Iteration 600, loss = 1.94824
I0525 14:57:52.346776 23721 solver.cpp:253]     Train net output #0: loss = 1.94824 (* 1 = 1.94824 loss)
I0525 14:57:52.346789 23721 sgd_solver.cpp:106] Iteration 600, lr = 0.0015
I0525 14:58:01.067168 23721 solver.cpp:237] Iteration 750, loss = 2.10798
I0525 14:58:01.067203 23721 solver.cpp:253]     Train net output #0: loss = 2.10798 (* 1 = 2.10798 loss)
I0525 14:58:01.067220 23721 sgd_solver.cpp:106] Iteration 750, lr = 0.0015
I0525 14:58:09.787612 23721 solver.cpp:237] Iteration 900, loss = 1.95708
I0525 14:58:09.787654 23721 solver.cpp:253]     Train net output #0: loss = 1.95708 (* 1 = 1.95708 loss)
I0525 14:58:09.787673 23721 sgd_solver.cpp:106] Iteration 900, lr = 0.0015
I0525 14:58:40.556903 23721 solver.cpp:237] Iteration 1050, loss = 1.94418
I0525 14:58:40.557073 23721 solver.cpp:253]     Train net output #0: loss = 1.94418 (* 1 = 1.94418 loss)
I0525 14:58:40.557088 23721 sgd_solver.cpp:106] Iteration 1050, lr = 0.0015
I0525 14:58:49.282623 23721 solver.cpp:237] Iteration 1200, loss = 1.84266
I0525 14:58:49.282657 23721 solver.cpp:253]     Train net output #0: loss = 1.84266 (* 1 = 1.84266 loss)
I0525 14:58:49.282670 23721 sgd_solver.cpp:106] Iteration 1200, lr = 0.0015
I0525 14:58:58.006907 23721 solver.cpp:237] Iteration 1350, loss = 1.8671
I0525 14:58:58.006952 23721 solver.cpp:253]     Train net output #0: loss = 1.8671 (* 1 = 1.8671 loss)
I0525 14:58:58.006969 23721 sgd_solver.cpp:106] Iteration 1350, lr = 0.0015
I0525 14:59:06.673388 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_1500.caffemodel
I0525 14:59:06.755538 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_1500.solverstate
I0525 14:59:06.801995 23721 solver.cpp:237] Iteration 1500, loss = 1.86755
I0525 14:59:06.802042 23721 solver.cpp:253]     Train net output #0: loss = 1.86755 (* 1 = 1.86755 loss)
I0525 14:59:06.802058 23721 sgd_solver.cpp:106] Iteration 1500, lr = 0.0015
I0525 14:59:15.525712 23721 solver.cpp:237] Iteration 1650, loss = 1.9326
I0525 14:59:15.525854 23721 solver.cpp:253]     Train net output #0: loss = 1.9326 (* 1 = 1.9326 loss)
I0525 14:59:15.525868 23721 sgd_solver.cpp:106] Iteration 1650, lr = 0.0015
I0525 14:59:24.244320 23721 solver.cpp:237] Iteration 1800, loss = 1.72901
I0525 14:59:24.244367 23721 solver.cpp:253]     Train net output #0: loss = 1.72901 (* 1 = 1.72901 loss)
I0525 14:59:24.244380 23721 sgd_solver.cpp:106] Iteration 1800, lr = 0.0015
I0525 14:59:32.966529 23721 solver.cpp:237] Iteration 1950, loss = 1.74109
I0525 14:59:32.966564 23721 solver.cpp:253]     Train net output #0: loss = 1.74109 (* 1 = 1.74109 loss)
I0525 14:59:32.966579 23721 sgd_solver.cpp:106] Iteration 1950, lr = 0.0015
I0525 15:00:03.790040 23721 solver.cpp:237] Iteration 2100, loss = 1.83733
I0525 15:00:03.790195 23721 solver.cpp:253]     Train net output #0: loss = 1.83733 (* 1 = 1.83733 loss)
I0525 15:00:03.790210 23721 sgd_solver.cpp:106] Iteration 2100, lr = 0.0015
I0525 15:00:12.513278 23721 solver.cpp:237] Iteration 2250, loss = 1.81343
I0525 15:00:12.513322 23721 solver.cpp:253]     Train net output #0: loss = 1.81343 (* 1 = 1.81343 loss)
I0525 15:00:12.513339 23721 sgd_solver.cpp:106] Iteration 2250, lr = 0.0015
I0525 15:00:21.238647 23721 solver.cpp:237] Iteration 2400, loss = 1.80128
I0525 15:00:21.238683 23721 solver.cpp:253]     Train net output #0: loss = 1.80128 (* 1 = 1.80128 loss)
I0525 15:00:21.238699 23721 sgd_solver.cpp:106] Iteration 2400, lr = 0.0015
I0525 15:00:29.958586 23721 solver.cpp:237] Iteration 2550, loss = 1.69119
I0525 15:00:29.958626 23721 solver.cpp:253]     Train net output #0: loss = 1.69119 (* 1 = 1.69119 loss)
I0525 15:00:29.958642 23721 sgd_solver.cpp:106] Iteration 2550, lr = 0.0015
I0525 15:00:38.682659 23721 solver.cpp:237] Iteration 2700, loss = 1.7977
I0525 15:00:38.682818 23721 solver.cpp:253]     Train net output #0: loss = 1.7977 (* 1 = 1.7977 loss)
I0525 15:00:38.682832 23721 sgd_solver.cpp:106] Iteration 2700, lr = 0.0015
I0525 15:00:47.404819 23721 solver.cpp:237] Iteration 2850, loss = 1.68325
I0525 15:00:47.404852 23721 solver.cpp:253]     Train net output #0: loss = 1.68325 (* 1 = 1.68325 loss)
I0525 15:00:47.404871 23721 sgd_solver.cpp:106] Iteration 2850, lr = 0.0015
I0525 15:00:56.067073 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_3000.caffemodel
I0525 15:00:56.147128 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_3000.solverstate
I0525 15:00:56.173888 23721 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 15:01:42.988945 23721 solver.cpp:409]     Test net output #0: accuracy = 0.659093
I0525 15:01:42.989104 23721 solver.cpp:409]     Test net output #1: loss = 1.15753 (* 1 = 1.15753 loss)
I0525 15:02:05.066666 23721 solver.cpp:237] Iteration 3000, loss = 1.60903
I0525 15:02:05.066718 23721 solver.cpp:253]     Train net output #0: loss = 1.60903 (* 1 = 1.60903 loss)
I0525 15:02:05.066733 23721 sgd_solver.cpp:106] Iteration 3000, lr = 0.0015
I0525 15:02:13.801712 23721 solver.cpp:237] Iteration 3150, loss = 1.97039
I0525 15:02:13.801853 23721 solver.cpp:253]     Train net output #0: loss = 1.97039 (* 1 = 1.97039 loss)
I0525 15:02:13.801867 23721 sgd_solver.cpp:106] Iteration 3150, lr = 0.0015
I0525 15:02:22.533583 23721 solver.cpp:237] Iteration 3300, loss = 2.00703
I0525 15:02:22.533623 23721 solver.cpp:253]     Train net output #0: loss = 2.00703 (* 1 = 2.00703 loss)
I0525 15:02:22.533641 23721 sgd_solver.cpp:106] Iteration 3300, lr = 0.0015
I0525 15:02:31.272169 23721 solver.cpp:237] Iteration 3450, loss = 1.76836
I0525 15:02:31.272204 23721 solver.cpp:253]     Train net output #0: loss = 1.76836 (* 1 = 1.76836 loss)
I0525 15:02:31.272220 23721 sgd_solver.cpp:106] Iteration 3450, lr = 0.0015
I0525 15:02:40.006551 23721 solver.cpp:237] Iteration 3600, loss = 1.6772
I0525 15:02:40.006593 23721 solver.cpp:253]     Train net output #0: loss = 1.6772 (* 1 = 1.6772 loss)
I0525 15:02:40.006614 23721 sgd_solver.cpp:106] Iteration 3600, lr = 0.0015
I0525 15:02:48.740710 23721 solver.cpp:237] Iteration 3750, loss = 1.59628
I0525 15:02:48.740859 23721 solver.cpp:253]     Train net output #0: loss = 1.59628 (* 1 = 1.59628 loss)
I0525 15:02:48.740871 23721 sgd_solver.cpp:106] Iteration 3750, lr = 0.0015
I0525 15:02:57.471505 23721 solver.cpp:237] Iteration 3900, loss = 1.67098
I0525 15:02:57.471539 23721 solver.cpp:253]     Train net output #0: loss = 1.67098 (* 1 = 1.67098 loss)
I0525 15:02:57.471557 23721 sgd_solver.cpp:106] Iteration 3900, lr = 0.0015
I0525 15:03:28.319003 23721 solver.cpp:237] Iteration 4050, loss = 1.74235
I0525 15:03:28.319169 23721 solver.cpp:253]     Train net output #0: loss = 1.74235 (* 1 = 1.74235 loss)
I0525 15:03:28.319183 23721 sgd_solver.cpp:106] Iteration 4050, lr = 0.0015
I0525 15:03:37.051445 23721 solver.cpp:237] Iteration 4200, loss = 1.65188
I0525 15:03:37.051488 23721 solver.cpp:253]     Train net output #0: loss = 1.65188 (* 1 = 1.65188 loss)
I0525 15:03:37.051506 23721 sgd_solver.cpp:106] Iteration 4200, lr = 0.0015
I0525 15:03:45.783444 23721 solver.cpp:237] Iteration 4350, loss = 1.62964
I0525 15:03:45.783479 23721 solver.cpp:253]     Train net output #0: loss = 1.62964 (* 1 = 1.62964 loss)
I0525 15:03:45.783494 23721 sgd_solver.cpp:106] Iteration 4350, lr = 0.0015
I0525 15:03:54.459137 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_4500.caffemodel
I0525 15:03:54.539963 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_4500.solverstate
I0525 15:03:54.586238 23721 solver.cpp:237] Iteration 4500, loss = 1.73896
I0525 15:03:54.586287 23721 solver.cpp:253]     Train net output #0: loss = 1.73896 (* 1 = 1.73896 loss)
I0525 15:03:54.586304 23721 sgd_solver.cpp:106] Iteration 4500, lr = 0.0015
I0525 15:04:03.320626 23721 solver.cpp:237] Iteration 4650, loss = 1.85278
I0525 15:04:03.320791 23721 solver.cpp:253]     Train net output #0: loss = 1.85278 (* 1 = 1.85278 loss)
I0525 15:04:03.320803 23721 sgd_solver.cpp:106] Iteration 4650, lr = 0.0015
I0525 15:04:12.057238 23721 solver.cpp:237] Iteration 4800, loss = 1.58637
I0525 15:04:12.057274 23721 solver.cpp:253]     Train net output #0: loss = 1.58637 (* 1 = 1.58637 loss)
I0525 15:04:12.057291 23721 sgd_solver.cpp:106] Iteration 4800, lr = 0.0015
I0525 15:04:20.787458 23721 solver.cpp:237] Iteration 4950, loss = 1.57939
I0525 15:04:20.787504 23721 solver.cpp:253]     Train net output #0: loss = 1.57939 (* 1 = 1.57939 loss)
I0525 15:04:20.787521 23721 sgd_solver.cpp:106] Iteration 4950, lr = 0.0015
I0525 15:04:51.588450 23721 solver.cpp:237] Iteration 5100, loss = 1.79413
I0525 15:04:51.588614 23721 solver.cpp:253]     Train net output #0: loss = 1.79413 (* 1 = 1.79413 loss)
I0525 15:04:51.588629 23721 sgd_solver.cpp:106] Iteration 5100, lr = 0.0015
I0525 15:05:00.320765 23721 solver.cpp:237] Iteration 5250, loss = 1.55123
I0525 15:05:00.320799 23721 solver.cpp:253]     Train net output #0: loss = 1.55123 (* 1 = 1.55123 loss)
I0525 15:05:00.320818 23721 sgd_solver.cpp:106] Iteration 5250, lr = 0.0015
I0525 15:05:09.055099 23721 solver.cpp:237] Iteration 5400, loss = 1.45594
I0525 15:05:09.055135 23721 solver.cpp:253]     Train net output #0: loss = 1.45594 (* 1 = 1.45594 loss)
I0525 15:05:09.055150 23721 sgd_solver.cpp:106] Iteration 5400, lr = 0.0015
I0525 15:05:17.789608 23721 solver.cpp:237] Iteration 5550, loss = 1.74835
I0525 15:05:17.789649 23721 solver.cpp:253]     Train net output #0: loss = 1.74835 (* 1 = 1.74835 loss)
I0525 15:05:17.789666 23721 sgd_solver.cpp:106] Iteration 5550, lr = 0.0015
I0525 15:05:26.522514 23721 solver.cpp:237] Iteration 5700, loss = 1.41667
I0525 15:05:26.522665 23721 solver.cpp:253]     Train net output #0: loss = 1.41667 (* 1 = 1.41667 loss)
I0525 15:05:26.522680 23721 sgd_solver.cpp:106] Iteration 5700, lr = 0.0015
I0525 15:05:35.257362 23721 solver.cpp:237] Iteration 5850, loss = 1.42931
I0525 15:05:35.257405 23721 solver.cpp:253]     Train net output #0: loss = 1.42931 (* 1 = 1.42931 loss)
I0525 15:05:35.257422 23721 sgd_solver.cpp:106] Iteration 5850, lr = 0.0015
I0525 15:05:43.931459 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_6000.caffemodel
I0525 15:05:44.012079 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_6000.solverstate
I0525 15:05:44.039959 23721 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 15:06:51.679605 23721 solver.cpp:409]     Test net output #0: accuracy = 0.724614
I0525 15:06:51.679782 23721 solver.cpp:409]     Test net output #1: loss = 0.946008 (* 1 = 0.946008 loss)
I0525 15:07:13.868192 23721 solver.cpp:237] Iteration 6000, loss = 1.74692
I0525 15:07:13.868247 23721 solver.cpp:253]     Train net output #0: loss = 1.74692 (* 1 = 1.74692 loss)
I0525 15:07:13.868262 23721 sgd_solver.cpp:106] Iteration 6000, lr = 0.0015
I0525 15:07:22.599702 23721 solver.cpp:237] Iteration 6150, loss = 1.60802
I0525 15:07:22.599860 23721 solver.cpp:253]     Train net output #0: loss = 1.60802 (* 1 = 1.60802 loss)
I0525 15:07:22.599874 23721 sgd_solver.cpp:106] Iteration 6150, lr = 0.0015
I0525 15:07:31.328655 23721 solver.cpp:237] Iteration 6300, loss = 1.58434
I0525 15:07:31.328691 23721 solver.cpp:253]     Train net output #0: loss = 1.58434 (* 1 = 1.58434 loss)
I0525 15:07:31.328708 23721 sgd_solver.cpp:106] Iteration 6300, lr = 0.0015
I0525 15:07:40.067172 23721 solver.cpp:237] Iteration 6450, loss = 1.69441
I0525 15:07:40.067212 23721 solver.cpp:253]     Train net output #0: loss = 1.69441 (* 1 = 1.69441 loss)
I0525 15:07:40.067230 23721 sgd_solver.cpp:106] Iteration 6450, lr = 0.0015
I0525 15:07:48.802139 23721 solver.cpp:237] Iteration 6600, loss = 1.50943
I0525 15:07:48.802175 23721 solver.cpp:253]     Train net output #0: loss = 1.50943 (* 1 = 1.50943 loss)
I0525 15:07:48.802191 23721 sgd_solver.cpp:106] Iteration 6600, lr = 0.0015
I0525 15:07:57.532157 23721 solver.cpp:237] Iteration 6750, loss = 1.58548
I0525 15:07:57.532296 23721 solver.cpp:253]     Train net output #0: loss = 1.58548 (* 1 = 1.58548 loss)
I0525 15:07:57.532311 23721 sgd_solver.cpp:106] Iteration 6750, lr = 0.0015
I0525 15:08:06.265058 23721 solver.cpp:237] Iteration 6900, loss = 1.47628
I0525 15:08:06.265105 23721 solver.cpp:253]     Train net output #0: loss = 1.47628 (* 1 = 1.47628 loss)
I0525 15:08:06.265120 23721 sgd_solver.cpp:106] Iteration 6900, lr = 0.0015
I0525 15:08:37.145828 23721 solver.cpp:237] Iteration 7050, loss = 1.53068
I0525 15:08:37.145987 23721 solver.cpp:253]     Train net output #0: loss = 1.53068 (* 1 = 1.53068 loss)
I0525 15:08:37.146003 23721 sgd_solver.cpp:106] Iteration 7050, lr = 0.0015
I0525 15:08:45.878459 23721 solver.cpp:237] Iteration 7200, loss = 1.51269
I0525 15:08:45.878494 23721 solver.cpp:253]     Train net output #0: loss = 1.51269 (* 1 = 1.51269 loss)
I0525 15:08:45.878510 23721 sgd_solver.cpp:106] Iteration 7200, lr = 0.0015
I0525 15:08:54.606153 23721 solver.cpp:237] Iteration 7350, loss = 1.64951
I0525 15:08:54.606202 23721 solver.cpp:253]     Train net output #0: loss = 1.64951 (* 1 = 1.64951 loss)
I0525 15:08:54.606218 23721 sgd_solver.cpp:106] Iteration 7350, lr = 0.0015
I0525 15:09:03.279952 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_7500.caffemodel
I0525 15:09:03.361429 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_7500.solverstate
I0525 15:09:03.407043 23721 solver.cpp:237] Iteration 7500, loss = 1.55109
I0525 15:09:03.407093 23721 solver.cpp:253]     Train net output #0: loss = 1.55109 (* 1 = 1.55109 loss)
I0525 15:09:03.407109 23721 sgd_solver.cpp:106] Iteration 7500, lr = 0.0015
I0525 15:09:12.136786 23721 solver.cpp:237] Iteration 7650, loss = 1.48387
I0525 15:09:12.136929 23721 solver.cpp:253]     Train net output #0: loss = 1.48387 (* 1 = 1.48387 loss)
I0525 15:09:12.136942 23721 sgd_solver.cpp:106] Iteration 7650, lr = 0.0015
I0525 15:09:20.872500 23721 solver.cpp:237] Iteration 7800, loss = 1.48694
I0525 15:09:20.872550 23721 solver.cpp:253]     Train net output #0: loss = 1.48694 (* 1 = 1.48694 loss)
I0525 15:09:20.872565 23721 sgd_solver.cpp:106] Iteration 7800, lr = 0.0015
I0525 15:09:29.604970 23721 solver.cpp:237] Iteration 7950, loss = 1.38105
I0525 15:09:29.605005 23721 solver.cpp:253]     Train net output #0: loss = 1.38105 (* 1 = 1.38105 loss)
I0525 15:09:29.605021 23721 sgd_solver.cpp:106] Iteration 7950, lr = 0.0015
I0525 15:10:00.507371 23721 solver.cpp:237] Iteration 8100, loss = 1.46231
I0525 15:10:00.507539 23721 solver.cpp:253]     Train net output #0: loss = 1.46231 (* 1 = 1.46231 loss)
I0525 15:10:00.507555 23721 sgd_solver.cpp:106] Iteration 8100, lr = 0.0015
I0525 15:10:09.244072 23721 solver.cpp:237] Iteration 8250, loss = 1.4495
I0525 15:10:09.244107 23721 solver.cpp:253]     Train net output #0: loss = 1.4495 (* 1 = 1.4495 loss)
I0525 15:10:09.244124 23721 sgd_solver.cpp:106] Iteration 8250, lr = 0.0015
I0525 15:10:17.976706 23721 solver.cpp:237] Iteration 8400, loss = 1.36093
I0525 15:10:17.976747 23721 solver.cpp:253]     Train net output #0: loss = 1.36093 (* 1 = 1.36093 loss)
I0525 15:10:17.976764 23721 sgd_solver.cpp:106] Iteration 8400, lr = 0.0015
I0525 15:10:26.710790 23721 solver.cpp:237] Iteration 8550, loss = 1.52173
I0525 15:10:26.710821 23721 solver.cpp:253]     Train net output #0: loss = 1.52173 (* 1 = 1.52173 loss)
I0525 15:10:26.710834 23721 sgd_solver.cpp:106] Iteration 8550, lr = 0.0015
I0525 15:10:35.444142 23721 solver.cpp:237] Iteration 8700, loss = 1.46734
I0525 15:10:35.444298 23721 solver.cpp:253]     Train net output #0: loss = 1.46734 (* 1 = 1.46734 loss)
I0525 15:10:35.444313 23721 sgd_solver.cpp:106] Iteration 8700, lr = 0.0015
I0525 15:10:44.179005 23721 solver.cpp:237] Iteration 8850, loss = 1.22628
I0525 15:10:44.179040 23721 solver.cpp:253]     Train net output #0: loss = 1.22628 (* 1 = 1.22628 loss)
I0525 15:10:44.179056 23721 sgd_solver.cpp:106] Iteration 8850, lr = 0.0015
I0525 15:10:52.847061 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_9000.caffemodel
I0525 15:10:52.925635 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_9000.solverstate
I0525 15:10:52.951000 23721 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 15:11:39.493115 23721 solver.cpp:409]     Test net output #0: accuracy = 0.769881
I0525 15:11:39.493294 23721 solver.cpp:409]     Test net output #1: loss = 0.89247 (* 1 = 0.89247 loss)
I0525 15:12:01.616659 23721 solver.cpp:237] Iteration 9000, loss = 1.37726
I0525 15:12:01.616711 23721 solver.cpp:253]     Train net output #0: loss = 1.37726 (* 1 = 1.37726 loss)
I0525 15:12:01.616726 23721 sgd_solver.cpp:106] Iteration 9000, lr = 0.0015
I0525 15:12:10.354378 23721 solver.cpp:237] Iteration 9150, loss = 1.25147
I0525 15:12:10.354529 23721 solver.cpp:253]     Train net output #0: loss = 1.25147 (* 1 = 1.25147 loss)
I0525 15:12:10.354543 23721 sgd_solver.cpp:106] Iteration 9150, lr = 0.0015
I0525 15:12:19.091892 23721 solver.cpp:237] Iteration 9300, loss = 1.32598
I0525 15:12:19.091938 23721 solver.cpp:253]     Train net output #0: loss = 1.32598 (* 1 = 1.32598 loss)
I0525 15:12:19.091951 23721 sgd_solver.cpp:106] Iteration 9300, lr = 0.0015
I0525 15:12:27.821813 23721 solver.cpp:237] Iteration 9450, loss = 1.58776
I0525 15:12:27.821848 23721 solver.cpp:253]     Train net output #0: loss = 1.58776 (* 1 = 1.58776 loss)
I0525 15:12:27.821866 23721 sgd_solver.cpp:106] Iteration 9450, lr = 0.0015
I0525 15:12:36.556073 23721 solver.cpp:237] Iteration 9600, loss = 1.65131
I0525 15:12:36.556108 23721 solver.cpp:253]     Train net output #0: loss = 1.65131 (* 1 = 1.65131 loss)
I0525 15:12:36.556124 23721 sgd_solver.cpp:106] Iteration 9600, lr = 0.0015
I0525 15:12:45.291245 23721 solver.cpp:237] Iteration 9750, loss = 1.45426
I0525 15:12:45.291394 23721 solver.cpp:253]     Train net output #0: loss = 1.45426 (* 1 = 1.45426 loss)
I0525 15:12:45.291409 23721 sgd_solver.cpp:106] Iteration 9750, lr = 0.0015
I0525 15:12:54.024083 23721 solver.cpp:237] Iteration 9900, loss = 1.53894
I0525 15:12:54.024118 23721 solver.cpp:253]     Train net output #0: loss = 1.53894 (* 1 = 1.53894 loss)
I0525 15:12:54.024132 23721 sgd_solver.cpp:106] Iteration 9900, lr = 0.0015
I0525 15:13:24.882164 23721 solver.cpp:237] Iteration 10050, loss = 1.63338
I0525 15:13:24.882350 23721 solver.cpp:253]     Train net output #0: loss = 1.63338 (* 1 = 1.63338 loss)
I0525 15:13:24.882366 23721 sgd_solver.cpp:106] Iteration 10050, lr = 0.0015
I0525 15:13:33.616649 23721 solver.cpp:237] Iteration 10200, loss = 1.36672
I0525 15:13:33.616693 23721 solver.cpp:253]     Train net output #0: loss = 1.36672 (* 1 = 1.36672 loss)
I0525 15:13:33.616710 23721 sgd_solver.cpp:106] Iteration 10200, lr = 0.0015
I0525 15:13:42.356367 23721 solver.cpp:237] Iteration 10350, loss = 1.26997
I0525 15:13:42.356403 23721 solver.cpp:253]     Train net output #0: loss = 1.26997 (* 1 = 1.26997 loss)
I0525 15:13:42.356420 23721 sgd_solver.cpp:106] Iteration 10350, lr = 0.0015
I0525 15:13:51.034296 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_10500.caffemodel
I0525 15:13:51.113644 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_10500.solverstate
I0525 15:13:51.157969 23721 solver.cpp:237] Iteration 10500, loss = 1.60794
I0525 15:13:51.158015 23721 solver.cpp:253]     Train net output #0: loss = 1.60794 (* 1 = 1.60794 loss)
I0525 15:13:51.158028 23721 sgd_solver.cpp:106] Iteration 10500, lr = 0.0015
I0525 15:13:59.895756 23721 solver.cpp:237] Iteration 10650, loss = 1.45693
I0525 15:13:59.895913 23721 solver.cpp:253]     Train net output #0: loss = 1.45693 (* 1 = 1.45693 loss)
I0525 15:13:59.895927 23721 sgd_solver.cpp:106] Iteration 10650, lr = 0.0015
I0525 15:14:08.630471 23721 solver.cpp:237] Iteration 10800, loss = 1.46746
I0525 15:14:08.630506 23721 solver.cpp:253]     Train net output #0: loss = 1.46746 (* 1 = 1.46746 loss)
I0525 15:14:08.630522 23721 sgd_solver.cpp:106] Iteration 10800, lr = 0.0015
I0525 15:14:17.362257 23721 solver.cpp:237] Iteration 10950, loss = 1.39058
I0525 15:14:17.362292 23721 solver.cpp:253]     Train net output #0: loss = 1.39058 (* 1 = 1.39058 loss)
I0525 15:14:17.362304 23721 sgd_solver.cpp:106] Iteration 10950, lr = 0.0015
I0525 15:14:48.178351 23721 solver.cpp:237] Iteration 11100, loss = 1.28658
I0525 15:14:48.178519 23721 solver.cpp:253]     Train net output #0: loss = 1.28658 (* 1 = 1.28658 loss)
I0525 15:14:48.178534 23721 sgd_solver.cpp:106] Iteration 11100, lr = 0.0015
I0525 15:14:56.913712 23721 solver.cpp:237] Iteration 11250, loss = 1.4452
I0525 15:14:56.913746 23721 solver.cpp:253]     Train net output #0: loss = 1.4452 (* 1 = 1.4452 loss)
I0525 15:14:56.913763 23721 sgd_solver.cpp:106] Iteration 11250, lr = 0.0015
I0525 15:15:05.645478 23721 solver.cpp:237] Iteration 11400, loss = 1.46175
I0525 15:15:05.645514 23721 solver.cpp:253]     Train net output #0: loss = 1.46175 (* 1 = 1.46175 loss)
I0525 15:15:05.645526 23721 sgd_solver.cpp:106] Iteration 11400, lr = 0.0015
I0525 15:15:14.379103 23721 solver.cpp:237] Iteration 11550, loss = 1.35735
I0525 15:15:14.379151 23721 solver.cpp:253]     Train net output #0: loss = 1.35735 (* 1 = 1.35735 loss)
I0525 15:15:14.379169 23721 sgd_solver.cpp:106] Iteration 11550, lr = 0.0015
I0525 15:15:23.112609 23721 solver.cpp:237] Iteration 11700, loss = 1.32501
I0525 15:15:23.112751 23721 solver.cpp:253]     Train net output #0: loss = 1.32501 (* 1 = 1.32501 loss)
I0525 15:15:23.112764 23721 sgd_solver.cpp:106] Iteration 11700, lr = 0.0015
I0525 15:15:31.845335 23721 solver.cpp:237] Iteration 11850, loss = 1.18609
I0525 15:15:31.845369 23721 solver.cpp:253]     Train net output #0: loss = 1.18609 (* 1 = 1.18609 loss)
I0525 15:15:31.845386 23721 sgd_solver.cpp:106] Iteration 11850, lr = 0.0015
I0525 15:15:40.521176 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_12000.caffemodel
I0525 15:15:40.600014 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_12000.solverstate
I0525 15:15:40.626453 23721 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 15:16:48.302431 23721 solver.cpp:409]     Test net output #0: accuracy = 0.800987
I0525 15:16:48.302613 23721 solver.cpp:409]     Test net output #1: loss = 0.685451 (* 1 = 0.685451 loss)
I0525 15:17:10.381271 23721 solver.cpp:237] Iteration 12000, loss = 1.38066
I0525 15:17:10.381325 23721 solver.cpp:253]     Train net output #0: loss = 1.38066 (* 1 = 1.38066 loss)
I0525 15:17:10.381338 23721 sgd_solver.cpp:106] Iteration 12000, lr = 0.0015
I0525 15:17:19.110584 23721 solver.cpp:237] Iteration 12150, loss = 1.56387
I0525 15:17:19.110754 23721 solver.cpp:253]     Train net output #0: loss = 1.56387 (* 1 = 1.56387 loss)
I0525 15:17:19.110769 23721 sgd_solver.cpp:106] Iteration 12150, lr = 0.0015
I0525 15:17:27.833199 23721 solver.cpp:237] Iteration 12300, loss = 1.21378
I0525 15:17:27.833233 23721 solver.cpp:253]     Train net output #0: loss = 1.21378 (* 1 = 1.21378 loss)
I0525 15:17:27.833251 23721 sgd_solver.cpp:106] Iteration 12300, lr = 0.0015
I0525 15:17:36.558696 23721 solver.cpp:237] Iteration 12450, loss = 1.45526
I0525 15:17:36.558730 23721 solver.cpp:253]     Train net output #0: loss = 1.45526 (* 1 = 1.45526 loss)
I0525 15:17:36.558746 23721 sgd_solver.cpp:106] Iteration 12450, lr = 0.0015
I0525 15:17:45.282912 23721 solver.cpp:237] Iteration 12600, loss = 1.22139
I0525 15:17:45.282953 23721 solver.cpp:253]     Train net output #0: loss = 1.22139 (* 1 = 1.22139 loss)
I0525 15:17:45.282973 23721 sgd_solver.cpp:106] Iteration 12600, lr = 0.0015
I0525 15:17:54.005259 23721 solver.cpp:237] Iteration 12750, loss = 1.54986
I0525 15:17:54.005405 23721 solver.cpp:253]     Train net output #0: loss = 1.54986 (* 1 = 1.54986 loss)
I0525 15:17:54.005420 23721 sgd_solver.cpp:106] Iteration 12750, lr = 0.0015
I0525 15:18:02.731178 23721 solver.cpp:237] Iteration 12900, loss = 1.09353
I0525 15:18:02.731212 23721 solver.cpp:253]     Train net output #0: loss = 1.09353 (* 1 = 1.09353 loss)
I0525 15:18:02.731230 23721 sgd_solver.cpp:106] Iteration 12900, lr = 0.0015
I0525 15:18:33.570580 23721 solver.cpp:237] Iteration 13050, loss = 1.56593
I0525 15:18:33.570760 23721 solver.cpp:253]     Train net output #0: loss = 1.56593 (* 1 = 1.56593 loss)
I0525 15:18:33.570775 23721 sgd_solver.cpp:106] Iteration 13050, lr = 0.0015
I0525 15:18:42.295769 23721 solver.cpp:237] Iteration 13200, loss = 1.39694
I0525 15:18:42.295805 23721 solver.cpp:253]     Train net output #0: loss = 1.39694 (* 1 = 1.39694 loss)
I0525 15:18:42.295819 23721 sgd_solver.cpp:106] Iteration 13200, lr = 0.0015
I0525 15:18:51.016692 23721 solver.cpp:237] Iteration 13350, loss = 1.16002
I0525 15:18:51.016726 23721 solver.cpp:253]     Train net output #0: loss = 1.16002 (* 1 = 1.16002 loss)
I0525 15:18:51.016744 23721 sgd_solver.cpp:106] Iteration 13350, lr = 0.0015
I0525 15:18:59.681537 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_13500.caffemodel
I0525 15:18:59.761858 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_13500.solverstate
I0525 15:18:59.808681 23721 solver.cpp:237] Iteration 13500, loss = 1.47502
I0525 15:18:59.808732 23721 solver.cpp:253]     Train net output #0: loss = 1.47502 (* 1 = 1.47502 loss)
I0525 15:18:59.808746 23721 sgd_solver.cpp:106] Iteration 13500, lr = 0.0015
I0525 15:19:08.534466 23721 solver.cpp:237] Iteration 13650, loss = 1.42124
I0525 15:19:08.534621 23721 solver.cpp:253]     Train net output #0: loss = 1.42124 (* 1 = 1.42124 loss)
I0525 15:19:08.534636 23721 sgd_solver.cpp:106] Iteration 13650, lr = 0.0015
I0525 15:19:17.251215 23721 solver.cpp:237] Iteration 13800, loss = 1.39693
I0525 15:19:17.251248 23721 solver.cpp:253]     Train net output #0: loss = 1.39693 (* 1 = 1.39693 loss)
I0525 15:19:17.251266 23721 sgd_solver.cpp:106] Iteration 13800, lr = 0.0015
I0525 15:19:25.977557 23721 solver.cpp:237] Iteration 13950, loss = 1.45254
I0525 15:19:25.977602 23721 solver.cpp:253]     Train net output #0: loss = 1.45254 (* 1 = 1.45254 loss)
I0525 15:19:25.977617 23721 sgd_solver.cpp:106] Iteration 13950, lr = 0.0015
I0525 15:19:56.806762 23721 solver.cpp:237] Iteration 14100, loss = 1.33964
I0525 15:19:56.806941 23721 solver.cpp:253]     Train net output #0: loss = 1.33964 (* 1 = 1.33964 loss)
I0525 15:19:56.806956 23721 sgd_solver.cpp:106] Iteration 14100, lr = 0.0015
I0525 15:20:05.530212 23721 solver.cpp:237] Iteration 14250, loss = 1.29383
I0525 15:20:05.530248 23721 solver.cpp:253]     Train net output #0: loss = 1.29383 (* 1 = 1.29383 loss)
I0525 15:20:05.530261 23721 sgd_solver.cpp:106] Iteration 14250, lr = 0.0015
I0525 15:20:14.249191 23721 solver.cpp:237] Iteration 14400, loss = 1.50277
I0525 15:20:14.249233 23721 solver.cpp:253]     Train net output #0: loss = 1.50277 (* 1 = 1.50277 loss)
I0525 15:20:14.249249 23721 sgd_solver.cpp:106] Iteration 14400, lr = 0.0015
I0525 15:20:22.970857 23721 solver.cpp:237] Iteration 14550, loss = 1.45018
I0525 15:20:22.970892 23721 solver.cpp:253]     Train net output #0: loss = 1.45018 (* 1 = 1.45018 loss)
I0525 15:20:22.970906 23721 sgd_solver.cpp:106] Iteration 14550, lr = 0.0015
I0525 15:20:31.695638 23721 solver.cpp:237] Iteration 14700, loss = 1.3567
I0525 15:20:31.695792 23721 solver.cpp:253]     Train net output #0: loss = 1.3567 (* 1 = 1.3567 loss)
I0525 15:20:31.695806 23721 sgd_solver.cpp:106] Iteration 14700, lr = 0.0015
I0525 15:20:40.422366 23721 solver.cpp:237] Iteration 14850, loss = 1.34672
I0525 15:20:40.422401 23721 solver.cpp:253]     Train net output #0: loss = 1.34672 (* 1 = 1.34672 loss)
I0525 15:20:40.422422 23721 sgd_solver.cpp:106] Iteration 14850, lr = 0.0015
I0525 15:20:49.088182 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_15000.caffemodel
I0525 15:20:49.168763 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_15000.solverstate
I0525 15:20:49.197271 23721 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 15:21:35.996085 23721 solver.cpp:409]     Test net output #0: accuracy = 0.815901
I0525 15:21:35.996249 23721 solver.cpp:409]     Test net output #1: loss = 0.64541 (* 1 = 0.64541 loss)
I0525 15:21:56.852093 23721 solver.cpp:237] Iteration 15000, loss = 1.24388
I0525 15:21:56.852147 23721 solver.cpp:253]     Train net output #0: loss = 1.24388 (* 1 = 1.24388 loss)
I0525 15:21:56.852164 23721 sgd_solver.cpp:106] Iteration 15000, lr = 0.0015
I0525 15:22:05.587260 23721 solver.cpp:237] Iteration 15150, loss = 1.31416
I0525 15:22:05.587296 23721 solver.cpp:253]     Train net output #0: loss = 1.31416 (* 1 = 1.31416 loss)
I0525 15:22:05.587309 23721 sgd_solver.cpp:106] Iteration 15150, lr = 0.0015
I0525 15:22:14.320165 23721 solver.cpp:237] Iteration 15300, loss = 1.34283
I0525 15:22:14.320322 23721 solver.cpp:253]     Train net output #0: loss = 1.34283 (* 1 = 1.34283 loss)
I0525 15:22:14.320338 23721 sgd_solver.cpp:106] Iteration 15300, lr = 0.0015
I0525 15:22:23.057443 23721 solver.cpp:237] Iteration 15450, loss = 1.18416
I0525 15:22:23.057478 23721 solver.cpp:253]     Train net output #0: loss = 1.18416 (* 1 = 1.18416 loss)
I0525 15:22:23.057495 23721 sgd_solver.cpp:106] Iteration 15450, lr = 0.0015
I0525 15:22:31.786679 23721 solver.cpp:237] Iteration 15600, loss = 1.25652
I0525 15:22:31.786713 23721 solver.cpp:253]     Train net output #0: loss = 1.25652 (* 1 = 1.25652 loss)
I0525 15:22:31.786730 23721 sgd_solver.cpp:106] Iteration 15600, lr = 0.0015
I0525 15:22:40.523633 23721 solver.cpp:237] Iteration 15750, loss = 1.5156
I0525 15:22:40.523674 23721 solver.cpp:253]     Train net output #0: loss = 1.5156 (* 1 = 1.5156 loss)
I0525 15:22:40.523694 23721 sgd_solver.cpp:106] Iteration 15750, lr = 0.0015
I0525 15:22:49.258631 23721 solver.cpp:237] Iteration 15900, loss = 1.29158
I0525 15:22:49.258790 23721 solver.cpp:253]     Train net output #0: loss = 1.29158 (* 1 = 1.29158 loss)
I0525 15:22:49.258803 23721 sgd_solver.cpp:106] Iteration 15900, lr = 0.0015
I0525 15:23:18.852447 23721 solver.cpp:237] Iteration 16050, loss = 1.47152
I0525 15:23:18.852497 23721 solver.cpp:253]     Train net output #0: loss = 1.47152 (* 1 = 1.47152 loss)
I0525 15:23:18.852512 23721 sgd_solver.cpp:106] Iteration 16050, lr = 0.0015
I0525 15:23:27.586977 23721 solver.cpp:237] Iteration 16200, loss = 1.21522
I0525 15:23:27.587131 23721 solver.cpp:253]     Train net output #0: loss = 1.21522 (* 1 = 1.21522 loss)
I0525 15:23:27.587146 23721 sgd_solver.cpp:106] Iteration 16200, lr = 0.0015
I0525 15:23:36.318593 23721 solver.cpp:237] Iteration 16350, loss = 1.31469
I0525 15:23:36.318636 23721 solver.cpp:253]     Train net output #0: loss = 1.31469 (* 1 = 1.31469 loss)
I0525 15:23:36.318657 23721 sgd_solver.cpp:106] Iteration 16350, lr = 0.0015
I0525 15:23:45.000671 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_16500.caffemodel
I0525 15:23:45.079361 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_16500.solverstate
I0525 15:23:45.122858 23721 solver.cpp:237] Iteration 16500, loss = 1.25591
I0525 15:23:45.122902 23721 solver.cpp:253]     Train net output #0: loss = 1.25591 (* 1 = 1.25591 loss)
I0525 15:23:45.122918 23721 sgd_solver.cpp:106] Iteration 16500, lr = 0.0015
I0525 15:23:53.856669 23721 solver.cpp:237] Iteration 16650, loss = 1.50827
I0525 15:23:53.856705 23721 solver.cpp:253]     Train net output #0: loss = 1.50827 (* 1 = 1.50827 loss)
I0525 15:23:53.856720 23721 sgd_solver.cpp:106] Iteration 16650, lr = 0.0015
I0525 15:24:02.589810 23721 solver.cpp:237] Iteration 16800, loss = 1.35309
I0525 15:24:02.589982 23721 solver.cpp:253]     Train net output #0: loss = 1.35309 (* 1 = 1.35309 loss)
I0525 15:24:02.589995 23721 sgd_solver.cpp:106] Iteration 16800, lr = 0.0015
I0525 15:24:11.319195 23721 solver.cpp:237] Iteration 16950, loss = 1.32504
I0525 15:24:11.319231 23721 solver.cpp:253]     Train net output #0: loss = 1.32504 (* 1 = 1.32504 loss)
I0525 15:24:11.319244 23721 sgd_solver.cpp:106] Iteration 16950, lr = 0.0015
I0525 15:24:40.919075 23721 solver.cpp:237] Iteration 17100, loss = 1.39148
I0525 15:24:40.919245 23721 solver.cpp:253]     Train net output #0: loss = 1.39148 (* 1 = 1.39148 loss)
I0525 15:24:40.919258 23721 sgd_solver.cpp:106] Iteration 17100, lr = 0.0015
I0525 15:24:49.655727 23721 solver.cpp:237] Iteration 17250, loss = 1.46503
I0525 15:24:49.655766 23721 solver.cpp:253]     Train net output #0: loss = 1.46503 (* 1 = 1.46503 loss)
I0525 15:24:49.655786 23721 sgd_solver.cpp:106] Iteration 17250, lr = 0.0015
I0525 15:24:58.390964 23721 solver.cpp:237] Iteration 17400, loss = 1.47504
I0525 15:24:58.390998 23721 solver.cpp:253]     Train net output #0: loss = 1.47504 (* 1 = 1.47504 loss)
I0525 15:24:58.391016 23721 sgd_solver.cpp:106] Iteration 17400, lr = 0.0015
I0525 15:25:07.124122 23721 solver.cpp:237] Iteration 17550, loss = 1.27241
I0525 15:25:07.124157 23721 solver.cpp:253]     Train net output #0: loss = 1.27241 (* 1 = 1.27241 loss)
I0525 15:25:07.124173 23721 sgd_solver.cpp:106] Iteration 17550, lr = 0.0015
I0525 15:25:15.855567 23721 solver.cpp:237] Iteration 17700, loss = 1.29411
I0525 15:25:15.855722 23721 solver.cpp:253]     Train net output #0: loss = 1.29411 (* 1 = 1.29411 loss)
I0525 15:25:15.855736 23721 sgd_solver.cpp:106] Iteration 17700, lr = 0.0015
I0525 15:25:24.593406 23721 solver.cpp:237] Iteration 17850, loss = 1.44427
I0525 15:25:24.593441 23721 solver.cpp:253]     Train net output #0: loss = 1.44427 (* 1 = 1.44427 loss)
I0525 15:25:24.593457 23721 sgd_solver.cpp:106] Iteration 17850, lr = 0.0015
I0525 15:25:33.271159 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_18000.caffemodel
I0525 15:25:33.349915 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_18000.solverstate
I0525 15:25:33.375661 23721 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 15:26:41.052628 23721 solver.cpp:409]     Test net output #0: accuracy = 0.82312
I0525 15:26:41.052803 23721 solver.cpp:409]     Test net output #1: loss = 0.589788 (* 1 = 0.589788 loss)
I0525 15:27:01.915422 23721 solver.cpp:237] Iteration 18000, loss = 1.32978
I0525 15:27:01.915477 23721 solver.cpp:253]     Train net output #0: loss = 1.32978 (* 1 = 1.32978 loss)
I0525 15:27:01.915491 23721 sgd_solver.cpp:106] Iteration 18000, lr = 0.0015
I0525 15:27:10.647294 23721 solver.cpp:237] Iteration 18150, loss = 1.17767
I0525 15:27:10.647328 23721 solver.cpp:253]     Train net output #0: loss = 1.17767 (* 1 = 1.17767 loss)
I0525 15:27:10.647346 23721 sgd_solver.cpp:106] Iteration 18150, lr = 0.0015
I0525 15:27:19.375149 23721 solver.cpp:237] Iteration 18300, loss = 1.23988
I0525 15:27:19.375319 23721 solver.cpp:253]     Train net output #0: loss = 1.23988 (* 1 = 1.23988 loss)
I0525 15:27:19.375332 23721 sgd_solver.cpp:106] Iteration 18300, lr = 0.0015
I0525 15:27:28.111400 23721 solver.cpp:237] Iteration 18450, loss = 1.54467
I0525 15:27:28.111434 23721 solver.cpp:253]     Train net output #0: loss = 1.54467 (* 1 = 1.54467 loss)
I0525 15:27:28.111449 23721 sgd_solver.cpp:106] Iteration 18450, lr = 0.0015
I0525 15:27:36.841459 23721 solver.cpp:237] Iteration 18600, loss = 1.42215
I0525 15:27:36.841493 23721 solver.cpp:253]     Train net output #0: loss = 1.42215 (* 1 = 1.42215 loss)
I0525 15:27:36.841511 23721 sgd_solver.cpp:106] Iteration 18600, lr = 0.0015
I0525 15:27:45.575109 23721 solver.cpp:237] Iteration 18750, loss = 1.59679
I0525 15:27:45.575145 23721 solver.cpp:253]     Train net output #0: loss = 1.59679 (* 1 = 1.59679 loss)
I0525 15:27:45.575166 23721 sgd_solver.cpp:106] Iteration 18750, lr = 0.0015
I0525 15:27:54.303689 23721 solver.cpp:237] Iteration 18900, loss = 1.26201
I0525 15:27:54.303834 23721 solver.cpp:253]     Train net output #0: loss = 1.26201 (* 1 = 1.26201 loss)
I0525 15:27:54.303848 23721 sgd_solver.cpp:106] Iteration 18900, lr = 0.0015
I0525 15:28:23.942306 23721 solver.cpp:237] Iteration 19050, loss = 1.33432
I0525 15:28:23.942355 23721 solver.cpp:253]     Train net output #0: loss = 1.33432 (* 1 = 1.33432 loss)
I0525 15:28:23.942373 23721 sgd_solver.cpp:106] Iteration 19050, lr = 0.0015
I0525 15:28:32.670294 23721 solver.cpp:237] Iteration 19200, loss = 1.31668
I0525 15:28:32.670454 23721 solver.cpp:253]     Train net output #0: loss = 1.31668 (* 1 = 1.31668 loss)
I0525 15:28:32.670469 23721 sgd_solver.cpp:106] Iteration 19200, lr = 0.0015
I0525 15:28:41.402055 23721 solver.cpp:237] Iteration 19350, loss = 1.56438
I0525 15:28:41.402089 23721 solver.cpp:253]     Train net output #0: loss = 1.56438 (* 1 = 1.56438 loss)
I0525 15:28:41.402107 23721 sgd_solver.cpp:106] Iteration 19350, lr = 0.0015
I0525 15:28:50.078459 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_19500.caffemodel
I0525 15:28:50.157795 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_19500.solverstate
I0525 15:28:50.204368 23721 solver.cpp:237] Iteration 19500, loss = 1.29007
I0525 15:28:50.204418 23721 solver.cpp:253]     Train net output #0: loss = 1.29007 (* 1 = 1.29007 loss)
I0525 15:28:50.204433 23721 sgd_solver.cpp:106] Iteration 19500, lr = 0.0015
I0525 15:28:58.937482 23721 solver.cpp:237] Iteration 19650, loss = 1.34464
I0525 15:28:58.937523 23721 solver.cpp:253]     Train net output #0: loss = 1.34464 (* 1 = 1.34464 loss)
I0525 15:28:58.937541 23721 sgd_solver.cpp:106] Iteration 19650, lr = 0.0015
I0525 15:29:07.664293 23721 solver.cpp:237] Iteration 19800, loss = 1.3557
I0525 15:29:07.664455 23721 solver.cpp:253]     Train net output #0: loss = 1.3557 (* 1 = 1.3557 loss)
I0525 15:29:07.664469 23721 sgd_solver.cpp:106] Iteration 19800, lr = 0.0015
I0525 15:29:16.390887 23721 solver.cpp:237] Iteration 19950, loss = 1.32069
I0525 15:29:16.390920 23721 solver.cpp:253]     Train net output #0: loss = 1.32069 (* 1 = 1.32069 loss)
I0525 15:29:16.390938 23721 sgd_solver.cpp:106] Iteration 19950, lr = 0.0015
I0525 15:29:45.976500 23721 solver.cpp:237] Iteration 20100, loss = 1.26398
I0525 15:29:45.976670 23721 solver.cpp:253]     Train net output #0: loss = 1.26398 (* 1 = 1.26398 loss)
I0525 15:29:45.976685 23721 sgd_solver.cpp:106] Iteration 20100, lr = 0.0015
I0525 15:29:54.711608 23721 solver.cpp:237] Iteration 20250, loss = 1.22415
I0525 15:29:54.711642 23721 solver.cpp:253]     Train net output #0: loss = 1.22415 (* 1 = 1.22415 loss)
I0525 15:29:54.711661 23721 sgd_solver.cpp:106] Iteration 20250, lr = 0.0015
I0525 15:30:03.442808 23721 solver.cpp:237] Iteration 20400, loss = 1.42137
I0525 15:30:03.442842 23721 solver.cpp:253]     Train net output #0: loss = 1.42137 (* 1 = 1.42137 loss)
I0525 15:30:03.442858 23721 sgd_solver.cpp:106] Iteration 20400, lr = 0.0015
I0525 15:30:12.179167 23721 solver.cpp:237] Iteration 20550, loss = 1.36218
I0525 15:30:12.179205 23721 solver.cpp:253]     Train net output #0: loss = 1.36218 (* 1 = 1.36218 loss)
I0525 15:30:12.179222 23721 sgd_solver.cpp:106] Iteration 20550, lr = 0.0015
I0525 15:30:20.909438 23721 solver.cpp:237] Iteration 20700, loss = 1.28272
I0525 15:30:20.909584 23721 solver.cpp:253]     Train net output #0: loss = 1.28272 (* 1 = 1.28272 loss)
I0525 15:30:20.909596 23721 sgd_solver.cpp:106] Iteration 20700, lr = 0.0015
I0525 15:30:29.648383 23721 solver.cpp:237] Iteration 20850, loss = 1.2135
I0525 15:30:29.648416 23721 solver.cpp:253]     Train net output #0: loss = 1.2135 (* 1 = 1.2135 loss)
I0525 15:30:29.648437 23721 sgd_solver.cpp:106] Iteration 20850, lr = 0.0015
I0525 15:30:38.319155 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_21000.caffemodel
I0525 15:30:38.399029 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_21000.solverstate
I0525 15:30:38.426065 23721 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 15:31:24.945683 23721 solver.cpp:409]     Test net output #0: accuracy = 0.835819
I0525 15:31:24.945847 23721 solver.cpp:409]     Test net output #1: loss = 0.564483 (* 1 = 0.564483 loss)
I0525 15:31:45.808845 23721 solver.cpp:237] Iteration 21000, loss = 1.46711
I0525 15:31:45.808897 23721 solver.cpp:253]     Train net output #0: loss = 1.46711 (* 1 = 1.46711 loss)
I0525 15:31:45.808910 23721 sgd_solver.cpp:106] Iteration 21000, lr = 0.0015
I0525 15:31:54.546555 23721 solver.cpp:237] Iteration 21150, loss = 1.26244
I0525 15:31:54.546610 23721 solver.cpp:253]     Train net output #0: loss = 1.26244 (* 1 = 1.26244 loss)
I0525 15:31:54.546624 23721 sgd_solver.cpp:106] Iteration 21150, lr = 0.0015
I0525 15:32:03.275995 23721 solver.cpp:237] Iteration 21300, loss = 1.14453
I0525 15:32:03.276151 23721 solver.cpp:253]     Train net output #0: loss = 1.14453 (* 1 = 1.14453 loss)
I0525 15:32:03.276165 23721 sgd_solver.cpp:106] Iteration 21300, lr = 0.0015
I0525 15:32:12.008337 23721 solver.cpp:237] Iteration 21450, loss = 1.37762
I0525 15:32:12.008371 23721 solver.cpp:253]     Train net output #0: loss = 1.37762 (* 1 = 1.37762 loss)
I0525 15:32:12.008385 23721 sgd_solver.cpp:106] Iteration 21450, lr = 0.0015
I0525 15:32:20.745339 23721 solver.cpp:237] Iteration 21600, loss = 1.41384
I0525 15:32:20.745378 23721 solver.cpp:253]     Train net output #0: loss = 1.41384 (* 1 = 1.41384 loss)
I0525 15:32:20.745398 23721 sgd_solver.cpp:106] Iteration 21600, lr = 0.0015
I0525 15:32:29.480083 23721 solver.cpp:237] Iteration 21750, loss = 1.31613
I0525 15:32:29.480118 23721 solver.cpp:253]     Train net output #0: loss = 1.31613 (* 1 = 1.31613 loss)
I0525 15:32:29.480135 23721 sgd_solver.cpp:106] Iteration 21750, lr = 0.0015
I0525 15:32:38.221421 23721 solver.cpp:237] Iteration 21900, loss = 1.28141
I0525 15:32:38.221581 23721 solver.cpp:253]     Train net output #0: loss = 1.28141 (* 1 = 1.28141 loss)
I0525 15:32:38.221596 23721 sgd_solver.cpp:106] Iteration 21900, lr = 0.0015
I0525 15:33:07.806335 23721 solver.cpp:237] Iteration 22050, loss = 1.07623
I0525 15:33:07.806385 23721 solver.cpp:253]     Train net output #0: loss = 1.07623 (* 1 = 1.07623 loss)
I0525 15:33:07.806401 23721 sgd_solver.cpp:106] Iteration 22050, lr = 0.0015
I0525 15:33:16.545464 23721 solver.cpp:237] Iteration 22200, loss = 1.31555
I0525 15:33:16.545639 23721 solver.cpp:253]     Train net output #0: loss = 1.31555 (* 1 = 1.31555 loss)
I0525 15:33:16.545655 23721 sgd_solver.cpp:106] Iteration 22200, lr = 0.0015
I0525 15:33:25.281945 23721 solver.cpp:237] Iteration 22350, loss = 1.2971
I0525 15:33:25.281978 23721 solver.cpp:253]     Train net output #0: loss = 1.2971 (* 1 = 1.2971 loss)
I0525 15:33:25.281996 23721 sgd_solver.cpp:106] Iteration 22350, lr = 0.0015
I0525 15:33:33.960366 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_22500.caffemodel
I0525 15:33:34.041059 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_22500.solverstate
I0525 15:33:34.087005 23721 solver.cpp:237] Iteration 22500, loss = 1.23943
I0525 15:33:34.087055 23721 solver.cpp:253]     Train net output #0: loss = 1.23943 (* 1 = 1.23943 loss)
I0525 15:33:34.087069 23721 sgd_solver.cpp:106] Iteration 22500, lr = 0.0015
I0525 15:33:42.820623 23721 solver.cpp:237] Iteration 22650, loss = 1.38845
I0525 15:33:42.820658 23721 solver.cpp:253]     Train net output #0: loss = 1.38845 (* 1 = 1.38845 loss)
I0525 15:33:42.820675 23721 sgd_solver.cpp:106] Iteration 22650, lr = 0.0015
I0525 15:33:51.554332 23721 solver.cpp:237] Iteration 22800, loss = 1.35389
I0525 15:33:51.554494 23721 solver.cpp:253]     Train net output #0: loss = 1.35389 (* 1 = 1.35389 loss)
I0525 15:33:51.554509 23721 sgd_solver.cpp:106] Iteration 22800, lr = 0.0015
I0525 15:34:00.284979 23721 solver.cpp:237] Iteration 22950, loss = 1.21567
I0525 15:34:00.285022 23721 solver.cpp:253]     Train net output #0: loss = 1.21567 (* 1 = 1.21567 loss)
I0525 15:34:00.285038 23721 sgd_solver.cpp:106] Iteration 22950, lr = 0.0015
I0525 15:34:29.874568 23721 solver.cpp:237] Iteration 23100, loss = 1.23345
I0525 15:34:29.874749 23721 solver.cpp:253]     Train net output #0: loss = 1.23345 (* 1 = 1.23345 loss)
I0525 15:34:29.874764 23721 sgd_solver.cpp:106] Iteration 23100, lr = 0.0015
I0525 15:34:38.609149 23721 solver.cpp:237] Iteration 23250, loss = 1.27555
I0525 15:34:38.609184 23721 solver.cpp:253]     Train net output #0: loss = 1.27555 (* 1 = 1.27555 loss)
I0525 15:34:38.609200 23721 sgd_solver.cpp:106] Iteration 23250, lr = 0.0015
I0525 15:34:47.344517 23721 solver.cpp:237] Iteration 23400, loss = 1.1675
I0525 15:34:47.344558 23721 solver.cpp:253]     Train net output #0: loss = 1.1675 (* 1 = 1.1675 loss)
I0525 15:34:47.344573 23721 sgd_solver.cpp:106] Iteration 23400, lr = 0.0015
I0525 15:34:56.083282 23721 solver.cpp:237] Iteration 23550, loss = 1.41094
I0525 15:34:56.083317 23721 solver.cpp:253]     Train net output #0: loss = 1.41094 (* 1 = 1.41094 loss)
I0525 15:34:56.083333 23721 sgd_solver.cpp:106] Iteration 23550, lr = 0.0015
I0525 15:35:04.818231 23721 solver.cpp:237] Iteration 23700, loss = 1.41544
I0525 15:35:04.818392 23721 solver.cpp:253]     Train net output #0: loss = 1.41544 (* 1 = 1.41544 loss)
I0525 15:35:04.818405 23721 sgd_solver.cpp:106] Iteration 23700, lr = 0.0015
I0525 15:35:13.559456 23721 solver.cpp:237] Iteration 23850, loss = 1.19763
I0525 15:35:13.559496 23721 solver.cpp:253]     Train net output #0: loss = 1.19763 (* 1 = 1.19763 loss)
I0525 15:35:13.559514 23721 sgd_solver.cpp:106] Iteration 23850, lr = 0.0015
I0525 15:35:22.230034 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_24000.caffemodel
I0525 15:35:22.308117 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_24000.solverstate
I0525 15:35:22.333910 23721 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 15:36:29.973682 23721 solver.cpp:409]     Test net output #0: accuracy = 0.844246
I0525 15:36:29.973851 23721 solver.cpp:409]     Test net output #1: loss = 0.518326 (* 1 = 0.518326 loss)
I0525 15:36:50.795361 23721 solver.cpp:237] Iteration 24000, loss = 1.27983
I0525 15:36:50.795413 23721 solver.cpp:253]     Train net output #0: loss = 1.27983 (* 1 = 1.27983 loss)
I0525 15:36:50.795429 23721 sgd_solver.cpp:106] Iteration 24000, lr = 0.0015
I0525 15:36:59.520030 23721 solver.cpp:237] Iteration 24150, loss = 1.1296
I0525 15:36:59.520066 23721 solver.cpp:253]     Train net output #0: loss = 1.1296 (* 1 = 1.1296 loss)
I0525 15:36:59.520082 23721 sgd_solver.cpp:106] Iteration 24150, lr = 0.0015
I0525 15:37:08.245276 23721 solver.cpp:237] Iteration 24300, loss = 1.28996
I0525 15:37:08.245430 23721 solver.cpp:253]     Train net output #0: loss = 1.28996 (* 1 = 1.28996 loss)
I0525 15:37:08.245445 23721 sgd_solver.cpp:106] Iteration 24300, lr = 0.0015
I0525 15:37:16.974439 23721 solver.cpp:237] Iteration 24450, loss = 1.26388
I0525 15:37:16.974483 23721 solver.cpp:253]     Train net output #0: loss = 1.26388 (* 1 = 1.26388 loss)
I0525 15:37:16.974499 23721 sgd_solver.cpp:106] Iteration 24450, lr = 0.0015
I0525 15:37:25.696269 23721 solver.cpp:237] Iteration 24600, loss = 1.25854
I0525 15:37:25.696305 23721 solver.cpp:253]     Train net output #0: loss = 1.25854 (* 1 = 1.25854 loss)
I0525 15:37:25.696321 23721 sgd_solver.cpp:106] Iteration 24600, lr = 0.0015
I0525 15:37:34.419482 23721 solver.cpp:237] Iteration 24750, loss = 1.35314
I0525 15:37:34.419517 23721 solver.cpp:253]     Train net output #0: loss = 1.35314 (* 1 = 1.35314 loss)
I0525 15:37:34.419533 23721 sgd_solver.cpp:106] Iteration 24750, lr = 0.0015
I0525 15:37:43.147189 23721 solver.cpp:237] Iteration 24900, loss = 1.29255
I0525 15:37:43.147359 23721 solver.cpp:253]     Train net output #0: loss = 1.29255 (* 1 = 1.29255 loss)
I0525 15:37:43.147373 23721 sgd_solver.cpp:106] Iteration 24900, lr = 0.0015
I0525 15:38:12.670661 23721 solver.cpp:237] Iteration 25050, loss = 1.45737
I0525 15:38:12.670709 23721 solver.cpp:253]     Train net output #0: loss = 1.45737 (* 1 = 1.45737 loss)
I0525 15:38:12.670727 23721 sgd_solver.cpp:106] Iteration 25050, lr = 0.0015
I0525 15:38:21.392808 23721 solver.cpp:237] Iteration 25200, loss = 1.3577
I0525 15:38:21.392964 23721 solver.cpp:253]     Train net output #0: loss = 1.3577 (* 1 = 1.3577 loss)
I0525 15:38:21.392978 23721 sgd_solver.cpp:106] Iteration 25200, lr = 0.0015
I0525 15:38:30.117449 23721 solver.cpp:237] Iteration 25350, loss = 1.23606
I0525 15:38:30.117491 23721 solver.cpp:253]     Train net output #0: loss = 1.23606 (* 1 = 1.23606 loss)
I0525 15:38:30.117507 23721 sgd_solver.cpp:106] Iteration 25350, lr = 0.0015
I0525 15:38:38.782295 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_25500.caffemodel
I0525 15:38:38.866535 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_25500.solverstate
I0525 15:38:38.910221 23721 solver.cpp:237] Iteration 25500, loss = 1.17755
I0525 15:38:38.910265 23721 solver.cpp:253]     Train net output #0: loss = 1.17755 (* 1 = 1.17755 loss)
I0525 15:38:38.910279 23721 sgd_solver.cpp:106] Iteration 25500, lr = 0.0015
I0525 15:38:47.638820 23721 solver.cpp:237] Iteration 25650, loss = 1.45571
I0525 15:38:47.638855 23721 solver.cpp:253]     Train net output #0: loss = 1.45571 (* 1 = 1.45571 loss)
I0525 15:38:47.638871 23721 sgd_solver.cpp:106] Iteration 25650, lr = 0.0015
I0525 15:38:56.363060 23721 solver.cpp:237] Iteration 25800, loss = 1.28427
I0525 15:38:56.363240 23721 solver.cpp:253]     Train net output #0: loss = 1.28427 (* 1 = 1.28427 loss)
I0525 15:38:56.363253 23721 sgd_solver.cpp:106] Iteration 25800, lr = 0.0015
I0525 15:39:05.089159 23721 solver.cpp:237] Iteration 25950, loss = 1.45582
I0525 15:39:05.089193 23721 solver.cpp:253]     Train net output #0: loss = 1.45582 (* 1 = 1.45582 loss)
I0525 15:39:05.089210 23721 sgd_solver.cpp:106] Iteration 25950, lr = 0.0015
I0525 15:39:34.655700 23721 solver.cpp:237] Iteration 26100, loss = 1.17695
I0525 15:39:34.655877 23721 solver.cpp:253]     Train net output #0: loss = 1.17695 (* 1 = 1.17695 loss)
I0525 15:39:34.655894 23721 sgd_solver.cpp:106] Iteration 26100, lr = 0.0015
I0525 15:39:43.380002 23721 solver.cpp:237] Iteration 26250, loss = 1.4616
I0525 15:39:43.380036 23721 solver.cpp:253]     Train net output #0: loss = 1.4616 (* 1 = 1.4616 loss)
I0525 15:39:43.380054 23721 sgd_solver.cpp:106] Iteration 26250, lr = 0.0015
I0525 15:39:52.103977 23721 solver.cpp:237] Iteration 26400, loss = 1.06849
I0525 15:39:52.104017 23721 solver.cpp:253]     Train net output #0: loss = 1.06849 (* 1 = 1.06849 loss)
I0525 15:39:52.104037 23721 sgd_solver.cpp:106] Iteration 26400, lr = 0.0015
I0525 15:40:00.827409 23721 solver.cpp:237] Iteration 26550, loss = 1.29793
I0525 15:40:00.827445 23721 solver.cpp:253]     Train net output #0: loss = 1.29793 (* 1 = 1.29793 loss)
I0525 15:40:00.827462 23721 sgd_solver.cpp:106] Iteration 26550, lr = 0.0015
I0525 15:40:09.554896 23721 solver.cpp:237] Iteration 26700, loss = 1.32127
I0525 15:40:09.555058 23721 solver.cpp:253]     Train net output #0: loss = 1.32127 (* 1 = 1.32127 loss)
I0525 15:40:09.555070 23721 sgd_solver.cpp:106] Iteration 26700, lr = 0.0015
I0525 15:40:18.276836 23721 solver.cpp:237] Iteration 26850, loss = 1.33702
I0525 15:40:18.276870 23721 solver.cpp:253]     Train net output #0: loss = 1.33702 (* 1 = 1.33702 loss)
I0525 15:40:18.276888 23721 sgd_solver.cpp:106] Iteration 26850, lr = 0.0015
I0525 15:40:26.944082 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_27000.caffemodel
I0525 15:40:27.022960 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_27000.solverstate
I0525 15:40:27.049337 23721 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 15:41:13.880480 23721 solver.cpp:409]     Test net output #0: accuracy = 0.847919
I0525 15:41:13.880646 23721 solver.cpp:409]     Test net output #1: loss = 0.50138 (* 1 = 0.50138 loss)
I0525 15:41:34.757575 23721 solver.cpp:237] Iteration 27000, loss = 1.25847
I0525 15:41:34.757628 23721 solver.cpp:253]     Train net output #0: loss = 1.25847 (* 1 = 1.25847 loss)
I0525 15:41:34.757645 23721 sgd_solver.cpp:106] Iteration 27000, lr = 0.0015
I0525 15:41:43.497512 23721 solver.cpp:237] Iteration 27150, loss = 1.15381
I0525 15:41:43.497548 23721 solver.cpp:253]     Train net output #0: loss = 1.15381 (* 1 = 1.15381 loss)
I0525 15:41:43.497566 23721 sgd_solver.cpp:106] Iteration 27150, lr = 0.0015
I0525 15:41:52.237895 23721 solver.cpp:237] Iteration 27300, loss = 1.31475
I0525 15:41:52.238083 23721 solver.cpp:253]     Train net output #0: loss = 1.31475 (* 1 = 1.31475 loss)
I0525 15:41:52.238098 23721 sgd_solver.cpp:106] Iteration 27300, lr = 0.0015
I0525 15:42:00.966963 23721 solver.cpp:237] Iteration 27450, loss = 1.29682
I0525 15:42:00.966997 23721 solver.cpp:253]     Train net output #0: loss = 1.29682 (* 1 = 1.29682 loss)
I0525 15:42:00.967015 23721 sgd_solver.cpp:106] Iteration 27450, lr = 0.0015
I0525 15:42:09.701572 23721 solver.cpp:237] Iteration 27600, loss = 0.987833
I0525 15:42:09.701607 23721 solver.cpp:253]     Train net output #0: loss = 0.987833 (* 1 = 0.987833 loss)
I0525 15:42:09.701622 23721 sgd_solver.cpp:106] Iteration 27600, lr = 0.0015
I0525 15:42:18.438616 23721 solver.cpp:237] Iteration 27750, loss = 1.301
I0525 15:42:18.438658 23721 solver.cpp:253]     Train net output #0: loss = 1.301 (* 1 = 1.301 loss)
I0525 15:42:18.438673 23721 sgd_solver.cpp:106] Iteration 27750, lr = 0.0015
I0525 15:42:27.174767 23721 solver.cpp:237] Iteration 27900, loss = 1.25363
I0525 15:42:27.174923 23721 solver.cpp:253]     Train net output #0: loss = 1.25363 (* 1 = 1.25363 loss)
I0525 15:42:27.174937 23721 sgd_solver.cpp:106] Iteration 27900, lr = 0.0015
I0525 15:42:56.766376 23721 solver.cpp:237] Iteration 28050, loss = 1.47628
I0525 15:42:56.766425 23721 solver.cpp:253]     Train net output #0: loss = 1.47628 (* 1 = 1.47628 loss)
I0525 15:42:56.766440 23721 sgd_solver.cpp:106] Iteration 28050, lr = 0.0015
I0525 15:43:05.498884 23721 solver.cpp:237] Iteration 28200, loss = 1.36191
I0525 15:43:05.499050 23721 solver.cpp:253]     Train net output #0: loss = 1.36191 (* 1 = 1.36191 loss)
I0525 15:43:05.499064 23721 sgd_solver.cpp:106] Iteration 28200, lr = 0.0015
I0525 15:43:14.229845 23721 solver.cpp:237] Iteration 28350, loss = 1.27048
I0525 15:43:14.229879 23721 solver.cpp:253]     Train net output #0: loss = 1.27048 (* 1 = 1.27048 loss)
I0525 15:43:14.229895 23721 sgd_solver.cpp:106] Iteration 28350, lr = 0.0015
I0525 15:43:22.900661 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_28500.caffemodel
I0525 15:43:22.982331 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_28500.solverstate
I0525 15:43:23.028295 23721 solver.cpp:237] Iteration 28500, loss = 1.46578
I0525 15:43:23.028347 23721 solver.cpp:253]     Train net output #0: loss = 1.46578 (* 1 = 1.46578 loss)
I0525 15:43:23.028362 23721 sgd_solver.cpp:106] Iteration 28500, lr = 0.0015
I0525 15:43:31.759093 23721 solver.cpp:237] Iteration 28650, loss = 1.34545
I0525 15:43:31.759131 23721 solver.cpp:253]     Train net output #0: loss = 1.34545 (* 1 = 1.34545 loss)
I0525 15:43:31.759151 23721 sgd_solver.cpp:106] Iteration 28650, lr = 0.0015
I0525 15:43:40.491539 23721 solver.cpp:237] Iteration 28800, loss = 1.48433
I0525 15:43:40.491698 23721 solver.cpp:253]     Train net output #0: loss = 1.48433 (* 1 = 1.48433 loss)
I0525 15:43:40.491711 23721 sgd_solver.cpp:106] Iteration 28800, lr = 0.0015
I0525 15:43:49.219782 23721 solver.cpp:237] Iteration 28950, loss = 1.31928
I0525 15:43:49.219816 23721 solver.cpp:253]     Train net output #0: loss = 1.31928 (* 1 = 1.31928 loss)
I0525 15:43:49.219835 23721 sgd_solver.cpp:106] Iteration 28950, lr = 0.0015
I0525 15:44:18.756893 23721 solver.cpp:237] Iteration 29100, loss = 1.18356
I0525 15:44:18.757081 23721 solver.cpp:253]     Train net output #0: loss = 1.18356 (* 1 = 1.18356 loss)
I0525 15:44:18.757094 23721 sgd_solver.cpp:106] Iteration 29100, lr = 0.0015
I0525 15:44:27.491415 23721 solver.cpp:237] Iteration 29250, loss = 1.48525
I0525 15:44:27.491457 23721 solver.cpp:253]     Train net output #0: loss = 1.48525 (* 1 = 1.48525 loss)
I0525 15:44:27.491473 23721 sgd_solver.cpp:106] Iteration 29250, lr = 0.0015
I0525 15:44:36.225018 23721 solver.cpp:237] Iteration 29400, loss = 1.16009
I0525 15:44:36.225054 23721 solver.cpp:253]     Train net output #0: loss = 1.16009 (* 1 = 1.16009 loss)
I0525 15:44:36.225070 23721 sgd_solver.cpp:106] Iteration 29400, lr = 0.0015
I0525 15:44:44.958369 23721 solver.cpp:237] Iteration 29550, loss = 1.31781
I0525 15:44:44.958415 23721 solver.cpp:253]     Train net output #0: loss = 1.31781 (* 1 = 1.31781 loss)
I0525 15:44:44.958430 23721 sgd_solver.cpp:106] Iteration 29550, lr = 0.0015
I0525 15:44:53.691304 23721 solver.cpp:237] Iteration 29700, loss = 1.2811
I0525 15:44:53.691468 23721 solver.cpp:253]     Train net output #0: loss = 1.2811 (* 1 = 1.2811 loss)
I0525 15:44:53.691483 23721 sgd_solver.cpp:106] Iteration 29700, lr = 0.0015
I0525 15:45:02.418684 23721 solver.cpp:237] Iteration 29850, loss = 1.39643
I0525 15:45:02.418718 23721 solver.cpp:253]     Train net output #0: loss = 1.39643 (* 1 = 1.39643 loss)
I0525 15:45:02.418736 23721 sgd_solver.cpp:106] Iteration 29850, lr = 0.0015
I0525 15:45:11.096776 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_30000.caffemodel
I0525 15:45:11.177817 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_30000.solverstate
I0525 15:45:11.205899 23721 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 15:46:18.894784 23721 solver.cpp:409]     Test net output #0: accuracy = 0.851845
I0525 15:46:18.894958 23721 solver.cpp:409]     Test net output #1: loss = 0.482695 (* 1 = 0.482695 loss)
I0525 15:46:39.719861 23721 solver.cpp:237] Iteration 30000, loss = 1.1385
I0525 15:46:39.719913 23721 solver.cpp:253]     Train net output #0: loss = 1.1385 (* 1 = 1.1385 loss)
I0525 15:46:39.719929 23721 sgd_solver.cpp:106] Iteration 30000, lr = 0.0015
I0525 15:46:48.448550 23721 solver.cpp:237] Iteration 30150, loss = 1.14554
I0525 15:46:48.448585 23721 solver.cpp:253]     Train net output #0: loss = 1.14554 (* 1 = 1.14554 loss)
I0525 15:46:48.448601 23721 sgd_solver.cpp:106] Iteration 30150, lr = 0.0015
I0525 15:46:57.172564 23721 solver.cpp:237] Iteration 30300, loss = 1.4265
I0525 15:46:57.172725 23721 solver.cpp:253]     Train net output #0: loss = 1.4265 (* 1 = 1.4265 loss)
I0525 15:46:57.172739 23721 sgd_solver.cpp:106] Iteration 30300, lr = 0.0015
I0525 15:47:05.898624 23721 solver.cpp:237] Iteration 30450, loss = 1.23128
I0525 15:47:05.898658 23721 solver.cpp:253]     Train net output #0: loss = 1.23128 (* 1 = 1.23128 loss)
I0525 15:47:05.898675 23721 sgd_solver.cpp:106] Iteration 30450, lr = 0.0015
I0525 15:47:14.628159 23721 solver.cpp:237] Iteration 30600, loss = 1.296
I0525 15:47:14.628206 23721 solver.cpp:253]     Train net output #0: loss = 1.296 (* 1 = 1.296 loss)
I0525 15:47:14.628223 23721 sgd_solver.cpp:106] Iteration 30600, lr = 0.0015
I0525 15:47:23.366832 23721 solver.cpp:237] Iteration 30750, loss = 1.15983
I0525 15:47:23.366868 23721 solver.cpp:253]     Train net output #0: loss = 1.15983 (* 1 = 1.15983 loss)
I0525 15:47:23.366884 23721 sgd_solver.cpp:106] Iteration 30750, lr = 0.0015
I0525 15:47:32.099093 23721 solver.cpp:237] Iteration 30900, loss = 1.23313
I0525 15:47:32.099248 23721 solver.cpp:253]     Train net output #0: loss = 1.23313 (* 1 = 1.23313 loss)
I0525 15:47:32.099262 23721 sgd_solver.cpp:106] Iteration 30900, lr = 0.0015
I0525 15:48:01.695266 23721 solver.cpp:237] Iteration 31050, loss = 1.39583
I0525 15:48:01.695315 23721 solver.cpp:253]     Train net output #0: loss = 1.39583 (* 1 = 1.39583 loss)
I0525 15:48:01.695332 23721 sgd_solver.cpp:106] Iteration 31050, lr = 0.0015
I0525 15:48:10.433374 23721 solver.cpp:237] Iteration 31200, loss = 1.15035
I0525 15:48:10.433542 23721 solver.cpp:253]     Train net output #0: loss = 1.15035 (* 1 = 1.15035 loss)
I0525 15:48:10.433557 23721 sgd_solver.cpp:106] Iteration 31200, lr = 0.0015
I0525 15:48:19.170130 23721 solver.cpp:237] Iteration 31350, loss = 1.1951
I0525 15:48:19.170164 23721 solver.cpp:253]     Train net output #0: loss = 1.1951 (* 1 = 1.1951 loss)
I0525 15:48:19.170181 23721 sgd_solver.cpp:106] Iteration 31350, lr = 0.0015
I0525 15:48:27.837558 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_31500.caffemodel
I0525 15:48:27.917801 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_31500.solverstate
I0525 15:48:27.961634 23721 solver.cpp:237] Iteration 31500, loss = 1.11153
I0525 15:48:27.961673 23721 solver.cpp:253]     Train net output #0: loss = 1.11153 (* 1 = 1.11153 loss)
I0525 15:48:27.961691 23721 sgd_solver.cpp:106] Iteration 31500, lr = 0.0015
I0525 15:48:36.694386 23721 solver.cpp:237] Iteration 31650, loss = 1.22339
I0525 15:48:36.694427 23721 solver.cpp:253]     Train net output #0: loss = 1.22339 (* 1 = 1.22339 loss)
I0525 15:48:36.694444 23721 sgd_solver.cpp:106] Iteration 31650, lr = 0.0015
I0525 15:48:45.423882 23721 solver.cpp:237] Iteration 31800, loss = 1.10559
I0525 15:48:45.424051 23721 solver.cpp:253]     Train net output #0: loss = 1.10559 (* 1 = 1.10559 loss)
I0525 15:48:45.424065 23721 sgd_solver.cpp:106] Iteration 31800, lr = 0.0015
I0525 15:48:54.158668 23721 solver.cpp:237] Iteration 31950, loss = 1.32022
I0525 15:48:54.158701 23721 solver.cpp:253]     Train net output #0: loss = 1.32022 (* 1 = 1.32022 loss)
I0525 15:48:54.158718 23721 sgd_solver.cpp:106] Iteration 31950, lr = 0.0015
I0525 15:49:23.683104 23721 solver.cpp:237] Iteration 32100, loss = 1.15788
I0525 15:49:23.683279 23721 solver.cpp:253]     Train net output #0: loss = 1.15788 (* 1 = 1.15788 loss)
I0525 15:49:23.683293 23721 sgd_solver.cpp:106] Iteration 32100, lr = 0.0015
I0525 15:49:32.411996 23721 solver.cpp:237] Iteration 32250, loss = 1.47459
I0525 15:49:32.412030 23721 solver.cpp:253]     Train net output #0: loss = 1.47459 (* 1 = 1.47459 loss)
I0525 15:49:32.412048 23721 sgd_solver.cpp:106] Iteration 32250, lr = 0.0015
I0525 15:49:41.140907 23721 solver.cpp:237] Iteration 32400, loss = 1.34436
I0525 15:49:41.140943 23721 solver.cpp:253]     Train net output #0: loss = 1.34436 (* 1 = 1.34436 loss)
I0525 15:49:41.140959 23721 sgd_solver.cpp:106] Iteration 32400, lr = 0.0015
I0525 15:49:49.876772 23721 solver.cpp:237] Iteration 32550, loss = 1.04619
I0525 15:49:49.876818 23721 solver.cpp:253]     Train net output #0: loss = 1.04619 (* 1 = 1.04619 loss)
I0525 15:49:49.876834 23721 sgd_solver.cpp:106] Iteration 32550, lr = 0.0015
I0525 15:49:58.606644 23721 solver.cpp:237] Iteration 32700, loss = 1.28859
I0525 15:49:58.606801 23721 solver.cpp:253]     Train net output #0: loss = 1.28859 (* 1 = 1.28859 loss)
I0525 15:49:58.606813 23721 sgd_solver.cpp:106] Iteration 32700, lr = 0.0015
I0525 15:50:07.336154 23721 solver.cpp:237] Iteration 32850, loss = 1.27746
I0525 15:50:07.336189 23721 solver.cpp:253]     Train net output #0: loss = 1.27746 (* 1 = 1.27746 loss)
I0525 15:50:07.336204 23721 sgd_solver.cpp:106] Iteration 32850, lr = 0.0015
I0525 15:50:16.012473 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_33000.caffemodel
I0525 15:50:16.090414 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_33000.solverstate
I0525 15:50:16.116387 23721 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 15:51:02.651229 23721 solver.cpp:409]     Test net output #0: accuracy = 0.855933
I0525 15:51:02.651403 23721 solver.cpp:409]     Test net output #1: loss = 0.462447 (* 1 = 0.462447 loss)
I0525 15:51:23.504406 23721 solver.cpp:237] Iteration 33000, loss = 1.05381
I0525 15:51:23.504461 23721 solver.cpp:253]     Train net output #0: loss = 1.05381 (* 1 = 1.05381 loss)
I0525 15:51:23.504475 23721 sgd_solver.cpp:106] Iteration 33000, lr = 0.0015
I0525 15:51:32.238108 23721 solver.cpp:237] Iteration 33150, loss = 1.26155
I0525 15:51:32.238144 23721 solver.cpp:253]     Train net output #0: loss = 1.26155 (* 1 = 1.26155 loss)
I0525 15:51:32.238163 23721 sgd_solver.cpp:106] Iteration 33150, lr = 0.0015
I0525 15:51:40.974306 23721 solver.cpp:237] Iteration 33300, loss = 1.38135
I0525 15:51:40.974477 23721 solver.cpp:253]     Train net output #0: loss = 1.38135 (* 1 = 1.38135 loss)
I0525 15:51:40.974490 23721 sgd_solver.cpp:106] Iteration 33300, lr = 0.0015
I0525 15:51:49.716576 23721 solver.cpp:237] Iteration 33450, loss = 1.29237
I0525 15:51:49.716624 23721 solver.cpp:253]     Train net output #0: loss = 1.29237 (* 1 = 1.29237 loss)
I0525 15:51:49.716637 23721 sgd_solver.cpp:106] Iteration 33450, lr = 0.0015
I0525 15:51:58.451449 23721 solver.cpp:237] Iteration 33600, loss = 1.2952
I0525 15:51:58.451484 23721 solver.cpp:253]     Train net output #0: loss = 1.2952 (* 1 = 1.2952 loss)
I0525 15:51:58.451500 23721 sgd_solver.cpp:106] Iteration 33600, lr = 0.0015
I0525 15:52:07.180552 23721 solver.cpp:237] Iteration 33750, loss = 1.16499
I0525 15:52:07.180586 23721 solver.cpp:253]     Train net output #0: loss = 1.16499 (* 1 = 1.16499 loss)
I0525 15:52:07.180603 23721 sgd_solver.cpp:106] Iteration 33750, lr = 0.0015
I0525 15:52:15.918581 23721 solver.cpp:237] Iteration 33900, loss = 1.39692
I0525 15:52:15.918759 23721 solver.cpp:253]     Train net output #0: loss = 1.39692 (* 1 = 1.39692 loss)
I0525 15:52:15.918773 23721 sgd_solver.cpp:106] Iteration 33900, lr = 0.0015
I0525 15:52:45.467895 23721 solver.cpp:237] Iteration 34050, loss = 1.2186
I0525 15:52:45.467943 23721 solver.cpp:253]     Train net output #0: loss = 1.2186 (* 1 = 1.2186 loss)
I0525 15:52:45.467957 23721 sgd_solver.cpp:106] Iteration 34050, lr = 0.0015
I0525 15:52:54.205039 23721 solver.cpp:237] Iteration 34200, loss = 1.1436
I0525 15:52:54.205201 23721 solver.cpp:253]     Train net output #0: loss = 1.1436 (* 1 = 1.1436 loss)
I0525 15:52:54.205214 23721 sgd_solver.cpp:106] Iteration 34200, lr = 0.0015
I0525 15:53:02.941246 23721 solver.cpp:237] Iteration 34350, loss = 1.32095
I0525 15:53:02.941279 23721 solver.cpp:253]     Train net output #0: loss = 1.32095 (* 1 = 1.32095 loss)
I0525 15:53:02.941296 23721 sgd_solver.cpp:106] Iteration 34350, lr = 0.0015
I0525 15:53:11.616642 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_34500.caffemodel
I0525 15:53:11.695109 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_34500.solverstate
I0525 15:53:11.738418 23721 solver.cpp:237] Iteration 34500, loss = 1.20396
I0525 15:53:11.738463 23721 solver.cpp:253]     Train net output #0: loss = 1.20396 (* 1 = 1.20396 loss)
I0525 15:53:11.738476 23721 sgd_solver.cpp:106] Iteration 34500, lr = 0.0015
I0525 15:53:20.469465 23721 solver.cpp:237] Iteration 34650, loss = 1.24822
I0525 15:53:20.469499 23721 solver.cpp:253]     Train net output #0: loss = 1.24822 (* 1 = 1.24822 loss)
I0525 15:53:20.469513 23721 sgd_solver.cpp:106] Iteration 34650, lr = 0.0015
I0525 15:53:29.200868 23721 solver.cpp:237] Iteration 34800, loss = 1.26399
I0525 15:53:29.201028 23721 solver.cpp:253]     Train net output #0: loss = 1.26399 (* 1 = 1.26399 loss)
I0525 15:53:29.201042 23721 sgd_solver.cpp:106] Iteration 34800, lr = 0.0015
I0525 15:53:37.937538 23721 solver.cpp:237] Iteration 34950, loss = 1.21866
I0525 15:53:37.937580 23721 solver.cpp:253]     Train net output #0: loss = 1.21866 (* 1 = 1.21866 loss)
I0525 15:53:37.937595 23721 sgd_solver.cpp:106] Iteration 34950, lr = 0.0015
I0525 15:54:07.495334 23721 solver.cpp:237] Iteration 35100, loss = 1.12156
I0525 15:54:07.495514 23721 solver.cpp:253]     Train net output #0: loss = 1.12156 (* 1 = 1.12156 loss)
I0525 15:54:07.495528 23721 sgd_solver.cpp:106] Iteration 35100, lr = 0.0015
I0525 15:54:16.232288 23721 solver.cpp:237] Iteration 35250, loss = 1.40078
I0525 15:54:16.232322 23721 solver.cpp:253]     Train net output #0: loss = 1.40078 (* 1 = 1.40078 loss)
I0525 15:54:16.232339 23721 sgd_solver.cpp:106] Iteration 35250, lr = 0.0015
I0525 15:54:24.963872 23721 solver.cpp:237] Iteration 35400, loss = 1.36423
I0525 15:54:24.963922 23721 solver.cpp:253]     Train net output #0: loss = 1.36423 (* 1 = 1.36423 loss)
I0525 15:54:24.963935 23721 sgd_solver.cpp:106] Iteration 35400, lr = 0.0015
I0525 15:54:33.692147 23721 solver.cpp:237] Iteration 35550, loss = 1.20367
I0525 15:54:33.692181 23721 solver.cpp:253]     Train net output #0: loss = 1.20367 (* 1 = 1.20367 loss)
I0525 15:54:33.692194 23721 sgd_solver.cpp:106] Iteration 35550, lr = 0.0015
I0525 15:54:42.420142 23721 solver.cpp:237] Iteration 35700, loss = 1.29019
I0525 15:54:42.420313 23721 solver.cpp:253]     Train net output #0: loss = 1.29019 (* 1 = 1.29019 loss)
I0525 15:54:42.420328 23721 sgd_solver.cpp:106] Iteration 35700, lr = 0.0015
I0525 15:54:51.157555 23721 solver.cpp:237] Iteration 35850, loss = 1.33544
I0525 15:54:51.157598 23721 solver.cpp:253]     Train net output #0: loss = 1.33544 (* 1 = 1.33544 loss)
I0525 15:54:51.157614 23721 sgd_solver.cpp:106] Iteration 35850, lr = 0.0015
I0525 15:54:59.833281 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_36000.caffemodel
I0525 15:54:59.914482 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_36000.solverstate
I0525 15:54:59.941527 23721 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 15:56:07.697734 23721 solver.cpp:409]     Test net output #0: accuracy = 0.861759
I0525 15:56:07.697924 23721 solver.cpp:409]     Test net output #1: loss = 0.484559 (* 1 = 0.484559 loss)
I0525 15:56:28.589227 23721 solver.cpp:237] Iteration 36000, loss = 1.30169
I0525 15:56:28.589280 23721 solver.cpp:253]     Train net output #0: loss = 1.30169 (* 1 = 1.30169 loss)
I0525 15:56:28.589298 23721 sgd_solver.cpp:106] Iteration 36000, lr = 0.0015
I0525 15:56:37.308866 23721 solver.cpp:237] Iteration 36150, loss = 1.19667
I0525 15:56:37.308902 23721 solver.cpp:253]     Train net output #0: loss = 1.19667 (* 1 = 1.19667 loss)
I0525 15:56:37.308917 23721 sgd_solver.cpp:106] Iteration 36150, lr = 0.0015
I0525 15:56:46.029155 23721 solver.cpp:237] Iteration 36300, loss = 1.2622
I0525 15:56:46.029319 23721 solver.cpp:253]     Train net output #0: loss = 1.2622 (* 1 = 1.2622 loss)
I0525 15:56:46.029331 23721 sgd_solver.cpp:106] Iteration 36300, lr = 0.0015
I0525 15:56:54.751322 23721 solver.cpp:237] Iteration 36450, loss = 1.40697
I0525 15:56:54.751363 23721 solver.cpp:253]     Train net output #0: loss = 1.40697 (* 1 = 1.40697 loss)
I0525 15:56:54.751384 23721 sgd_solver.cpp:106] Iteration 36450, lr = 0.0015
I0525 15:57:03.467495 23721 solver.cpp:237] Iteration 36600, loss = 1.28921
I0525 15:57:03.467530 23721 solver.cpp:253]     Train net output #0: loss = 1.28921 (* 1 = 1.28921 loss)
I0525 15:57:03.467546 23721 sgd_solver.cpp:106] Iteration 36600, lr = 0.0015
I0525 15:57:12.189764 23721 solver.cpp:237] Iteration 36750, loss = 1.22488
I0525 15:57:12.189798 23721 solver.cpp:253]     Train net output #0: loss = 1.22488 (* 1 = 1.22488 loss)
I0525 15:57:12.189815 23721 sgd_solver.cpp:106] Iteration 36750, lr = 0.0015
I0525 15:57:20.913445 23721 solver.cpp:237] Iteration 36900, loss = 1.38537
I0525 15:57:20.913614 23721 solver.cpp:253]     Train net output #0: loss = 1.38537 (* 1 = 1.38537 loss)
I0525 15:57:20.913627 23721 sgd_solver.cpp:106] Iteration 36900, lr = 0.0015
I0525 15:57:50.489142 23721 solver.cpp:237] Iteration 37050, loss = 1.26678
I0525 15:57:50.489192 23721 solver.cpp:253]     Train net output #0: loss = 1.26678 (* 1 = 1.26678 loss)
I0525 15:57:50.489207 23721 sgd_solver.cpp:106] Iteration 37050, lr = 0.0015
I0525 15:57:59.217322 23721 solver.cpp:237] Iteration 37200, loss = 1.24891
I0525 15:57:59.217497 23721 solver.cpp:253]     Train net output #0: loss = 1.24891 (* 1 = 1.24891 loss)
I0525 15:57:59.217510 23721 sgd_solver.cpp:106] Iteration 37200, lr = 0.0015
I0525 15:58:07.942059 23721 solver.cpp:237] Iteration 37350, loss = 1.17196
I0525 15:58:07.942104 23721 solver.cpp:253]     Train net output #0: loss = 1.17196 (* 1 = 1.17196 loss)
I0525 15:58:07.942119 23721 sgd_solver.cpp:106] Iteration 37350, lr = 0.0015
I0525 15:58:16.608772 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_37500.caffemodel
I0525 15:58:16.689546 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_37500.solverstate
I0525 15:58:16.734931 23721 solver.cpp:237] Iteration 37500, loss = 1.10572
I0525 15:58:16.734979 23721 solver.cpp:253]     Train net output #0: loss = 1.10572 (* 1 = 1.10572 loss)
I0525 15:58:16.734997 23721 sgd_solver.cpp:106] Iteration 37500, lr = 0.0015
I0525 15:58:25.462401 23721 solver.cpp:237] Iteration 37650, loss = 1.22459
I0525 15:58:25.462436 23721 solver.cpp:253]     Train net output #0: loss = 1.22459 (* 1 = 1.22459 loss)
I0525 15:58:25.462452 23721 sgd_solver.cpp:106] Iteration 37650, lr = 0.0015
I0525 15:58:34.189590 23721 solver.cpp:237] Iteration 37800, loss = 1.14649
I0525 15:58:34.189769 23721 solver.cpp:253]     Train net output #0: loss = 1.14649 (* 1 = 1.14649 loss)
I0525 15:58:34.189784 23721 sgd_solver.cpp:106] Iteration 37800, lr = 0.0015
I0525 15:58:42.920670 23721 solver.cpp:237] Iteration 37950, loss = 1.22987
I0525 15:58:42.920703 23721 solver.cpp:253]     Train net output #0: loss = 1.22987 (* 1 = 1.22987 loss)
I0525 15:58:42.920720 23721 sgd_solver.cpp:106] Iteration 37950, lr = 0.0015
I0525 15:59:12.511627 23721 solver.cpp:237] Iteration 38100, loss = 1.04728
I0525 15:59:12.511807 23721 solver.cpp:253]     Train net output #0: loss = 1.04728 (* 1 = 1.04728 loss)
I0525 15:59:12.511822 23721 sgd_solver.cpp:106] Iteration 38100, lr = 0.0015
I0525 15:59:21.233327 23721 solver.cpp:237] Iteration 38250, loss = 1.12873
I0525 15:59:21.233369 23721 solver.cpp:253]     Train net output #0: loss = 1.12873 (* 1 = 1.12873 loss)
I0525 15:59:21.233386 23721 sgd_solver.cpp:106] Iteration 38250, lr = 0.0015
I0525 15:59:29.955977 23721 solver.cpp:237] Iteration 38400, loss = 1.16707
I0525 15:59:29.956012 23721 solver.cpp:253]     Train net output #0: loss = 1.16707 (* 1 = 1.16707 loss)
I0525 15:59:29.956027 23721 sgd_solver.cpp:106] Iteration 38400, lr = 0.0015
I0525 15:59:38.682081 23721 solver.cpp:237] Iteration 38550, loss = 1.38282
I0525 15:59:38.682116 23721 solver.cpp:253]     Train net output #0: loss = 1.38282 (* 1 = 1.38282 loss)
I0525 15:59:38.682129 23721 sgd_solver.cpp:106] Iteration 38550, lr = 0.0015
I0525 15:59:47.406934 23721 solver.cpp:237] Iteration 38700, loss = 1.13008
I0525 15:59:47.407117 23721 solver.cpp:253]     Train net output #0: loss = 1.13008 (* 1 = 1.13008 loss)
I0525 15:59:47.407131 23721 sgd_solver.cpp:106] Iteration 38700, lr = 0.0015
I0525 15:59:56.127929 23721 solver.cpp:237] Iteration 38850, loss = 0.994632
I0525 15:59:56.127964 23721 solver.cpp:253]     Train net output #0: loss = 0.994632 (* 1 = 0.994632 loss)
I0525 15:59:56.127980 23721 sgd_solver.cpp:106] Iteration 38850, lr = 0.0015
I0525 16:00:04.795316 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_39000.caffemodel
I0525 16:00:04.874135 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_39000.solverstate
I0525 16:00:04.899889 23721 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 16:00:51.736871 23721 solver.cpp:409]     Test net output #0: accuracy = 0.852632
I0525 16:00:51.737071 23721 solver.cpp:409]     Test net output #1: loss = 0.498883 (* 1 = 0.498883 loss)
I0525 16:01:12.585193 23721 solver.cpp:237] Iteration 39000, loss = 1.21207
I0525 16:01:12.585245 23721 solver.cpp:253]     Train net output #0: loss = 1.21207 (* 1 = 1.21207 loss)
I0525 16:01:12.585259 23721 sgd_solver.cpp:106] Iteration 39000, lr = 0.0015
I0525 16:01:21.315538 23721 solver.cpp:237] Iteration 39150, loss = 1.02397
I0525 16:01:21.315574 23721 solver.cpp:253]     Train net output #0: loss = 1.02397 (* 1 = 1.02397 loss)
I0525 16:01:21.315589 23721 sgd_solver.cpp:106] Iteration 39150, lr = 0.0015
I0525 16:01:30.051288 23721 solver.cpp:237] Iteration 39300, loss = 1.15582
I0525 16:01:30.051465 23721 solver.cpp:253]     Train net output #0: loss = 1.15582 (* 1 = 1.15582 loss)
I0525 16:01:30.051479 23721 sgd_solver.cpp:106] Iteration 39300, lr = 0.0015
I0525 16:01:38.785259 23721 solver.cpp:237] Iteration 39450, loss = 1.24888
I0525 16:01:38.785295 23721 solver.cpp:253]     Train net output #0: loss = 1.24888 (* 1 = 1.24888 loss)
I0525 16:01:38.785308 23721 sgd_solver.cpp:106] Iteration 39450, lr = 0.0015
I0525 16:01:47.520655 23721 solver.cpp:237] Iteration 39600, loss = 1.18297
I0525 16:01:47.520690 23721 solver.cpp:253]     Train net output #0: loss = 1.18297 (* 1 = 1.18297 loss)
I0525 16:01:47.520706 23721 sgd_solver.cpp:106] Iteration 39600, lr = 0.0015
I0525 16:01:56.255717 23721 solver.cpp:237] Iteration 39750, loss = 1.33005
I0525 16:01:56.255761 23721 solver.cpp:253]     Train net output #0: loss = 1.33005 (* 1 = 1.33005 loss)
I0525 16:01:56.255779 23721 sgd_solver.cpp:106] Iteration 39750, lr = 0.0015
I0525 16:02:04.989152 23721 solver.cpp:237] Iteration 39900, loss = 1.14035
I0525 16:02:04.989313 23721 solver.cpp:253]     Train net output #0: loss = 1.14035 (* 1 = 1.14035 loss)
I0525 16:02:04.989326 23721 sgd_solver.cpp:106] Iteration 39900, lr = 0.0015
I0525 16:02:34.542584 23721 solver.cpp:237] Iteration 40050, loss = 1.30224
I0525 16:02:34.542640 23721 solver.cpp:253]     Train net output #0: loss = 1.30224 (* 1 = 1.30224 loss)
I0525 16:02:34.542656 23721 sgd_solver.cpp:106] Iteration 40050, lr = 0.0015
I0525 16:02:43.274350 23721 solver.cpp:237] Iteration 40200, loss = 1.33929
I0525 16:02:43.274530 23721 solver.cpp:253]     Train net output #0: loss = 1.33929 (* 1 = 1.33929 loss)
I0525 16:02:43.274544 23721 sgd_solver.cpp:106] Iteration 40200, lr = 0.0015
I0525 16:02:52.010615 23721 solver.cpp:237] Iteration 40350, loss = 1.17193
I0525 16:02:52.010650 23721 solver.cpp:253]     Train net output #0: loss = 1.17193 (* 1 = 1.17193 loss)
I0525 16:02:52.010668 23721 sgd_solver.cpp:106] Iteration 40350, lr = 0.0015
I0525 16:03:00.689357 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_40500.caffemodel
I0525 16:03:00.767602 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_40500.solverstate
I0525 16:03:00.811475 23721 solver.cpp:237] Iteration 40500, loss = 1.29793
I0525 16:03:00.811516 23721 solver.cpp:253]     Train net output #0: loss = 1.29793 (* 1 = 1.29793 loss)
I0525 16:03:00.811532 23721 sgd_solver.cpp:106] Iteration 40500, lr = 0.0015
I0525 16:03:09.543884 23721 solver.cpp:237] Iteration 40650, loss = 1.16755
I0525 16:03:09.543926 23721 solver.cpp:253]     Train net output #0: loss = 1.16755 (* 1 = 1.16755 loss)
I0525 16:03:09.543943 23721 sgd_solver.cpp:106] Iteration 40650, lr = 0.0015
I0525 16:03:18.279350 23721 solver.cpp:237] Iteration 40800, loss = 1.21563
I0525 16:03:18.279516 23721 solver.cpp:253]     Train net output #0: loss = 1.21563 (* 1 = 1.21563 loss)
I0525 16:03:18.279531 23721 sgd_solver.cpp:106] Iteration 40800, lr = 0.0015
I0525 16:03:27.014979 23721 solver.cpp:237] Iteration 40950, loss = 1.27202
I0525 16:03:27.015015 23721 solver.cpp:253]     Train net output #0: loss = 1.27202 (* 1 = 1.27202 loss)
I0525 16:03:27.015031 23721 sgd_solver.cpp:106] Iteration 40950, lr = 0.0015
I0525 16:03:56.577189 23721 solver.cpp:237] Iteration 41100, loss = 1.21158
I0525 16:03:56.577380 23721 solver.cpp:253]     Train net output #0: loss = 1.21158 (* 1 = 1.21158 loss)
I0525 16:03:56.577394 23721 sgd_solver.cpp:106] Iteration 41100, lr = 0.0015
I0525 16:04:05.312492 23721 solver.cpp:237] Iteration 41250, loss = 1.28589
I0525 16:04:05.312528 23721 solver.cpp:253]     Train net output #0: loss = 1.28589 (* 1 = 1.28589 loss)
I0525 16:04:05.312546 23721 sgd_solver.cpp:106] Iteration 41250, lr = 0.0015
I0525 16:04:14.044903 23721 solver.cpp:237] Iteration 41400, loss = 1.17531
I0525 16:04:14.044939 23721 solver.cpp:253]     Train net output #0: loss = 1.17531 (* 1 = 1.17531 loss)
I0525 16:04:14.044955 23721 sgd_solver.cpp:106] Iteration 41400, lr = 0.0015
I0525 16:04:22.782728 23721 solver.cpp:237] Iteration 41550, loss = 1.38033
I0525 16:04:22.782773 23721 solver.cpp:253]     Train net output #0: loss = 1.38033 (* 1 = 1.38033 loss)
I0525 16:04:22.782789 23721 sgd_solver.cpp:106] Iteration 41550, lr = 0.0015
I0525 16:04:31.522794 23721 solver.cpp:237] Iteration 41700, loss = 1.23354
I0525 16:04:31.522958 23721 solver.cpp:253]     Train net output #0: loss = 1.23354 (* 1 = 1.23354 loss)
I0525 16:04:31.522970 23721 sgd_solver.cpp:106] Iteration 41700, lr = 0.0015
I0525 16:04:40.254899 23721 solver.cpp:237] Iteration 41850, loss = 1.19101
I0525 16:04:40.254933 23721 solver.cpp:253]     Train net output #0: loss = 1.19101 (* 1 = 1.19101 loss)
I0525 16:04:40.254950 23721 sgd_solver.cpp:106] Iteration 41850, lr = 0.0015
I0525 16:04:48.931643 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_42000.caffemodel
I0525 16:04:49.009907 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_42000.solverstate
I0525 16:04:49.035729 23721 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 16:05:56.734719 23721 solver.cpp:409]     Test net output #0: accuracy = 0.861279
I0525 16:05:56.734904 23721 solver.cpp:409]     Test net output #1: loss = 0.43157 (* 1 = 0.43157 loss)
I0525 16:06:17.584137 23721 solver.cpp:237] Iteration 42000, loss = 1.32593
I0525 16:06:17.584192 23721 solver.cpp:253]     Train net output #0: loss = 1.32593 (* 1 = 1.32593 loss)
I0525 16:06:17.584206 23721 sgd_solver.cpp:106] Iteration 42000, lr = 0.0015
I0525 16:06:26.327569 23721 solver.cpp:237] Iteration 42150, loss = 1.12875
I0525 16:06:26.327615 23721 solver.cpp:253]     Train net output #0: loss = 1.12875 (* 1 = 1.12875 loss)
I0525 16:06:26.327632 23721 sgd_solver.cpp:106] Iteration 42150, lr = 0.0015
I0525 16:06:35.053728 23721 solver.cpp:237] Iteration 42300, loss = 1.00642
I0525 16:06:35.053896 23721 solver.cpp:253]     Train net output #0: loss = 1.00642 (* 1 = 1.00642 loss)
I0525 16:06:35.053910 23721 sgd_solver.cpp:106] Iteration 42300, lr = 0.0015
I0525 16:06:43.781028 23721 solver.cpp:237] Iteration 42450, loss = 1.17947
I0525 16:06:43.781062 23721 solver.cpp:253]     Train net output #0: loss = 1.17947 (* 1 = 1.17947 loss)
I0525 16:06:43.781077 23721 sgd_solver.cpp:106] Iteration 42450, lr = 0.0015
I0525 16:06:52.513869 23721 solver.cpp:237] Iteration 42600, loss = 1.18961
I0525 16:06:52.513906 23721 solver.cpp:253]     Train net output #0: loss = 1.18961 (* 1 = 1.18961 loss)
I0525 16:06:52.513923 23721 sgd_solver.cpp:106] Iteration 42600, lr = 0.0015
I0525 16:07:01.246443 23721 solver.cpp:237] Iteration 42750, loss = 1.22826
I0525 16:07:01.246477 23721 solver.cpp:253]     Train net output #0: loss = 1.22826 (* 1 = 1.22826 loss)
I0525 16:07:01.246495 23721 sgd_solver.cpp:106] Iteration 42750, lr = 0.0015
I0525 16:07:09.977243 23721 solver.cpp:237] Iteration 42900, loss = 0.959951
I0525 16:07:09.977413 23721 solver.cpp:253]     Train net output #0: loss = 0.959951 (* 1 = 0.959951 loss)
I0525 16:07:09.977429 23721 sgd_solver.cpp:106] Iteration 42900, lr = 0.0015
I0525 16:07:39.549906 23721 solver.cpp:237] Iteration 43050, loss = 1.47055
I0525 16:07:39.549954 23721 solver.cpp:253]     Train net output #0: loss = 1.47055 (* 1 = 1.47055 loss)
I0525 16:07:39.549973 23721 sgd_solver.cpp:106] Iteration 43050, lr = 0.0015
I0525 16:07:48.284646 23721 solver.cpp:237] Iteration 43200, loss = 1.23715
I0525 16:07:48.284824 23721 solver.cpp:253]     Train net output #0: loss = 1.23715 (* 1 = 1.23715 loss)
I0525 16:07:48.284838 23721 sgd_solver.cpp:106] Iteration 43200, lr = 0.0015
I0525 16:07:57.008846 23721 solver.cpp:237] Iteration 43350, loss = 1.16549
I0525 16:07:57.008882 23721 solver.cpp:253]     Train net output #0: loss = 1.16549 (* 1 = 1.16549 loss)
I0525 16:07:57.008898 23721 sgd_solver.cpp:106] Iteration 43350, lr = 0.0015
I0525 16:08:05.687244 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_43500.caffemodel
I0525 16:08:05.768286 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_43500.solverstate
I0525 16:08:05.814039 23721 solver.cpp:237] Iteration 43500, loss = 1.29228
I0525 16:08:05.814090 23721 solver.cpp:253]     Train net output #0: loss = 1.29228 (* 1 = 1.29228 loss)
I0525 16:08:05.814103 23721 sgd_solver.cpp:106] Iteration 43500, lr = 0.0015
I0525 16:08:14.546002 23721 solver.cpp:237] Iteration 43650, loss = 1.08677
I0525 16:08:14.546038 23721 solver.cpp:253]     Train net output #0: loss = 1.08677 (* 1 = 1.08677 loss)
I0525 16:08:14.546054 23721 sgd_solver.cpp:106] Iteration 43650, lr = 0.0015
I0525 16:08:23.279152 23721 solver.cpp:237] Iteration 43800, loss = 1.43465
I0525 16:08:23.279330 23721 solver.cpp:253]     Train net output #0: loss = 1.43465 (* 1 = 1.43465 loss)
I0525 16:08:23.279345 23721 sgd_solver.cpp:106] Iteration 43800, lr = 0.0015
I0525 16:08:32.011869 23721 solver.cpp:237] Iteration 43950, loss = 1.31394
I0525 16:08:32.011906 23721 solver.cpp:253]     Train net output #0: loss = 1.31394 (* 1 = 1.31394 loss)
I0525 16:08:32.011927 23721 sgd_solver.cpp:106] Iteration 43950, lr = 0.0015
I0525 16:09:01.619693 23721 solver.cpp:237] Iteration 44100, loss = 1.12999
I0525 16:09:01.619877 23721 solver.cpp:253]     Train net output #0: loss = 1.12999 (* 1 = 1.12999 loss)
I0525 16:09:01.619892 23721 sgd_solver.cpp:106] Iteration 44100, lr = 0.0015
I0525 16:09:10.357163 23721 solver.cpp:237] Iteration 44250, loss = 1.2718
I0525 16:09:10.357197 23721 solver.cpp:253]     Train net output #0: loss = 1.2718 (* 1 = 1.2718 loss)
I0525 16:09:10.357214 23721 sgd_solver.cpp:106] Iteration 44250, lr = 0.0015
I0525 16:09:19.089601 23721 solver.cpp:237] Iteration 44400, loss = 1.07139
I0525 16:09:19.089635 23721 solver.cpp:253]     Train net output #0: loss = 1.07139 (* 1 = 1.07139 loss)
I0525 16:09:19.089651 23721 sgd_solver.cpp:106] Iteration 44400, lr = 0.0015
I0525 16:09:27.819105 23721 solver.cpp:237] Iteration 44550, loss = 1.20983
I0525 16:09:27.819145 23721 solver.cpp:253]     Train net output #0: loss = 1.20983 (* 1 = 1.20983 loss)
I0525 16:09:27.819164 23721 sgd_solver.cpp:106] Iteration 44550, lr = 0.0015
I0525 16:09:36.549106 23721 solver.cpp:237] Iteration 44700, loss = 1.21047
I0525 16:09:36.549279 23721 solver.cpp:253]     Train net output #0: loss = 1.21047 (* 1 = 1.21047 loss)
I0525 16:09:36.549293 23721 sgd_solver.cpp:106] Iteration 44700, lr = 0.0015
I0525 16:09:45.283248 23721 solver.cpp:237] Iteration 44850, loss = 1.30997
I0525 16:09:45.283293 23721 solver.cpp:253]     Train net output #0: loss = 1.30997 (* 1 = 1.30997 loss)
I0525 16:09:45.283309 23721 sgd_solver.cpp:106] Iteration 44850, lr = 0.0015
I0525 16:09:53.963573 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_45000.caffemodel
I0525 16:09:54.045142 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_45000.solverstate
I0525 16:09:54.073077 23721 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 16:10:40.605237 23721 solver.cpp:409]     Test net output #0: accuracy = 0.86742
I0525 16:10:40.605430 23721 solver.cpp:409]     Test net output #1: loss = 0.436275 (* 1 = 0.436275 loss)
I0525 16:11:01.456152 23721 solver.cpp:237] Iteration 45000, loss = 1.2774
I0525 16:11:01.456204 23721 solver.cpp:253]     Train net output #0: loss = 1.2774 (* 1 = 1.2774 loss)
I0525 16:11:01.456221 23721 sgd_solver.cpp:106] Iteration 45000, lr = 0.0015
I0525 16:11:10.187834 23721 solver.cpp:237] Iteration 45150, loss = 1.04541
I0525 16:11:10.187868 23721 solver.cpp:253]     Train net output #0: loss = 1.04541 (* 1 = 1.04541 loss)
I0525 16:11:10.187885 23721 sgd_solver.cpp:106] Iteration 45150, lr = 0.0015
I0525 16:11:18.922005 23721 solver.cpp:237] Iteration 45300, loss = 1.21785
I0525 16:11:18.922174 23721 solver.cpp:253]     Train net output #0: loss = 1.21785 (* 1 = 1.21785 loss)
I0525 16:11:18.922188 23721 sgd_solver.cpp:106] Iteration 45300, lr = 0.0015
I0525 16:11:27.654213 23721 solver.cpp:237] Iteration 45450, loss = 1.14136
I0525 16:11:27.654254 23721 solver.cpp:253]     Train net output #0: loss = 1.14136 (* 1 = 1.14136 loss)
I0525 16:11:27.654273 23721 sgd_solver.cpp:106] Iteration 45450, lr = 0.0015
I0525 16:11:36.384909 23721 solver.cpp:237] Iteration 45600, loss = 1.13468
I0525 16:11:36.384944 23721 solver.cpp:253]     Train net output #0: loss = 1.13468 (* 1 = 1.13468 loss)
I0525 16:11:36.384961 23721 sgd_solver.cpp:106] Iteration 45600, lr = 0.0015
I0525 16:11:45.118057 23721 solver.cpp:237] Iteration 45750, loss = 1.12991
I0525 16:11:45.118093 23721 solver.cpp:253]     Train net output #0: loss = 1.12991 (* 1 = 1.12991 loss)
I0525 16:11:45.118108 23721 sgd_solver.cpp:106] Iteration 45750, lr = 0.0015
I0525 16:11:53.854966 23721 solver.cpp:237] Iteration 45900, loss = 1.23893
I0525 16:11:53.855142 23721 solver.cpp:253]     Train net output #0: loss = 1.23893 (* 1 = 1.23893 loss)
I0525 16:11:53.855156 23721 sgd_solver.cpp:106] Iteration 45900, lr = 0.0015
I0525 16:12:23.451972 23721 solver.cpp:237] Iteration 46050, loss = 1.16535
I0525 16:12:23.452020 23721 solver.cpp:253]     Train net output #0: loss = 1.16535 (* 1 = 1.16535 loss)
I0525 16:12:23.452038 23721 sgd_solver.cpp:106] Iteration 46050, lr = 0.0015
I0525 16:12:32.181327 23721 solver.cpp:237] Iteration 46200, loss = 1.05774
I0525 16:12:32.181496 23721 solver.cpp:253]     Train net output #0: loss = 1.05774 (* 1 = 1.05774 loss)
I0525 16:12:32.181509 23721 sgd_solver.cpp:106] Iteration 46200, lr = 0.0015
I0525 16:12:40.916568 23721 solver.cpp:237] Iteration 46350, loss = 1.42374
I0525 16:12:40.916615 23721 solver.cpp:253]     Train net output #0: loss = 1.42374 (* 1 = 1.42374 loss)
I0525 16:12:40.916630 23721 sgd_solver.cpp:106] Iteration 46350, lr = 0.0015
I0525 16:12:49.590106 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_46500.caffemodel
I0525 16:12:49.668350 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_46500.solverstate
I0525 16:12:49.711748 23721 solver.cpp:237] Iteration 46500, loss = 1.18101
I0525 16:12:49.711793 23721 solver.cpp:253]     Train net output #0: loss = 1.18101 (* 1 = 1.18101 loss)
I0525 16:12:49.711812 23721 sgd_solver.cpp:106] Iteration 46500, lr = 0.0015
I0525 16:12:58.448402 23721 solver.cpp:237] Iteration 46650, loss = 1.18143
I0525 16:12:58.448438 23721 solver.cpp:253]     Train net output #0: loss = 1.18143 (* 1 = 1.18143 loss)
I0525 16:12:58.448451 23721 sgd_solver.cpp:106] Iteration 46650, lr = 0.0015
I0525 16:13:07.182421 23721 solver.cpp:237] Iteration 46800, loss = 1.06644
I0525 16:13:07.182617 23721 solver.cpp:253]     Train net output #0: loss = 1.06644 (* 1 = 1.06644 loss)
I0525 16:13:07.182633 23721 sgd_solver.cpp:106] Iteration 46800, lr = 0.0015
I0525 16:13:15.921998 23721 solver.cpp:237] Iteration 46950, loss = 1.35074
I0525 16:13:15.922031 23721 solver.cpp:253]     Train net output #0: loss = 1.35074 (* 1 = 1.35074 loss)
I0525 16:13:15.922049 23721 sgd_solver.cpp:106] Iteration 46950, lr = 0.0015
I0525 16:13:45.487691 23721 solver.cpp:237] Iteration 47100, loss = 1.04378
I0525 16:13:45.487891 23721 solver.cpp:253]     Train net output #0: loss = 1.04378 (* 1 = 1.04378 loss)
I0525 16:13:45.487905 23721 sgd_solver.cpp:106] Iteration 47100, lr = 0.0015
I0525 16:13:54.219292 23721 solver.cpp:237] Iteration 47250, loss = 1.2465
I0525 16:13:54.219326 23721 solver.cpp:253]     Train net output #0: loss = 1.2465 (* 1 = 1.2465 loss)
I0525 16:13:54.219343 23721 sgd_solver.cpp:106] Iteration 47250, lr = 0.0015
I0525 16:14:02.958304 23721 solver.cpp:237] Iteration 47400, loss = 1.06147
I0525 16:14:02.958336 23721 solver.cpp:253]     Train net output #0: loss = 1.06147 (* 1 = 1.06147 loss)
I0525 16:14:02.958356 23721 sgd_solver.cpp:106] Iteration 47400, lr = 0.0015
I0525 16:14:11.691947 23721 solver.cpp:237] Iteration 47550, loss = 1.10864
I0525 16:14:11.691982 23721 solver.cpp:253]     Train net output #0: loss = 1.10864 (* 1 = 1.10864 loss)
I0525 16:14:11.691998 23721 sgd_solver.cpp:106] Iteration 47550, lr = 0.0015
I0525 16:14:20.424458 23721 solver.cpp:237] Iteration 47700, loss = 1.14742
I0525 16:14:20.424638 23721 solver.cpp:253]     Train net output #0: loss = 1.14742 (* 1 = 1.14742 loss)
I0525 16:14:20.424652 23721 sgd_solver.cpp:106] Iteration 47700, lr = 0.0015
I0525 16:14:29.159834 23721 solver.cpp:237] Iteration 47850, loss = 1.21532
I0525 16:14:29.159868 23721 solver.cpp:253]     Train net output #0: loss = 1.21532 (* 1 = 1.21532 loss)
I0525 16:14:29.159886 23721 sgd_solver.cpp:106] Iteration 47850, lr = 0.0015
I0525 16:14:37.837460 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_48000.caffemodel
I0525 16:14:37.916196 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_48000.solverstate
I0525 16:14:37.941953 23721 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 16:15:45.641621 23721 solver.cpp:409]     Test net output #0: accuracy = 0.870601
I0525 16:15:45.641808 23721 solver.cpp:409]     Test net output #1: loss = 0.398097 (* 1 = 0.398097 loss)
I0525 16:16:06.510938 23721 solver.cpp:237] Iteration 48000, loss = 0.99159
I0525 16:16:06.510993 23721 solver.cpp:253]     Train net output #0: loss = 0.99159 (* 1 = 0.99159 loss)
I0525 16:16:06.511008 23721 sgd_solver.cpp:106] Iteration 48000, lr = 0.0015
I0525 16:16:15.236434 23721 solver.cpp:237] Iteration 48150, loss = 1.15028
I0525 16:16:15.236469 23721 solver.cpp:253]     Train net output #0: loss = 1.15028 (* 1 = 1.15028 loss)
I0525 16:16:15.236487 23721 sgd_solver.cpp:106] Iteration 48150, lr = 0.0015
I0525 16:16:23.959218 23721 solver.cpp:237] Iteration 48300, loss = 0.977961
I0525 16:16:23.959388 23721 solver.cpp:253]     Train net output #0: loss = 0.977961 (* 1 = 0.977961 loss)
I0525 16:16:23.959403 23721 sgd_solver.cpp:106] Iteration 48300, lr = 0.0015
I0525 16:16:32.684260 23721 solver.cpp:237] Iteration 48450, loss = 1.35194
I0525 16:16:32.684298 23721 solver.cpp:253]     Train net output #0: loss = 1.35194 (* 1 = 1.35194 loss)
I0525 16:16:32.684314 23721 sgd_solver.cpp:106] Iteration 48450, lr = 0.0015
I0525 16:16:41.410395 23721 solver.cpp:237] Iteration 48600, loss = 1.34453
I0525 16:16:41.410431 23721 solver.cpp:253]     Train net output #0: loss = 1.34453 (* 1 = 1.34453 loss)
I0525 16:16:41.410449 23721 sgd_solver.cpp:106] Iteration 48600, lr = 0.0015
I0525 16:16:50.137439 23721 solver.cpp:237] Iteration 48750, loss = 1.20019
I0525 16:16:50.137476 23721 solver.cpp:253]     Train net output #0: loss = 1.20019 (* 1 = 1.20019 loss)
I0525 16:16:50.137495 23721 sgd_solver.cpp:106] Iteration 48750, lr = 0.0015
I0525 16:16:58.859623 23721 solver.cpp:237] Iteration 48900, loss = 1.09278
I0525 16:16:58.859799 23721 solver.cpp:253]     Train net output #0: loss = 1.09278 (* 1 = 1.09278 loss)
I0525 16:16:58.859814 23721 sgd_solver.cpp:106] Iteration 48900, lr = 0.0015
I0525 16:17:28.475585 23721 solver.cpp:237] Iteration 49050, loss = 1.25692
I0525 16:17:28.475636 23721 solver.cpp:253]     Train net output #0: loss = 1.25692 (* 1 = 1.25692 loss)
I0525 16:17:28.475648 23721 sgd_solver.cpp:106] Iteration 49050, lr = 0.0015
I0525 16:17:37.202679 23721 solver.cpp:237] Iteration 49200, loss = 1.24391
I0525 16:17:37.202853 23721 solver.cpp:253]     Train net output #0: loss = 1.24391 (* 1 = 1.24391 loss)
I0525 16:17:37.202867 23721 sgd_solver.cpp:106] Iteration 49200, lr = 0.0015
I0525 16:17:45.928350 23721 solver.cpp:237] Iteration 49350, loss = 1.11844
I0525 16:17:45.928396 23721 solver.cpp:253]     Train net output #0: loss = 1.11844 (* 1 = 1.11844 loss)
I0525 16:17:45.928413 23721 sgd_solver.cpp:106] Iteration 49350, lr = 0.0015
I0525 16:17:54.598383 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_49500.caffemodel
I0525 16:17:54.676365 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_49500.solverstate
I0525 16:17:54.722277 23721 solver.cpp:237] Iteration 49500, loss = 1.17132
I0525 16:17:54.722322 23721 solver.cpp:253]     Train net output #0: loss = 1.17132 (* 1 = 1.17132 loss)
I0525 16:17:54.722340 23721 sgd_solver.cpp:106] Iteration 49500, lr = 0.0015
I0525 16:18:03.453547 23721 solver.cpp:237] Iteration 49650, loss = 1.14635
I0525 16:18:03.453582 23721 solver.cpp:253]     Train net output #0: loss = 1.14635 (* 1 = 1.14635 loss)
I0525 16:18:03.453598 23721 sgd_solver.cpp:106] Iteration 49650, lr = 0.0015
I0525 16:18:12.176065 23721 solver.cpp:237] Iteration 49800, loss = 1.26967
I0525 16:18:12.176239 23721 solver.cpp:253]     Train net output #0: loss = 1.26967 (* 1 = 1.26967 loss)
I0525 16:18:12.176252 23721 sgd_solver.cpp:106] Iteration 49800, lr = 0.0015
I0525 16:18:20.903841 23721 solver.cpp:237] Iteration 49950, loss = 1.28133
I0525 16:18:20.903875 23721 solver.cpp:253]     Train net output #0: loss = 1.28133 (* 1 = 1.28133 loss)
I0525 16:18:20.903892 23721 sgd_solver.cpp:106] Iteration 49950, lr = 0.0015
I0525 16:18:50.511324 23721 solver.cpp:237] Iteration 50100, loss = 1.08331
I0525 16:18:50.511512 23721 solver.cpp:253]     Train net output #0: loss = 1.08331 (* 1 = 1.08331 loss)
I0525 16:18:50.511526 23721 sgd_solver.cpp:106] Iteration 50100, lr = 0.0015
I0525 16:18:59.231221 23721 solver.cpp:237] Iteration 50250, loss = 1.18571
I0525 16:18:59.231263 23721 solver.cpp:253]     Train net output #0: loss = 1.18571 (* 1 = 1.18571 loss)
I0525 16:18:59.231281 23721 sgd_solver.cpp:106] Iteration 50250, lr = 0.0015
I0525 16:19:07.957017 23721 solver.cpp:237] Iteration 50400, loss = 1.15993
I0525 16:19:07.957052 23721 solver.cpp:253]     Train net output #0: loss = 1.15993 (* 1 = 1.15993 loss)
I0525 16:19:07.957067 23721 sgd_solver.cpp:106] Iteration 50400, lr = 0.0015
I0525 16:19:16.684171 23721 solver.cpp:237] Iteration 50550, loss = 1.01749
I0525 16:19:16.684206 23721 solver.cpp:253]     Train net output #0: loss = 1.01749 (* 1 = 1.01749 loss)
I0525 16:19:16.684223 23721 sgd_solver.cpp:106] Iteration 50550, lr = 0.0015
I0525 16:19:25.407429 23721 solver.cpp:237] Iteration 50700, loss = 1.25773
I0525 16:19:25.407606 23721 solver.cpp:253]     Train net output #0: loss = 1.25773 (* 1 = 1.25773 loss)
I0525 16:19:25.407620 23721 sgd_solver.cpp:106] Iteration 50700, lr = 0.0015
I0525 16:19:34.133502 23721 solver.cpp:237] Iteration 50850, loss = 1.22239
I0525 16:19:34.133538 23721 solver.cpp:253]     Train net output #0: loss = 1.22239 (* 1 = 1.22239 loss)
I0525 16:19:34.133551 23721 sgd_solver.cpp:106] Iteration 50850, lr = 0.0015
I0525 16:19:42.797845 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_51000.caffemodel
I0525 16:19:42.878993 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_51000.solverstate
I0525 16:19:42.905756 23721 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 16:20:29.728477 23721 solver.cpp:409]     Test net output #0: accuracy = 0.874546
I0525 16:20:29.728675 23721 solver.cpp:409]     Test net output #1: loss = 0.42773 (* 1 = 0.42773 loss)
I0525 16:20:50.598791 23721 solver.cpp:237] Iteration 51000, loss = 1.26494
I0525 16:20:50.598845 23721 solver.cpp:253]     Train net output #0: loss = 1.26494 (* 1 = 1.26494 loss)
I0525 16:20:50.598862 23721 sgd_solver.cpp:106] Iteration 51000, lr = 0.0015
I0525 16:20:59.336066 23721 solver.cpp:237] Iteration 51150, loss = 1.16664
I0525 16:20:59.336099 23721 solver.cpp:253]     Train net output #0: loss = 1.16664 (* 1 = 1.16664 loss)
I0525 16:20:59.336117 23721 sgd_solver.cpp:106] Iteration 51150, lr = 0.0015
I0525 16:21:08.070077 23721 solver.cpp:237] Iteration 51300, loss = 1.2459
I0525 16:21:08.070251 23721 solver.cpp:253]     Train net output #0: loss = 1.2459 (* 1 = 1.2459 loss)
I0525 16:21:08.070266 23721 sgd_solver.cpp:106] Iteration 51300, lr = 0.0015
I0525 16:21:16.804530 23721 solver.cpp:237] Iteration 51450, loss = 1.13577
I0525 16:21:16.804564 23721 solver.cpp:253]     Train net output #0: loss = 1.13577 (* 1 = 1.13577 loss)
I0525 16:21:16.804584 23721 sgd_solver.cpp:106] Iteration 51450, lr = 0.0015
I0525 16:21:25.541399 23721 solver.cpp:237] Iteration 51600, loss = 1.35922
I0525 16:21:25.541441 23721 solver.cpp:253]     Train net output #0: loss = 1.35922 (* 1 = 1.35922 loss)
I0525 16:21:25.541458 23721 sgd_solver.cpp:106] Iteration 51600, lr = 0.0015
I0525 16:21:34.276316 23721 solver.cpp:237] Iteration 51750, loss = 1.14484
I0525 16:21:34.276351 23721 solver.cpp:253]     Train net output #0: loss = 1.14484 (* 1 = 1.14484 loss)
I0525 16:21:34.276367 23721 sgd_solver.cpp:106] Iteration 51750, lr = 0.0015
I0525 16:21:43.010342 23721 solver.cpp:237] Iteration 51900, loss = 1.1393
I0525 16:21:43.010510 23721 solver.cpp:253]     Train net output #0: loss = 1.1393 (* 1 = 1.1393 loss)
I0525 16:21:43.010524 23721 sgd_solver.cpp:106] Iteration 51900, lr = 0.0015
I0525 16:22:12.600122 23721 solver.cpp:237] Iteration 52050, loss = 1.03657
I0525 16:22:12.600172 23721 solver.cpp:253]     Train net output #0: loss = 1.03657 (* 1 = 1.03657 loss)
I0525 16:22:12.600188 23721 sgd_solver.cpp:106] Iteration 52050, lr = 0.0015
I0525 16:22:21.337404 23721 solver.cpp:237] Iteration 52200, loss = 1.15004
I0525 16:22:21.337575 23721 solver.cpp:253]     Train net output #0: loss = 1.15004 (* 1 = 1.15004 loss)
I0525 16:22:21.337589 23721 sgd_solver.cpp:106] Iteration 52200, lr = 0.0015
I0525 16:22:30.074952 23721 solver.cpp:237] Iteration 52350, loss = 1.26701
I0525 16:22:30.074987 23721 solver.cpp:253]     Train net output #0: loss = 1.26701 (* 1 = 1.26701 loss)
I0525 16:22:30.075004 23721 sgd_solver.cpp:106] Iteration 52350, lr = 0.0015
I0525 16:22:38.752830 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_52500.caffemodel
I0525 16:22:38.833942 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_52500.solverstate
I0525 16:22:38.879339 23721 solver.cpp:237] Iteration 52500, loss = 1.18392
I0525 16:22:38.879389 23721 solver.cpp:253]     Train net output #0: loss = 1.18392 (* 1 = 1.18392 loss)
I0525 16:22:38.879405 23721 sgd_solver.cpp:106] Iteration 52500, lr = 0.0015
I0525 16:22:47.613201 23721 solver.cpp:237] Iteration 52650, loss = 1.07943
I0525 16:22:47.613234 23721 solver.cpp:253]     Train net output #0: loss = 1.07943 (* 1 = 1.07943 loss)
I0525 16:22:47.613257 23721 sgd_solver.cpp:106] Iteration 52650, lr = 0.0015
I0525 16:22:56.346892 23721 solver.cpp:237] Iteration 52800, loss = 1.21132
I0525 16:22:56.347085 23721 solver.cpp:253]     Train net output #0: loss = 1.21132 (* 1 = 1.21132 loss)
I0525 16:22:56.347100 23721 sgd_solver.cpp:106] Iteration 52800, lr = 0.0015
I0525 16:23:05.079601 23721 solver.cpp:237] Iteration 52950, loss = 1.18433
I0525 16:23:05.079644 23721 solver.cpp:253]     Train net output #0: loss = 1.18433 (* 1 = 1.18433 loss)
I0525 16:23:05.079658 23721 sgd_solver.cpp:106] Iteration 52950, lr = 0.0015
I0525 16:23:34.662210 23721 solver.cpp:237] Iteration 53100, loss = 1.09568
I0525 16:23:34.662408 23721 solver.cpp:253]     Train net output #0: loss = 1.09568 (* 1 = 1.09568 loss)
I0525 16:23:34.662423 23721 sgd_solver.cpp:106] Iteration 53100, lr = 0.0015
I0525 16:23:43.399397 23721 solver.cpp:237] Iteration 53250, loss = 1.14176
I0525 16:23:43.399431 23721 solver.cpp:253]     Train net output #0: loss = 1.14176 (* 1 = 1.14176 loss)
I0525 16:23:43.399446 23721 sgd_solver.cpp:106] Iteration 53250, lr = 0.0015
I0525 16:23:52.133257 23721 solver.cpp:237] Iteration 53400, loss = 1.3869
I0525 16:23:52.133292 23721 solver.cpp:253]     Train net output #0: loss = 1.3869 (* 1 = 1.3869 loss)
I0525 16:23:52.133309 23721 sgd_solver.cpp:106] Iteration 53400, lr = 0.0015
I0525 16:24:00.865700 23721 solver.cpp:237] Iteration 53550, loss = 1.18348
I0525 16:24:00.865744 23721 solver.cpp:253]     Train net output #0: loss = 1.18348 (* 1 = 1.18348 loss)
I0525 16:24:00.865761 23721 sgd_solver.cpp:106] Iteration 53550, lr = 0.0015
I0525 16:24:09.602455 23721 solver.cpp:237] Iteration 53700, loss = 1.23908
I0525 16:24:09.602632 23721 solver.cpp:253]     Train net output #0: loss = 1.23908 (* 1 = 1.23908 loss)
I0525 16:24:09.602646 23721 sgd_solver.cpp:106] Iteration 53700, lr = 0.0015
I0525 16:24:18.339043 23721 solver.cpp:237] Iteration 53850, loss = 0.959349
I0525 16:24:18.339078 23721 solver.cpp:253]     Train net output #0: loss = 0.959349 (* 1 = 0.959349 loss)
I0525 16:24:18.339095 23721 sgd_solver.cpp:106] Iteration 53850, lr = 0.0015
I0525 16:24:27.019739 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_54000.caffemodel
I0525 16:24:27.101797 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_54000.solverstate
I0525 16:24:27.132908 23721 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 16:25:34.787580 23721 solver.cpp:409]     Test net output #0: accuracy = 0.872839
I0525 16:25:34.787757 23721 solver.cpp:409]     Test net output #1: loss = 0.412182 (* 1 = 0.412182 loss)
I0525 16:25:55.626379 23721 solver.cpp:237] Iteration 54000, loss = 1.3251
I0525 16:25:55.626430 23721 solver.cpp:253]     Train net output #0: loss = 1.3251 (* 1 = 1.3251 loss)
I0525 16:25:55.626446 23721 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015
I0525 16:26:04.359742 23721 solver.cpp:237] Iteration 54150, loss = 1.05388
I0525 16:26:04.359784 23721 solver.cpp:253]     Train net output #0: loss = 1.05388 (* 1 = 1.05388 loss)
I0525 16:26:04.359804 23721 sgd_solver.cpp:106] Iteration 54150, lr = 0.0015
I0525 16:26:13.094485 23721 solver.cpp:237] Iteration 54300, loss = 1.33033
I0525 16:26:13.094667 23721 solver.cpp:253]     Train net output #0: loss = 1.33033 (* 1 = 1.33033 loss)
I0525 16:26:13.094681 23721 sgd_solver.cpp:106] Iteration 54300, lr = 0.0015
I0525 16:26:21.822099 23721 solver.cpp:237] Iteration 54450, loss = 1.0568
I0525 16:26:21.822134 23721 solver.cpp:253]     Train net output #0: loss = 1.0568 (* 1 = 1.0568 loss)
I0525 16:26:21.822150 23721 sgd_solver.cpp:106] Iteration 54450, lr = 0.0015
I0525 16:26:30.558471 23721 solver.cpp:237] Iteration 54600, loss = 0.913818
I0525 16:26:30.558517 23721 solver.cpp:253]     Train net output #0: loss = 0.913818 (* 1 = 0.913818 loss)
I0525 16:26:30.558536 23721 sgd_solver.cpp:106] Iteration 54600, lr = 0.0015
I0525 16:26:39.286593 23721 solver.cpp:237] Iteration 54750, loss = 1.43222
I0525 16:26:39.286633 23721 solver.cpp:253]     Train net output #0: loss = 1.43222 (* 1 = 1.43222 loss)
I0525 16:26:39.286650 23721 sgd_solver.cpp:106] Iteration 54750, lr = 0.0015
I0525 16:26:48.020382 23721 solver.cpp:237] Iteration 54900, loss = 1.19373
I0525 16:26:48.020563 23721 solver.cpp:253]     Train net output #0: loss = 1.19373 (* 1 = 1.19373 loss)
I0525 16:26:48.020577 23721 sgd_solver.cpp:106] Iteration 54900, lr = 0.0015
I0525 16:27:17.560147 23721 solver.cpp:237] Iteration 55050, loss = 1.23785
I0525 16:27:17.560196 23721 solver.cpp:253]     Train net output #0: loss = 1.23785 (* 1 = 1.23785 loss)
I0525 16:27:17.560212 23721 sgd_solver.cpp:106] Iteration 55050, lr = 0.0015
I0525 16:27:26.289371 23721 solver.cpp:237] Iteration 55200, loss = 1.24021
I0525 16:27:26.289546 23721 solver.cpp:253]     Train net output #0: loss = 1.24021 (* 1 = 1.24021 loss)
I0525 16:27:26.289559 23721 sgd_solver.cpp:106] Iteration 55200, lr = 0.0015
I0525 16:27:35.019850 23721 solver.cpp:237] Iteration 55350, loss = 1.10406
I0525 16:27:35.019886 23721 solver.cpp:253]     Train net output #0: loss = 1.10406 (* 1 = 1.10406 loss)
I0525 16:27:35.019902 23721 sgd_solver.cpp:106] Iteration 55350, lr = 0.0015
I0525 16:27:43.694520 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_55500.caffemodel
I0525 16:27:43.773522 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_55500.solverstate
I0525 16:27:43.817150 23721 solver.cpp:237] Iteration 55500, loss = 1.12757
I0525 16:27:43.817195 23721 solver.cpp:253]     Train net output #0: loss = 1.12757 (* 1 = 1.12757 loss)
I0525 16:27:43.817209 23721 sgd_solver.cpp:106] Iteration 55500, lr = 0.0015
I0525 16:27:52.544708 23721 solver.cpp:237] Iteration 55650, loss = 1.4375
I0525 16:27:52.544744 23721 solver.cpp:253]     Train net output #0: loss = 1.4375 (* 1 = 1.4375 loss)
I0525 16:27:52.544759 23721 sgd_solver.cpp:106] Iteration 55650, lr = 0.0015
I0525 16:28:01.277868 23721 solver.cpp:237] Iteration 55800, loss = 1.10661
I0525 16:28:01.278041 23721 solver.cpp:253]     Train net output #0: loss = 1.10661 (* 1 = 1.10661 loss)
I0525 16:28:01.278055 23721 sgd_solver.cpp:106] Iteration 55800, lr = 0.0015
I0525 16:28:10.010298 23721 solver.cpp:237] Iteration 55950, loss = 1.26104
I0525 16:28:10.010341 23721 solver.cpp:253]     Train net output #0: loss = 1.26104 (* 1 = 1.26104 loss)
I0525 16:28:10.010357 23721 sgd_solver.cpp:106] Iteration 55950, lr = 0.0015
I0525 16:28:39.561403 23721 solver.cpp:237] Iteration 56100, loss = 1.00157
I0525 16:28:39.561594 23721 solver.cpp:253]     Train net output #0: loss = 1.00157 (* 1 = 1.00157 loss)
I0525 16:28:39.561609 23721 sgd_solver.cpp:106] Iteration 56100, lr = 0.0015
I0525 16:28:48.293628 23721 solver.cpp:237] Iteration 56250, loss = 1.19476
I0525 16:28:48.293663 23721 solver.cpp:253]     Train net output #0: loss = 1.19476 (* 1 = 1.19476 loss)
I0525 16:28:48.293679 23721 sgd_solver.cpp:106] Iteration 56250, lr = 0.0015
I0525 16:28:57.022527 23721 solver.cpp:237] Iteration 56400, loss = 1.13823
I0525 16:28:57.022569 23721 solver.cpp:253]     Train net output #0: loss = 1.13823 (* 1 = 1.13823 loss)
I0525 16:28:57.022588 23721 sgd_solver.cpp:106] Iteration 56400, lr = 0.0015
I0525 16:29:05.749076 23721 solver.cpp:237] Iteration 56550, loss = 1.10422
I0525 16:29:05.749112 23721 solver.cpp:253]     Train net output #0: loss = 1.10422 (* 1 = 1.10422 loss)
I0525 16:29:05.749128 23721 sgd_solver.cpp:106] Iteration 56550, lr = 0.0015
I0525 16:29:14.478483 23721 solver.cpp:237] Iteration 56700, loss = 1.21915
I0525 16:29:14.478685 23721 solver.cpp:253]     Train net output #0: loss = 1.21915 (* 1 = 1.21915 loss)
I0525 16:29:14.478698 23721 sgd_solver.cpp:106] Iteration 56700, lr = 0.0015
I0525 16:29:23.203784 23721 solver.cpp:237] Iteration 56850, loss = 1.28395
I0525 16:29:23.203830 23721 solver.cpp:253]     Train net output #0: loss = 1.28395 (* 1 = 1.28395 loss)
I0525 16:29:23.203846 23721 sgd_solver.cpp:106] Iteration 56850, lr = 0.0015
I0525 16:29:31.878074 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_57000.caffemodel
I0525 16:29:31.957911 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_57000.solverstate
I0525 16:29:31.983507 23721 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 16:30:18.503096 23721 solver.cpp:409]     Test net output #0: accuracy = 0.878581
I0525 16:30:18.503289 23721 solver.cpp:409]     Test net output #1: loss = 0.383957 (* 1 = 0.383957 loss)
I0525 16:30:39.359251 23721 solver.cpp:237] Iteration 57000, loss = 1.26759
I0525 16:30:39.359304 23721 solver.cpp:253]     Train net output #0: loss = 1.26759 (* 1 = 1.26759 loss)
I0525 16:30:39.359320 23721 sgd_solver.cpp:106] Iteration 57000, lr = 0.0015
I0525 16:30:48.093395 23721 solver.cpp:237] Iteration 57150, loss = 1.19075
I0525 16:30:48.093430 23721 solver.cpp:253]     Train net output #0: loss = 1.19075 (* 1 = 1.19075 loss)
I0525 16:30:48.093444 23721 sgd_solver.cpp:106] Iteration 57150, lr = 0.0015
I0525 16:30:56.828598 23721 solver.cpp:237] Iteration 57300, loss = 1.17104
I0525 16:30:56.828776 23721 solver.cpp:253]     Train net output #0: loss = 1.17104 (* 1 = 1.17104 loss)
I0525 16:30:56.828790 23721 sgd_solver.cpp:106] Iteration 57300, lr = 0.0015
I0525 16:31:05.561882 23721 solver.cpp:237] Iteration 57450, loss = 1.32982
I0525 16:31:05.561924 23721 solver.cpp:253]     Train net output #0: loss = 1.32982 (* 1 = 1.32982 loss)
I0525 16:31:05.561940 23721 sgd_solver.cpp:106] Iteration 57450, lr = 0.0015
I0525 16:31:14.300933 23721 solver.cpp:237] Iteration 57600, loss = 1.28951
I0525 16:31:14.300969 23721 solver.cpp:253]     Train net output #0: loss = 1.28951 (* 1 = 1.28951 loss)
I0525 16:31:14.300983 23721 sgd_solver.cpp:106] Iteration 57600, lr = 0.0015
I0525 16:31:23.037497 23721 solver.cpp:237] Iteration 57750, loss = 1.18107
I0525 16:31:23.037533 23721 solver.cpp:253]     Train net output #0: loss = 1.18107 (* 1 = 1.18107 loss)
I0525 16:31:23.037544 23721 sgd_solver.cpp:106] Iteration 57750, lr = 0.0015
I0525 16:31:31.766065 23721 solver.cpp:237] Iteration 57900, loss = 1.07579
I0525 16:31:31.766250 23721 solver.cpp:253]     Train net output #0: loss = 1.07579 (* 1 = 1.07579 loss)
I0525 16:31:31.766264 23721 sgd_solver.cpp:106] Iteration 57900, lr = 0.0015
I0525 16:32:01.382369 23721 solver.cpp:237] Iteration 58050, loss = 1.28079
I0525 16:32:01.382417 23721 solver.cpp:253]     Train net output #0: loss = 1.28079 (* 1 = 1.28079 loss)
I0525 16:32:01.382436 23721 sgd_solver.cpp:106] Iteration 58050, lr = 0.0015
I0525 16:32:10.115725 23721 solver.cpp:237] Iteration 58200, loss = 1.20051
I0525 16:32:10.115917 23721 solver.cpp:253]     Train net output #0: loss = 1.20051 (* 1 = 1.20051 loss)
I0525 16:32:10.115931 23721 sgd_solver.cpp:106] Iteration 58200, lr = 0.0015
I0525 16:32:18.852213 23721 solver.cpp:237] Iteration 58350, loss = 1.14689
I0525 16:32:18.852258 23721 solver.cpp:253]     Train net output #0: loss = 1.14689 (* 1 = 1.14689 loss)
I0525 16:32:18.852272 23721 sgd_solver.cpp:106] Iteration 58350, lr = 0.0015
I0525 16:32:27.535183 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_58500.caffemodel
I0525 16:32:27.614508 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_58500.solverstate
I0525 16:32:27.658905 23721 solver.cpp:237] Iteration 58500, loss = 1.47612
I0525 16:32:27.658949 23721 solver.cpp:253]     Train net output #0: loss = 1.47612 (* 1 = 1.47612 loss)
I0525 16:32:27.658967 23721 sgd_solver.cpp:106] Iteration 58500, lr = 0.0015
I0525 16:32:36.398008 23721 solver.cpp:237] Iteration 58650, loss = 0.992264
I0525 16:32:36.398043 23721 solver.cpp:253]     Train net output #0: loss = 0.992264 (* 1 = 0.992264 loss)
I0525 16:32:36.398057 23721 sgd_solver.cpp:106] Iteration 58650, lr = 0.0015
I0525 16:32:45.134009 23721 solver.cpp:237] Iteration 58800, loss = 1.27521
I0525 16:32:45.134223 23721 solver.cpp:253]     Train net output #0: loss = 1.27521 (* 1 = 1.27521 loss)
I0525 16:32:45.134238 23721 sgd_solver.cpp:106] Iteration 58800, lr = 0.0015
I0525 16:32:53.873263 23721 solver.cpp:237] Iteration 58950, loss = 1.18415
I0525 16:32:53.873301 23721 solver.cpp:253]     Train net output #0: loss = 1.18415 (* 1 = 1.18415 loss)
I0525 16:32:53.873314 23721 sgd_solver.cpp:106] Iteration 58950, lr = 0.0015
I0525 16:33:23.478034 23721 solver.cpp:237] Iteration 59100, loss = 1.15542
I0525 16:33:23.478229 23721 solver.cpp:253]     Train net output #0: loss = 1.15542 (* 1 = 1.15542 loss)
I0525 16:33:23.478243 23721 sgd_solver.cpp:106] Iteration 59100, lr = 0.0015
I0525 16:33:32.210177 23721 solver.cpp:237] Iteration 59250, loss = 1.23408
I0525 16:33:32.210214 23721 solver.cpp:253]     Train net output #0: loss = 1.23408 (* 1 = 1.23408 loss)
I0525 16:33:32.210235 23721 sgd_solver.cpp:106] Iteration 59250, lr = 0.0015
I0525 16:33:40.943585 23721 solver.cpp:237] Iteration 59400, loss = 1.04451
I0525 16:33:40.943620 23721 solver.cpp:253]     Train net output #0: loss = 1.04451 (* 1 = 1.04451 loss)
I0525 16:33:40.943634 23721 sgd_solver.cpp:106] Iteration 59400, lr = 0.0015
I0525 16:33:49.681371 23721 solver.cpp:237] Iteration 59550, loss = 1.48105
I0525 16:33:49.681406 23721 solver.cpp:253]     Train net output #0: loss = 1.48105 (* 1 = 1.48105 loss)
I0525 16:33:49.681423 23721 sgd_solver.cpp:106] Iteration 59550, lr = 0.0015
I0525 16:33:58.417871 23721 solver.cpp:237] Iteration 59700, loss = 1.23779
I0525 16:33:58.418056 23721 solver.cpp:253]     Train net output #0: loss = 1.23779 (* 1 = 1.23779 loss)
I0525 16:33:58.418071 23721 sgd_solver.cpp:106] Iteration 59700, lr = 0.0015
I0525 16:34:07.147445 23721 solver.cpp:237] Iteration 59850, loss = 1.31834
I0525 16:34:07.147480 23721 solver.cpp:253]     Train net output #0: loss = 1.31834 (* 1 = 1.31834 loss)
I0525 16:34:07.147497 23721 sgd_solver.cpp:106] Iteration 59850, lr = 0.0015
I0525 16:34:15.821440 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_60000.caffemodel
I0525 16:34:15.902297 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_60000.solverstate
I0525 16:34:15.930447 23721 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 16:35:23.698417 23721 solver.cpp:409]     Test net output #0: accuracy = 0.879587
I0525 16:35:23.698616 23721 solver.cpp:409]     Test net output #1: loss = 0.384486 (* 1 = 0.384486 loss)
I0525 16:35:44.572479 23721 solver.cpp:237] Iteration 60000, loss = 1.19892
I0525 16:35:44.572532 23721 solver.cpp:253]     Train net output #0: loss = 1.19892 (* 1 = 1.19892 loss)
I0525 16:35:44.572546 23721 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0525 16:35:53.296363 23721 solver.cpp:237] Iteration 60150, loss = 1.06416
I0525 16:35:53.296399 23721 solver.cpp:253]     Train net output #0: loss = 1.06416 (* 1 = 1.06416 loss)
I0525 16:35:53.296416 23721 sgd_solver.cpp:106] Iteration 60150, lr = 0.0015
I0525 16:36:02.018957 23721 solver.cpp:237] Iteration 60300, loss = 1.31574
I0525 16:36:02.019155 23721 solver.cpp:253]     Train net output #0: loss = 1.31574 (* 1 = 1.31574 loss)
I0525 16:36:02.019170 23721 sgd_solver.cpp:106] Iteration 60300, lr = 0.0015
I0525 16:36:10.744273 23721 solver.cpp:237] Iteration 60450, loss = 1.05796
I0525 16:36:10.744307 23721 solver.cpp:253]     Train net output #0: loss = 1.05796 (* 1 = 1.05796 loss)
I0525 16:36:10.744324 23721 sgd_solver.cpp:106] Iteration 60450, lr = 0.0015
I0525 16:36:19.473927 23721 solver.cpp:237] Iteration 60600, loss = 1.1098
I0525 16:36:19.473961 23721 solver.cpp:253]     Train net output #0: loss = 1.1098 (* 1 = 1.1098 loss)
I0525 16:36:19.473975 23721 sgd_solver.cpp:106] Iteration 60600, lr = 0.0015
I0525 16:36:28.199389 23721 solver.cpp:237] Iteration 60750, loss = 1.28431
I0525 16:36:28.199436 23721 solver.cpp:253]     Train net output #0: loss = 1.28431 (* 1 = 1.28431 loss)
I0525 16:36:28.199450 23721 sgd_solver.cpp:106] Iteration 60750, lr = 0.0015
I0525 16:36:36.929499 23721 solver.cpp:237] Iteration 60900, loss = 1.32688
I0525 16:36:36.929677 23721 solver.cpp:253]     Train net output #0: loss = 1.32688 (* 1 = 1.32688 loss)
I0525 16:36:36.929690 23721 sgd_solver.cpp:106] Iteration 60900, lr = 0.0015
I0525 16:37:06.502269 23721 solver.cpp:237] Iteration 61050, loss = 1.19845
I0525 16:37:06.502317 23721 solver.cpp:253]     Train net output #0: loss = 1.19845 (* 1 = 1.19845 loss)
I0525 16:37:06.502334 23721 sgd_solver.cpp:106] Iteration 61050, lr = 0.0015
I0525 16:37:15.226073 23721 solver.cpp:237] Iteration 61200, loss = 0.942922
I0525 16:37:15.226263 23721 solver.cpp:253]     Train net output #0: loss = 0.942922 (* 1 = 0.942922 loss)
I0525 16:37:15.226276 23721 sgd_solver.cpp:106] Iteration 61200, lr = 0.0015
I0525 16:37:23.943847 23721 solver.cpp:237] Iteration 61350, loss = 1.42533
I0525 16:37:23.943881 23721 solver.cpp:253]     Train net output #0: loss = 1.42533 (* 1 = 1.42533 loss)
I0525 16:37:23.943895 23721 sgd_solver.cpp:106] Iteration 61350, lr = 0.0015
I0525 16:37:32.608366 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_61500.caffemodel
I0525 16:37:32.686970 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_61500.solverstate
I0525 16:37:32.730806 23721 solver.cpp:237] Iteration 61500, loss = 1.15941
I0525 16:37:32.730851 23721 solver.cpp:253]     Train net output #0: loss = 1.15941 (* 1 = 1.15941 loss)
I0525 16:37:32.730865 23721 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0525 16:37:41.451982 23721 solver.cpp:237] Iteration 61650, loss = 1.3517
I0525 16:37:41.452024 23721 solver.cpp:253]     Train net output #0: loss = 1.3517 (* 1 = 1.3517 loss)
I0525 16:37:41.452044 23721 sgd_solver.cpp:106] Iteration 61650, lr = 0.0015
I0525 16:37:50.171447 23721 solver.cpp:237] Iteration 61800, loss = 1.12883
I0525 16:37:50.171625 23721 solver.cpp:253]     Train net output #0: loss = 1.12883 (* 1 = 1.12883 loss)
I0525 16:37:50.171639 23721 sgd_solver.cpp:106] Iteration 61800, lr = 0.0015
I0525 16:37:58.892467 23721 solver.cpp:237] Iteration 61950, loss = 1.20244
I0525 16:37:58.892501 23721 solver.cpp:253]     Train net output #0: loss = 1.20244 (* 1 = 1.20244 loss)
I0525 16:37:58.892518 23721 sgd_solver.cpp:106] Iteration 61950, lr = 0.0015
I0525 16:38:28.417690 23721 solver.cpp:237] Iteration 62100, loss = 0.997681
I0525 16:38:28.417887 23721 solver.cpp:253]     Train net output #0: loss = 0.997681 (* 1 = 0.997681 loss)
I0525 16:38:28.417901 23721 sgd_solver.cpp:106] Iteration 62100, lr = 0.0015
I0525 16:38:37.140344 23721 solver.cpp:237] Iteration 62250, loss = 1.13003
I0525 16:38:37.140380 23721 solver.cpp:253]     Train net output #0: loss = 1.13003 (* 1 = 1.13003 loss)
I0525 16:38:37.140401 23721 sgd_solver.cpp:106] Iteration 62250, lr = 0.0015
I0525 16:38:45.861016 23721 solver.cpp:237] Iteration 62400, loss = 1.09955
I0525 16:38:45.861052 23721 solver.cpp:253]     Train net output #0: loss = 1.09955 (* 1 = 1.09955 loss)
I0525 16:38:45.861068 23721 sgd_solver.cpp:106] Iteration 62400, lr = 0.0015
I0525 16:38:54.585947 23721 solver.cpp:237] Iteration 62550, loss = 1.03367
I0525 16:38:54.585996 23721 solver.cpp:253]     Train net output #0: loss = 1.03367 (* 1 = 1.03367 loss)
I0525 16:38:54.586014 23721 sgd_solver.cpp:106] Iteration 62550, lr = 0.0015
I0525 16:39:03.308743 23721 solver.cpp:237] Iteration 62700, loss = 1.22155
I0525 16:39:03.308907 23721 solver.cpp:253]     Train net output #0: loss = 1.22155 (* 1 = 1.22155 loss)
I0525 16:39:03.308922 23721 sgd_solver.cpp:106] Iteration 62700, lr = 0.0015
I0525 16:39:12.038269 23721 solver.cpp:237] Iteration 62850, loss = 1.29581
I0525 16:39:12.038303 23721 solver.cpp:253]     Train net output #0: loss = 1.29581 (* 1 = 1.29581 loss)
I0525 16:39:12.038321 23721 sgd_solver.cpp:106] Iteration 62850, lr = 0.0015
I0525 16:39:20.705322 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_63000.caffemodel
I0525 16:39:20.784019 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_63000.solverstate
I0525 16:39:20.809959 23721 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 16:40:07.654350 23721 solver.cpp:409]     Test net output #0: accuracy = 0.878508
I0525 16:40:07.654547 23721 solver.cpp:409]     Test net output #1: loss = 0.388467 (* 1 = 0.388467 loss)
I0525 16:40:28.471748 23721 solver.cpp:237] Iteration 63000, loss = 1.17201
I0525 16:40:28.471801 23721 solver.cpp:253]     Train net output #0: loss = 1.17201 (* 1 = 1.17201 loss)
I0525 16:40:28.471817 23721 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0525 16:40:37.209852 23721 solver.cpp:237] Iteration 63150, loss = 1.17709
I0525 16:40:37.209898 23721 solver.cpp:253]     Train net output #0: loss = 1.17709 (* 1 = 1.17709 loss)
I0525 16:40:37.209913 23721 sgd_solver.cpp:106] Iteration 63150, lr = 0.0015
I0525 16:40:45.946233 23721 solver.cpp:237] Iteration 63300, loss = 1.25203
I0525 16:40:45.946413 23721 solver.cpp:253]     Train net output #0: loss = 1.25203 (* 1 = 1.25203 loss)
I0525 16:40:45.946426 23721 sgd_solver.cpp:106] Iteration 63300, lr = 0.0015
I0525 16:40:54.682371 23721 solver.cpp:237] Iteration 63450, loss = 1.20787
I0525 16:40:54.682405 23721 solver.cpp:253]     Train net output #0: loss = 1.20787 (* 1 = 1.20787 loss)
I0525 16:40:54.682422 23721 sgd_solver.cpp:106] Iteration 63450, lr = 0.0015
I0525 16:41:03.416702 23721 solver.cpp:237] Iteration 63600, loss = 1.18318
I0525 16:41:03.416743 23721 solver.cpp:253]     Train net output #0: loss = 1.18318 (* 1 = 1.18318 loss)
I0525 16:41:03.416759 23721 sgd_solver.cpp:106] Iteration 63600, lr = 0.0015
I0525 16:41:12.151360 23721 solver.cpp:237] Iteration 63750, loss = 1.17523
I0525 16:41:12.151394 23721 solver.cpp:253]     Train net output #0: loss = 1.17523 (* 1 = 1.17523 loss)
I0525 16:41:12.151410 23721 sgd_solver.cpp:106] Iteration 63750, lr = 0.0015
I0525 16:41:20.885179 23721 solver.cpp:237] Iteration 63900, loss = 1.2777
I0525 16:41:20.885351 23721 solver.cpp:253]     Train net output #0: loss = 1.2777 (* 1 = 1.2777 loss)
I0525 16:41:20.885365 23721 sgd_solver.cpp:106] Iteration 63900, lr = 0.0015
I0525 16:41:50.441627 23721 solver.cpp:237] Iteration 64050, loss = 1.26857
I0525 16:41:50.441675 23721 solver.cpp:253]     Train net output #0: loss = 1.26857 (* 1 = 1.26857 loss)
I0525 16:41:50.441694 23721 sgd_solver.cpp:106] Iteration 64050, lr = 0.0015
I0525 16:41:59.178707 23721 solver.cpp:237] Iteration 64200, loss = 1.22371
I0525 16:41:59.178885 23721 solver.cpp:253]     Train net output #0: loss = 1.22371 (* 1 = 1.22371 loss)
I0525 16:41:59.178900 23721 sgd_solver.cpp:106] Iteration 64200, lr = 0.0015
I0525 16:42:07.913265 23721 solver.cpp:237] Iteration 64350, loss = 1.26381
I0525 16:42:07.913300 23721 solver.cpp:253]     Train net output #0: loss = 1.26381 (* 1 = 1.26381 loss)
I0525 16:42:07.913316 23721 sgd_solver.cpp:106] Iteration 64350, lr = 0.0015
I0525 16:42:16.593243 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_64500.caffemodel
I0525 16:42:16.671772 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_64500.solverstate
I0525 16:42:16.715390 23721 solver.cpp:237] Iteration 64500, loss = 1.16463
I0525 16:42:16.715436 23721 solver.cpp:253]     Train net output #0: loss = 1.16463 (* 1 = 1.16463 loss)
I0525 16:42:16.715456 23721 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0525 16:42:25.450984 23721 solver.cpp:237] Iteration 64650, loss = 1.13762
I0525 16:42:25.451019 23721 solver.cpp:253]     Train net output #0: loss = 1.13762 (* 1 = 1.13762 loss)
I0525 16:42:25.451031 23721 sgd_solver.cpp:106] Iteration 64650, lr = 0.0015
I0525 16:42:34.191736 23721 solver.cpp:237] Iteration 64800, loss = 1.2566
I0525 16:42:34.191925 23721 solver.cpp:253]     Train net output #0: loss = 1.2566 (* 1 = 1.2566 loss)
I0525 16:42:34.191937 23721 sgd_solver.cpp:106] Iteration 64800, lr = 0.0015
I0525 16:42:42.922816 23721 solver.cpp:237] Iteration 64950, loss = 1.20952
I0525 16:42:42.922859 23721 solver.cpp:253]     Train net output #0: loss = 1.20952 (* 1 = 1.20952 loss)
I0525 16:42:42.922873 23721 sgd_solver.cpp:106] Iteration 64950, lr = 0.0015
I0525 16:43:12.478572 23721 solver.cpp:237] Iteration 65100, loss = 1.30986
I0525 16:43:12.478776 23721 solver.cpp:253]     Train net output #0: loss = 1.30986 (* 1 = 1.30986 loss)
I0525 16:43:12.478790 23721 sgd_solver.cpp:106] Iteration 65100, lr = 0.0015
I0525 16:43:21.221148 23721 solver.cpp:237] Iteration 65250, loss = 1.13304
I0525 16:43:21.221182 23721 solver.cpp:253]     Train net output #0: loss = 1.13304 (* 1 = 1.13304 loss)
I0525 16:43:21.221199 23721 sgd_solver.cpp:106] Iteration 65250, lr = 0.0015
I0525 16:43:29.955230 23721 solver.cpp:237] Iteration 65400, loss = 1.20021
I0525 16:43:29.955273 23721 solver.cpp:253]     Train net output #0: loss = 1.20021 (* 1 = 1.20021 loss)
I0525 16:43:29.955292 23721 sgd_solver.cpp:106] Iteration 65400, lr = 0.0015
I0525 16:43:38.696243 23721 solver.cpp:237] Iteration 65550, loss = 1.33381
I0525 16:43:38.696277 23721 solver.cpp:253]     Train net output #0: loss = 1.33381 (* 1 = 1.33381 loss)
I0525 16:43:38.696291 23721 sgd_solver.cpp:106] Iteration 65550, lr = 0.0015
I0525 16:43:47.435653 23721 solver.cpp:237] Iteration 65700, loss = 1.18722
I0525 16:43:47.435832 23721 solver.cpp:253]     Train net output #0: loss = 1.18722 (* 1 = 1.18722 loss)
I0525 16:43:47.435844 23721 sgd_solver.cpp:106] Iteration 65700, lr = 0.0015
I0525 16:43:56.167996 23721 solver.cpp:237] Iteration 65850, loss = 1.13375
I0525 16:43:56.168041 23721 solver.cpp:253]     Train net output #0: loss = 1.13375 (* 1 = 1.13375 loss)
I0525 16:43:56.168056 23721 sgd_solver.cpp:106] Iteration 65850, lr = 0.0015
I0525 16:44:04.846930 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_66000.caffemodel
I0525 16:44:04.926723 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_66000.solverstate
I0525 16:44:04.953874 23721 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 16:45:12.608913 23721 solver.cpp:409]     Test net output #0: accuracy = 0.881341
I0525 16:45:12.609118 23721 solver.cpp:409]     Test net output #1: loss = 0.379313 (* 1 = 0.379313 loss)
I0525 16:45:33.472105 23721 solver.cpp:237] Iteration 66000, loss = 1.26316
I0525 16:45:33.472157 23721 solver.cpp:253]     Train net output #0: loss = 1.26316 (* 1 = 1.26316 loss)
I0525 16:45:33.472172 23721 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0525 16:45:42.194382 23721 solver.cpp:237] Iteration 66150, loss = 1.17755
I0525 16:45:42.194421 23721 solver.cpp:253]     Train net output #0: loss = 1.17755 (* 1 = 1.17755 loss)
I0525 16:45:42.194442 23721 sgd_solver.cpp:106] Iteration 66150, lr = 0.0015
I0525 16:45:50.926998 23721 solver.cpp:237] Iteration 66300, loss = 1.17282
I0525 16:45:50.927191 23721 solver.cpp:253]     Train net output #0: loss = 1.17282 (* 1 = 1.17282 loss)
I0525 16:45:50.927204 23721 sgd_solver.cpp:106] Iteration 66300, lr = 0.0015
I0525 16:45:59.652989 23721 solver.cpp:237] Iteration 66450, loss = 1.17503
I0525 16:45:59.653038 23721 solver.cpp:253]     Train net output #0: loss = 1.17503 (* 1 = 1.17503 loss)
I0525 16:45:59.653055 23721 sgd_solver.cpp:106] Iteration 66450, lr = 0.0015
I0525 16:46:08.383630 23721 solver.cpp:237] Iteration 66600, loss = 0.990481
I0525 16:46:08.383666 23721 solver.cpp:253]     Train net output #0: loss = 0.990481 (* 1 = 0.990481 loss)
I0525 16:46:08.383679 23721 sgd_solver.cpp:106] Iteration 66600, lr = 0.0015
I0525 16:46:17.115275 23721 solver.cpp:237] Iteration 66750, loss = 1.20171
I0525 16:46:17.115310 23721 solver.cpp:253]     Train net output #0: loss = 1.20171 (* 1 = 1.20171 loss)
I0525 16:46:17.115326 23721 sgd_solver.cpp:106] Iteration 66750, lr = 0.0015
I0525 16:46:25.839318 23721 solver.cpp:237] Iteration 66900, loss = 1.23255
I0525 16:46:25.839509 23721 solver.cpp:253]     Train net output #0: loss = 1.23255 (* 1 = 1.23255 loss)
I0525 16:46:25.839524 23721 sgd_solver.cpp:106] Iteration 66900, lr = 0.0015
I0525 16:46:55.406626 23721 solver.cpp:237] Iteration 67050, loss = 1.31644
I0525 16:46:55.406675 23721 solver.cpp:253]     Train net output #0: loss = 1.31644 (* 1 = 1.31644 loss)
I0525 16:46:55.406694 23721 sgd_solver.cpp:106] Iteration 67050, lr = 0.0015
I0525 16:47:04.139336 23721 solver.cpp:237] Iteration 67200, loss = 1.05099
I0525 16:47:04.139519 23721 solver.cpp:253]     Train net output #0: loss = 1.05099 (* 1 = 1.05099 loss)
I0525 16:47:04.139533 23721 sgd_solver.cpp:106] Iteration 67200, lr = 0.0015
I0525 16:47:12.867485 23721 solver.cpp:237] Iteration 67350, loss = 0.984961
I0525 16:47:12.867519 23721 solver.cpp:253]     Train net output #0: loss = 0.984961 (* 1 = 0.984961 loss)
I0525 16:47:12.867533 23721 sgd_solver.cpp:106] Iteration 67350, lr = 0.0015
I0525 16:47:21.538884 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_67500.caffemodel
I0525 16:47:21.619479 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_67500.solverstate
I0525 16:47:21.664988 23721 solver.cpp:237] Iteration 67500, loss = 1.3665
I0525 16:47:21.665037 23721 solver.cpp:253]     Train net output #0: loss = 1.3665 (* 1 = 1.3665 loss)
I0525 16:47:21.665050 23721 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0525 16:47:30.394233 23721 solver.cpp:237] Iteration 67650, loss = 1.1775
I0525 16:47:30.394268 23721 solver.cpp:253]     Train net output #0: loss = 1.1775 (* 1 = 1.1775 loss)
I0525 16:47:30.394284 23721 sgd_solver.cpp:106] Iteration 67650, lr = 0.0015
I0525 16:47:39.123080 23721 solver.cpp:237] Iteration 67800, loss = 1.01802
I0525 16:47:39.123263 23721 solver.cpp:253]     Train net output #0: loss = 1.01802 (* 1 = 1.01802 loss)
I0525 16:47:39.123277 23721 sgd_solver.cpp:106] Iteration 67800, lr = 0.0015
I0525 16:47:47.847906 23721 solver.cpp:237] Iteration 67950, loss = 1.06243
I0525 16:47:47.847947 23721 solver.cpp:253]     Train net output #0: loss = 1.06243 (* 1 = 1.06243 loss)
I0525 16:47:47.847965 23721 sgd_solver.cpp:106] Iteration 67950, lr = 0.0015
I0525 16:48:17.411731 23721 solver.cpp:237] Iteration 68100, loss = 1.20698
I0525 16:48:17.411929 23721 solver.cpp:253]     Train net output #0: loss = 1.20698 (* 1 = 1.20698 loss)
I0525 16:48:17.411943 23721 sgd_solver.cpp:106] Iteration 68100, lr = 0.0015
I0525 16:48:26.147243 23721 solver.cpp:237] Iteration 68250, loss = 1.07666
I0525 16:48:26.147276 23721 solver.cpp:253]     Train net output #0: loss = 1.07666 (* 1 = 1.07666 loss)
I0525 16:48:26.147292 23721 sgd_solver.cpp:106] Iteration 68250, lr = 0.0015
I0525 16:48:34.882800 23721 solver.cpp:237] Iteration 68400, loss = 1.15154
I0525 16:48:34.882843 23721 solver.cpp:253]     Train net output #0: loss = 1.15154 (* 1 = 1.15154 loss)
I0525 16:48:34.882856 23721 sgd_solver.cpp:106] Iteration 68400, lr = 0.0015
I0525 16:48:43.617907 23721 solver.cpp:237] Iteration 68550, loss = 1.35536
I0525 16:48:43.617941 23721 solver.cpp:253]     Train net output #0: loss = 1.35536 (* 1 = 1.35536 loss)
I0525 16:48:43.617955 23721 sgd_solver.cpp:106] Iteration 68550, lr = 0.0015
I0525 16:48:52.349243 23721 solver.cpp:237] Iteration 68700, loss = 1.2754
I0525 16:48:52.349443 23721 solver.cpp:253]     Train net output #0: loss = 1.2754 (* 1 = 1.2754 loss)
I0525 16:48:52.349457 23721 sgd_solver.cpp:106] Iteration 68700, lr = 0.0015
I0525 16:49:01.085093 23721 solver.cpp:237] Iteration 68850, loss = 1.04581
I0525 16:49:01.085136 23721 solver.cpp:253]     Train net output #0: loss = 1.04581 (* 1 = 1.04581 loss)
I0525 16:49:01.085155 23721 sgd_solver.cpp:106] Iteration 68850, lr = 0.0015
I0525 16:49:09.761715 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_69000.caffemodel
I0525 16:49:09.841035 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_69000.solverstate
I0525 16:49:09.866590 23721 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 16:49:56.390444 23721 solver.cpp:409]     Test net output #0: accuracy = 0.881308
I0525 16:49:56.390650 23721 solver.cpp:409]     Test net output #1: loss = 0.372768 (* 1 = 0.372768 loss)
I0525 16:50:17.245134 23721 solver.cpp:237] Iteration 69000, loss = 1.24112
I0525 16:50:17.245187 23721 solver.cpp:253]     Train net output #0: loss = 1.24112 (* 1 = 1.24112 loss)
I0525 16:50:17.245201 23721 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0525 16:50:25.973647 23721 solver.cpp:237] Iteration 69150, loss = 1.06405
I0525 16:50:25.973683 23721 solver.cpp:253]     Train net output #0: loss = 1.06405 (* 1 = 1.06405 loss)
I0525 16:50:25.973696 23721 sgd_solver.cpp:106] Iteration 69150, lr = 0.0015
I0525 16:50:34.703606 23721 solver.cpp:237] Iteration 69300, loss = 1.20141
I0525 16:50:34.703800 23721 solver.cpp:253]     Train net output #0: loss = 1.20141 (* 1 = 1.20141 loss)
I0525 16:50:34.703814 23721 sgd_solver.cpp:106] Iteration 69300, lr = 0.0015
I0525 16:50:43.436966 23721 solver.cpp:237] Iteration 69450, loss = 1.22806
I0525 16:50:43.437001 23721 solver.cpp:253]     Train net output #0: loss = 1.22806 (* 1 = 1.22806 loss)
I0525 16:50:43.437021 23721 sgd_solver.cpp:106] Iteration 69450, lr = 0.0015
I0525 16:50:52.178782 23721 solver.cpp:237] Iteration 69600, loss = 1.18703
I0525 16:50:52.178818 23721 solver.cpp:253]     Train net output #0: loss = 1.18703 (* 1 = 1.18703 loss)
I0525 16:50:52.178833 23721 sgd_solver.cpp:106] Iteration 69600, lr = 0.0015
I0525 16:51:00.914443 23721 solver.cpp:237] Iteration 69750, loss = 1.33203
I0525 16:51:00.914489 23721 solver.cpp:253]     Train net output #0: loss = 1.33203 (* 1 = 1.33203 loss)
I0525 16:51:00.914505 23721 sgd_solver.cpp:106] Iteration 69750, lr = 0.0015
I0525 16:51:09.647436 23721 solver.cpp:237] Iteration 69900, loss = 1.0439
I0525 16:51:09.647617 23721 solver.cpp:253]     Train net output #0: loss = 1.0439 (* 1 = 1.0439 loss)
I0525 16:51:09.647630 23721 sgd_solver.cpp:106] Iteration 69900, lr = 0.0015
I0525 16:51:39.233965 23721 solver.cpp:237] Iteration 70050, loss = 1.27472
I0525 16:51:39.234014 23721 solver.cpp:253]     Train net output #0: loss = 1.27472 (* 1 = 1.27472 loss)
I0525 16:51:39.234030 23721 sgd_solver.cpp:106] Iteration 70050, lr = 0.0015
I0525 16:51:47.964957 23721 solver.cpp:237] Iteration 70200, loss = 1.19484
I0525 16:51:47.965148 23721 solver.cpp:253]     Train net output #0: loss = 1.19484 (* 1 = 1.19484 loss)
I0525 16:51:47.965162 23721 sgd_solver.cpp:106] Iteration 70200, lr = 0.0015
I0525 16:51:56.698443 23721 solver.cpp:237] Iteration 70350, loss = 1.09586
I0525 16:51:56.698487 23721 solver.cpp:253]     Train net output #0: loss = 1.09586 (* 1 = 1.09586 loss)
I0525 16:51:56.698504 23721 sgd_solver.cpp:106] Iteration 70350, lr = 0.0015
I0525 16:52:05.378582 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_70500.caffemodel
I0525 16:52:05.466509 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_70500.solverstate
I0525 16:52:05.510030 23721 solver.cpp:237] Iteration 70500, loss = 1.00275
I0525 16:52:05.510074 23721 solver.cpp:253]     Train net output #0: loss = 1.00275 (* 1 = 1.00275 loss)
I0525 16:52:05.510092 23721 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0525 16:52:14.247383 23721 solver.cpp:237] Iteration 70650, loss = 1.22488
I0525 16:52:14.247419 23721 solver.cpp:253]     Train net output #0: loss = 1.22488 (* 1 = 1.22488 loss)
I0525 16:52:14.247434 23721 sgd_solver.cpp:106] Iteration 70650, lr = 0.0015
I0525 16:52:22.975563 23721 solver.cpp:237] Iteration 70800, loss = 1.27494
I0525 16:52:22.975762 23721 solver.cpp:253]     Train net output #0: loss = 1.27494 (* 1 = 1.27494 loss)
I0525 16:52:22.975776 23721 sgd_solver.cpp:106] Iteration 70800, lr = 0.0015
I0525 16:52:31.704396 23721 solver.cpp:237] Iteration 70950, loss = 1.38796
I0525 16:52:31.704429 23721 solver.cpp:253]     Train net output #0: loss = 1.38796 (* 1 = 1.38796 loss)
I0525 16:52:31.704447 23721 sgd_solver.cpp:106] Iteration 70950, lr = 0.0015
I0525 16:53:01.250177 23721 solver.cpp:237] Iteration 71100, loss = 1.24839
I0525 16:53:01.250380 23721 solver.cpp:253]     Train net output #0: loss = 1.24839 (* 1 = 1.24839 loss)
I0525 16:53:01.250396 23721 sgd_solver.cpp:106] Iteration 71100, lr = 0.0015
I0525 16:53:09.979529 23721 solver.cpp:237] Iteration 71250, loss = 1.00339
I0525 16:53:09.979570 23721 solver.cpp:253]     Train net output #0: loss = 1.00339 (* 1 = 1.00339 loss)
I0525 16:53:09.979590 23721 sgd_solver.cpp:106] Iteration 71250, lr = 0.0015
I0525 16:53:18.717397 23721 solver.cpp:237] Iteration 71400, loss = 0.973317
I0525 16:53:18.717434 23721 solver.cpp:253]     Train net output #0: loss = 0.973317 (* 1 = 0.973317 loss)
I0525 16:53:18.717449 23721 sgd_solver.cpp:106] Iteration 71400, lr = 0.0015
I0525 16:53:27.449582 23721 solver.cpp:237] Iteration 71550, loss = 1.24961
I0525 16:53:27.449617 23721 solver.cpp:253]     Train net output #0: loss = 1.24961 (* 1 = 1.24961 loss)
I0525 16:53:27.449633 23721 sgd_solver.cpp:106] Iteration 71550, lr = 0.0015
I0525 16:53:36.182878 23721 solver.cpp:237] Iteration 71700, loss = 1.25637
I0525 16:53:36.183063 23721 solver.cpp:253]     Train net output #0: loss = 1.25637 (* 1 = 1.25637 loss)
I0525 16:53:36.183078 23721 sgd_solver.cpp:106] Iteration 71700, lr = 0.0015
I0525 16:53:44.917251 23721 solver.cpp:237] Iteration 71850, loss = 1.19955
I0525 16:53:44.917285 23721 solver.cpp:253]     Train net output #0: loss = 1.19955 (* 1 = 1.19955 loss)
I0525 16:53:44.917301 23721 sgd_solver.cpp:106] Iteration 71850, lr = 0.0015
I0525 16:53:53.592267 23721 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_72000.caffemodel
I0525 16:53:53.671360 23721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0015_2016-05-20T15.49.24.741074_iter_72000.solverstate
I0525 16:53:53.697793 23721 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 16:55:01.388079 23721 solver.cpp:409]     Test net output #0: accuracy = 0.882548
I0525 16:55:01.388305 23721 solver.cpp:409]     Test net output #1: loss = 0.370752 (* 1 = 0.370752 loss)
I0525 16:55:22.237370 23721 solver.cpp:237] Iteration 72000, loss = 1.36685
I0525 16:55:22.237423 23721 solver.cpp:253]     Train net output #0: loss = 1.36685 (* 1 = 1.36685 loss)
I0525 16:55:22.237439 23721 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0525 16:55:30.964489 23721 solver.cpp:237] Iteration 72150, loss = 1.26905
I0525 16:55:30.964525 23721 solver.cpp:253]     Train net output #0: loss = 1.26905 (* 1 = 1.26905 loss)
I0525 16:55:30.964541 23721 sgd_solver.cpp:106] Iteration 72150, lr = 0.0015
I0525 16:55:39.690445 23721 solver.cpp:237] Iteration 72300, loss = 1.00275
I0525 16:55:39.690647 23721 solver.cpp:253]     Train net output #0: loss = 1.00275 (* 1 = 1.00275 loss)
I0525 16:55:39.690661 23721 sgd_solver.cpp:106] Iteration 72300, lr = 0.0015
I0525 16:55:48.415248 23721 solver.cpp:237] Iteration 72450, loss = 1.17506
I0525 16:55:48.415283 23721 solver.cpp:253]     Train net output #0: loss = 1.17506 (* 1 = 1.17506 loss)
I0525 16:55:48.415297 23721 sgd_solver.cpp:106] Iteration 72450, lr = 0.0015
I0525 16:55:57.138591 23721 solver.cpp:237] Iteration 72600, loss = 1.22912
I0525 16:55:57.138630 23721 solver.cpp:253]     Train net output #0: loss = 1.22912 (* 1 = 1.22912 loss)
I0525 16:55:57.138648 23721 sgd_solver.cpp:106] Iteration 72600, lr = 0.0015
I0525 16:56:05.862838 23721 solver.cpp:237] Iteration 72750, loss = 1.09409
I0525 16:56:05.862881 23721 solver.cpp:253]     Train net output #0: loss = 1.09409 (* 1 = 1.09409 loss)
I0525 16:56:05.862900 23721 sgd_solver.cpp:106] Iteration 72750, lr = 0.0015
aprun: Apid 11264679: Caught signal Terminated, sending to application
*** Aborted at 1464209766 (unix time) try "date -d @1464209766" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x5ca6) received by PID 23721 (TID 0x2aaac746f900) from PID 23718; stack trace: ***
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
=>> PBS: job killed: walltime 7231 exceeded limit 7200
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11264679: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
aprun: Apid 11264679: Caught signal Terminated, sending to application
