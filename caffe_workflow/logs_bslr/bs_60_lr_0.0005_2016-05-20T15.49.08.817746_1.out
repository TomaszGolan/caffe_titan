2808420
I0523 11:56:51.588646  1678 caffe.cpp:184] Using GPUs 0
I0523 11:56:52.015337  1678 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.0005
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746.prototxt"
I0523 11:56:52.017592  1678 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746.prototxt
I0523 11:56:52.033284  1678 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 11:56:52.033344  1678 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 11:56:52.033690  1678 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 11:56:52.033870  1678 layer_factory.hpp:77] Creating layer data_hdf5
I0523 11:56:52.033895  1678 net.cpp:106] Creating Layer data_hdf5
I0523 11:56:52.033910  1678 net.cpp:411] data_hdf5 -> data
I0523 11:56:52.033943  1678 net.cpp:411] data_hdf5 -> label
I0523 11:56:52.033975  1678 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 11:56:52.046262  1678 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 11:56:52.060219  1678 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 11:57:13.663441  1678 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 11:57:13.668619  1678 net.cpp:150] Setting up data_hdf5
I0523 11:57:13.668659  1678 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 11:57:13.668673  1678 net.cpp:157] Top shape: 60 (60)
I0523 11:57:13.668686  1678 net.cpp:165] Memory required for data: 1524240
I0523 11:57:13.668700  1678 layer_factory.hpp:77] Creating layer conv1
I0523 11:57:13.668735  1678 net.cpp:106] Creating Layer conv1
I0523 11:57:13.668746  1678 net.cpp:454] conv1 <- data
I0523 11:57:13.668766  1678 net.cpp:411] conv1 -> conv1
I0523 11:57:16.518126  1678 net.cpp:150] Setting up conv1
I0523 11:57:16.518169  1678 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 11:57:16.518182  1678 net.cpp:165] Memory required for data: 18113040
I0523 11:57:16.518213  1678 layer_factory.hpp:77] Creating layer relu1
I0523 11:57:16.518234  1678 net.cpp:106] Creating Layer relu1
I0523 11:57:16.518244  1678 net.cpp:454] relu1 <- conv1
I0523 11:57:16.518257  1678 net.cpp:397] relu1 -> conv1 (in-place)
I0523 11:57:16.518770  1678 net.cpp:150] Setting up relu1
I0523 11:57:16.518786  1678 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 11:57:16.518797  1678 net.cpp:165] Memory required for data: 34701840
I0523 11:57:16.518807  1678 layer_factory.hpp:77] Creating layer pool1
I0523 11:57:16.518823  1678 net.cpp:106] Creating Layer pool1
I0523 11:57:16.518833  1678 net.cpp:454] pool1 <- conv1
I0523 11:57:16.518846  1678 net.cpp:411] pool1 -> pool1
I0523 11:57:16.518925  1678 net.cpp:150] Setting up pool1
I0523 11:57:16.518939  1678 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 11:57:16.518949  1678 net.cpp:165] Memory required for data: 42996240
I0523 11:57:16.518959  1678 layer_factory.hpp:77] Creating layer conv2
I0523 11:57:16.518980  1678 net.cpp:106] Creating Layer conv2
I0523 11:57:16.518990  1678 net.cpp:454] conv2 <- pool1
I0523 11:57:16.519003  1678 net.cpp:411] conv2 -> conv2
I0523 11:57:16.521744  1678 net.cpp:150] Setting up conv2
I0523 11:57:16.521767  1678 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 11:57:16.521777  1678 net.cpp:165] Memory required for data: 54919440
I0523 11:57:16.521797  1678 layer_factory.hpp:77] Creating layer relu2
I0523 11:57:16.521811  1678 net.cpp:106] Creating Layer relu2
I0523 11:57:16.521821  1678 net.cpp:454] relu2 <- conv2
I0523 11:57:16.521833  1678 net.cpp:397] relu2 -> conv2 (in-place)
I0523 11:57:16.522163  1678 net.cpp:150] Setting up relu2
I0523 11:57:16.522178  1678 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 11:57:16.522188  1678 net.cpp:165] Memory required for data: 66842640
I0523 11:57:16.522198  1678 layer_factory.hpp:77] Creating layer pool2
I0523 11:57:16.522212  1678 net.cpp:106] Creating Layer pool2
I0523 11:57:16.522222  1678 net.cpp:454] pool2 <- conv2
I0523 11:57:16.522233  1678 net.cpp:411] pool2 -> pool2
I0523 11:57:16.522315  1678 net.cpp:150] Setting up pool2
I0523 11:57:16.522328  1678 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 11:57:16.522337  1678 net.cpp:165] Memory required for data: 72804240
I0523 11:57:16.522347  1678 layer_factory.hpp:77] Creating layer conv3
I0523 11:57:16.522366  1678 net.cpp:106] Creating Layer conv3
I0523 11:57:16.522375  1678 net.cpp:454] conv3 <- pool2
I0523 11:57:16.522389  1678 net.cpp:411] conv3 -> conv3
I0523 11:57:16.524340  1678 net.cpp:150] Setting up conv3
I0523 11:57:16.524363  1678 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 11:57:16.524376  1678 net.cpp:165] Memory required for data: 79309200
I0523 11:57:16.524395  1678 layer_factory.hpp:77] Creating layer relu3
I0523 11:57:16.524411  1678 net.cpp:106] Creating Layer relu3
I0523 11:57:16.524421  1678 net.cpp:454] relu3 <- conv3
I0523 11:57:16.524433  1678 net.cpp:397] relu3 -> conv3 (in-place)
I0523 11:57:16.524904  1678 net.cpp:150] Setting up relu3
I0523 11:57:16.524920  1678 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 11:57:16.524930  1678 net.cpp:165] Memory required for data: 85814160
I0523 11:57:16.524940  1678 layer_factory.hpp:77] Creating layer pool3
I0523 11:57:16.524953  1678 net.cpp:106] Creating Layer pool3
I0523 11:57:16.524963  1678 net.cpp:454] pool3 <- conv3
I0523 11:57:16.524976  1678 net.cpp:411] pool3 -> pool3
I0523 11:57:16.525043  1678 net.cpp:150] Setting up pool3
I0523 11:57:16.525055  1678 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 11:57:16.525065  1678 net.cpp:165] Memory required for data: 89066640
I0523 11:57:16.525074  1678 layer_factory.hpp:77] Creating layer conv4
I0523 11:57:16.525094  1678 net.cpp:106] Creating Layer conv4
I0523 11:57:16.525105  1678 net.cpp:454] conv4 <- pool3
I0523 11:57:16.525118  1678 net.cpp:411] conv4 -> conv4
I0523 11:57:16.527883  1678 net.cpp:150] Setting up conv4
I0523 11:57:16.527911  1678 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 11:57:16.527921  1678 net.cpp:165] Memory required for data: 91243920
I0523 11:57:16.527937  1678 layer_factory.hpp:77] Creating layer relu4
I0523 11:57:16.527951  1678 net.cpp:106] Creating Layer relu4
I0523 11:57:16.527961  1678 net.cpp:454] relu4 <- conv4
I0523 11:57:16.527974  1678 net.cpp:397] relu4 -> conv4 (in-place)
I0523 11:57:16.528452  1678 net.cpp:150] Setting up relu4
I0523 11:57:16.528468  1678 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 11:57:16.528480  1678 net.cpp:165] Memory required for data: 93421200
I0523 11:57:16.528489  1678 layer_factory.hpp:77] Creating layer pool4
I0523 11:57:16.528502  1678 net.cpp:106] Creating Layer pool4
I0523 11:57:16.528512  1678 net.cpp:454] pool4 <- conv4
I0523 11:57:16.528524  1678 net.cpp:411] pool4 -> pool4
I0523 11:57:16.528592  1678 net.cpp:150] Setting up pool4
I0523 11:57:16.528606  1678 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 11:57:16.528616  1678 net.cpp:165] Memory required for data: 94509840
I0523 11:57:16.528626  1678 layer_factory.hpp:77] Creating layer ip1
I0523 11:57:16.528646  1678 net.cpp:106] Creating Layer ip1
I0523 11:57:16.528656  1678 net.cpp:454] ip1 <- pool4
I0523 11:57:16.528669  1678 net.cpp:411] ip1 -> ip1
I0523 11:57:16.544026  1678 net.cpp:150] Setting up ip1
I0523 11:57:16.544055  1678 net.cpp:157] Top shape: 60 196 (11760)
I0523 11:57:16.544067  1678 net.cpp:165] Memory required for data: 94556880
I0523 11:57:16.544090  1678 layer_factory.hpp:77] Creating layer relu5
I0523 11:57:16.544105  1678 net.cpp:106] Creating Layer relu5
I0523 11:57:16.544114  1678 net.cpp:454] relu5 <- ip1
I0523 11:57:16.544128  1678 net.cpp:397] relu5 -> ip1 (in-place)
I0523 11:57:16.544471  1678 net.cpp:150] Setting up relu5
I0523 11:57:16.544484  1678 net.cpp:157] Top shape: 60 196 (11760)
I0523 11:57:16.544495  1678 net.cpp:165] Memory required for data: 94603920
I0523 11:57:16.544505  1678 layer_factory.hpp:77] Creating layer drop1
I0523 11:57:16.544528  1678 net.cpp:106] Creating Layer drop1
I0523 11:57:16.544538  1678 net.cpp:454] drop1 <- ip1
I0523 11:57:16.544549  1678 net.cpp:397] drop1 -> ip1 (in-place)
I0523 11:57:16.544610  1678 net.cpp:150] Setting up drop1
I0523 11:57:16.544625  1678 net.cpp:157] Top shape: 60 196 (11760)
I0523 11:57:16.544634  1678 net.cpp:165] Memory required for data: 94650960
I0523 11:57:16.544644  1678 layer_factory.hpp:77] Creating layer ip2
I0523 11:57:16.544662  1678 net.cpp:106] Creating Layer ip2
I0523 11:57:16.544672  1678 net.cpp:454] ip2 <- ip1
I0523 11:57:16.544685  1678 net.cpp:411] ip2 -> ip2
I0523 11:57:16.545148  1678 net.cpp:150] Setting up ip2
I0523 11:57:16.545161  1678 net.cpp:157] Top shape: 60 98 (5880)
I0523 11:57:16.545171  1678 net.cpp:165] Memory required for data: 94674480
I0523 11:57:16.545192  1678 layer_factory.hpp:77] Creating layer relu6
I0523 11:57:16.545205  1678 net.cpp:106] Creating Layer relu6
I0523 11:57:16.545217  1678 net.cpp:454] relu6 <- ip2
I0523 11:57:16.545228  1678 net.cpp:397] relu6 -> ip2 (in-place)
I0523 11:57:16.545739  1678 net.cpp:150] Setting up relu6
I0523 11:57:16.545756  1678 net.cpp:157] Top shape: 60 98 (5880)
I0523 11:57:16.545766  1678 net.cpp:165] Memory required for data: 94698000
I0523 11:57:16.545778  1678 layer_factory.hpp:77] Creating layer drop2
I0523 11:57:16.545791  1678 net.cpp:106] Creating Layer drop2
I0523 11:57:16.545801  1678 net.cpp:454] drop2 <- ip2
I0523 11:57:16.545814  1678 net.cpp:397] drop2 -> ip2 (in-place)
I0523 11:57:16.545856  1678 net.cpp:150] Setting up drop2
I0523 11:57:16.545871  1678 net.cpp:157] Top shape: 60 98 (5880)
I0523 11:57:16.545881  1678 net.cpp:165] Memory required for data: 94721520
I0523 11:57:16.545891  1678 layer_factory.hpp:77] Creating layer ip3
I0523 11:57:16.545903  1678 net.cpp:106] Creating Layer ip3
I0523 11:57:16.545913  1678 net.cpp:454] ip3 <- ip2
I0523 11:57:16.545925  1678 net.cpp:411] ip3 -> ip3
I0523 11:57:16.546136  1678 net.cpp:150] Setting up ip3
I0523 11:57:16.546149  1678 net.cpp:157] Top shape: 60 11 (660)
I0523 11:57:16.546159  1678 net.cpp:165] Memory required for data: 94724160
I0523 11:57:16.546175  1678 layer_factory.hpp:77] Creating layer drop3
I0523 11:57:16.546186  1678 net.cpp:106] Creating Layer drop3
I0523 11:57:16.546196  1678 net.cpp:454] drop3 <- ip3
I0523 11:57:16.546207  1678 net.cpp:397] drop3 -> ip3 (in-place)
I0523 11:57:16.546247  1678 net.cpp:150] Setting up drop3
I0523 11:57:16.546259  1678 net.cpp:157] Top shape: 60 11 (660)
I0523 11:57:16.546269  1678 net.cpp:165] Memory required for data: 94726800
I0523 11:57:16.546279  1678 layer_factory.hpp:77] Creating layer loss
I0523 11:57:16.546298  1678 net.cpp:106] Creating Layer loss
I0523 11:57:16.546308  1678 net.cpp:454] loss <- ip3
I0523 11:57:16.546319  1678 net.cpp:454] loss <- label
I0523 11:57:16.546331  1678 net.cpp:411] loss -> loss
I0523 11:57:16.546350  1678 layer_factory.hpp:77] Creating layer loss
I0523 11:57:16.546994  1678 net.cpp:150] Setting up loss
I0523 11:57:16.547015  1678 net.cpp:157] Top shape: (1)
I0523 11:57:16.547029  1678 net.cpp:160]     with loss weight 1
I0523 11:57:16.547071  1678 net.cpp:165] Memory required for data: 94726804
I0523 11:57:16.547081  1678 net.cpp:226] loss needs backward computation.
I0523 11:57:16.547092  1678 net.cpp:226] drop3 needs backward computation.
I0523 11:57:16.547102  1678 net.cpp:226] ip3 needs backward computation.
I0523 11:57:16.547112  1678 net.cpp:226] drop2 needs backward computation.
I0523 11:57:16.547122  1678 net.cpp:226] relu6 needs backward computation.
I0523 11:57:16.547132  1678 net.cpp:226] ip2 needs backward computation.
I0523 11:57:16.547142  1678 net.cpp:226] drop1 needs backward computation.
I0523 11:57:16.547152  1678 net.cpp:226] relu5 needs backward computation.
I0523 11:57:16.547161  1678 net.cpp:226] ip1 needs backward computation.
I0523 11:57:16.547171  1678 net.cpp:226] pool4 needs backward computation.
I0523 11:57:16.547183  1678 net.cpp:226] relu4 needs backward computation.
I0523 11:57:16.547193  1678 net.cpp:226] conv4 needs backward computation.
I0523 11:57:16.547202  1678 net.cpp:226] pool3 needs backward computation.
I0523 11:57:16.547212  1678 net.cpp:226] relu3 needs backward computation.
I0523 11:57:16.547222  1678 net.cpp:226] conv3 needs backward computation.
I0523 11:57:16.547241  1678 net.cpp:226] pool2 needs backward computation.
I0523 11:57:16.547253  1678 net.cpp:226] relu2 needs backward computation.
I0523 11:57:16.547263  1678 net.cpp:226] conv2 needs backward computation.
I0523 11:57:16.547273  1678 net.cpp:226] pool1 needs backward computation.
I0523 11:57:16.547284  1678 net.cpp:226] relu1 needs backward computation.
I0523 11:57:16.547294  1678 net.cpp:226] conv1 needs backward computation.
I0523 11:57:16.547305  1678 net.cpp:228] data_hdf5 does not need backward computation.
I0523 11:57:16.547314  1678 net.cpp:270] This network produces output loss
I0523 11:57:16.547338  1678 net.cpp:283] Network initialization done.
I0523 11:57:16.549072  1678 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746.prototxt
I0523 11:57:16.549144  1678 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 11:57:16.549499  1678 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 11:57:16.549687  1678 layer_factory.hpp:77] Creating layer data_hdf5
I0523 11:57:16.549703  1678 net.cpp:106] Creating Layer data_hdf5
I0523 11:57:16.549715  1678 net.cpp:411] data_hdf5 -> data
I0523 11:57:16.549732  1678 net.cpp:411] data_hdf5 -> label
I0523 11:57:16.549748  1678 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 11:57:16.557667  1678 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 11:57:37.970237  1678 net.cpp:150] Setting up data_hdf5
I0523 11:57:37.970402  1678 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 11:57:37.970415  1678 net.cpp:157] Top shape: 60 (60)
I0523 11:57:37.970427  1678 net.cpp:165] Memory required for data: 1524240
I0523 11:57:37.970440  1678 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 11:57:37.970468  1678 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 11:57:37.970479  1678 net.cpp:454] label_data_hdf5_1_split <- label
I0523 11:57:37.970494  1678 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 11:57:37.970515  1678 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 11:57:37.970588  1678 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 11:57:37.970602  1678 net.cpp:157] Top shape: 60 (60)
I0523 11:57:37.970613  1678 net.cpp:157] Top shape: 60 (60)
I0523 11:57:37.970623  1678 net.cpp:165] Memory required for data: 1524720
I0523 11:57:37.970633  1678 layer_factory.hpp:77] Creating layer conv1
I0523 11:57:37.970654  1678 net.cpp:106] Creating Layer conv1
I0523 11:57:37.970664  1678 net.cpp:454] conv1 <- data
I0523 11:57:37.970679  1678 net.cpp:411] conv1 -> conv1
I0523 11:57:37.972599  1678 net.cpp:150] Setting up conv1
I0523 11:57:37.972625  1678 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 11:57:37.972635  1678 net.cpp:165] Memory required for data: 18113520
I0523 11:57:37.972656  1678 layer_factory.hpp:77] Creating layer relu1
I0523 11:57:37.972671  1678 net.cpp:106] Creating Layer relu1
I0523 11:57:37.972681  1678 net.cpp:454] relu1 <- conv1
I0523 11:57:37.972693  1678 net.cpp:397] relu1 -> conv1 (in-place)
I0523 11:57:37.973191  1678 net.cpp:150] Setting up relu1
I0523 11:57:37.973206  1678 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 11:57:37.973217  1678 net.cpp:165] Memory required for data: 34702320
I0523 11:57:37.973227  1678 layer_factory.hpp:77] Creating layer pool1
I0523 11:57:37.973243  1678 net.cpp:106] Creating Layer pool1
I0523 11:57:37.973253  1678 net.cpp:454] pool1 <- conv1
I0523 11:57:37.973266  1678 net.cpp:411] pool1 -> pool1
I0523 11:57:37.973340  1678 net.cpp:150] Setting up pool1
I0523 11:57:37.973353  1678 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 11:57:37.973363  1678 net.cpp:165] Memory required for data: 42996720
I0523 11:57:37.973371  1678 layer_factory.hpp:77] Creating layer conv2
I0523 11:57:37.973389  1678 net.cpp:106] Creating Layer conv2
I0523 11:57:37.973399  1678 net.cpp:454] conv2 <- pool1
I0523 11:57:37.973413  1678 net.cpp:411] conv2 -> conv2
I0523 11:57:37.975319  1678 net.cpp:150] Setting up conv2
I0523 11:57:37.975342  1678 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 11:57:37.975354  1678 net.cpp:165] Memory required for data: 54919920
I0523 11:57:37.975371  1678 layer_factory.hpp:77] Creating layer relu2
I0523 11:57:37.975385  1678 net.cpp:106] Creating Layer relu2
I0523 11:57:37.975394  1678 net.cpp:454] relu2 <- conv2
I0523 11:57:37.975407  1678 net.cpp:397] relu2 -> conv2 (in-place)
I0523 11:57:37.975746  1678 net.cpp:150] Setting up relu2
I0523 11:57:37.975759  1678 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 11:57:37.975770  1678 net.cpp:165] Memory required for data: 66843120
I0523 11:57:37.975780  1678 layer_factory.hpp:77] Creating layer pool2
I0523 11:57:37.975793  1678 net.cpp:106] Creating Layer pool2
I0523 11:57:37.975802  1678 net.cpp:454] pool2 <- conv2
I0523 11:57:37.975814  1678 net.cpp:411] pool2 -> pool2
I0523 11:57:37.975888  1678 net.cpp:150] Setting up pool2
I0523 11:57:37.975900  1678 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 11:57:37.975910  1678 net.cpp:165] Memory required for data: 72804720
I0523 11:57:37.975919  1678 layer_factory.hpp:77] Creating layer conv3
I0523 11:57:37.975936  1678 net.cpp:106] Creating Layer conv3
I0523 11:57:37.975947  1678 net.cpp:454] conv3 <- pool2
I0523 11:57:37.975961  1678 net.cpp:411] conv3 -> conv3
I0523 11:57:37.977926  1678 net.cpp:150] Setting up conv3
I0523 11:57:37.977943  1678 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 11:57:37.977954  1678 net.cpp:165] Memory required for data: 79309680
I0523 11:57:37.977987  1678 layer_factory.hpp:77] Creating layer relu3
I0523 11:57:37.977999  1678 net.cpp:106] Creating Layer relu3
I0523 11:57:37.978010  1678 net.cpp:454] relu3 <- conv3
I0523 11:57:37.978023  1678 net.cpp:397] relu3 -> conv3 (in-place)
I0523 11:57:37.978490  1678 net.cpp:150] Setting up relu3
I0523 11:57:37.978507  1678 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 11:57:37.978516  1678 net.cpp:165] Memory required for data: 85814640
I0523 11:57:37.978525  1678 layer_factory.hpp:77] Creating layer pool3
I0523 11:57:37.978538  1678 net.cpp:106] Creating Layer pool3
I0523 11:57:37.978549  1678 net.cpp:454] pool3 <- conv3
I0523 11:57:37.978560  1678 net.cpp:411] pool3 -> pool3
I0523 11:57:37.978632  1678 net.cpp:150] Setting up pool3
I0523 11:57:37.978646  1678 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 11:57:37.978655  1678 net.cpp:165] Memory required for data: 89067120
I0523 11:57:37.978665  1678 layer_factory.hpp:77] Creating layer conv4
I0523 11:57:37.978680  1678 net.cpp:106] Creating Layer conv4
I0523 11:57:37.978690  1678 net.cpp:454] conv4 <- pool3
I0523 11:57:37.978704  1678 net.cpp:411] conv4 -> conv4
I0523 11:57:37.980764  1678 net.cpp:150] Setting up conv4
I0523 11:57:37.980787  1678 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 11:57:37.980799  1678 net.cpp:165] Memory required for data: 91244400
I0523 11:57:37.980815  1678 layer_factory.hpp:77] Creating layer relu4
I0523 11:57:37.980829  1678 net.cpp:106] Creating Layer relu4
I0523 11:57:37.980839  1678 net.cpp:454] relu4 <- conv4
I0523 11:57:37.980851  1678 net.cpp:397] relu4 -> conv4 (in-place)
I0523 11:57:37.981319  1678 net.cpp:150] Setting up relu4
I0523 11:57:37.981336  1678 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 11:57:37.981346  1678 net.cpp:165] Memory required for data: 93421680
I0523 11:57:37.981356  1678 layer_factory.hpp:77] Creating layer pool4
I0523 11:57:37.981369  1678 net.cpp:106] Creating Layer pool4
I0523 11:57:37.981379  1678 net.cpp:454] pool4 <- conv4
I0523 11:57:37.981391  1678 net.cpp:411] pool4 -> pool4
I0523 11:57:37.981463  1678 net.cpp:150] Setting up pool4
I0523 11:57:37.981477  1678 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 11:57:37.981485  1678 net.cpp:165] Memory required for data: 94510320
I0523 11:57:37.981495  1678 layer_factory.hpp:77] Creating layer ip1
I0523 11:57:37.981509  1678 net.cpp:106] Creating Layer ip1
I0523 11:57:37.981519  1678 net.cpp:454] ip1 <- pool4
I0523 11:57:37.981534  1678 net.cpp:411] ip1 -> ip1
I0523 11:57:37.997019  1678 net.cpp:150] Setting up ip1
I0523 11:57:37.997040  1678 net.cpp:157] Top shape: 60 196 (11760)
I0523 11:57:37.997056  1678 net.cpp:165] Memory required for data: 94557360
I0523 11:57:37.997079  1678 layer_factory.hpp:77] Creating layer relu5
I0523 11:57:37.997094  1678 net.cpp:106] Creating Layer relu5
I0523 11:57:37.997105  1678 net.cpp:454] relu5 <- ip1
I0523 11:57:37.997119  1678 net.cpp:397] relu5 -> ip1 (in-place)
I0523 11:57:37.997467  1678 net.cpp:150] Setting up relu5
I0523 11:57:37.997480  1678 net.cpp:157] Top shape: 60 196 (11760)
I0523 11:57:37.997490  1678 net.cpp:165] Memory required for data: 94604400
I0523 11:57:37.997500  1678 layer_factory.hpp:77] Creating layer drop1
I0523 11:57:37.997519  1678 net.cpp:106] Creating Layer drop1
I0523 11:57:37.997529  1678 net.cpp:454] drop1 <- ip1
I0523 11:57:37.997542  1678 net.cpp:397] drop1 -> ip1 (in-place)
I0523 11:57:37.997587  1678 net.cpp:150] Setting up drop1
I0523 11:57:37.997601  1678 net.cpp:157] Top shape: 60 196 (11760)
I0523 11:57:37.997609  1678 net.cpp:165] Memory required for data: 94651440
I0523 11:57:37.997620  1678 layer_factory.hpp:77] Creating layer ip2
I0523 11:57:37.997634  1678 net.cpp:106] Creating Layer ip2
I0523 11:57:37.997644  1678 net.cpp:454] ip2 <- ip1
I0523 11:57:37.997658  1678 net.cpp:411] ip2 -> ip2
I0523 11:57:37.998134  1678 net.cpp:150] Setting up ip2
I0523 11:57:37.998147  1678 net.cpp:157] Top shape: 60 98 (5880)
I0523 11:57:37.998157  1678 net.cpp:165] Memory required for data: 94674960
I0523 11:57:37.998172  1678 layer_factory.hpp:77] Creating layer relu6
I0523 11:57:37.998198  1678 net.cpp:106] Creating Layer relu6
I0523 11:57:37.998208  1678 net.cpp:454] relu6 <- ip2
I0523 11:57:37.998220  1678 net.cpp:397] relu6 -> ip2 (in-place)
I0523 11:57:37.998747  1678 net.cpp:150] Setting up relu6
I0523 11:57:37.998764  1678 net.cpp:157] Top shape: 60 98 (5880)
I0523 11:57:37.998770  1678 net.cpp:165] Memory required for data: 94698480
I0523 11:57:37.998780  1678 layer_factory.hpp:77] Creating layer drop2
I0523 11:57:37.998793  1678 net.cpp:106] Creating Layer drop2
I0523 11:57:37.998805  1678 net.cpp:454] drop2 <- ip2
I0523 11:57:37.998816  1678 net.cpp:397] drop2 -> ip2 (in-place)
I0523 11:57:37.998860  1678 net.cpp:150] Setting up drop2
I0523 11:57:37.998873  1678 net.cpp:157] Top shape: 60 98 (5880)
I0523 11:57:37.998883  1678 net.cpp:165] Memory required for data: 94722000
I0523 11:57:37.998893  1678 layer_factory.hpp:77] Creating layer ip3
I0523 11:57:37.998908  1678 net.cpp:106] Creating Layer ip3
I0523 11:57:37.998917  1678 net.cpp:454] ip3 <- ip2
I0523 11:57:37.998931  1678 net.cpp:411] ip3 -> ip3
I0523 11:57:37.999153  1678 net.cpp:150] Setting up ip3
I0523 11:57:37.999166  1678 net.cpp:157] Top shape: 60 11 (660)
I0523 11:57:37.999176  1678 net.cpp:165] Memory required for data: 94724640
I0523 11:57:37.999191  1678 layer_factory.hpp:77] Creating layer drop3
I0523 11:57:37.999204  1678 net.cpp:106] Creating Layer drop3
I0523 11:57:37.999213  1678 net.cpp:454] drop3 <- ip3
I0523 11:57:37.999227  1678 net.cpp:397] drop3 -> ip3 (in-place)
I0523 11:57:37.999269  1678 net.cpp:150] Setting up drop3
I0523 11:57:37.999280  1678 net.cpp:157] Top shape: 60 11 (660)
I0523 11:57:37.999289  1678 net.cpp:165] Memory required for data: 94727280
I0523 11:57:37.999300  1678 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 11:57:37.999312  1678 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 11:57:37.999322  1678 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 11:57:37.999335  1678 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 11:57:37.999349  1678 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 11:57:37.999423  1678 net.cpp:150] Setting up ip3_drop3_0_split
I0523 11:57:37.999434  1678 net.cpp:157] Top shape: 60 11 (660)
I0523 11:57:37.999447  1678 net.cpp:157] Top shape: 60 11 (660)
I0523 11:57:37.999456  1678 net.cpp:165] Memory required for data: 94732560
I0523 11:57:37.999464  1678 layer_factory.hpp:77] Creating layer accuracy
I0523 11:57:37.999486  1678 net.cpp:106] Creating Layer accuracy
I0523 11:57:37.999496  1678 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 11:57:37.999507  1678 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 11:57:37.999521  1678 net.cpp:411] accuracy -> accuracy
I0523 11:57:37.999544  1678 net.cpp:150] Setting up accuracy
I0523 11:57:37.999557  1678 net.cpp:157] Top shape: (1)
I0523 11:57:37.999567  1678 net.cpp:165] Memory required for data: 94732564
I0523 11:57:37.999575  1678 layer_factory.hpp:77] Creating layer loss
I0523 11:57:37.999589  1678 net.cpp:106] Creating Layer loss
I0523 11:57:37.999599  1678 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 11:57:37.999610  1678 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 11:57:37.999624  1678 net.cpp:411] loss -> loss
I0523 11:57:37.999640  1678 layer_factory.hpp:77] Creating layer loss
I0523 11:57:38.000157  1678 net.cpp:150] Setting up loss
I0523 11:57:38.000171  1678 net.cpp:157] Top shape: (1)
I0523 11:57:38.000181  1678 net.cpp:160]     with loss weight 1
I0523 11:57:38.000200  1678 net.cpp:165] Memory required for data: 94732568
I0523 11:57:38.000211  1678 net.cpp:226] loss needs backward computation.
I0523 11:57:38.000221  1678 net.cpp:228] accuracy does not need backward computation.
I0523 11:57:38.000232  1678 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 11:57:38.000242  1678 net.cpp:226] drop3 needs backward computation.
I0523 11:57:38.000252  1678 net.cpp:226] ip3 needs backward computation.
I0523 11:57:38.000262  1678 net.cpp:226] drop2 needs backward computation.
I0523 11:57:38.000270  1678 net.cpp:226] relu6 needs backward computation.
I0523 11:57:38.000288  1678 net.cpp:226] ip2 needs backward computation.
I0523 11:57:38.000298  1678 net.cpp:226] drop1 needs backward computation.
I0523 11:57:38.000308  1678 net.cpp:226] relu5 needs backward computation.
I0523 11:57:38.000318  1678 net.cpp:226] ip1 needs backward computation.
I0523 11:57:38.000327  1678 net.cpp:226] pool4 needs backward computation.
I0523 11:57:38.000337  1678 net.cpp:226] relu4 needs backward computation.
I0523 11:57:38.000347  1678 net.cpp:226] conv4 needs backward computation.
I0523 11:57:38.000355  1678 net.cpp:226] pool3 needs backward computation.
I0523 11:57:38.000366  1678 net.cpp:226] relu3 needs backward computation.
I0523 11:57:38.000376  1678 net.cpp:226] conv3 needs backward computation.
I0523 11:57:38.000387  1678 net.cpp:226] pool2 needs backward computation.
I0523 11:57:38.000397  1678 net.cpp:226] relu2 needs backward computation.
I0523 11:57:38.000407  1678 net.cpp:226] conv2 needs backward computation.
I0523 11:57:38.000417  1678 net.cpp:226] pool1 needs backward computation.
I0523 11:57:38.000427  1678 net.cpp:226] relu1 needs backward computation.
I0523 11:57:38.000437  1678 net.cpp:226] conv1 needs backward computation.
I0523 11:57:38.000448  1678 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 11:57:38.000459  1678 net.cpp:228] data_hdf5 does not need backward computation.
I0523 11:57:38.000468  1678 net.cpp:270] This network produces output accuracy
I0523 11:57:38.000478  1678 net.cpp:270] This network produces output loss
I0523 11:57:38.000506  1678 net.cpp:283] Network initialization done.
I0523 11:57:38.000640  1678 solver.cpp:60] Solver scaffolding done.
I0523 11:57:38.001770  1678 caffe.cpp:212] Starting Optimization
I0523 11:57:38.001785  1678 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 11:57:38.001796  1678 solver.cpp:289] Learning Rate Policy: fixed
I0523 11:57:38.003011  1678 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 11:58:26.262665  1678 solver.cpp:409]     Test net output #0: accuracy = 0.11048
I0523 11:58:26.262825  1678 solver.cpp:409]     Test net output #1: loss = 2.39605 (* 1 = 2.39605 loss)
I0523 11:58:26.288700  1678 solver.cpp:237] Iteration 0, loss = 2.39407
I0523 11:58:26.288736  1678 solver.cpp:253]     Train net output #0: loss = 2.39407 (* 1 = 2.39407 loss)
I0523 11:58:26.288754  1678 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0523 11:58:35.384044  1678 solver.cpp:237] Iteration 250, loss = 2.3169
I0523 11:58:35.384079  1678 solver.cpp:253]     Train net output #0: loss = 2.3169 (* 1 = 2.3169 loss)
I0523 11:58:35.384096  1678 sgd_solver.cpp:106] Iteration 250, lr = 0.0005
I0523 11:58:44.479085  1678 solver.cpp:237] Iteration 500, loss = 2.29096
I0523 11:58:44.479120  1678 solver.cpp:253]     Train net output #0: loss = 2.29096 (* 1 = 2.29096 loss)
I0523 11:58:44.479133  1678 sgd_solver.cpp:106] Iteration 500, lr = 0.0005
I0523 11:58:53.568830  1678 solver.cpp:237] Iteration 750, loss = 2.31866
I0523 11:58:53.568863  1678 solver.cpp:253]     Train net output #0: loss = 2.31866 (* 1 = 2.31866 loss)
I0523 11:58:53.568886  1678 sgd_solver.cpp:106] Iteration 750, lr = 0.0005
I0523 11:59:02.672102  1678 solver.cpp:237] Iteration 1000, loss = 2.26179
I0523 11:59:02.672250  1678 solver.cpp:253]     Train net output #0: loss = 2.26179 (* 1 = 2.26179 loss)
I0523 11:59:02.672262  1678 sgd_solver.cpp:106] Iteration 1000, lr = 0.0005
I0523 11:59:11.769091  1678 solver.cpp:237] Iteration 1250, loss = 2.28738
I0523 11:59:11.769135  1678 solver.cpp:253]     Train net output #0: loss = 2.28738 (* 1 = 2.28738 loss)
I0523 11:59:11.769152  1678 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0523 11:59:20.863698  1678 solver.cpp:237] Iteration 1500, loss = 2.1927
I0523 11:59:20.863732  1678 solver.cpp:253]     Train net output #0: loss = 2.1927 (* 1 = 2.1927 loss)
I0523 11:59:20.863746  1678 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0523 11:59:52.138103  1678 solver.cpp:237] Iteration 1750, loss = 2.18672
I0523 11:59:52.138267  1678 solver.cpp:253]     Train net output #0: loss = 2.18672 (* 1 = 2.18672 loss)
I0523 11:59:52.138280  1678 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0523 12:00:01.241305  1678 solver.cpp:237] Iteration 2000, loss = 2.08607
I0523 12:00:01.241353  1678 solver.cpp:253]     Train net output #0: loss = 2.08607 (* 1 = 2.08607 loss)
I0523 12:00:01.241369  1678 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0523 12:00:10.341713  1678 solver.cpp:237] Iteration 2250, loss = 2.08667
I0523 12:00:10.341748  1678 solver.cpp:253]     Train net output #0: loss = 2.08667 (* 1 = 2.08667 loss)
I0523 12:00:10.341764  1678 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0523 12:00:19.399945  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_2500.caffemodel
I0523 12:00:19.466007  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_2500.solverstate
I0523 12:00:19.502523  1678 solver.cpp:237] Iteration 2500, loss = 1.98386
I0523 12:00:19.502569  1678 solver.cpp:253]     Train net output #0: loss = 1.98386 (* 1 = 1.98386 loss)
I0523 12:00:19.502583  1678 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I0523 12:00:28.604059  1678 solver.cpp:237] Iteration 2750, loss = 1.86819
I0523 12:00:28.604213  1678 solver.cpp:253]     Train net output #0: loss = 1.86819 (* 1 = 1.86819 loss)
I0523 12:00:28.604228  1678 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I0523 12:00:37.705775  1678 solver.cpp:237] Iteration 3000, loss = 1.93141
I0523 12:00:37.705809  1678 solver.cpp:253]     Train net output #0: loss = 1.93141 (* 1 = 1.93141 loss)
I0523 12:00:37.705826  1678 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0523 12:00:46.800714  1678 solver.cpp:237] Iteration 3250, loss = 1.92001
I0523 12:00:46.800750  1678 solver.cpp:253]     Train net output #0: loss = 1.92001 (* 1 = 1.92001 loss)
I0523 12:00:46.800765  1678 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0523 12:01:18.096427  1678 solver.cpp:237] Iteration 3500, loss = 1.82668
I0523 12:01:18.096583  1678 solver.cpp:253]     Train net output #0: loss = 1.82668 (* 1 = 1.82668 loss)
I0523 12:01:18.096599  1678 sgd_solver.cpp:106] Iteration 3500, lr = 0.0005
I0523 12:01:27.191347  1678 solver.cpp:237] Iteration 3750, loss = 2.00434
I0523 12:01:27.191381  1678 solver.cpp:253]     Train net output #0: loss = 2.00434 (* 1 = 2.00434 loss)
I0523 12:01:27.191398  1678 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0523 12:01:36.300609  1678 solver.cpp:237] Iteration 4000, loss = 1.88062
I0523 12:01:36.300644  1678 solver.cpp:253]     Train net output #0: loss = 1.88062 (* 1 = 1.88062 loss)
I0523 12:01:36.300662  1678 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0523 12:01:45.403039  1678 solver.cpp:237] Iteration 4250, loss = 1.81633
I0523 12:01:45.403084  1678 solver.cpp:253]     Train net output #0: loss = 1.81633 (* 1 = 1.81633 loss)
I0523 12:01:45.403101  1678 sgd_solver.cpp:106] Iteration 4250, lr = 0.0005
I0523 12:01:54.505916  1678 solver.cpp:237] Iteration 4500, loss = 1.94376
I0523 12:01:54.506074  1678 solver.cpp:253]     Train net output #0: loss = 1.94376 (* 1 = 1.94376 loss)
I0523 12:01:54.506088  1678 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0523 12:02:03.604308  1678 solver.cpp:237] Iteration 4750, loss = 1.80831
I0523 12:02:03.604342  1678 solver.cpp:253]     Train net output #0: loss = 1.80831 (* 1 = 1.80831 loss)
I0523 12:02:03.604362  1678 sgd_solver.cpp:106] Iteration 4750, lr = 0.0005
I0523 12:02:12.664122  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_5000.caffemodel
I0523 12:02:12.727411  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_5000.solverstate
I0523 12:02:12.752717  1678 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 12:03:00.079942  1678 solver.cpp:409]     Test net output #0: accuracy = 0.62898
I0523 12:03:00.080101  1678 solver.cpp:409]     Test net output #1: loss = 1.33535 (* 1 = 1.33535 loss)
I0523 12:03:22.306967  1678 solver.cpp:237] Iteration 5000, loss = 1.59208
I0523 12:03:22.307018  1678 solver.cpp:253]     Train net output #0: loss = 1.59208 (* 1 = 1.59208 loss)
I0523 12:03:22.307036  1678 sgd_solver.cpp:106] Iteration 5000, lr = 0.0005
I0523 12:03:31.381048  1678 solver.cpp:237] Iteration 5250, loss = 1.76836
I0523 12:03:31.381189  1678 solver.cpp:253]     Train net output #0: loss = 1.76836 (* 1 = 1.76836 loss)
I0523 12:03:31.381203  1678 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0523 12:03:40.455163  1678 solver.cpp:237] Iteration 5500, loss = 1.85039
I0523 12:03:40.455196  1678 solver.cpp:253]     Train net output #0: loss = 1.85039 (* 1 = 1.85039 loss)
I0523 12:03:40.455214  1678 sgd_solver.cpp:106] Iteration 5500, lr = 0.0005
I0523 12:03:49.522666  1678 solver.cpp:237] Iteration 5750, loss = 1.86375
I0523 12:03:49.522711  1678 solver.cpp:253]     Train net output #0: loss = 1.86375 (* 1 = 1.86375 loss)
I0523 12:03:49.522727  1678 sgd_solver.cpp:106] Iteration 5750, lr = 0.0005
I0523 12:03:58.593916  1678 solver.cpp:237] Iteration 6000, loss = 1.67962
I0523 12:03:58.593951  1678 solver.cpp:253]     Train net output #0: loss = 1.67962 (* 1 = 1.67962 loss)
I0523 12:03:58.593966  1678 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0523 12:04:07.659234  1678 solver.cpp:237] Iteration 6250, loss = 1.66346
I0523 12:04:07.659369  1678 solver.cpp:253]     Train net output #0: loss = 1.66346 (* 1 = 1.66346 loss)
I0523 12:04:07.659382  1678 sgd_solver.cpp:106] Iteration 6250, lr = 0.0005
I0523 12:04:16.735185  1678 solver.cpp:237] Iteration 6500, loss = 1.64503
I0523 12:04:16.735229  1678 solver.cpp:253]     Train net output #0: loss = 1.64503 (* 1 = 1.64503 loss)
I0523 12:04:16.735246  1678 sgd_solver.cpp:106] Iteration 6500, lr = 0.0005
I0523 12:04:48.048846  1678 solver.cpp:237] Iteration 6750, loss = 1.78695
I0523 12:04:48.049003  1678 solver.cpp:253]     Train net output #0: loss = 1.78695 (* 1 = 1.78695 loss)
I0523 12:04:48.049018  1678 sgd_solver.cpp:106] Iteration 6750, lr = 0.0005
I0523 12:04:57.118722  1678 solver.cpp:237] Iteration 7000, loss = 1.56264
I0523 12:04:57.118757  1678 solver.cpp:253]     Train net output #0: loss = 1.56264 (* 1 = 1.56264 loss)
I0523 12:04:57.118770  1678 sgd_solver.cpp:106] Iteration 7000, lr = 0.0005
I0523 12:05:06.193703  1678 solver.cpp:237] Iteration 7250, loss = 1.64333
I0523 12:05:06.193747  1678 solver.cpp:253]     Train net output #0: loss = 1.64333 (* 1 = 1.64333 loss)
I0523 12:05:06.193763  1678 sgd_solver.cpp:106] Iteration 7250, lr = 0.0005
I0523 12:05:15.231830  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_7500.caffemodel
I0523 12:05:15.299206  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_7500.solverstate
I0523 12:05:15.338348  1678 solver.cpp:237] Iteration 7500, loss = 1.75291
I0523 12:05:15.338397  1678 solver.cpp:253]     Train net output #0: loss = 1.75291 (* 1 = 1.75291 loss)
I0523 12:05:15.338413  1678 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0523 12:05:24.407287  1678 solver.cpp:237] Iteration 7750, loss = 1.59975
I0523 12:05:24.407452  1678 solver.cpp:253]     Train net output #0: loss = 1.59975 (* 1 = 1.59975 loss)
I0523 12:05:24.407466  1678 sgd_solver.cpp:106] Iteration 7750, lr = 0.0005
I0523 12:05:33.478726  1678 solver.cpp:237] Iteration 8000, loss = 1.9373
I0523 12:05:33.478770  1678 solver.cpp:253]     Train net output #0: loss = 1.9373 (* 1 = 1.9373 loss)
I0523 12:05:33.478788  1678 sgd_solver.cpp:106] Iteration 8000, lr = 0.0005
I0523 12:05:42.553864  1678 solver.cpp:237] Iteration 8250, loss = 1.74979
I0523 12:05:42.553899  1678 solver.cpp:253]     Train net output #0: loss = 1.74979 (* 1 = 1.74979 loss)
I0523 12:05:42.553915  1678 sgd_solver.cpp:106] Iteration 8250, lr = 0.0005
I0523 12:06:13.885659  1678 solver.cpp:237] Iteration 8500, loss = 1.59175
I0523 12:06:13.885823  1678 solver.cpp:253]     Train net output #0: loss = 1.59175 (* 1 = 1.59175 loss)
I0523 12:06:13.885838  1678 sgd_solver.cpp:106] Iteration 8500, lr = 0.0005
I0523 12:06:22.956929  1678 solver.cpp:237] Iteration 8750, loss = 1.60893
I0523 12:06:22.956971  1678 solver.cpp:253]     Train net output #0: loss = 1.60893 (* 1 = 1.60893 loss)
I0523 12:06:22.956991  1678 sgd_solver.cpp:106] Iteration 8750, lr = 0.0005
I0523 12:06:32.026478  1678 solver.cpp:237] Iteration 9000, loss = 1.69666
I0523 12:06:32.026513  1678 solver.cpp:253]     Train net output #0: loss = 1.69666 (* 1 = 1.69666 loss)
I0523 12:06:32.026530  1678 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0523 12:06:41.096133  1678 solver.cpp:237] Iteration 9250, loss = 1.8069
I0523 12:06:41.096181  1678 solver.cpp:253]     Train net output #0: loss = 1.8069 (* 1 = 1.8069 loss)
I0523 12:06:41.096201  1678 sgd_solver.cpp:106] Iteration 9250, lr = 0.0005
I0523 12:06:50.170001  1678 solver.cpp:237] Iteration 9500, loss = 1.49661
I0523 12:06:50.170141  1678 solver.cpp:253]     Train net output #0: loss = 1.49661 (* 1 = 1.49661 loss)
I0523 12:06:50.170155  1678 sgd_solver.cpp:106] Iteration 9500, lr = 0.0005
I0523 12:06:59.249266  1678 solver.cpp:237] Iteration 9750, loss = 1.54754
I0523 12:06:59.249300  1678 solver.cpp:253]     Train net output #0: loss = 1.54754 (* 1 = 1.54754 loss)
I0523 12:06:59.249318  1678 sgd_solver.cpp:106] Iteration 9750, lr = 0.0005
I0523 12:07:08.290189  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_10000.caffemodel
I0523 12:07:08.354912  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_10000.solverstate
I0523 12:07:08.383767  1678 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 12:08:16.515702  1678 solver.cpp:409]     Test net output #0: accuracy = 0.670666
I0523 12:08:16.515861  1678 solver.cpp:409]     Test net output #1: loss = 1.1467 (* 1 = 1.1467 loss)
I0523 12:08:38.788446  1678 solver.cpp:237] Iteration 10000, loss = 1.8734
I0523 12:08:38.788497  1678 solver.cpp:253]     Train net output #0: loss = 1.8734 (* 1 = 1.8734 loss)
I0523 12:08:38.788513  1678 sgd_solver.cpp:106] Iteration 10000, lr = 0.0005
I0523 12:08:47.908638  1678 solver.cpp:237] Iteration 10250, loss = 1.70888
I0523 12:08:47.908797  1678 solver.cpp:253]     Train net output #0: loss = 1.70888 (* 1 = 1.70888 loss)
I0523 12:08:47.908810  1678 sgd_solver.cpp:106] Iteration 10250, lr = 0.0005
I0523 12:08:57.022778  1678 solver.cpp:237] Iteration 10500, loss = 1.78471
I0523 12:08:57.022811  1678 solver.cpp:253]     Train net output #0: loss = 1.78471 (* 1 = 1.78471 loss)
I0523 12:08:57.022830  1678 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0523 12:09:06.137897  1678 solver.cpp:237] Iteration 10750, loss = 1.7555
I0523 12:09:06.137931  1678 solver.cpp:253]     Train net output #0: loss = 1.7555 (* 1 = 1.7555 loss)
I0523 12:09:06.137944  1678 sgd_solver.cpp:106] Iteration 10750, lr = 0.0005
I0523 12:09:15.245563  1678 solver.cpp:237] Iteration 11000, loss = 1.76106
I0523 12:09:15.245600  1678 solver.cpp:253]     Train net output #0: loss = 1.76106 (* 1 = 1.76106 loss)
I0523 12:09:15.245618  1678 sgd_solver.cpp:106] Iteration 11000, lr = 0.0005
I0523 12:09:24.356395  1678 solver.cpp:237] Iteration 11250, loss = 1.48304
I0523 12:09:24.356536  1678 solver.cpp:253]     Train net output #0: loss = 1.48304 (* 1 = 1.48304 loss)
I0523 12:09:24.356549  1678 sgd_solver.cpp:106] Iteration 11250, lr = 0.0005
I0523 12:09:33.464509  1678 solver.cpp:237] Iteration 11500, loss = 1.47864
I0523 12:09:33.464542  1678 solver.cpp:253]     Train net output #0: loss = 1.47864 (* 1 = 1.47864 loss)
I0523 12:09:33.464560  1678 sgd_solver.cpp:106] Iteration 11500, lr = 0.0005
I0523 12:10:04.828498  1678 solver.cpp:237] Iteration 11750, loss = 1.62377
I0523 12:10:04.828675  1678 solver.cpp:253]     Train net output #0: loss = 1.62377 (* 1 = 1.62377 loss)
I0523 12:10:04.828691  1678 sgd_solver.cpp:106] Iteration 11750, lr = 0.0005
I0523 12:10:13.945430  1678 solver.cpp:237] Iteration 12000, loss = 1.85553
I0523 12:10:13.945463  1678 solver.cpp:253]     Train net output #0: loss = 1.85553 (* 1 = 1.85553 loss)
I0523 12:10:13.945480  1678 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0523 12:10:23.055124  1678 solver.cpp:237] Iteration 12250, loss = 1.69448
I0523 12:10:23.055160  1678 solver.cpp:253]     Train net output #0: loss = 1.69448 (* 1 = 1.69448 loss)
I0523 12:10:23.055177  1678 sgd_solver.cpp:106] Iteration 12250, lr = 0.0005
I0523 12:10:32.129259  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_12500.caffemodel
I0523 12:10:32.194573  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_12500.solverstate
I0523 12:10:32.233220  1678 solver.cpp:237] Iteration 12500, loss = 1.62007
I0523 12:10:32.233273  1678 solver.cpp:253]     Train net output #0: loss = 1.62007 (* 1 = 1.62007 loss)
I0523 12:10:32.233286  1678 sgd_solver.cpp:106] Iteration 12500, lr = 0.0005
I0523 12:10:41.343395  1678 solver.cpp:237] Iteration 12750, loss = 1.48467
I0523 12:10:41.343543  1678 solver.cpp:253]     Train net output #0: loss = 1.48467 (* 1 = 1.48467 loss)
I0523 12:10:41.343556  1678 sgd_solver.cpp:106] Iteration 12750, lr = 0.0005
I0523 12:10:50.452056  1678 solver.cpp:237] Iteration 13000, loss = 1.62666
I0523 12:10:50.452102  1678 solver.cpp:253]     Train net output #0: loss = 1.62666 (* 1 = 1.62666 loss)
I0523 12:10:50.452117  1678 sgd_solver.cpp:106] Iteration 13000, lr = 0.0005
I0523 12:10:59.566462  1678 solver.cpp:237] Iteration 13250, loss = 1.79365
I0523 12:10:59.566498  1678 solver.cpp:253]     Train net output #0: loss = 1.79365 (* 1 = 1.79365 loss)
I0523 12:10:59.566511  1678 sgd_solver.cpp:106] Iteration 13250, lr = 0.0005
I0523 12:11:30.922456  1678 solver.cpp:237] Iteration 13500, loss = 1.7092
I0523 12:11:30.922633  1678 solver.cpp:253]     Train net output #0: loss = 1.7092 (* 1 = 1.7092 loss)
I0523 12:11:30.922647  1678 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0523 12:11:40.022771  1678 solver.cpp:237] Iteration 13750, loss = 1.65269
I0523 12:11:40.022805  1678 solver.cpp:253]     Train net output #0: loss = 1.65269 (* 1 = 1.65269 loss)
I0523 12:11:40.022824  1678 sgd_solver.cpp:106] Iteration 13750, lr = 0.0005
I0523 12:11:49.133260  1678 solver.cpp:237] Iteration 14000, loss = 1.65935
I0523 12:11:49.133311  1678 solver.cpp:253]     Train net output #0: loss = 1.65935 (* 1 = 1.65935 loss)
I0523 12:11:49.133323  1678 sgd_solver.cpp:106] Iteration 14000, lr = 0.0005
I0523 12:11:58.241185  1678 solver.cpp:237] Iteration 14250, loss = 1.58612
I0523 12:11:58.241220  1678 solver.cpp:253]     Train net output #0: loss = 1.58612 (* 1 = 1.58612 loss)
I0523 12:11:58.241236  1678 sgd_solver.cpp:106] Iteration 14250, lr = 0.0005
I0523 12:12:07.362103  1678 solver.cpp:237] Iteration 14500, loss = 1.62029
I0523 12:12:07.362258  1678 solver.cpp:253]     Train net output #0: loss = 1.62029 (* 1 = 1.62029 loss)
I0523 12:12:07.362272  1678 sgd_solver.cpp:106] Iteration 14500, lr = 0.0005
I0523 12:12:16.476181  1678 solver.cpp:237] Iteration 14750, loss = 1.55312
I0523 12:12:16.476214  1678 solver.cpp:253]     Train net output #0: loss = 1.55312 (* 1 = 1.55312 loss)
I0523 12:12:16.476233  1678 sgd_solver.cpp:106] Iteration 14750, lr = 0.0005
I0523 12:12:25.546470  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_15000.caffemodel
I0523 12:12:25.610430  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_15000.solverstate
I0523 12:12:25.635704  1678 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 12:13:12.641012  1678 solver.cpp:409]     Test net output #0: accuracy = 0.695013
I0523 12:13:12.641171  1678 solver.cpp:409]     Test net output #1: loss = 1.15126 (* 1 = 1.15126 loss)
I0523 12:13:34.850137  1678 solver.cpp:237] Iteration 15000, loss = 1.52674
I0523 12:13:34.850189  1678 solver.cpp:253]     Train net output #0: loss = 1.52674 (* 1 = 1.52674 loss)
I0523 12:13:34.850208  1678 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0523 12:13:43.874469  1678 solver.cpp:237] Iteration 15250, loss = 1.30354
I0523 12:13:43.874639  1678 solver.cpp:253]     Train net output #0: loss = 1.30354 (* 1 = 1.30354 loss)
I0523 12:13:43.874652  1678 sgd_solver.cpp:106] Iteration 15250, lr = 0.0005
I0523 12:13:52.901593  1678 solver.cpp:237] Iteration 15500, loss = 1.53766
I0523 12:13:52.901634  1678 solver.cpp:253]     Train net output #0: loss = 1.53766 (* 1 = 1.53766 loss)
I0523 12:13:52.901655  1678 sgd_solver.cpp:106] Iteration 15500, lr = 0.0005
I0523 12:14:01.926057  1678 solver.cpp:237] Iteration 15750, loss = 1.64308
I0523 12:14:01.926092  1678 solver.cpp:253]     Train net output #0: loss = 1.64308 (* 1 = 1.64308 loss)
I0523 12:14:01.926110  1678 sgd_solver.cpp:106] Iteration 15750, lr = 0.0005
I0523 12:14:10.958143  1678 solver.cpp:237] Iteration 16000, loss = 2.10677
I0523 12:14:10.958191  1678 solver.cpp:253]     Train net output #0: loss = 2.10677 (* 1 = 2.10677 loss)
I0523 12:14:10.958207  1678 sgd_solver.cpp:106] Iteration 16000, lr = 0.0005
I0523 12:14:19.994194  1678 solver.cpp:237] Iteration 16250, loss = 1.56114
I0523 12:14:19.994335  1678 solver.cpp:253]     Train net output #0: loss = 1.56114 (* 1 = 1.56114 loss)
I0523 12:14:19.994349  1678 sgd_solver.cpp:106] Iteration 16250, lr = 0.0005
I0523 12:14:29.026089  1678 solver.cpp:237] Iteration 16500, loss = 1.41535
I0523 12:14:29.026124  1678 solver.cpp:253]     Train net output #0: loss = 1.41535 (* 1 = 1.41535 loss)
I0523 12:14:29.026141  1678 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0523 12:15:00.319938  1678 solver.cpp:237] Iteration 16750, loss = 1.43394
I0523 12:15:00.320116  1678 solver.cpp:253]     Train net output #0: loss = 1.43394 (* 1 = 1.43394 loss)
I0523 12:15:00.320132  1678 sgd_solver.cpp:106] Iteration 16750, lr = 0.0005
I0523 12:15:09.350288  1678 solver.cpp:237] Iteration 17000, loss = 1.47633
I0523 12:15:09.350335  1678 solver.cpp:253]     Train net output #0: loss = 1.47633 (* 1 = 1.47633 loss)
I0523 12:15:09.350353  1678 sgd_solver.cpp:106] Iteration 17000, lr = 0.0005
I0523 12:15:18.379645  1678 solver.cpp:237] Iteration 17250, loss = 1.43112
I0523 12:15:18.379684  1678 solver.cpp:253]     Train net output #0: loss = 1.43112 (* 1 = 1.43112 loss)
I0523 12:15:18.379698  1678 sgd_solver.cpp:106] Iteration 17250, lr = 0.0005
I0523 12:15:27.373857  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_17500.caffemodel
I0523 12:15:27.436347  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_17500.solverstate
I0523 12:15:27.473639  1678 solver.cpp:237] Iteration 17500, loss = 1.96639
I0523 12:15:27.473685  1678 solver.cpp:253]     Train net output #0: loss = 1.96639 (* 1 = 1.96639 loss)
I0523 12:15:27.473698  1678 sgd_solver.cpp:106] Iteration 17500, lr = 0.0005
I0523 12:15:36.503743  1678 solver.cpp:237] Iteration 17750, loss = 1.4144
I0523 12:15:36.503890  1678 solver.cpp:253]     Train net output #0: loss = 1.4144 (* 1 = 1.4144 loss)
I0523 12:15:36.503903  1678 sgd_solver.cpp:106] Iteration 17750, lr = 0.0005
I0523 12:15:45.535876  1678 solver.cpp:237] Iteration 18000, loss = 1.77595
I0523 12:15:45.535909  1678 solver.cpp:253]     Train net output #0: loss = 1.77595 (* 1 = 1.77595 loss)
I0523 12:15:45.535926  1678 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0523 12:15:54.567806  1678 solver.cpp:237] Iteration 18250, loss = 1.46592
I0523 12:15:54.567852  1678 solver.cpp:253]     Train net output #0: loss = 1.46592 (* 1 = 1.46592 loss)
I0523 12:15:54.567869  1678 sgd_solver.cpp:106] Iteration 18250, lr = 0.0005
I0523 12:16:25.823712  1678 solver.cpp:237] Iteration 18500, loss = 1.46056
I0523 12:16:25.823876  1678 solver.cpp:253]     Train net output #0: loss = 1.46056 (* 1 = 1.46056 loss)
I0523 12:16:25.823892  1678 sgd_solver.cpp:106] Iteration 18500, lr = 0.0005
I0523 12:16:34.856509  1678 solver.cpp:237] Iteration 18750, loss = 1.647
I0523 12:16:34.856544  1678 solver.cpp:253]     Train net output #0: loss = 1.647 (* 1 = 1.647 loss)
I0523 12:16:34.856561  1678 sgd_solver.cpp:106] Iteration 18750, lr = 0.0005
I0523 12:16:43.878619  1678 solver.cpp:237] Iteration 19000, loss = 1.52065
I0523 12:16:43.878667  1678 solver.cpp:253]     Train net output #0: loss = 1.52065 (* 1 = 1.52065 loss)
I0523 12:16:43.878684  1678 sgd_solver.cpp:106] Iteration 19000, lr = 0.0005
I0523 12:16:52.905776  1678 solver.cpp:237] Iteration 19250, loss = 1.48706
I0523 12:16:52.905810  1678 solver.cpp:253]     Train net output #0: loss = 1.48706 (* 1 = 1.48706 loss)
I0523 12:16:52.905827  1678 sgd_solver.cpp:106] Iteration 19250, lr = 0.0005
I0523 12:17:01.937963  1678 solver.cpp:237] Iteration 19500, loss = 1.64871
I0523 12:17:01.938105  1678 solver.cpp:253]     Train net output #0: loss = 1.64871 (* 1 = 1.64871 loss)
I0523 12:17:01.938118  1678 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0523 12:17:10.967279  1678 solver.cpp:237] Iteration 19750, loss = 1.58584
I0523 12:17:10.967317  1678 solver.cpp:253]     Train net output #0: loss = 1.58584 (* 1 = 1.58584 loss)
I0523 12:17:10.967339  1678 sgd_solver.cpp:106] Iteration 19750, lr = 0.0005
I0523 12:17:19.958350  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_20000.caffemodel
I0523 12:17:20.020696  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_20000.solverstate
I0523 12:17:20.046998  1678 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 12:18:28.237210  1678 solver.cpp:409]     Test net output #0: accuracy = 0.728832
I0523 12:18:28.237399  1678 solver.cpp:409]     Test net output #1: loss = 0.964852 (* 1 = 0.964852 loss)
I0523 12:18:50.451629  1678 solver.cpp:237] Iteration 20000, loss = 1.55868
I0523 12:18:50.451688  1678 solver.cpp:253]     Train net output #0: loss = 1.55868 (* 1 = 1.55868 loss)
I0523 12:18:50.451702  1678 sgd_solver.cpp:106] Iteration 20000, lr = 0.0005
I0523 12:18:59.501839  1678 solver.cpp:237] Iteration 20250, loss = 1.58551
I0523 12:18:59.502010  1678 solver.cpp:253]     Train net output #0: loss = 1.58551 (* 1 = 1.58551 loss)
I0523 12:18:59.502024  1678 sgd_solver.cpp:106] Iteration 20250, lr = 0.0005
I0523 12:19:08.552479  1678 solver.cpp:237] Iteration 20500, loss = 1.4942
I0523 12:19:08.552515  1678 solver.cpp:253]     Train net output #0: loss = 1.4942 (* 1 = 1.4942 loss)
I0523 12:19:08.552531  1678 sgd_solver.cpp:106] Iteration 20500, lr = 0.0005
I0523 12:19:17.585898  1678 solver.cpp:237] Iteration 20750, loss = 1.41521
I0523 12:19:17.585943  1678 solver.cpp:253]     Train net output #0: loss = 1.41521 (* 1 = 1.41521 loss)
I0523 12:19:17.585963  1678 sgd_solver.cpp:106] Iteration 20750, lr = 0.0005
I0523 12:19:26.637012  1678 solver.cpp:237] Iteration 21000, loss = 1.32236
I0523 12:19:26.637047  1678 solver.cpp:253]     Train net output #0: loss = 1.32236 (* 1 = 1.32236 loss)
I0523 12:19:26.637063  1678 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0523 12:19:35.670632  1678 solver.cpp:237] Iteration 21250, loss = 1.64776
I0523 12:19:35.670791  1678 solver.cpp:253]     Train net output #0: loss = 1.64776 (* 1 = 1.64776 loss)
I0523 12:19:35.670805  1678 sgd_solver.cpp:106] Iteration 21250, lr = 0.0005
I0523 12:19:44.697600  1678 solver.cpp:237] Iteration 21500, loss = 1.47502
I0523 12:19:44.697634  1678 solver.cpp:253]     Train net output #0: loss = 1.47502 (* 1 = 1.47502 loss)
I0523 12:19:44.697651  1678 sgd_solver.cpp:106] Iteration 21500, lr = 0.0005
I0523 12:20:15.943869  1678 solver.cpp:237] Iteration 21750, loss = 1.63878
I0523 12:20:15.944036  1678 solver.cpp:253]     Train net output #0: loss = 1.63878 (* 1 = 1.63878 loss)
I0523 12:20:15.944051  1678 sgd_solver.cpp:106] Iteration 21750, lr = 0.0005
I0523 12:20:24.967587  1678 solver.cpp:237] Iteration 22000, loss = 1.44768
I0523 12:20:24.967622  1678 solver.cpp:253]     Train net output #0: loss = 1.44768 (* 1 = 1.44768 loss)
I0523 12:20:24.967636  1678 sgd_solver.cpp:106] Iteration 22000, lr = 0.0005
I0523 12:20:34.012922  1678 solver.cpp:237] Iteration 22250, loss = 1.24907
I0523 12:20:34.012959  1678 solver.cpp:253]     Train net output #0: loss = 1.24907 (* 1 = 1.24907 loss)
I0523 12:20:34.012980  1678 sgd_solver.cpp:106] Iteration 22250, lr = 0.0005
I0523 12:20:43.023246  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_22500.caffemodel
I0523 12:20:43.090448  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_22500.solverstate
I0523 12:20:43.129241  1678 solver.cpp:237] Iteration 22500, loss = 1.28171
I0523 12:20:43.129292  1678 solver.cpp:253]     Train net output #0: loss = 1.28171 (* 1 = 1.28171 loss)
I0523 12:20:43.129305  1678 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0523 12:20:52.166715  1678 solver.cpp:237] Iteration 22750, loss = 1.62003
I0523 12:20:52.166874  1678 solver.cpp:253]     Train net output #0: loss = 1.62003 (* 1 = 1.62003 loss)
I0523 12:20:52.166888  1678 sgd_solver.cpp:106] Iteration 22750, lr = 0.0005
I0523 12:21:01.195169  1678 solver.cpp:237] Iteration 23000, loss = 1.61062
I0523 12:21:01.195204  1678 solver.cpp:253]     Train net output #0: loss = 1.61062 (* 1 = 1.61062 loss)
I0523 12:21:01.195222  1678 sgd_solver.cpp:106] Iteration 23000, lr = 0.0005
I0523 12:21:10.226099  1678 solver.cpp:237] Iteration 23250, loss = 1.80593
I0523 12:21:10.226135  1678 solver.cpp:253]     Train net output #0: loss = 1.80593 (* 1 = 1.80593 loss)
I0523 12:21:10.226150  1678 sgd_solver.cpp:106] Iteration 23250, lr = 0.0005
I0523 12:21:41.517520  1678 solver.cpp:237] Iteration 23500, loss = 1.59898
I0523 12:21:41.517700  1678 solver.cpp:253]     Train net output #0: loss = 1.59898 (* 1 = 1.59898 loss)
I0523 12:21:41.517715  1678 sgd_solver.cpp:106] Iteration 23500, lr = 0.0005
I0523 12:21:50.560241  1678 solver.cpp:237] Iteration 23750, loss = 1.50318
I0523 12:21:50.560276  1678 solver.cpp:253]     Train net output #0: loss = 1.50318 (* 1 = 1.50318 loss)
I0523 12:21:50.560293  1678 sgd_solver.cpp:106] Iteration 23750, lr = 0.0005
I0523 12:21:59.602882  1678 solver.cpp:237] Iteration 24000, loss = 1.5704
I0523 12:21:59.602917  1678 solver.cpp:253]     Train net output #0: loss = 1.5704 (* 1 = 1.5704 loss)
I0523 12:21:59.602934  1678 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0523 12:22:08.637547  1678 solver.cpp:237] Iteration 24250, loss = 1.58381
I0523 12:22:08.637593  1678 solver.cpp:253]     Train net output #0: loss = 1.58381 (* 1 = 1.58381 loss)
I0523 12:22:08.637609  1678 sgd_solver.cpp:106] Iteration 24250, lr = 0.0005
I0523 12:22:17.666030  1678 solver.cpp:237] Iteration 24500, loss = 1.3151
I0523 12:22:17.666177  1678 solver.cpp:253]     Train net output #0: loss = 1.3151 (* 1 = 1.3151 loss)
I0523 12:22:17.666191  1678 sgd_solver.cpp:106] Iteration 24500, lr = 0.0005
I0523 12:22:26.703316  1678 solver.cpp:237] Iteration 24750, loss = 1.58032
I0523 12:22:26.703351  1678 solver.cpp:253]     Train net output #0: loss = 1.58032 (* 1 = 1.58032 loss)
I0523 12:22:26.703369  1678 sgd_solver.cpp:106] Iteration 24750, lr = 0.0005
I0523 12:22:35.700145  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_25000.caffemodel
I0523 12:22:35.765889  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_25000.solverstate
I0523 12:22:35.795716  1678 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 12:23:23.161604  1678 solver.cpp:409]     Test net output #0: accuracy = 0.778242
I0523 12:23:23.161768  1678 solver.cpp:409]     Test net output #1: loss = 0.797238 (* 1 = 0.797238 loss)
I0523 12:23:44.072870  1678 solver.cpp:237] Iteration 25000, loss = 1.35294
I0523 12:23:44.072923  1678 solver.cpp:253]     Train net output #0: loss = 1.35294 (* 1 = 1.35294 loss)
I0523 12:23:44.072937  1678 sgd_solver.cpp:106] Iteration 25000, lr = 0.0005
I0523 12:23:53.122807  1678 solver.cpp:237] Iteration 25250, loss = 1.29533
I0523 12:23:53.122846  1678 solver.cpp:253]     Train net output #0: loss = 1.29533 (* 1 = 1.29533 loss)
I0523 12:23:53.122865  1678 sgd_solver.cpp:106] Iteration 25250, lr = 0.0005
I0523 12:24:02.173643  1678 solver.cpp:237] Iteration 25500, loss = 1.45673
I0523 12:24:02.173796  1678 solver.cpp:253]     Train net output #0: loss = 1.45673 (* 1 = 1.45673 loss)
I0523 12:24:02.173810  1678 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0523 12:24:11.220337  1678 solver.cpp:237] Iteration 25750, loss = 1.49254
I0523 12:24:11.220381  1678 solver.cpp:253]     Train net output #0: loss = 1.49254 (* 1 = 1.49254 loss)
I0523 12:24:11.220397  1678 sgd_solver.cpp:106] Iteration 25750, lr = 0.0005
I0523 12:24:20.264777  1678 solver.cpp:237] Iteration 26000, loss = 1.56061
I0523 12:24:20.264813  1678 solver.cpp:253]     Train net output #0: loss = 1.56061 (* 1 = 1.56061 loss)
I0523 12:24:20.264829  1678 sgd_solver.cpp:106] Iteration 26000, lr = 0.0005
I0523 12:24:29.311980  1678 solver.cpp:237] Iteration 26250, loss = 1.56615
I0523 12:24:29.312016  1678 solver.cpp:253]     Train net output #0: loss = 1.56615 (* 1 = 1.56615 loss)
I0523 12:24:29.312029  1678 sgd_solver.cpp:106] Iteration 26250, lr = 0.0005
I0523 12:24:38.353266  1678 solver.cpp:237] Iteration 26500, loss = 1.46054
I0523 12:24:38.353440  1678 solver.cpp:253]     Train net output #0: loss = 1.46054 (* 1 = 1.46054 loss)
I0523 12:24:38.353453  1678 sgd_solver.cpp:106] Iteration 26500, lr = 0.0005
I0523 12:25:08.323629  1678 solver.cpp:237] Iteration 26750, loss = 1.40585
I0523 12:25:08.323685  1678 solver.cpp:253]     Train net output #0: loss = 1.40585 (* 1 = 1.40585 loss)
I0523 12:25:08.323699  1678 sgd_solver.cpp:106] Iteration 26750, lr = 0.0005
I0523 12:25:17.375005  1678 solver.cpp:237] Iteration 27000, loss = 1.29625
I0523 12:25:17.375161  1678 solver.cpp:253]     Train net output #0: loss = 1.29625 (* 1 = 1.29625 loss)
I0523 12:25:17.375174  1678 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0523 12:25:26.417852  1678 solver.cpp:237] Iteration 27250, loss = 1.61528
I0523 12:25:26.417896  1678 solver.cpp:253]     Train net output #0: loss = 1.61528 (* 1 = 1.61528 loss)
I0523 12:25:26.417917  1678 sgd_solver.cpp:106] Iteration 27250, lr = 0.0005
I0523 12:25:35.440382  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_27500.caffemodel
I0523 12:25:35.503005  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_27500.solverstate
I0523 12:25:35.540547  1678 solver.cpp:237] Iteration 27500, loss = 1.52032
I0523 12:25:35.540593  1678 solver.cpp:253]     Train net output #0: loss = 1.52032 (* 1 = 1.52032 loss)
I0523 12:25:35.540607  1678 sgd_solver.cpp:106] Iteration 27500, lr = 0.0005
I0523 12:25:44.597376  1678 solver.cpp:237] Iteration 27750, loss = 1.20351
I0523 12:25:44.597411  1678 solver.cpp:253]     Train net output #0: loss = 1.20351 (* 1 = 1.20351 loss)
I0523 12:25:44.597427  1678 sgd_solver.cpp:106] Iteration 27750, lr = 0.0005
I0523 12:25:53.650878  1678 solver.cpp:237] Iteration 28000, loss = 1.29097
I0523 12:25:53.651042  1678 solver.cpp:253]     Train net output #0: loss = 1.29097 (* 1 = 1.29097 loss)
I0523 12:25:53.651057  1678 sgd_solver.cpp:106] Iteration 28000, lr = 0.0005
I0523 12:26:02.700325  1678 solver.cpp:237] Iteration 28250, loss = 1.31036
I0523 12:26:02.700359  1678 solver.cpp:253]     Train net output #0: loss = 1.31036 (* 1 = 1.31036 loss)
I0523 12:26:02.700376  1678 sgd_solver.cpp:106] Iteration 28250, lr = 0.0005
I0523 12:26:32.679250  1678 solver.cpp:237] Iteration 28500, loss = 1.27009
I0523 12:26:32.679421  1678 solver.cpp:253]     Train net output #0: loss = 1.27009 (* 1 = 1.27009 loss)
I0523 12:26:32.679435  1678 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0523 12:26:41.736269  1678 solver.cpp:237] Iteration 28750, loss = 1.16922
I0523 12:26:41.736313  1678 solver.cpp:253]     Train net output #0: loss = 1.16922 (* 1 = 1.16922 loss)
I0523 12:26:41.736327  1678 sgd_solver.cpp:106] Iteration 28750, lr = 0.0005
I0523 12:26:50.776367  1678 solver.cpp:237] Iteration 29000, loss = 1.29458
I0523 12:26:50.776403  1678 solver.cpp:253]     Train net output #0: loss = 1.29458 (* 1 = 1.29458 loss)
I0523 12:26:50.776419  1678 sgd_solver.cpp:106] Iteration 29000, lr = 0.0005
I0523 12:26:59.828737  1678 solver.cpp:237] Iteration 29250, loss = 1.32864
I0523 12:26:59.828773  1678 solver.cpp:253]     Train net output #0: loss = 1.32864 (* 1 = 1.32864 loss)
I0523 12:26:59.828788  1678 sgd_solver.cpp:106] Iteration 29250, lr = 0.0005
I0523 12:27:08.887641  1678 solver.cpp:237] Iteration 29500, loss = 1.48873
I0523 12:27:08.887804  1678 solver.cpp:253]     Train net output #0: loss = 1.48873 (* 1 = 1.48873 loss)
I0523 12:27:08.887817  1678 sgd_solver.cpp:106] Iteration 29500, lr = 0.0005
I0523 12:27:17.938452  1678 solver.cpp:237] Iteration 29750, loss = 1.35813
I0523 12:27:17.938485  1678 solver.cpp:253]     Train net output #0: loss = 1.35813 (* 1 = 1.35813 loss)
I0523 12:27:17.938503  1678 sgd_solver.cpp:106] Iteration 29750, lr = 0.0005
I0523 12:27:26.950083  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_30000.caffemodel
I0523 12:27:27.013442  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_30000.solverstate
I0523 12:27:27.039517  1678 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 12:28:35.206619  1678 solver.cpp:409]     Test net output #0: accuracy = 0.797328
I0523 12:28:35.206796  1678 solver.cpp:409]     Test net output #1: loss = 0.695947 (* 1 = 0.695947 loss)
I0523 12:28:56.150241  1678 solver.cpp:237] Iteration 30000, loss = 1.32459
I0523 12:28:56.150295  1678 solver.cpp:253]     Train net output #0: loss = 1.32459 (* 1 = 1.32459 loss)
I0523 12:28:56.150308  1678 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0523 12:29:05.115939  1678 solver.cpp:237] Iteration 30250, loss = 1.47146
I0523 12:29:05.115974  1678 solver.cpp:253]     Train net output #0: loss = 1.47146 (* 1 = 1.47146 loss)
I0523 12:29:05.115991  1678 sgd_solver.cpp:106] Iteration 30250, lr = 0.0005
I0523 12:29:14.079442  1678 solver.cpp:237] Iteration 30500, loss = 1.55571
I0523 12:29:14.079609  1678 solver.cpp:253]     Train net output #0: loss = 1.55571 (* 1 = 1.55571 loss)
I0523 12:29:14.079623  1678 sgd_solver.cpp:106] Iteration 30500, lr = 0.0005
I0523 12:29:23.048277  1678 solver.cpp:237] Iteration 30750, loss = 1.52721
I0523 12:29:23.048312  1678 solver.cpp:253]     Train net output #0: loss = 1.52721 (* 1 = 1.52721 loss)
I0523 12:29:23.048331  1678 sgd_solver.cpp:106] Iteration 30750, lr = 0.0005
I0523 12:29:32.014489  1678 solver.cpp:237] Iteration 31000, loss = 1.43787
I0523 12:29:32.014524  1678 solver.cpp:253]     Train net output #0: loss = 1.43787 (* 1 = 1.43787 loss)
I0523 12:29:32.014542  1678 sgd_solver.cpp:106] Iteration 31000, lr = 0.0005
I0523 12:29:40.985249  1678 solver.cpp:237] Iteration 31250, loss = 1.391
I0523 12:29:40.985287  1678 solver.cpp:253]     Train net output #0: loss = 1.391 (* 1 = 1.391 loss)
I0523 12:29:40.985306  1678 sgd_solver.cpp:106] Iteration 31250, lr = 0.0005
I0523 12:29:49.956192  1678 solver.cpp:237] Iteration 31500, loss = 1.29126
I0523 12:29:49.956346  1678 solver.cpp:253]     Train net output #0: loss = 1.29126 (* 1 = 1.29126 loss)
I0523 12:29:49.956360  1678 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0523 12:30:19.858819  1678 solver.cpp:237] Iteration 31750, loss = 1.60267
I0523 12:30:19.858870  1678 solver.cpp:253]     Train net output #0: loss = 1.60267 (* 1 = 1.60267 loss)
I0523 12:30:19.858886  1678 sgd_solver.cpp:106] Iteration 31750, lr = 0.0005
I0523 12:30:28.836401  1678 solver.cpp:237] Iteration 32000, loss = 1.21249
I0523 12:30:28.836567  1678 solver.cpp:253]     Train net output #0: loss = 1.21249 (* 1 = 1.21249 loss)
I0523 12:30:28.836581  1678 sgd_solver.cpp:106] Iteration 32000, lr = 0.0005
I0523 12:30:37.804375  1678 solver.cpp:237] Iteration 32250, loss = 1.39882
I0523 12:30:37.804409  1678 solver.cpp:253]     Train net output #0: loss = 1.39882 (* 1 = 1.39882 loss)
I0523 12:30:37.804428  1678 sgd_solver.cpp:106] Iteration 32250, lr = 0.0005
I0523 12:30:46.746505  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_32500.caffemodel
I0523 12:30:46.810731  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_32500.solverstate
I0523 12:30:46.848490  1678 solver.cpp:237] Iteration 32500, loss = 1.3212
I0523 12:30:46.848534  1678 solver.cpp:253]     Train net output #0: loss = 1.3212 (* 1 = 1.3212 loss)
I0523 12:30:46.848548  1678 sgd_solver.cpp:106] Iteration 32500, lr = 0.0005
I0523 12:30:55.821326  1678 solver.cpp:237] Iteration 32750, loss = 1.37761
I0523 12:30:55.821372  1678 solver.cpp:253]     Train net output #0: loss = 1.37761 (* 1 = 1.37761 loss)
I0523 12:30:55.821388  1678 sgd_solver.cpp:106] Iteration 32750, lr = 0.0005
I0523 12:31:04.785004  1678 solver.cpp:237] Iteration 33000, loss = 1.56979
I0523 12:31:04.785168  1678 solver.cpp:253]     Train net output #0: loss = 1.56979 (* 1 = 1.56979 loss)
I0523 12:31:04.785181  1678 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0523 12:31:13.754982  1678 solver.cpp:237] Iteration 33250, loss = 1.28441
I0523 12:31:13.755015  1678 solver.cpp:253]     Train net output #0: loss = 1.28441 (* 1 = 1.28441 loss)
I0523 12:31:13.755033  1678 sgd_solver.cpp:106] Iteration 33250, lr = 0.0005
I0523 12:31:43.583745  1678 solver.cpp:237] Iteration 33500, loss = 1.46678
I0523 12:31:43.583916  1678 solver.cpp:253]     Train net output #0: loss = 1.46678 (* 1 = 1.46678 loss)
I0523 12:31:43.583930  1678 sgd_solver.cpp:106] Iteration 33500, lr = 0.0005
I0523 12:31:52.556128  1678 solver.cpp:237] Iteration 33750, loss = 1.22463
I0523 12:31:52.556162  1678 solver.cpp:253]     Train net output #0: loss = 1.22463 (* 1 = 1.22463 loss)
I0523 12:31:52.556180  1678 sgd_solver.cpp:106] Iteration 33750, lr = 0.0005
I0523 12:32:01.527438  1678 solver.cpp:237] Iteration 34000, loss = 1.57841
I0523 12:32:01.527473  1678 solver.cpp:253]     Train net output #0: loss = 1.57841 (* 1 = 1.57841 loss)
I0523 12:32:01.527488  1678 sgd_solver.cpp:106] Iteration 34000, lr = 0.0005
I0523 12:32:10.494735  1678 solver.cpp:237] Iteration 34250, loss = 1.45861
I0523 12:32:10.494778  1678 solver.cpp:253]     Train net output #0: loss = 1.45861 (* 1 = 1.45861 loss)
I0523 12:32:10.494797  1678 sgd_solver.cpp:106] Iteration 34250, lr = 0.0005
I0523 12:32:19.461593  1678 solver.cpp:237] Iteration 34500, loss = 1.38124
I0523 12:32:19.461743  1678 solver.cpp:253]     Train net output #0: loss = 1.38124 (* 1 = 1.38124 loss)
I0523 12:32:19.461756  1678 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0523 12:32:28.432747  1678 solver.cpp:237] Iteration 34750, loss = 1.09325
I0523 12:32:28.432781  1678 solver.cpp:253]     Train net output #0: loss = 1.09325 (* 1 = 1.09325 loss)
I0523 12:32:28.432797  1678 sgd_solver.cpp:106] Iteration 34750, lr = 0.0005
I0523 12:32:37.375740  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_35000.caffemodel
I0523 12:32:37.438670  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_35000.solverstate
I0523 12:32:37.465279  1678 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 12:33:24.476527  1678 solver.cpp:409]     Test net output #0: accuracy = 0.803449
I0523 12:33:24.476693  1678 solver.cpp:409]     Test net output #1: loss = 0.686087 (* 1 = 0.686087 loss)
I0523 12:33:45.406697  1678 solver.cpp:237] Iteration 35000, loss = 1.48444
I0523 12:33:45.406751  1678 solver.cpp:253]     Train net output #0: loss = 1.48444 (* 1 = 1.48444 loss)
I0523 12:33:45.406766  1678 sgd_solver.cpp:106] Iteration 35000, lr = 0.0005
I0523 12:33:54.411154  1678 solver.cpp:237] Iteration 35250, loss = 1.33115
I0523 12:33:54.411193  1678 solver.cpp:253]     Train net output #0: loss = 1.33115 (* 1 = 1.33115 loss)
I0523 12:33:54.411212  1678 sgd_solver.cpp:106] Iteration 35250, lr = 0.0005
I0523 12:34:03.419935  1678 solver.cpp:237] Iteration 35500, loss = 1.61547
I0523 12:34:03.420088  1678 solver.cpp:253]     Train net output #0: loss = 1.61547 (* 1 = 1.61547 loss)
I0523 12:34:03.420100  1678 sgd_solver.cpp:106] Iteration 35500, lr = 0.0005
I0523 12:34:12.424844  1678 solver.cpp:237] Iteration 35750, loss = 1.28439
I0523 12:34:12.424890  1678 solver.cpp:253]     Train net output #0: loss = 1.28439 (* 1 = 1.28439 loss)
I0523 12:34:12.424907  1678 sgd_solver.cpp:106] Iteration 35750, lr = 0.0005
I0523 12:34:21.430791  1678 solver.cpp:237] Iteration 36000, loss = 1.51269
I0523 12:34:21.430826  1678 solver.cpp:253]     Train net output #0: loss = 1.51269 (* 1 = 1.51269 loss)
I0523 12:34:21.430843  1678 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0523 12:34:30.436837  1678 solver.cpp:237] Iteration 36250, loss = 1.25405
I0523 12:34:30.436873  1678 solver.cpp:253]     Train net output #0: loss = 1.25405 (* 1 = 1.25405 loss)
I0523 12:34:30.436888  1678 sgd_solver.cpp:106] Iteration 36250, lr = 0.0005
I0523 12:34:39.443027  1678 solver.cpp:237] Iteration 36500, loss = 1.31946
I0523 12:34:39.443197  1678 solver.cpp:253]     Train net output #0: loss = 1.31946 (* 1 = 1.31946 loss)
I0523 12:34:39.443212  1678 sgd_solver.cpp:106] Iteration 36500, lr = 0.0005
I0523 12:35:09.401448  1678 solver.cpp:237] Iteration 36750, loss = 1.3526
I0523 12:35:09.401499  1678 solver.cpp:253]     Train net output #0: loss = 1.3526 (* 1 = 1.3526 loss)
I0523 12:35:09.401515  1678 sgd_solver.cpp:106] Iteration 36750, lr = 0.0005
I0523 12:35:18.411902  1678 solver.cpp:237] Iteration 37000, loss = 1.51614
I0523 12:35:18.412060  1678 solver.cpp:253]     Train net output #0: loss = 1.51614 (* 1 = 1.51614 loss)
I0523 12:35:18.412072  1678 sgd_solver.cpp:106] Iteration 37000, lr = 0.0005
I0523 12:35:27.426700  1678 solver.cpp:237] Iteration 37250, loss = 1.37379
I0523 12:35:27.426748  1678 solver.cpp:253]     Train net output #0: loss = 1.37379 (* 1 = 1.37379 loss)
I0523 12:35:27.426762  1678 sgd_solver.cpp:106] Iteration 37250, lr = 0.0005
I0523 12:35:36.395931  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_37500.caffemodel
I0523 12:35:36.460081  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_37500.solverstate
I0523 12:35:36.499614  1678 solver.cpp:237] Iteration 37500, loss = 1.41708
I0523 12:35:36.499660  1678 solver.cpp:253]     Train net output #0: loss = 1.41708 (* 1 = 1.41708 loss)
I0523 12:35:36.499686  1678 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0523 12:35:45.512202  1678 solver.cpp:237] Iteration 37750, loss = 1.15608
I0523 12:35:45.512236  1678 solver.cpp:253]     Train net output #0: loss = 1.15608 (* 1 = 1.15608 loss)
I0523 12:35:45.512251  1678 sgd_solver.cpp:106] Iteration 37750, lr = 0.0005
I0523 12:35:54.528064  1678 solver.cpp:237] Iteration 38000, loss = 1.42055
I0523 12:35:54.528235  1678 solver.cpp:253]     Train net output #0: loss = 1.42055 (* 1 = 1.42055 loss)
I0523 12:35:54.528250  1678 sgd_solver.cpp:106] Iteration 38000, lr = 0.0005
I0523 12:36:03.530644  1678 solver.cpp:237] Iteration 38250, loss = 1.68773
I0523 12:36:03.530678  1678 solver.cpp:253]     Train net output #0: loss = 1.68773 (* 1 = 1.68773 loss)
I0523 12:36:03.530694  1678 sgd_solver.cpp:106] Iteration 38250, lr = 0.0005
I0523 12:36:33.442065  1678 solver.cpp:237] Iteration 38500, loss = 1.24931
I0523 12:36:33.442239  1678 solver.cpp:253]     Train net output #0: loss = 1.24931 (* 1 = 1.24931 loss)
I0523 12:36:33.442255  1678 sgd_solver.cpp:106] Iteration 38500, lr = 0.0005
I0523 12:36:42.445736  1678 solver.cpp:237] Iteration 38750, loss = 1.22574
I0523 12:36:42.445777  1678 solver.cpp:253]     Train net output #0: loss = 1.22574 (* 1 = 1.22574 loss)
I0523 12:36:42.445797  1678 sgd_solver.cpp:106] Iteration 38750, lr = 0.0005
I0523 12:36:51.448557  1678 solver.cpp:237] Iteration 39000, loss = 1.1467
I0523 12:36:51.448593  1678 solver.cpp:253]     Train net output #0: loss = 1.1467 (* 1 = 1.1467 loss)
I0523 12:36:51.448607  1678 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0523 12:37:00.465811  1678 solver.cpp:237] Iteration 39250, loss = 1.43814
I0523 12:37:00.465844  1678 solver.cpp:253]     Train net output #0: loss = 1.43814 (* 1 = 1.43814 loss)
I0523 12:37:00.465862  1678 sgd_solver.cpp:106] Iteration 39250, lr = 0.0005
I0523 12:37:09.476346  1678 solver.cpp:237] Iteration 39500, loss = 1.09592
I0523 12:37:09.476536  1678 solver.cpp:253]     Train net output #0: loss = 1.09592 (* 1 = 1.09592 loss)
I0523 12:37:09.476550  1678 sgd_solver.cpp:106] Iteration 39500, lr = 0.0005
I0523 12:37:18.480481  1678 solver.cpp:237] Iteration 39750, loss = 1.20913
I0523 12:37:18.480515  1678 solver.cpp:253]     Train net output #0: loss = 1.20913 (* 1 = 1.20913 loss)
I0523 12:37:18.480531  1678 sgd_solver.cpp:106] Iteration 39750, lr = 0.0005
I0523 12:37:27.461931  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_40000.caffemodel
I0523 12:37:27.524646  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_40000.solverstate
I0523 12:37:27.551208  1678 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 12:38:35.683090  1678 solver.cpp:409]     Test net output #0: accuracy = 0.813848
I0523 12:38:35.683274  1678 solver.cpp:409]     Test net output #1: loss = 0.625496 (* 1 = 0.625496 loss)
I0523 12:38:56.574581  1678 solver.cpp:237] Iteration 40000, loss = 1.14985
I0523 12:38:56.574633  1678 solver.cpp:253]     Train net output #0: loss = 1.14985 (* 1 = 1.14985 loss)
I0523 12:38:56.574648  1678 sgd_solver.cpp:106] Iteration 40000, lr = 0.0005
I0523 12:39:05.613595  1678 solver.cpp:237] Iteration 40250, loss = 1.23504
I0523 12:39:05.613629  1678 solver.cpp:253]     Train net output #0: loss = 1.23504 (* 1 = 1.23504 loss)
I0523 12:39:05.613643  1678 sgd_solver.cpp:106] Iteration 40250, lr = 0.0005
I0523 12:39:14.647007  1678 solver.cpp:237] Iteration 40500, loss = 1.20661
I0523 12:39:14.647171  1678 solver.cpp:253]     Train net output #0: loss = 1.20661 (* 1 = 1.20661 loss)
I0523 12:39:14.647184  1678 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0523 12:39:23.694751  1678 solver.cpp:237] Iteration 40750, loss = 1.50764
I0523 12:39:23.694784  1678 solver.cpp:253]     Train net output #0: loss = 1.50764 (* 1 = 1.50764 loss)
I0523 12:39:23.694800  1678 sgd_solver.cpp:106] Iteration 40750, lr = 0.0005
I0523 12:39:32.732105  1678 solver.cpp:237] Iteration 41000, loss = 1.3925
I0523 12:39:32.732141  1678 solver.cpp:253]     Train net output #0: loss = 1.3925 (* 1 = 1.3925 loss)
I0523 12:39:32.732154  1678 sgd_solver.cpp:106] Iteration 41000, lr = 0.0005
I0523 12:39:41.773437  1678 solver.cpp:237] Iteration 41250, loss = 1.28091
I0523 12:39:41.773478  1678 solver.cpp:253]     Train net output #0: loss = 1.28091 (* 1 = 1.28091 loss)
I0523 12:39:41.773496  1678 sgd_solver.cpp:106] Iteration 41250, lr = 0.0005
I0523 12:39:50.816032  1678 solver.cpp:237] Iteration 41500, loss = 1.20838
I0523 12:39:50.816192  1678 solver.cpp:253]     Train net output #0: loss = 1.20838 (* 1 = 1.20838 loss)
I0523 12:39:50.816206  1678 sgd_solver.cpp:106] Iteration 41500, lr = 0.0005
I0523 12:40:20.754551  1678 solver.cpp:237] Iteration 41750, loss = 1.39974
I0523 12:40:20.754602  1678 solver.cpp:253]     Train net output #0: loss = 1.39974 (* 1 = 1.39974 loss)
I0523 12:40:20.754616  1678 sgd_solver.cpp:106] Iteration 41750, lr = 0.0005
I0523 12:40:29.801888  1678 solver.cpp:237] Iteration 42000, loss = 1.24541
I0523 12:40:29.802047  1678 solver.cpp:253]     Train net output #0: loss = 1.24541 (* 1 = 1.24541 loss)
I0523 12:40:29.802060  1678 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0523 12:40:38.846227  1678 solver.cpp:237] Iteration 42250, loss = 1.15168
I0523 12:40:38.846261  1678 solver.cpp:253]     Train net output #0: loss = 1.15168 (* 1 = 1.15168 loss)
I0523 12:40:38.846276  1678 sgd_solver.cpp:106] Iteration 42250, lr = 0.0005
I0523 12:40:47.853781  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_42500.caffemodel
I0523 12:40:47.917796  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_42500.solverstate
I0523 12:40:47.955549  1678 solver.cpp:237] Iteration 42500, loss = 1.2063
I0523 12:40:47.955590  1678 solver.cpp:253]     Train net output #0: loss = 1.2063 (* 1 = 1.2063 loss)
I0523 12:40:47.955610  1678 sgd_solver.cpp:106] Iteration 42500, lr = 0.0005
I0523 12:40:56.999534  1678 solver.cpp:237] Iteration 42750, loss = 1.36629
I0523 12:40:56.999574  1678 solver.cpp:253]     Train net output #0: loss = 1.36629 (* 1 = 1.36629 loss)
I0523 12:40:56.999590  1678 sgd_solver.cpp:106] Iteration 42750, lr = 0.0005
I0523 12:41:06.036162  1678 solver.cpp:237] Iteration 43000, loss = 1.49941
I0523 12:41:06.036327  1678 solver.cpp:253]     Train net output #0: loss = 1.49941 (* 1 = 1.49941 loss)
I0523 12:41:06.036341  1678 sgd_solver.cpp:106] Iteration 43000, lr = 0.0005
I0523 12:41:15.073938  1678 solver.cpp:237] Iteration 43250, loss = 1.35164
I0523 12:41:15.073973  1678 solver.cpp:253]     Train net output #0: loss = 1.35164 (* 1 = 1.35164 loss)
I0523 12:41:15.073987  1678 sgd_solver.cpp:106] Iteration 43250, lr = 0.0005
I0523 12:41:44.977113  1678 solver.cpp:237] Iteration 43500, loss = 1.31036
I0523 12:41:44.977294  1678 solver.cpp:253]     Train net output #0: loss = 1.31036 (* 1 = 1.31036 loss)
I0523 12:41:44.977309  1678 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0523 12:41:54.008460  1678 solver.cpp:237] Iteration 43750, loss = 1.48759
I0523 12:41:54.008496  1678 solver.cpp:253]     Train net output #0: loss = 1.48759 (* 1 = 1.48759 loss)
I0523 12:41:54.008510  1678 sgd_solver.cpp:106] Iteration 43750, lr = 0.0005
I0523 12:42:03.047629  1678 solver.cpp:237] Iteration 44000, loss = 1.43068
I0523 12:42:03.047664  1678 solver.cpp:253]     Train net output #0: loss = 1.43068 (* 1 = 1.43068 loss)
I0523 12:42:03.047683  1678 sgd_solver.cpp:106] Iteration 44000, lr = 0.0005
I0523 12:42:12.087484  1678 solver.cpp:237] Iteration 44250, loss = 1.3066
I0523 12:42:12.087529  1678 solver.cpp:253]     Train net output #0: loss = 1.3066 (* 1 = 1.3066 loss)
I0523 12:42:12.087545  1678 sgd_solver.cpp:106] Iteration 44250, lr = 0.0005
I0523 12:42:21.124259  1678 solver.cpp:237] Iteration 44500, loss = 1.45671
I0523 12:42:21.124413  1678 solver.cpp:253]     Train net output #0: loss = 1.45671 (* 1 = 1.45671 loss)
I0523 12:42:21.124428  1678 sgd_solver.cpp:106] Iteration 44500, lr = 0.0005
I0523 12:42:30.164985  1678 solver.cpp:237] Iteration 44750, loss = 1.3463
I0523 12:42:30.165019  1678 solver.cpp:253]     Train net output #0: loss = 1.3463 (* 1 = 1.3463 loss)
I0523 12:42:30.165035  1678 sgd_solver.cpp:106] Iteration 44750, lr = 0.0005
I0523 12:42:39.169492  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_45000.caffemodel
I0523 12:42:39.232532  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_45000.solverstate
I0523 12:42:39.259228  1678 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 12:43:26.542903  1678 solver.cpp:409]     Test net output #0: accuracy = 0.824222
I0523 12:43:26.543074  1678 solver.cpp:409]     Test net output #1: loss = 0.608991 (* 1 = 0.608991 loss)
I0523 12:43:47.451779  1678 solver.cpp:237] Iteration 45000, loss = 1.33237
I0523 12:43:47.451833  1678 solver.cpp:253]     Train net output #0: loss = 1.33237 (* 1 = 1.33237 loss)
I0523 12:43:47.451848  1678 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0523 12:43:56.445796  1678 solver.cpp:237] Iteration 45250, loss = 1.22146
I0523 12:43:56.445832  1678 solver.cpp:253]     Train net output #0: loss = 1.22146 (* 1 = 1.22146 loss)
I0523 12:43:56.445847  1678 sgd_solver.cpp:106] Iteration 45250, lr = 0.0005
I0523 12:44:05.449722  1678 solver.cpp:237] Iteration 45500, loss = 1.21429
I0523 12:44:05.449882  1678 solver.cpp:253]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0523 12:44:05.449895  1678 sgd_solver.cpp:106] Iteration 45500, lr = 0.0005
I0523 12:44:14.443146  1678 solver.cpp:237] Iteration 45750, loss = 1.28401
I0523 12:44:14.443193  1678 solver.cpp:253]     Train net output #0: loss = 1.28401 (* 1 = 1.28401 loss)
I0523 12:44:14.443208  1678 sgd_solver.cpp:106] Iteration 45750, lr = 0.0005
I0523 12:44:23.437270  1678 solver.cpp:237] Iteration 46000, loss = 1.22429
I0523 12:44:23.437306  1678 solver.cpp:253]     Train net output #0: loss = 1.22429 (* 1 = 1.22429 loss)
I0523 12:44:23.437320  1678 sgd_solver.cpp:106] Iteration 46000, lr = 0.0005
I0523 12:44:32.437638  1678 solver.cpp:237] Iteration 46250, loss = 1.53673
I0523 12:44:32.437669  1678 solver.cpp:253]     Train net output #0: loss = 1.53673 (* 1 = 1.53673 loss)
I0523 12:44:32.437681  1678 sgd_solver.cpp:106] Iteration 46250, lr = 0.0005
I0523 12:44:41.431898  1678 solver.cpp:237] Iteration 46500, loss = 1.11524
I0523 12:44:41.432072  1678 solver.cpp:253]     Train net output #0: loss = 1.11524 (* 1 = 1.11524 loss)
I0523 12:44:41.432087  1678 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0523 12:45:11.342373  1678 solver.cpp:237] Iteration 46750, loss = 1.33218
I0523 12:45:11.342424  1678 solver.cpp:253]     Train net output #0: loss = 1.33218 (* 1 = 1.33218 loss)
I0523 12:45:11.342438  1678 sgd_solver.cpp:106] Iteration 46750, lr = 0.0005
I0523 12:45:20.338032  1678 solver.cpp:237] Iteration 47000, loss = 1.84015
I0523 12:45:20.338196  1678 solver.cpp:253]     Train net output #0: loss = 1.84015 (* 1 = 1.84015 loss)
I0523 12:45:20.338208  1678 sgd_solver.cpp:106] Iteration 47000, lr = 0.0005
I0523 12:45:29.334527  1678 solver.cpp:237] Iteration 47250, loss = 1.38787
I0523 12:45:29.334568  1678 solver.cpp:253]     Train net output #0: loss = 1.38787 (* 1 = 1.38787 loss)
I0523 12:45:29.334588  1678 sgd_solver.cpp:106] Iteration 47250, lr = 0.0005
I0523 12:45:38.292090  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_47500.caffemodel
I0523 12:45:38.356026  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_47500.solverstate
I0523 12:45:38.395370  1678 solver.cpp:237] Iteration 47500, loss = 1.54699
I0523 12:45:38.395419  1678 solver.cpp:253]     Train net output #0: loss = 1.54699 (* 1 = 1.54699 loss)
I0523 12:45:38.395434  1678 sgd_solver.cpp:106] Iteration 47500, lr = 0.0005
I0523 12:45:47.391616  1678 solver.cpp:237] Iteration 47750, loss = 1.52092
I0523 12:45:47.391652  1678 solver.cpp:253]     Train net output #0: loss = 1.52092 (* 1 = 1.52092 loss)
I0523 12:45:47.391666  1678 sgd_solver.cpp:106] Iteration 47750, lr = 0.0005
I0523 12:45:56.394011  1678 solver.cpp:237] Iteration 48000, loss = 1.32564
I0523 12:45:56.394181  1678 solver.cpp:253]     Train net output #0: loss = 1.32564 (* 1 = 1.32564 loss)
I0523 12:45:56.394194  1678 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0523 12:46:05.386569  1678 solver.cpp:237] Iteration 48250, loss = 1.45308
I0523 12:46:05.386602  1678 solver.cpp:253]     Train net output #0: loss = 1.45308 (* 1 = 1.45308 loss)
I0523 12:46:05.386617  1678 sgd_solver.cpp:106] Iteration 48250, lr = 0.0005
I0523 12:46:35.308886  1678 solver.cpp:237] Iteration 48500, loss = 1.20139
I0523 12:46:35.309065  1678 solver.cpp:253]     Train net output #0: loss = 1.20139 (* 1 = 1.20139 loss)
I0523 12:46:35.309079  1678 sgd_solver.cpp:106] Iteration 48500, lr = 0.0005
I0523 12:46:44.305052  1678 solver.cpp:237] Iteration 48750, loss = 1.37562
I0523 12:46:44.305093  1678 solver.cpp:253]     Train net output #0: loss = 1.37562 (* 1 = 1.37562 loss)
I0523 12:46:44.305109  1678 sgd_solver.cpp:106] Iteration 48750, lr = 0.0005
I0523 12:46:53.296202  1678 solver.cpp:237] Iteration 49000, loss = 1.37495
I0523 12:46:53.296237  1678 solver.cpp:253]     Train net output #0: loss = 1.37495 (* 1 = 1.37495 loss)
I0523 12:46:53.296252  1678 sgd_solver.cpp:106] Iteration 49000, lr = 0.0005
I0523 12:47:02.291275  1678 solver.cpp:237] Iteration 49250, loss = 1.38777
I0523 12:47:02.291311  1678 solver.cpp:253]     Train net output #0: loss = 1.38777 (* 1 = 1.38777 loss)
I0523 12:47:02.291324  1678 sgd_solver.cpp:106] Iteration 49250, lr = 0.0005
I0523 12:47:11.284667  1678 solver.cpp:237] Iteration 49500, loss = 1.27608
I0523 12:47:11.284838  1678 solver.cpp:253]     Train net output #0: loss = 1.27608 (* 1 = 1.27608 loss)
I0523 12:47:11.284852  1678 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0523 12:47:20.283046  1678 solver.cpp:237] Iteration 49750, loss = 1.40159
I0523 12:47:20.283080  1678 solver.cpp:253]     Train net output #0: loss = 1.40159 (* 1 = 1.40159 loss)
I0523 12:47:20.283097  1678 sgd_solver.cpp:106] Iteration 49750, lr = 0.0005
I0523 12:47:29.248119  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_50000.caffemodel
I0523 12:47:29.314187  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_50000.solverstate
I0523 12:47:29.344226  1678 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 12:48:37.597676  1678 solver.cpp:409]     Test net output #0: accuracy = 0.831022
I0523 12:48:37.597863  1678 solver.cpp:409]     Test net output #1: loss = 0.583481 (* 1 = 0.583481 loss)
I0523 12:48:58.508184  1678 solver.cpp:237] Iteration 50000, loss = 1.16066
I0523 12:48:58.508237  1678 solver.cpp:253]     Train net output #0: loss = 1.16066 (* 1 = 1.16066 loss)
I0523 12:48:58.508252  1678 sgd_solver.cpp:106] Iteration 50000, lr = 0.0005
I0523 12:49:07.587940  1678 solver.cpp:237] Iteration 50250, loss = 1.19267
I0523 12:49:07.587975  1678 solver.cpp:253]     Train net output #0: loss = 1.19267 (* 1 = 1.19267 loss)
I0523 12:49:07.587990  1678 sgd_solver.cpp:106] Iteration 50250, lr = 0.0005
I0523 12:49:16.681644  1678 solver.cpp:237] Iteration 50500, loss = 1.66185
I0523 12:49:16.681819  1678 solver.cpp:253]     Train net output #0: loss = 1.66185 (* 1 = 1.66185 loss)
I0523 12:49:16.681834  1678 sgd_solver.cpp:106] Iteration 50500, lr = 0.0005
I0523 12:49:25.760553  1678 solver.cpp:237] Iteration 50750, loss = 1.44937
I0523 12:49:25.760588  1678 solver.cpp:253]     Train net output #0: loss = 1.44937 (* 1 = 1.44937 loss)
I0523 12:49:25.760603  1678 sgd_solver.cpp:106] Iteration 50750, lr = 0.0005
I0523 12:49:34.856577  1678 solver.cpp:237] Iteration 51000, loss = 1.47668
I0523 12:49:34.856611  1678 solver.cpp:253]     Train net output #0: loss = 1.47668 (* 1 = 1.47668 loss)
I0523 12:49:34.856626  1678 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0523 12:49:43.938047  1678 solver.cpp:237] Iteration 51250, loss = 1.34477
I0523 12:49:43.938086  1678 solver.cpp:253]     Train net output #0: loss = 1.34477 (* 1 = 1.34477 loss)
I0523 12:49:43.938105  1678 sgd_solver.cpp:106] Iteration 51250, lr = 0.0005
I0523 12:49:53.024878  1678 solver.cpp:237] Iteration 51500, loss = 1.09282
I0523 12:49:53.025030  1678 solver.cpp:253]     Train net output #0: loss = 1.09282 (* 1 = 1.09282 loss)
I0523 12:49:53.025044  1678 sgd_solver.cpp:106] Iteration 51500, lr = 0.0005
I0523 12:50:23.009737  1678 solver.cpp:237] Iteration 51750, loss = 1.10487
I0523 12:50:23.009788  1678 solver.cpp:253]     Train net output #0: loss = 1.10487 (* 1 = 1.10487 loss)
I0523 12:50:23.009804  1678 sgd_solver.cpp:106] Iteration 51750, lr = 0.0005
I0523 12:50:32.096006  1678 solver.cpp:237] Iteration 52000, loss = 1.17164
I0523 12:50:32.096174  1678 solver.cpp:253]     Train net output #0: loss = 1.17164 (* 1 = 1.17164 loss)
I0523 12:50:32.096189  1678 sgd_solver.cpp:106] Iteration 52000, lr = 0.0005
I0523 12:50:41.172166  1678 solver.cpp:237] Iteration 52250, loss = 1.48464
I0523 12:50:41.172199  1678 solver.cpp:253]     Train net output #0: loss = 1.48464 (* 1 = 1.48464 loss)
I0523 12:50:41.172215  1678 sgd_solver.cpp:106] Iteration 52250, lr = 0.0005
I0523 12:50:50.213928  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_52500.caffemodel
I0523 12:50:50.278901  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_52500.solverstate
I0523 12:50:50.316594  1678 solver.cpp:237] Iteration 52500, loss = 1.11017
I0523 12:50:50.316640  1678 solver.cpp:253]     Train net output #0: loss = 1.11017 (* 1 = 1.11017 loss)
I0523 12:50:50.316656  1678 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0523 12:50:59.406855  1678 solver.cpp:237] Iteration 52750, loss = 1.32343
I0523 12:50:59.406898  1678 solver.cpp:253]     Train net output #0: loss = 1.32343 (* 1 = 1.32343 loss)
I0523 12:50:59.406913  1678 sgd_solver.cpp:106] Iteration 52750, lr = 0.0005
I0523 12:51:08.499182  1678 solver.cpp:237] Iteration 53000, loss = 1.24653
I0523 12:51:08.499352  1678 solver.cpp:253]     Train net output #0: loss = 1.24653 (* 1 = 1.24653 loss)
I0523 12:51:08.499366  1678 sgd_solver.cpp:106] Iteration 53000, lr = 0.0005
I0523 12:51:17.585289  1678 solver.cpp:237] Iteration 53250, loss = 1.01513
I0523 12:51:17.585331  1678 solver.cpp:253]     Train net output #0: loss = 1.01513 (* 1 = 1.01513 loss)
I0523 12:51:17.585346  1678 sgd_solver.cpp:106] Iteration 53250, lr = 0.0005
I0523 12:51:47.523160  1678 solver.cpp:237] Iteration 53500, loss = 1.28114
I0523 12:51:47.523334  1678 solver.cpp:253]     Train net output #0: loss = 1.28114 (* 1 = 1.28114 loss)
I0523 12:51:47.523347  1678 sgd_solver.cpp:106] Iteration 53500, lr = 0.0005
I0523 12:51:56.611464  1678 solver.cpp:237] Iteration 53750, loss = 1.17218
I0523 12:51:56.611498  1678 solver.cpp:253]     Train net output #0: loss = 1.17218 (* 1 = 1.17218 loss)
I0523 12:51:56.611513  1678 sgd_solver.cpp:106] Iteration 53750, lr = 0.0005
I0523 12:52:05.684944  1678 solver.cpp:237] Iteration 54000, loss = 1.33647
I0523 12:52:05.684991  1678 solver.cpp:253]     Train net output #0: loss = 1.33647 (* 1 = 1.33647 loss)
I0523 12:52:05.685009  1678 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0523 12:52:14.763120  1678 solver.cpp:237] Iteration 54250, loss = 1.25167
I0523 12:52:14.763156  1678 solver.cpp:253]     Train net output #0: loss = 1.25167 (* 1 = 1.25167 loss)
I0523 12:52:14.763171  1678 sgd_solver.cpp:106] Iteration 54250, lr = 0.0005
I0523 12:52:23.852793  1678 solver.cpp:237] Iteration 54500, loss = 1.26972
I0523 12:52:23.852946  1678 solver.cpp:253]     Train net output #0: loss = 1.26972 (* 1 = 1.26972 loss)
I0523 12:52:23.852958  1678 sgd_solver.cpp:106] Iteration 54500, lr = 0.0005
I0523 12:52:32.942487  1678 solver.cpp:237] Iteration 54750, loss = 1.3055
I0523 12:52:32.942531  1678 solver.cpp:253]     Train net output #0: loss = 1.3055 (* 1 = 1.3055 loss)
I0523 12:52:32.942548  1678 sgd_solver.cpp:106] Iteration 54750, lr = 0.0005
I0523 12:52:41.980533  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_55000.caffemodel
I0523 12:52:42.043841  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_55000.solverstate
I0523 12:52:42.070339  1678 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 12:53:29.013041  1678 solver.cpp:409]     Test net output #0: accuracy = 0.834802
I0523 12:53:29.013216  1678 solver.cpp:409]     Test net output #1: loss = 0.536079 (* 1 = 0.536079 loss)
I0523 12:53:49.868599  1678 solver.cpp:237] Iteration 55000, loss = 1.236
I0523 12:53:49.868651  1678 solver.cpp:253]     Train net output #0: loss = 1.236 (* 1 = 1.236 loss)
I0523 12:53:49.868666  1678 sgd_solver.cpp:106] Iteration 55000, lr = 0.0005
I0523 12:53:58.961477  1678 solver.cpp:237] Iteration 55250, loss = 1.24743
I0523 12:53:58.961513  1678 solver.cpp:253]     Train net output #0: loss = 1.24743 (* 1 = 1.24743 loss)
I0523 12:53:58.961526  1678 sgd_solver.cpp:106] Iteration 55250, lr = 0.0005
I0523 12:54:08.053675  1678 solver.cpp:237] Iteration 55500, loss = 1.35406
I0523 12:54:08.053838  1678 solver.cpp:253]     Train net output #0: loss = 1.35406 (* 1 = 1.35406 loss)
I0523 12:54:08.053851  1678 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0523 12:54:17.151675  1678 solver.cpp:237] Iteration 55750, loss = 1.51233
I0523 12:54:17.151711  1678 solver.cpp:253]     Train net output #0: loss = 1.51233 (* 1 = 1.51233 loss)
I0523 12:54:17.151723  1678 sgd_solver.cpp:106] Iteration 55750, lr = 0.0005
I0523 12:54:26.247014  1678 solver.cpp:237] Iteration 56000, loss = 1.36957
I0523 12:54:26.247048  1678 solver.cpp:253]     Train net output #0: loss = 1.36957 (* 1 = 1.36957 loss)
I0523 12:54:26.247063  1678 sgd_solver.cpp:106] Iteration 56000, lr = 0.0005
I0523 12:54:35.343236  1678 solver.cpp:237] Iteration 56250, loss = 1.24842
I0523 12:54:35.343271  1678 solver.cpp:253]     Train net output #0: loss = 1.24842 (* 1 = 1.24842 loss)
I0523 12:54:35.343286  1678 sgd_solver.cpp:106] Iteration 56250, lr = 0.0005
I0523 12:54:44.437999  1678 solver.cpp:237] Iteration 56500, loss = 1.25481
I0523 12:54:44.438156  1678 solver.cpp:253]     Train net output #0: loss = 1.25481 (* 1 = 1.25481 loss)
I0523 12:54:44.438170  1678 sgd_solver.cpp:106] Iteration 56500, lr = 0.0005
I0523 12:55:14.427069  1678 solver.cpp:237] Iteration 56750, loss = 1.34165
I0523 12:55:14.427119  1678 solver.cpp:253]     Train net output #0: loss = 1.34165 (* 1 = 1.34165 loss)
I0523 12:55:14.427134  1678 sgd_solver.cpp:106] Iteration 56750, lr = 0.0005
I0523 12:55:23.520225  1678 solver.cpp:237] Iteration 57000, loss = 1.1769
I0523 12:55:23.520385  1678 solver.cpp:253]     Train net output #0: loss = 1.1769 (* 1 = 1.1769 loss)
I0523 12:55:23.520397  1678 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0523 12:55:32.625639  1678 solver.cpp:237] Iteration 57250, loss = 1.53089
I0523 12:55:32.625684  1678 solver.cpp:253]     Train net output #0: loss = 1.53089 (* 1 = 1.53089 loss)
I0523 12:55:32.625699  1678 sgd_solver.cpp:106] Iteration 57250, lr = 0.0005
I0523 12:55:41.687988  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_57500.caffemodel
I0523 12:55:41.752596  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_57500.solverstate
I0523 12:55:41.790662  1678 solver.cpp:237] Iteration 57500, loss = 1.33622
I0523 12:55:41.790704  1678 solver.cpp:253]     Train net output #0: loss = 1.33622 (* 1 = 1.33622 loss)
I0523 12:55:41.790717  1678 sgd_solver.cpp:106] Iteration 57500, lr = 0.0005
I0523 12:55:50.892554  1678 solver.cpp:237] Iteration 57750, loss = 1.12412
I0523 12:55:50.892597  1678 solver.cpp:253]     Train net output #0: loss = 1.12412 (* 1 = 1.12412 loss)
I0523 12:55:50.892611  1678 sgd_solver.cpp:106] Iteration 57750, lr = 0.0005
I0523 12:55:59.995925  1678 solver.cpp:237] Iteration 58000, loss = 1.44508
I0523 12:55:59.996094  1678 solver.cpp:253]     Train net output #0: loss = 1.44508 (* 1 = 1.44508 loss)
I0523 12:55:59.996109  1678 sgd_solver.cpp:106] Iteration 58000, lr = 0.0005
I0523 12:56:09.094849  1678 solver.cpp:237] Iteration 58250, loss = 1.1519
I0523 12:56:09.094883  1678 solver.cpp:253]     Train net output #0: loss = 1.1519 (* 1 = 1.1519 loss)
I0523 12:56:09.094898  1678 sgd_solver.cpp:106] Iteration 58250, lr = 0.0005
I0523 12:56:39.126174  1678 solver.cpp:237] Iteration 58500, loss = 1.4695
I0523 12:56:39.126353  1678 solver.cpp:253]     Train net output #0: loss = 1.4695 (* 1 = 1.4695 loss)
I0523 12:56:39.126369  1678 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0523 12:56:48.221362  1678 solver.cpp:237] Iteration 58750, loss = 1.20112
I0523 12:56:48.221402  1678 solver.cpp:253]     Train net output #0: loss = 1.20112 (* 1 = 1.20112 loss)
I0523 12:56:48.221420  1678 sgd_solver.cpp:106] Iteration 58750, lr = 0.0005
I0523 12:56:57.320909  1678 solver.cpp:237] Iteration 59000, loss = 1.31757
I0523 12:56:57.320942  1678 solver.cpp:253]     Train net output #0: loss = 1.31757 (* 1 = 1.31757 loss)
I0523 12:56:57.320958  1678 sgd_solver.cpp:106] Iteration 59000, lr = 0.0005
I0523 12:57:06.416697  1678 solver.cpp:237] Iteration 59250, loss = 1.35407
I0523 12:57:06.416743  1678 solver.cpp:253]     Train net output #0: loss = 1.35407 (* 1 = 1.35407 loss)
I0523 12:57:06.416756  1678 sgd_solver.cpp:106] Iteration 59250, lr = 0.0005
I0523 12:57:15.522374  1678 solver.cpp:237] Iteration 59500, loss = 1.28864
I0523 12:57:15.522552  1678 solver.cpp:253]     Train net output #0: loss = 1.28864 (* 1 = 1.28864 loss)
I0523 12:57:15.522564  1678 sgd_solver.cpp:106] Iteration 59500, lr = 0.0005
I0523 12:57:24.629226  1678 solver.cpp:237] Iteration 59750, loss = 1.0413
I0523 12:57:24.629261  1678 solver.cpp:253]     Train net output #0: loss = 1.0413 (* 1 = 1.0413 loss)
I0523 12:57:24.629276  1678 sgd_solver.cpp:106] Iteration 59750, lr = 0.0005
I0523 12:57:33.691704  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_60000.caffemodel
I0523 12:57:33.755210  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_60000.solverstate
I0523 12:57:33.781772  1678 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 12:58:41.983239  1678 solver.cpp:409]     Test net output #0: accuracy = 0.840902
I0523 12:58:41.983425  1678 solver.cpp:409]     Test net output #1: loss = 0.552104 (* 1 = 0.552104 loss)
I0523 12:59:02.873634  1678 solver.cpp:237] Iteration 60000, loss = 1.43631
I0523 12:59:02.873687  1678 solver.cpp:253]     Train net output #0: loss = 1.43631 (* 1 = 1.43631 loss)
I0523 12:59:02.873703  1678 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0523 12:59:11.843528  1678 solver.cpp:237] Iteration 60250, loss = 1.23861
I0523 12:59:11.843575  1678 solver.cpp:253]     Train net output #0: loss = 1.23861 (* 1 = 1.23861 loss)
I0523 12:59:11.843590  1678 sgd_solver.cpp:106] Iteration 60250, lr = 0.0005
I0523 12:59:20.812824  1678 solver.cpp:237] Iteration 60500, loss = 1.30647
I0523 12:59:20.812988  1678 solver.cpp:253]     Train net output #0: loss = 1.30647 (* 1 = 1.30647 loss)
I0523 12:59:20.813000  1678 sgd_solver.cpp:106] Iteration 60500, lr = 0.0005
I0523 12:59:29.786309  1678 solver.cpp:237] Iteration 60750, loss = 1.33549
I0523 12:59:29.786342  1678 solver.cpp:253]     Train net output #0: loss = 1.33549 (* 1 = 1.33549 loss)
I0523 12:59:29.786357  1678 sgd_solver.cpp:106] Iteration 60750, lr = 0.0005
I0523 12:59:38.754853  1678 solver.cpp:237] Iteration 61000, loss = 1.30274
I0523 12:59:38.754899  1678 solver.cpp:253]     Train net output #0: loss = 1.30274 (* 1 = 1.30274 loss)
I0523 12:59:38.754914  1678 sgd_solver.cpp:106] Iteration 61000, lr = 0.0005
I0523 12:59:47.728562  1678 solver.cpp:237] Iteration 61250, loss = 1.21553
I0523 12:59:47.728597  1678 solver.cpp:253]     Train net output #0: loss = 1.21553 (* 1 = 1.21553 loss)
I0523 12:59:47.728611  1678 sgd_solver.cpp:106] Iteration 61250, lr = 0.0005
I0523 12:59:56.697686  1678 solver.cpp:237] Iteration 61500, loss = 1.30358
I0523 12:59:56.697846  1678 solver.cpp:253]     Train net output #0: loss = 1.30358 (* 1 = 1.30358 loss)
I0523 12:59:56.697860  1678 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0523 13:00:26.570549  1678 solver.cpp:237] Iteration 61750, loss = 1.27547
I0523 13:00:26.570600  1678 solver.cpp:253]     Train net output #0: loss = 1.27547 (* 1 = 1.27547 loss)
I0523 13:00:26.570616  1678 sgd_solver.cpp:106] Iteration 61750, lr = 0.0005
I0523 13:00:35.537510  1678 solver.cpp:237] Iteration 62000, loss = 1.26494
I0523 13:00:35.537672  1678 solver.cpp:253]     Train net output #0: loss = 1.26494 (* 1 = 1.26494 loss)
I0523 13:00:35.537686  1678 sgd_solver.cpp:106] Iteration 62000, lr = 0.0005
I0523 13:00:44.509819  1678 solver.cpp:237] Iteration 62250, loss = 1.35896
I0523 13:00:44.509853  1678 solver.cpp:253]     Train net output #0: loss = 1.35896 (* 1 = 1.35896 loss)
I0523 13:00:44.509870  1678 sgd_solver.cpp:106] Iteration 62250, lr = 0.0005
I0523 13:00:53.447567  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_62500.caffemodel
I0523 13:00:53.512634  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_62500.solverstate
I0523 13:00:53.553903  1678 solver.cpp:237] Iteration 62500, loss = 1.26182
I0523 13:00:53.553953  1678 solver.cpp:253]     Train net output #0: loss = 1.26182 (* 1 = 1.26182 loss)
I0523 13:00:53.553968  1678 sgd_solver.cpp:106] Iteration 62500, lr = 0.0005
I0523 13:01:02.530709  1678 solver.cpp:237] Iteration 62750, loss = 1.2937
I0523 13:01:02.530743  1678 solver.cpp:253]     Train net output #0: loss = 1.2937 (* 1 = 1.2937 loss)
I0523 13:01:02.530758  1678 sgd_solver.cpp:106] Iteration 62750, lr = 0.0005
I0523 13:01:11.505066  1678 solver.cpp:237] Iteration 63000, loss = 1.55927
I0523 13:01:11.505240  1678 solver.cpp:253]     Train net output #0: loss = 1.55927 (* 1 = 1.55927 loss)
I0523 13:01:11.505254  1678 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0523 13:01:20.469461  1678 solver.cpp:237] Iteration 63250, loss = 1.67214
I0523 13:01:20.469506  1678 solver.cpp:253]     Train net output #0: loss = 1.67214 (* 1 = 1.67214 loss)
I0523 13:01:20.469523  1678 sgd_solver.cpp:106] Iteration 63250, lr = 0.0005
I0523 13:01:50.393419  1678 solver.cpp:237] Iteration 63500, loss = 1.31049
I0523 13:01:50.393604  1678 solver.cpp:253]     Train net output #0: loss = 1.31049 (* 1 = 1.31049 loss)
I0523 13:01:50.393617  1678 sgd_solver.cpp:106] Iteration 63500, lr = 0.0005
I0523 13:01:59.368604  1678 solver.cpp:237] Iteration 63750, loss = 1.28408
I0523 13:01:59.368638  1678 solver.cpp:253]     Train net output #0: loss = 1.28408 (* 1 = 1.28408 loss)
I0523 13:01:59.368655  1678 sgd_solver.cpp:106] Iteration 63750, lr = 0.0005
I0523 13:02:08.340131  1678 solver.cpp:237] Iteration 64000, loss = 1.26248
I0523 13:02:08.340173  1678 solver.cpp:253]     Train net output #0: loss = 1.26248 (* 1 = 1.26248 loss)
I0523 13:02:08.340193  1678 sgd_solver.cpp:106] Iteration 64000, lr = 0.0005
I0523 13:02:17.308490  1678 solver.cpp:237] Iteration 64250, loss = 1.27436
I0523 13:02:17.308526  1678 solver.cpp:253]     Train net output #0: loss = 1.27436 (* 1 = 1.27436 loss)
I0523 13:02:17.308542  1678 sgd_solver.cpp:106] Iteration 64250, lr = 0.0005
I0523 13:02:26.281826  1678 solver.cpp:237] Iteration 64500, loss = 1.356
I0523 13:02:26.281985  1678 solver.cpp:253]     Train net output #0: loss = 1.356 (* 1 = 1.356 loss)
I0523 13:02:26.281998  1678 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0523 13:02:35.257267  1678 solver.cpp:237] Iteration 64750, loss = 1.14918
I0523 13:02:35.257311  1678 solver.cpp:253]     Train net output #0: loss = 1.14918 (* 1 = 1.14918 loss)
I0523 13:02:35.257324  1678 sgd_solver.cpp:106] Iteration 64750, lr = 0.0005
I0523 13:02:44.196017  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_65000.caffemodel
I0523 13:02:44.259584  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_65000.solverstate
I0523 13:02:44.286144  1678 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 13:03:31.644273  1678 solver.cpp:409]     Test net output #0: accuracy = 0.838969
I0523 13:03:31.644451  1678 solver.cpp:409]     Test net output #1: loss = 0.503328 (* 1 = 0.503328 loss)
I0523 13:03:52.599066  1678 solver.cpp:237] Iteration 65000, loss = 1.15755
I0523 13:03:52.599119  1678 solver.cpp:253]     Train net output #0: loss = 1.15755 (* 1 = 1.15755 loss)
I0523 13:03:52.599134  1678 sgd_solver.cpp:106] Iteration 65000, lr = 0.0005
I0523 13:04:01.614367  1678 solver.cpp:237] Iteration 65250, loss = 1.25176
I0523 13:04:01.614403  1678 solver.cpp:253]     Train net output #0: loss = 1.25176 (* 1 = 1.25176 loss)
I0523 13:04:01.614418  1678 sgd_solver.cpp:106] Iteration 65250, lr = 0.0005
I0523 13:04:10.625723  1678 solver.cpp:237] Iteration 65500, loss = 1.30485
I0523 13:04:10.625900  1678 solver.cpp:253]     Train net output #0: loss = 1.30485 (* 1 = 1.30485 loss)
I0523 13:04:10.625915  1678 sgd_solver.cpp:106] Iteration 65500, lr = 0.0005
I0523 13:04:19.634671  1678 solver.cpp:237] Iteration 65750, loss = 1.34135
I0523 13:04:19.634706  1678 solver.cpp:253]     Train net output #0: loss = 1.34135 (* 1 = 1.34135 loss)
I0523 13:04:19.634721  1678 sgd_solver.cpp:106] Iteration 65750, lr = 0.0005
I0523 13:04:28.642951  1678 solver.cpp:237] Iteration 66000, loss = 1.20676
I0523 13:04:28.642985  1678 solver.cpp:253]     Train net output #0: loss = 1.20676 (* 1 = 1.20676 loss)
I0523 13:04:28.643000  1678 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0523 13:04:37.656723  1678 solver.cpp:237] Iteration 66250, loss = 1.4082
I0523 13:04:37.656761  1678 solver.cpp:253]     Train net output #0: loss = 1.4082 (* 1 = 1.4082 loss)
I0523 13:04:37.656782  1678 sgd_solver.cpp:106] Iteration 66250, lr = 0.0005
I0523 13:04:46.661494  1678 solver.cpp:237] Iteration 66500, loss = 1.18972
I0523 13:04:46.661654  1678 solver.cpp:253]     Train net output #0: loss = 1.18972 (* 1 = 1.18972 loss)
I0523 13:04:46.661667  1678 sgd_solver.cpp:106] Iteration 66500, lr = 0.0005
I0523 13:05:16.649147  1678 solver.cpp:237] Iteration 66750, loss = 1.32441
I0523 13:05:16.649196  1678 solver.cpp:253]     Train net output #0: loss = 1.32441 (* 1 = 1.32441 loss)
I0523 13:05:16.649212  1678 sgd_solver.cpp:106] Iteration 66750, lr = 0.0005
I0523 13:05:25.664926  1678 solver.cpp:237] Iteration 67000, loss = 1.14237
I0523 13:05:25.665092  1678 solver.cpp:253]     Train net output #0: loss = 1.14237 (* 1 = 1.14237 loss)
I0523 13:05:25.665107  1678 sgd_solver.cpp:106] Iteration 67000, lr = 0.0005
I0523 13:05:34.673104  1678 solver.cpp:237] Iteration 67250, loss = 1.12388
I0523 13:05:34.673137  1678 solver.cpp:253]     Train net output #0: loss = 1.12388 (* 1 = 1.12388 loss)
I0523 13:05:34.673153  1678 sgd_solver.cpp:106] Iteration 67250, lr = 0.0005
I0523 13:05:43.648696  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_67500.caffemodel
I0523 13:05:43.711046  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_67500.solverstate
I0523 13:05:43.748725  1678 solver.cpp:237] Iteration 67500, loss = 1.18802
I0523 13:05:43.748767  1678 solver.cpp:253]     Train net output #0: loss = 1.18802 (* 1 = 1.18802 loss)
I0523 13:05:43.748788  1678 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0523 13:05:52.753983  1678 solver.cpp:237] Iteration 67750, loss = 1.36116
I0523 13:05:52.754029  1678 solver.cpp:253]     Train net output #0: loss = 1.36116 (* 1 = 1.36116 loss)
I0523 13:05:52.754045  1678 sgd_solver.cpp:106] Iteration 67750, lr = 0.0005
I0523 13:06:01.761912  1678 solver.cpp:237] Iteration 68000, loss = 1.15809
I0523 13:06:01.762086  1678 solver.cpp:253]     Train net output #0: loss = 1.15809 (* 1 = 1.15809 loss)
I0523 13:06:01.762100  1678 sgd_solver.cpp:106] Iteration 68000, lr = 0.0005
I0523 13:06:10.769047  1678 solver.cpp:237] Iteration 68250, loss = 1.06586
I0523 13:06:10.769080  1678 solver.cpp:253]     Train net output #0: loss = 1.06586 (* 1 = 1.06586 loss)
I0523 13:06:10.769096  1678 sgd_solver.cpp:106] Iteration 68250, lr = 0.0005
I0523 13:06:40.689988  1678 solver.cpp:237] Iteration 68500, loss = 1.08571
I0523 13:06:40.690182  1678 solver.cpp:253]     Train net output #0: loss = 1.08571 (* 1 = 1.08571 loss)
I0523 13:06:40.690196  1678 sgd_solver.cpp:106] Iteration 68500, lr = 0.0005
I0523 13:06:49.700055  1678 solver.cpp:237] Iteration 68750, loss = 1.32366
I0523 13:06:49.700089  1678 solver.cpp:253]     Train net output #0: loss = 1.32366 (* 1 = 1.32366 loss)
I0523 13:06:49.700105  1678 sgd_solver.cpp:106] Iteration 68750, lr = 0.0005
I0523 13:06:58.717814  1678 solver.cpp:237] Iteration 69000, loss = 1.34241
I0523 13:06:58.717849  1678 solver.cpp:253]     Train net output #0: loss = 1.34241 (* 1 = 1.34241 loss)
I0523 13:06:58.717864  1678 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0523 13:07:07.729900  1678 solver.cpp:237] Iteration 69250, loss = 1.3763
I0523 13:07:07.729943  1678 solver.cpp:253]     Train net output #0: loss = 1.3763 (* 1 = 1.3763 loss)
I0523 13:07:07.729961  1678 sgd_solver.cpp:106] Iteration 69250, lr = 0.0005
I0523 13:07:16.745177  1678 solver.cpp:237] Iteration 69500, loss = 1.29113
I0523 13:07:16.745339  1678 solver.cpp:253]     Train net output #0: loss = 1.29113 (* 1 = 1.29113 loss)
I0523 13:07:16.745353  1678 sgd_solver.cpp:106] Iteration 69500, lr = 0.0005
I0523 13:07:25.754024  1678 solver.cpp:237] Iteration 69750, loss = 1.47222
I0523 13:07:25.754060  1678 solver.cpp:253]     Train net output #0: loss = 1.47222 (* 1 = 1.47222 loss)
I0523 13:07:25.754076  1678 sgd_solver.cpp:106] Iteration 69750, lr = 0.0005
I0523 13:07:34.722412  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_70000.caffemodel
I0523 13:07:34.784916  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_70000.solverstate
I0523 13:07:34.811486  1678 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 13:08:42.959583  1678 solver.cpp:409]     Test net output #0: accuracy = 0.846167
I0523 13:08:42.959775  1678 solver.cpp:409]     Test net output #1: loss = 0.504431 (* 1 = 0.504431 loss)
I0523 13:09:03.806813  1678 solver.cpp:237] Iteration 70000, loss = 1.33197
I0523 13:09:03.806867  1678 solver.cpp:253]     Train net output #0: loss = 1.33197 (* 1 = 1.33197 loss)
I0523 13:09:03.806881  1678 sgd_solver.cpp:106] Iteration 70000, lr = 0.0005
I0523 13:09:12.846494  1678 solver.cpp:237] Iteration 70250, loss = 1.33935
I0523 13:09:12.846537  1678 solver.cpp:253]     Train net output #0: loss = 1.33935 (* 1 = 1.33935 loss)
I0523 13:09:12.846554  1678 sgd_solver.cpp:106] Iteration 70250, lr = 0.0005
I0523 13:09:21.880060  1678 solver.cpp:237] Iteration 70500, loss = 1.15412
I0523 13:09:21.880229  1678 solver.cpp:253]     Train net output #0: loss = 1.15412 (* 1 = 1.15412 loss)
I0523 13:09:21.880244  1678 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0523 13:09:30.917531  1678 solver.cpp:237] Iteration 70750, loss = 0.964539
I0523 13:09:30.917565  1678 solver.cpp:253]     Train net output #0: loss = 0.964539 (* 1 = 0.964539 loss)
I0523 13:09:30.917580  1678 sgd_solver.cpp:106] Iteration 70750, lr = 0.0005
I0523 13:09:39.954254  1678 solver.cpp:237] Iteration 71000, loss = 1.24968
I0523 13:09:39.954298  1678 solver.cpp:253]     Train net output #0: loss = 1.24968 (* 1 = 1.24968 loss)
I0523 13:09:39.954314  1678 sgd_solver.cpp:106] Iteration 71000, lr = 0.0005
I0523 13:09:48.995332  1678 solver.cpp:237] Iteration 71250, loss = 1.39964
I0523 13:09:48.995368  1678 solver.cpp:253]     Train net output #0: loss = 1.39964 (* 1 = 1.39964 loss)
I0523 13:09:48.995383  1678 sgd_solver.cpp:106] Iteration 71250, lr = 0.0005
I0523 13:09:58.036705  1678 solver.cpp:237] Iteration 71500, loss = 1.30148
I0523 13:09:58.036867  1678 solver.cpp:253]     Train net output #0: loss = 1.30148 (* 1 = 1.30148 loss)
I0523 13:09:58.036881  1678 sgd_solver.cpp:106] Iteration 71500, lr = 0.0005
I0523 13:10:27.954915  1678 solver.cpp:237] Iteration 71750, loss = 1.28454
I0523 13:10:27.954964  1678 solver.cpp:253]     Train net output #0: loss = 1.28454 (* 1 = 1.28454 loss)
I0523 13:10:27.954979  1678 sgd_solver.cpp:106] Iteration 71750, lr = 0.0005
I0523 13:10:36.990594  1678 solver.cpp:237] Iteration 72000, loss = 1.37396
I0523 13:10:36.990767  1678 solver.cpp:253]     Train net output #0: loss = 1.37396 (* 1 = 1.37396 loss)
I0523 13:10:36.990782  1678 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0523 13:10:46.040933  1678 solver.cpp:237] Iteration 72250, loss = 1.08999
I0523 13:10:46.040967  1678 solver.cpp:253]     Train net output #0: loss = 1.08999 (* 1 = 1.08999 loss)
I0523 13:10:46.040982  1678 sgd_solver.cpp:106] Iteration 72250, lr = 0.0005
I0523 13:10:55.041718  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_72500.caffemodel
I0523 13:10:55.106834  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_72500.solverstate
I0523 13:10:55.145879  1678 solver.cpp:237] Iteration 72500, loss = 1.46662
I0523 13:10:55.145931  1678 solver.cpp:253]     Train net output #0: loss = 1.46662 (* 1 = 1.46662 loss)
I0523 13:10:55.145946  1678 sgd_solver.cpp:106] Iteration 72500, lr = 0.0005
I0523 13:11:04.182351  1678 solver.cpp:237] Iteration 72750, loss = 1.4043
I0523 13:11:04.182387  1678 solver.cpp:253]     Train net output #0: loss = 1.4043 (* 1 = 1.4043 loss)
I0523 13:11:04.182401  1678 sgd_solver.cpp:106] Iteration 72750, lr = 0.0005
I0523 13:11:13.216423  1678 solver.cpp:237] Iteration 73000, loss = 1.40185
I0523 13:11:13.216594  1678 solver.cpp:253]     Train net output #0: loss = 1.40185 (* 1 = 1.40185 loss)
I0523 13:11:13.216609  1678 sgd_solver.cpp:106] Iteration 73000, lr = 0.0005
I0523 13:11:22.251047  1678 solver.cpp:237] Iteration 73250, loss = 1.19591
I0523 13:11:22.251096  1678 solver.cpp:253]     Train net output #0: loss = 1.19591 (* 1 = 1.19591 loss)
I0523 13:11:22.251111  1678 sgd_solver.cpp:106] Iteration 73250, lr = 0.0005
I0523 13:11:52.216727  1678 solver.cpp:237] Iteration 73500, loss = 1.24595
I0523 13:11:52.216914  1678 solver.cpp:253]     Train net output #0: loss = 1.24595 (* 1 = 1.24595 loss)
I0523 13:11:52.216929  1678 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I0523 13:12:01.256772  1678 solver.cpp:237] Iteration 73750, loss = 1.29795
I0523 13:12:01.256808  1678 solver.cpp:253]     Train net output #0: loss = 1.29795 (* 1 = 1.29795 loss)
I0523 13:12:01.256821  1678 sgd_solver.cpp:106] Iteration 73750, lr = 0.0005
I0523 13:12:10.299263  1678 solver.cpp:237] Iteration 74000, loss = 1.30692
I0523 13:12:10.299309  1678 solver.cpp:253]     Train net output #0: loss = 1.30692 (* 1 = 1.30692 loss)
I0523 13:12:10.299324  1678 sgd_solver.cpp:106] Iteration 74000, lr = 0.0005
I0523 13:12:19.338748  1678 solver.cpp:237] Iteration 74250, loss = 1.20348
I0523 13:12:19.338784  1678 solver.cpp:253]     Train net output #0: loss = 1.20348 (* 1 = 1.20348 loss)
I0523 13:12:19.338799  1678 sgd_solver.cpp:106] Iteration 74250, lr = 0.0005
I0523 13:12:28.376276  1678 solver.cpp:237] Iteration 74500, loss = 1.11834
I0523 13:12:28.376441  1678 solver.cpp:253]     Train net output #0: loss = 1.11834 (* 1 = 1.11834 loss)
I0523 13:12:28.376454  1678 sgd_solver.cpp:106] Iteration 74500, lr = 0.0005
I0523 13:12:37.405274  1678 solver.cpp:237] Iteration 74750, loss = 1.22971
I0523 13:12:37.405321  1678 solver.cpp:253]     Train net output #0: loss = 1.22971 (* 1 = 1.22971 loss)
I0523 13:12:37.405336  1678 sgd_solver.cpp:106] Iteration 74750, lr = 0.0005
I0523 13:12:46.406064  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_75000.caffemodel
I0523 13:12:46.469969  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_75000.solverstate
I0523 13:12:46.499892  1678 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 13:13:33.539618  1678 solver.cpp:409]     Test net output #0: accuracy = 0.849635
I0523 13:13:33.539814  1678 solver.cpp:409]     Test net output #1: loss = 0.505256 (* 1 = 0.505256 loss)
I0523 13:13:54.477260  1678 solver.cpp:237] Iteration 75000, loss = 1.2368
I0523 13:13:54.477313  1678 solver.cpp:253]     Train net output #0: loss = 1.2368 (* 1 = 1.2368 loss)
I0523 13:13:54.477329  1678 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I0523 13:14:03.474289  1678 solver.cpp:237] Iteration 75250, loss = 1.17018
I0523 13:14:03.474326  1678 solver.cpp:253]     Train net output #0: loss = 1.17018 (* 1 = 1.17018 loss)
I0523 13:14:03.474341  1678 sgd_solver.cpp:106] Iteration 75250, lr = 0.0005
I0523 13:14:12.474741  1678 solver.cpp:237] Iteration 75500, loss = 1.35377
I0523 13:14:12.474921  1678 solver.cpp:253]     Train net output #0: loss = 1.35377 (* 1 = 1.35377 loss)
I0523 13:14:12.474936  1678 sgd_solver.cpp:106] Iteration 75500, lr = 0.0005
I0523 13:14:21.472306  1678 solver.cpp:237] Iteration 75750, loss = 1.03588
I0523 13:14:21.472342  1678 solver.cpp:253]     Train net output #0: loss = 1.03588 (* 1 = 1.03588 loss)
I0523 13:14:21.472357  1678 sgd_solver.cpp:106] Iteration 75750, lr = 0.0005
I0523 13:14:30.473623  1678 solver.cpp:237] Iteration 76000, loss = 1.13852
I0523 13:14:30.473659  1678 solver.cpp:253]     Train net output #0: loss = 1.13852 (* 1 = 1.13852 loss)
I0523 13:14:30.473673  1678 sgd_solver.cpp:106] Iteration 76000, lr = 0.0005
I0523 13:14:39.473942  1678 solver.cpp:237] Iteration 76250, loss = 1.17723
I0523 13:14:39.473985  1678 solver.cpp:253]     Train net output #0: loss = 1.17723 (* 1 = 1.17723 loss)
I0523 13:14:39.474004  1678 sgd_solver.cpp:106] Iteration 76250, lr = 0.0005
I0523 13:14:48.463819  1678 solver.cpp:237] Iteration 76500, loss = 1.5224
I0523 13:14:48.463984  1678 solver.cpp:253]     Train net output #0: loss = 1.5224 (* 1 = 1.5224 loss)
I0523 13:14:48.463996  1678 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I0523 13:15:18.370767  1678 solver.cpp:237] Iteration 76750, loss = 1.47185
I0523 13:15:18.370816  1678 solver.cpp:253]     Train net output #0: loss = 1.47185 (* 1 = 1.47185 loss)
I0523 13:15:18.370832  1678 sgd_solver.cpp:106] Iteration 76750, lr = 0.0005
I0523 13:15:27.357802  1678 solver.cpp:237] Iteration 77000, loss = 1.21098
I0523 13:15:27.357982  1678 solver.cpp:253]     Train net output #0: loss = 1.21098 (* 1 = 1.21098 loss)
I0523 13:15:27.357996  1678 sgd_solver.cpp:106] Iteration 77000, lr = 0.0005
I0523 13:15:36.357223  1678 solver.cpp:237] Iteration 77250, loss = 1.46332
I0523 13:15:36.357256  1678 solver.cpp:253]     Train net output #0: loss = 1.46332 (* 1 = 1.46332 loss)
I0523 13:15:36.357272  1678 sgd_solver.cpp:106] Iteration 77250, lr = 0.0005
I0523 13:15:45.321204  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_77500.caffemodel
I0523 13:15:45.384696  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_77500.solverstate
I0523 13:15:45.422485  1678 solver.cpp:237] Iteration 77500, loss = 1.05122
I0523 13:15:45.422530  1678 solver.cpp:253]     Train net output #0: loss = 1.05122 (* 1 = 1.05122 loss)
I0523 13:15:45.422545  1678 sgd_solver.cpp:106] Iteration 77500, lr = 0.0005
I0523 13:15:54.416333  1678 solver.cpp:237] Iteration 77750, loss = 1.1282
I0523 13:15:54.416379  1678 solver.cpp:253]     Train net output #0: loss = 1.1282 (* 1 = 1.1282 loss)
I0523 13:15:54.416393  1678 sgd_solver.cpp:106] Iteration 77750, lr = 0.0005
I0523 13:16:03.406644  1678 solver.cpp:237] Iteration 78000, loss = 1.29698
I0523 13:16:03.406813  1678 solver.cpp:253]     Train net output #0: loss = 1.29698 (* 1 = 1.29698 loss)
I0523 13:16:03.406827  1678 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I0523 13:16:12.400002  1678 solver.cpp:237] Iteration 78250, loss = 1.1644
I0523 13:16:12.400037  1678 solver.cpp:253]     Train net output #0: loss = 1.1644 (* 1 = 1.1644 loss)
I0523 13:16:12.400053  1678 sgd_solver.cpp:106] Iteration 78250, lr = 0.0005
I0523 13:16:42.292703  1678 solver.cpp:237] Iteration 78500, loss = 1.23972
I0523 13:16:42.292897  1678 solver.cpp:253]     Train net output #0: loss = 1.23972 (* 1 = 1.23972 loss)
I0523 13:16:42.292912  1678 sgd_solver.cpp:106] Iteration 78500, lr = 0.0005
I0523 13:16:51.290755  1678 solver.cpp:237] Iteration 78750, loss = 1.19669
I0523 13:16:51.290788  1678 solver.cpp:253]     Train net output #0: loss = 1.19669 (* 1 = 1.19669 loss)
I0523 13:16:51.290804  1678 sgd_solver.cpp:106] Iteration 78750, lr = 0.0005
I0523 13:17:00.288094  1678 solver.cpp:237] Iteration 79000, loss = 1.48503
I0523 13:17:00.288130  1678 solver.cpp:253]     Train net output #0: loss = 1.48503 (* 1 = 1.48503 loss)
I0523 13:17:00.288142  1678 sgd_solver.cpp:106] Iteration 79000, lr = 0.0005
I0523 13:17:09.283347  1678 solver.cpp:237] Iteration 79250, loss = 1.37372
I0523 13:17:09.283386  1678 solver.cpp:253]     Train net output #0: loss = 1.37372 (* 1 = 1.37372 loss)
I0523 13:17:09.283406  1678 sgd_solver.cpp:106] Iteration 79250, lr = 0.0005
I0523 13:17:18.280163  1678 solver.cpp:237] Iteration 79500, loss = 1.02393
I0523 13:17:18.280328  1678 solver.cpp:253]     Train net output #0: loss = 1.02393 (* 1 = 1.02393 loss)
I0523 13:17:18.280340  1678 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I0523 13:17:27.276880  1678 solver.cpp:237] Iteration 79750, loss = 1.15541
I0523 13:17:27.276916  1678 solver.cpp:253]     Train net output #0: loss = 1.15541 (* 1 = 1.15541 loss)
I0523 13:17:27.276931  1678 sgd_solver.cpp:106] Iteration 79750, lr = 0.0005
I0523 13:17:36.233001  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_80000.caffemodel
I0523 13:17:36.296772  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_80000.solverstate
I0523 13:17:36.323559  1678 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 13:18:44.480523  1678 solver.cpp:409]     Test net output #0: accuracy = 0.850974
I0523 13:18:44.480710  1678 solver.cpp:409]     Test net output #1: loss = 0.476252 (* 1 = 0.476252 loss)
I0523 13:19:05.378571  1678 solver.cpp:237] Iteration 80000, loss = 1.28107
I0523 13:19:05.378623  1678 solver.cpp:253]     Train net output #0: loss = 1.28107 (* 1 = 1.28107 loss)
I0523 13:19:05.378638  1678 sgd_solver.cpp:106] Iteration 80000, lr = 0.0005
I0523 13:19:14.466383  1678 solver.cpp:237] Iteration 80250, loss = 1.10357
I0523 13:19:14.466430  1678 solver.cpp:253]     Train net output #0: loss = 1.10357 (* 1 = 1.10357 loss)
I0523 13:19:14.466447  1678 sgd_solver.cpp:106] Iteration 80250, lr = 0.0005
I0523 13:19:23.544590  1678 solver.cpp:237] Iteration 80500, loss = 1.06271
I0523 13:19:23.544761  1678 solver.cpp:253]     Train net output #0: loss = 1.06271 (* 1 = 1.06271 loss)
I0523 13:19:23.544775  1678 sgd_solver.cpp:106] Iteration 80500, lr = 0.0005
I0523 13:19:32.630569  1678 solver.cpp:237] Iteration 80750, loss = 1.41192
I0523 13:19:32.630604  1678 solver.cpp:253]     Train net output #0: loss = 1.41192 (* 1 = 1.41192 loss)
I0523 13:19:32.630620  1678 sgd_solver.cpp:106] Iteration 80750, lr = 0.0005
I0523 13:19:41.730334  1678 solver.cpp:237] Iteration 81000, loss = 1.3564
I0523 13:19:41.730370  1678 solver.cpp:253]     Train net output #0: loss = 1.3564 (* 1 = 1.3564 loss)
I0523 13:19:41.730382  1678 sgd_solver.cpp:106] Iteration 81000, lr = 0.0005
I0523 13:19:50.818370  1678 solver.cpp:237] Iteration 81250, loss = 1.61723
I0523 13:19:50.818405  1678 solver.cpp:253]     Train net output #0: loss = 1.61723 (* 1 = 1.61723 loss)
I0523 13:19:50.818418  1678 sgd_solver.cpp:106] Iteration 81250, lr = 0.0005
I0523 13:19:59.914701  1678 solver.cpp:237] Iteration 81500, loss = 1.36239
I0523 13:19:59.914885  1678 solver.cpp:253]     Train net output #0: loss = 1.36239 (* 1 = 1.36239 loss)
I0523 13:19:59.914899  1678 sgd_solver.cpp:106] Iteration 81500, lr = 0.0005
I0523 13:20:29.884874  1678 solver.cpp:237] Iteration 81750, loss = 1.32875
I0523 13:20:29.884922  1678 solver.cpp:253]     Train net output #0: loss = 1.32875 (* 1 = 1.32875 loss)
I0523 13:20:29.884940  1678 sgd_solver.cpp:106] Iteration 81750, lr = 0.0005
I0523 13:20:38.961040  1678 solver.cpp:237] Iteration 82000, loss = 1.15272
I0523 13:20:38.961225  1678 solver.cpp:253]     Train net output #0: loss = 1.15272 (* 1 = 1.15272 loss)
I0523 13:20:38.961238  1678 sgd_solver.cpp:106] Iteration 82000, lr = 0.0005
I0523 13:20:48.061666  1678 solver.cpp:237] Iteration 82250, loss = 1.04776
I0523 13:20:48.061699  1678 solver.cpp:253]     Train net output #0: loss = 1.04776 (* 1 = 1.04776 loss)
I0523 13:20:48.061714  1678 sgd_solver.cpp:106] Iteration 82250, lr = 0.0005
I0523 13:20:57.111963  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_82500.caffemodel
I0523 13:20:57.182145  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_82500.solverstate
I0523 13:20:57.222204  1678 solver.cpp:237] Iteration 82500, loss = 1.37858
I0523 13:20:57.222249  1678 solver.cpp:253]     Train net output #0: loss = 1.37858 (* 1 = 1.37858 loss)
I0523 13:20:57.222265  1678 sgd_solver.cpp:106] Iteration 82500, lr = 0.0005
I0523 13:21:06.308107  1678 solver.cpp:237] Iteration 82750, loss = 1.13602
I0523 13:21:06.308141  1678 solver.cpp:253]     Train net output #0: loss = 1.13602 (* 1 = 1.13602 loss)
I0523 13:21:06.308157  1678 sgd_solver.cpp:106] Iteration 82750, lr = 0.0005
I0523 13:21:15.393043  1678 solver.cpp:237] Iteration 83000, loss = 1.03627
I0523 13:21:15.393229  1678 solver.cpp:253]     Train net output #0: loss = 1.03627 (* 1 = 1.03627 loss)
I0523 13:21:15.393241  1678 sgd_solver.cpp:106] Iteration 83000, lr = 0.0005
I0523 13:21:24.470875  1678 solver.cpp:237] Iteration 83250, loss = 1.44868
I0523 13:21:24.470909  1678 solver.cpp:253]     Train net output #0: loss = 1.44868 (* 1 = 1.44868 loss)
I0523 13:21:24.470929  1678 sgd_solver.cpp:106] Iteration 83250, lr = 0.0005
I0523 13:21:54.463809  1678 solver.cpp:237] Iteration 83500, loss = 1.12936
I0523 13:21:54.463997  1678 solver.cpp:253]     Train net output #0: loss = 1.12936 (* 1 = 1.12936 loss)
I0523 13:21:54.464011  1678 sgd_solver.cpp:106] Iteration 83500, lr = 0.0005
I0523 13:22:03.545667  1678 solver.cpp:237] Iteration 83750, loss = 1.27463
I0523 13:22:03.545701  1678 solver.cpp:253]     Train net output #0: loss = 1.27463 (* 1 = 1.27463 loss)
I0523 13:22:03.545717  1678 sgd_solver.cpp:106] Iteration 83750, lr = 0.0005
I0523 13:22:12.641026  1678 solver.cpp:237] Iteration 84000, loss = 1.46917
I0523 13:22:12.641072  1678 solver.cpp:253]     Train net output #0: loss = 1.46917 (* 1 = 1.46917 loss)
I0523 13:22:12.641088  1678 sgd_solver.cpp:106] Iteration 84000, lr = 0.0005
I0523 13:22:21.728176  1678 solver.cpp:237] Iteration 84250, loss = 1.2612
I0523 13:22:21.728212  1678 solver.cpp:253]     Train net output #0: loss = 1.2612 (* 1 = 1.2612 loss)
I0523 13:22:21.728226  1678 sgd_solver.cpp:106] Iteration 84250, lr = 0.0005
I0523 13:22:30.825351  1678 solver.cpp:237] Iteration 84500, loss = 1.34575
I0523 13:22:30.825523  1678 solver.cpp:253]     Train net output #0: loss = 1.34575 (* 1 = 1.34575 loss)
I0523 13:22:30.825537  1678 sgd_solver.cpp:106] Iteration 84500, lr = 0.0005
I0523 13:22:39.903580  1678 solver.cpp:237] Iteration 84750, loss = 1.10388
I0523 13:22:39.903615  1678 solver.cpp:253]     Train net output #0: loss = 1.10388 (* 1 = 1.10388 loss)
I0523 13:22:39.903631  1678 sgd_solver.cpp:106] Iteration 84750, lr = 0.0005
I0523 13:22:48.954192  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_85000.caffemodel
I0523 13:22:49.018352  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_85000.solverstate
I0523 13:22:49.044754  1678 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 13:23:36.430791  1678 solver.cpp:409]     Test net output #0: accuracy = 0.853688
I0523 13:23:36.430989  1678 solver.cpp:409]     Test net output #1: loss = 0.493513 (* 1 = 0.493513 loss)
I0523 13:23:57.374406  1678 solver.cpp:237] Iteration 85000, loss = 1.17174
I0523 13:23:57.374462  1678 solver.cpp:253]     Train net output #0: loss = 1.17174 (* 1 = 1.17174 loss)
I0523 13:23:57.374478  1678 sgd_solver.cpp:106] Iteration 85000, lr = 0.0005
I0523 13:24:06.474303  1678 solver.cpp:237] Iteration 85250, loss = 1.19211
I0523 13:24:06.474481  1678 solver.cpp:253]     Train net output #0: loss = 1.19211 (* 1 = 1.19211 loss)
I0523 13:24:06.474494  1678 sgd_solver.cpp:106] Iteration 85250, lr = 0.0005
I0523 13:24:15.574107  1678 solver.cpp:237] Iteration 85500, loss = 1.11337
I0523 13:24:15.574151  1678 solver.cpp:253]     Train net output #0: loss = 1.11337 (* 1 = 1.11337 loss)
I0523 13:24:15.574167  1678 sgd_solver.cpp:106] Iteration 85500, lr = 0.0005
I0523 13:24:24.675266  1678 solver.cpp:237] Iteration 85750, loss = 1.30841
I0523 13:24:24.675302  1678 solver.cpp:253]     Train net output #0: loss = 1.30841 (* 1 = 1.30841 loss)
I0523 13:24:24.675318  1678 sgd_solver.cpp:106] Iteration 85750, lr = 0.0005
I0523 13:24:33.778712  1678 solver.cpp:237] Iteration 86000, loss = 1.30555
I0523 13:24:33.778748  1678 solver.cpp:253]     Train net output #0: loss = 1.30555 (* 1 = 1.30555 loss)
I0523 13:24:33.778761  1678 sgd_solver.cpp:106] Iteration 86000, lr = 0.0005
I0523 13:24:42.873869  1678 solver.cpp:237] Iteration 86250, loss = 1.12792
I0523 13:24:42.874050  1678 solver.cpp:253]     Train net output #0: loss = 1.12792 (* 1 = 1.12792 loss)
I0523 13:24:42.874064  1678 sgd_solver.cpp:106] Iteration 86250, lr = 0.0005
I0523 13:24:51.967746  1678 solver.cpp:237] Iteration 86500, loss = 1.35045
I0523 13:24:51.967777  1678 solver.cpp:253]     Train net output #0: loss = 1.35045 (* 1 = 1.35045 loss)
I0523 13:24:51.967790  1678 sgd_solver.cpp:106] Iteration 86500, lr = 0.0005
I0523 13:25:22.005801  1678 solver.cpp:237] Iteration 86750, loss = 1.09532
I0523 13:25:22.005995  1678 solver.cpp:253]     Train net output #0: loss = 1.09532 (* 1 = 1.09532 loss)
I0523 13:25:22.006011  1678 sgd_solver.cpp:106] Iteration 86750, lr = 0.0005
I0523 13:25:31.099588  1678 solver.cpp:237] Iteration 87000, loss = 1.27236
I0523 13:25:31.099629  1678 solver.cpp:253]     Train net output #0: loss = 1.27236 (* 1 = 1.27236 loss)
I0523 13:25:31.099648  1678 sgd_solver.cpp:106] Iteration 87000, lr = 0.0005
I0523 13:25:40.186854  1678 solver.cpp:237] Iteration 87250, loss = 1.22846
I0523 13:25:40.186888  1678 solver.cpp:253]     Train net output #0: loss = 1.22846 (* 1 = 1.22846 loss)
I0523 13:25:40.186904  1678 sgd_solver.cpp:106] Iteration 87250, lr = 0.0005
I0523 13:25:49.249442  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_87500.caffemodel
I0523 13:25:49.314435  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_87500.solverstate
I0523 13:25:49.355690  1678 solver.cpp:237] Iteration 87500, loss = 1.16517
I0523 13:25:49.355738  1678 solver.cpp:253]     Train net output #0: loss = 1.16517 (* 1 = 1.16517 loss)
I0523 13:25:49.355753  1678 sgd_solver.cpp:106] Iteration 87500, lr = 0.0005
I0523 13:25:58.455385  1678 solver.cpp:237] Iteration 87750, loss = 1.00263
I0523 13:25:58.455580  1678 solver.cpp:253]     Train net output #0: loss = 1.00263 (* 1 = 1.00263 loss)
I0523 13:25:58.455595  1678 sgd_solver.cpp:106] Iteration 87750, lr = 0.0005
I0523 13:26:07.545243  1678 solver.cpp:237] Iteration 88000, loss = 1.37891
I0523 13:26:07.545277  1678 solver.cpp:253]     Train net output #0: loss = 1.37891 (* 1 = 1.37891 loss)
I0523 13:26:07.545292  1678 sgd_solver.cpp:106] Iteration 88000, lr = 0.0005
I0523 13:26:16.643051  1678 solver.cpp:237] Iteration 88250, loss = 1.4668
I0523 13:26:16.643100  1678 solver.cpp:253]     Train net output #0: loss = 1.4668 (* 1 = 1.4668 loss)
I0523 13:26:16.643113  1678 sgd_solver.cpp:106] Iteration 88250, lr = 0.0005
I0523 13:26:46.670905  1678 solver.cpp:237] Iteration 88500, loss = 1.30898
I0523 13:26:46.671097  1678 solver.cpp:253]     Train net output #0: loss = 1.30898 (* 1 = 1.30898 loss)
I0523 13:26:46.671110  1678 sgd_solver.cpp:106] Iteration 88500, lr = 0.0005
I0523 13:26:55.765805  1678 solver.cpp:237] Iteration 88750, loss = 1.25135
I0523 13:26:55.765841  1678 solver.cpp:253]     Train net output #0: loss = 1.25135 (* 1 = 1.25135 loss)
I0523 13:26:55.765856  1678 sgd_solver.cpp:106] Iteration 88750, lr = 0.0005
I0523 13:27:04.866367  1678 solver.cpp:237] Iteration 89000, loss = 1.2734
I0523 13:27:04.866402  1678 solver.cpp:253]     Train net output #0: loss = 1.2734 (* 1 = 1.2734 loss)
I0523 13:27:04.866417  1678 sgd_solver.cpp:106] Iteration 89000, lr = 0.0005
I0523 13:27:13.962208  1678 solver.cpp:237] Iteration 89250, loss = 1.13052
I0523 13:27:13.962250  1678 solver.cpp:253]     Train net output #0: loss = 1.13052 (* 1 = 1.13052 loss)
I0523 13:27:13.962267  1678 sgd_solver.cpp:106] Iteration 89250, lr = 0.0005
I0523 13:27:23.057124  1678 solver.cpp:237] Iteration 89500, loss = 1.08377
I0523 13:27:23.057303  1678 solver.cpp:253]     Train net output #0: loss = 1.08377 (* 1 = 1.08377 loss)
I0523 13:27:23.057317  1678 sgd_solver.cpp:106] Iteration 89500, lr = 0.0005
I0523 13:27:32.151419  1678 solver.cpp:237] Iteration 89750, loss = 1.21425
I0523 13:27:32.151464  1678 solver.cpp:253]     Train net output #0: loss = 1.21425 (* 1 = 1.21425 loss)
I0523 13:27:32.151480  1678 sgd_solver.cpp:106] Iteration 89750, lr = 0.0005
I0523 13:27:41.212198  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_90000.caffemodel
I0523 13:27:41.279196  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_90000.solverstate
I0523 13:27:41.308318  1678 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 13:28:49.613212  1678 solver.cpp:409]     Test net output #0: accuracy = 0.856601
I0523 13:28:49.613396  1678 solver.cpp:409]     Test net output #1: loss = 0.445669 (* 1 = 0.445669 loss)
I0523 13:29:10.513056  1678 solver.cpp:237] Iteration 90000, loss = 0.985002
I0523 13:29:10.513109  1678 solver.cpp:253]     Train net output #0: loss = 0.985002 (* 1 = 0.985002 loss)
I0523 13:29:10.513128  1678 sgd_solver.cpp:106] Iteration 90000, lr = 0.0005
I0523 13:29:19.495174  1678 solver.cpp:237] Iteration 90250, loss = 1.2305
I0523 13:29:19.495210  1678 solver.cpp:253]     Train net output #0: loss = 1.2305 (* 1 = 1.2305 loss)
I0523 13:29:19.495225  1678 sgd_solver.cpp:106] Iteration 90250, lr = 0.0005
I0523 13:29:28.464900  1678 solver.cpp:237] Iteration 90500, loss = 1.23849
I0523 13:29:28.465073  1678 solver.cpp:253]     Train net output #0: loss = 1.23849 (* 1 = 1.23849 loss)
I0523 13:29:28.465086  1678 sgd_solver.cpp:106] Iteration 90500, lr = 0.0005
I0523 13:29:37.434511  1678 solver.cpp:237] Iteration 90750, loss = 1.22448
I0523 13:29:37.434556  1678 solver.cpp:253]     Train net output #0: loss = 1.22448 (* 1 = 1.22448 loss)
I0523 13:29:37.434569  1678 sgd_solver.cpp:106] Iteration 90750, lr = 0.0005
I0523 13:29:46.405752  1678 solver.cpp:237] Iteration 91000, loss = 1.38584
I0523 13:29:46.405786  1678 solver.cpp:253]     Train net output #0: loss = 1.38584 (* 1 = 1.38584 loss)
I0523 13:29:46.405802  1678 sgd_solver.cpp:106] Iteration 91000, lr = 0.0005
I0523 13:29:55.375993  1678 solver.cpp:237] Iteration 91250, loss = 1.19077
I0523 13:29:55.376027  1678 solver.cpp:253]     Train net output #0: loss = 1.19077 (* 1 = 1.19077 loss)
I0523 13:29:55.376042  1678 sgd_solver.cpp:106] Iteration 91250, lr = 0.0005
I0523 13:30:04.350476  1678 solver.cpp:237] Iteration 91500, loss = 1.23355
I0523 13:30:04.350668  1678 solver.cpp:253]     Train net output #0: loss = 1.23355 (* 1 = 1.23355 loss)
I0523 13:30:04.350682  1678 sgd_solver.cpp:106] Iteration 91500, lr = 0.0005
I0523 13:30:34.206257  1678 solver.cpp:237] Iteration 91750, loss = 1.39942
I0523 13:30:34.206307  1678 solver.cpp:253]     Train net output #0: loss = 1.39942 (* 1 = 1.39942 loss)
I0523 13:30:34.206323  1678 sgd_solver.cpp:106] Iteration 91750, lr = 0.0005
I0523 13:30:43.175221  1678 solver.cpp:237] Iteration 92000, loss = 1.49565
I0523 13:30:43.175398  1678 solver.cpp:253]     Train net output #0: loss = 1.49565 (* 1 = 1.49565 loss)
I0523 13:30:43.175411  1678 sgd_solver.cpp:106] Iteration 92000, lr = 0.0005
I0523 13:30:52.155143  1678 solver.cpp:237] Iteration 92250, loss = 1.05576
I0523 13:30:52.155177  1678 solver.cpp:253]     Train net output #0: loss = 1.05576 (* 1 = 1.05576 loss)
I0523 13:30:52.155200  1678 sgd_solver.cpp:106] Iteration 92250, lr = 0.0005
I0523 13:31:01.090023  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_92500.caffemodel
I0523 13:31:01.153708  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_92500.solverstate
I0523 13:31:01.191689  1678 solver.cpp:237] Iteration 92500, loss = 1.16168
I0523 13:31:01.191730  1678 solver.cpp:253]     Train net output #0: loss = 1.16168 (* 1 = 1.16168 loss)
I0523 13:31:01.191752  1678 sgd_solver.cpp:106] Iteration 92500, lr = 0.0005
I0523 13:31:10.162559  1678 solver.cpp:237] Iteration 92750, loss = 1.30594
I0523 13:31:10.162595  1678 solver.cpp:253]     Train net output #0: loss = 1.30594 (* 1 = 1.30594 loss)
I0523 13:31:10.162608  1678 sgd_solver.cpp:106] Iteration 92750, lr = 0.0005
I0523 13:31:19.129094  1678 solver.cpp:237] Iteration 93000, loss = 0.986886
I0523 13:31:19.129286  1678 solver.cpp:253]     Train net output #0: loss = 0.986886 (* 1 = 0.986886 loss)
I0523 13:31:19.129299  1678 sgd_solver.cpp:106] Iteration 93000, lr = 0.0005
I0523 13:31:28.098407  1678 solver.cpp:237] Iteration 93250, loss = 1.3543
I0523 13:31:28.098440  1678 solver.cpp:253]     Train net output #0: loss = 1.3543 (* 1 = 1.3543 loss)
I0523 13:31:28.098456  1678 sgd_solver.cpp:106] Iteration 93250, lr = 0.0005
I0523 13:31:58.002696  1678 solver.cpp:237] Iteration 93500, loss = 1.04521
I0523 13:31:58.002889  1678 solver.cpp:253]     Train net output #0: loss = 1.04521 (* 1 = 1.04521 loss)
I0523 13:31:58.002904  1678 sgd_solver.cpp:106] Iteration 93500, lr = 0.0005
I0523 13:32:06.979969  1678 solver.cpp:237] Iteration 93750, loss = 1.21508
I0523 13:32:06.980006  1678 solver.cpp:253]     Train net output #0: loss = 1.21508 (* 1 = 1.21508 loss)
I0523 13:32:06.980020  1678 sgd_solver.cpp:106] Iteration 93750, lr = 0.0005
I0523 13:32:15.953737  1678 solver.cpp:237] Iteration 94000, loss = 1.3912
I0523 13:32:15.953766  1678 solver.cpp:253]     Train net output #0: loss = 1.3912 (* 1 = 1.3912 loss)
I0523 13:32:15.953779  1678 sgd_solver.cpp:106] Iteration 94000, lr = 0.0005
I0523 13:32:24.929587  1678 solver.cpp:237] Iteration 94250, loss = 1.43246
I0523 13:32:24.929622  1678 solver.cpp:253]     Train net output #0: loss = 1.43246 (* 1 = 1.43246 loss)
I0523 13:32:24.929636  1678 sgd_solver.cpp:106] Iteration 94250, lr = 0.0005
I0523 13:32:33.902779  1678 solver.cpp:237] Iteration 94500, loss = 1.38572
I0523 13:32:33.902976  1678 solver.cpp:253]     Train net output #0: loss = 1.38572 (* 1 = 1.38572 loss)
I0523 13:32:33.902989  1678 sgd_solver.cpp:106] Iteration 94500, lr = 0.0005
I0523 13:32:42.869698  1678 solver.cpp:237] Iteration 94750, loss = 1.4585
I0523 13:32:42.869731  1678 solver.cpp:253]     Train net output #0: loss = 1.4585 (* 1 = 1.4585 loss)
I0523 13:32:42.869748  1678 sgd_solver.cpp:106] Iteration 94750, lr = 0.0005
I0523 13:32:51.799835  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_95000.caffemodel
I0523 13:32:51.862992  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_95000.solverstate
I0523 13:32:51.890239  1678 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 13:33:38.917430  1678 solver.cpp:409]     Test net output #0: accuracy = 0.858414
I0523 13:33:38.917621  1678 solver.cpp:409]     Test net output #1: loss = 0.457622 (* 1 = 0.457622 loss)
I0523 13:33:59.858695  1678 solver.cpp:237] Iteration 95000, loss = 0.978019
I0523 13:33:59.858748  1678 solver.cpp:253]     Train net output #0: loss = 0.978019 (* 1 = 0.978019 loss)
I0523 13:33:59.858764  1678 sgd_solver.cpp:106] Iteration 95000, lr = 0.0005
I0523 13:34:08.862849  1678 solver.cpp:237] Iteration 95250, loss = 1.27416
I0523 13:34:08.862886  1678 solver.cpp:253]     Train net output #0: loss = 1.27416 (* 1 = 1.27416 loss)
I0523 13:34:08.862900  1678 sgd_solver.cpp:106] Iteration 95250, lr = 0.0005
I0523 13:34:17.876711  1678 solver.cpp:237] Iteration 95500, loss = 1.20266
I0523 13:34:17.876894  1678 solver.cpp:253]     Train net output #0: loss = 1.20266 (* 1 = 1.20266 loss)
I0523 13:34:17.876909  1678 sgd_solver.cpp:106] Iteration 95500, lr = 0.0005
I0523 13:34:26.886852  1678 solver.cpp:237] Iteration 95750, loss = 0.775051
I0523 13:34:26.886886  1678 solver.cpp:253]     Train net output #0: loss = 0.775051 (* 1 = 0.775051 loss)
I0523 13:34:26.886901  1678 sgd_solver.cpp:106] Iteration 95750, lr = 0.0005
I0523 13:34:35.899266  1678 solver.cpp:237] Iteration 96000, loss = 1.41058
I0523 13:34:35.899309  1678 solver.cpp:253]     Train net output #0: loss = 1.41058 (* 1 = 1.41058 loss)
I0523 13:34:35.899324  1678 sgd_solver.cpp:106] Iteration 96000, lr = 0.0005
I0523 13:34:44.912542  1678 solver.cpp:237] Iteration 96250, loss = 1.35361
I0523 13:34:44.912578  1678 solver.cpp:253]     Train net output #0: loss = 1.35361 (* 1 = 1.35361 loss)
I0523 13:34:44.912595  1678 sgd_solver.cpp:106] Iteration 96250, lr = 0.0005
I0523 13:34:53.921375  1678 solver.cpp:237] Iteration 96500, loss = 1.13109
I0523 13:34:53.921542  1678 solver.cpp:253]     Train net output #0: loss = 1.13109 (* 1 = 1.13109 loss)
I0523 13:34:53.921556  1678 sgd_solver.cpp:106] Iteration 96500, lr = 0.0005
I0523 13:35:23.811537  1678 solver.cpp:237] Iteration 96750, loss = 1.05245
I0523 13:35:23.811588  1678 solver.cpp:253]     Train net output #0: loss = 1.05245 (* 1 = 1.05245 loss)
I0523 13:35:23.811602  1678 sgd_solver.cpp:106] Iteration 96750, lr = 0.0005
I0523 13:35:32.817762  1678 solver.cpp:237] Iteration 97000, loss = 1.20571
I0523 13:35:32.817950  1678 solver.cpp:253]     Train net output #0: loss = 1.20571 (* 1 = 1.20571 loss)
I0523 13:35:32.817965  1678 sgd_solver.cpp:106] Iteration 97000, lr = 0.0005
I0523 13:35:41.827173  1678 solver.cpp:237] Iteration 97250, loss = 1.10793
I0523 13:35:41.827208  1678 solver.cpp:253]     Train net output #0: loss = 1.10793 (* 1 = 1.10793 loss)
I0523 13:35:41.827224  1678 sgd_solver.cpp:106] Iteration 97250, lr = 0.0005
I0523 13:35:50.799448  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_97500.caffemodel
I0523 13:35:50.862496  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_97500.solverstate
I0523 13:35:50.900231  1678 solver.cpp:237] Iteration 97500, loss = 1.17546
I0523 13:35:50.900279  1678 solver.cpp:253]     Train net output #0: loss = 1.17546 (* 1 = 1.17546 loss)
I0523 13:35:50.900295  1678 sgd_solver.cpp:106] Iteration 97500, lr = 0.0005
I0523 13:35:59.913976  1678 solver.cpp:237] Iteration 97750, loss = 0.909486
I0523 13:35:59.914012  1678 solver.cpp:253]     Train net output #0: loss = 0.909486 (* 1 = 0.909486 loss)
I0523 13:35:59.914027  1678 sgd_solver.cpp:106] Iteration 97750, lr = 0.0005
I0523 13:36:08.938127  1678 solver.cpp:237] Iteration 98000, loss = 1.27797
I0523 13:36:08.938308  1678 solver.cpp:253]     Train net output #0: loss = 1.27797 (* 1 = 1.27797 loss)
I0523 13:36:08.938321  1678 sgd_solver.cpp:106] Iteration 98000, lr = 0.0005
I0523 13:36:17.944161  1678 solver.cpp:237] Iteration 98250, loss = 1.16068
I0523 13:36:17.944205  1678 solver.cpp:253]     Train net output #0: loss = 1.16068 (* 1 = 1.16068 loss)
I0523 13:36:17.944223  1678 sgd_solver.cpp:106] Iteration 98250, lr = 0.0005
I0523 13:36:47.876051  1678 solver.cpp:237] Iteration 98500, loss = 1.00225
I0523 13:36:47.876250  1678 solver.cpp:253]     Train net output #0: loss = 1.00225 (* 1 = 1.00225 loss)
I0523 13:36:47.876263  1678 sgd_solver.cpp:106] Iteration 98500, lr = 0.0005
I0523 13:36:56.880337  1678 solver.cpp:237] Iteration 98750, loss = 1.59051
I0523 13:36:56.880372  1678 solver.cpp:253]     Train net output #0: loss = 1.59051 (* 1 = 1.59051 loss)
I0523 13:36:56.880386  1678 sgd_solver.cpp:106] Iteration 98750, lr = 0.0005
I0523 13:37:05.893569  1678 solver.cpp:237] Iteration 99000, loss = 0.983636
I0523 13:37:05.893615  1678 solver.cpp:253]     Train net output #0: loss = 0.983636 (* 1 = 0.983636 loss)
I0523 13:37:05.893628  1678 sgd_solver.cpp:106] Iteration 99000, lr = 0.0005
I0523 13:37:14.905165  1678 solver.cpp:237] Iteration 99250, loss = 1.16714
I0523 13:37:14.905200  1678 solver.cpp:253]     Train net output #0: loss = 1.16714 (* 1 = 1.16714 loss)
I0523 13:37:14.905215  1678 sgd_solver.cpp:106] Iteration 99250, lr = 0.0005
I0523 13:37:23.922862  1678 solver.cpp:237] Iteration 99500, loss = 1.2145
I0523 13:37:23.923037  1678 solver.cpp:253]     Train net output #0: loss = 1.2145 (* 1 = 1.2145 loss)
I0523 13:37:23.923049  1678 sgd_solver.cpp:106] Iteration 99500, lr = 0.0005
I0523 13:37:32.929834  1678 solver.cpp:237] Iteration 99750, loss = 1.20066
I0523 13:37:32.929880  1678 solver.cpp:253]     Train net output #0: loss = 1.20066 (* 1 = 1.20066 loss)
I0523 13:37:32.929895  1678 sgd_solver.cpp:106] Iteration 99750, lr = 0.0005
I0523 13:37:41.895346  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_100000.caffemodel
I0523 13:37:41.961107  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_100000.solverstate
I0523 13:37:41.988003  1678 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 13:38:50.155774  1678 solver.cpp:409]     Test net output #0: accuracy = 0.861754
I0523 13:38:50.155974  1678 solver.cpp:409]     Test net output #1: loss = 0.431828 (* 1 = 0.431828 loss)
I0523 13:39:11.036027  1678 solver.cpp:237] Iteration 100000, loss = 1.09455
I0523 13:39:11.036082  1678 solver.cpp:253]     Train net output #0: loss = 1.09455 (* 1 = 1.09455 loss)
I0523 13:39:11.036097  1678 sgd_solver.cpp:106] Iteration 100000, lr = 0.0005
I0523 13:39:20.071501  1678 solver.cpp:237] Iteration 100250, loss = 0.964123
I0523 13:39:20.071538  1678 solver.cpp:253]     Train net output #0: loss = 0.964123 (* 1 = 0.964123 loss)
I0523 13:39:20.071552  1678 sgd_solver.cpp:106] Iteration 100250, lr = 0.0005
I0523 13:39:29.117811  1678 solver.cpp:237] Iteration 100500, loss = 1.46469
I0523 13:39:29.117992  1678 solver.cpp:253]     Train net output #0: loss = 1.46469 (* 1 = 1.46469 loss)
I0523 13:39:29.118005  1678 sgd_solver.cpp:106] Iteration 100500, lr = 0.0005
I0523 13:39:38.156299  1678 solver.cpp:237] Iteration 100750, loss = 1.09682
I0523 13:39:38.156347  1678 solver.cpp:253]     Train net output #0: loss = 1.09682 (* 1 = 1.09682 loss)
I0523 13:39:38.156363  1678 sgd_solver.cpp:106] Iteration 100750, lr = 0.0005
I0523 13:39:47.199350  1678 solver.cpp:237] Iteration 101000, loss = 1.28609
I0523 13:39:47.199384  1678 solver.cpp:253]     Train net output #0: loss = 1.28609 (* 1 = 1.28609 loss)
I0523 13:39:47.199400  1678 sgd_solver.cpp:106] Iteration 101000, lr = 0.0005
I0523 13:39:56.231050  1678 solver.cpp:237] Iteration 101250, loss = 1.19915
I0523 13:39:56.231084  1678 solver.cpp:253]     Train net output #0: loss = 1.19915 (* 1 = 1.19915 loss)
I0523 13:39:56.231099  1678 sgd_solver.cpp:106] Iteration 101250, lr = 0.0005
I0523 13:40:05.270771  1678 solver.cpp:237] Iteration 101500, loss = 1.42297
I0523 13:40:05.270969  1678 solver.cpp:253]     Train net output #0: loss = 1.42297 (* 1 = 1.42297 loss)
I0523 13:40:05.270984  1678 sgd_solver.cpp:106] Iteration 101500, lr = 0.0005
I0523 13:40:35.189992  1678 solver.cpp:237] Iteration 101750, loss = 1.22368
I0523 13:40:35.190042  1678 solver.cpp:253]     Train net output #0: loss = 1.22368 (* 1 = 1.22368 loss)
I0523 13:40:35.190058  1678 sgd_solver.cpp:106] Iteration 101750, lr = 0.0005
I0523 13:40:44.235951  1678 solver.cpp:237] Iteration 102000, loss = 0.913935
I0523 13:40:44.236132  1678 solver.cpp:253]     Train net output #0: loss = 0.913935 (* 1 = 0.913935 loss)
I0523 13:40:44.236146  1678 sgd_solver.cpp:106] Iteration 102000, lr = 0.0005
I0523 13:40:53.279692  1678 solver.cpp:237] Iteration 102250, loss = 1.30225
I0523 13:40:53.279734  1678 solver.cpp:253]     Train net output #0: loss = 1.30225 (* 1 = 1.30225 loss)
I0523 13:40:53.279752  1678 sgd_solver.cpp:106] Iteration 102250, lr = 0.0005
I0523 13:41:02.284492  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_102500.caffemodel
I0523 13:41:02.346833  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_102500.solverstate
I0523 13:41:02.383857  1678 solver.cpp:237] Iteration 102500, loss = 1.0794
I0523 13:41:02.383898  1678 solver.cpp:253]     Train net output #0: loss = 1.0794 (* 1 = 1.0794 loss)
I0523 13:41:02.383916  1678 sgd_solver.cpp:106] Iteration 102500, lr = 0.0005
I0523 13:41:11.417472  1678 solver.cpp:237] Iteration 102750, loss = 1.07315
I0523 13:41:11.417508  1678 solver.cpp:253]     Train net output #0: loss = 1.07315 (* 1 = 1.07315 loss)
I0523 13:41:11.417523  1678 sgd_solver.cpp:106] Iteration 102750, lr = 0.0005
I0523 13:41:20.455862  1678 solver.cpp:237] Iteration 103000, loss = 1.35672
I0523 13:41:20.456063  1678 solver.cpp:253]     Train net output #0: loss = 1.35672 (* 1 = 1.35672 loss)
I0523 13:41:20.456076  1678 sgd_solver.cpp:106] Iteration 103000, lr = 0.0005
I0523 13:41:29.486099  1678 solver.cpp:237] Iteration 103250, loss = 1.21174
I0523 13:41:29.486134  1678 solver.cpp:253]     Train net output #0: loss = 1.21174 (* 1 = 1.21174 loss)
I0523 13:41:29.486150  1678 sgd_solver.cpp:106] Iteration 103250, lr = 0.0005
I0523 13:41:59.404634  1678 solver.cpp:237] Iteration 103500, loss = 1.33923
I0523 13:41:59.404827  1678 solver.cpp:253]     Train net output #0: loss = 1.33923 (* 1 = 1.33923 loss)
I0523 13:41:59.404841  1678 sgd_solver.cpp:106] Iteration 103500, lr = 0.0005
I0523 13:42:08.441637  1678 solver.cpp:237] Iteration 103750, loss = 1.19355
I0523 13:42:08.441679  1678 solver.cpp:253]     Train net output #0: loss = 1.19355 (* 1 = 1.19355 loss)
I0523 13:42:08.441692  1678 sgd_solver.cpp:106] Iteration 103750, lr = 0.0005
I0523 13:42:17.480041  1678 solver.cpp:237] Iteration 104000, loss = 1.40447
I0523 13:42:17.480075  1678 solver.cpp:253]     Train net output #0: loss = 1.40447 (* 1 = 1.40447 loss)
I0523 13:42:17.480092  1678 sgd_solver.cpp:106] Iteration 104000, lr = 0.0005
I0523 13:42:26.519906  1678 solver.cpp:237] Iteration 104250, loss = 1.2095
I0523 13:42:26.519942  1678 solver.cpp:253]     Train net output #0: loss = 1.2095 (* 1 = 1.2095 loss)
I0523 13:42:26.519954  1678 sgd_solver.cpp:106] Iteration 104250, lr = 0.0005
I0523 13:42:35.553421  1678 solver.cpp:237] Iteration 104500, loss = 1.05794
I0523 13:42:35.553620  1678 solver.cpp:253]     Train net output #0: loss = 1.05794 (* 1 = 1.05794 loss)
I0523 13:42:35.553634  1678 sgd_solver.cpp:106] Iteration 104500, lr = 0.0005
I0523 13:42:44.587052  1678 solver.cpp:237] Iteration 104750, loss = 1.35005
I0523 13:42:44.587086  1678 solver.cpp:253]     Train net output #0: loss = 1.35005 (* 1 = 1.35005 loss)
I0523 13:42:44.587102  1678 sgd_solver.cpp:106] Iteration 104750, lr = 0.0005
I0523 13:42:53.586982  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_105000.caffemodel
I0523 13:42:53.650513  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_105000.solverstate
I0523 13:42:53.676753  1678 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 13:43:40.999737  1678 solver.cpp:409]     Test net output #0: accuracy = 0.861289
I0523 13:43:40.999934  1678 solver.cpp:409]     Test net output #1: loss = 0.429537 (* 1 = 0.429537 loss)
I0523 13:44:01.934667  1678 solver.cpp:237] Iteration 105000, loss = 0.992511
I0523 13:44:01.934721  1678 solver.cpp:253]     Train net output #0: loss = 0.992511 (* 1 = 0.992511 loss)
I0523 13:44:01.934737  1678 sgd_solver.cpp:106] Iteration 105000, lr = 0.0005
I0523 13:44:10.933708  1678 solver.cpp:237] Iteration 105250, loss = 1.21251
I0523 13:44:10.933756  1678 solver.cpp:253]     Train net output #0: loss = 1.21251 (* 1 = 1.21251 loss)
I0523 13:44:10.933771  1678 sgd_solver.cpp:106] Iteration 105250, lr = 0.0005
I0523 13:44:19.930241  1678 solver.cpp:237] Iteration 105500, loss = 1.32966
I0523 13:44:19.930424  1678 solver.cpp:253]     Train net output #0: loss = 1.32966 (* 1 = 1.32966 loss)
I0523 13:44:19.930438  1678 sgd_solver.cpp:106] Iteration 105500, lr = 0.0005
I0523 13:44:28.927656  1678 solver.cpp:237] Iteration 105750, loss = 1.26184
I0523 13:44:28.927695  1678 solver.cpp:253]     Train net output #0: loss = 1.26184 (* 1 = 1.26184 loss)
I0523 13:44:28.927711  1678 sgd_solver.cpp:106] Iteration 105750, lr = 0.0005
I0523 13:44:37.923534  1678 solver.cpp:237] Iteration 106000, loss = 1.29926
I0523 13:44:37.923578  1678 solver.cpp:253]     Train net output #0: loss = 1.29926 (* 1 = 1.29926 loss)
I0523 13:44:37.923593  1678 sgd_solver.cpp:106] Iteration 106000, lr = 0.0005
I0523 13:44:46.919209  1678 solver.cpp:237] Iteration 106250, loss = 1.44088
I0523 13:44:46.919244  1678 solver.cpp:253]     Train net output #0: loss = 1.44088 (* 1 = 1.44088 loss)
I0523 13:44:46.919258  1678 sgd_solver.cpp:106] Iteration 106250, lr = 0.0005
I0523 13:44:55.911324  1678 solver.cpp:237] Iteration 106500, loss = 1.06119
I0523 13:44:55.911497  1678 solver.cpp:253]     Train net output #0: loss = 1.06119 (* 1 = 1.06119 loss)
I0523 13:44:55.911511  1678 sgd_solver.cpp:106] Iteration 106500, lr = 0.0005
I0523 13:45:25.828151  1678 solver.cpp:237] Iteration 106750, loss = 1.25008
I0523 13:45:25.828204  1678 solver.cpp:253]     Train net output #0: loss = 1.25008 (* 1 = 1.25008 loss)
I0523 13:45:25.828219  1678 sgd_solver.cpp:106] Iteration 106750, lr = 0.0005
I0523 13:45:34.829726  1678 solver.cpp:237] Iteration 107000, loss = 1.34309
I0523 13:45:34.829912  1678 solver.cpp:253]     Train net output #0: loss = 1.34309 (* 1 = 1.34309 loss)
I0523 13:45:34.829926  1678 sgd_solver.cpp:106] Iteration 107000, lr = 0.0005
I0523 13:45:43.816638  1678 solver.cpp:237] Iteration 107250, loss = 1.57552
I0523 13:45:43.816671  1678 solver.cpp:253]     Train net output #0: loss = 1.57552 (* 1 = 1.57552 loss)
I0523 13:45:43.816687  1678 sgd_solver.cpp:106] Iteration 107250, lr = 0.0005
I0523 13:45:52.779573  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_107500.caffemodel
I0523 13:45:52.841883  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_107500.solverstate
I0523 13:45:52.878371  1678 solver.cpp:237] Iteration 107500, loss = 1.25059
I0523 13:45:52.878412  1678 solver.cpp:253]     Train net output #0: loss = 1.25059 (* 1 = 1.25059 loss)
I0523 13:45:52.878432  1678 sgd_solver.cpp:106] Iteration 107500, lr = 0.0005
I0523 13:46:01.875429  1678 solver.cpp:237] Iteration 107750, loss = 1.23738
I0523 13:46:01.875465  1678 solver.cpp:253]     Train net output #0: loss = 1.23738 (* 1 = 1.23738 loss)
I0523 13:46:01.875479  1678 sgd_solver.cpp:106] Iteration 107750, lr = 0.0005
I0523 13:46:10.871410  1678 solver.cpp:237] Iteration 108000, loss = 1.1975
I0523 13:46:10.871598  1678 solver.cpp:253]     Train net output #0: loss = 1.1975 (* 1 = 1.1975 loss)
I0523 13:46:10.871611  1678 sgd_solver.cpp:106] Iteration 108000, lr = 0.0005
I0523 13:46:19.871021  1678 solver.cpp:237] Iteration 108250, loss = 1.32604
I0523 13:46:19.871058  1678 solver.cpp:253]     Train net output #0: loss = 1.32604 (* 1 = 1.32604 loss)
I0523 13:46:19.871078  1678 sgd_solver.cpp:106] Iteration 108250, lr = 0.0005
I0523 13:46:49.769860  1678 solver.cpp:237] Iteration 108500, loss = 1.22586
I0523 13:46:49.770054  1678 solver.cpp:253]     Train net output #0: loss = 1.22586 (* 1 = 1.22586 loss)
I0523 13:46:49.770069  1678 sgd_solver.cpp:106] Iteration 108500, lr = 0.0005
I0523 13:46:58.764459  1678 solver.cpp:237] Iteration 108750, loss = 1.32587
I0523 13:46:58.764493  1678 solver.cpp:253]     Train net output #0: loss = 1.32587 (* 1 = 1.32587 loss)
I0523 13:46:58.764509  1678 sgd_solver.cpp:106] Iteration 108750, lr = 0.0005
I0523 13:47:07.760622  1678 solver.cpp:237] Iteration 109000, loss = 1.3534
I0523 13:47:07.760661  1678 solver.cpp:253]     Train net output #0: loss = 1.3534 (* 1 = 1.3534 loss)
I0523 13:47:07.760682  1678 sgd_solver.cpp:106] Iteration 109000, lr = 0.0005
I0523 13:47:16.762275  1678 solver.cpp:237] Iteration 109250, loss = 1.07607
I0523 13:47:16.762311  1678 solver.cpp:253]     Train net output #0: loss = 1.07607 (* 1 = 1.07607 loss)
I0523 13:47:16.762326  1678 sgd_solver.cpp:106] Iteration 109250, lr = 0.0005
I0523 13:47:25.754497  1678 solver.cpp:237] Iteration 109500, loss = 1.1997
I0523 13:47:25.754669  1678 solver.cpp:253]     Train net output #0: loss = 1.1997 (* 1 = 1.1997 loss)
I0523 13:47:25.754683  1678 sgd_solver.cpp:106] Iteration 109500, lr = 0.0005
I0523 13:47:34.749243  1678 solver.cpp:237] Iteration 109750, loss = 1.1331
I0523 13:47:34.749280  1678 solver.cpp:253]     Train net output #0: loss = 1.1331 (* 1 = 1.1331 loss)
I0523 13:47:34.749300  1678 sgd_solver.cpp:106] Iteration 109750, lr = 0.0005
I0523 13:47:43.713930  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_110000.caffemodel
I0523 13:47:43.783682  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_110000.solverstate
I0523 13:47:43.810107  1678 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 13:48:52.005493  1678 solver.cpp:409]     Test net output #0: accuracy = 0.865668
I0523 13:48:52.005702  1678 solver.cpp:409]     Test net output #1: loss = 0.460973 (* 1 = 0.460973 loss)
I0523 13:55:12.086844  1678 solver.cpp:237] Iteration 110000, loss = 1.21123
I0523 13:55:12.087056  1678 solver.cpp:253]     Train net output #0: loss = 1.21123 (* 1 = 1.21123 loss)
I0523 13:55:12.087071  1678 sgd_solver.cpp:106] Iteration 110000, lr = 0.0005
I0523 13:55:21.167541  1678 solver.cpp:237] Iteration 110250, loss = 1.382
I0523 13:55:21.167577  1678 solver.cpp:253]     Train net output #0: loss = 1.382 (* 1 = 1.382 loss)
I0523 13:55:21.167592  1678 sgd_solver.cpp:106] Iteration 110250, lr = 0.0005
I0523 13:55:30.254436  1678 solver.cpp:237] Iteration 110500, loss = 1.25662
I0523 13:55:30.254482  1678 solver.cpp:253]     Train net output #0: loss = 1.25662 (* 1 = 1.25662 loss)
I0523 13:55:30.254498  1678 sgd_solver.cpp:106] Iteration 110500, lr = 0.0005
I0523 13:55:39.342815  1678 solver.cpp:237] Iteration 110750, loss = 1.32203
I0523 13:55:39.342849  1678 solver.cpp:253]     Train net output #0: loss = 1.32203 (* 1 = 1.32203 loss)
I0523 13:55:39.342864  1678 sgd_solver.cpp:106] Iteration 110750, lr = 0.0005
I0523 13:55:48.420809  1678 solver.cpp:237] Iteration 111000, loss = 1.3238
I0523 13:55:48.420996  1678 solver.cpp:253]     Train net output #0: loss = 1.3238 (* 1 = 1.3238 loss)
I0523 13:55:48.421010  1678 sgd_solver.cpp:106] Iteration 111000, lr = 0.0005
I0523 13:55:57.501979  1678 solver.cpp:237] Iteration 111250, loss = 1.1628
I0523 13:55:57.502022  1678 solver.cpp:253]     Train net output #0: loss = 1.1628 (* 1 = 1.1628 loss)
I0523 13:55:57.502041  1678 sgd_solver.cpp:106] Iteration 111250, lr = 0.0005
I0523 13:56:06.582693  1678 solver.cpp:237] Iteration 111500, loss = 0.973751
I0523 13:56:06.582729  1678 solver.cpp:253]     Train net output #0: loss = 0.973751 (* 1 = 0.973751 loss)
I0523 13:56:06.582744  1678 sgd_solver.cpp:106] Iteration 111500, lr = 0.0005
I0523 13:56:36.537986  1678 solver.cpp:237] Iteration 111750, loss = 1.14248
I0523 13:56:36.538188  1678 solver.cpp:253]     Train net output #0: loss = 1.14248 (* 1 = 1.14248 loss)
I0523 13:56:36.538203  1678 sgd_solver.cpp:106] Iteration 111750, lr = 0.0005
I0523 13:56:45.620800  1678 solver.cpp:237] Iteration 112000, loss = 1.4041
I0523 13:56:45.620848  1678 solver.cpp:253]     Train net output #0: loss = 1.4041 (* 1 = 1.4041 loss)
I0523 13:56:45.620862  1678 sgd_solver.cpp:106] Iteration 112000, lr = 0.0005
I0523 13:56:54.700656  1678 solver.cpp:237] Iteration 112250, loss = 1.12431
I0523 13:56:54.700691  1678 solver.cpp:253]     Train net output #0: loss = 1.12431 (* 1 = 1.12431 loss)
I0523 13:56:54.700706  1678 sgd_solver.cpp:106] Iteration 112250, lr = 0.0005
I0523 13:57:03.737563  1678 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_112500.caffemodel
I0523 13:57:03.803917  1678 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0005_2016-05-20T15.49.08.817746_iter_112500.solverstate
I0523 13:57:03.843189  1678 solver.cpp:237] Iteration 112500, loss = 1.20447
I0523 13:57:03.843235  1678 solver.cpp:253]     Train net output #0: loss = 1.20447 (* 1 = 1.20447 loss)
I0523 13:57:03.843253  1678 sgd_solver.cpp:106] Iteration 112500, lr = 0.0005
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
*** Aborted at 1464026231 (unix time) try "date -d @1464026231" if you are using GNU date ***
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
PC: @     0x2aaab9276640 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
*** SIGTERM (@0x68b) received by PID 1678 (TID 0x2aaac746f900) from PID 1675; stack trace: ***
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab9276640 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab928a3b8 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7232 exceeded limit 7200
    @     0x2aaab91e9877 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab928eb4e (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11255211: Caught signal Terminated, sending to application
