2812728
I0526 19:37:44.205853   912 caffe.cpp:184] Using GPUs 0
I0526 19:37:44.637138   912 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0045
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375.prototxt"
I0526 19:37:44.638823   912 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375.prototxt
I0526 19:37:44.651520   912 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 19:37:44.651582   912 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 19:37:44.651969   912 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 19:37:44.652175   912 layer_factory.hpp:77] Creating layer data_hdf5
I0526 19:37:44.652202   912 net.cpp:106] Creating Layer data_hdf5
I0526 19:37:44.652228   912 net.cpp:411] data_hdf5 -> data
I0526 19:37:44.652262   912 net.cpp:411] data_hdf5 -> label
I0526 19:37:44.652299   912 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 19:37:44.661784   912 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 19:37:44.664090   912 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 19:38:06.228543   912 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 19:38:06.233723   912 net.cpp:150] Setting up data_hdf5
I0526 19:38:06.233764   912 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 19:38:06.233783   912 net.cpp:157] Top shape: 20 (20)
I0526 19:38:06.233794   912 net.cpp:165] Memory required for data: 508080
I0526 19:38:06.233814   912 layer_factory.hpp:77] Creating layer conv1
I0526 19:38:06.233860   912 net.cpp:106] Creating Layer conv1
I0526 19:38:06.233875   912 net.cpp:454] conv1 <- data
I0526 19:38:06.233899   912 net.cpp:411] conv1 -> conv1
I0526 19:38:07.233710   912 net.cpp:150] Setting up conv1
I0526 19:38:07.233764   912 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:38:07.233789   912 net.cpp:165] Memory required for data: 6037680
I0526 19:38:07.233820   912 layer_factory.hpp:77] Creating layer relu1
I0526 19:38:07.233844   912 net.cpp:106] Creating Layer relu1
I0526 19:38:07.233863   912 net.cpp:454] relu1 <- conv1
I0526 19:38:07.233901   912 net.cpp:397] relu1 -> conv1 (in-place)
I0526 19:38:07.234431   912 net.cpp:150] Setting up relu1
I0526 19:38:07.234455   912 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:38:07.234468   912 net.cpp:165] Memory required for data: 11567280
I0526 19:38:07.234485   912 layer_factory.hpp:77] Creating layer pool1
I0526 19:38:07.234513   912 net.cpp:106] Creating Layer pool1
I0526 19:38:07.234525   912 net.cpp:454] pool1 <- conv1
I0526 19:38:07.234542   912 net.cpp:411] pool1 -> pool1
I0526 19:38:07.234635   912 net.cpp:150] Setting up pool1
I0526 19:38:07.234653   912 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 19:38:07.234674   912 net.cpp:165] Memory required for data: 14332080
I0526 19:38:07.234689   912 layer_factory.hpp:77] Creating layer conv2
I0526 19:38:07.234714   912 net.cpp:106] Creating Layer conv2
I0526 19:38:07.234727   912 net.cpp:454] conv2 <- pool1
I0526 19:38:07.234746   912 net.cpp:411] conv2 -> conv2
I0526 19:38:07.237463   912 net.cpp:150] Setting up conv2
I0526 19:38:07.237498   912 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:38:07.237511   912 net.cpp:165] Memory required for data: 18306480
I0526 19:38:07.237540   912 layer_factory.hpp:77] Creating layer relu2
I0526 19:38:07.237567   912 net.cpp:106] Creating Layer relu2
I0526 19:38:07.237581   912 net.cpp:454] relu2 <- conv2
I0526 19:38:07.237597   912 net.cpp:397] relu2 -> conv2 (in-place)
I0526 19:38:07.237954   912 net.cpp:150] Setting up relu2
I0526 19:38:07.237974   912 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:38:07.237987   912 net.cpp:165] Memory required for data: 22280880
I0526 19:38:07.237999   912 layer_factory.hpp:77] Creating layer pool2
I0526 19:38:07.238026   912 net.cpp:106] Creating Layer pool2
I0526 19:38:07.238039   912 net.cpp:454] pool2 <- conv2
I0526 19:38:07.238055   912 net.cpp:411] pool2 -> pool2
I0526 19:38:07.238152   912 net.cpp:150] Setting up pool2
I0526 19:38:07.238168   912 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 19:38:07.238183   912 net.cpp:165] Memory required for data: 24268080
I0526 19:38:07.238204   912 layer_factory.hpp:77] Creating layer conv3
I0526 19:38:07.238224   912 net.cpp:106] Creating Layer conv3
I0526 19:38:07.238245   912 net.cpp:454] conv3 <- pool2
I0526 19:38:07.238262   912 net.cpp:411] conv3 -> conv3
I0526 19:38:07.240239   912 net.cpp:150] Setting up conv3
I0526 19:38:07.240265   912 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:38:07.240278   912 net.cpp:165] Memory required for data: 26436400
I0526 19:38:07.240305   912 layer_factory.hpp:77] Creating layer relu3
I0526 19:38:07.240334   912 net.cpp:106] Creating Layer relu3
I0526 19:38:07.240347   912 net.cpp:454] relu3 <- conv3
I0526 19:38:07.240363   912 net.cpp:397] relu3 -> conv3 (in-place)
I0526 19:38:07.240861   912 net.cpp:150] Setting up relu3
I0526 19:38:07.240885   912 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:38:07.240898   912 net.cpp:165] Memory required for data: 28604720
I0526 19:38:07.240914   912 layer_factory.hpp:77] Creating layer pool3
I0526 19:38:07.240931   912 net.cpp:106] Creating Layer pool3
I0526 19:38:07.240952   912 net.cpp:454] pool3 <- conv3
I0526 19:38:07.240967   912 net.cpp:411] pool3 -> pool3
I0526 19:38:07.241050   912 net.cpp:150] Setting up pool3
I0526 19:38:07.241073   912 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 19:38:07.241086   912 net.cpp:165] Memory required for data: 29688880
I0526 19:38:07.241101   912 layer_factory.hpp:77] Creating layer conv4
I0526 19:38:07.241127   912 net.cpp:106] Creating Layer conv4
I0526 19:38:07.241142   912 net.cpp:454] conv4 <- pool3
I0526 19:38:07.241158   912 net.cpp:411] conv4 -> conv4
I0526 19:38:07.243911   912 net.cpp:150] Setting up conv4
I0526 19:38:07.243942   912 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:38:07.243957   912 net.cpp:165] Memory required for data: 30414640
I0526 19:38:07.243976   912 layer_factory.hpp:77] Creating layer relu4
I0526 19:38:07.243998   912 net.cpp:106] Creating Layer relu4
I0526 19:38:07.244022   912 net.cpp:454] relu4 <- conv4
I0526 19:38:07.244040   912 net.cpp:397] relu4 -> conv4 (in-place)
I0526 19:38:07.244532   912 net.cpp:150] Setting up relu4
I0526 19:38:07.244555   912 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:38:07.244568   912 net.cpp:165] Memory required for data: 31140400
I0526 19:38:07.244585   912 layer_factory.hpp:77] Creating layer pool4
I0526 19:38:07.244601   912 net.cpp:106] Creating Layer pool4
I0526 19:38:07.244622   912 net.cpp:454] pool4 <- conv4
I0526 19:38:07.244638   912 net.cpp:411] pool4 -> pool4
I0526 19:38:07.244721   912 net.cpp:150] Setting up pool4
I0526 19:38:07.244746   912 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 19:38:07.244760   912 net.cpp:165] Memory required for data: 31503280
I0526 19:38:07.244774   912 layer_factory.hpp:77] Creating layer ip1
I0526 19:38:07.244802   912 net.cpp:106] Creating Layer ip1
I0526 19:38:07.244817   912 net.cpp:454] ip1 <- pool4
I0526 19:38:07.244832   912 net.cpp:411] ip1 -> ip1
I0526 19:38:07.260316   912 net.cpp:150] Setting up ip1
I0526 19:38:07.260349   912 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:38:07.260365   912 net.cpp:165] Memory required for data: 31518960
I0526 19:38:07.260396   912 layer_factory.hpp:77] Creating layer relu5
I0526 19:38:07.260424   912 net.cpp:106] Creating Layer relu5
I0526 19:38:07.260438   912 net.cpp:454] relu5 <- ip1
I0526 19:38:07.260454   912 net.cpp:397] relu5 -> ip1 (in-place)
I0526 19:38:07.260823   912 net.cpp:150] Setting up relu5
I0526 19:38:07.260844   912 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:38:07.260857   912 net.cpp:165] Memory required for data: 31534640
I0526 19:38:07.260872   912 layer_factory.hpp:77] Creating layer drop1
I0526 19:38:07.260903   912 net.cpp:106] Creating Layer drop1
I0526 19:38:07.260917   912 net.cpp:454] drop1 <- ip1
I0526 19:38:07.260941   912 net.cpp:397] drop1 -> ip1 (in-place)
I0526 19:38:07.261014   912 net.cpp:150] Setting up drop1
I0526 19:38:07.261031   912 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:38:07.261044   912 net.cpp:165] Memory required for data: 31550320
I0526 19:38:07.261059   912 layer_factory.hpp:77] Creating layer ip2
I0526 19:38:07.261080   912 net.cpp:106] Creating Layer ip2
I0526 19:38:07.261093   912 net.cpp:454] ip2 <- ip1
I0526 19:38:07.261116   912 net.cpp:411] ip2 -> ip2
I0526 19:38:07.261605   912 net.cpp:150] Setting up ip2
I0526 19:38:07.261625   912 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:38:07.261637   912 net.cpp:165] Memory required for data: 31558160
I0526 19:38:07.261657   912 layer_factory.hpp:77] Creating layer relu6
I0526 19:38:07.261680   912 net.cpp:106] Creating Layer relu6
I0526 19:38:07.261693   912 net.cpp:454] relu6 <- ip2
I0526 19:38:07.261709   912 net.cpp:397] relu6 -> ip2 (in-place)
I0526 19:38:07.262256   912 net.cpp:150] Setting up relu6
I0526 19:38:07.262279   912 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:38:07.262293   912 net.cpp:165] Memory required for data: 31566000
I0526 19:38:07.262310   912 layer_factory.hpp:77] Creating layer drop2
I0526 19:38:07.262333   912 net.cpp:106] Creating Layer drop2
I0526 19:38:07.262347   912 net.cpp:454] drop2 <- ip2
I0526 19:38:07.262362   912 net.cpp:397] drop2 -> ip2 (in-place)
I0526 19:38:07.262419   912 net.cpp:150] Setting up drop2
I0526 19:38:07.262435   912 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:38:07.262449   912 net.cpp:165] Memory required for data: 31573840
I0526 19:38:07.262461   912 layer_factory.hpp:77] Creating layer ip3
I0526 19:38:07.262477   912 net.cpp:106] Creating Layer ip3
I0526 19:38:07.262492   912 net.cpp:454] ip3 <- ip2
I0526 19:38:07.262516   912 net.cpp:411] ip3 -> ip3
I0526 19:38:07.262742   912 net.cpp:150] Setting up ip3
I0526 19:38:07.262761   912 net.cpp:157] Top shape: 20 11 (220)
I0526 19:38:07.262773   912 net.cpp:165] Memory required for data: 31574720
I0526 19:38:07.262794   912 layer_factory.hpp:77] Creating layer drop3
I0526 19:38:07.262815   912 net.cpp:106] Creating Layer drop3
I0526 19:38:07.262828   912 net.cpp:454] drop3 <- ip3
I0526 19:38:07.262845   912 net.cpp:397] drop3 -> ip3 (in-place)
I0526 19:38:07.262890   912 net.cpp:150] Setting up drop3
I0526 19:38:07.262913   912 net.cpp:157] Top shape: 20 11 (220)
I0526 19:38:07.262926   912 net.cpp:165] Memory required for data: 31575600
I0526 19:38:07.262944   912 layer_factory.hpp:77] Creating layer loss
I0526 19:38:07.262966   912 net.cpp:106] Creating Layer loss
I0526 19:38:07.262981   912 net.cpp:454] loss <- ip3
I0526 19:38:07.263001   912 net.cpp:454] loss <- label
I0526 19:38:07.263016   912 net.cpp:411] loss -> loss
I0526 19:38:07.263036   912 layer_factory.hpp:77] Creating layer loss
I0526 19:38:07.263702   912 net.cpp:150] Setting up loss
I0526 19:38:07.263725   912 net.cpp:157] Top shape: (1)
I0526 19:38:07.263746   912 net.cpp:160]     with loss weight 1
I0526 19:38:07.263795   912 net.cpp:165] Memory required for data: 31575604
I0526 19:38:07.263824   912 net.cpp:226] loss needs backward computation.
I0526 19:38:07.263839   912 net.cpp:226] drop3 needs backward computation.
I0526 19:38:07.263856   912 net.cpp:226] ip3 needs backward computation.
I0526 19:38:07.263870   912 net.cpp:226] drop2 needs backward computation.
I0526 19:38:07.263882   912 net.cpp:226] relu6 needs backward computation.
I0526 19:38:07.263896   912 net.cpp:226] ip2 needs backward computation.
I0526 19:38:07.263916   912 net.cpp:226] drop1 needs backward computation.
I0526 19:38:07.263928   912 net.cpp:226] relu5 needs backward computation.
I0526 19:38:07.263942   912 net.cpp:226] ip1 needs backward computation.
I0526 19:38:07.263957   912 net.cpp:226] pool4 needs backward computation.
I0526 19:38:07.263970   912 net.cpp:226] relu4 needs backward computation.
I0526 19:38:07.263983   912 net.cpp:226] conv4 needs backward computation.
I0526 19:38:07.263998   912 net.cpp:226] pool3 needs backward computation.
I0526 19:38:07.264019   912 net.cpp:226] relu3 needs backward computation.
I0526 19:38:07.264031   912 net.cpp:226] conv3 needs backward computation.
I0526 19:38:07.264055   912 net.cpp:226] pool2 needs backward computation.
I0526 19:38:07.264068   912 net.cpp:226] relu2 needs backward computation.
I0526 19:38:07.264081   912 net.cpp:226] conv2 needs backward computation.
I0526 19:38:07.264098   912 net.cpp:226] pool1 needs backward computation.
I0526 19:38:07.264112   912 net.cpp:226] relu1 needs backward computation.
I0526 19:38:07.264132   912 net.cpp:226] conv1 needs backward computation.
I0526 19:38:07.264147   912 net.cpp:228] data_hdf5 does not need backward computation.
I0526 19:38:07.264163   912 net.cpp:270] This network produces output loss
I0526 19:38:07.264189   912 net.cpp:283] Network initialization done.
I0526 19:38:07.265882   912 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375.prototxt
I0526 19:38:07.265962   912 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 19:38:07.266342   912 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 19:38:07.266564   912 layer_factory.hpp:77] Creating layer data_hdf5
I0526 19:38:07.266584   912 net.cpp:106] Creating Layer data_hdf5
I0526 19:38:07.266600   912 net.cpp:411] data_hdf5 -> data
I0526 19:38:07.266620   912 net.cpp:411] data_hdf5 -> label
I0526 19:38:07.266641   912 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 19:38:07.268008   912 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 19:38:28.687718   912 net.cpp:150] Setting up data_hdf5
I0526 19:38:28.687901   912 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 19:38:28.687918   912 net.cpp:157] Top shape: 20 (20)
I0526 19:38:28.687932   912 net.cpp:165] Memory required for data: 508080
I0526 19:38:28.687947   912 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 19:38:28.687980   912 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 19:38:28.687994   912 net.cpp:454] label_data_hdf5_1_split <- label
I0526 19:38:28.688011   912 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 19:38:28.688053   912 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 19:38:28.688151   912 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 19:38:28.688169   912 net.cpp:157] Top shape: 20 (20)
I0526 19:38:28.688184   912 net.cpp:157] Top shape: 20 (20)
I0526 19:38:28.688197   912 net.cpp:165] Memory required for data: 508240
I0526 19:38:28.688210   912 layer_factory.hpp:77] Creating layer conv1
I0526 19:38:28.688242   912 net.cpp:106] Creating Layer conv1
I0526 19:38:28.688256   912 net.cpp:454] conv1 <- data
I0526 19:38:28.688273   912 net.cpp:411] conv1 -> conv1
I0526 19:38:28.690235   912 net.cpp:150] Setting up conv1
I0526 19:38:28.690261   912 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:38:28.690281   912 net.cpp:165] Memory required for data: 6037840
I0526 19:38:28.690305   912 layer_factory.hpp:77] Creating layer relu1
I0526 19:38:28.690327   912 net.cpp:106] Creating Layer relu1
I0526 19:38:28.690351   912 net.cpp:454] relu1 <- conv1
I0526 19:38:28.690366   912 net.cpp:397] relu1 -> conv1 (in-place)
I0526 19:38:28.690886   912 net.cpp:150] Setting up relu1
I0526 19:38:28.690910   912 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:38:28.690923   912 net.cpp:165] Memory required for data: 11567440
I0526 19:38:28.690935   912 layer_factory.hpp:77] Creating layer pool1
I0526 19:38:28.690966   912 net.cpp:106] Creating Layer pool1
I0526 19:38:28.690980   912 net.cpp:454] pool1 <- conv1
I0526 19:38:28.690996   912 net.cpp:411] pool1 -> pool1
I0526 19:38:28.691084   912 net.cpp:150] Setting up pool1
I0526 19:38:28.691102   912 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 19:38:28.691117   912 net.cpp:165] Memory required for data: 14332240
I0526 19:38:28.691136   912 layer_factory.hpp:77] Creating layer conv2
I0526 19:38:28.691157   912 net.cpp:106] Creating Layer conv2
I0526 19:38:28.691179   912 net.cpp:454] conv2 <- pool1
I0526 19:38:28.691195   912 net.cpp:411] conv2 -> conv2
I0526 19:38:28.693152   912 net.cpp:150] Setting up conv2
I0526 19:38:28.693176   912 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:38:28.693197   912 net.cpp:165] Memory required for data: 18306640
I0526 19:38:28.693219   912 layer_factory.hpp:77] Creating layer relu2
I0526 19:38:28.693239   912 net.cpp:106] Creating Layer relu2
I0526 19:38:28.693261   912 net.cpp:454] relu2 <- conv2
I0526 19:38:28.693279   912 net.cpp:397] relu2 -> conv2 (in-place)
I0526 19:38:28.693629   912 net.cpp:150] Setting up relu2
I0526 19:38:28.693650   912 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:38:28.693662   912 net.cpp:165] Memory required for data: 22281040
I0526 19:38:28.693677   912 layer_factory.hpp:77] Creating layer pool2
I0526 19:38:28.693699   912 net.cpp:106] Creating Layer pool2
I0526 19:38:28.693713   912 net.cpp:454] pool2 <- conv2
I0526 19:38:28.693728   912 net.cpp:411] pool2 -> pool2
I0526 19:38:28.693816   912 net.cpp:150] Setting up pool2
I0526 19:38:28.693838   912 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 19:38:28.693851   912 net.cpp:165] Memory required for data: 24268240
I0526 19:38:28.693866   912 layer_factory.hpp:77] Creating layer conv3
I0526 19:38:28.693894   912 net.cpp:106] Creating Layer conv3
I0526 19:38:28.693908   912 net.cpp:454] conv3 <- pool2
I0526 19:38:28.693925   912 net.cpp:411] conv3 -> conv3
I0526 19:38:28.695935   912 net.cpp:150] Setting up conv3
I0526 19:38:28.695960   912 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:38:28.695979   912 net.cpp:165] Memory required for data: 26436560
I0526 19:38:28.696002   912 layer_factory.hpp:77] Creating layer relu3
I0526 19:38:28.696044   912 net.cpp:106] Creating Layer relu3
I0526 19:38:28.696058   912 net.cpp:454] relu3 <- conv3
I0526 19:38:28.696076   912 net.cpp:397] relu3 -> conv3 (in-place)
I0526 19:38:28.696583   912 net.cpp:150] Setting up relu3
I0526 19:38:28.696605   912 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:38:28.696619   912 net.cpp:165] Memory required for data: 28604880
I0526 19:38:28.696635   912 layer_factory.hpp:77] Creating layer pool3
I0526 19:38:28.696660   912 net.cpp:106] Creating Layer pool3
I0526 19:38:28.696672   912 net.cpp:454] pool3 <- conv3
I0526 19:38:28.696688   912 net.cpp:411] pool3 -> pool3
I0526 19:38:28.696776   912 net.cpp:150] Setting up pool3
I0526 19:38:28.696794   912 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 19:38:28.696810   912 net.cpp:165] Memory required for data: 29689040
I0526 19:38:28.696821   912 layer_factory.hpp:77] Creating layer conv4
I0526 19:38:28.696848   912 net.cpp:106] Creating Layer conv4
I0526 19:38:28.696861   912 net.cpp:454] conv4 <- pool3
I0526 19:38:28.696878   912 net.cpp:411] conv4 -> conv4
I0526 19:38:28.698969   912 net.cpp:150] Setting up conv4
I0526 19:38:28.698997   912 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:38:28.699012   912 net.cpp:165] Memory required for data: 30414800
I0526 19:38:28.699030   912 layer_factory.hpp:77] Creating layer relu4
I0526 19:38:28.699050   912 net.cpp:106] Creating Layer relu4
I0526 19:38:28.699074   912 net.cpp:454] relu4 <- conv4
I0526 19:38:28.699090   912 net.cpp:397] relu4 -> conv4 (in-place)
I0526 19:38:28.699586   912 net.cpp:150] Setting up relu4
I0526 19:38:28.699609   912 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:38:28.699622   912 net.cpp:165] Memory required for data: 31140560
I0526 19:38:28.699638   912 layer_factory.hpp:77] Creating layer pool4
I0526 19:38:28.699656   912 net.cpp:106] Creating Layer pool4
I0526 19:38:28.699676   912 net.cpp:454] pool4 <- conv4
I0526 19:38:28.699693   912 net.cpp:411] pool4 -> pool4
I0526 19:38:28.699780   912 net.cpp:150] Setting up pool4
I0526 19:38:28.699797   912 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 19:38:28.699812   912 net.cpp:165] Memory required for data: 31503440
I0526 19:38:28.699831   912 layer_factory.hpp:77] Creating layer ip1
I0526 19:38:28.699856   912 net.cpp:106] Creating Layer ip1
I0526 19:38:28.699875   912 net.cpp:454] ip1 <- pool4
I0526 19:38:28.699892   912 net.cpp:411] ip1 -> ip1
I0526 19:38:28.715284   912 net.cpp:150] Setting up ip1
I0526 19:38:28.715315   912 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:38:28.715335   912 net.cpp:165] Memory required for data: 31519120
I0526 19:38:28.715363   912 layer_factory.hpp:77] Creating layer relu5
I0526 19:38:28.715384   912 net.cpp:106] Creating Layer relu5
I0526 19:38:28.715409   912 net.cpp:454] relu5 <- ip1
I0526 19:38:28.715426   912 net.cpp:397] relu5 -> ip1 (in-place)
I0526 19:38:28.715791   912 net.cpp:150] Setting up relu5
I0526 19:38:28.715811   912 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:38:28.715831   912 net.cpp:165] Memory required for data: 31534800
I0526 19:38:28.715845   912 layer_factory.hpp:77] Creating layer drop1
I0526 19:38:28.715875   912 net.cpp:106] Creating Layer drop1
I0526 19:38:28.715889   912 net.cpp:454] drop1 <- ip1
I0526 19:38:28.715914   912 net.cpp:397] drop1 -> ip1 (in-place)
I0526 19:38:28.715975   912 net.cpp:150] Setting up drop1
I0526 19:38:28.715991   912 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:38:28.716003   912 net.cpp:165] Memory required for data: 31550480
I0526 19:38:28.716017   912 layer_factory.hpp:77] Creating layer ip2
I0526 19:38:28.716037   912 net.cpp:106] Creating Layer ip2
I0526 19:38:28.716049   912 net.cpp:454] ip2 <- ip1
I0526 19:38:28.716075   912 net.cpp:411] ip2 -> ip2
I0526 19:38:28.716578   912 net.cpp:150] Setting up ip2
I0526 19:38:28.716596   912 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:38:28.716609   912 net.cpp:165] Memory required for data: 31558320
I0526 19:38:28.716630   912 layer_factory.hpp:77] Creating layer relu6
I0526 19:38:28.716665   912 net.cpp:106] Creating Layer relu6
I0526 19:38:28.716678   912 net.cpp:454] relu6 <- ip2
I0526 19:38:28.716694   912 net.cpp:397] relu6 -> ip2 (in-place)
I0526 19:38:28.717255   912 net.cpp:150] Setting up relu6
I0526 19:38:28.717279   912 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:38:28.717293   912 net.cpp:165] Memory required for data: 31566160
I0526 19:38:28.717304   912 layer_factory.hpp:77] Creating layer drop2
I0526 19:38:28.717324   912 net.cpp:106] Creating Layer drop2
I0526 19:38:28.717346   912 net.cpp:454] drop2 <- ip2
I0526 19:38:28.717363   912 net.cpp:397] drop2 -> ip2 (in-place)
I0526 19:38:28.717414   912 net.cpp:150] Setting up drop2
I0526 19:38:28.717437   912 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:38:28.717449   912 net.cpp:165] Memory required for data: 31574000
I0526 19:38:28.717468   912 layer_factory.hpp:77] Creating layer ip3
I0526 19:38:28.717485   912 net.cpp:106] Creating Layer ip3
I0526 19:38:28.717500   912 net.cpp:454] ip3 <- ip2
I0526 19:38:28.717524   912 net.cpp:411] ip3 -> ip3
I0526 19:38:28.717762   912 net.cpp:150] Setting up ip3
I0526 19:38:28.717782   912 net.cpp:157] Top shape: 20 11 (220)
I0526 19:38:28.717794   912 net.cpp:165] Memory required for data: 31574880
I0526 19:38:28.717815   912 layer_factory.hpp:77] Creating layer drop3
I0526 19:38:28.717839   912 net.cpp:106] Creating Layer drop3
I0526 19:38:28.717851   912 net.cpp:454] drop3 <- ip3
I0526 19:38:28.717867   912 net.cpp:397] drop3 -> ip3 (in-place)
I0526 19:38:28.717916   912 net.cpp:150] Setting up drop3
I0526 19:38:28.717938   912 net.cpp:157] Top shape: 20 11 (220)
I0526 19:38:28.717950   912 net.cpp:165] Memory required for data: 31575760
I0526 19:38:28.717968   912 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 19:38:28.717985   912 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 19:38:28.718000   912 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 19:38:28.718015   912 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 19:38:28.718040   912 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 19:38:28.718127   912 net.cpp:150] Setting up ip3_drop3_0_split
I0526 19:38:28.718145   912 net.cpp:157] Top shape: 20 11 (220)
I0526 19:38:28.718164   912 net.cpp:157] Top shape: 20 11 (220)
I0526 19:38:28.718176   912 net.cpp:165] Memory required for data: 31577520
I0526 19:38:28.718191   912 layer_factory.hpp:77] Creating layer accuracy
I0526 19:38:28.718220   912 net.cpp:106] Creating Layer accuracy
I0526 19:38:28.718233   912 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 19:38:28.718247   912 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 19:38:28.718264   912 net.cpp:411] accuracy -> accuracy
I0526 19:38:28.718292   912 net.cpp:150] Setting up accuracy
I0526 19:38:28.718314   912 net.cpp:157] Top shape: (1)
I0526 19:38:28.718327   912 net.cpp:165] Memory required for data: 31577524
I0526 19:38:28.718343   912 layer_factory.hpp:77] Creating layer loss
I0526 19:38:28.718359   912 net.cpp:106] Creating Layer loss
I0526 19:38:28.718371   912 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 19:38:28.718387   912 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 19:38:28.718410   912 net.cpp:411] loss -> loss
I0526 19:38:28.718430   912 layer_factory.hpp:77] Creating layer loss
I0526 19:38:28.718942   912 net.cpp:150] Setting up loss
I0526 19:38:28.718963   912 net.cpp:157] Top shape: (1)
I0526 19:38:28.718976   912 net.cpp:160]     with loss weight 1
I0526 19:38:28.718999   912 net.cpp:165] Memory required for data: 31577528
I0526 19:38:28.719020   912 net.cpp:226] loss needs backward computation.
I0526 19:38:28.719034   912 net.cpp:228] accuracy does not need backward computation.
I0526 19:38:28.719048   912 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 19:38:28.719063   912 net.cpp:226] drop3 needs backward computation.
I0526 19:38:28.719074   912 net.cpp:226] ip3 needs backward computation.
I0526 19:38:28.719089   912 net.cpp:226] drop2 needs backward computation.
I0526 19:38:28.719108   912 net.cpp:226] relu6 needs backward computation.
I0526 19:38:28.719130   912 net.cpp:226] ip2 needs backward computation.
I0526 19:38:28.719146   912 net.cpp:226] drop1 needs backward computation.
I0526 19:38:28.719157   912 net.cpp:226] relu5 needs backward computation.
I0526 19:38:28.719172   912 net.cpp:226] ip1 needs backward computation.
I0526 19:38:28.719184   912 net.cpp:226] pool4 needs backward computation.
I0526 19:38:28.719204   912 net.cpp:226] relu4 needs backward computation.
I0526 19:38:28.719218   912 net.cpp:226] conv4 needs backward computation.
I0526 19:38:28.719233   912 net.cpp:226] pool3 needs backward computation.
I0526 19:38:28.719247   912 net.cpp:226] relu3 needs backward computation.
I0526 19:38:28.719259   912 net.cpp:226] conv3 needs backward computation.
I0526 19:38:28.719274   912 net.cpp:226] pool2 needs backward computation.
I0526 19:38:28.719287   912 net.cpp:226] relu2 needs backward computation.
I0526 19:38:28.719306   912 net.cpp:226] conv2 needs backward computation.
I0526 19:38:28.719321   912 net.cpp:226] pool1 needs backward computation.
I0526 19:38:28.719337   912 net.cpp:226] relu1 needs backward computation.
I0526 19:38:28.719350   912 net.cpp:226] conv1 needs backward computation.
I0526 19:38:28.719364   912 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 19:38:28.719378   912 net.cpp:228] data_hdf5 does not need backward computation.
I0526 19:38:28.719393   912 net.cpp:270] This network produces output accuracy
I0526 19:38:28.719411   912 net.cpp:270] This network produces output loss
I0526 19:38:28.719442   912 net.cpp:283] Network initialization done.
I0526 19:38:28.719599   912 solver.cpp:60] Solver scaffolding done.
I0526 19:38:28.720779   912 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_285000.solverstate
I0526 19:38:28.927042   912 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 19:38:28.932559   912 caffe.cpp:212] Starting Optimization
I0526 19:38:28.932603   912 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 19:38:28.932621   912 solver.cpp:289] Learning Rate Policy: fixed
I0526 19:38:28.934016   912 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 19:39:21.930619   912 solver.cpp:409]     Test net output #0: accuracy = 0.89497
I0526 19:39:21.930778   912 solver.cpp:409]     Test net output #1: loss = 0.329454 (* 1 = 0.329454 loss)
I0526 19:39:21.949918   912 solver.cpp:237] Iteration 285000, loss = 0.699085
I0526 19:39:21.949956   912 solver.cpp:253]     Train net output #0: loss = 0.699085 (* 1 = 0.699085 loss)
I0526 19:39:21.949978   912 sgd_solver.cpp:106] Iteration 285000, lr = 0.0045
I0526 19:39:34.117388   912 solver.cpp:237] Iteration 285750, loss = 1.16517
I0526 19:39:34.117427   912 solver.cpp:253]     Train net output #0: loss = 1.16517 (* 1 = 1.16517 loss)
I0526 19:39:34.117444   912 sgd_solver.cpp:106] Iteration 285750, lr = 0.0045
I0526 19:39:46.298436   912 solver.cpp:237] Iteration 286500, loss = 1.14823
I0526 19:39:46.298491   912 solver.cpp:253]     Train net output #0: loss = 1.14823 (* 1 = 1.14823 loss)
I0526 19:39:46.298518   912 sgd_solver.cpp:106] Iteration 286500, lr = 0.0045
I0526 19:39:58.460386   912 solver.cpp:237] Iteration 287250, loss = 0.921677
I0526 19:39:58.460542   912 solver.cpp:253]     Train net output #0: loss = 0.921677 (* 1 = 0.921677 loss)
I0526 19:39:58.460559   912 sgd_solver.cpp:106] Iteration 287250, lr = 0.0045
I0526 19:40:10.684144   912 solver.cpp:237] Iteration 288000, loss = 1.03198
I0526 19:40:10.684185   912 solver.cpp:253]     Train net output #0: loss = 1.03198 (* 1 = 1.03198 loss)
I0526 19:40:10.684202   912 sgd_solver.cpp:106] Iteration 288000, lr = 0.0045
I0526 19:40:22.830581   912 solver.cpp:237] Iteration 288750, loss = 1.05653
I0526 19:40:22.830631   912 solver.cpp:253]     Train net output #0: loss = 1.05653 (* 1 = 1.05653 loss)
I0526 19:40:22.830648   912 sgd_solver.cpp:106] Iteration 288750, lr = 0.0045
I0526 19:40:34.991894   912 solver.cpp:237] Iteration 289500, loss = 1.49998
I0526 19:40:34.992038   912 solver.cpp:253]     Train net output #0: loss = 1.49998 (* 1 = 1.49998 loss)
I0526 19:40:34.992054   912 sgd_solver.cpp:106] Iteration 289500, lr = 0.0045
I0526 19:41:09.355932   912 solver.cpp:237] Iteration 290250, loss = 1.04771
I0526 19:41:09.356098   912 solver.cpp:253]     Train net output #0: loss = 1.04771 (* 1 = 1.04771 loss)
I0526 19:41:09.356117   912 sgd_solver.cpp:106] Iteration 290250, lr = 0.0045
I0526 19:41:21.527113   912 solver.cpp:237] Iteration 291000, loss = 1.17282
I0526 19:41:21.527153   912 solver.cpp:253]     Train net output #0: loss = 1.17282 (* 1 = 1.17282 loss)
I0526 19:41:21.527171   912 sgd_solver.cpp:106] Iteration 291000, lr = 0.0045
I0526 19:41:33.773543   912 solver.cpp:237] Iteration 291750, loss = 1.65052
I0526 19:41:33.773594   912 solver.cpp:253]     Train net output #0: loss = 1.65052 (* 1 = 1.65052 loss)
I0526 19:41:33.773612   912 sgd_solver.cpp:106] Iteration 291750, lr = 0.0045
I0526 19:41:45.991199   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_292500.caffemodel
I0526 19:41:46.041731   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_292500.solverstate
I0526 19:41:46.072542   912 solver.cpp:237] Iteration 292500, loss = 1.11488
I0526 19:41:46.072595   912 solver.cpp:253]     Train net output #0: loss = 1.11488 (* 1 = 1.11488 loss)
I0526 19:41:46.072613   912 sgd_solver.cpp:106] Iteration 292500, lr = 0.0045
I0526 19:41:58.301020   912 solver.cpp:237] Iteration 293250, loss = 1.11519
I0526 19:41:58.301074   912 solver.cpp:253]     Train net output #0: loss = 1.11519 (* 1 = 1.11519 loss)
I0526 19:41:58.301090   912 sgd_solver.cpp:106] Iteration 293250, lr = 0.0045
I0526 19:42:10.515337   912 solver.cpp:237] Iteration 294000, loss = 1.17863
I0526 19:42:10.515375   912 solver.cpp:253]     Train net output #0: loss = 1.17863 (* 1 = 1.17863 loss)
I0526 19:42:10.515393   912 sgd_solver.cpp:106] Iteration 294000, lr = 0.0045
I0526 19:42:22.775671   912 solver.cpp:237] Iteration 294750, loss = 0.834076
I0526 19:42:22.775838   912 solver.cpp:253]     Train net output #0: loss = 0.834076 (* 1 = 0.834076 loss)
I0526 19:42:22.775856   912 sgd_solver.cpp:106] Iteration 294750, lr = 0.0045
I0526 19:42:57.113275   912 solver.cpp:237] Iteration 295500, loss = 0.644307
I0526 19:42:57.113451   912 solver.cpp:253]     Train net output #0: loss = 0.644307 (* 1 = 0.644307 loss)
I0526 19:42:57.113469   912 sgd_solver.cpp:106] Iteration 295500, lr = 0.0045
I0526 19:43:09.327131   912 solver.cpp:237] Iteration 296250, loss = 1.02282
I0526 19:43:09.327183   912 solver.cpp:253]     Train net output #0: loss = 1.02282 (* 1 = 1.02282 loss)
I0526 19:43:09.327200   912 sgd_solver.cpp:106] Iteration 296250, lr = 0.0045
I0526 19:43:21.500337   912 solver.cpp:237] Iteration 297000, loss = 0.941016
I0526 19:43:21.500375   912 solver.cpp:253]     Train net output #0: loss = 0.941016 (* 1 = 0.941016 loss)
I0526 19:43:21.500392   912 sgd_solver.cpp:106] Iteration 297000, lr = 0.0045
I0526 19:43:33.633622   912 solver.cpp:237] Iteration 297750, loss = 1.53039
I0526 19:43:33.633780   912 solver.cpp:253]     Train net output #0: loss = 1.53039 (* 1 = 1.53039 loss)
I0526 19:43:33.633798   912 sgd_solver.cpp:106] Iteration 297750, lr = 0.0045
I0526 19:43:45.765106   912 solver.cpp:237] Iteration 298500, loss = 1.43709
I0526 19:43:45.765146   912 solver.cpp:253]     Train net output #0: loss = 1.43709 (* 1 = 1.43709 loss)
I0526 19:43:45.765161   912 sgd_solver.cpp:106] Iteration 298500, lr = 0.0045
I0526 19:43:57.911903   912 solver.cpp:237] Iteration 299250, loss = 0.955087
I0526 19:43:57.911957   912 solver.cpp:253]     Train net output #0: loss = 0.955087 (* 1 = 0.955087 loss)
I0526 19:43:57.911983   912 sgd_solver.cpp:106] Iteration 299250, lr = 0.0045
I0526 19:44:10.092569   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_300000.caffemodel
I0526 19:44:10.141780   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_300000.solverstate
I0526 19:44:10.170351   912 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 19:45:02.219719   912 solver.cpp:409]     Test net output #0: accuracy = 0.898678
I0526 19:45:02.219889   912 solver.cpp:409]     Test net output #1: loss = 0.315836 (* 1 = 0.315836 loss)
I0526 19:45:24.392284   912 solver.cpp:237] Iteration 300000, loss = 1.05736
I0526 19:45:24.392348   912 solver.cpp:253]     Train net output #0: loss = 1.05736 (* 1 = 1.05736 loss)
I0526 19:45:24.392366   912 sgd_solver.cpp:106] Iteration 300000, lr = 0.0045
I0526 19:45:36.548517   912 solver.cpp:237] Iteration 300750, loss = 0.717269
I0526 19:45:36.548682   912 solver.cpp:253]     Train net output #0: loss = 0.717269 (* 1 = 0.717269 loss)
I0526 19:45:36.548701   912 sgd_solver.cpp:106] Iteration 300750, lr = 0.0045
I0526 19:45:48.765491   912 solver.cpp:237] Iteration 301500, loss = 0.868886
I0526 19:45:48.765528   912 solver.cpp:253]     Train net output #0: loss = 0.868886 (* 1 = 0.868886 loss)
I0526 19:45:48.765547   912 sgd_solver.cpp:106] Iteration 301500, lr = 0.0045
I0526 19:46:00.984577   912 solver.cpp:237] Iteration 302250, loss = 1.44953
I0526 19:46:00.984627   912 solver.cpp:253]     Train net output #0: loss = 1.44953 (* 1 = 1.44953 loss)
I0526 19:46:00.984647   912 sgd_solver.cpp:106] Iteration 302250, lr = 0.0045
I0526 19:46:13.039763   912 solver.cpp:237] Iteration 303000, loss = 0.957636
I0526 19:46:13.039916   912 solver.cpp:253]     Train net output #0: loss = 0.957637 (* 1 = 0.957637 loss)
I0526 19:46:13.039932   912 sgd_solver.cpp:106] Iteration 303000, lr = 0.0045
I0526 19:46:25.082542   912 solver.cpp:237] Iteration 303750, loss = 1.52672
I0526 19:46:25.082581   912 solver.cpp:253]     Train net output #0: loss = 1.52672 (* 1 = 1.52672 loss)
I0526 19:46:25.082597   912 sgd_solver.cpp:106] Iteration 303750, lr = 0.0045
I0526 19:46:37.240319   912 solver.cpp:237] Iteration 304500, loss = 1.36639
I0526 19:46:37.240372   912 solver.cpp:253]     Train net output #0: loss = 1.36639 (* 1 = 1.36639 loss)
I0526 19:46:37.240391   912 sgd_solver.cpp:106] Iteration 304500, lr = 0.0045
I0526 19:47:11.606683   912 solver.cpp:237] Iteration 305250, loss = 0.917695
I0526 19:47:11.606860   912 solver.cpp:253]     Train net output #0: loss = 0.917695 (* 1 = 0.917695 loss)
I0526 19:47:11.606878   912 sgd_solver.cpp:106] Iteration 305250, lr = 0.0045
I0526 19:47:23.726490   912 solver.cpp:237] Iteration 306000, loss = 1.17758
I0526 19:47:23.726542   912 solver.cpp:253]     Train net output #0: loss = 1.17758 (* 1 = 1.17758 loss)
I0526 19:47:23.726559   912 sgd_solver.cpp:106] Iteration 306000, lr = 0.0045
I0526 19:47:35.833722   912 solver.cpp:237] Iteration 306750, loss = 0.918553
I0526 19:47:35.833760   912 solver.cpp:253]     Train net output #0: loss = 0.918553 (* 1 = 0.918553 loss)
I0526 19:47:35.833777   912 sgd_solver.cpp:106] Iteration 306750, lr = 0.0045
I0526 19:47:47.948256   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_307500.caffemodel
I0526 19:47:48.000551   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_307500.solverstate
I0526 19:47:48.033669   912 solver.cpp:237] Iteration 307500, loss = 1.11922
I0526 19:47:48.033731   912 solver.cpp:253]     Train net output #0: loss = 1.11922 (* 1 = 1.11922 loss)
I0526 19:47:48.033749   912 sgd_solver.cpp:106] Iteration 307500, lr = 0.0045
I0526 19:48:00.185541   912 solver.cpp:237] Iteration 308250, loss = 1.34921
I0526 19:48:00.185580   912 solver.cpp:253]     Train net output #0: loss = 1.34921 (* 1 = 1.34921 loss)
I0526 19:48:00.185596   912 sgd_solver.cpp:106] Iteration 308250, lr = 0.0045
I0526 19:48:12.340190   912 solver.cpp:237] Iteration 309000, loss = 0.864434
I0526 19:48:12.340245   912 solver.cpp:253]     Train net output #0: loss = 0.864434 (* 1 = 0.864434 loss)
I0526 19:48:12.340262   912 sgd_solver.cpp:106] Iteration 309000, lr = 0.0045
I0526 19:48:24.490319   912 solver.cpp:237] Iteration 309750, loss = 1.28314
I0526 19:48:24.490469   912 solver.cpp:253]     Train net output #0: loss = 1.28314 (* 1 = 1.28314 loss)
I0526 19:48:24.490486   912 sgd_solver.cpp:106] Iteration 309750, lr = 0.0045
I0526 19:48:58.817359   912 solver.cpp:237] Iteration 310500, loss = 1.04008
I0526 19:48:58.817538   912 solver.cpp:253]     Train net output #0: loss = 1.04008 (* 1 = 1.04008 loss)
I0526 19:48:58.817554   912 sgd_solver.cpp:106] Iteration 310500, lr = 0.0045
I0526 19:49:10.968992   912 solver.cpp:237] Iteration 311250, loss = 1.39102
I0526 19:49:10.969029   912 solver.cpp:253]     Train net output #0: loss = 1.39102 (* 1 = 1.39102 loss)
I0526 19:49:10.969048   912 sgd_solver.cpp:106] Iteration 311250, lr = 0.0045
I0526 19:49:23.051898   912 solver.cpp:237] Iteration 312000, loss = 1.16026
I0526 19:49:23.051949   912 solver.cpp:253]     Train net output #0: loss = 1.16026 (* 1 = 1.16026 loss)
I0526 19:49:23.051965   912 sgd_solver.cpp:106] Iteration 312000, lr = 0.0045
I0526 19:49:35.113415   912 solver.cpp:237] Iteration 312750, loss = 0.862004
I0526 19:49:35.113566   912 solver.cpp:253]     Train net output #0: loss = 0.862004 (* 1 = 0.862004 loss)
I0526 19:49:35.113584   912 sgd_solver.cpp:106] Iteration 312750, lr = 0.0045
I0526 19:49:47.189963   912 solver.cpp:237] Iteration 313500, loss = 1.4382
I0526 19:49:47.190016   912 solver.cpp:253]     Train net output #0: loss = 1.4382 (* 1 = 1.4382 loss)
I0526 19:49:47.190042   912 sgd_solver.cpp:106] Iteration 313500, lr = 0.0045
I0526 19:49:59.386498   912 solver.cpp:237] Iteration 314250, loss = 1.27869
I0526 19:49:59.386536   912 solver.cpp:253]     Train net output #0: loss = 1.27869 (* 1 = 1.27869 loss)
I0526 19:49:59.386554   912 sgd_solver.cpp:106] Iteration 314250, lr = 0.0045
I0526 19:50:11.521863   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_315000.caffemodel
I0526 19:50:11.573791   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_315000.solverstate
I0526 19:50:11.603377   912 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 19:51:24.423254   912 solver.cpp:409]     Test net output #0: accuracy = 0.899388
I0526 19:51:24.423418   912 solver.cpp:409]     Test net output #1: loss = 0.326369 (* 1 = 0.326369 loss)
I0526 19:51:46.596572   912 solver.cpp:237] Iteration 315000, loss = 0.841227
I0526 19:51:46.596635   912 solver.cpp:253]     Train net output #0: loss = 0.841227 (* 1 = 0.841227 loss)
I0526 19:51:46.596663   912 sgd_solver.cpp:106] Iteration 315000, lr = 0.0045
I0526 19:51:58.703312   912 solver.cpp:237] Iteration 315750, loss = 1.22238
I0526 19:51:58.703480   912 solver.cpp:253]     Train net output #0: loss = 1.22238 (* 1 = 1.22238 loss)
I0526 19:51:58.703496   912 sgd_solver.cpp:106] Iteration 315750, lr = 0.0045
I0526 19:52:10.806653   912 solver.cpp:237] Iteration 316500, loss = 1.2406
I0526 19:52:10.806692   912 solver.cpp:253]     Train net output #0: loss = 1.2406 (* 1 = 1.2406 loss)
I0526 19:52:10.806710   912 sgd_solver.cpp:106] Iteration 316500, lr = 0.0045
I0526 19:52:22.959138   912 solver.cpp:237] Iteration 317250, loss = 1.14274
I0526 19:52:22.959189   912 solver.cpp:253]     Train net output #0: loss = 1.14274 (* 1 = 1.14274 loss)
I0526 19:52:22.959208   912 sgd_solver.cpp:106] Iteration 317250, lr = 0.0045
I0526 19:52:35.095700   912 solver.cpp:237] Iteration 318000, loss = 1.19072
I0526 19:52:35.095847   912 solver.cpp:253]     Train net output #0: loss = 1.19072 (* 1 = 1.19072 loss)
I0526 19:52:35.095865   912 sgd_solver.cpp:106] Iteration 318000, lr = 0.0045
I0526 19:52:47.270731   912 solver.cpp:237] Iteration 318750, loss = 1.04607
I0526 19:52:47.270776   912 solver.cpp:253]     Train net output #0: loss = 1.04607 (* 1 = 1.04607 loss)
I0526 19:52:47.270794   912 sgd_solver.cpp:106] Iteration 318750, lr = 0.0045
I0526 19:52:59.451303   912 solver.cpp:237] Iteration 319500, loss = 1.60439
I0526 19:52:59.451340   912 solver.cpp:253]     Train net output #0: loss = 1.60439 (* 1 = 1.60439 loss)
I0526 19:52:59.451359   912 sgd_solver.cpp:106] Iteration 319500, lr = 0.0045
I0526 19:53:33.785063   912 solver.cpp:237] Iteration 320250, loss = 1.25502
I0526 19:53:33.785244   912 solver.cpp:253]     Train net output #0: loss = 1.25502 (* 1 = 1.25502 loss)
I0526 19:53:33.785262   912 sgd_solver.cpp:106] Iteration 320250, lr = 0.0045
I0526 19:53:45.842872   912 solver.cpp:237] Iteration 321000, loss = 1.26613
I0526 19:53:45.842912   912 solver.cpp:253]     Train net output #0: loss = 1.26613 (* 1 = 1.26613 loss)
I0526 19:53:45.842929   912 sgd_solver.cpp:106] Iteration 321000, lr = 0.0045
I0526 19:53:57.958921   912 solver.cpp:237] Iteration 321750, loss = 0.937773
I0526 19:53:57.958971   912 solver.cpp:253]     Train net output #0: loss = 0.937772 (* 1 = 0.937772 loss)
I0526 19:53:57.958989   912 sgd_solver.cpp:106] Iteration 321750, lr = 0.0045
I0526 19:54:10.118348   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_322500.caffemodel
I0526 19:54:10.170677   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_322500.solverstate
I0526 19:54:10.203554   912 solver.cpp:237] Iteration 322500, loss = 1.45677
I0526 19:54:10.203615   912 solver.cpp:253]     Train net output #0: loss = 1.45677 (* 1 = 1.45677 loss)
I0526 19:54:10.203634   912 sgd_solver.cpp:106] Iteration 322500, lr = 0.0045
I0526 19:54:22.320127   912 solver.cpp:237] Iteration 323250, loss = 1.17358
I0526 19:54:22.320184   912 solver.cpp:253]     Train net output #0: loss = 1.17358 (* 1 = 1.17358 loss)
I0526 19:54:22.320204   912 sgd_solver.cpp:106] Iteration 323250, lr = 0.0045
I0526 19:54:34.565510   912 solver.cpp:237] Iteration 324000, loss = 1.19681
I0526 19:54:34.565548   912 solver.cpp:253]     Train net output #0: loss = 1.19681 (* 1 = 1.19681 loss)
I0526 19:54:34.565565   912 sgd_solver.cpp:106] Iteration 324000, lr = 0.0045
I0526 19:54:46.822583   912 solver.cpp:237] Iteration 324750, loss = 1.28421
I0526 19:54:46.822767   912 solver.cpp:253]     Train net output #0: loss = 1.28421 (* 1 = 1.28421 loss)
I0526 19:54:46.822784   912 sgd_solver.cpp:106] Iteration 324750, lr = 0.0045
I0526 19:55:21.224985   912 solver.cpp:237] Iteration 325500, loss = 0.536933
I0526 19:55:21.225152   912 solver.cpp:253]     Train net output #0: loss = 0.536932 (* 1 = 0.536932 loss)
I0526 19:55:21.225168   912 sgd_solver.cpp:106] Iteration 325500, lr = 0.0045
I0526 19:55:33.408818   912 solver.cpp:237] Iteration 326250, loss = 0.915846
I0526 19:55:33.408859   912 solver.cpp:253]     Train net output #0: loss = 0.915845 (* 1 = 0.915845 loss)
I0526 19:55:33.408875   912 sgd_solver.cpp:106] Iteration 326250, lr = 0.0045
I0526 19:55:45.643587   912 solver.cpp:237] Iteration 327000, loss = 1.93778
I0526 19:55:45.643641   912 solver.cpp:253]     Train net output #0: loss = 1.93778 (* 1 = 1.93778 loss)
I0526 19:55:45.643658   912 sgd_solver.cpp:106] Iteration 327000, lr = 0.0045
I0526 19:55:57.878134   912 solver.cpp:237] Iteration 327750, loss = 1.08814
I0526 19:55:57.878284   912 solver.cpp:253]     Train net output #0: loss = 1.08814 (* 1 = 1.08814 loss)
I0526 19:55:57.878301   912 sgd_solver.cpp:106] Iteration 327750, lr = 0.0045
I0526 19:56:10.058490   912 solver.cpp:237] Iteration 328500, loss = 1.457
I0526 19:56:10.058543   912 solver.cpp:253]     Train net output #0: loss = 1.457 (* 1 = 1.457 loss)
I0526 19:56:10.058562   912 sgd_solver.cpp:106] Iteration 328500, lr = 0.0045
I0526 19:56:22.233122   912 solver.cpp:237] Iteration 329250, loss = 0.894995
I0526 19:56:22.233161   912 solver.cpp:253]     Train net output #0: loss = 0.894995 (* 1 = 0.894995 loss)
I0526 19:56:22.233180   912 sgd_solver.cpp:106] Iteration 329250, lr = 0.0045
I0526 19:56:34.410204   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_330000.caffemodel
I0526 19:56:34.465837   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_330000.solverstate
I0526 19:56:34.491731   912 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 19:57:26.276080   912 solver.cpp:409]     Test net output #0: accuracy = 0.901098
I0526 19:57:26.276247   912 solver.cpp:409]     Test net output #1: loss = 0.323139 (* 1 = 0.323139 loss)
I0526 19:57:48.463667   912 solver.cpp:237] Iteration 330000, loss = 0.646898
I0526 19:57:48.463726   912 solver.cpp:253]     Train net output #0: loss = 0.646898 (* 1 = 0.646898 loss)
I0526 19:57:48.463757   912 sgd_solver.cpp:106] Iteration 330000, lr = 0.0045
I0526 19:58:00.613080   912 solver.cpp:237] Iteration 330750, loss = 1.17326
I0526 19:58:00.613246   912 solver.cpp:253]     Train net output #0: loss = 1.17326 (* 1 = 1.17326 loss)
I0526 19:58:00.613265   912 sgd_solver.cpp:106] Iteration 330750, lr = 0.0045
I0526 19:58:12.776355   912 solver.cpp:237] Iteration 331500, loss = 2.19538
I0526 19:58:12.776407   912 solver.cpp:253]     Train net output #0: loss = 2.19538 (* 1 = 2.19538 loss)
I0526 19:58:12.776424   912 sgd_solver.cpp:106] Iteration 331500, lr = 0.0045
I0526 19:58:24.951048   912 solver.cpp:237] Iteration 332250, loss = 1.54918
I0526 19:58:24.951086   912 solver.cpp:253]     Train net output #0: loss = 1.54918 (* 1 = 1.54918 loss)
I0526 19:58:24.951103   912 sgd_solver.cpp:106] Iteration 332250, lr = 0.0045
I0526 19:58:37.148952   912 solver.cpp:237] Iteration 333000, loss = 1.23252
I0526 19:58:37.149114   912 solver.cpp:253]     Train net output #0: loss = 1.23252 (* 1 = 1.23252 loss)
I0526 19:58:37.149132   912 sgd_solver.cpp:106] Iteration 333000, lr = 0.0045
I0526 19:58:49.367424   912 solver.cpp:237] Iteration 333750, loss = 0.776554
I0526 19:58:49.367463   912 solver.cpp:253]     Train net output #0: loss = 0.776553 (* 1 = 0.776553 loss)
I0526 19:58:49.367481   912 sgd_solver.cpp:106] Iteration 333750, lr = 0.0045
I0526 19:59:01.575312   912 solver.cpp:237] Iteration 334500, loss = 0.922874
I0526 19:59:01.575366   912 solver.cpp:253]     Train net output #0: loss = 0.922874 (* 1 = 0.922874 loss)
I0526 19:59:01.575384   912 sgd_solver.cpp:106] Iteration 334500, lr = 0.0045
I0526 19:59:35.991456   912 solver.cpp:237] Iteration 335250, loss = 0.930025
I0526 19:59:35.991636   912 solver.cpp:253]     Train net output #0: loss = 0.930024 (* 1 = 0.930024 loss)
I0526 19:59:35.991652   912 sgd_solver.cpp:106] Iteration 335250, lr = 0.0045
I0526 19:59:48.198660   912 solver.cpp:237] Iteration 336000, loss = 0.844355
I0526 19:59:48.198711   912 solver.cpp:253]     Train net output #0: loss = 0.844355 (* 1 = 0.844355 loss)
I0526 19:59:48.198729   912 sgd_solver.cpp:106] Iteration 336000, lr = 0.0045
I0526 20:00:00.363253   912 solver.cpp:237] Iteration 336750, loss = 1.2549
I0526 20:00:00.363292   912 solver.cpp:253]     Train net output #0: loss = 1.2549 (* 1 = 1.2549 loss)
I0526 20:00:00.363309   912 sgd_solver.cpp:106] Iteration 336750, lr = 0.0045
I0526 20:00:12.487679   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_337500.caffemodel
I0526 20:00:12.537747   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_337500.solverstate
I0526 20:00:12.568763   912 solver.cpp:237] Iteration 337500, loss = 1.1447
I0526 20:00:12.568822   912 solver.cpp:253]     Train net output #0: loss = 1.1447 (* 1 = 1.1447 loss)
I0526 20:00:12.568840   912 sgd_solver.cpp:106] Iteration 337500, lr = 0.0045
I0526 20:00:24.730654   912 solver.cpp:237] Iteration 338250, loss = 0.874228
I0526 20:00:24.730692   912 solver.cpp:253]     Train net output #0: loss = 0.874228 (* 1 = 0.874228 loss)
I0526 20:00:24.730710   912 sgd_solver.cpp:106] Iteration 338250, lr = 0.0045
I0526 20:00:36.932473   912 solver.cpp:237] Iteration 339000, loss = 1.36257
I0526 20:00:36.932526   912 solver.cpp:253]     Train net output #0: loss = 1.36257 (* 1 = 1.36257 loss)
I0526 20:00:36.932551   912 sgd_solver.cpp:106] Iteration 339000, lr = 0.0045
I0526 20:00:49.082772   912 solver.cpp:237] Iteration 339750, loss = 1.25485
I0526 20:00:49.082926   912 solver.cpp:253]     Train net output #0: loss = 1.25485 (* 1 = 1.25485 loss)
I0526 20:00:49.082943   912 sgd_solver.cpp:106] Iteration 339750, lr = 0.0045
I0526 20:01:23.392812   912 solver.cpp:237] Iteration 340500, loss = 1.47936
I0526 20:01:23.392984   912 solver.cpp:253]     Train net output #0: loss = 1.47936 (* 1 = 1.47936 loss)
I0526 20:01:23.393002   912 sgd_solver.cpp:106] Iteration 340500, lr = 0.0045
I0526 20:01:35.555730   912 solver.cpp:237] Iteration 341250, loss = 1.1857
I0526 20:01:35.555780   912 solver.cpp:253]     Train net output #0: loss = 1.1857 (* 1 = 1.1857 loss)
I0526 20:01:35.555799   912 sgd_solver.cpp:106] Iteration 341250, lr = 0.0045
I0526 20:01:47.768255   912 solver.cpp:237] Iteration 342000, loss = 1.28786
I0526 20:01:47.768292   912 solver.cpp:253]     Train net output #0: loss = 1.28786 (* 1 = 1.28786 loss)
I0526 20:01:47.768311   912 sgd_solver.cpp:106] Iteration 342000, lr = 0.0045
I0526 20:01:59.956830   912 solver.cpp:237] Iteration 342750, loss = 1.11309
I0526 20:01:59.956991   912 solver.cpp:253]     Train net output #0: loss = 1.11309 (* 1 = 1.11309 loss)
I0526 20:01:59.957010   912 sgd_solver.cpp:106] Iteration 342750, lr = 0.0045
I0526 20:02:12.159060   912 solver.cpp:237] Iteration 343500, loss = 1.50137
I0526 20:02:12.159097   912 solver.cpp:253]     Train net output #0: loss = 1.50137 (* 1 = 1.50137 loss)
I0526 20:02:12.159114   912 sgd_solver.cpp:106] Iteration 343500, lr = 0.0045
I0526 20:02:24.319147   912 solver.cpp:237] Iteration 344250, loss = 1.03388
I0526 20:02:24.319198   912 solver.cpp:253]     Train net output #0: loss = 1.03388 (* 1 = 1.03388 loss)
I0526 20:02:24.319216   912 sgd_solver.cpp:106] Iteration 344250, lr = 0.0045
I0526 20:02:36.430972   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_345000.caffemodel
I0526 20:02:36.480082   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_345000.solverstate
I0526 20:02:36.506244   912 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 20:03:49.364567   912 solver.cpp:409]     Test net output #0: accuracy = 0.899072
I0526 20:03:49.364744   912 solver.cpp:409]     Test net output #1: loss = 0.319043 (* 1 = 0.319043 loss)
I0526 20:04:11.546257   912 solver.cpp:237] Iteration 345000, loss = 1.13275
I0526 20:04:11.546316   912 solver.cpp:253]     Train net output #0: loss = 1.13275 (* 1 = 1.13275 loss)
I0526 20:04:11.546344   912 sgd_solver.cpp:106] Iteration 345000, lr = 0.0045
I0526 20:04:23.626464   912 solver.cpp:237] Iteration 345750, loss = 1.30236
I0526 20:04:23.626634   912 solver.cpp:253]     Train net output #0: loss = 1.30236 (* 1 = 1.30236 loss)
I0526 20:04:23.626652   912 sgd_solver.cpp:106] Iteration 345750, lr = 0.0045
I0526 20:04:35.772923   912 solver.cpp:237] Iteration 346500, loss = 0.929111
I0526 20:04:35.772961   912 solver.cpp:253]     Train net output #0: loss = 0.92911 (* 1 = 0.92911 loss)
I0526 20:04:35.772979   912 sgd_solver.cpp:106] Iteration 346500, lr = 0.0045
I0526 20:04:47.931010   912 solver.cpp:237] Iteration 347250, loss = 0.759391
I0526 20:04:47.931066   912 solver.cpp:253]     Train net output #0: loss = 0.75939 (* 1 = 0.75939 loss)
I0526 20:04:47.931090   912 sgd_solver.cpp:106] Iteration 347250, lr = 0.0045
I0526 20:05:00.101045   912 solver.cpp:237] Iteration 348000, loss = 1.12357
I0526 20:05:00.101198   912 solver.cpp:253]     Train net output #0: loss = 1.12357 (* 1 = 1.12357 loss)
I0526 20:05:00.101215   912 sgd_solver.cpp:106] Iteration 348000, lr = 0.0045
I0526 20:05:12.302911   912 solver.cpp:237] Iteration 348750, loss = 0.996671
I0526 20:05:12.302966   912 solver.cpp:253]     Train net output #0: loss = 0.99667 (* 1 = 0.99667 loss)
I0526 20:05:12.302991   912 sgd_solver.cpp:106] Iteration 348750, lr = 0.0045
I0526 20:05:24.513962   912 solver.cpp:237] Iteration 349500, loss = 1.12201
I0526 20:05:24.514001   912 solver.cpp:253]     Train net output #0: loss = 1.12201 (* 1 = 1.12201 loss)
I0526 20:05:24.514019   912 sgd_solver.cpp:106] Iteration 349500, lr = 0.0045
I0526 20:05:58.878279   912 solver.cpp:237] Iteration 350250, loss = 0.999639
I0526 20:05:58.878456   912 solver.cpp:253]     Train net output #0: loss = 0.999639 (* 1 = 0.999639 loss)
I0526 20:05:58.878474   912 sgd_solver.cpp:106] Iteration 350250, lr = 0.0045
I0526 20:06:11.052477   912 solver.cpp:237] Iteration 351000, loss = 1.26518
I0526 20:06:11.052528   912 solver.cpp:253]     Train net output #0: loss = 1.26518 (* 1 = 1.26518 loss)
I0526 20:06:11.052546   912 sgd_solver.cpp:106] Iteration 351000, lr = 0.0045
I0526 20:06:23.242106   912 solver.cpp:237] Iteration 351750, loss = 1.1735
I0526 20:06:23.242146   912 solver.cpp:253]     Train net output #0: loss = 1.1735 (* 1 = 1.1735 loss)
I0526 20:06:23.242162   912 sgd_solver.cpp:106] Iteration 351750, lr = 0.0045
I0526 20:06:35.381465   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_352500.caffemodel
I0526 20:06:35.433533   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_352500.solverstate
I0526 20:06:35.465764   912 solver.cpp:237] Iteration 352500, loss = 1.40582
I0526 20:06:35.465824   912 solver.cpp:253]     Train net output #0: loss = 1.40582 (* 1 = 1.40582 loss)
I0526 20:06:35.465842   912 sgd_solver.cpp:106] Iteration 352500, lr = 0.0045
I0526 20:06:47.626940   912 solver.cpp:237] Iteration 353250, loss = 1.12291
I0526 20:06:47.626981   912 solver.cpp:253]     Train net output #0: loss = 1.12291 (* 1 = 1.12291 loss)
I0526 20:06:47.626997   912 sgd_solver.cpp:106] Iteration 353250, lr = 0.0045
I0526 20:06:59.825384   912 solver.cpp:237] Iteration 354000, loss = 1.51192
I0526 20:06:59.825436   912 solver.cpp:253]     Train net output #0: loss = 1.51192 (* 1 = 1.51192 loss)
I0526 20:06:59.825454   912 sgd_solver.cpp:106] Iteration 354000, lr = 0.0045
I0526 20:07:12.042611   912 solver.cpp:237] Iteration 354750, loss = 0.743477
I0526 20:07:12.042781   912 solver.cpp:253]     Train net output #0: loss = 0.743476 (* 1 = 0.743476 loss)
I0526 20:07:12.042800   912 sgd_solver.cpp:106] Iteration 354750, lr = 0.0045
I0526 20:07:46.455047   912 solver.cpp:237] Iteration 355500, loss = 0.923919
I0526 20:07:46.455222   912 solver.cpp:253]     Train net output #0: loss = 0.923919 (* 1 = 0.923919 loss)
I0526 20:07:46.455240   912 sgd_solver.cpp:106] Iteration 355500, lr = 0.0045
I0526 20:07:58.614526   912 solver.cpp:237] Iteration 356250, loss = 1.08306
I0526 20:07:58.614564   912 solver.cpp:253]     Train net output #0: loss = 1.08306 (* 1 = 1.08306 loss)
I0526 20:07:58.614581   912 sgd_solver.cpp:106] Iteration 356250, lr = 0.0045
I0526 20:08:10.787763   912 solver.cpp:237] Iteration 357000, loss = 0.833173
I0526 20:08:10.787824   912 solver.cpp:253]     Train net output #0: loss = 0.833173 (* 1 = 0.833173 loss)
I0526 20:08:10.787843   912 sgd_solver.cpp:106] Iteration 357000, lr = 0.0045
I0526 20:08:22.932196   912 solver.cpp:237] Iteration 357750, loss = 1.21281
I0526 20:08:22.932349   912 solver.cpp:253]     Train net output #0: loss = 1.21281 (* 1 = 1.21281 loss)
I0526 20:08:22.932366   912 sgd_solver.cpp:106] Iteration 357750, lr = 0.0045
I0526 20:08:35.093927   912 solver.cpp:237] Iteration 358500, loss = 1.37156
I0526 20:08:35.093981   912 solver.cpp:253]     Train net output #0: loss = 1.37156 (* 1 = 1.37156 loss)
I0526 20:08:35.093997   912 sgd_solver.cpp:106] Iteration 358500, lr = 0.0045
I0526 20:08:47.245529   912 solver.cpp:237] Iteration 359250, loss = 1.89494
I0526 20:08:47.245568   912 solver.cpp:253]     Train net output #0: loss = 1.89494 (* 1 = 1.89494 loss)
I0526 20:08:47.245585   912 sgd_solver.cpp:106] Iteration 359250, lr = 0.0045
I0526 20:08:59.406576   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_360000.caffemodel
I0526 20:08:59.457469   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_360000.solverstate
I0526 20:08:59.487102   912 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 20:09:51.503754   912 solver.cpp:409]     Test net output #0: accuracy = 0.899264
I0526 20:09:51.503927   912 solver.cpp:409]     Test net output #1: loss = 0.330829 (* 1 = 0.330829 loss)
I0526 20:10:12.423869   912 solver.cpp:237] Iteration 360000, loss = 1.68734
I0526 20:10:12.423929   912 solver.cpp:253]     Train net output #0: loss = 1.68735 (* 1 = 1.68735 loss)
I0526 20:10:12.423949   912 sgd_solver.cpp:106] Iteration 360000, lr = 0.0045
I0526 20:10:24.528444   912 solver.cpp:237] Iteration 360750, loss = 1.28212
I0526 20:10:24.528600   912 solver.cpp:253]     Train net output #0: loss = 1.28212 (* 1 = 1.28212 loss)
I0526 20:10:24.528617   912 sgd_solver.cpp:106] Iteration 360750, lr = 0.0045
I0526 20:10:36.640054   912 solver.cpp:237] Iteration 361500, loss = 0.949791
I0526 20:10:36.640106   912 solver.cpp:253]     Train net output #0: loss = 0.949791 (* 1 = 0.949791 loss)
I0526 20:10:36.640126   912 sgd_solver.cpp:106] Iteration 361500, lr = 0.0045
I0526 20:10:48.833102   912 solver.cpp:237] Iteration 362250, loss = 1.05431
I0526 20:10:48.833143   912 solver.cpp:253]     Train net output #0: loss = 1.05431 (* 1 = 1.05431 loss)
I0526 20:10:48.833160   912 sgd_solver.cpp:106] Iteration 362250, lr = 0.0045
I0526 20:11:01.020941   912 solver.cpp:237] Iteration 363000, loss = 1.10457
I0526 20:11:01.021119   912 solver.cpp:253]     Train net output #0: loss = 1.10457 (* 1 = 1.10457 loss)
I0526 20:11:01.021139   912 sgd_solver.cpp:106] Iteration 363000, lr = 0.0045
I0526 20:11:13.123718   912 solver.cpp:237] Iteration 363750, loss = 1.21594
I0526 20:11:13.123769   912 solver.cpp:253]     Train net output #0: loss = 1.21594 (* 1 = 1.21594 loss)
I0526 20:11:13.123785   912 sgd_solver.cpp:106] Iteration 363750, lr = 0.0045
I0526 20:11:25.247105   912 solver.cpp:237] Iteration 364500, loss = 1.58677
I0526 20:11:25.247143   912 solver.cpp:253]     Train net output #0: loss = 1.58677 (* 1 = 1.58677 loss)
I0526 20:11:25.247161   912 sgd_solver.cpp:106] Iteration 364500, lr = 0.0045
I0526 20:11:58.318101   912 solver.cpp:237] Iteration 365250, loss = 1.3473
I0526 20:11:58.318275   912 solver.cpp:253]     Train net output #0: loss = 1.3473 (* 1 = 1.3473 loss)
I0526 20:11:58.318292   912 sgd_solver.cpp:106] Iteration 365250, lr = 0.0045
I0526 20:12:10.489425   912 solver.cpp:237] Iteration 366000, loss = 1.09738
I0526 20:12:10.489462   912 solver.cpp:253]     Train net output #0: loss = 1.09738 (* 1 = 1.09738 loss)
I0526 20:12:10.489481   912 sgd_solver.cpp:106] Iteration 366000, lr = 0.0045
I0526 20:12:22.652987   912 solver.cpp:237] Iteration 366750, loss = 1.65507
I0526 20:12:22.653035   912 solver.cpp:253]     Train net output #0: loss = 1.65507 (* 1 = 1.65507 loss)
I0526 20:12:22.653055   912 sgd_solver.cpp:106] Iteration 366750, lr = 0.0045
I0526 20:12:34.789733   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_367500.caffemodel
I0526 20:12:34.840237   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_367500.solverstate
I0526 20:12:34.871249   912 solver.cpp:237] Iteration 367500, loss = 0.469035
I0526 20:12:34.871302   912 solver.cpp:253]     Train net output #0: loss = 0.469035 (* 1 = 0.469035 loss)
I0526 20:12:34.871322   912 sgd_solver.cpp:106] Iteration 367500, lr = 0.0045
I0526 20:12:46.988003   912 solver.cpp:237] Iteration 368250, loss = 1.36789
I0526 20:12:46.988054   912 solver.cpp:253]     Train net output #0: loss = 1.36789 (* 1 = 1.36789 loss)
I0526 20:12:46.988072   912 sgd_solver.cpp:106] Iteration 368250, lr = 0.0045
I0526 20:12:59.115895   912 solver.cpp:237] Iteration 369000, loss = 0.880077
I0526 20:12:59.115933   912 solver.cpp:253]     Train net output #0: loss = 0.880076 (* 1 = 0.880076 loss)
I0526 20:12:59.115952   912 sgd_solver.cpp:106] Iteration 369000, lr = 0.0045
I0526 20:13:11.270706   912 solver.cpp:237] Iteration 369750, loss = 1.02395
I0526 20:13:11.270877   912 solver.cpp:253]     Train net output #0: loss = 1.02395 (* 1 = 1.02395 loss)
I0526 20:13:11.270895   912 sgd_solver.cpp:106] Iteration 369750, lr = 0.0045
I0526 20:13:44.375207   912 solver.cpp:237] Iteration 370500, loss = 1.05741
I0526 20:13:44.375380   912 solver.cpp:253]     Train net output #0: loss = 1.05741 (* 1 = 1.05741 loss)
I0526 20:13:44.375398   912 sgd_solver.cpp:106] Iteration 370500, lr = 0.0045
I0526 20:13:56.548554   912 solver.cpp:237] Iteration 371250, loss = 0.889205
I0526 20:13:56.548609   912 solver.cpp:253]     Train net output #0: loss = 0.889205 (* 1 = 0.889205 loss)
I0526 20:13:56.548635   912 sgd_solver.cpp:106] Iteration 371250, lr = 0.0045
I0526 20:14:08.673986   912 solver.cpp:237] Iteration 372000, loss = 0.95672
I0526 20:14:08.674026   912 solver.cpp:253]     Train net output #0: loss = 0.95672 (* 1 = 0.95672 loss)
I0526 20:14:08.674042   912 sgd_solver.cpp:106] Iteration 372000, lr = 0.0045
I0526 20:14:20.811573   912 solver.cpp:237] Iteration 372750, loss = 0.880564
I0526 20:14:20.814270   912 solver.cpp:253]     Train net output #0: loss = 0.880564 (* 1 = 0.880564 loss)
I0526 20:14:20.814288   912 sgd_solver.cpp:106] Iteration 372750, lr = 0.0045
I0526 20:14:32.987329   912 solver.cpp:237] Iteration 373500, loss = 1.64021
I0526 20:14:32.987368   912 solver.cpp:253]     Train net output #0: loss = 1.64021 (* 1 = 1.64021 loss)
I0526 20:14:32.987385   912 sgd_solver.cpp:106] Iteration 373500, lr = 0.0045
I0526 20:14:45.139353   912 solver.cpp:237] Iteration 374250, loss = 0.939857
I0526 20:14:45.139392   912 solver.cpp:253]     Train net output #0: loss = 0.939857 (* 1 = 0.939857 loss)
I0526 20:14:45.139410   912 sgd_solver.cpp:106] Iteration 374250, lr = 0.0045
I0526 20:14:57.334573   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_375000.caffemodel
I0526 20:14:57.383949   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_375000.solverstate
I0526 20:14:57.409629   912 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 20:16:10.228034   912 solver.cpp:409]     Test net output #0: accuracy = 0.900691
I0526 20:16:10.228214   912 solver.cpp:409]     Test net output #1: loss = 0.316096 (* 1 = 0.316096 loss)
I0526 20:16:31.084909   912 solver.cpp:237] Iteration 375000, loss = 0.915293
I0526 20:16:31.084971   912 solver.cpp:253]     Train net output #0: loss = 0.915293 (* 1 = 0.915293 loss)
I0526 20:16:31.085000   912 sgd_solver.cpp:106] Iteration 375000, lr = 0.0045
I0526 20:16:43.185982   912 solver.cpp:237] Iteration 375750, loss = 0.441028
I0526 20:16:43.186142   912 solver.cpp:253]     Train net output #0: loss = 0.441028 (* 1 = 0.441028 loss)
I0526 20:16:43.186159   912 sgd_solver.cpp:106] Iteration 375750, lr = 0.0045
I0526 20:16:55.320683   912 solver.cpp:237] Iteration 376500, loss = 1.0932
I0526 20:16:55.320735   912 solver.cpp:253]     Train net output #0: loss = 1.0932 (* 1 = 1.0932 loss)
I0526 20:16:55.320752   912 sgd_solver.cpp:106] Iteration 376500, lr = 0.0045
I0526 20:17:07.509304   912 solver.cpp:237] Iteration 377250, loss = 1.32636
I0526 20:17:07.509342   912 solver.cpp:253]     Train net output #0: loss = 1.32636 (* 1 = 1.32636 loss)
I0526 20:17:07.509358   912 sgd_solver.cpp:106] Iteration 377250, lr = 0.0045
I0526 20:17:19.672770   912 solver.cpp:237] Iteration 378000, loss = 0.839418
I0526 20:17:19.672941   912 solver.cpp:253]     Train net output #0: loss = 0.839418 (* 1 = 0.839418 loss)
I0526 20:17:19.672960   912 sgd_solver.cpp:106] Iteration 378000, lr = 0.0045
I0526 20:17:31.828332   912 solver.cpp:237] Iteration 378750, loss = 1.3867
I0526 20:17:31.828372   912 solver.cpp:253]     Train net output #0: loss = 1.3867 (* 1 = 1.3867 loss)
I0526 20:17:31.828388   912 sgd_solver.cpp:106] Iteration 378750, lr = 0.0045
I0526 20:17:43.957787   912 solver.cpp:237] Iteration 379500, loss = 1.20199
I0526 20:17:43.957839   912 solver.cpp:253]     Train net output #0: loss = 1.20199 (* 1 = 1.20199 loss)
I0526 20:17:43.957856   912 sgd_solver.cpp:106] Iteration 379500, lr = 0.0045
I0526 20:18:16.961235   912 solver.cpp:237] Iteration 380250, loss = 1.30903
I0526 20:18:16.961408   912 solver.cpp:253]     Train net output #0: loss = 1.30903 (* 1 = 1.30903 loss)
I0526 20:18:16.961426   912 sgd_solver.cpp:106] Iteration 380250, lr = 0.0045
I0526 20:18:29.110153   912 solver.cpp:237] Iteration 381000, loss = 0.943022
I0526 20:18:29.110193   912 solver.cpp:253]     Train net output #0: loss = 0.943021 (* 1 = 0.943021 loss)
I0526 20:18:29.110210   912 sgd_solver.cpp:106] Iteration 381000, lr = 0.0045
I0526 20:18:41.190275   912 solver.cpp:237] Iteration 381750, loss = 1.0696
I0526 20:18:41.190331   912 solver.cpp:253]     Train net output #0: loss = 1.0696 (* 1 = 1.0696 loss)
I0526 20:18:41.190348   912 sgd_solver.cpp:106] Iteration 381750, lr = 0.0045
I0526 20:18:53.249423   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_382500.caffemodel
I0526 20:18:53.299345   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_382500.solverstate
I0526 20:18:53.330533   912 solver.cpp:237] Iteration 382500, loss = 0.868452
I0526 20:18:53.330587   912 solver.cpp:253]     Train net output #0: loss = 0.868452 (* 1 = 0.868452 loss)
I0526 20:18:53.330613   912 sgd_solver.cpp:106] Iteration 382500, lr = 0.0045
I0526 20:19:05.415011   912 solver.cpp:237] Iteration 383250, loss = 1.04462
I0526 20:19:05.415061   912 solver.cpp:253]     Train net output #0: loss = 1.04462 (* 1 = 1.04462 loss)
I0526 20:19:05.415078   912 sgd_solver.cpp:106] Iteration 383250, lr = 0.0045
I0526 20:19:17.608644   912 solver.cpp:237] Iteration 384000, loss = 0.997177
I0526 20:19:17.608681   912 solver.cpp:253]     Train net output #0: loss = 0.997177 (* 1 = 0.997177 loss)
I0526 20:19:17.608700   912 sgd_solver.cpp:106] Iteration 384000, lr = 0.0045
I0526 20:19:29.799259   912 solver.cpp:237] Iteration 384750, loss = 1.42027
I0526 20:19:29.799433   912 solver.cpp:253]     Train net output #0: loss = 1.42027 (* 1 = 1.42027 loss)
I0526 20:19:29.799450   912 sgd_solver.cpp:106] Iteration 384750, lr = 0.0045
I0526 20:20:02.860785   912 solver.cpp:237] Iteration 385500, loss = 1.04983
I0526 20:20:02.860961   912 solver.cpp:253]     Train net output #0: loss = 1.04983 (* 1 = 1.04983 loss)
I0526 20:20:02.860980   912 sgd_solver.cpp:106] Iteration 385500, lr = 0.0045
I0526 20:20:14.978904   912 solver.cpp:237] Iteration 386250, loss = 1.55731
I0526 20:20:14.978955   912 solver.cpp:253]     Train net output #0: loss = 1.55731 (* 1 = 1.55731 loss)
I0526 20:20:14.978972   912 sgd_solver.cpp:106] Iteration 386250, lr = 0.0045
I0526 20:20:27.039834   912 solver.cpp:237] Iteration 387000, loss = 1.36964
I0526 20:20:27.039871   912 solver.cpp:253]     Train net output #0: loss = 1.36964 (* 1 = 1.36964 loss)
I0526 20:20:27.039888   912 sgd_solver.cpp:106] Iteration 387000, lr = 0.0045
I0526 20:20:39.100155   912 solver.cpp:237] Iteration 387750, loss = 0.928868
I0526 20:20:39.100322   912 solver.cpp:253]     Train net output #0: loss = 0.928869 (* 1 = 0.928869 loss)
I0526 20:20:39.100340   912 sgd_solver.cpp:106] Iteration 387750, lr = 0.0045
I0526 20:20:51.257726   912 solver.cpp:237] Iteration 388500, loss = 0.793424
I0526 20:20:51.257766   912 solver.cpp:253]     Train net output #0: loss = 0.793424 (* 1 = 0.793424 loss)
I0526 20:20:51.257782   912 sgd_solver.cpp:106] Iteration 388500, lr = 0.0045
I0526 20:21:03.420642   912 solver.cpp:237] Iteration 389250, loss = 0.965223
I0526 20:21:03.420696   912 solver.cpp:253]     Train net output #0: loss = 0.965223 (* 1 = 0.965223 loss)
I0526 20:21:03.420713   912 sgd_solver.cpp:106] Iteration 389250, lr = 0.0045
I0526 20:21:15.543982   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_390000.caffemodel
I0526 20:21:15.594852   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_390000.solverstate
I0526 20:21:15.620810   912 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 20:22:07.281841   912 solver.cpp:409]     Test net output #0: accuracy = 0.899458
I0526 20:22:07.282012   912 solver.cpp:409]     Test net output #1: loss = 0.321217 (* 1 = 0.321217 loss)
I0526 20:22:28.186524   912 solver.cpp:237] Iteration 390000, loss = 1.15542
I0526 20:22:28.186586   912 solver.cpp:253]     Train net output #0: loss = 1.15542 (* 1 = 1.15542 loss)
I0526 20:22:28.186605   912 sgd_solver.cpp:106] Iteration 390000, lr = 0.0045
I0526 20:22:40.382199   912 solver.cpp:237] Iteration 390750, loss = 0.979276
I0526 20:22:40.382371   912 solver.cpp:253]     Train net output #0: loss = 0.979276 (* 1 = 0.979276 loss)
I0526 20:22:40.382388   912 sgd_solver.cpp:106] Iteration 390750, lr = 0.0045
I0526 20:22:52.550762   912 solver.cpp:237] Iteration 391500, loss = 1.18966
I0526 20:22:52.550811   912 solver.cpp:253]     Train net output #0: loss = 1.18966 (* 1 = 1.18966 loss)
I0526 20:22:52.550827   912 sgd_solver.cpp:106] Iteration 391500, lr = 0.0045
I0526 20:23:04.720049   912 solver.cpp:237] Iteration 392250, loss = 1.03625
I0526 20:23:04.720087   912 solver.cpp:253]     Train net output #0: loss = 1.03625 (* 1 = 1.03625 loss)
I0526 20:23:04.720104   912 sgd_solver.cpp:106] Iteration 392250, lr = 0.0045
I0526 20:23:16.862076   912 solver.cpp:237] Iteration 393000, loss = 0.690919
I0526 20:23:16.862258   912 solver.cpp:253]     Train net output #0: loss = 0.690919 (* 1 = 0.690919 loss)
I0526 20:23:16.862277   912 sgd_solver.cpp:106] Iteration 393000, lr = 0.0045
I0526 20:23:28.990275   912 solver.cpp:237] Iteration 393750, loss = 1.09861
I0526 20:23:28.990314   912 solver.cpp:253]     Train net output #0: loss = 1.09861 (* 1 = 1.09861 loss)
I0526 20:23:28.990330   912 sgd_solver.cpp:106] Iteration 393750, lr = 0.0045
I0526 20:23:41.079190   912 solver.cpp:237] Iteration 394500, loss = 1.61004
I0526 20:23:41.079242   912 solver.cpp:253]     Train net output #0: loss = 1.61004 (* 1 = 1.61004 loss)
I0526 20:23:41.079260   912 sgd_solver.cpp:106] Iteration 394500, lr = 0.0045
I0526 20:24:14.023257   912 solver.cpp:237] Iteration 395250, loss = 0.59507
I0526 20:24:14.023437   912 solver.cpp:253]     Train net output #0: loss = 0.59507 (* 1 = 0.59507 loss)
I0526 20:24:14.023455   912 sgd_solver.cpp:106] Iteration 395250, lr = 0.0045
I0526 20:24:26.122432   912 solver.cpp:237] Iteration 396000, loss = 1.22383
I0526 20:24:26.122485   912 solver.cpp:253]     Train net output #0: loss = 1.22383 (* 1 = 1.22383 loss)
I0526 20:24:26.122503   912 sgd_solver.cpp:106] Iteration 396000, lr = 0.0045
I0526 20:24:38.233316   912 solver.cpp:237] Iteration 396750, loss = 1.30671
I0526 20:24:38.233355   912 solver.cpp:253]     Train net output #0: loss = 1.30671 (* 1 = 1.30671 loss)
I0526 20:24:38.233372   912 sgd_solver.cpp:106] Iteration 396750, lr = 0.0045
I0526 20:24:50.366588   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_397500.caffemodel
I0526 20:24:50.418033   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_397500.solverstate
I0526 20:24:50.452049   912 solver.cpp:237] Iteration 397500, loss = 1.13462
I0526 20:24:50.452103   912 solver.cpp:253]     Train net output #0: loss = 1.13462 (* 1 = 1.13462 loss)
I0526 20:24:50.452129   912 sgd_solver.cpp:106] Iteration 397500, lr = 0.0045
I0526 20:25:02.688074   912 solver.cpp:237] Iteration 398250, loss = 1.40924
I0526 20:25:02.688113   912 solver.cpp:253]     Train net output #0: loss = 1.40924 (* 1 = 1.40924 loss)
I0526 20:25:02.688130   912 sgd_solver.cpp:106] Iteration 398250, lr = 0.0045
I0526 20:25:14.874678   912 solver.cpp:237] Iteration 399000, loss = 1.17326
I0526 20:25:14.874732   912 solver.cpp:253]     Train net output #0: loss = 1.17326 (* 1 = 1.17326 loss)
I0526 20:25:14.874748   912 sgd_solver.cpp:106] Iteration 399000, lr = 0.0045
I0526 20:25:27.016999   912 solver.cpp:237] Iteration 399750, loss = 0.826053
I0526 20:25:27.017163   912 solver.cpp:253]     Train net output #0: loss = 0.826054 (* 1 = 0.826054 loss)
I0526 20:25:27.017179   912 sgd_solver.cpp:106] Iteration 399750, lr = 0.0045
I0526 20:26:00.056815   912 solver.cpp:237] Iteration 400500, loss = 0.959247
I0526 20:26:00.057006   912 solver.cpp:253]     Train net output #0: loss = 0.959248 (* 1 = 0.959248 loss)
I0526 20:26:00.057024   912 sgd_solver.cpp:106] Iteration 400500, lr = 0.0045
I0526 20:26:12.209303   912 solver.cpp:237] Iteration 401250, loss = 0.977919
I0526 20:26:12.209357   912 solver.cpp:253]     Train net output #0: loss = 0.97792 (* 1 = 0.97792 loss)
I0526 20:26:12.209374   912 sgd_solver.cpp:106] Iteration 401250, lr = 0.0045
I0526 20:26:24.317960   912 solver.cpp:237] Iteration 402000, loss = 1.96621
I0526 20:26:24.317996   912 solver.cpp:253]     Train net output #0: loss = 1.96621 (* 1 = 1.96621 loss)
I0526 20:26:24.318014   912 sgd_solver.cpp:106] Iteration 402000, lr = 0.0045
I0526 20:26:36.509110   912 solver.cpp:237] Iteration 402750, loss = 1.31672
I0526 20:26:36.509294   912 solver.cpp:253]     Train net output #0: loss = 1.31672 (* 1 = 1.31672 loss)
I0526 20:26:36.509312   912 sgd_solver.cpp:106] Iteration 402750, lr = 0.0045
I0526 20:26:48.689609   912 solver.cpp:237] Iteration 403500, loss = 1.29016
I0526 20:26:48.689646   912 solver.cpp:253]     Train net output #0: loss = 1.29016 (* 1 = 1.29016 loss)
I0526 20:26:48.689663   912 sgd_solver.cpp:106] Iteration 403500, lr = 0.0045
I0526 20:27:00.853425   912 solver.cpp:237] Iteration 404250, loss = 0.818477
I0526 20:27:00.853479   912 solver.cpp:253]     Train net output #0: loss = 0.818477 (* 1 = 0.818477 loss)
I0526 20:27:00.853497   912 sgd_solver.cpp:106] Iteration 404250, lr = 0.0045
I0526 20:27:12.978718   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_405000.caffemodel
I0526 20:27:13.029160   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_405000.solverstate
I0526 20:27:13.055152   912 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 20:28:25.898905   912 solver.cpp:409]     Test net output #0: accuracy = 0.898618
I0526 20:28:25.899090   912 solver.cpp:409]     Test net output #1: loss = 0.323206 (* 1 = 0.323206 loss)
I0526 20:28:46.762424   912 solver.cpp:237] Iteration 405000, loss = 1.02356
I0526 20:28:46.762485   912 solver.cpp:253]     Train net output #0: loss = 1.02356 (* 1 = 1.02356 loss)
I0526 20:28:46.762513   912 sgd_solver.cpp:106] Iteration 405000, lr = 0.0045
I0526 20:28:58.948830   912 solver.cpp:237] Iteration 405750, loss = 0.696245
I0526 20:28:58.949005   912 solver.cpp:253]     Train net output #0: loss = 0.696246 (* 1 = 0.696246 loss)
I0526 20:28:58.949023   912 sgd_solver.cpp:106] Iteration 405750, lr = 0.0045
I0526 20:29:11.120748   912 solver.cpp:237] Iteration 406500, loss = 1.01036
I0526 20:29:11.120785   912 solver.cpp:253]     Train net output #0: loss = 1.01036 (* 1 = 1.01036 loss)
I0526 20:29:11.120802   912 sgd_solver.cpp:106] Iteration 406500, lr = 0.0045
I0526 20:29:23.291544   912 solver.cpp:237] Iteration 407250, loss = 0.861371
I0526 20:29:23.291596   912 solver.cpp:253]     Train net output #0: loss = 0.861371 (* 1 = 0.861371 loss)
I0526 20:29:23.291613   912 sgd_solver.cpp:106] Iteration 407250, lr = 0.0045
I0526 20:29:35.445050   912 solver.cpp:237] Iteration 408000, loss = 0.848511
I0526 20:29:35.445209   912 solver.cpp:253]     Train net output #0: loss = 0.848512 (* 1 = 0.848512 loss)
I0526 20:29:35.445226   912 sgd_solver.cpp:106] Iteration 408000, lr = 0.0045
I0526 20:29:47.596796   912 solver.cpp:237] Iteration 408750, loss = 1.35643
I0526 20:29:47.596848   912 solver.cpp:253]     Train net output #0: loss = 1.35643 (* 1 = 1.35643 loss)
I0526 20:29:47.596874   912 sgd_solver.cpp:106] Iteration 408750, lr = 0.0045
I0526 20:29:59.741785   912 solver.cpp:237] Iteration 409500, loss = 1.04493
I0526 20:29:59.741822   912 solver.cpp:253]     Train net output #0: loss = 1.04493 (* 1 = 1.04493 loss)
I0526 20:29:59.741839   912 sgd_solver.cpp:106] Iteration 409500, lr = 0.0045
I0526 20:30:32.821187   912 solver.cpp:237] Iteration 410250, loss = 0.900125
I0526 20:30:32.821377   912 solver.cpp:253]     Train net output #0: loss = 0.900126 (* 1 = 0.900126 loss)
I0526 20:30:32.821395   912 sgd_solver.cpp:106] Iteration 410250, lr = 0.0045
I0526 20:30:44.976909   912 solver.cpp:237] Iteration 411000, loss = 1.04842
I0526 20:30:44.976960   912 solver.cpp:253]     Train net output #0: loss = 1.04842 (* 1 = 1.04842 loss)
I0526 20:30:44.976977   912 sgd_solver.cpp:106] Iteration 411000, lr = 0.0045
I0526 20:30:57.113507   912 solver.cpp:237] Iteration 411750, loss = 0.931009
I0526 20:30:57.113545   912 solver.cpp:253]     Train net output #0: loss = 0.931009 (* 1 = 0.931009 loss)
I0526 20:30:57.113562   912 sgd_solver.cpp:106] Iteration 411750, lr = 0.0045
I0526 20:31:09.288542   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_412500.caffemodel
I0526 20:31:09.338353   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_412500.solverstate
I0526 20:31:09.369513   912 solver.cpp:237] Iteration 412500, loss = 0.847132
I0526 20:31:09.369570   912 solver.cpp:253]     Train net output #0: loss = 0.847133 (* 1 = 0.847133 loss)
I0526 20:31:09.369590   912 sgd_solver.cpp:106] Iteration 412500, lr = 0.0045
I0526 20:31:21.532148   912 solver.cpp:237] Iteration 413250, loss = 1.00744
I0526 20:31:21.532186   912 solver.cpp:253]     Train net output #0: loss = 1.00744 (* 1 = 1.00744 loss)
I0526 20:31:21.532203   912 sgd_solver.cpp:106] Iteration 413250, lr = 0.0045
I0526 20:31:33.772471   912 solver.cpp:237] Iteration 414000, loss = 0.855645
I0526 20:31:33.772526   912 solver.cpp:253]     Train net output #0: loss = 0.855646 (* 1 = 0.855646 loss)
I0526 20:31:33.772544   912 sgd_solver.cpp:106] Iteration 414000, lr = 0.0045
I0526 20:31:45.966421   912 solver.cpp:237] Iteration 414750, loss = 1.13303
I0526 20:31:45.966598   912 solver.cpp:253]     Train net output #0: loss = 1.13303 (* 1 = 1.13303 loss)
I0526 20:31:45.966614   912 sgd_solver.cpp:106] Iteration 414750, lr = 0.0045
I0526 20:32:19.091215   912 solver.cpp:237] Iteration 415500, loss = 1.48154
I0526 20:32:19.091394   912 solver.cpp:253]     Train net output #0: loss = 1.48155 (* 1 = 1.48155 loss)
I0526 20:32:19.091411   912 sgd_solver.cpp:106] Iteration 415500, lr = 0.0045
I0526 20:32:31.285653   912 solver.cpp:237] Iteration 416250, loss = 1.43397
I0526 20:32:31.285692   912 solver.cpp:253]     Train net output #0: loss = 1.43397 (* 1 = 1.43397 loss)
I0526 20:32:31.285709   912 sgd_solver.cpp:106] Iteration 416250, lr = 0.0045
I0526 20:32:43.471983   912 solver.cpp:237] Iteration 417000, loss = 1.8499
I0526 20:32:43.472035   912 solver.cpp:253]     Train net output #0: loss = 1.8499 (* 1 = 1.8499 loss)
I0526 20:32:43.472053   912 sgd_solver.cpp:106] Iteration 417000, lr = 0.0045
I0526 20:32:55.623208   912 solver.cpp:237] Iteration 417750, loss = 1.76973
I0526 20:32:55.623384   912 solver.cpp:253]     Train net output #0: loss = 1.76973 (* 1 = 1.76973 loss)
I0526 20:32:55.623401   912 sgd_solver.cpp:106] Iteration 417750, lr = 0.0045
I0526 20:33:07.788638   912 solver.cpp:237] Iteration 418500, loss = 1.03016
I0526 20:33:07.788684   912 solver.cpp:253]     Train net output #0: loss = 1.03016 (* 1 = 1.03016 loss)
I0526 20:33:07.788712   912 sgd_solver.cpp:106] Iteration 418500, lr = 0.0045
I0526 20:33:19.995616   912 solver.cpp:237] Iteration 419250, loss = 1.46601
I0526 20:33:19.995656   912 solver.cpp:253]     Train net output #0: loss = 1.46601 (* 1 = 1.46601 loss)
I0526 20:33:19.995672   912 sgd_solver.cpp:106] Iteration 419250, lr = 0.0045
I0526 20:33:32.230289   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_420000.caffemodel
I0526 20:33:32.279979   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_420000.solverstate
I0526 20:33:32.305649   912 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 20:34:24.329187   912 solver.cpp:409]     Test net output #0: accuracy = 0.898817
I0526 20:34:24.329373   912 solver.cpp:409]     Test net output #1: loss = 0.316546 (* 1 = 0.316546 loss)
I0526 20:34:45.234807   912 solver.cpp:237] Iteration 420000, loss = 1.02062
I0526 20:34:45.234869   912 solver.cpp:253]     Train net output #0: loss = 1.02062 (* 1 = 1.02062 loss)
I0526 20:34:45.234890   912 sgd_solver.cpp:106] Iteration 420000, lr = 0.0045
I0526 20:34:57.429368   912 solver.cpp:237] Iteration 420750, loss = 1.11039
I0526 20:34:57.429555   912 solver.cpp:253]     Train net output #0: loss = 1.11039 (* 1 = 1.11039 loss)
I0526 20:34:57.429572   912 sgd_solver.cpp:106] Iteration 420750, lr = 0.0045
I0526 20:35:09.672158   912 solver.cpp:237] Iteration 421500, loss = 1.03019
I0526 20:35:09.672195   912 solver.cpp:253]     Train net output #0: loss = 1.03019 (* 1 = 1.03019 loss)
I0526 20:35:09.672214   912 sgd_solver.cpp:106] Iteration 421500, lr = 0.0045
I0526 20:35:21.879170   912 solver.cpp:237] Iteration 422250, loss = 1.01708
I0526 20:35:21.879223   912 solver.cpp:253]     Train net output #0: loss = 1.01708 (* 1 = 1.01708 loss)
I0526 20:35:21.879240   912 sgd_solver.cpp:106] Iteration 422250, lr = 0.0045
I0526 20:35:34.111346   912 solver.cpp:237] Iteration 423000, loss = 1.34038
I0526 20:35:34.111508   912 solver.cpp:253]     Train net output #0: loss = 1.34038 (* 1 = 1.34038 loss)
I0526 20:35:34.111526   912 sgd_solver.cpp:106] Iteration 423000, lr = 0.0045
I0526 20:35:46.344377   912 solver.cpp:237] Iteration 423750, loss = 1.17931
I0526 20:35:46.344427   912 solver.cpp:253]     Train net output #0: loss = 1.17931 (* 1 = 1.17931 loss)
I0526 20:35:46.344446   912 sgd_solver.cpp:106] Iteration 423750, lr = 0.0045
I0526 20:35:58.582602   912 solver.cpp:237] Iteration 424500, loss = 0.934045
I0526 20:35:58.582639   912 solver.cpp:253]     Train net output #0: loss = 0.934046 (* 1 = 0.934046 loss)
I0526 20:35:58.582658   912 sgd_solver.cpp:106] Iteration 424500, lr = 0.0045
I0526 20:36:31.683030   912 solver.cpp:237] Iteration 425250, loss = 1.14672
I0526 20:36:31.683210   912 solver.cpp:253]     Train net output #0: loss = 1.14672 (* 1 = 1.14672 loss)
I0526 20:36:31.683228   912 sgd_solver.cpp:106] Iteration 425250, lr = 0.0045
I0526 20:36:43.895177   912 solver.cpp:237] Iteration 426000, loss = 1.02368
I0526 20:36:43.895216   912 solver.cpp:253]     Train net output #0: loss = 1.02368 (* 1 = 1.02368 loss)
I0526 20:36:43.895232   912 sgd_solver.cpp:106] Iteration 426000, lr = 0.0045
I0526 20:36:56.107552   912 solver.cpp:237] Iteration 426750, loss = 1.40873
I0526 20:36:56.107601   912 solver.cpp:253]     Train net output #0: loss = 1.40873 (* 1 = 1.40873 loss)
I0526 20:36:56.107619   912 sgd_solver.cpp:106] Iteration 426750, lr = 0.0045
I0526 20:37:08.218951   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_427500.caffemodel
I0526 20:37:08.351797   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_427500.solverstate
I0526 20:37:08.595655   912 solver.cpp:237] Iteration 427500, loss = 1.42893
I0526 20:37:08.595710   912 solver.cpp:253]     Train net output #0: loss = 1.42893 (* 1 = 1.42893 loss)
I0526 20:37:08.595736   912 sgd_solver.cpp:106] Iteration 427500, lr = 0.0045
I0526 20:37:20.727620   912 solver.cpp:237] Iteration 428250, loss = 1.26019
I0526 20:37:20.727674   912 solver.cpp:253]     Train net output #0: loss = 1.26019 (* 1 = 1.26019 loss)
I0526 20:37:20.727692   912 sgd_solver.cpp:106] Iteration 428250, lr = 0.0045
I0526 20:37:32.850242   912 solver.cpp:237] Iteration 429000, loss = 1.66687
I0526 20:37:32.850281   912 solver.cpp:253]     Train net output #0: loss = 1.66687 (* 1 = 1.66687 loss)
I0526 20:37:32.850298   912 sgd_solver.cpp:106] Iteration 429000, lr = 0.0045
I0526 20:37:44.948508   912 solver.cpp:237] Iteration 429750, loss = 1.07189
I0526 20:37:44.948695   912 solver.cpp:253]     Train net output #0: loss = 1.0719 (* 1 = 1.0719 loss)
I0526 20:37:44.948714   912 sgd_solver.cpp:106] Iteration 429750, lr = 0.0045
I0526 20:38:18.031709   912 solver.cpp:237] Iteration 430500, loss = 0.819579
I0526 20:38:18.031911   912 solver.cpp:253]     Train net output #0: loss = 0.81958 (* 1 = 0.81958 loss)
I0526 20:38:18.031929   912 sgd_solver.cpp:106] Iteration 430500, lr = 0.0045
I0526 20:38:30.196858   912 solver.cpp:237] Iteration 431250, loss = 1.5183
I0526 20:38:30.196897   912 solver.cpp:253]     Train net output #0: loss = 1.5183 (* 1 = 1.5183 loss)
I0526 20:38:30.196914   912 sgd_solver.cpp:106] Iteration 431250, lr = 0.0045
I0526 20:38:42.343511   912 solver.cpp:237] Iteration 432000, loss = 0.986437
I0526 20:38:42.343566   912 solver.cpp:253]     Train net output #0: loss = 0.986438 (* 1 = 0.986438 loss)
I0526 20:38:42.343585   912 sgd_solver.cpp:106] Iteration 432000, lr = 0.0045
I0526 20:38:54.465986   912 solver.cpp:237] Iteration 432750, loss = 1.13249
I0526 20:38:54.466150   912 solver.cpp:253]     Train net output #0: loss = 1.1325 (* 1 = 1.1325 loss)
I0526 20:38:54.466167   912 sgd_solver.cpp:106] Iteration 432750, lr = 0.0045
I0526 20:39:06.634469   912 solver.cpp:237] Iteration 433500, loss = 1.71583
I0526 20:39:06.634519   912 solver.cpp:253]     Train net output #0: loss = 1.71584 (* 1 = 1.71584 loss)
I0526 20:39:06.634538   912 sgd_solver.cpp:106] Iteration 433500, lr = 0.0045
I0526 20:39:18.788686   912 solver.cpp:237] Iteration 434250, loss = 1.00967
I0526 20:39:18.788725   912 solver.cpp:253]     Train net output #0: loss = 1.00967 (* 1 = 1.00967 loss)
I0526 20:39:18.788743   912 sgd_solver.cpp:106] Iteration 434250, lr = 0.0045
I0526 20:39:30.903619   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_435000.caffemodel
I0526 20:39:30.955088   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_435000.solverstate
I0526 20:39:30.984146   912 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 20:40:43.964859   912 solver.cpp:409]     Test net output #0: accuracy = 0.899424
I0526 20:40:43.965036   912 solver.cpp:409]     Test net output #1: loss = 0.329602 (* 1 = 0.329602 loss)
I0526 20:41:04.865759   912 solver.cpp:237] Iteration 435000, loss = 1.14906
I0526 20:41:04.865823   912 solver.cpp:253]     Train net output #0: loss = 1.14906 (* 1 = 1.14906 loss)
I0526 20:41:04.865842   912 sgd_solver.cpp:106] Iteration 435000, lr = 0.0045
I0526 20:41:17.108321   912 solver.cpp:237] Iteration 435750, loss = 1.09654
I0526 20:41:17.108487   912 solver.cpp:253]     Train net output #0: loss = 1.09654 (* 1 = 1.09654 loss)
I0526 20:41:17.108505   912 sgd_solver.cpp:106] Iteration 435750, lr = 0.0045
I0526 20:41:29.224311   912 solver.cpp:237] Iteration 436500, loss = 1.22377
I0526 20:41:29.224359   912 solver.cpp:253]     Train net output #0: loss = 1.22377 (* 1 = 1.22377 loss)
I0526 20:41:29.224376   912 sgd_solver.cpp:106] Iteration 436500, lr = 0.0045
I0526 20:41:41.372992   912 solver.cpp:237] Iteration 437250, loss = 1.52193
I0526 20:41:41.373031   912 solver.cpp:253]     Train net output #0: loss = 1.52193 (* 1 = 1.52193 loss)
I0526 20:41:41.373049   912 sgd_solver.cpp:106] Iteration 437250, lr = 0.0045
I0526 20:41:53.547526   912 solver.cpp:237] Iteration 438000, loss = 1.20562
I0526 20:41:53.547700   912 solver.cpp:253]     Train net output #0: loss = 1.20563 (* 1 = 1.20563 loss)
I0526 20:41:53.547719   912 sgd_solver.cpp:106] Iteration 438000, lr = 0.0045
I0526 20:42:05.740777   912 solver.cpp:237] Iteration 438750, loss = 1.5957
I0526 20:42:05.740814   912 solver.cpp:253]     Train net output #0: loss = 1.5957 (* 1 = 1.5957 loss)
I0526 20:42:05.740831   912 sgd_solver.cpp:106] Iteration 438750, lr = 0.0045
I0526 20:42:17.882299   912 solver.cpp:237] Iteration 439500, loss = 1.2982
I0526 20:42:17.882352   912 solver.cpp:253]     Train net output #0: loss = 1.2982 (* 1 = 1.2982 loss)
I0526 20:42:17.882372   912 sgd_solver.cpp:106] Iteration 439500, lr = 0.0045
I0526 20:42:51.044205   912 solver.cpp:237] Iteration 440250, loss = 1.11104
I0526 20:42:51.044399   912 solver.cpp:253]     Train net output #0: loss = 1.11104 (* 1 = 1.11104 loss)
I0526 20:42:51.044416   912 sgd_solver.cpp:106] Iteration 440250, lr = 0.0045
I0526 20:43:03.298804   912 solver.cpp:237] Iteration 441000, loss = 1.39205
I0526 20:43:03.298841   912 solver.cpp:253]     Train net output #0: loss = 1.39205 (* 1 = 1.39205 loss)
I0526 20:43:03.298861   912 sgd_solver.cpp:106] Iteration 441000, lr = 0.0045
I0526 20:43:15.467788   912 solver.cpp:237] Iteration 441750, loss = 1.62365
I0526 20:43:15.467844   912 solver.cpp:253]     Train net output #0: loss = 1.62365 (* 1 = 1.62365 loss)
I0526 20:43:15.467860   912 sgd_solver.cpp:106] Iteration 441750, lr = 0.0045
I0526 20:43:27.560250   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_442500.caffemodel
I0526 20:43:27.609911   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_442500.solverstate
I0526 20:43:27.641036   912 solver.cpp:237] Iteration 442500, loss = 0.863597
I0526 20:43:27.641091   912 solver.cpp:253]     Train net output #0: loss = 0.863599 (* 1 = 0.863599 loss)
I0526 20:43:27.641109   912 sgd_solver.cpp:106] Iteration 442500, lr = 0.0045
I0526 20:43:39.770400   912 solver.cpp:237] Iteration 443250, loss = 1.16852
I0526 20:43:39.770447   912 solver.cpp:253]     Train net output #0: loss = 1.16852 (* 1 = 1.16852 loss)
I0526 20:43:39.770464   912 sgd_solver.cpp:106] Iteration 443250, lr = 0.0045
I0526 20:43:51.892105   912 solver.cpp:237] Iteration 444000, loss = 1.02003
I0526 20:43:51.892143   912 solver.cpp:253]     Train net output #0: loss = 1.02003 (* 1 = 1.02003 loss)
I0526 20:43:51.892161   912 sgd_solver.cpp:106] Iteration 444000, lr = 0.0045
I0526 20:44:04.059921   912 solver.cpp:237] Iteration 444750, loss = 0.506119
I0526 20:44:04.060113   912 solver.cpp:253]     Train net output #0: loss = 0.506121 (* 1 = 0.506121 loss)
I0526 20:44:04.060132   912 sgd_solver.cpp:106] Iteration 444750, lr = 0.0045
I0526 20:44:37.106528   912 solver.cpp:237] Iteration 445500, loss = 0.856638
I0526 20:44:37.106709   912 solver.cpp:253]     Train net output #0: loss = 0.85664 (* 1 = 0.85664 loss)
I0526 20:44:37.106727   912 sgd_solver.cpp:106] Iteration 445500, lr = 0.0045
I0526 20:44:49.240347   912 solver.cpp:237] Iteration 446250, loss = 1.02882
I0526 20:44:49.240398   912 solver.cpp:253]     Train net output #0: loss = 1.02883 (* 1 = 1.02883 loss)
I0526 20:44:49.240417   912 sgd_solver.cpp:106] Iteration 446250, lr = 0.0045
I0526 20:45:01.412978   912 solver.cpp:237] Iteration 447000, loss = 0.862741
I0526 20:45:01.413017   912 solver.cpp:253]     Train net output #0: loss = 0.862744 (* 1 = 0.862744 loss)
I0526 20:45:01.413033   912 sgd_solver.cpp:106] Iteration 447000, lr = 0.0045
I0526 20:45:13.544481   912 solver.cpp:237] Iteration 447750, loss = 0.972848
I0526 20:45:13.544659   912 solver.cpp:253]     Train net output #0: loss = 0.97285 (* 1 = 0.97285 loss)
I0526 20:45:13.544677   912 sgd_solver.cpp:106] Iteration 447750, lr = 0.0045
I0526 20:45:25.720402   912 solver.cpp:237] Iteration 448500, loss = 1.48425
I0526 20:45:25.720440   912 solver.cpp:253]     Train net output #0: loss = 1.48425 (* 1 = 1.48425 loss)
I0526 20:45:25.720458   912 sgd_solver.cpp:106] Iteration 448500, lr = 0.0045
I0526 20:45:37.865298   912 solver.cpp:237] Iteration 449250, loss = 1.13716
I0526 20:45:37.865351   912 solver.cpp:253]     Train net output #0: loss = 1.13716 (* 1 = 1.13716 loss)
I0526 20:45:37.865370   912 sgd_solver.cpp:106] Iteration 449250, lr = 0.0045
I0526 20:45:49.987587   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_450000.caffemodel
I0526 20:45:50.037802   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_450000.solverstate
I0526 20:45:50.064121   912 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 20:46:41.713160   912 solver.cpp:409]     Test net output #0: accuracy = 0.900797
I0526 20:46:41.713342   912 solver.cpp:409]     Test net output #1: loss = 0.313104 (* 1 = 0.313104 loss)
I0526 20:47:02.600678   912 solver.cpp:237] Iteration 450000, loss = 1.15536
I0526 20:47:02.600736   912 solver.cpp:253]     Train net output #0: loss = 1.15537 (* 1 = 1.15537 loss)
I0526 20:47:02.600766   912 sgd_solver.cpp:106] Iteration 450000, lr = 0.0045
I0526 20:47:14.726950   912 solver.cpp:237] Iteration 450750, loss = 1.20711
I0526 20:47:14.727120   912 solver.cpp:253]     Train net output #0: loss = 1.20712 (* 1 = 1.20712 loss)
I0526 20:47:14.727138   912 sgd_solver.cpp:106] Iteration 450750, lr = 0.0045
I0526 20:47:26.896037   912 solver.cpp:237] Iteration 451500, loss = 0.875621
I0526 20:47:26.896090   912 solver.cpp:253]     Train net output #0: loss = 0.875623 (* 1 = 0.875623 loss)
I0526 20:47:26.896108   912 sgd_solver.cpp:106] Iteration 451500, lr = 0.0045
I0526 20:47:39.040669   912 solver.cpp:237] Iteration 452250, loss = 1.04852
I0526 20:47:39.040707   912 solver.cpp:253]     Train net output #0: loss = 1.04852 (* 1 = 1.04852 loss)
I0526 20:47:39.040724   912 sgd_solver.cpp:106] Iteration 452250, lr = 0.0045
I0526 20:47:51.254945   912 solver.cpp:237] Iteration 453000, loss = 1.08583
I0526 20:47:51.255122   912 solver.cpp:253]     Train net output #0: loss = 1.08583 (* 1 = 1.08583 loss)
I0526 20:47:51.255139   912 sgd_solver.cpp:106] Iteration 453000, lr = 0.0045
I0526 20:48:03.453284   912 solver.cpp:237] Iteration 453750, loss = 1.43312
I0526 20:48:03.453323   912 solver.cpp:253]     Train net output #0: loss = 1.43312 (* 1 = 1.43312 loss)
I0526 20:48:03.453341   912 sgd_solver.cpp:106] Iteration 453750, lr = 0.0045
I0526 20:48:15.603993   912 solver.cpp:237] Iteration 454500, loss = 1.58269
I0526 20:48:15.604046   912 solver.cpp:253]     Train net output #0: loss = 1.58269 (* 1 = 1.58269 loss)
I0526 20:48:15.604063   912 sgd_solver.cpp:106] Iteration 454500, lr = 0.0045
I0526 20:48:48.679647   912 solver.cpp:237] Iteration 455250, loss = 0.835586
I0526 20:48:48.679839   912 solver.cpp:253]     Train net output #0: loss = 0.835589 (* 1 = 0.835589 loss)
I0526 20:48:48.679858   912 sgd_solver.cpp:106] Iteration 455250, lr = 0.0045
I0526 20:49:00.871213   912 solver.cpp:237] Iteration 456000, loss = 1.10578
I0526 20:49:00.871266   912 solver.cpp:253]     Train net output #0: loss = 1.10578 (* 1 = 1.10578 loss)
I0526 20:49:00.871284   912 sgd_solver.cpp:106] Iteration 456000, lr = 0.0045
I0526 20:49:13.056282   912 solver.cpp:237] Iteration 456750, loss = 0.92235
I0526 20:49:13.056321   912 solver.cpp:253]     Train net output #0: loss = 0.922353 (* 1 = 0.922353 loss)
I0526 20:49:13.056339   912 sgd_solver.cpp:106] Iteration 456750, lr = 0.0045
I0526 20:49:25.197027   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_457500.caffemodel
I0526 20:49:25.247288   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_457500.solverstate
I0526 20:49:25.278214   912 solver.cpp:237] Iteration 457500, loss = 1.35584
I0526 20:49:25.278270   912 solver.cpp:253]     Train net output #0: loss = 1.35584 (* 1 = 1.35584 loss)
I0526 20:49:25.278295   912 sgd_solver.cpp:106] Iteration 457500, lr = 0.0045
I0526 20:49:37.482873   912 solver.cpp:237] Iteration 458250, loss = 1.28969
I0526 20:49:37.482910   912 solver.cpp:253]     Train net output #0: loss = 1.28969 (* 1 = 1.28969 loss)
I0526 20:49:37.482929   912 sgd_solver.cpp:106] Iteration 458250, lr = 0.0045
I0526 20:49:49.645783   912 solver.cpp:237] Iteration 459000, loss = 0.762815
I0526 20:49:49.645838   912 solver.cpp:253]     Train net output #0: loss = 0.762818 (* 1 = 0.762818 loss)
I0526 20:49:49.645855   912 sgd_solver.cpp:106] Iteration 459000, lr = 0.0045
I0526 20:50:01.816196   912 solver.cpp:237] Iteration 459750, loss = 1.47837
I0526 20:50:01.816377   912 solver.cpp:253]     Train net output #0: loss = 1.47837 (* 1 = 1.47837 loss)
I0526 20:50:01.816395   912 sgd_solver.cpp:106] Iteration 459750, lr = 0.0045
I0526 20:50:34.911478   912 solver.cpp:237] Iteration 460500, loss = 1.28031
I0526 20:50:34.911671   912 solver.cpp:253]     Train net output #0: loss = 1.28031 (* 1 = 1.28031 loss)
I0526 20:50:34.911689   912 sgd_solver.cpp:106] Iteration 460500, lr = 0.0045
I0526 20:50:47.173496   912 solver.cpp:237] Iteration 461250, loss = 1.20525
I0526 20:50:47.173545   912 solver.cpp:253]     Train net output #0: loss = 1.20525 (* 1 = 1.20525 loss)
I0526 20:50:47.173563   912 sgd_solver.cpp:106] Iteration 461250, lr = 0.0045
I0526 20:50:59.381496   912 solver.cpp:237] Iteration 462000, loss = 0.907669
I0526 20:50:59.381536   912 solver.cpp:253]     Train net output #0: loss = 0.907672 (* 1 = 0.907672 loss)
I0526 20:50:59.381552   912 sgd_solver.cpp:106] Iteration 462000, lr = 0.0045
I0526 20:51:11.564757   912 solver.cpp:237] Iteration 462750, loss = 1.10887
I0526 20:51:11.564935   912 solver.cpp:253]     Train net output #0: loss = 1.10887 (* 1 = 1.10887 loss)
I0526 20:51:11.564954   912 sgd_solver.cpp:106] Iteration 462750, lr = 0.0045
I0526 20:51:23.741436   912 solver.cpp:237] Iteration 463500, loss = 1.33277
I0526 20:51:23.741472   912 solver.cpp:253]     Train net output #0: loss = 1.33277 (* 1 = 1.33277 loss)
I0526 20:51:23.741492   912 sgd_solver.cpp:106] Iteration 463500, lr = 0.0045
I0526 20:51:35.841464   912 solver.cpp:237] Iteration 464250, loss = 1.05371
I0526 20:51:35.841514   912 solver.cpp:253]     Train net output #0: loss = 1.05372 (* 1 = 1.05372 loss)
I0526 20:51:35.841531   912 sgd_solver.cpp:106] Iteration 464250, lr = 0.0045
I0526 20:51:47.950146   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_465000.caffemodel
I0526 20:51:48.000078   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_465000.solverstate
I0526 20:51:48.026111   912 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 20:53:00.823300   912 solver.cpp:409]     Test net output #0: accuracy = 0.901591
I0526 20:53:00.823483   912 solver.cpp:409]     Test net output #1: loss = 0.310451 (* 1 = 0.310451 loss)
I0526 20:53:21.703351   912 solver.cpp:237] Iteration 465000, loss = 1.01394
I0526 20:53:21.703413   912 solver.cpp:253]     Train net output #0: loss = 1.01394 (* 1 = 1.01394 loss)
I0526 20:53:21.703434   912 sgd_solver.cpp:106] Iteration 465000, lr = 0.0045
I0526 20:53:33.924100   912 solver.cpp:237] Iteration 465750, loss = 0.832252
I0526 20:53:33.924284   912 solver.cpp:253]     Train net output #0: loss = 0.832255 (* 1 = 0.832255 loss)
I0526 20:53:33.924301   912 sgd_solver.cpp:106] Iteration 465750, lr = 0.0045
I0526 20:53:46.150650   912 solver.cpp:237] Iteration 466500, loss = 0.942456
I0526 20:53:46.150689   912 solver.cpp:253]     Train net output #0: loss = 0.942459 (* 1 = 0.942459 loss)
I0526 20:53:46.150707   912 sgd_solver.cpp:106] Iteration 466500, lr = 0.0045
I0526 20:53:58.320540   912 solver.cpp:237] Iteration 467250, loss = 1.27839
I0526 20:53:58.320593   912 solver.cpp:253]     Train net output #0: loss = 1.27839 (* 1 = 1.27839 loss)
I0526 20:53:58.320611   912 sgd_solver.cpp:106] Iteration 467250, lr = 0.0045
I0526 20:54:10.467609   912 solver.cpp:237] Iteration 468000, loss = 1.10945
I0526 20:54:10.467784   912 solver.cpp:253]     Train net output #0: loss = 1.10945 (* 1 = 1.10945 loss)
I0526 20:54:10.467802   912 sgd_solver.cpp:106] Iteration 468000, lr = 0.0045
I0526 20:54:22.590747   912 solver.cpp:237] Iteration 468750, loss = 1.26685
I0526 20:54:22.590800   912 solver.cpp:253]     Train net output #0: loss = 1.26685 (* 1 = 1.26685 loss)
I0526 20:54:22.590824   912 sgd_solver.cpp:106] Iteration 468750, lr = 0.0045
I0526 20:54:34.730829   912 solver.cpp:237] Iteration 469500, loss = 1.3054
I0526 20:54:34.730866   912 solver.cpp:253]     Train net output #0: loss = 1.3054 (* 1 = 1.3054 loss)
I0526 20:54:34.730885   912 sgd_solver.cpp:106] Iteration 469500, lr = 0.0045
I0526 20:55:07.712534   912 solver.cpp:237] Iteration 470250, loss = 1.08441
I0526 20:55:07.712721   912 solver.cpp:253]     Train net output #0: loss = 1.08441 (* 1 = 1.08441 loss)
I0526 20:55:07.712738   912 sgd_solver.cpp:106] Iteration 470250, lr = 0.0045
I0526 20:55:19.854661   912 solver.cpp:237] Iteration 471000, loss = 1.00187
I0526 20:55:19.854712   912 solver.cpp:253]     Train net output #0: loss = 1.00187 (* 1 = 1.00187 loss)
I0526 20:55:19.854730   912 sgd_solver.cpp:106] Iteration 471000, lr = 0.0045
I0526 20:55:31.939990   912 solver.cpp:237] Iteration 471750, loss = 1.20116
I0526 20:55:31.940026   912 solver.cpp:253]     Train net output #0: loss = 1.20116 (* 1 = 1.20116 loss)
I0526 20:55:31.940043   912 sgd_solver.cpp:106] Iteration 471750, lr = 0.0045
I0526 20:55:44.039119   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_472500.caffemodel
I0526 20:55:44.090435   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_472500.solverstate
I0526 20:55:44.125697   912 solver.cpp:237] Iteration 472500, loss = 1.16489
I0526 20:55:44.125753   912 solver.cpp:253]     Train net output #0: loss = 1.16489 (* 1 = 1.16489 loss)
I0526 20:55:44.125771   912 sgd_solver.cpp:106] Iteration 472500, lr = 0.0045
I0526 20:55:56.230311   912 solver.cpp:237] Iteration 473250, loss = 1.20763
I0526 20:55:56.230348   912 solver.cpp:253]     Train net output #0: loss = 1.20763 (* 1 = 1.20763 loss)
I0526 20:55:56.230367   912 sgd_solver.cpp:106] Iteration 473250, lr = 0.0045
I0526 20:56:08.354787   912 solver.cpp:237] Iteration 474000, loss = 1.12548
I0526 20:56:08.354838   912 solver.cpp:253]     Train net output #0: loss = 1.12549 (* 1 = 1.12549 loss)
I0526 20:56:08.354857   912 sgd_solver.cpp:106] Iteration 474000, lr = 0.0045
I0526 20:56:20.541506   912 solver.cpp:237] Iteration 474750, loss = 0.418125
I0526 20:56:20.541678   912 solver.cpp:253]     Train net output #0: loss = 0.418128 (* 1 = 0.418128 loss)
I0526 20:56:20.541695   912 sgd_solver.cpp:106] Iteration 474750, lr = 0.0045
I0526 20:56:53.584637   912 solver.cpp:237] Iteration 475500, loss = 1.46988
I0526 20:56:53.584825   912 solver.cpp:253]     Train net output #0: loss = 1.46988 (* 1 = 1.46988 loss)
I0526 20:56:53.584842   912 sgd_solver.cpp:106] Iteration 475500, lr = 0.0045
I0526 20:57:05.697909   912 solver.cpp:237] Iteration 476250, loss = 1.29768
I0526 20:57:05.697948   912 solver.cpp:253]     Train net output #0: loss = 1.29769 (* 1 = 1.29769 loss)
I0526 20:57:05.697965   912 sgd_solver.cpp:106] Iteration 476250, lr = 0.0045
I0526 20:57:17.817948   912 solver.cpp:237] Iteration 477000, loss = 1.06997
I0526 20:57:17.817996   912 solver.cpp:253]     Train net output #0: loss = 1.06997 (* 1 = 1.06997 loss)
I0526 20:57:17.818020   912 sgd_solver.cpp:106] Iteration 477000, lr = 0.0045
I0526 20:57:29.954663   912 solver.cpp:237] Iteration 477750, loss = 1.4512
I0526 20:57:29.954828   912 solver.cpp:253]     Train net output #0: loss = 1.45121 (* 1 = 1.45121 loss)
I0526 20:57:29.954844   912 sgd_solver.cpp:106] Iteration 477750, lr = 0.0045
I0526 20:57:42.093344   912 solver.cpp:237] Iteration 478500, loss = 1.09885
I0526 20:57:42.093390   912 solver.cpp:253]     Train net output #0: loss = 1.09886 (* 1 = 1.09886 loss)
I0526 20:57:42.093417   912 sgd_solver.cpp:106] Iteration 478500, lr = 0.0045
I0526 20:57:54.243265   912 solver.cpp:237] Iteration 479250, loss = 0.951712
I0526 20:57:54.243304   912 solver.cpp:253]     Train net output #0: loss = 0.951715 (* 1 = 0.951715 loss)
I0526 20:57:54.243321   912 sgd_solver.cpp:106] Iteration 479250, lr = 0.0045
I0526 20:58:06.377014   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_480000.caffemodel
I0526 20:58:06.427482   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_480000.solverstate
I0526 20:58:06.453891   912 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 20:58:58.467226   912 solver.cpp:409]     Test net output #0: accuracy = 0.904451
I0526 20:58:58.467412   912 solver.cpp:409]     Test net output #1: loss = 0.329428 (* 1 = 0.329428 loss)
I0526 20:59:19.371546   912 solver.cpp:237] Iteration 480000, loss = 0.873876
I0526 20:59:19.371608   912 solver.cpp:253]     Train net output #0: loss = 0.873879 (* 1 = 0.873879 loss)
I0526 20:59:19.371629   912 sgd_solver.cpp:106] Iteration 480000, lr = 0.0045
I0526 20:59:31.530247   912 solver.cpp:237] Iteration 480750, loss = 0.994037
I0526 20:59:31.530429   912 solver.cpp:253]     Train net output #0: loss = 0.99404 (* 1 = 0.99404 loss)
I0526 20:59:31.530447   912 sgd_solver.cpp:106] Iteration 480750, lr = 0.0045
I0526 20:59:43.705958   912 solver.cpp:237] Iteration 481500, loss = 1.33689
I0526 20:59:43.705996   912 solver.cpp:253]     Train net output #0: loss = 1.33689 (* 1 = 1.33689 loss)
I0526 20:59:43.706013   912 sgd_solver.cpp:106] Iteration 481500, lr = 0.0045
I0526 20:59:55.867936   912 solver.cpp:237] Iteration 482250, loss = 1.39887
I0526 20:59:55.867986   912 solver.cpp:253]     Train net output #0: loss = 1.39888 (* 1 = 1.39888 loss)
I0526 20:59:55.868005   912 sgd_solver.cpp:106] Iteration 482250, lr = 0.0045
I0526 21:00:08.026590   912 solver.cpp:237] Iteration 483000, loss = 1.52472
I0526 21:00:08.026758   912 solver.cpp:253]     Train net output #0: loss = 1.52473 (* 1 = 1.52473 loss)
I0526 21:00:08.026775   912 sgd_solver.cpp:106] Iteration 483000, lr = 0.0045
I0526 21:00:20.135797   912 solver.cpp:237] Iteration 483750, loss = 1.19655
I0526 21:00:20.135854   912 solver.cpp:253]     Train net output #0: loss = 1.19655 (* 1 = 1.19655 loss)
I0526 21:00:20.135871   912 sgd_solver.cpp:106] Iteration 483750, lr = 0.0045
I0526 21:00:32.223664   912 solver.cpp:237] Iteration 484500, loss = 0.916048
I0526 21:00:32.223703   912 solver.cpp:253]     Train net output #0: loss = 0.916051 (* 1 = 0.916051 loss)
I0526 21:00:32.223722   912 sgd_solver.cpp:106] Iteration 484500, lr = 0.0045
I0526 21:01:05.282896   912 solver.cpp:237] Iteration 485250, loss = 1.07033
I0526 21:01:05.283084   912 solver.cpp:253]     Train net output #0: loss = 1.07034 (* 1 = 1.07034 loss)
I0526 21:01:05.283102   912 sgd_solver.cpp:106] Iteration 485250, lr = 0.0045
I0526 21:01:17.427342   912 solver.cpp:237] Iteration 486000, loss = 1.21102
I0526 21:01:17.427381   912 solver.cpp:253]     Train net output #0: loss = 1.21102 (* 1 = 1.21102 loss)
I0526 21:01:17.427397   912 sgd_solver.cpp:106] Iteration 486000, lr = 0.0045
I0526 21:01:29.588202   912 solver.cpp:237] Iteration 486750, loss = 1.24417
I0526 21:01:29.588256   912 solver.cpp:253]     Train net output #0: loss = 1.24417 (* 1 = 1.24417 loss)
I0526 21:01:29.588274   912 sgd_solver.cpp:106] Iteration 486750, lr = 0.0045
I0526 21:01:41.779914   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_487500.caffemodel
I0526 21:01:41.830126   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_487500.solverstate
I0526 21:01:41.861320   912 solver.cpp:237] Iteration 487500, loss = 1.21028
I0526 21:01:41.861374   912 solver.cpp:253]     Train net output #0: loss = 1.21029 (* 1 = 1.21029 loss)
I0526 21:01:41.861402   912 sgd_solver.cpp:106] Iteration 487500, lr = 0.0045
I0526 21:01:54.027259   912 solver.cpp:237] Iteration 488250, loss = 0.973997
I0526 21:01:54.027312   912 solver.cpp:253]     Train net output #0: loss = 0.974 (* 1 = 0.974 loss)
I0526 21:01:54.027330   912 sgd_solver.cpp:106] Iteration 488250, lr = 0.0045
I0526 21:02:06.158468   912 solver.cpp:237] Iteration 489000, loss = 0.903504
I0526 21:02:06.158506   912 solver.cpp:253]     Train net output #0: loss = 0.903507 (* 1 = 0.903507 loss)
I0526 21:02:06.158524   912 sgd_solver.cpp:106] Iteration 489000, lr = 0.0045
I0526 21:02:18.309238   912 solver.cpp:237] Iteration 489750, loss = 1.29809
I0526 21:02:18.309427   912 solver.cpp:253]     Train net output #0: loss = 1.29809 (* 1 = 1.29809 loss)
I0526 21:02:18.309445   912 sgd_solver.cpp:106] Iteration 489750, lr = 0.0045
I0526 21:02:51.287988   912 solver.cpp:237] Iteration 490500, loss = 1.25948
I0526 21:02:51.288177   912 solver.cpp:253]     Train net output #0: loss = 1.25949 (* 1 = 1.25949 loss)
I0526 21:02:51.288194   912 sgd_solver.cpp:106] Iteration 490500, lr = 0.0045
I0526 21:03:03.353258   912 solver.cpp:237] Iteration 491250, loss = 1.33123
I0526 21:03:03.353298   912 solver.cpp:253]     Train net output #0: loss = 1.33124 (* 1 = 1.33124 loss)
I0526 21:03:03.353315   912 sgd_solver.cpp:106] Iteration 491250, lr = 0.0045
I0526 21:03:15.478723   912 solver.cpp:237] Iteration 492000, loss = 1.37358
I0526 21:03:15.478776   912 solver.cpp:253]     Train net output #0: loss = 1.37358 (* 1 = 1.37358 loss)
I0526 21:03:15.478793   912 sgd_solver.cpp:106] Iteration 492000, lr = 0.0045
I0526 21:03:27.598544   912 solver.cpp:237] Iteration 492750, loss = 1.08195
I0526 21:03:27.598713   912 solver.cpp:253]     Train net output #0: loss = 1.08196 (* 1 = 1.08196 loss)
I0526 21:03:27.598731   912 sgd_solver.cpp:106] Iteration 492750, lr = 0.0045
I0526 21:03:39.774566   912 solver.cpp:237] Iteration 493500, loss = 1.50903
I0526 21:03:39.774621   912 solver.cpp:253]     Train net output #0: loss = 1.50904 (* 1 = 1.50904 loss)
I0526 21:03:39.774639   912 sgd_solver.cpp:106] Iteration 493500, lr = 0.0045
I0526 21:03:51.946406   912 solver.cpp:237] Iteration 494250, loss = 0.97216
I0526 21:03:51.946446   912 solver.cpp:253]     Train net output #0: loss = 0.972163 (* 1 = 0.972163 loss)
I0526 21:03:51.946465   912 sgd_solver.cpp:106] Iteration 494250, lr = 0.0045
I0526 21:04:04.043051   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_495000.caffemodel
I0526 21:04:04.094856   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_495000.solverstate
I0526 21:04:04.121510   912 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 21:05:16.990301   912 solver.cpp:409]     Test net output #0: accuracy = 0.903099
I0526 21:05:16.990494   912 solver.cpp:409]     Test net output #1: loss = 0.307426 (* 1 = 0.307426 loss)
I0526 21:05:37.897313   912 solver.cpp:237] Iteration 495000, loss = 1.30538
I0526 21:05:37.897374   912 solver.cpp:253]     Train net output #0: loss = 1.30539 (* 1 = 1.30539 loss)
I0526 21:05:37.897395   912 sgd_solver.cpp:106] Iteration 495000, lr = 0.0045
I0526 21:05:50.092999   912 solver.cpp:237] Iteration 495750, loss = 1.2397
I0526 21:05:50.093173   912 solver.cpp:253]     Train net output #0: loss = 1.23971 (* 1 = 1.23971 loss)
I0526 21:05:50.093190   912 sgd_solver.cpp:106] Iteration 495750, lr = 0.0045
I0526 21:06:02.270895   912 solver.cpp:237] Iteration 496500, loss = 0.763542
I0526 21:06:02.270947   912 solver.cpp:253]     Train net output #0: loss = 0.763545 (* 1 = 0.763545 loss)
I0526 21:06:02.270965   912 sgd_solver.cpp:106] Iteration 496500, lr = 0.0045
I0526 21:06:14.458710   912 solver.cpp:237] Iteration 497250, loss = 0.747838
I0526 21:06:14.458748   912 solver.cpp:253]     Train net output #0: loss = 0.74784 (* 1 = 0.74784 loss)
I0526 21:06:14.458766   912 sgd_solver.cpp:106] Iteration 497250, lr = 0.0045
I0526 21:06:26.656225   912 solver.cpp:237] Iteration 498000, loss = 0.743433
I0526 21:06:26.656421   912 solver.cpp:253]     Train net output #0: loss = 0.743436 (* 1 = 0.743436 loss)
I0526 21:06:26.656440   912 sgd_solver.cpp:106] Iteration 498000, lr = 0.0045
I0526 21:06:38.760596   912 solver.cpp:237] Iteration 498750, loss = 1.3621
I0526 21:06:38.760633   912 solver.cpp:253]     Train net output #0: loss = 1.36211 (* 1 = 1.36211 loss)
I0526 21:06:38.760653   912 sgd_solver.cpp:106] Iteration 498750, lr = 0.0045
I0526 21:06:50.898373   912 solver.cpp:237] Iteration 499500, loss = 0.681472
I0526 21:06:50.898428   912 solver.cpp:253]     Train net output #0: loss = 0.681475 (* 1 = 0.681475 loss)
I0526 21:06:50.898448   912 sgd_solver.cpp:106] Iteration 499500, lr = 0.0045
I0526 21:07:24.069911   912 solver.cpp:237] Iteration 500250, loss = 1.3713
I0526 21:07:24.070101   912 solver.cpp:253]     Train net output #0: loss = 1.3713 (* 1 = 1.3713 loss)
I0526 21:07:24.070119   912 sgd_solver.cpp:106] Iteration 500250, lr = 0.0045
I0526 21:07:36.339961   912 solver.cpp:237] Iteration 501000, loss = 1.53347
I0526 21:07:36.339999   912 solver.cpp:253]     Train net output #0: loss = 1.53347 (* 1 = 1.53347 loss)
I0526 21:07:36.340016   912 sgd_solver.cpp:106] Iteration 501000, lr = 0.0045
I0526 21:07:48.567225   912 solver.cpp:237] Iteration 501750, loss = 0.902533
I0526 21:07:48.567281   912 solver.cpp:253]     Train net output #0: loss = 0.902536 (* 1 = 0.902536 loss)
I0526 21:07:48.567298   912 sgd_solver.cpp:106] Iteration 501750, lr = 0.0045
I0526 21:08:00.715381   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_502500.caffemodel
I0526 21:08:00.767504   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_502500.solverstate
I0526 21:08:00.800681   912 solver.cpp:237] Iteration 502500, loss = 1.27484
I0526 21:08:00.800742   912 solver.cpp:253]     Train net output #0: loss = 1.27484 (* 1 = 1.27484 loss)
I0526 21:08:00.800760   912 sgd_solver.cpp:106] Iteration 502500, lr = 0.0045
I0526 21:08:12.973697   912 solver.cpp:237] Iteration 503250, loss = 0.857558
I0526 21:08:12.973749   912 solver.cpp:253]     Train net output #0: loss = 0.857561 (* 1 = 0.857561 loss)
I0526 21:08:12.973767   912 sgd_solver.cpp:106] Iteration 503250, lr = 0.0045
I0526 21:08:25.103729   912 solver.cpp:237] Iteration 504000, loss = 1.32001
I0526 21:08:25.103768   912 solver.cpp:253]     Train net output #0: loss = 1.32002 (* 1 = 1.32002 loss)
I0526 21:08:25.103785   912 sgd_solver.cpp:106] Iteration 504000, lr = 0.0045
I0526 21:08:37.209807   912 solver.cpp:237] Iteration 504750, loss = 1.30317
I0526 21:08:37.209995   912 solver.cpp:253]     Train net output #0: loss = 1.30317 (* 1 = 1.30317 loss)
I0526 21:08:37.210013   912 sgd_solver.cpp:106] Iteration 504750, lr = 0.0045
I0526 21:09:10.156105   912 solver.cpp:237] Iteration 505500, loss = 1.01834
I0526 21:09:10.156293   912 solver.cpp:253]     Train net output #0: loss = 1.01834 (* 1 = 1.01834 loss)
I0526 21:09:10.156311   912 sgd_solver.cpp:106] Iteration 505500, lr = 0.0045
I0526 21:09:22.244032   912 solver.cpp:237] Iteration 506250, loss = 0.925505
I0526 21:09:22.244086   912 solver.cpp:253]     Train net output #0: loss = 0.925507 (* 1 = 0.925507 loss)
I0526 21:09:22.244112   912 sgd_solver.cpp:106] Iteration 506250, lr = 0.0045
I0526 21:09:34.334236   912 solver.cpp:237] Iteration 507000, loss = 1.18615
I0526 21:09:34.334273   912 solver.cpp:253]     Train net output #0: loss = 1.18616 (* 1 = 1.18616 loss)
I0526 21:09:34.334290   912 sgd_solver.cpp:106] Iteration 507000, lr = 0.0045
I0526 21:09:46.492756   912 solver.cpp:237] Iteration 507750, loss = 1.60331
I0526 21:09:46.492949   912 solver.cpp:253]     Train net output #0: loss = 1.60331 (* 1 = 1.60331 loss)
I0526 21:09:46.492967   912 sgd_solver.cpp:106] Iteration 507750, lr = 0.0045
I0526 21:09:58.726979   912 solver.cpp:237] Iteration 508500, loss = 1.08879
I0526 21:09:58.727018   912 solver.cpp:253]     Train net output #0: loss = 1.08879 (* 1 = 1.08879 loss)
I0526 21:09:58.727035   912 sgd_solver.cpp:106] Iteration 508500, lr = 0.0045
I0526 21:10:10.950723   912 solver.cpp:237] Iteration 509250, loss = 1.36609
I0526 21:10:10.950776   912 solver.cpp:253]     Train net output #0: loss = 1.36609 (* 1 = 1.36609 loss)
I0526 21:10:10.950803   912 sgd_solver.cpp:106] Iteration 509250, lr = 0.0045
I0526 21:10:23.142299   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_510000.caffemodel
I0526 21:10:23.193773   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_510000.solverstate
I0526 21:10:23.223526   912 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 21:11:14.856744   912 solver.cpp:409]     Test net output #0: accuracy = 0.90071
I0526 21:11:14.856937   912 solver.cpp:409]     Test net output #1: loss = 0.307723 (* 1 = 0.307723 loss)
I0526 21:11:35.728869   912 solver.cpp:237] Iteration 510000, loss = 1.22765
I0526 21:11:35.728930   912 solver.cpp:253]     Train net output #0: loss = 1.22765 (* 1 = 1.22765 loss)
I0526 21:11:35.728960   912 sgd_solver.cpp:106] Iteration 510000, lr = 0.0045
I0526 21:11:47.936094   912 solver.cpp:237] Iteration 510750, loss = 1.145
I0526 21:11:47.936269   912 solver.cpp:253]     Train net output #0: loss = 1.145 (* 1 = 1.145 loss)
I0526 21:11:47.936286   912 sgd_solver.cpp:106] Iteration 510750, lr = 0.0045
I0526 21:12:00.084236   912 solver.cpp:237] Iteration 511500, loss = 0.94491
I0526 21:12:00.084291   912 solver.cpp:253]     Train net output #0: loss = 0.944912 (* 1 = 0.944912 loss)
I0526 21:12:00.084309   912 sgd_solver.cpp:106] Iteration 511500, lr = 0.0045
I0526 21:12:12.241397   912 solver.cpp:237] Iteration 512250, loss = 1.44951
I0526 21:12:12.241435   912 solver.cpp:253]     Train net output #0: loss = 1.44951 (* 1 = 1.44951 loss)
I0526 21:12:12.241452   912 sgd_solver.cpp:106] Iteration 512250, lr = 0.0045
I0526 21:12:24.435029   912 solver.cpp:237] Iteration 513000, loss = 0.719278
I0526 21:12:24.435216   912 solver.cpp:253]     Train net output #0: loss = 0.719281 (* 1 = 0.719281 loss)
I0526 21:12:24.435233   912 sgd_solver.cpp:106] Iteration 513000, lr = 0.0045
I0526 21:12:36.637485   912 solver.cpp:237] Iteration 513750, loss = 1.27359
I0526 21:12:36.637521   912 solver.cpp:253]     Train net output #0: loss = 1.27359 (* 1 = 1.27359 loss)
I0526 21:12:36.637539   912 sgd_solver.cpp:106] Iteration 513750, lr = 0.0045
I0526 21:12:48.784705   912 solver.cpp:237] Iteration 514500, loss = 1.14477
I0526 21:12:48.784757   912 solver.cpp:253]     Train net output #0: loss = 1.14478 (* 1 = 1.14478 loss)
I0526 21:12:48.784775   912 sgd_solver.cpp:106] Iteration 514500, lr = 0.0045
I0526 21:13:21.768472   912 solver.cpp:237] Iteration 515250, loss = 1.23974
I0526 21:13:21.768662   912 solver.cpp:253]     Train net output #0: loss = 1.23974 (* 1 = 1.23974 loss)
I0526 21:13:21.768679   912 sgd_solver.cpp:106] Iteration 515250, lr = 0.0045
I0526 21:13:33.912238   912 solver.cpp:237] Iteration 516000, loss = 1.11057
I0526 21:13:33.912292   912 solver.cpp:253]     Train net output #0: loss = 1.11057 (* 1 = 1.11057 loss)
I0526 21:13:33.912309   912 sgd_solver.cpp:106] Iteration 516000, lr = 0.0045
I0526 21:13:46.022454   912 solver.cpp:237] Iteration 516750, loss = 1.47793
I0526 21:13:46.022491   912 solver.cpp:253]     Train net output #0: loss = 1.47793 (* 1 = 1.47793 loss)
I0526 21:13:46.022510   912 sgd_solver.cpp:106] Iteration 516750, lr = 0.0045
I0526 21:13:58.116991   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_517500.caffemodel
I0526 21:13:58.167559   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_517500.solverstate
I0526 21:13:58.198884   912 solver.cpp:237] Iteration 517500, loss = 1.10993
I0526 21:13:58.198937   912 solver.cpp:253]     Train net output #0: loss = 1.10994 (* 1 = 1.10994 loss)
I0526 21:13:58.198964   912 sgd_solver.cpp:106] Iteration 517500, lr = 0.0045
I0526 21:14:10.314695   912 solver.cpp:237] Iteration 518250, loss = 1.29448
I0526 21:14:10.314733   912 solver.cpp:253]     Train net output #0: loss = 1.29448 (* 1 = 1.29448 loss)
I0526 21:14:10.314750   912 sgd_solver.cpp:106] Iteration 518250, lr = 0.0045
I0526 21:14:22.425458   912 solver.cpp:237] Iteration 519000, loss = 1.31674
I0526 21:14:22.425513   912 solver.cpp:253]     Train net output #0: loss = 1.31674 (* 1 = 1.31674 loss)
I0526 21:14:22.425537   912 sgd_solver.cpp:106] Iteration 519000, lr = 0.0045
I0526 21:14:34.551622   912 solver.cpp:237] Iteration 519750, loss = 1.31428
I0526 21:14:34.551801   912 solver.cpp:253]     Train net output #0: loss = 1.31428 (* 1 = 1.31428 loss)
I0526 21:14:34.551823   912 sgd_solver.cpp:106] Iteration 519750, lr = 0.0045
I0526 21:15:07.540577   912 solver.cpp:237] Iteration 520500, loss = 0.799894
I0526 21:15:07.540772   912 solver.cpp:253]     Train net output #0: loss = 0.799897 (* 1 = 0.799897 loss)
I0526 21:15:07.540789   912 sgd_solver.cpp:106] Iteration 520500, lr = 0.0045
I0526 21:15:19.698261   912 solver.cpp:237] Iteration 521250, loss = 1.26437
I0526 21:15:19.698312   912 solver.cpp:253]     Train net output #0: loss = 1.26437 (* 1 = 1.26437 loss)
I0526 21:15:19.698330   912 sgd_solver.cpp:106] Iteration 521250, lr = 0.0045
I0526 21:15:31.901407   912 solver.cpp:237] Iteration 522000, loss = 1.06495
I0526 21:15:31.901445   912 solver.cpp:253]     Train net output #0: loss = 1.06496 (* 1 = 1.06496 loss)
I0526 21:15:31.901463   912 sgd_solver.cpp:106] Iteration 522000, lr = 0.0045
I0526 21:15:44.112757   912 solver.cpp:237] Iteration 522750, loss = 1.08675
I0526 21:15:44.112956   912 solver.cpp:253]     Train net output #0: loss = 1.08676 (* 1 = 1.08676 loss)
I0526 21:15:44.112974   912 sgd_solver.cpp:106] Iteration 522750, lr = 0.0045
I0526 21:15:56.297651   912 solver.cpp:237] Iteration 523500, loss = 1.16078
I0526 21:15:56.297688   912 solver.cpp:253]     Train net output #0: loss = 1.16078 (* 1 = 1.16078 loss)
I0526 21:15:56.297705   912 sgd_solver.cpp:106] Iteration 523500, lr = 0.0045
I0526 21:16:08.508155   912 solver.cpp:237] Iteration 524250, loss = 1.47438
I0526 21:16:08.508208   912 solver.cpp:253]     Train net output #0: loss = 1.47438 (* 1 = 1.47438 loss)
I0526 21:16:08.508225   912 sgd_solver.cpp:106] Iteration 524250, lr = 0.0045
I0526 21:16:20.723175   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_525000.caffemodel
I0526 21:16:20.773226   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_525000.solverstate
I0526 21:16:20.799280   912 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 21:17:33.801995   912 solver.cpp:409]     Test net output #0: accuracy = 0.902849
I0526 21:17:33.802187   912 solver.cpp:409]     Test net output #1: loss = 0.294805 (* 1 = 0.294805 loss)
I0526 21:17:54.687625   912 solver.cpp:237] Iteration 525000, loss = 0.705463
I0526 21:17:54.687685   912 solver.cpp:253]     Train net output #0: loss = 0.705467 (* 1 = 0.705467 loss)
I0526 21:17:54.687714   912 sgd_solver.cpp:106] Iteration 525000, lr = 0.0045
I0526 21:18:06.801540   912 solver.cpp:237] Iteration 525750, loss = 0.762088
I0526 21:18:06.801743   912 solver.cpp:253]     Train net output #0: loss = 0.762091 (* 1 = 0.762091 loss)
I0526 21:18:06.801760   912 sgd_solver.cpp:106] Iteration 525750, lr = 0.0045
I0526 21:18:18.963585   912 solver.cpp:237] Iteration 526500, loss = 0.816122
I0526 21:18:18.963625   912 solver.cpp:253]     Train net output #0: loss = 0.816126 (* 1 = 0.816126 loss)
I0526 21:18:18.963642   912 sgd_solver.cpp:106] Iteration 526500, lr = 0.0045
I0526 21:18:31.135732   912 solver.cpp:237] Iteration 527250, loss = 1.3843
I0526 21:18:31.135787   912 solver.cpp:253]     Train net output #0: loss = 1.3843 (* 1 = 1.3843 loss)
I0526 21:18:31.135812   912 sgd_solver.cpp:106] Iteration 527250, lr = 0.0045
I0526 21:18:43.294889   912 solver.cpp:237] Iteration 528000, loss = 1.12949
I0526 21:18:43.295065   912 solver.cpp:253]     Train net output #0: loss = 1.12949 (* 1 = 1.12949 loss)
I0526 21:18:43.295083   912 sgd_solver.cpp:106] Iteration 528000, lr = 0.0045
I0526 21:18:55.484043   912 solver.cpp:237] Iteration 528750, loss = 1.41125
I0526 21:18:55.484081   912 solver.cpp:253]     Train net output #0: loss = 1.41125 (* 1 = 1.41125 loss)
I0526 21:18:55.484098   912 sgd_solver.cpp:106] Iteration 528750, lr = 0.0045
I0526 21:19:20.963883   912 solver.cpp:237] Iteration 529500, loss = 0.812632
I0526 21:19:20.964072   912 solver.cpp:253]     Train net output #0: loss = 0.812635 (* 1 = 0.812635 loss)
I0526 21:19:20.964089   912 sgd_solver.cpp:106] Iteration 529500, lr = 0.0045
I0526 21:19:53.990322   912 solver.cpp:237] Iteration 530250, loss = 1.22549
I0526 21:19:53.990520   912 solver.cpp:253]     Train net output #0: loss = 1.22549 (* 1 = 1.22549 loss)
I0526 21:19:53.990537   912 sgd_solver.cpp:106] Iteration 530250, lr = 0.0045
I0526 21:20:06.195114   912 solver.cpp:237] Iteration 531000, loss = 1.03126
I0526 21:20:06.195152   912 solver.cpp:253]     Train net output #0: loss = 1.03126 (* 1 = 1.03126 loss)
I0526 21:20:06.195176   912 sgd_solver.cpp:106] Iteration 531000, lr = 0.0045
I0526 21:20:18.389470   912 solver.cpp:237] Iteration 531750, loss = 1.5129
I0526 21:20:18.389523   912 solver.cpp:253]     Train net output #0: loss = 1.51291 (* 1 = 1.51291 loss)
I0526 21:20:18.389540   912 sgd_solver.cpp:106] Iteration 531750, lr = 0.0045
I0526 21:20:30.599822   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_532500.caffemodel
I0526 21:20:30.650339   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_532500.solverstate
I0526 21:20:30.681567   912 solver.cpp:237] Iteration 532500, loss = 1.12531
I0526 21:20:30.681627   912 solver.cpp:253]     Train net output #0: loss = 1.12531 (* 1 = 1.12531 loss)
I0526 21:20:30.681646   912 sgd_solver.cpp:106] Iteration 532500, lr = 0.0045
I0526 21:20:42.867700   912 solver.cpp:237] Iteration 533250, loss = 0.882548
I0526 21:20:42.867755   912 solver.cpp:253]     Train net output #0: loss = 0.882551 (* 1 = 0.882551 loss)
I0526 21:20:42.867774   912 sgd_solver.cpp:106] Iteration 533250, lr = 0.0045
I0526 21:20:55.017093   912 solver.cpp:237] Iteration 534000, loss = 0.604554
I0526 21:20:55.017133   912 solver.cpp:253]     Train net output #0: loss = 0.604557 (* 1 = 0.604557 loss)
I0526 21:20:55.017153   912 sgd_solver.cpp:106] Iteration 534000, lr = 0.0045
I0526 21:21:07.192374   912 solver.cpp:237] Iteration 534750, loss = 1.06292
I0526 21:21:07.192564   912 solver.cpp:253]     Train net output #0: loss = 1.06293 (* 1 = 1.06293 loss)
I0526 21:21:07.192580   912 sgd_solver.cpp:106] Iteration 534750, lr = 0.0045
I0526 21:21:40.269847   912 solver.cpp:237] Iteration 535500, loss = 0.990142
I0526 21:21:40.270051   912 solver.cpp:253]     Train net output #0: loss = 0.990145 (* 1 = 0.990145 loss)
I0526 21:21:40.270071   912 sgd_solver.cpp:106] Iteration 535500, lr = 0.0045
I0526 21:21:52.426167   912 solver.cpp:237] Iteration 536250, loss = 1.68155
I0526 21:21:52.426219   912 solver.cpp:253]     Train net output #0: loss = 1.68156 (* 1 = 1.68156 loss)
I0526 21:21:52.426245   912 sgd_solver.cpp:106] Iteration 536250, lr = 0.0045
I0526 21:22:04.615886   912 solver.cpp:237] Iteration 537000, loss = 1.05635
I0526 21:22:04.615924   912 solver.cpp:253]     Train net output #0: loss = 1.05635 (* 1 = 1.05635 loss)
I0526 21:22:04.615949   912 sgd_solver.cpp:106] Iteration 537000, lr = 0.0045
I0526 21:22:16.802268   912 solver.cpp:237] Iteration 537750, loss = 0.818512
I0526 21:22:16.802460   912 solver.cpp:253]     Train net output #0: loss = 0.818515 (* 1 = 0.818515 loss)
I0526 21:22:16.802479   912 sgd_solver.cpp:106] Iteration 537750, lr = 0.0045
I0526 21:22:28.968627   912 solver.cpp:237] Iteration 538500, loss = 1.06035
I0526 21:22:28.968667   912 solver.cpp:253]     Train net output #0: loss = 1.06035 (* 1 = 1.06035 loss)
I0526 21:22:28.968691   912 sgd_solver.cpp:106] Iteration 538500, lr = 0.0045
I0526 21:22:41.165617   912 solver.cpp:237] Iteration 539250, loss = 0.85851
I0526 21:22:41.165670   912 solver.cpp:253]     Train net output #0: loss = 0.858512 (* 1 = 0.858512 loss)
I0526 21:22:41.165699   912 sgd_solver.cpp:106] Iteration 539250, lr = 0.0045
I0526 21:22:53.332985   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_540000.caffemodel
I0526 21:22:53.383021   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_540000.solverstate
I0526 21:22:53.409167   912 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 21:23:45.525430   912 solver.cpp:409]     Test net output #0: accuracy = 0.898383
I0526 21:23:45.525626   912 solver.cpp:409]     Test net output #1: loss = 0.318119 (* 1 = 0.318119 loss)
I0526 21:24:06.416474   912 solver.cpp:237] Iteration 540000, loss = 0.915331
I0526 21:24:06.416538   912 solver.cpp:253]     Train net output #0: loss = 0.915333 (* 1 = 0.915333 loss)
I0526 21:24:06.416558   912 sgd_solver.cpp:106] Iteration 540000, lr = 0.0045
I0526 21:24:18.592267   912 solver.cpp:237] Iteration 540750, loss = 0.78416
I0526 21:24:18.592448   912 solver.cpp:253]     Train net output #0: loss = 0.784162 (* 1 = 0.784162 loss)
I0526 21:24:18.592465   912 sgd_solver.cpp:106] Iteration 540750, lr = 0.0045
I0526 21:24:30.723212   912 solver.cpp:237] Iteration 541500, loss = 1.0704
I0526 21:24:30.723263   912 solver.cpp:253]     Train net output #0: loss = 1.0704 (* 1 = 1.0704 loss)
I0526 21:24:30.723280   912 sgd_solver.cpp:106] Iteration 541500, lr = 0.0045
I0526 21:24:42.906916   912 solver.cpp:237] Iteration 542250, loss = 1.0262
I0526 21:24:42.906954   912 solver.cpp:253]     Train net output #0: loss = 1.0262 (* 1 = 1.0262 loss)
I0526 21:24:42.906978   912 sgd_solver.cpp:106] Iteration 542250, lr = 0.0045
I0526 21:24:55.038174   912 solver.cpp:237] Iteration 543000, loss = 1.30525
I0526 21:24:55.038363   912 solver.cpp:253]     Train net output #0: loss = 1.30525 (* 1 = 1.30525 loss)
I0526 21:24:55.038381   912 sgd_solver.cpp:106] Iteration 543000, lr = 0.0045
I0526 21:25:07.176599   912 solver.cpp:237] Iteration 543750, loss = 1.21557
I0526 21:25:07.176638   912 solver.cpp:253]     Train net output #0: loss = 1.21557 (* 1 = 1.21557 loss)
I0526 21:25:07.176658   912 sgd_solver.cpp:106] Iteration 543750, lr = 0.0045
I0526 21:25:19.322363   912 solver.cpp:237] Iteration 544500, loss = 1.49268
I0526 21:25:19.322414   912 solver.cpp:253]     Train net output #0: loss = 1.49268 (* 1 = 1.49268 loss)
I0526 21:25:19.322432   912 sgd_solver.cpp:106] Iteration 544500, lr = 0.0045
I0526 21:25:52.362576   912 solver.cpp:237] Iteration 545250, loss = 1.34488
I0526 21:25:52.362784   912 solver.cpp:253]     Train net output #0: loss = 1.34488 (* 1 = 1.34488 loss)
I0526 21:25:52.362802   912 sgd_solver.cpp:106] Iteration 545250, lr = 0.0045
I0526 21:26:04.524189   912 solver.cpp:237] Iteration 546000, loss = 1.2025
I0526 21:26:04.524242   912 solver.cpp:253]     Train net output #0: loss = 1.2025 (* 1 = 1.2025 loss)
I0526 21:26:04.524262   912 sgd_solver.cpp:106] Iteration 546000, lr = 0.0045
I0526 21:26:16.685055   912 solver.cpp:237] Iteration 546750, loss = 0.870638
I0526 21:26:16.685099   912 solver.cpp:253]     Train net output #0: loss = 0.870641 (* 1 = 0.870641 loss)
I0526 21:26:16.685117   912 sgd_solver.cpp:106] Iteration 546750, lr = 0.0045
I0526 21:26:28.862835   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_547500.caffemodel
I0526 21:26:28.918331   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_547500.solverstate
I0526 21:26:28.951485   912 solver.cpp:237] Iteration 547500, loss = 1.13426
I0526 21:26:28.951547   912 solver.cpp:253]     Train net output #0: loss = 1.13426 (* 1 = 1.13426 loss)
I0526 21:26:28.951565   912 sgd_solver.cpp:106] Iteration 547500, lr = 0.0045
I0526 21:26:41.118803   912 solver.cpp:237] Iteration 548250, loss = 0.885531
I0526 21:26:41.118844   912 solver.cpp:253]     Train net output #0: loss = 0.885534 (* 1 = 0.885534 loss)
I0526 21:26:41.118865   912 sgd_solver.cpp:106] Iteration 548250, lr = 0.0045
I0526 21:26:53.294548   912 solver.cpp:237] Iteration 549000, loss = 1.01771
I0526 21:26:53.294601   912 solver.cpp:253]     Train net output #0: loss = 1.01771 (* 1 = 1.01771 loss)
I0526 21:26:53.294621   912 sgd_solver.cpp:106] Iteration 549000, lr = 0.0045
I0526 21:27:05.403944   912 solver.cpp:237] Iteration 549750, loss = 0.901498
I0526 21:27:05.404129   912 solver.cpp:253]     Train net output #0: loss = 0.9015 (* 1 = 0.9015 loss)
I0526 21:27:05.404147   912 sgd_solver.cpp:106] Iteration 549750, lr = 0.0045
I0526 21:27:38.445003   912 solver.cpp:237] Iteration 550500, loss = 0.983215
I0526 21:27:38.445201   912 solver.cpp:253]     Train net output #0: loss = 0.983217 (* 1 = 0.983217 loss)
I0526 21:27:38.445220   912 sgd_solver.cpp:106] Iteration 550500, lr = 0.0045
I0526 21:27:50.641525   912 solver.cpp:237] Iteration 551250, loss = 1.08546
I0526 21:27:50.641580   912 solver.cpp:253]     Train net output #0: loss = 1.08546 (* 1 = 1.08546 loss)
I0526 21:27:50.641598   912 sgd_solver.cpp:106] Iteration 551250, lr = 0.0045
I0526 21:28:02.852809   912 solver.cpp:237] Iteration 552000, loss = 1.05943
I0526 21:28:02.852846   912 solver.cpp:253]     Train net output #0: loss = 1.05943 (* 1 = 1.05943 loss)
I0526 21:28:02.852871   912 sgd_solver.cpp:106] Iteration 552000, lr = 0.0045
I0526 21:28:14.992871   912 solver.cpp:237] Iteration 552750, loss = 0.599872
I0526 21:28:14.993065   912 solver.cpp:253]     Train net output #0: loss = 0.599874 (* 1 = 0.599874 loss)
I0526 21:28:14.993084   912 sgd_solver.cpp:106] Iteration 552750, lr = 0.0045
I0526 21:28:27.107513   912 solver.cpp:237] Iteration 553500, loss = 1.26448
I0526 21:28:27.107550   912 solver.cpp:253]     Train net output #0: loss = 1.26448 (* 1 = 1.26448 loss)
I0526 21:28:27.107576   912 sgd_solver.cpp:106] Iteration 553500, lr = 0.0045
I0526 21:28:39.281275   912 solver.cpp:237] Iteration 554250, loss = 1.03277
I0526 21:28:39.281328   912 solver.cpp:253]     Train net output #0: loss = 1.03277 (* 1 = 1.03277 loss)
I0526 21:28:39.281347   912 sgd_solver.cpp:106] Iteration 554250, lr = 0.0045
I0526 21:28:51.449158   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_555000.caffemodel
I0526 21:28:51.505560   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_555000.solverstate
I0526 21:28:51.537350   912 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 21:30:04.454805   912 solver.cpp:409]     Test net output #0: accuracy = 0.900785
I0526 21:30:04.455013   912 solver.cpp:409]     Test net output #1: loss = 0.337513 (* 1 = 0.337513 loss)
I0526 21:30:25.344249   912 solver.cpp:237] Iteration 555000, loss = 1.10685
I0526 21:30:25.344306   912 solver.cpp:253]     Train net output #0: loss = 1.10685 (* 1 = 1.10685 loss)
I0526 21:30:25.344327   912 sgd_solver.cpp:106] Iteration 555000, lr = 0.0045
I0526 21:30:37.457964   912 solver.cpp:237] Iteration 555750, loss = 1.43544
I0526 21:30:37.458161   912 solver.cpp:253]     Train net output #0: loss = 1.43545 (* 1 = 1.43545 loss)
I0526 21:30:37.458179   912 sgd_solver.cpp:106] Iteration 555750, lr = 0.0045
I0526 21:30:49.531780   912 solver.cpp:237] Iteration 556500, loss = 1.53317
I0526 21:30:49.531823   912 solver.cpp:253]     Train net output #0: loss = 1.53317 (* 1 = 1.53317 loss)
I0526 21:30:49.531841   912 sgd_solver.cpp:106] Iteration 556500, lr = 0.0045
I0526 21:31:01.612695   912 solver.cpp:237] Iteration 557250, loss = 1.21997
I0526 21:31:01.612751   912 solver.cpp:253]     Train net output #0: loss = 1.21997 (* 1 = 1.21997 loss)
I0526 21:31:01.612771   912 sgd_solver.cpp:106] Iteration 557250, lr = 0.0045
I0526 21:31:13.775671   912 solver.cpp:237] Iteration 558000, loss = 1.07873
I0526 21:31:13.775857   912 solver.cpp:253]     Train net output #0: loss = 1.07873 (* 1 = 1.07873 loss)
I0526 21:31:13.775874   912 sgd_solver.cpp:106] Iteration 558000, lr = 0.0045
I0526 21:31:25.912798   912 solver.cpp:237] Iteration 558750, loss = 1.3456
I0526 21:31:25.912850   912 solver.cpp:253]     Train net output #0: loss = 1.3456 (* 1 = 1.3456 loss)
I0526 21:31:25.912878   912 sgd_solver.cpp:106] Iteration 558750, lr = 0.0045
I0526 21:31:38.169617   912 solver.cpp:237] Iteration 559500, loss = 1.12238
I0526 21:31:38.169658   912 solver.cpp:253]     Train net output #0: loss = 1.12238 (* 1 = 1.12238 loss)
I0526 21:31:38.169678   912 sgd_solver.cpp:106] Iteration 559500, lr = 0.0045
I0526 21:32:11.302016   912 solver.cpp:237] Iteration 560250, loss = 1.10132
I0526 21:32:11.302215   912 solver.cpp:253]     Train net output #0: loss = 1.10132 (* 1 = 1.10132 loss)
I0526 21:32:11.302232   912 sgd_solver.cpp:106] Iteration 560250, lr = 0.0045
I0526 21:32:23.488394   912 solver.cpp:237] Iteration 561000, loss = 1.30006
I0526 21:32:23.488448   912 solver.cpp:253]     Train net output #0: loss = 1.30006 (* 1 = 1.30006 loss)
I0526 21:32:23.488466   912 sgd_solver.cpp:106] Iteration 561000, lr = 0.0045
I0526 21:32:35.690420   912 solver.cpp:237] Iteration 561750, loss = 1.26474
I0526 21:32:35.690457   912 solver.cpp:253]     Train net output #0: loss = 1.26474 (* 1 = 1.26474 loss)
I0526 21:32:35.690481   912 sgd_solver.cpp:106] Iteration 561750, lr = 0.0045
I0526 21:32:47.904719   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_562500.caffemodel
I0526 21:32:47.954591   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_562500.solverstate
I0526 21:32:47.985537   912 solver.cpp:237] Iteration 562500, loss = 1.31893
I0526 21:32:47.985595   912 solver.cpp:253]     Train net output #0: loss = 1.31894 (* 1 = 1.31894 loss)
I0526 21:32:47.985612   912 sgd_solver.cpp:106] Iteration 562500, lr = 0.0045
I0526 21:33:00.185801   912 solver.cpp:237] Iteration 563250, loss = 0.813452
I0526 21:33:00.185844   912 solver.cpp:253]     Train net output #0: loss = 0.813454 (* 1 = 0.813454 loss)
I0526 21:33:00.185863   912 sgd_solver.cpp:106] Iteration 563250, lr = 0.0045
I0526 21:33:12.385900   912 solver.cpp:237] Iteration 564000, loss = 1.11529
I0526 21:33:12.385952   912 solver.cpp:253]     Train net output #0: loss = 1.11529 (* 1 = 1.11529 loss)
I0526 21:33:12.385972   912 sgd_solver.cpp:106] Iteration 564000, lr = 0.0045
I0526 21:33:24.605626   912 solver.cpp:237] Iteration 564750, loss = 0.778802
I0526 21:33:24.605824   912 solver.cpp:253]     Train net output #0: loss = 0.778804 (* 1 = 0.778804 loss)
I0526 21:33:24.605841   912 sgd_solver.cpp:106] Iteration 564750, lr = 0.0045
I0526 21:33:57.737164   912 solver.cpp:237] Iteration 565500, loss = 1.46731
I0526 21:33:57.737363   912 solver.cpp:253]     Train net output #0: loss = 1.46731 (* 1 = 1.46731 loss)
I0526 21:33:57.737381   912 sgd_solver.cpp:106] Iteration 565500, lr = 0.0045
I0526 21:34:09.955986   912 solver.cpp:237] Iteration 566250, loss = 1.64566
I0526 21:34:09.956025   912 solver.cpp:253]     Train net output #0: loss = 1.64566 (* 1 = 1.64566 loss)
I0526 21:34:09.956045   912 sgd_solver.cpp:106] Iteration 566250, lr = 0.0045
I0526 21:34:22.149271   912 solver.cpp:237] Iteration 567000, loss = 1.54388
I0526 21:34:22.149322   912 solver.cpp:253]     Train net output #0: loss = 1.54388 (* 1 = 1.54388 loss)
I0526 21:34:22.149349   912 sgd_solver.cpp:106] Iteration 567000, lr = 0.0045
I0526 21:34:34.310648   912 solver.cpp:237] Iteration 567750, loss = 1.26985
I0526 21:34:34.310828   912 solver.cpp:253]     Train net output #0: loss = 1.26985 (* 1 = 1.26985 loss)
I0526 21:34:34.310845   912 sgd_solver.cpp:106] Iteration 567750, lr = 0.0045
I0526 21:34:46.464877   912 solver.cpp:237] Iteration 568500, loss = 0.87579
I0526 21:34:46.464934   912 solver.cpp:253]     Train net output #0: loss = 0.875792 (* 1 = 0.875792 loss)
I0526 21:34:46.464952   912 sgd_solver.cpp:106] Iteration 568500, lr = 0.0045
I0526 21:34:58.606987   912 solver.cpp:237] Iteration 569250, loss = 1.2559
I0526 21:34:58.607024   912 solver.cpp:253]     Train net output #0: loss = 1.25591 (* 1 = 1.25591 loss)
I0526 21:34:58.607049   912 sgd_solver.cpp:106] Iteration 569250, lr = 0.0045
I0526 21:35:10.739226   912 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_570000.caffemodel
I0526 21:35:10.792178   912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_570000.solverstate
I0526 21:35:10.836465   912 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 21:36:02.534693   912 solver.cpp:409]     Test net output #0: accuracy = 0.904899
I0526 21:36:02.534891   912 solver.cpp:409]     Test net output #1: loss = 0.302472 (* 1 = 0.302472 loss)
I0526 21:36:23.440853   912 solver.cpp:237] Iteration 570000, loss = 1.09091
I0526 21:36:23.440912   912 solver.cpp:253]     Train net output #0: loss = 1.09091 (* 1 = 1.09091 loss)
I0526 21:36:23.440932   912 sgd_solver.cpp:106] Iteration 570000, lr = 0.0045
I0526 21:36:35.613049   912 solver.cpp:237] Iteration 570750, loss = 1.15241
I0526 21:36:35.613246   912 solver.cpp:253]     Train net output #0: loss = 1.15241 (* 1 = 1.15241 loss)
I0526 21:36:35.613265   912 sgd_solver.cpp:106] Iteration 570750, lr = 0.0045
I0526 21:36:47.761131   912 solver.cpp:237] Iteration 571500, loss = 1.12854
I0526 21:36:47.761169   912 solver.cpp:253]     Train net output #0: loss = 1.12855 (* 1 = 1.12855 loss)
I0526 21:36:47.761190   912 sgd_solver.cpp:106] Iteration 571500, lr = 0.0045
I0526 21:36:59.854610   912 solver.cpp:237] Iteration 572250, loss = 1.20939
I0526 21:36:59.854665   912 solver.cpp:253]     Train net output #0: loss = 1.20939 (* 1 = 1.20939 loss)
I0526 21:36:59.854683   912 sgd_solver.cpp:106] Iteration 572250, lr = 0.0045
I0526 21:37:11.992902   912 solver.cpp:237] Iteration 573000, loss = 1.05683
I0526 21:37:11.993083   912 solver.cpp:253]     Train net output #0: loss = 1.05683 (* 1 = 1.05683 loss)
I0526 21:37:11.993100   912 sgd_solver.cpp:106] Iteration 573000, lr = 0.0045
I0526 21:37:24.145092   912 solver.cpp:237] Iteration 573750, loss = 1.28232
I0526 21:37:24.145148   912 solver.cpp:253]     Train net output #0: loss = 1.28232 (* 1 = 1.28232 loss)
I0526 21:37:24.145165   912 sgd_solver.cpp:106] Iteration 573750, lr = 0.0045
I0526 21:37:36.268563   912 solver.cpp:237] Iteration 574500, loss = 0.93067
I0526 21:37:36.268607   912 solver.cpp:253]     Train net output #0: loss = 0.930672 (* 1 = 0.930672 loss)
I0526 21:37:36.268625   912 sgd_solver.cpp:106] Iteration 574500, lr = 0.0045
=>> PBS: job killed: walltime 7211 exceeded limit 7200
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
aprun: Apid 11270472: Caught signal Terminated, sending to application
*** Aborted at 1464313065 (unix time) try "date -d @1464313065" if you are using GNU date ***
PC: @     0x2aaab7f6156a __GI_mmap
*** SIGTERM (@0x38d) received by PID 912 (TID 0x2aaac746f900) from PID 909; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab7f6156a __GI_mmap
    @     0x2aaab930c652 (unknown)
    @     0x2aaab930e5b8 (unknown)
    @     0x2aaab930e5e5 (unknown)
    @     0x2aaab9283556 (unknown)
    @     0x2aaab9286878 (unknown)
    @     0x2aaab92868f9 (unknown)
    @     0x2aaab91d3618 (unknown)
    @     0x2aaab91a0aa2 cuMemFreeHost
    @     0x2aaaaacf825d (unknown)
    @     0x2aaaaacdb31c (unknown)
    @     0x2aaaaad07d11 cudaFreeHost
    @           0x5ea897 caffe::SyncedMemory::~SyncedMemory()
    @           0x49ab62 boost::detail::sp_counted_impl_p<>::dispose()
    @           0x43d769 boost::detail::shared_count::~shared_count()
    @           0x4afef8 boost::detail::sp_counted_impl_p<>::dispose()
    @           0x5b8e61 caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 02237] [c4-1c1s1n1] [Thu May 26 21:37:46 2016] PE RANK 0 exit signal Terminated
Application 11270472 network throttled: 1 node throttled, 00:00:20 node-seconds
Application 11270472 balanced injection 100, after throttle 100
Application 11270472 exit codes: 143
Application 11270472 resources: utime ~6241s, stime ~952s, Rss ~5329664, inblocks ~13185618, outblocks ~592963
