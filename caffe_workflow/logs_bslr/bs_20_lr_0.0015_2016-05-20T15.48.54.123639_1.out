2806994
I0521 22:03:06.630506 10174 caffe.cpp:184] Using GPUs 0
I0521 22:03:07.051982 10174 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0015
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639.prototxt"
I0521 22:03:07.053504 10174 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639.prototxt
I0521 22:03:07.071631 10174 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 22:03:07.071691 10174 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 22:03:07.072039 10174 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 22:03:07.072218 10174 layer_factory.hpp:77] Creating layer data_hdf5
I0521 22:03:07.072242 10174 net.cpp:106] Creating Layer data_hdf5
I0521 22:03:07.072257 10174 net.cpp:411] data_hdf5 -> data
I0521 22:03:07.072291 10174 net.cpp:411] data_hdf5 -> label
I0521 22:03:07.072324 10174 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 22:03:07.073686 10174 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 22:03:07.075908 10174 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 22:03:28.585919 10174 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 22:03:28.591012 10174 net.cpp:150] Setting up data_hdf5
I0521 22:03:28.591053 10174 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0521 22:03:28.591068 10174 net.cpp:157] Top shape: 20 (20)
I0521 22:03:28.591079 10174 net.cpp:165] Memory required for data: 508080
I0521 22:03:28.591092 10174 layer_factory.hpp:77] Creating layer conv1
I0521 22:03:28.591126 10174 net.cpp:106] Creating Layer conv1
I0521 22:03:28.591137 10174 net.cpp:454] conv1 <- data
I0521 22:03:28.591159 10174 net.cpp:411] conv1 -> conv1
I0521 22:03:28.955946 10174 net.cpp:150] Setting up conv1
I0521 22:03:28.955988 10174 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 22:03:28.955999 10174 net.cpp:165] Memory required for data: 6037680
I0521 22:03:28.956027 10174 layer_factory.hpp:77] Creating layer relu1
I0521 22:03:28.956049 10174 net.cpp:106] Creating Layer relu1
I0521 22:03:28.956061 10174 net.cpp:454] relu1 <- conv1
I0521 22:03:28.956074 10174 net.cpp:397] relu1 -> conv1 (in-place)
I0521 22:03:28.956591 10174 net.cpp:150] Setting up relu1
I0521 22:03:28.956609 10174 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 22:03:28.956619 10174 net.cpp:165] Memory required for data: 11567280
I0521 22:03:28.956629 10174 layer_factory.hpp:77] Creating layer pool1
I0521 22:03:28.956645 10174 net.cpp:106] Creating Layer pool1
I0521 22:03:28.956655 10174 net.cpp:454] pool1 <- conv1
I0521 22:03:28.956667 10174 net.cpp:411] pool1 -> pool1
I0521 22:03:28.956746 10174 net.cpp:150] Setting up pool1
I0521 22:03:28.956760 10174 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0521 22:03:28.956770 10174 net.cpp:165] Memory required for data: 14332080
I0521 22:03:28.956780 10174 layer_factory.hpp:77] Creating layer conv2
I0521 22:03:28.956801 10174 net.cpp:106] Creating Layer conv2
I0521 22:03:28.956812 10174 net.cpp:454] conv2 <- pool1
I0521 22:03:28.956825 10174 net.cpp:411] conv2 -> conv2
I0521 22:03:28.959529 10174 net.cpp:150] Setting up conv2
I0521 22:03:28.959552 10174 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 22:03:28.959563 10174 net.cpp:165] Memory required for data: 18306480
I0521 22:03:28.959581 10174 layer_factory.hpp:77] Creating layer relu2
I0521 22:03:28.959595 10174 net.cpp:106] Creating Layer relu2
I0521 22:03:28.959605 10174 net.cpp:454] relu2 <- conv2
I0521 22:03:28.959619 10174 net.cpp:397] relu2 -> conv2 (in-place)
I0521 22:03:28.959949 10174 net.cpp:150] Setting up relu2
I0521 22:03:28.959964 10174 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 22:03:28.959974 10174 net.cpp:165] Memory required for data: 22280880
I0521 22:03:28.959985 10174 layer_factory.hpp:77] Creating layer pool2
I0521 22:03:28.959996 10174 net.cpp:106] Creating Layer pool2
I0521 22:03:28.960006 10174 net.cpp:454] pool2 <- conv2
I0521 22:03:28.960018 10174 net.cpp:411] pool2 -> pool2
I0521 22:03:28.960099 10174 net.cpp:150] Setting up pool2
I0521 22:03:28.960114 10174 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0521 22:03:28.960122 10174 net.cpp:165] Memory required for data: 24268080
I0521 22:03:28.960132 10174 layer_factory.hpp:77] Creating layer conv3
I0521 22:03:28.960150 10174 net.cpp:106] Creating Layer conv3
I0521 22:03:28.960161 10174 net.cpp:454] conv3 <- pool2
I0521 22:03:28.960175 10174 net.cpp:411] conv3 -> conv3
I0521 22:03:28.962123 10174 net.cpp:150] Setting up conv3
I0521 22:03:28.962146 10174 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 22:03:28.962159 10174 net.cpp:165] Memory required for data: 26436400
I0521 22:03:28.962177 10174 layer_factory.hpp:77] Creating layer relu3
I0521 22:03:28.962193 10174 net.cpp:106] Creating Layer relu3
I0521 22:03:28.962203 10174 net.cpp:454] relu3 <- conv3
I0521 22:03:28.962216 10174 net.cpp:397] relu3 -> conv3 (in-place)
I0521 22:03:28.962685 10174 net.cpp:150] Setting up relu3
I0521 22:03:28.962702 10174 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 22:03:28.962713 10174 net.cpp:165] Memory required for data: 28604720
I0521 22:03:28.962723 10174 layer_factory.hpp:77] Creating layer pool3
I0521 22:03:28.962735 10174 net.cpp:106] Creating Layer pool3
I0521 22:03:28.962744 10174 net.cpp:454] pool3 <- conv3
I0521 22:03:28.962757 10174 net.cpp:411] pool3 -> pool3
I0521 22:03:28.962826 10174 net.cpp:150] Setting up pool3
I0521 22:03:28.962838 10174 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0521 22:03:28.962847 10174 net.cpp:165] Memory required for data: 29688880
I0521 22:03:28.962857 10174 layer_factory.hpp:77] Creating layer conv4
I0521 22:03:28.962874 10174 net.cpp:106] Creating Layer conv4
I0521 22:03:28.962885 10174 net.cpp:454] conv4 <- pool3
I0521 22:03:28.962898 10174 net.cpp:411] conv4 -> conv4
I0521 22:03:28.965636 10174 net.cpp:150] Setting up conv4
I0521 22:03:28.965662 10174 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 22:03:28.965673 10174 net.cpp:165] Memory required for data: 30414640
I0521 22:03:28.965689 10174 layer_factory.hpp:77] Creating layer relu4
I0521 22:03:28.965703 10174 net.cpp:106] Creating Layer relu4
I0521 22:03:28.965713 10174 net.cpp:454] relu4 <- conv4
I0521 22:03:28.965726 10174 net.cpp:397] relu4 -> conv4 (in-place)
I0521 22:03:28.966199 10174 net.cpp:150] Setting up relu4
I0521 22:03:28.966217 10174 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 22:03:28.966226 10174 net.cpp:165] Memory required for data: 31140400
I0521 22:03:28.966238 10174 layer_factory.hpp:77] Creating layer pool4
I0521 22:03:28.966250 10174 net.cpp:106] Creating Layer pool4
I0521 22:03:28.966260 10174 net.cpp:454] pool4 <- conv4
I0521 22:03:28.966274 10174 net.cpp:411] pool4 -> pool4
I0521 22:03:28.966341 10174 net.cpp:150] Setting up pool4
I0521 22:03:28.966354 10174 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0521 22:03:28.966366 10174 net.cpp:165] Memory required for data: 31503280
I0521 22:03:28.966375 10174 layer_factory.hpp:77] Creating layer ip1
I0521 22:03:28.966397 10174 net.cpp:106] Creating Layer ip1
I0521 22:03:28.966406 10174 net.cpp:454] ip1 <- pool4
I0521 22:03:28.966418 10174 net.cpp:411] ip1 -> ip1
I0521 22:03:28.981874 10174 net.cpp:150] Setting up ip1
I0521 22:03:28.981904 10174 net.cpp:157] Top shape: 20 196 (3920)
I0521 22:03:28.981915 10174 net.cpp:165] Memory required for data: 31518960
I0521 22:03:28.981938 10174 layer_factory.hpp:77] Creating layer relu5
I0521 22:03:28.981953 10174 net.cpp:106] Creating Layer relu5
I0521 22:03:28.981963 10174 net.cpp:454] relu5 <- ip1
I0521 22:03:28.981977 10174 net.cpp:397] relu5 -> ip1 (in-place)
I0521 22:03:28.982321 10174 net.cpp:150] Setting up relu5
I0521 22:03:28.982333 10174 net.cpp:157] Top shape: 20 196 (3920)
I0521 22:03:28.982344 10174 net.cpp:165] Memory required for data: 31534640
I0521 22:03:28.982354 10174 layer_factory.hpp:77] Creating layer drop1
I0521 22:03:28.982377 10174 net.cpp:106] Creating Layer drop1
I0521 22:03:28.982386 10174 net.cpp:454] drop1 <- ip1
I0521 22:03:28.982399 10174 net.cpp:397] drop1 -> ip1 (in-place)
I0521 22:03:28.982457 10174 net.cpp:150] Setting up drop1
I0521 22:03:28.982470 10174 net.cpp:157] Top shape: 20 196 (3920)
I0521 22:03:28.982481 10174 net.cpp:165] Memory required for data: 31550320
I0521 22:03:28.982491 10174 layer_factory.hpp:77] Creating layer ip2
I0521 22:03:28.982508 10174 net.cpp:106] Creating Layer ip2
I0521 22:03:28.982518 10174 net.cpp:454] ip2 <- ip1
I0521 22:03:28.982532 10174 net.cpp:411] ip2 -> ip2
I0521 22:03:28.982992 10174 net.cpp:150] Setting up ip2
I0521 22:03:28.983006 10174 net.cpp:157] Top shape: 20 98 (1960)
I0521 22:03:28.983016 10174 net.cpp:165] Memory required for data: 31558160
I0521 22:03:28.983031 10174 layer_factory.hpp:77] Creating layer relu6
I0521 22:03:28.983043 10174 net.cpp:106] Creating Layer relu6
I0521 22:03:28.983052 10174 net.cpp:454] relu6 <- ip2
I0521 22:03:28.983064 10174 net.cpp:397] relu6 -> ip2 (in-place)
I0521 22:03:28.983580 10174 net.cpp:150] Setting up relu6
I0521 22:03:28.983597 10174 net.cpp:157] Top shape: 20 98 (1960)
I0521 22:03:28.983608 10174 net.cpp:165] Memory required for data: 31566000
I0521 22:03:28.983619 10174 layer_factory.hpp:77] Creating layer drop2
I0521 22:03:28.983633 10174 net.cpp:106] Creating Layer drop2
I0521 22:03:28.983644 10174 net.cpp:454] drop2 <- ip2
I0521 22:03:28.983659 10174 net.cpp:397] drop2 -> ip2 (in-place)
I0521 22:03:28.983701 10174 net.cpp:150] Setting up drop2
I0521 22:03:28.983716 10174 net.cpp:157] Top shape: 20 98 (1960)
I0521 22:03:28.983726 10174 net.cpp:165] Memory required for data: 31573840
I0521 22:03:28.983736 10174 layer_factory.hpp:77] Creating layer ip3
I0521 22:03:28.983749 10174 net.cpp:106] Creating Layer ip3
I0521 22:03:28.983759 10174 net.cpp:454] ip3 <- ip2
I0521 22:03:28.983773 10174 net.cpp:411] ip3 -> ip3
I0521 22:03:28.983983 10174 net.cpp:150] Setting up ip3
I0521 22:03:28.983996 10174 net.cpp:157] Top shape: 20 11 (220)
I0521 22:03:28.984005 10174 net.cpp:165] Memory required for data: 31574720
I0521 22:03:28.984021 10174 layer_factory.hpp:77] Creating layer drop3
I0521 22:03:28.984033 10174 net.cpp:106] Creating Layer drop3
I0521 22:03:28.984043 10174 net.cpp:454] drop3 <- ip3
I0521 22:03:28.984055 10174 net.cpp:397] drop3 -> ip3 (in-place)
I0521 22:03:28.984094 10174 net.cpp:150] Setting up drop3
I0521 22:03:28.984107 10174 net.cpp:157] Top shape: 20 11 (220)
I0521 22:03:28.984118 10174 net.cpp:165] Memory required for data: 31575600
I0521 22:03:28.984128 10174 layer_factory.hpp:77] Creating layer loss
I0521 22:03:28.984146 10174 net.cpp:106] Creating Layer loss
I0521 22:03:28.984156 10174 net.cpp:454] loss <- ip3
I0521 22:03:28.984169 10174 net.cpp:454] loss <- label
I0521 22:03:28.984180 10174 net.cpp:411] loss -> loss
I0521 22:03:28.984197 10174 layer_factory.hpp:77] Creating layer loss
I0521 22:03:28.984838 10174 net.cpp:150] Setting up loss
I0521 22:03:28.984859 10174 net.cpp:157] Top shape: (1)
I0521 22:03:28.984872 10174 net.cpp:160]     with loss weight 1
I0521 22:03:28.984915 10174 net.cpp:165] Memory required for data: 31575604
I0521 22:03:28.984925 10174 net.cpp:226] loss needs backward computation.
I0521 22:03:28.984935 10174 net.cpp:226] drop3 needs backward computation.
I0521 22:03:28.984946 10174 net.cpp:226] ip3 needs backward computation.
I0521 22:03:28.984953 10174 net.cpp:226] drop2 needs backward computation.
I0521 22:03:28.984964 10174 net.cpp:226] relu6 needs backward computation.
I0521 22:03:28.984973 10174 net.cpp:226] ip2 needs backward computation.
I0521 22:03:28.984983 10174 net.cpp:226] drop1 needs backward computation.
I0521 22:03:28.984995 10174 net.cpp:226] relu5 needs backward computation.
I0521 22:03:28.985004 10174 net.cpp:226] ip1 needs backward computation.
I0521 22:03:28.985014 10174 net.cpp:226] pool4 needs backward computation.
I0521 22:03:28.985024 10174 net.cpp:226] relu4 needs backward computation.
I0521 22:03:28.985034 10174 net.cpp:226] conv4 needs backward computation.
I0521 22:03:28.985045 10174 net.cpp:226] pool3 needs backward computation.
I0521 22:03:28.985056 10174 net.cpp:226] relu3 needs backward computation.
I0521 22:03:28.985066 10174 net.cpp:226] conv3 needs backward computation.
I0521 22:03:28.985085 10174 net.cpp:226] pool2 needs backward computation.
I0521 22:03:28.985096 10174 net.cpp:226] relu2 needs backward computation.
I0521 22:03:28.985106 10174 net.cpp:226] conv2 needs backward computation.
I0521 22:03:28.985117 10174 net.cpp:226] pool1 needs backward computation.
I0521 22:03:28.985127 10174 net.cpp:226] relu1 needs backward computation.
I0521 22:03:28.985137 10174 net.cpp:226] conv1 needs backward computation.
I0521 22:03:28.985148 10174 net.cpp:228] data_hdf5 does not need backward computation.
I0521 22:03:28.985158 10174 net.cpp:270] This network produces output loss
I0521 22:03:28.985183 10174 net.cpp:283] Network initialization done.
I0521 22:03:28.986831 10174 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639.prototxt
I0521 22:03:28.986902 10174 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 22:03:28.987257 10174 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 22:03:28.987447 10174 layer_factory.hpp:77] Creating layer data_hdf5
I0521 22:03:28.987462 10174 net.cpp:106] Creating Layer data_hdf5
I0521 22:03:28.987474 10174 net.cpp:411] data_hdf5 -> data
I0521 22:03:28.987490 10174 net.cpp:411] data_hdf5 -> label
I0521 22:03:28.987506 10174 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 22:03:28.988620 10174 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 22:03:50.254094 10174 net.cpp:150] Setting up data_hdf5
I0521 22:03:50.254259 10174 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0521 22:03:50.254273 10174 net.cpp:157] Top shape: 20 (20)
I0521 22:03:50.254286 10174 net.cpp:165] Memory required for data: 508080
I0521 22:03:50.254298 10174 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 22:03:50.254326 10174 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 22:03:50.254338 10174 net.cpp:454] label_data_hdf5_1_split <- label
I0521 22:03:50.254353 10174 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 22:03:50.254374 10174 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 22:03:50.254447 10174 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 22:03:50.254462 10174 net.cpp:157] Top shape: 20 (20)
I0521 22:03:50.254473 10174 net.cpp:157] Top shape: 20 (20)
I0521 22:03:50.254482 10174 net.cpp:165] Memory required for data: 508240
I0521 22:03:50.254493 10174 layer_factory.hpp:77] Creating layer conv1
I0521 22:03:50.254513 10174 net.cpp:106] Creating Layer conv1
I0521 22:03:50.254524 10174 net.cpp:454] conv1 <- data
I0521 22:03:50.254539 10174 net.cpp:411] conv1 -> conv1
I0521 22:03:50.256463 10174 net.cpp:150] Setting up conv1
I0521 22:03:50.256487 10174 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 22:03:50.256499 10174 net.cpp:165] Memory required for data: 6037840
I0521 22:03:50.256520 10174 layer_factory.hpp:77] Creating layer relu1
I0521 22:03:50.256534 10174 net.cpp:106] Creating Layer relu1
I0521 22:03:50.256544 10174 net.cpp:454] relu1 <- conv1
I0521 22:03:50.256556 10174 net.cpp:397] relu1 -> conv1 (in-place)
I0521 22:03:50.257050 10174 net.cpp:150] Setting up relu1
I0521 22:03:50.257066 10174 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 22:03:50.257076 10174 net.cpp:165] Memory required for data: 11567440
I0521 22:03:50.257086 10174 layer_factory.hpp:77] Creating layer pool1
I0521 22:03:50.257103 10174 net.cpp:106] Creating Layer pool1
I0521 22:03:50.257112 10174 net.cpp:454] pool1 <- conv1
I0521 22:03:50.257127 10174 net.cpp:411] pool1 -> pool1
I0521 22:03:50.257200 10174 net.cpp:150] Setting up pool1
I0521 22:03:50.257213 10174 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0521 22:03:50.257223 10174 net.cpp:165] Memory required for data: 14332240
I0521 22:03:50.257233 10174 layer_factory.hpp:77] Creating layer conv2
I0521 22:03:50.257251 10174 net.cpp:106] Creating Layer conv2
I0521 22:03:50.257261 10174 net.cpp:454] conv2 <- pool1
I0521 22:03:50.257275 10174 net.cpp:411] conv2 -> conv2
I0521 22:03:50.259194 10174 net.cpp:150] Setting up conv2
I0521 22:03:50.259217 10174 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 22:03:50.259229 10174 net.cpp:165] Memory required for data: 18306640
I0521 22:03:50.259248 10174 layer_factory.hpp:77] Creating layer relu2
I0521 22:03:50.259261 10174 net.cpp:106] Creating Layer relu2
I0521 22:03:50.259271 10174 net.cpp:454] relu2 <- conv2
I0521 22:03:50.259284 10174 net.cpp:397] relu2 -> conv2 (in-place)
I0521 22:03:50.259618 10174 net.cpp:150] Setting up relu2
I0521 22:03:50.259631 10174 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 22:03:50.259642 10174 net.cpp:165] Memory required for data: 22281040
I0521 22:03:50.259651 10174 layer_factory.hpp:77] Creating layer pool2
I0521 22:03:50.259662 10174 net.cpp:106] Creating Layer pool2
I0521 22:03:50.259675 10174 net.cpp:454] pool2 <- conv2
I0521 22:03:50.259686 10174 net.cpp:411] pool2 -> pool2
I0521 22:03:50.259758 10174 net.cpp:150] Setting up pool2
I0521 22:03:50.259771 10174 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0521 22:03:50.259781 10174 net.cpp:165] Memory required for data: 24268240
I0521 22:03:50.259791 10174 layer_factory.hpp:77] Creating layer conv3
I0521 22:03:50.259811 10174 net.cpp:106] Creating Layer conv3
I0521 22:03:50.259821 10174 net.cpp:454] conv3 <- pool2
I0521 22:03:50.259836 10174 net.cpp:411] conv3 -> conv3
I0521 22:03:50.261814 10174 net.cpp:150] Setting up conv3
I0521 22:03:50.261837 10174 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 22:03:50.261849 10174 net.cpp:165] Memory required for data: 26436560
I0521 22:03:50.261868 10174 layer_factory.hpp:77] Creating layer relu3
I0521 22:03:50.261894 10174 net.cpp:106] Creating Layer relu3
I0521 22:03:50.261904 10174 net.cpp:454] relu3 <- conv3
I0521 22:03:50.261919 10174 net.cpp:397] relu3 -> conv3 (in-place)
I0521 22:03:50.262390 10174 net.cpp:150] Setting up relu3
I0521 22:03:50.262406 10174 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 22:03:50.262416 10174 net.cpp:165] Memory required for data: 28604880
I0521 22:03:50.262428 10174 layer_factory.hpp:77] Creating layer pool3
I0521 22:03:50.262440 10174 net.cpp:106] Creating Layer pool3
I0521 22:03:50.262450 10174 net.cpp:454] pool3 <- conv3
I0521 22:03:50.262464 10174 net.cpp:411] pool3 -> pool3
I0521 22:03:50.262534 10174 net.cpp:150] Setting up pool3
I0521 22:03:50.262548 10174 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0521 22:03:50.262557 10174 net.cpp:165] Memory required for data: 29689040
I0521 22:03:50.262565 10174 layer_factory.hpp:77] Creating layer conv4
I0521 22:03:50.262583 10174 net.cpp:106] Creating Layer conv4
I0521 22:03:50.262593 10174 net.cpp:454] conv4 <- pool3
I0521 22:03:50.262606 10174 net.cpp:411] conv4 -> conv4
I0521 22:03:50.264649 10174 net.cpp:150] Setting up conv4
I0521 22:03:50.264672 10174 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 22:03:50.264685 10174 net.cpp:165] Memory required for data: 30414800
I0521 22:03:50.264699 10174 layer_factory.hpp:77] Creating layer relu4
I0521 22:03:50.264714 10174 net.cpp:106] Creating Layer relu4
I0521 22:03:50.264724 10174 net.cpp:454] relu4 <- conv4
I0521 22:03:50.264736 10174 net.cpp:397] relu4 -> conv4 (in-place)
I0521 22:03:50.265208 10174 net.cpp:150] Setting up relu4
I0521 22:03:50.265223 10174 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 22:03:50.265234 10174 net.cpp:165] Memory required for data: 31140560
I0521 22:03:50.265244 10174 layer_factory.hpp:77] Creating layer pool4
I0521 22:03:50.265257 10174 net.cpp:106] Creating Layer pool4
I0521 22:03:50.265267 10174 net.cpp:454] pool4 <- conv4
I0521 22:03:50.265280 10174 net.cpp:411] pool4 -> pool4
I0521 22:03:50.265352 10174 net.cpp:150] Setting up pool4
I0521 22:03:50.265367 10174 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0521 22:03:50.265375 10174 net.cpp:165] Memory required for data: 31503440
I0521 22:03:50.265383 10174 layer_factory.hpp:77] Creating layer ip1
I0521 22:03:50.265399 10174 net.cpp:106] Creating Layer ip1
I0521 22:03:50.265410 10174 net.cpp:454] ip1 <- pool4
I0521 22:03:50.265424 10174 net.cpp:411] ip1 -> ip1
I0521 22:03:50.280947 10174 net.cpp:150] Setting up ip1
I0521 22:03:50.280977 10174 net.cpp:157] Top shape: 20 196 (3920)
I0521 22:03:50.280992 10174 net.cpp:165] Memory required for data: 31519120
I0521 22:03:50.281015 10174 layer_factory.hpp:77] Creating layer relu5
I0521 22:03:50.281030 10174 net.cpp:106] Creating Layer relu5
I0521 22:03:50.281040 10174 net.cpp:454] relu5 <- ip1
I0521 22:03:50.281054 10174 net.cpp:397] relu5 -> ip1 (in-place)
I0521 22:03:50.281399 10174 net.cpp:150] Setting up relu5
I0521 22:03:50.281414 10174 net.cpp:157] Top shape: 20 196 (3920)
I0521 22:03:50.281424 10174 net.cpp:165] Memory required for data: 31534800
I0521 22:03:50.281435 10174 layer_factory.hpp:77] Creating layer drop1
I0521 22:03:50.281455 10174 net.cpp:106] Creating Layer drop1
I0521 22:03:50.281464 10174 net.cpp:454] drop1 <- ip1
I0521 22:03:50.281477 10174 net.cpp:397] drop1 -> ip1 (in-place)
I0521 22:03:50.281522 10174 net.cpp:150] Setting up drop1
I0521 22:03:50.281535 10174 net.cpp:157] Top shape: 20 196 (3920)
I0521 22:03:50.281545 10174 net.cpp:165] Memory required for data: 31550480
I0521 22:03:50.281554 10174 layer_factory.hpp:77] Creating layer ip2
I0521 22:03:50.281569 10174 net.cpp:106] Creating Layer ip2
I0521 22:03:50.281579 10174 net.cpp:454] ip2 <- ip1
I0521 22:03:50.281592 10174 net.cpp:411] ip2 -> ip2
I0521 22:03:50.282076 10174 net.cpp:150] Setting up ip2
I0521 22:03:50.282090 10174 net.cpp:157] Top shape: 20 98 (1960)
I0521 22:03:50.282100 10174 net.cpp:165] Memory required for data: 31558320
I0521 22:03:50.282115 10174 layer_factory.hpp:77] Creating layer relu6
I0521 22:03:50.282140 10174 net.cpp:106] Creating Layer relu6
I0521 22:03:50.282150 10174 net.cpp:454] relu6 <- ip2
I0521 22:03:50.282163 10174 net.cpp:397] relu6 -> ip2 (in-place)
I0521 22:03:50.282691 10174 net.cpp:150] Setting up relu6
I0521 22:03:50.282706 10174 net.cpp:157] Top shape: 20 98 (1960)
I0521 22:03:50.282717 10174 net.cpp:165] Memory required for data: 31566160
I0521 22:03:50.282727 10174 layer_factory.hpp:77] Creating layer drop2
I0521 22:03:50.282739 10174 net.cpp:106] Creating Layer drop2
I0521 22:03:50.282750 10174 net.cpp:454] drop2 <- ip2
I0521 22:03:50.282763 10174 net.cpp:397] drop2 -> ip2 (in-place)
I0521 22:03:50.282807 10174 net.cpp:150] Setting up drop2
I0521 22:03:50.282820 10174 net.cpp:157] Top shape: 20 98 (1960)
I0521 22:03:50.282831 10174 net.cpp:165] Memory required for data: 31574000
I0521 22:03:50.282841 10174 layer_factory.hpp:77] Creating layer ip3
I0521 22:03:50.282855 10174 net.cpp:106] Creating Layer ip3
I0521 22:03:50.282866 10174 net.cpp:454] ip3 <- ip2
I0521 22:03:50.282879 10174 net.cpp:411] ip3 -> ip3
I0521 22:03:50.283104 10174 net.cpp:150] Setting up ip3
I0521 22:03:50.283118 10174 net.cpp:157] Top shape: 20 11 (220)
I0521 22:03:50.283128 10174 net.cpp:165] Memory required for data: 31574880
I0521 22:03:50.283143 10174 layer_factory.hpp:77] Creating layer drop3
I0521 22:03:50.283156 10174 net.cpp:106] Creating Layer drop3
I0521 22:03:50.283166 10174 net.cpp:454] drop3 <- ip3
I0521 22:03:50.283179 10174 net.cpp:397] drop3 -> ip3 (in-place)
I0521 22:03:50.283220 10174 net.cpp:150] Setting up drop3
I0521 22:03:50.283232 10174 net.cpp:157] Top shape: 20 11 (220)
I0521 22:03:50.283242 10174 net.cpp:165] Memory required for data: 31575760
I0521 22:03:50.283252 10174 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 22:03:50.283265 10174 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 22:03:50.283275 10174 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 22:03:50.283285 10174 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 22:03:50.283300 10174 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 22:03:50.283373 10174 net.cpp:150] Setting up ip3_drop3_0_split
I0521 22:03:50.283386 10174 net.cpp:157] Top shape: 20 11 (220)
I0521 22:03:50.283398 10174 net.cpp:157] Top shape: 20 11 (220)
I0521 22:03:50.283408 10174 net.cpp:165] Memory required for data: 31577520
I0521 22:03:50.283417 10174 layer_factory.hpp:77] Creating layer accuracy
I0521 22:03:50.283439 10174 net.cpp:106] Creating Layer accuracy
I0521 22:03:50.283449 10174 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 22:03:50.283462 10174 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 22:03:50.283475 10174 net.cpp:411] accuracy -> accuracy
I0521 22:03:50.283499 10174 net.cpp:150] Setting up accuracy
I0521 22:03:50.283510 10174 net.cpp:157] Top shape: (1)
I0521 22:03:50.283520 10174 net.cpp:165] Memory required for data: 31577524
I0521 22:03:50.283530 10174 layer_factory.hpp:77] Creating layer loss
I0521 22:03:50.283542 10174 net.cpp:106] Creating Layer loss
I0521 22:03:50.283552 10174 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 22:03:50.283565 10174 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 22:03:50.283578 10174 net.cpp:411] loss -> loss
I0521 22:03:50.283596 10174 layer_factory.hpp:77] Creating layer loss
I0521 22:03:50.284075 10174 net.cpp:150] Setting up loss
I0521 22:03:50.284090 10174 net.cpp:157] Top shape: (1)
I0521 22:03:50.284099 10174 net.cpp:160]     with loss weight 1
I0521 22:03:50.284118 10174 net.cpp:165] Memory required for data: 31577528
I0521 22:03:50.284128 10174 net.cpp:226] loss needs backward computation.
I0521 22:03:50.284140 10174 net.cpp:228] accuracy does not need backward computation.
I0521 22:03:50.284152 10174 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 22:03:50.284162 10174 net.cpp:226] drop3 needs backward computation.
I0521 22:03:50.284173 10174 net.cpp:226] ip3 needs backward computation.
I0521 22:03:50.284183 10174 net.cpp:226] drop2 needs backward computation.
I0521 22:03:50.284193 10174 net.cpp:226] relu6 needs backward computation.
I0521 22:03:50.284211 10174 net.cpp:226] ip2 needs backward computation.
I0521 22:03:50.284221 10174 net.cpp:226] drop1 needs backward computation.
I0521 22:03:50.284231 10174 net.cpp:226] relu5 needs backward computation.
I0521 22:03:50.284240 10174 net.cpp:226] ip1 needs backward computation.
I0521 22:03:50.284250 10174 net.cpp:226] pool4 needs backward computation.
I0521 22:03:50.284260 10174 net.cpp:226] relu4 needs backward computation.
I0521 22:03:50.284271 10174 net.cpp:226] conv4 needs backward computation.
I0521 22:03:50.284279 10174 net.cpp:226] pool3 needs backward computation.
I0521 22:03:50.284291 10174 net.cpp:226] relu3 needs backward computation.
I0521 22:03:50.284301 10174 net.cpp:226] conv3 needs backward computation.
I0521 22:03:50.284312 10174 net.cpp:226] pool2 needs backward computation.
I0521 22:03:50.284322 10174 net.cpp:226] relu2 needs backward computation.
I0521 22:03:50.284332 10174 net.cpp:226] conv2 needs backward computation.
I0521 22:03:50.284342 10174 net.cpp:226] pool1 needs backward computation.
I0521 22:03:50.284353 10174 net.cpp:226] relu1 needs backward computation.
I0521 22:03:50.284361 10174 net.cpp:226] conv1 needs backward computation.
I0521 22:03:50.284373 10174 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 22:03:50.284385 10174 net.cpp:228] data_hdf5 does not need backward computation.
I0521 22:03:50.284394 10174 net.cpp:270] This network produces output accuracy
I0521 22:03:50.284405 10174 net.cpp:270] This network produces output loss
I0521 22:03:50.284435 10174 net.cpp:283] Network initialization done.
I0521 22:03:50.284569 10174 solver.cpp:60] Solver scaffolding done.
I0521 22:03:50.285698 10174 caffe.cpp:212] Starting Optimization
I0521 22:03:50.285717 10174 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 22:03:50.285730 10174 solver.cpp:289] Learning Rate Policy: fixed
I0521 22:03:50.286954 10174 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 22:04:43.049857 10174 solver.cpp:409]     Test net output #0: accuracy = 0.0885248
I0521 22:04:43.050014 10174 solver.cpp:409]     Test net output #1: loss = 2.39879 (* 1 = 2.39879 loss)
I0521 22:04:43.068917 10174 solver.cpp:237] Iteration 0, loss = 2.40576
I0521 22:04:43.068954 10174 solver.cpp:253]     Train net output #0: loss = 2.40576 (* 1 = 2.40576 loss)
I0521 22:04:43.068974 10174 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0521 22:04:55.217471 10174 solver.cpp:237] Iteration 750, loss = 2.25324
I0521 22:04:55.217511 10174 solver.cpp:253]     Train net output #0: loss = 2.25324 (* 1 = 2.25324 loss)
I0521 22:04:55.217528 10174 sgd_solver.cpp:106] Iteration 750, lr = 0.0015
I0521 22:05:07.391039 10174 solver.cpp:237] Iteration 1500, loss = 2.23227
I0521 22:05:07.391090 10174 solver.cpp:253]     Train net output #0: loss = 2.23227 (* 1 = 2.23227 loss)
I0521 22:05:07.391104 10174 sgd_solver.cpp:106] Iteration 1500, lr = 0.0015
I0521 22:05:19.543377 10174 solver.cpp:237] Iteration 2250, loss = 1.80507
I0521 22:05:19.543526 10174 solver.cpp:253]     Train net output #0: loss = 1.80507 (* 1 = 1.80507 loss)
I0521 22:05:19.543542 10174 sgd_solver.cpp:106] Iteration 2250, lr = 0.0015
I0521 22:05:31.694228 10174 solver.cpp:237] Iteration 3000, loss = 1.63001
I0521 22:05:31.694281 10174 solver.cpp:253]     Train net output #0: loss = 1.63001 (* 1 = 1.63001 loss)
I0521 22:05:31.694295 10174 sgd_solver.cpp:106] Iteration 3000, lr = 0.0015
I0521 22:05:43.839216 10174 solver.cpp:237] Iteration 3750, loss = 1.67837
I0521 22:05:43.839253 10174 solver.cpp:253]     Train net output #0: loss = 1.67837 (* 1 = 1.67837 loss)
I0521 22:05:43.839270 10174 sgd_solver.cpp:106] Iteration 3750, lr = 0.0015
I0521 22:05:56.004840 10174 solver.cpp:237] Iteration 4500, loss = 1.6973
I0521 22:05:56.004994 10174 solver.cpp:253]     Train net output #0: loss = 1.6973 (* 1 = 1.6973 loss)
I0521 22:05:56.005009 10174 sgd_solver.cpp:106] Iteration 4500, lr = 0.0015
I0521 22:06:30.287446 10174 solver.cpp:237] Iteration 5250, loss = 1.71743
I0521 22:06:30.287606 10174 solver.cpp:253]     Train net output #0: loss = 1.71743 (* 1 = 1.71743 loss)
I0521 22:06:30.287621 10174 sgd_solver.cpp:106] Iteration 5250, lr = 0.0015
I0521 22:06:42.457290 10174 solver.cpp:237] Iteration 6000, loss = 1.5567
I0521 22:06:42.457335 10174 solver.cpp:253]     Train net output #0: loss = 1.5567 (* 1 = 1.5567 loss)
I0521 22:06:42.457350 10174 sgd_solver.cpp:106] Iteration 6000, lr = 0.0015
I0521 22:06:54.657798 10174 solver.cpp:237] Iteration 6750, loss = 1.77238
I0521 22:06:54.657833 10174 solver.cpp:253]     Train net output #0: loss = 1.77238 (* 1 = 1.77238 loss)
I0521 22:06:54.657850 10174 sgd_solver.cpp:106] Iteration 6750, lr = 0.0015
I0521 22:07:06.808188 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_7500.caffemodel
I0521 22:07:06.861102 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_7500.solverstate
I0521 22:07:06.894503 10174 solver.cpp:237] Iteration 7500, loss = 1.43914
I0521 22:07:06.894551 10174 solver.cpp:253]     Train net output #0: loss = 1.43914 (* 1 = 1.43914 loss)
I0521 22:07:06.894567 10174 sgd_solver.cpp:106] Iteration 7500, lr = 0.0015
I0521 22:07:19.011169 10174 solver.cpp:237] Iteration 8250, loss = 1.38387
I0521 22:07:19.011207 10174 solver.cpp:253]     Train net output #0: loss = 1.38387 (* 1 = 1.38387 loss)
I0521 22:07:19.011224 10174 sgd_solver.cpp:106] Iteration 8250, lr = 0.0015
I0521 22:07:31.194851 10174 solver.cpp:237] Iteration 9000, loss = 1.18291
I0521 22:07:31.194900 10174 solver.cpp:253]     Train net output #0: loss = 1.18291 (* 1 = 1.18291 loss)
I0521 22:07:31.194917 10174 sgd_solver.cpp:106] Iteration 9000, lr = 0.0015
I0521 22:07:43.425513 10174 solver.cpp:237] Iteration 9750, loss = 1.65714
I0521 22:07:43.425665 10174 solver.cpp:253]     Train net output #0: loss = 1.65714 (* 1 = 1.65714 loss)
I0521 22:07:43.425679 10174 sgd_solver.cpp:106] Iteration 9750, lr = 0.0015
I0521 22:08:17.751663 10174 solver.cpp:237] Iteration 10500, loss = 1.36537
I0521 22:08:17.751824 10174 solver.cpp:253]     Train net output #0: loss = 1.36537 (* 1 = 1.36537 loss)
I0521 22:08:17.751838 10174 sgd_solver.cpp:106] Iteration 10500, lr = 0.0015
I0521 22:08:29.862002 10174 solver.cpp:237] Iteration 11250, loss = 1.15698
I0521 22:08:29.862048 10174 solver.cpp:253]     Train net output #0: loss = 1.15698 (* 1 = 1.15698 loss)
I0521 22:08:29.862062 10174 sgd_solver.cpp:106] Iteration 11250, lr = 0.0015
I0521 22:08:41.979363 10174 solver.cpp:237] Iteration 12000, loss = 1.52164
I0521 22:08:41.979399 10174 solver.cpp:253]     Train net output #0: loss = 1.52163 (* 1 = 1.52163 loss)
I0521 22:08:41.979415 10174 sgd_solver.cpp:106] Iteration 12000, lr = 0.0015
I0521 22:08:54.146035 10174 solver.cpp:237] Iteration 12750, loss = 1.46994
I0521 22:08:54.146193 10174 solver.cpp:253]     Train net output #0: loss = 1.46994 (* 1 = 1.46994 loss)
I0521 22:08:54.146206 10174 sgd_solver.cpp:106] Iteration 12750, lr = 0.0015
I0521 22:09:06.318373 10174 solver.cpp:237] Iteration 13500, loss = 1.8078
I0521 22:09:06.318410 10174 solver.cpp:253]     Train net output #0: loss = 1.8078 (* 1 = 1.8078 loss)
I0521 22:09:06.318424 10174 sgd_solver.cpp:106] Iteration 13500, lr = 0.0015
I0521 22:09:18.489116 10174 solver.cpp:237] Iteration 14250, loss = 1.35174
I0521 22:09:18.489161 10174 solver.cpp:253]     Train net output #0: loss = 1.35174 (* 1 = 1.35174 loss)
I0521 22:09:18.489176 10174 sgd_solver.cpp:106] Iteration 14250, lr = 0.0015
I0521 22:09:30.619420 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_15000.caffemodel
I0521 22:09:30.669867 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_15000.solverstate
I0521 22:09:30.696185 10174 solver.cpp:341] Iteration 15000, Testing net (#0)
I0521 22:10:22.568517 10174 solver.cpp:409]     Test net output #0: accuracy = 0.822205
I0521 22:10:22.568675 10174 solver.cpp:409]     Test net output #1: loss = 0.596736 (* 1 = 0.596736 loss)
I0521 22:10:44.727438 10174 solver.cpp:237] Iteration 15000, loss = 1.34064
I0521 22:10:44.727493 10174 solver.cpp:253]     Train net output #0: loss = 1.34064 (* 1 = 1.34064 loss)
I0521 22:10:44.727509 10174 sgd_solver.cpp:106] Iteration 15000, lr = 0.0015
I0521 22:10:56.929492 10174 solver.cpp:237] Iteration 15750, loss = 1.38331
I0521 22:10:56.929646 10174 solver.cpp:253]     Train net output #0: loss = 1.38331 (* 1 = 1.38331 loss)
I0521 22:10:56.929661 10174 sgd_solver.cpp:106] Iteration 15750, lr = 0.0015
I0521 22:11:09.100307 10174 solver.cpp:237] Iteration 16500, loss = 2.19584
I0521 22:11:09.100342 10174 solver.cpp:253]     Train net output #0: loss = 2.19584 (* 1 = 2.19584 loss)
I0521 22:11:09.100359 10174 sgd_solver.cpp:106] Iteration 16500, lr = 0.0015
I0521 22:11:21.229632 10174 solver.cpp:237] Iteration 17250, loss = 1.34704
I0521 22:11:21.229678 10174 solver.cpp:253]     Train net output #0: loss = 1.34704 (* 1 = 1.34704 loss)
I0521 22:11:21.229693 10174 sgd_solver.cpp:106] Iteration 17250, lr = 0.0015
I0521 22:11:33.355054 10174 solver.cpp:237] Iteration 18000, loss = 1.21669
I0521 22:11:33.355191 10174 solver.cpp:253]     Train net output #0: loss = 1.21669 (* 1 = 1.21669 loss)
I0521 22:11:33.355206 10174 sgd_solver.cpp:106] Iteration 18000, lr = 0.0015
I0521 22:11:45.482208 10174 solver.cpp:237] Iteration 18750, loss = 1.04906
I0521 22:11:45.482250 10174 solver.cpp:253]     Train net output #0: loss = 1.04906 (* 1 = 1.04906 loss)
I0521 22:11:45.482264 10174 sgd_solver.cpp:106] Iteration 18750, lr = 0.0015
I0521 22:11:57.605083 10174 solver.cpp:237] Iteration 19500, loss = 1.57076
I0521 22:11:57.605119 10174 solver.cpp:253]     Train net output #0: loss = 1.57076 (* 1 = 1.57076 loss)
I0521 22:11:57.605135 10174 sgd_solver.cpp:106] Iteration 19500, lr = 0.0015
I0521 22:12:31.874230 10174 solver.cpp:237] Iteration 20250, loss = 0.964756
I0521 22:12:31.874392 10174 solver.cpp:253]     Train net output #0: loss = 0.964757 (* 1 = 0.964757 loss)
I0521 22:12:31.874405 10174 sgd_solver.cpp:106] Iteration 20250, lr = 0.0015
I0521 22:12:44.026527 10174 solver.cpp:237] Iteration 21000, loss = 1.46123
I0521 22:12:44.026564 10174 solver.cpp:253]     Train net output #0: loss = 1.46123 (* 1 = 1.46123 loss)
I0521 22:12:44.026579 10174 sgd_solver.cpp:106] Iteration 21000, lr = 0.0015
I0521 22:12:56.192819 10174 solver.cpp:237] Iteration 21750, loss = 1.29886
I0521 22:12:56.192865 10174 solver.cpp:253]     Train net output #0: loss = 1.29886 (* 1 = 1.29886 loss)
I0521 22:12:56.192881 10174 sgd_solver.cpp:106] Iteration 21750, lr = 0.0015
I0521 22:13:08.384184 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_22500.caffemodel
I0521 22:13:08.435210 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_22500.solverstate
I0521 22:13:08.468749 10174 solver.cpp:237] Iteration 22500, loss = 1.38964
I0521 22:13:08.468793 10174 solver.cpp:253]     Train net output #0: loss = 1.38964 (* 1 = 1.38964 loss)
I0521 22:13:08.468811 10174 sgd_solver.cpp:106] Iteration 22500, lr = 0.0015
I0521 22:13:20.639478 10174 solver.cpp:237] Iteration 23250, loss = 1.17262
I0521 22:13:20.639525 10174 solver.cpp:253]     Train net output #0: loss = 1.17262 (* 1 = 1.17262 loss)
I0521 22:13:20.639544 10174 sgd_solver.cpp:106] Iteration 23250, lr = 0.0015
I0521 22:13:32.779062 10174 solver.cpp:237] Iteration 24000, loss = 1.33476
I0521 22:13:32.779099 10174 solver.cpp:253]     Train net output #0: loss = 1.33476 (* 1 = 1.33476 loss)
I0521 22:13:32.779112 10174 sgd_solver.cpp:106] Iteration 24000, lr = 0.0015
I0521 22:13:44.917278 10174 solver.cpp:237] Iteration 24750, loss = 1.76218
I0521 22:13:44.917428 10174 solver.cpp:253]     Train net output #0: loss = 1.76218 (* 1 = 1.76218 loss)
I0521 22:13:44.917443 10174 sgd_solver.cpp:106] Iteration 24750, lr = 0.0015
I0521 22:14:19.234114 10174 solver.cpp:237] Iteration 25500, loss = 1.42883
I0521 22:14:19.234257 10174 solver.cpp:253]     Train net output #0: loss = 1.42883 (* 1 = 1.42883 loss)
I0521 22:14:19.234272 10174 sgd_solver.cpp:106] Iteration 25500, lr = 0.0015
I0521 22:14:31.361469 10174 solver.cpp:237] Iteration 26250, loss = 1.64305
I0521 22:14:31.361505 10174 solver.cpp:253]     Train net output #0: loss = 1.64305 (* 1 = 1.64305 loss)
I0521 22:14:31.361521 10174 sgd_solver.cpp:106] Iteration 26250, lr = 0.0015
I0521 22:14:43.498034 10174 solver.cpp:237] Iteration 27000, loss = 0.955783
I0521 22:14:43.498082 10174 solver.cpp:253]     Train net output #0: loss = 0.955783 (* 1 = 0.955783 loss)
I0521 22:14:43.498096 10174 sgd_solver.cpp:106] Iteration 27000, lr = 0.0015
I0521 22:14:55.650822 10174 solver.cpp:237] Iteration 27750, loss = 1.27852
I0521 22:14:55.650960 10174 solver.cpp:253]     Train net output #0: loss = 1.27852 (* 1 = 1.27852 loss)
I0521 22:14:55.650974 10174 sgd_solver.cpp:106] Iteration 27750, lr = 0.0015
I0521 22:15:07.789288 10174 solver.cpp:237] Iteration 28500, loss = 1.36845
I0521 22:15:07.789335 10174 solver.cpp:253]     Train net output #0: loss = 1.36845 (* 1 = 1.36845 loss)
I0521 22:15:07.789350 10174 sgd_solver.cpp:106] Iteration 28500, lr = 0.0015
I0521 22:15:19.954808 10174 solver.cpp:237] Iteration 29250, loss = 0.55386
I0521 22:15:19.954845 10174 solver.cpp:253]     Train net output #0: loss = 0.553861 (* 1 = 0.553861 loss)
I0521 22:15:19.954859 10174 sgd_solver.cpp:106] Iteration 29250, lr = 0.0015
I0521 22:15:32.095456 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_30000.caffemodel
I0521 22:15:32.146880 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_30000.solverstate
I0521 22:15:32.175155 10174 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 22:16:45.007050 10174 solver.cpp:409]     Test net output #0: accuracy = 0.850575
I0521 22:16:45.007216 10174 solver.cpp:409]     Test net output #1: loss = 0.547657 (* 1 = 0.547657 loss)
I0521 22:17:07.134186 10174 solver.cpp:237] Iteration 30000, loss = 1.24898
I0521 22:17:07.134239 10174 solver.cpp:253]     Train net output #0: loss = 1.24898 (* 1 = 1.24898 loss)
I0521 22:17:07.134254 10174 sgd_solver.cpp:106] Iteration 30000, lr = 0.0015
I0521 22:17:19.283083 10174 solver.cpp:237] Iteration 30750, loss = 1.04998
I0521 22:17:19.283234 10174 solver.cpp:253]     Train net output #0: loss = 1.04998 (* 1 = 1.04998 loss)
I0521 22:17:19.283247 10174 sgd_solver.cpp:106] Iteration 30750, lr = 0.0015
I0521 22:17:31.442669 10174 solver.cpp:237] Iteration 31500, loss = 1.21187
I0521 22:17:31.442713 10174 solver.cpp:253]     Train net output #0: loss = 1.21187 (* 1 = 1.21187 loss)
I0521 22:17:31.442728 10174 sgd_solver.cpp:106] Iteration 31500, lr = 0.0015
I0521 22:17:43.623364 10174 solver.cpp:237] Iteration 32250, loss = 1.60227
I0521 22:17:43.623401 10174 solver.cpp:253]     Train net output #0: loss = 1.60227 (* 1 = 1.60227 loss)
I0521 22:17:43.623416 10174 sgd_solver.cpp:106] Iteration 32250, lr = 0.0015
I0521 22:17:55.779901 10174 solver.cpp:237] Iteration 33000, loss = 1.22311
I0521 22:17:55.780046 10174 solver.cpp:253]     Train net output #0: loss = 1.22311 (* 1 = 1.22311 loss)
I0521 22:17:55.780061 10174 sgd_solver.cpp:106] Iteration 33000, lr = 0.0015
I0521 22:18:07.956375 10174 solver.cpp:237] Iteration 33750, loss = 1.05185
I0521 22:18:07.956411 10174 solver.cpp:253]     Train net output #0: loss = 1.05185 (* 1 = 1.05185 loss)
I0521 22:18:07.956428 10174 sgd_solver.cpp:106] Iteration 33750, lr = 0.0015
I0521 22:18:20.142537 10174 solver.cpp:237] Iteration 34500, loss = 1.08047
I0521 22:18:20.142583 10174 solver.cpp:253]     Train net output #0: loss = 1.08047 (* 1 = 1.08047 loss)
I0521 22:18:20.142599 10174 sgd_solver.cpp:106] Iteration 34500, lr = 0.0015
I0521 22:18:54.496688 10174 solver.cpp:237] Iteration 35250, loss = 1.36436
I0521 22:18:54.496855 10174 solver.cpp:253]     Train net output #0: loss = 1.36436 (* 1 = 1.36436 loss)
I0521 22:18:54.496870 10174 sgd_solver.cpp:106] Iteration 35250, lr = 0.0015
I0521 22:19:06.704377 10174 solver.cpp:237] Iteration 36000, loss = 1.428
I0521 22:19:06.704413 10174 solver.cpp:253]     Train net output #0: loss = 1.428 (* 1 = 1.428 loss)
I0521 22:19:06.704428 10174 sgd_solver.cpp:106] Iteration 36000, lr = 0.0015
I0521 22:19:18.925482 10174 solver.cpp:237] Iteration 36750, loss = 1.13073
I0521 22:19:18.925528 10174 solver.cpp:253]     Train net output #0: loss = 1.13073 (* 1 = 1.13073 loss)
I0521 22:19:18.925541 10174 sgd_solver.cpp:106] Iteration 36750, lr = 0.0015
I0521 22:19:31.124557 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_37500.caffemodel
I0521 22:19:31.175801 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_37500.solverstate
I0521 22:19:31.208875 10174 solver.cpp:237] Iteration 37500, loss = 1.4796
I0521 22:19:31.208925 10174 solver.cpp:253]     Train net output #0: loss = 1.4796 (* 1 = 1.4796 loss)
I0521 22:19:31.208940 10174 sgd_solver.cpp:106] Iteration 37500, lr = 0.0015
I0521 22:19:43.391396 10174 solver.cpp:237] Iteration 38250, loss = 1.5082
I0521 22:19:43.391443 10174 solver.cpp:253]     Train net output #0: loss = 1.5082 (* 1 = 1.5082 loss)
I0521 22:19:43.391458 10174 sgd_solver.cpp:106] Iteration 38250, lr = 0.0015
I0521 22:19:55.612292 10174 solver.cpp:237] Iteration 39000, loss = 1.14752
I0521 22:19:55.612328 10174 solver.cpp:253]     Train net output #0: loss = 1.14753 (* 1 = 1.14753 loss)
I0521 22:19:55.612344 10174 sgd_solver.cpp:106] Iteration 39000, lr = 0.0015
I0521 22:20:07.832046 10174 solver.cpp:237] Iteration 39750, loss = 1.19582
I0521 22:20:07.832202 10174 solver.cpp:253]     Train net output #0: loss = 1.19582 (* 1 = 1.19582 loss)
I0521 22:20:07.832218 10174 sgd_solver.cpp:106] Iteration 39750, lr = 0.0015
I0521 22:20:42.219458 10174 solver.cpp:237] Iteration 40500, loss = 1.33824
I0521 22:20:42.219645 10174 solver.cpp:253]     Train net output #0: loss = 1.33824 (* 1 = 1.33824 loss)
I0521 22:20:42.219660 10174 sgd_solver.cpp:106] Iteration 40500, lr = 0.0015
I0521 22:20:54.402204 10174 solver.cpp:237] Iteration 41250, loss = 0.871482
I0521 22:20:54.402252 10174 solver.cpp:253]     Train net output #0: loss = 0.871484 (* 1 = 0.871484 loss)
I0521 22:20:54.402267 10174 sgd_solver.cpp:106] Iteration 41250, lr = 0.0015
I0521 22:21:06.595994 10174 solver.cpp:237] Iteration 42000, loss = 1.86977
I0521 22:21:06.596026 10174 solver.cpp:253]     Train net output #0: loss = 1.86977 (* 1 = 1.86977 loss)
I0521 22:21:06.596040 10174 sgd_solver.cpp:106] Iteration 42000, lr = 0.0015
I0521 22:21:18.763309 10174 solver.cpp:237] Iteration 42750, loss = 1.08723
I0521 22:21:18.763460 10174 solver.cpp:253]     Train net output #0: loss = 1.08723 (* 1 = 1.08723 loss)
I0521 22:21:18.763475 10174 sgd_solver.cpp:106] Iteration 42750, lr = 0.0015
I0521 22:21:30.997269 10174 solver.cpp:237] Iteration 43500, loss = 1.30169
I0521 22:21:30.997305 10174 solver.cpp:253]     Train net output #0: loss = 1.3017 (* 1 = 1.3017 loss)
I0521 22:21:30.997319 10174 sgd_solver.cpp:106] Iteration 43500, lr = 0.0015
I0521 22:21:43.246368 10174 solver.cpp:237] Iteration 44250, loss = 0.848423
I0521 22:21:43.246413 10174 solver.cpp:253]     Train net output #0: loss = 0.848425 (* 1 = 0.848425 loss)
I0521 22:21:43.246428 10174 sgd_solver.cpp:106] Iteration 44250, lr = 0.0015
I0521 22:21:55.433032 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_45000.caffemodel
I0521 22:21:55.481981 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_45000.solverstate
I0521 22:21:55.507971 10174 solver.cpp:341] Iteration 45000, Testing net (#0)
I0521 22:22:47.206610 10174 solver.cpp:409]     Test net output #0: accuracy = 0.862174
I0521 22:22:47.206768 10174 solver.cpp:409]     Test net output #1: loss = 0.493257 (* 1 = 0.493257 loss)
I0521 22:23:09.325105 10174 solver.cpp:237] Iteration 45000, loss = 1.25001
I0521 22:23:09.325157 10174 solver.cpp:253]     Train net output #0: loss = 1.25001 (* 1 = 1.25001 loss)
I0521 22:23:09.325175 10174 sgd_solver.cpp:106] Iteration 45000, lr = 0.0015
I0521 22:23:21.398828 10174 solver.cpp:237] Iteration 45750, loss = 1.0363
I0521 22:23:21.398993 10174 solver.cpp:253]     Train net output #0: loss = 1.0363 (* 1 = 1.0363 loss)
I0521 22:23:21.399008 10174 sgd_solver.cpp:106] Iteration 45750, lr = 0.0015
I0521 22:23:33.557903 10174 solver.cpp:237] Iteration 46500, loss = 1.53745
I0521 22:23:33.557939 10174 solver.cpp:253]     Train net output #0: loss = 1.53745 (* 1 = 1.53745 loss)
I0521 22:23:33.557955 10174 sgd_solver.cpp:106] Iteration 46500, lr = 0.0015
I0521 22:23:45.721978 10174 solver.cpp:237] Iteration 47250, loss = 1.56037
I0521 22:23:45.722018 10174 solver.cpp:253]     Train net output #0: loss = 1.56038 (* 1 = 1.56038 loss)
I0521 22:23:45.722038 10174 sgd_solver.cpp:106] Iteration 47250, lr = 0.0015
I0521 22:23:57.849509 10174 solver.cpp:237] Iteration 48000, loss = 0.782903
I0521 22:23:57.849653 10174 solver.cpp:253]     Train net output #0: loss = 0.782905 (* 1 = 0.782905 loss)
I0521 22:23:57.849668 10174 sgd_solver.cpp:106] Iteration 48000, lr = 0.0015
I0521 22:24:09.999560 10174 solver.cpp:237] Iteration 48750, loss = 1.58207
I0521 22:24:09.999601 10174 solver.cpp:253]     Train net output #0: loss = 1.58208 (* 1 = 1.58208 loss)
I0521 22:24:09.999620 10174 sgd_solver.cpp:106] Iteration 48750, lr = 0.0015
I0521 22:24:22.190985 10174 solver.cpp:237] Iteration 49500, loss = 1.23643
I0521 22:24:22.191020 10174 solver.cpp:253]     Train net output #0: loss = 1.23643 (* 1 = 1.23643 loss)
I0521 22:24:22.191038 10174 sgd_solver.cpp:106] Iteration 49500, lr = 0.0015
I0521 22:24:56.537227 10174 solver.cpp:237] Iteration 50250, loss = 1.32188
I0521 22:24:56.537405 10174 solver.cpp:253]     Train net output #0: loss = 1.32188 (* 1 = 1.32188 loss)
I0521 22:24:56.537420 10174 sgd_solver.cpp:106] Iteration 50250, lr = 0.0015
I0521 22:25:08.698806 10174 solver.cpp:237] Iteration 51000, loss = 1.43194
I0521 22:25:08.698851 10174 solver.cpp:253]     Train net output #0: loss = 1.43195 (* 1 = 1.43195 loss)
I0521 22:25:08.698864 10174 sgd_solver.cpp:106] Iteration 51000, lr = 0.0015
I0521 22:25:20.814708 10174 solver.cpp:237] Iteration 51750, loss = 1.43105
I0521 22:25:20.814744 10174 solver.cpp:253]     Train net output #0: loss = 1.43105 (* 1 = 1.43105 loss)
I0521 22:25:20.814760 10174 sgd_solver.cpp:106] Iteration 51750, lr = 0.0015
I0521 22:25:32.918416 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_52500.caffemodel
I0521 22:25:32.967538 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_52500.solverstate
I0521 22:25:32.998639 10174 solver.cpp:237] Iteration 52500, loss = 1.4446
I0521 22:25:32.998678 10174 solver.cpp:253]     Train net output #0: loss = 1.4446 (* 1 = 1.4446 loss)
I0521 22:25:32.998699 10174 sgd_solver.cpp:106] Iteration 52500, lr = 0.0015
I0521 22:25:45.117099 10174 solver.cpp:237] Iteration 53250, loss = 1.35621
I0521 22:25:45.117135 10174 solver.cpp:253]     Train net output #0: loss = 1.35621 (* 1 = 1.35621 loss)
I0521 22:25:45.117151 10174 sgd_solver.cpp:106] Iteration 53250, lr = 0.0015
I0521 22:25:57.282721 10174 solver.cpp:237] Iteration 54000, loss = 1.17612
I0521 22:25:57.282766 10174 solver.cpp:253]     Train net output #0: loss = 1.17612 (* 1 = 1.17612 loss)
I0521 22:25:57.282780 10174 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015
I0521 22:26:09.458019 10174 solver.cpp:237] Iteration 54750, loss = 0.775431
I0521 22:26:09.458175 10174 solver.cpp:253]     Train net output #0: loss = 0.775433 (* 1 = 0.775433 loss)
I0521 22:26:09.458189 10174 sgd_solver.cpp:106] Iteration 54750, lr = 0.0015
I0521 22:26:43.776794 10174 solver.cpp:237] Iteration 55500, loss = 0.928742
I0521 22:26:43.776964 10174 solver.cpp:253]     Train net output #0: loss = 0.928743 (* 1 = 0.928743 loss)
I0521 22:26:43.776978 10174 sgd_solver.cpp:106] Iteration 55500, lr = 0.0015
I0521 22:26:55.934384 10174 solver.cpp:237] Iteration 56250, loss = 1.29017
I0521 22:26:55.934420 10174 solver.cpp:253]     Train net output #0: loss = 1.29017 (* 1 = 1.29017 loss)
I0521 22:26:55.934433 10174 sgd_solver.cpp:106] Iteration 56250, lr = 0.0015
I0521 22:27:08.097975 10174 solver.cpp:237] Iteration 57000, loss = 1.64691
I0521 22:27:08.098024 10174 solver.cpp:253]     Train net output #0: loss = 1.64691 (* 1 = 1.64691 loss)
I0521 22:27:08.098038 10174 sgd_solver.cpp:106] Iteration 57000, lr = 0.0015
I0521 22:27:20.268513 10174 solver.cpp:237] Iteration 57750, loss = 0.967665
I0521 22:27:20.268661 10174 solver.cpp:253]     Train net output #0: loss = 0.967667 (* 1 = 0.967667 loss)
I0521 22:27:20.268674 10174 sgd_solver.cpp:106] Iteration 57750, lr = 0.0015
I0521 22:27:32.405990 10174 solver.cpp:237] Iteration 58500, loss = 1.06989
I0521 22:27:32.406038 10174 solver.cpp:253]     Train net output #0: loss = 1.06989 (* 1 = 1.06989 loss)
I0521 22:27:32.406054 10174 sgd_solver.cpp:106] Iteration 58500, lr = 0.0015
I0521 22:27:44.498452 10174 solver.cpp:237] Iteration 59250, loss = 1.28398
I0521 22:27:44.498488 10174 solver.cpp:253]     Train net output #0: loss = 1.28398 (* 1 = 1.28398 loss)
I0521 22:27:44.498504 10174 sgd_solver.cpp:106] Iteration 59250, lr = 0.0015
I0521 22:27:56.564112 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_60000.caffemodel
I0521 22:27:56.612902 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_60000.solverstate
I0521 22:27:56.638833 10174 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 22:29:09.453717 10174 solver.cpp:409]     Test net output #0: accuracy = 0.871434
I0521 22:29:09.453894 10174 solver.cpp:409]     Test net output #1: loss = 0.417616 (* 1 = 0.417616 loss)
I0521 22:29:31.630465 10174 solver.cpp:237] Iteration 60000, loss = 1.70379
I0521 22:29:31.630517 10174 solver.cpp:253]     Train net output #0: loss = 1.70379 (* 1 = 1.70379 loss)
I0521 22:29:31.630533 10174 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0521 22:29:43.829939 10174 solver.cpp:237] Iteration 60750, loss = 1.4377
I0521 22:29:43.830106 10174 solver.cpp:253]     Train net output #0: loss = 1.4377 (* 1 = 1.4377 loss)
I0521 22:29:43.830121 10174 sgd_solver.cpp:106] Iteration 60750, lr = 0.0015
I0521 22:29:56.044533 10174 solver.cpp:237] Iteration 61500, loss = 0.968654
I0521 22:29:56.044569 10174 solver.cpp:253]     Train net output #0: loss = 0.968656 (* 1 = 0.968656 loss)
I0521 22:29:56.044584 10174 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0521 22:30:08.241662 10174 solver.cpp:237] Iteration 62250, loss = 0.857876
I0521 22:30:08.241705 10174 solver.cpp:253]     Train net output #0: loss = 0.857878 (* 1 = 0.857878 loss)
I0521 22:30:08.241720 10174 sgd_solver.cpp:106] Iteration 62250, lr = 0.0015
I0521 22:30:20.441287 10174 solver.cpp:237] Iteration 63000, loss = 1.11508
I0521 22:30:20.441428 10174 solver.cpp:253]     Train net output #0: loss = 1.11508 (* 1 = 1.11508 loss)
I0521 22:30:20.441442 10174 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0521 22:30:32.634407 10174 solver.cpp:237] Iteration 63750, loss = 1.05907
I0521 22:30:32.634449 10174 solver.cpp:253]     Train net output #0: loss = 1.05907 (* 1 = 1.05907 loss)
I0521 22:30:32.634462 10174 sgd_solver.cpp:106] Iteration 63750, lr = 0.0015
I0521 22:30:44.817620 10174 solver.cpp:237] Iteration 64500, loss = 1.22015
I0521 22:30:44.817656 10174 solver.cpp:253]     Train net output #0: loss = 1.22015 (* 1 = 1.22015 loss)
I0521 22:30:44.817672 10174 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0521 22:31:19.181126 10174 solver.cpp:237] Iteration 65250, loss = 1.23892
I0521 22:31:19.181305 10174 solver.cpp:253]     Train net output #0: loss = 1.23893 (* 1 = 1.23893 loss)
I0521 22:31:19.181321 10174 sgd_solver.cpp:106] Iteration 65250, lr = 0.0015
I0521 22:31:31.434473 10174 solver.cpp:237] Iteration 66000, loss = 1.30134
I0521 22:31:31.434510 10174 solver.cpp:253]     Train net output #0: loss = 1.30134 (* 1 = 1.30134 loss)
I0521 22:31:31.434525 10174 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0521 22:31:43.691367 10174 solver.cpp:237] Iteration 66750, loss = 1.15148
I0521 22:31:43.691412 10174 solver.cpp:253]     Train net output #0: loss = 1.15148 (* 1 = 1.15148 loss)
I0521 22:31:43.691427 10174 sgd_solver.cpp:106] Iteration 66750, lr = 0.0015
I0521 22:31:55.871116 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_67500.caffemodel
I0521 22:31:55.926733 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_67500.solverstate
I0521 22:31:55.959785 10174 solver.cpp:237] Iteration 67500, loss = 2.26312
I0521 22:31:55.959836 10174 solver.cpp:253]     Train net output #0: loss = 2.26312 (* 1 = 2.26312 loss)
I0521 22:31:55.959851 10174 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0521 22:32:08.151145 10174 solver.cpp:237] Iteration 68250, loss = 1.20909
I0521 22:32:08.151196 10174 solver.cpp:253]     Train net output #0: loss = 1.20909 (* 1 = 1.20909 loss)
I0521 22:32:08.151211 10174 sgd_solver.cpp:106] Iteration 68250, lr = 0.0015
I0521 22:32:20.348727 10174 solver.cpp:237] Iteration 69000, loss = 2.19206
I0521 22:32:20.348763 10174 solver.cpp:253]     Train net output #0: loss = 2.19206 (* 1 = 2.19206 loss)
I0521 22:32:20.348779 10174 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0521 22:32:32.540983 10174 solver.cpp:237] Iteration 69750, loss = 1.15742
I0521 22:32:32.541157 10174 solver.cpp:253]     Train net output #0: loss = 1.15742 (* 1 = 1.15742 loss)
I0521 22:32:32.541172 10174 sgd_solver.cpp:106] Iteration 69750, lr = 0.0015
I0521 22:33:06.839371 10174 solver.cpp:237] Iteration 70500, loss = 1.39971
I0521 22:33:06.839542 10174 solver.cpp:253]     Train net output #0: loss = 1.39971 (* 1 = 1.39971 loss)
I0521 22:33:06.839556 10174 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0521 22:33:19.002715 10174 solver.cpp:237] Iteration 71250, loss = 1.2885
I0521 22:33:19.002751 10174 solver.cpp:253]     Train net output #0: loss = 1.2885 (* 1 = 1.2885 loss)
I0521 22:33:19.002768 10174 sgd_solver.cpp:106] Iteration 71250, lr = 0.0015
I0521 22:33:31.156961 10174 solver.cpp:237] Iteration 72000, loss = 0.917155
I0521 22:33:31.157007 10174 solver.cpp:253]     Train net output #0: loss = 0.917156 (* 1 = 0.917156 loss)
I0521 22:33:31.157023 10174 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0521 22:33:43.331544 10174 solver.cpp:237] Iteration 72750, loss = 1.36282
I0521 22:33:43.331691 10174 solver.cpp:253]     Train net output #0: loss = 1.36282 (* 1 = 1.36282 loss)
I0521 22:33:43.331706 10174 sgd_solver.cpp:106] Iteration 72750, lr = 0.0015
I0521 22:33:55.528655 10174 solver.cpp:237] Iteration 73500, loss = 1.3528
I0521 22:33:55.528699 10174 solver.cpp:253]     Train net output #0: loss = 1.3528 (* 1 = 1.3528 loss)
I0521 22:33:55.528717 10174 sgd_solver.cpp:106] Iteration 73500, lr = 0.0015
I0521 22:34:07.715895 10174 solver.cpp:237] Iteration 74250, loss = 2.46968
I0521 22:34:07.715931 10174 solver.cpp:253]     Train net output #0: loss = 2.46968 (* 1 = 2.46968 loss)
I0521 22:34:07.715948 10174 sgd_solver.cpp:106] Iteration 74250, lr = 0.0015
I0521 22:34:19.939728 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_75000.caffemodel
I0521 22:34:19.990545 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_75000.solverstate
I0521 22:34:20.018517 10174 solver.cpp:341] Iteration 75000, Testing net (#0)
I0521 22:35:11.901540 10174 solver.cpp:409]     Test net output #0: accuracy = 0.880349
I0521 22:35:11.901698 10174 solver.cpp:409]     Test net output #1: loss = 0.391905 (* 1 = 0.391905 loss)
I0521 22:35:32.754952 10174 solver.cpp:237] Iteration 75000, loss = 1.43253
I0521 22:35:32.755004 10174 solver.cpp:253]     Train net output #0: loss = 1.43253 (* 1 = 1.43253 loss)
I0521 22:35:32.755019 10174 sgd_solver.cpp:106] Iteration 75000, lr = 0.0015
I0521 22:35:44.895330 10174 solver.cpp:237] Iteration 75750, loss = 1.08601
I0521 22:35:44.895484 10174 solver.cpp:253]     Train net output #0: loss = 1.08601 (* 1 = 1.08601 loss)
I0521 22:35:44.895498 10174 sgd_solver.cpp:106] Iteration 75750, lr = 0.0015
I0521 22:35:57.041139 10174 solver.cpp:237] Iteration 76500, loss = 1.23703
I0521 22:35:57.041189 10174 solver.cpp:253]     Train net output #0: loss = 1.23703 (* 1 = 1.23703 loss)
I0521 22:35:57.041205 10174 sgd_solver.cpp:106] Iteration 76500, lr = 0.0015
I0521 22:36:09.161923 10174 solver.cpp:237] Iteration 77250, loss = 1.13631
I0521 22:36:09.161959 10174 solver.cpp:253]     Train net output #0: loss = 1.13631 (* 1 = 1.13631 loss)
I0521 22:36:09.161977 10174 sgd_solver.cpp:106] Iteration 77250, lr = 0.0015
I0521 22:36:21.261605 10174 solver.cpp:237] Iteration 78000, loss = 1.30626
I0521 22:36:21.261764 10174 solver.cpp:253]     Train net output #0: loss = 1.30627 (* 1 = 1.30627 loss)
I0521 22:36:21.261783 10174 sgd_solver.cpp:106] Iteration 78000, lr = 0.0015
I0521 22:36:33.331097 10174 solver.cpp:237] Iteration 78750, loss = 1.12435
I0521 22:36:33.331135 10174 solver.cpp:253]     Train net output #0: loss = 1.12435 (* 1 = 1.12435 loss)
I0521 22:36:33.331151 10174 sgd_solver.cpp:106] Iteration 78750, lr = 0.0015
I0521 22:36:45.403481 10174 solver.cpp:237] Iteration 79500, loss = 1.37499
I0521 22:36:45.403524 10174 solver.cpp:253]     Train net output #0: loss = 1.37499 (* 1 = 1.37499 loss)
I0521 22:36:45.403539 10174 sgd_solver.cpp:106] Iteration 79500, lr = 0.0015
I0521 22:37:18.324296 10174 solver.cpp:237] Iteration 80250, loss = 1.64615
I0521 22:37:18.324471 10174 solver.cpp:253]     Train net output #0: loss = 1.64615 (* 1 = 1.64615 loss)
I0521 22:37:18.324487 10174 sgd_solver.cpp:106] Iteration 80250, lr = 0.0015
I0521 22:37:30.440580 10174 solver.cpp:237] Iteration 81000, loss = 0.578587
I0521 22:37:30.440628 10174 solver.cpp:253]     Train net output #0: loss = 0.578588 (* 1 = 0.578588 loss)
I0521 22:37:30.440644 10174 sgd_solver.cpp:106] Iteration 81000, lr = 0.0015
I0521 22:37:42.578701 10174 solver.cpp:237] Iteration 81750, loss = 2.20465
I0521 22:37:42.578737 10174 solver.cpp:253]     Train net output #0: loss = 2.20465 (* 1 = 2.20465 loss)
I0521 22:37:42.578752 10174 sgd_solver.cpp:106] Iteration 81750, lr = 0.0015
I0521 22:37:54.717990 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_82500.caffemodel
I0521 22:37:54.766244 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_82500.solverstate
I0521 22:37:54.796982 10174 solver.cpp:237] Iteration 82500, loss = 0.957316
I0521 22:37:54.797026 10174 solver.cpp:253]     Train net output #0: loss = 0.957317 (* 1 = 0.957317 loss)
I0521 22:37:54.797040 10174 sgd_solver.cpp:106] Iteration 82500, lr = 0.0015
I0521 22:38:06.940722 10174 solver.cpp:237] Iteration 83250, loss = 1.74407
I0521 22:38:06.940758 10174 solver.cpp:253]     Train net output #0: loss = 1.74407 (* 1 = 1.74407 loss)
I0521 22:38:06.940774 10174 sgd_solver.cpp:106] Iteration 83250, lr = 0.0015
I0521 22:38:19.079849 10174 solver.cpp:237] Iteration 84000, loss = 0.750631
I0521 22:38:19.079885 10174 solver.cpp:253]     Train net output #0: loss = 0.750632 (* 1 = 0.750632 loss)
I0521 22:38:19.079901 10174 sgd_solver.cpp:106] Iteration 84000, lr = 0.0015
I0521 22:38:31.225687 10174 solver.cpp:237] Iteration 84750, loss = 1.26142
I0521 22:38:31.225855 10174 solver.cpp:253]     Train net output #0: loss = 1.26142 (* 1 = 1.26142 loss)
I0521 22:38:31.225869 10174 sgd_solver.cpp:106] Iteration 84750, lr = 0.0015
I0521 22:39:04.167359 10174 solver.cpp:237] Iteration 85500, loss = 1.19535
I0521 22:39:04.167529 10174 solver.cpp:253]     Train net output #0: loss = 1.19535 (* 1 = 1.19535 loss)
I0521 22:39:04.167544 10174 sgd_solver.cpp:106] Iteration 85500, lr = 0.0015
I0521 22:39:16.269914 10174 solver.cpp:237] Iteration 86250, loss = 0.717703
I0521 22:39:16.269958 10174 solver.cpp:253]     Train net output #0: loss = 0.717704 (* 1 = 0.717704 loss)
I0521 22:39:16.269973 10174 sgd_solver.cpp:106] Iteration 86250, lr = 0.0015
I0521 22:39:28.339658 10174 solver.cpp:237] Iteration 87000, loss = 1.28136
I0521 22:39:28.339694 10174 solver.cpp:253]     Train net output #0: loss = 1.28136 (* 1 = 1.28136 loss)
I0521 22:39:28.339709 10174 sgd_solver.cpp:106] Iteration 87000, lr = 0.0015
I0521 22:39:40.396051 10174 solver.cpp:237] Iteration 87750, loss = 1.32777
I0521 22:39:40.396199 10174 solver.cpp:253]     Train net output #0: loss = 1.32777 (* 1 = 1.32777 loss)
I0521 22:39:40.396214 10174 sgd_solver.cpp:106] Iteration 87750, lr = 0.0015
I0521 22:39:52.491835 10174 solver.cpp:237] Iteration 88500, loss = 1.37711
I0521 22:39:52.491871 10174 solver.cpp:253]     Train net output #0: loss = 1.37711 (* 1 = 1.37711 loss)
I0521 22:39:52.491884 10174 sgd_solver.cpp:106] Iteration 88500, lr = 0.0015
I0521 22:40:04.596230 10174 solver.cpp:237] Iteration 89250, loss = 1.61102
I0521 22:40:04.596276 10174 solver.cpp:253]     Train net output #0: loss = 1.61102 (* 1 = 1.61102 loss)
I0521 22:40:04.596292 10174 sgd_solver.cpp:106] Iteration 89250, lr = 0.0015
I0521 22:40:16.683218 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_90000.caffemodel
I0521 22:40:16.732285 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_90000.solverstate
I0521 22:40:16.758224 10174 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 22:41:29.535825 10174 solver.cpp:409]     Test net output #0: accuracy = 0.880382
I0521 22:41:29.535991 10174 solver.cpp:409]     Test net output #1: loss = 0.375135 (* 1 = 0.375135 loss)
I0521 22:41:50.374822 10174 solver.cpp:237] Iteration 90000, loss = 0.883228
I0521 22:41:50.374876 10174 solver.cpp:253]     Train net output #0: loss = 0.883229 (* 1 = 0.883229 loss)
I0521 22:41:50.374891 10174 sgd_solver.cpp:106] Iteration 90000, lr = 0.0015
I0521 22:42:02.545426 10174 solver.cpp:237] Iteration 90750, loss = 1.15607
I0521 22:42:02.545578 10174 solver.cpp:253]     Train net output #0: loss = 1.15607 (* 1 = 1.15607 loss)
I0521 22:42:02.545593 10174 sgd_solver.cpp:106] Iteration 90750, lr = 0.0015
I0521 22:42:14.697376 10174 solver.cpp:237] Iteration 91500, loss = 1.0521
I0521 22:42:14.697419 10174 solver.cpp:253]     Train net output #0: loss = 1.0521 (* 1 = 1.0521 loss)
I0521 22:42:14.697435 10174 sgd_solver.cpp:106] Iteration 91500, lr = 0.0015
I0521 22:42:26.846616 10174 solver.cpp:237] Iteration 92250, loss = 1.28797
I0521 22:42:26.846652 10174 solver.cpp:253]     Train net output #0: loss = 1.28798 (* 1 = 1.28798 loss)
I0521 22:42:26.846667 10174 sgd_solver.cpp:106] Iteration 92250, lr = 0.0015
I0521 22:42:38.972259 10174 solver.cpp:237] Iteration 93000, loss = 1.43228
I0521 22:42:38.972420 10174 solver.cpp:253]     Train net output #0: loss = 1.43228 (* 1 = 1.43228 loss)
I0521 22:42:38.972435 10174 sgd_solver.cpp:106] Iteration 93000, lr = 0.0015
I0521 22:42:51.056213 10174 solver.cpp:237] Iteration 93750, loss = 1.47944
I0521 22:42:51.056249 10174 solver.cpp:253]     Train net output #0: loss = 1.47944 (* 1 = 1.47944 loss)
I0521 22:42:51.056265 10174 sgd_solver.cpp:106] Iteration 93750, lr = 0.0015
I0521 22:43:03.164691 10174 solver.cpp:237] Iteration 94500, loss = 0.99775
I0521 22:43:03.164741 10174 solver.cpp:253]     Train net output #0: loss = 0.997752 (* 1 = 0.997752 loss)
I0521 22:43:03.164755 10174 sgd_solver.cpp:106] Iteration 94500, lr = 0.0015
I0521 22:43:36.138684 10174 solver.cpp:237] Iteration 95250, loss = 1.5276
I0521 22:43:36.138852 10174 solver.cpp:253]     Train net output #0: loss = 1.5276 (* 1 = 1.5276 loss)
I0521 22:43:36.138867 10174 sgd_solver.cpp:106] Iteration 95250, lr = 0.0015
I0521 22:43:48.307111 10174 solver.cpp:237] Iteration 96000, loss = 1.22423
I0521 22:43:48.307155 10174 solver.cpp:253]     Train net output #0: loss = 1.22424 (* 1 = 1.22424 loss)
I0521 22:43:48.307171 10174 sgd_solver.cpp:106] Iteration 96000, lr = 0.0015
I0521 22:44:00.479985 10174 solver.cpp:237] Iteration 96750, loss = 1.093
I0521 22:44:00.480021 10174 solver.cpp:253]     Train net output #0: loss = 1.093 (* 1 = 1.093 loss)
I0521 22:44:00.480036 10174 sgd_solver.cpp:106] Iteration 96750, lr = 0.0015
I0521 22:44:12.624181 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_97500.caffemodel
I0521 22:44:12.672912 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_97500.solverstate
I0521 22:44:12.706951 10174 solver.cpp:237] Iteration 97500, loss = 1.53613
I0521 22:44:12.706995 10174 solver.cpp:253]     Train net output #0: loss = 1.53614 (* 1 = 1.53614 loss)
I0521 22:44:12.707015 10174 sgd_solver.cpp:106] Iteration 97500, lr = 0.0015
I0521 22:44:24.806954 10174 solver.cpp:237] Iteration 98250, loss = 1.11731
I0521 22:44:24.806991 10174 solver.cpp:253]     Train net output #0: loss = 1.11731 (* 1 = 1.11731 loss)
I0521 22:44:24.807006 10174 sgd_solver.cpp:106] Iteration 98250, lr = 0.0015
I0521 22:44:36.904566 10174 solver.cpp:237] Iteration 99000, loss = 1.40042
I0521 22:44:36.904614 10174 solver.cpp:253]     Train net output #0: loss = 1.40042 (* 1 = 1.40042 loss)
I0521 22:44:36.904630 10174 sgd_solver.cpp:106] Iteration 99000, lr = 0.0015
I0521 22:44:48.964656 10174 solver.cpp:237] Iteration 99750, loss = 1.54963
I0521 22:44:48.964820 10174 solver.cpp:253]     Train net output #0: loss = 1.54963 (* 1 = 1.54963 loss)
I0521 22:44:48.964834 10174 sgd_solver.cpp:106] Iteration 99750, lr = 0.0015
I0521 22:45:21.863237 10174 solver.cpp:237] Iteration 100500, loss = 0.798039
I0521 22:45:21.863412 10174 solver.cpp:253]     Train net output #0: loss = 0.798041 (* 1 = 0.798041 loss)
I0521 22:45:21.863428 10174 sgd_solver.cpp:106] Iteration 100500, lr = 0.0015
I0521 22:45:33.925413 10174 solver.cpp:237] Iteration 101250, loss = 1.25842
I0521 22:45:33.925457 10174 solver.cpp:253]     Train net output #0: loss = 1.25842 (* 1 = 1.25842 loss)
I0521 22:45:33.925472 10174 sgd_solver.cpp:106] Iteration 101250, lr = 0.0015
I0521 22:45:46.058462 10174 solver.cpp:237] Iteration 102000, loss = 0.94303
I0521 22:45:46.058498 10174 solver.cpp:253]     Train net output #0: loss = 0.943031 (* 1 = 0.943031 loss)
I0521 22:45:46.058514 10174 sgd_solver.cpp:106] Iteration 102000, lr = 0.0015
I0521 22:45:58.161558 10174 solver.cpp:237] Iteration 102750, loss = 0.980154
I0521 22:45:58.161733 10174 solver.cpp:253]     Train net output #0: loss = 0.980156 (* 1 = 0.980156 loss)
I0521 22:45:58.161748 10174 sgd_solver.cpp:106] Iteration 102750, lr = 0.0015
I0521 22:46:10.246158 10174 solver.cpp:237] Iteration 103500, loss = 0.99882
I0521 22:46:10.246196 10174 solver.cpp:253]     Train net output #0: loss = 0.998822 (* 1 = 0.998822 loss)
I0521 22:46:10.246212 10174 sgd_solver.cpp:106] Iteration 103500, lr = 0.0015
I0521 22:46:22.385382 10174 solver.cpp:237] Iteration 104250, loss = 1.27637
I0521 22:46:22.385431 10174 solver.cpp:253]     Train net output #0: loss = 1.27637 (* 1 = 1.27637 loss)
I0521 22:46:22.385444 10174 sgd_solver.cpp:106] Iteration 104250, lr = 0.0015
I0521 22:46:34.519528 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_105000.caffemodel
I0521 22:46:34.570648 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_105000.solverstate
I0521 22:46:34.597342 10174 solver.cpp:341] Iteration 105000, Testing net (#0)
I0521 22:47:26.294606 10174 solver.cpp:409]     Test net output #0: accuracy = 0.881749
I0521 22:47:26.294773 10174 solver.cpp:409]     Test net output #1: loss = 0.382275 (* 1 = 0.382275 loss)
I0521 22:47:47.123636 10174 solver.cpp:237] Iteration 105000, loss = 0.997247
I0521 22:47:47.123692 10174 solver.cpp:253]     Train net output #0: loss = 0.997249 (* 1 = 0.997249 loss)
I0521 22:47:47.123708 10174 sgd_solver.cpp:106] Iteration 105000, lr = 0.0015
I0521 22:47:59.310431 10174 solver.cpp:237] Iteration 105750, loss = 1.05578
I0521 22:47:59.310601 10174 solver.cpp:253]     Train net output #0: loss = 1.05578 (* 1 = 1.05578 loss)
I0521 22:47:59.310616 10174 sgd_solver.cpp:106] Iteration 105750, lr = 0.0015
I0521 22:48:11.481195 10174 solver.cpp:237] Iteration 106500, loss = 1.15067
I0521 22:48:11.481231 10174 solver.cpp:253]     Train net output #0: loss = 1.15067 (* 1 = 1.15067 loss)
I0521 22:48:11.481250 10174 sgd_solver.cpp:106] Iteration 106500, lr = 0.0015
I0521 22:48:23.623256 10174 solver.cpp:237] Iteration 107250, loss = 0.967406
I0521 22:48:23.623306 10174 solver.cpp:253]     Train net output #0: loss = 0.967408 (* 1 = 0.967408 loss)
I0521 22:48:23.623319 10174 sgd_solver.cpp:106] Iteration 107250, lr = 0.0015
I0521 22:48:35.745612 10174 solver.cpp:237] Iteration 108000, loss = 0.985149
I0521 22:48:35.745782 10174 solver.cpp:253]     Train net output #0: loss = 0.985151 (* 1 = 0.985151 loss)
I0521 22:48:35.745796 10174 sgd_solver.cpp:106] Iteration 108000, lr = 0.0015
I0521 22:48:47.937816 10174 solver.cpp:237] Iteration 108750, loss = 1.25209
I0521 22:48:47.937862 10174 solver.cpp:253]     Train net output #0: loss = 1.25209 (* 1 = 1.25209 loss)
I0521 22:48:47.937877 10174 sgd_solver.cpp:106] Iteration 108750, lr = 0.0015
I0521 22:49:00.131594 10174 solver.cpp:237] Iteration 109500, loss = 1.33039
I0521 22:49:00.131630 10174 solver.cpp:253]     Train net output #0: loss = 1.33039 (* 1 = 1.33039 loss)
I0521 22:49:00.131647 10174 sgd_solver.cpp:106] Iteration 109500, lr = 0.0015
I0521 22:49:33.172631 10174 solver.cpp:237] Iteration 110250, loss = 1.22828
I0521 22:49:33.172806 10174 solver.cpp:253]     Train net output #0: loss = 1.22828 (* 1 = 1.22828 loss)
I0521 22:49:33.172822 10174 sgd_solver.cpp:106] Iteration 110250, lr = 0.0015
I0521 22:49:45.359189 10174 solver.cpp:237] Iteration 111000, loss = 1.28993
I0521 22:49:45.359236 10174 solver.cpp:253]     Train net output #0: loss = 1.28994 (* 1 = 1.28994 loss)
I0521 22:49:45.359251 10174 sgd_solver.cpp:106] Iteration 111000, lr = 0.0015
I0521 22:49:57.528141 10174 solver.cpp:237] Iteration 111750, loss = 1.18792
I0521 22:49:57.528175 10174 solver.cpp:253]     Train net output #0: loss = 1.18792 (* 1 = 1.18792 loss)
I0521 22:49:57.528193 10174 sgd_solver.cpp:106] Iteration 111750, lr = 0.0015
I0521 22:50:09.690207 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_112500.caffemodel
I0521 22:50:09.741156 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_112500.solverstate
I0521 22:50:09.773077 10174 solver.cpp:237] Iteration 112500, loss = 1.86062
I0521 22:50:09.773126 10174 solver.cpp:253]     Train net output #0: loss = 1.86062 (* 1 = 1.86062 loss)
I0521 22:50:09.773140 10174 sgd_solver.cpp:106] Iteration 112500, lr = 0.0015
I0521 22:50:21.957103 10174 solver.cpp:237] Iteration 113250, loss = 1.5491
I0521 22:50:21.957139 10174 solver.cpp:253]     Train net output #0: loss = 1.5491 (* 1 = 1.5491 loss)
I0521 22:50:21.957156 10174 sgd_solver.cpp:106] Iteration 113250, lr = 0.0015
I0521 22:50:34.140382 10174 solver.cpp:237] Iteration 114000, loss = 1.62401
I0521 22:50:34.140429 10174 solver.cpp:253]     Train net output #0: loss = 1.62402 (* 1 = 1.62402 loss)
I0521 22:50:34.140445 10174 sgd_solver.cpp:106] Iteration 114000, lr = 0.0015
I0521 22:50:46.326315 10174 solver.cpp:237] Iteration 114750, loss = 1.06749
I0521 22:50:46.326467 10174 solver.cpp:253]     Train net output #0: loss = 1.06749 (* 1 = 1.06749 loss)
I0521 22:50:46.326481 10174 sgd_solver.cpp:106] Iteration 114750, lr = 0.0015
I0521 22:51:19.407675 10174 solver.cpp:237] Iteration 115500, loss = 1.28814
I0521 22:51:19.407845 10174 solver.cpp:253]     Train net output #0: loss = 1.28814 (* 1 = 1.28814 loss)
I0521 22:51:19.407860 10174 sgd_solver.cpp:106] Iteration 115500, lr = 0.0015
I0521 22:51:31.584116 10174 solver.cpp:237] Iteration 116250, loss = 1.02926
I0521 22:51:31.584152 10174 solver.cpp:253]     Train net output #0: loss = 1.02926 (* 1 = 1.02926 loss)
I0521 22:51:31.584168 10174 sgd_solver.cpp:106] Iteration 116250, lr = 0.0015
I0521 22:51:43.742059 10174 solver.cpp:237] Iteration 117000, loss = 1.23518
I0521 22:51:43.742106 10174 solver.cpp:253]     Train net output #0: loss = 1.23518 (* 1 = 1.23518 loss)
I0521 22:51:43.742121 10174 sgd_solver.cpp:106] Iteration 117000, lr = 0.0015
I0521 22:51:55.888700 10174 solver.cpp:237] Iteration 117750, loss = 1.21792
I0521 22:51:55.888851 10174 solver.cpp:253]     Train net output #0: loss = 1.21792 (* 1 = 1.21792 loss)
I0521 22:51:55.888865 10174 sgd_solver.cpp:106] Iteration 117750, lr = 0.0015
I0521 22:52:08.044018 10174 solver.cpp:237] Iteration 118500, loss = 1.01154
I0521 22:52:08.044064 10174 solver.cpp:253]     Train net output #0: loss = 1.01154 (* 1 = 1.01154 loss)
I0521 22:52:08.044081 10174 sgd_solver.cpp:106] Iteration 118500, lr = 0.0015
I0521 22:52:20.195358 10174 solver.cpp:237] Iteration 119250, loss = 1.03154
I0521 22:52:20.195394 10174 solver.cpp:253]     Train net output #0: loss = 1.03154 (* 1 = 1.03154 loss)
I0521 22:52:20.195410 10174 sgd_solver.cpp:106] Iteration 119250, lr = 0.0015
I0521 22:52:32.251981 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_120000.caffemodel
I0521 22:52:32.300638 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_120000.solverstate
I0521 22:52:32.325343 10174 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 22:53:45.206080 10174 solver.cpp:409]     Test net output #0: accuracy = 0.882963
I0521 22:53:45.206249 10174 solver.cpp:409]     Test net output #1: loss = 0.367469 (* 1 = 0.367469 loss)
I0521 22:54:06.083592 10174 solver.cpp:237] Iteration 120000, loss = 0.751757
I0521 22:54:06.083645 10174 solver.cpp:253]     Train net output #0: loss = 0.751758 (* 1 = 0.751758 loss)
I0521 22:54:06.083660 10174 sgd_solver.cpp:106] Iteration 120000, lr = 0.0015
I0521 22:54:18.242643 10174 solver.cpp:237] Iteration 120750, loss = 0.9164
I0521 22:54:18.242812 10174 solver.cpp:253]     Train net output #0: loss = 0.916401 (* 1 = 0.916401 loss)
I0521 22:54:18.242827 10174 sgd_solver.cpp:106] Iteration 120750, lr = 0.0015
I0521 22:54:30.447036 10174 solver.cpp:237] Iteration 121500, loss = 1.38869
I0521 22:54:30.447072 10174 solver.cpp:253]     Train net output #0: loss = 1.38869 (* 1 = 1.38869 loss)
I0521 22:54:30.447084 10174 sgd_solver.cpp:106] Iteration 121500, lr = 0.0015
I0521 22:54:42.628305 10174 solver.cpp:237] Iteration 122250, loss = 1.41314
I0521 22:54:42.628347 10174 solver.cpp:253]     Train net output #0: loss = 1.41314 (* 1 = 1.41314 loss)
I0521 22:54:42.628363 10174 sgd_solver.cpp:106] Iteration 122250, lr = 0.0015
I0521 22:54:54.751288 10174 solver.cpp:237] Iteration 123000, loss = 1.03584
I0521 22:54:54.751441 10174 solver.cpp:253]     Train net output #0: loss = 1.03584 (* 1 = 1.03584 loss)
I0521 22:54:54.751454 10174 sgd_solver.cpp:106] Iteration 123000, lr = 0.0015
I0521 22:55:06.871155 10174 solver.cpp:237] Iteration 123750, loss = 1.10314
I0521 22:55:06.871203 10174 solver.cpp:253]     Train net output #0: loss = 1.10314 (* 1 = 1.10314 loss)
I0521 22:55:06.871217 10174 sgd_solver.cpp:106] Iteration 123750, lr = 0.0015
I0521 22:55:18.958406 10174 solver.cpp:237] Iteration 124500, loss = 0.770084
I0521 22:55:18.958442 10174 solver.cpp:253]     Train net output #0: loss = 0.770085 (* 1 = 0.770085 loss)
I0521 22:55:18.958456 10174 sgd_solver.cpp:106] Iteration 124500, lr = 0.0015
I0521 22:55:51.935101 10174 solver.cpp:237] Iteration 125250, loss = 1.06216
I0521 22:55:51.935274 10174 solver.cpp:253]     Train net output #0: loss = 1.06216 (* 1 = 1.06216 loss)
I0521 22:55:51.935289 10174 sgd_solver.cpp:106] Iteration 125250, lr = 0.0015
I0521 22:56:04.025677 10174 solver.cpp:237] Iteration 126000, loss = 0.97569
I0521 22:56:04.025715 10174 solver.cpp:253]     Train net output #0: loss = 0.975691 (* 1 = 0.975691 loss)
I0521 22:56:04.025730 10174 sgd_solver.cpp:106] Iteration 126000, lr = 0.0015
I0521 22:56:16.129041 10174 solver.cpp:237] Iteration 126750, loss = 1.09123
I0521 22:56:16.129091 10174 solver.cpp:253]     Train net output #0: loss = 1.09124 (* 1 = 1.09124 loss)
I0521 22:56:16.129107 10174 sgd_solver.cpp:106] Iteration 126750, lr = 0.0015
I0521 22:56:28.276410 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_127500.caffemodel
I0521 22:56:28.325340 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_127500.solverstate
I0521 22:56:28.355890 10174 solver.cpp:237] Iteration 127500, loss = 1.45157
I0521 22:56:28.355936 10174 solver.cpp:253]     Train net output #0: loss = 1.45157 (* 1 = 1.45157 loss)
I0521 22:56:28.355952 10174 sgd_solver.cpp:106] Iteration 127500, lr = 0.0015
I0521 22:56:40.553519 10174 solver.cpp:237] Iteration 128250, loss = 0.975891
I0521 22:56:40.553566 10174 solver.cpp:253]     Train net output #0: loss = 0.975892 (* 1 = 0.975892 loss)
I0521 22:56:40.553582 10174 sgd_solver.cpp:106] Iteration 128250, lr = 0.0015
I0521 22:56:52.672523 10174 solver.cpp:237] Iteration 129000, loss = 1.21865
I0521 22:56:52.672559 10174 solver.cpp:253]     Train net output #0: loss = 1.21865 (* 1 = 1.21865 loss)
I0521 22:56:52.672575 10174 sgd_solver.cpp:106] Iteration 129000, lr = 0.0015
I0521 22:57:04.800443 10174 solver.cpp:237] Iteration 129750, loss = 1.00743
I0521 22:57:04.800611 10174 solver.cpp:253]     Train net output #0: loss = 1.00743 (* 1 = 1.00743 loss)
I0521 22:57:04.800624 10174 sgd_solver.cpp:106] Iteration 129750, lr = 0.0015
I0521 22:57:37.820647 10174 solver.cpp:237] Iteration 130500, loss = 1.25602
I0521 22:57:37.820822 10174 solver.cpp:253]     Train net output #0: loss = 1.25602 (* 1 = 1.25602 loss)
I0521 22:57:37.820838 10174 sgd_solver.cpp:106] Iteration 130500, lr = 0.0015
I0521 22:57:49.952601 10174 solver.cpp:237] Iteration 131250, loss = 1.25584
I0521 22:57:49.952637 10174 solver.cpp:253]     Train net output #0: loss = 1.25585 (* 1 = 1.25585 loss)
I0521 22:57:49.952653 10174 sgd_solver.cpp:106] Iteration 131250, lr = 0.0015
I0521 22:58:02.095695 10174 solver.cpp:237] Iteration 132000, loss = 1.69076
I0521 22:58:02.095739 10174 solver.cpp:253]     Train net output #0: loss = 1.69076 (* 1 = 1.69076 loss)
I0521 22:58:02.095752 10174 sgd_solver.cpp:106] Iteration 132000, lr = 0.0015
I0521 22:58:14.225217 10174 solver.cpp:237] Iteration 132750, loss = 1.0817
I0521 22:58:14.225371 10174 solver.cpp:253]     Train net output #0: loss = 1.0817 (* 1 = 1.0817 loss)
I0521 22:58:14.225388 10174 sgd_solver.cpp:106] Iteration 132750, lr = 0.0015
I0521 22:58:26.356094 10174 solver.cpp:237] Iteration 133500, loss = 0.763358
I0521 22:58:26.356144 10174 solver.cpp:253]     Train net output #0: loss = 0.763359 (* 1 = 0.763359 loss)
I0521 22:58:26.356158 10174 sgd_solver.cpp:106] Iteration 133500, lr = 0.0015
I0521 22:58:38.482362 10174 solver.cpp:237] Iteration 134250, loss = 1.44802
I0521 22:58:38.482398 10174 solver.cpp:253]     Train net output #0: loss = 1.44802 (* 1 = 1.44802 loss)
I0521 22:58:38.482414 10174 sgd_solver.cpp:106] Iteration 134250, lr = 0.0015
I0521 22:58:50.606215 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_135000.caffemodel
I0521 22:58:50.655299 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_135000.solverstate
I0521 22:58:50.680368 10174 solver.cpp:341] Iteration 135000, Testing net (#0)
I0521 22:59:42.625102 10174 solver.cpp:409]     Test net output #0: accuracy = 0.887896
I0521 22:59:42.625272 10174 solver.cpp:409]     Test net output #1: loss = 0.363055 (* 1 = 0.363055 loss)
I0521 23:00:03.528300 10174 solver.cpp:237] Iteration 135000, loss = 0.799413
I0521 23:00:03.528353 10174 solver.cpp:253]     Train net output #0: loss = 0.799414 (* 1 = 0.799414 loss)
I0521 23:00:03.528368 10174 sgd_solver.cpp:106] Iteration 135000, lr = 0.0015
I0521 23:00:15.687978 10174 solver.cpp:237] Iteration 135750, loss = 1.15165
I0521 23:00:15.688138 10174 solver.cpp:253]     Train net output #0: loss = 1.15165 (* 1 = 1.15165 loss)
I0521 23:00:15.688150 10174 sgd_solver.cpp:106] Iteration 135750, lr = 0.0015
I0521 23:00:27.861086 10174 solver.cpp:237] Iteration 136500, loss = 0.837422
I0521 23:00:27.861130 10174 solver.cpp:253]     Train net output #0: loss = 0.837422 (* 1 = 0.837422 loss)
I0521 23:00:27.861145 10174 sgd_solver.cpp:106] Iteration 136500, lr = 0.0015
I0521 23:00:40.008117 10174 solver.cpp:237] Iteration 137250, loss = 1.23788
I0521 23:00:40.008154 10174 solver.cpp:253]     Train net output #0: loss = 1.23788 (* 1 = 1.23788 loss)
I0521 23:00:40.008172 10174 sgd_solver.cpp:106] Iteration 137250, lr = 0.0015
I0521 23:00:52.153939 10174 solver.cpp:237] Iteration 138000, loss = 1.36737
I0521 23:00:52.154114 10174 solver.cpp:253]     Train net output #0: loss = 1.36737 (* 1 = 1.36737 loss)
I0521 23:00:52.154129 10174 sgd_solver.cpp:106] Iteration 138000, lr = 0.0015
I0521 23:01:04.290900 10174 solver.cpp:237] Iteration 138750, loss = 1.04155
I0521 23:01:04.290936 10174 solver.cpp:253]     Train net output #0: loss = 1.04155 (* 1 = 1.04155 loss)
I0521 23:01:04.290952 10174 sgd_solver.cpp:106] Iteration 138750, lr = 0.0015
I0521 23:01:16.442360 10174 solver.cpp:237] Iteration 139500, loss = 1.117
I0521 23:01:16.442407 10174 solver.cpp:253]     Train net output #0: loss = 1.117 (* 1 = 1.117 loss)
I0521 23:01:16.442425 10174 sgd_solver.cpp:106] Iteration 139500, lr = 0.0015
I0521 23:01:49.419888 10174 solver.cpp:237] Iteration 140250, loss = 1.28425
I0521 23:01:49.420066 10174 solver.cpp:253]     Train net output #0: loss = 1.28425 (* 1 = 1.28425 loss)
I0521 23:01:49.420081 10174 sgd_solver.cpp:106] Iteration 140250, lr = 0.0015
I0521 23:02:01.544989 10174 solver.cpp:237] Iteration 141000, loss = 1.71238
I0521 23:02:01.545027 10174 solver.cpp:253]     Train net output #0: loss = 1.71238 (* 1 = 1.71238 loss)
I0521 23:02:01.545043 10174 sgd_solver.cpp:106] Iteration 141000, lr = 0.0015
I0521 23:02:13.653514 10174 solver.cpp:237] Iteration 141750, loss = 1.33446
I0521 23:02:13.653559 10174 solver.cpp:253]     Train net output #0: loss = 1.33446 (* 1 = 1.33446 loss)
I0521 23:02:13.653573 10174 sgd_solver.cpp:106] Iteration 141750, lr = 0.0015
I0521 23:02:25.796506 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_142500.caffemodel
I0521 23:02:25.848434 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_142500.solverstate
I0521 23:02:25.880691 10174 solver.cpp:237] Iteration 142500, loss = 1.73515
I0521 23:02:25.880735 10174 solver.cpp:253]     Train net output #0: loss = 1.73515 (* 1 = 1.73515 loss)
I0521 23:02:25.880756 10174 sgd_solver.cpp:106] Iteration 142500, lr = 0.0015
I0521 23:02:38.032546 10174 solver.cpp:237] Iteration 143250, loss = 0.754238
I0521 23:02:38.032591 10174 solver.cpp:253]     Train net output #0: loss = 0.754239 (* 1 = 0.754239 loss)
I0521 23:02:38.032605 10174 sgd_solver.cpp:106] Iteration 143250, lr = 0.0015
I0521 23:02:50.181465 10174 solver.cpp:237] Iteration 144000, loss = 2.48089
I0521 23:02:50.181501 10174 solver.cpp:253]     Train net output #0: loss = 2.4809 (* 1 = 2.4809 loss)
I0521 23:02:50.181519 10174 sgd_solver.cpp:106] Iteration 144000, lr = 0.0015
I0521 23:03:02.339480 10174 solver.cpp:237] Iteration 144750, loss = 1.39288
I0521 23:03:02.339650 10174 solver.cpp:253]     Train net output #0: loss = 1.39288 (* 1 = 1.39288 loss)
I0521 23:03:02.339679 10174 sgd_solver.cpp:106] Iteration 144750, lr = 0.0015
I0521 23:03:35.372581 10174 solver.cpp:237] Iteration 145500, loss = 1.15242
I0521 23:03:35.372759 10174 solver.cpp:253]     Train net output #0: loss = 1.15242 (* 1 = 1.15242 loss)
I0521 23:03:35.372776 10174 sgd_solver.cpp:106] Iteration 145500, lr = 0.0015
I0521 23:03:47.521184 10174 solver.cpp:237] Iteration 146250, loss = 1.37279
I0521 23:03:47.521232 10174 solver.cpp:253]     Train net output #0: loss = 1.37279 (* 1 = 1.37279 loss)
I0521 23:03:47.521245 10174 sgd_solver.cpp:106] Iteration 146250, lr = 0.0015
I0521 23:03:59.676489 10174 solver.cpp:237] Iteration 147000, loss = 1.05047
I0521 23:03:59.676527 10174 solver.cpp:253]     Train net output #0: loss = 1.05047 (* 1 = 1.05047 loss)
I0521 23:03:59.676542 10174 sgd_solver.cpp:106] Iteration 147000, lr = 0.0015
I0521 23:04:11.836550 10174 solver.cpp:237] Iteration 147750, loss = 1.36614
I0521 23:04:11.836730 10174 solver.cpp:253]     Train net output #0: loss = 1.36614 (* 1 = 1.36614 loss)
I0521 23:04:11.836745 10174 sgd_solver.cpp:106] Iteration 147750, lr = 0.0015
I0521 23:04:23.993824 10174 solver.cpp:237] Iteration 148500, loss = 1.65857
I0521 23:04:23.993856 10174 solver.cpp:253]     Train net output #0: loss = 1.65858 (* 1 = 1.65858 loss)
I0521 23:04:23.993870 10174 sgd_solver.cpp:106] Iteration 148500, lr = 0.0015
I0521 23:04:36.163857 10174 solver.cpp:237] Iteration 149250, loss = 2.06676
I0521 23:04:36.163903 10174 solver.cpp:253]     Train net output #0: loss = 2.06676 (* 1 = 2.06676 loss)
I0521 23:04:36.163921 10174 sgd_solver.cpp:106] Iteration 149250, lr = 0.0015
I0521 23:04:48.326308 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_150000.caffemodel
I0521 23:04:48.378048 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_150000.solverstate
I0521 23:04:48.405076 10174 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 23:06:01.235110 10174 solver.cpp:409]     Test net output #0: accuracy = 0.893125
I0521 23:06:01.235286 10174 solver.cpp:409]     Test net output #1: loss = 0.345555 (* 1 = 0.345555 loss)
I0521 23:06:22.141855 10174 solver.cpp:237] Iteration 150000, loss = 1.3516
I0521 23:06:22.141907 10174 solver.cpp:253]     Train net output #0: loss = 1.3516 (* 1 = 1.3516 loss)
I0521 23:06:22.141921 10174 sgd_solver.cpp:106] Iteration 150000, lr = 0.0015
I0521 23:06:34.334295 10174 solver.cpp:237] Iteration 150750, loss = 1.11377
I0521 23:06:34.334455 10174 solver.cpp:253]     Train net output #0: loss = 1.11377 (* 1 = 1.11377 loss)
I0521 23:06:34.334467 10174 sgd_solver.cpp:106] Iteration 150750, lr = 0.0015
I0521 23:06:46.541618 10174 solver.cpp:237] Iteration 151500, loss = 1.51768
I0521 23:06:46.541667 10174 solver.cpp:253]     Train net output #0: loss = 1.51768 (* 1 = 1.51768 loss)
I0521 23:06:46.541682 10174 sgd_solver.cpp:106] Iteration 151500, lr = 0.0015
I0521 23:06:58.758744 10174 solver.cpp:237] Iteration 152250, loss = 1.34485
I0521 23:06:58.758780 10174 solver.cpp:253]     Train net output #0: loss = 1.34486 (* 1 = 1.34486 loss)
I0521 23:06:58.758796 10174 sgd_solver.cpp:106] Iteration 152250, lr = 0.0015
I0521 23:07:10.991466 10174 solver.cpp:237] Iteration 153000, loss = 1.27375
I0521 23:07:10.991632 10174 solver.cpp:253]     Train net output #0: loss = 1.27375 (* 1 = 1.27375 loss)
I0521 23:07:10.991648 10174 sgd_solver.cpp:106] Iteration 153000, lr = 0.0015
I0521 23:07:23.194751 10174 solver.cpp:237] Iteration 153750, loss = 1.21071
I0521 23:07:23.194787 10174 solver.cpp:253]     Train net output #0: loss = 1.21071 (* 1 = 1.21071 loss)
I0521 23:07:23.194803 10174 sgd_solver.cpp:106] Iteration 153750, lr = 0.0015
I0521 23:07:35.350798 10174 solver.cpp:237] Iteration 154500, loss = 1.63103
I0521 23:07:35.350841 10174 solver.cpp:253]     Train net output #0: loss = 1.63103 (* 1 = 1.63103 loss)
I0521 23:07:35.350857 10174 sgd_solver.cpp:106] Iteration 154500, lr = 0.0015
I0521 23:08:08.376320 10174 solver.cpp:237] Iteration 155250, loss = 1.37993
I0521 23:08:08.376495 10174 solver.cpp:253]     Train net output #0: loss = 1.37993 (* 1 = 1.37993 loss)
I0521 23:08:08.376512 10174 sgd_solver.cpp:106] Iteration 155250, lr = 0.0015
I0521 23:08:20.576901 10174 solver.cpp:237] Iteration 156000, loss = 1.33732
I0521 23:08:20.576941 10174 solver.cpp:253]     Train net output #0: loss = 1.33732 (* 1 = 1.33732 loss)
I0521 23:08:20.576958 10174 sgd_solver.cpp:106] Iteration 156000, lr = 0.0015
I0521 23:08:32.770184 10174 solver.cpp:237] Iteration 156750, loss = 2.12114
I0521 23:08:32.770220 10174 solver.cpp:253]     Train net output #0: loss = 2.12114 (* 1 = 2.12114 loss)
I0521 23:08:32.770238 10174 sgd_solver.cpp:106] Iteration 156750, lr = 0.0015
I0521 23:08:44.915168 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_157500.caffemodel
I0521 23:08:44.964279 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_157500.solverstate
I0521 23:08:44.995141 10174 solver.cpp:237] Iteration 157500, loss = 0.847178
I0521 23:08:44.995188 10174 solver.cpp:253]     Train net output #0: loss = 0.84718 (* 1 = 0.84718 loss)
I0521 23:08:44.995203 10174 sgd_solver.cpp:106] Iteration 157500, lr = 0.0015
I0521 23:08:57.144649 10174 solver.cpp:237] Iteration 158250, loss = 1.13892
I0521 23:08:57.144685 10174 solver.cpp:253]     Train net output #0: loss = 1.13892 (* 1 = 1.13892 loss)
I0521 23:08:57.144701 10174 sgd_solver.cpp:106] Iteration 158250, lr = 0.0015
I0521 23:09:09.332180 10174 solver.cpp:237] Iteration 159000, loss = 1.20335
I0521 23:09:09.332223 10174 solver.cpp:253]     Train net output #0: loss = 1.20335 (* 1 = 1.20335 loss)
I0521 23:09:09.332242 10174 sgd_solver.cpp:106] Iteration 159000, lr = 0.0015
I0521 23:09:21.577503 10174 solver.cpp:237] Iteration 159750, loss = 1.2781
I0521 23:09:21.577667 10174 solver.cpp:253]     Train net output #0: loss = 1.2781 (* 1 = 1.2781 loss)
I0521 23:09:21.577682 10174 sgd_solver.cpp:106] Iteration 159750, lr = 0.0015
I0521 23:09:54.666684 10174 solver.cpp:237] Iteration 160500, loss = 0.746576
I0521 23:09:54.666878 10174 solver.cpp:253]     Train net output #0: loss = 0.746578 (* 1 = 0.746578 loss)
I0521 23:09:54.666895 10174 sgd_solver.cpp:106] Iteration 160500, lr = 0.0015
I0521 23:10:06.862506 10174 solver.cpp:237] Iteration 161250, loss = 0.789697
I0521 23:10:06.862551 10174 solver.cpp:253]     Train net output #0: loss = 0.789698 (* 1 = 0.789698 loss)
I0521 23:10:06.862565 10174 sgd_solver.cpp:106] Iteration 161250, lr = 0.0015
I0521 23:10:19.100579 10174 solver.cpp:237] Iteration 162000, loss = 1.2819
I0521 23:10:19.100615 10174 solver.cpp:253]     Train net output #0: loss = 1.28191 (* 1 = 1.28191 loss)
I0521 23:10:19.100628 10174 sgd_solver.cpp:106] Iteration 162000, lr = 0.0015
I0521 23:10:31.353659 10174 solver.cpp:237] Iteration 162750, loss = 1.32265
I0521 23:10:31.353833 10174 solver.cpp:253]     Train net output #0: loss = 1.32265 (* 1 = 1.32265 loss)
I0521 23:10:31.353849 10174 sgd_solver.cpp:106] Iteration 162750, lr = 0.0015
I0521 23:10:43.535923 10174 solver.cpp:237] Iteration 163500, loss = 1.47841
I0521 23:10:43.535959 10174 solver.cpp:253]     Train net output #0: loss = 1.47841 (* 1 = 1.47841 loss)
I0521 23:10:43.535974 10174 sgd_solver.cpp:106] Iteration 163500, lr = 0.0015
I0521 23:10:55.747889 10174 solver.cpp:237] Iteration 164250, loss = 1.34239
I0521 23:10:55.747934 10174 solver.cpp:253]     Train net output #0: loss = 1.3424 (* 1 = 1.3424 loss)
I0521 23:10:55.747949 10174 sgd_solver.cpp:106] Iteration 164250, lr = 0.0015
I0521 23:11:07.939191 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_165000.caffemodel
I0521 23:11:07.988320 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_165000.solverstate
I0521 23:11:08.013624 10174 solver.cpp:341] Iteration 165000, Testing net (#0)
I0521 23:11:59.543429 10174 solver.cpp:409]     Test net output #0: accuracy = 0.88743
I0521 23:11:59.543601 10174 solver.cpp:409]     Test net output #1: loss = 0.347726 (* 1 = 0.347726 loss)
I0521 23:12:20.438381 10174 solver.cpp:237] Iteration 165000, loss = 0.699878
I0521 23:12:20.438436 10174 solver.cpp:253]     Train net output #0: loss = 0.699879 (* 1 = 0.699879 loss)
I0521 23:12:20.438452 10174 sgd_solver.cpp:106] Iteration 165000, lr = 0.0015
I0521 23:12:32.586557 10174 solver.cpp:237] Iteration 165750, loss = 1.01412
I0521 23:12:32.586738 10174 solver.cpp:253]     Train net output #0: loss = 1.01412 (* 1 = 1.01412 loss)
I0521 23:12:32.586752 10174 sgd_solver.cpp:106] Iteration 165750, lr = 0.0015
I0521 23:12:44.769901 10174 solver.cpp:237] Iteration 166500, loss = 1.07068
I0521 23:12:44.769937 10174 solver.cpp:253]     Train net output #0: loss = 1.07069 (* 1 = 1.07069 loss)
I0521 23:12:44.769953 10174 sgd_solver.cpp:106] Iteration 166500, lr = 0.0015
I0521 23:12:56.879046 10174 solver.cpp:237] Iteration 167250, loss = 1.20103
I0521 23:12:56.879089 10174 solver.cpp:253]     Train net output #0: loss = 1.20103 (* 1 = 1.20103 loss)
I0521 23:12:56.879106 10174 sgd_solver.cpp:106] Iteration 167250, lr = 0.0015
I0521 23:13:08.989364 10174 solver.cpp:237] Iteration 168000, loss = 1.11018
I0521 23:13:08.989528 10174 solver.cpp:253]     Train net output #0: loss = 1.11018 (* 1 = 1.11018 loss)
I0521 23:13:08.989543 10174 sgd_solver.cpp:106] Iteration 168000, lr = 0.0015
I0521 23:13:21.125027 10174 solver.cpp:237] Iteration 168750, loss = 0.964819
I0521 23:13:21.125069 10174 solver.cpp:253]     Train net output #0: loss = 0.96482 (* 1 = 0.96482 loss)
I0521 23:13:21.125090 10174 sgd_solver.cpp:106] Iteration 168750, lr = 0.0015
I0521 23:13:33.252148 10174 solver.cpp:237] Iteration 169500, loss = 1.15903
I0521 23:13:33.252183 10174 solver.cpp:253]     Train net output #0: loss = 1.15903 (* 1 = 1.15903 loss)
I0521 23:13:33.252199 10174 sgd_solver.cpp:106] Iteration 169500, lr = 0.0015
I0521 23:14:06.233546 10174 solver.cpp:237] Iteration 170250, loss = 0.945399
I0521 23:14:06.233726 10174 solver.cpp:253]     Train net output #0: loss = 0.9454 (* 1 = 0.9454 loss)
I0521 23:14:06.233742 10174 sgd_solver.cpp:106] Iteration 170250, lr = 0.0015
I0521 23:14:18.362853 10174 solver.cpp:237] Iteration 171000, loss = 0.930578
I0521 23:14:18.362900 10174 solver.cpp:253]     Train net output #0: loss = 0.930579 (* 1 = 0.930579 loss)
I0521 23:14:18.362915 10174 sgd_solver.cpp:106] Iteration 171000, lr = 0.0015
I0521 23:14:30.517657 10174 solver.cpp:237] Iteration 171750, loss = 1.66247
I0521 23:14:30.517693 10174 solver.cpp:253]     Train net output #0: loss = 1.66248 (* 1 = 1.66248 loss)
I0521 23:14:30.517710 10174 sgd_solver.cpp:106] Iteration 171750, lr = 0.0015
I0521 23:14:42.634335 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_172500.caffemodel
I0521 23:14:42.682824 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_172500.solverstate
I0521 23:14:42.713001 10174 solver.cpp:237] Iteration 172500, loss = 1.50111
I0521 23:14:42.713042 10174 solver.cpp:253]     Train net output #0: loss = 1.50111 (* 1 = 1.50111 loss)
I0521 23:14:42.713063 10174 sgd_solver.cpp:106] Iteration 172500, lr = 0.0015
I0521 23:14:54.857292 10174 solver.cpp:237] Iteration 173250, loss = 1.05717
I0521 23:14:54.857328 10174 solver.cpp:253]     Train net output #0: loss = 1.05717 (* 1 = 1.05717 loss)
I0521 23:14:54.857343 10174 sgd_solver.cpp:106] Iteration 173250, lr = 0.0015
I0521 23:15:06.994040 10174 solver.cpp:237] Iteration 174000, loss = 1.253
I0521 23:15:06.994088 10174 solver.cpp:253]     Train net output #0: loss = 1.253 (* 1 = 1.253 loss)
I0521 23:15:06.994103 10174 sgd_solver.cpp:106] Iteration 174000, lr = 0.0015
I0521 23:15:19.112920 10174 solver.cpp:237] Iteration 174750, loss = 1.49031
I0521 23:15:19.113080 10174 solver.cpp:253]     Train net output #0: loss = 1.49031 (* 1 = 1.49031 loss)
I0521 23:15:19.113093 10174 sgd_solver.cpp:106] Iteration 174750, lr = 0.0015
I0521 23:15:52.092473 10174 solver.cpp:237] Iteration 175500, loss = 1.25568
I0521 23:15:52.092661 10174 solver.cpp:253]     Train net output #0: loss = 1.25568 (* 1 = 1.25568 loss)
I0521 23:15:52.092677 10174 sgd_solver.cpp:106] Iteration 175500, lr = 0.0015
I0521 23:16:04.271159 10174 solver.cpp:237] Iteration 176250, loss = 1.43911
I0521 23:16:04.271195 10174 solver.cpp:253]     Train net output #0: loss = 1.43911 (* 1 = 1.43911 loss)
I0521 23:16:04.271212 10174 sgd_solver.cpp:106] Iteration 176250, lr = 0.0015
I0521 23:16:16.441884 10174 solver.cpp:237] Iteration 177000, loss = 0.781618
I0521 23:16:16.441929 10174 solver.cpp:253]     Train net output #0: loss = 0.781618 (* 1 = 0.781618 loss)
I0521 23:16:16.441943 10174 sgd_solver.cpp:106] Iteration 177000, lr = 0.0015
I0521 23:16:28.617512 10174 solver.cpp:237] Iteration 177750, loss = 1.23892
I0521 23:16:28.617683 10174 solver.cpp:253]     Train net output #0: loss = 1.23892 (* 1 = 1.23892 loss)
I0521 23:16:28.617697 10174 sgd_solver.cpp:106] Iteration 177750, lr = 0.0015
I0521 23:16:40.784343 10174 solver.cpp:237] Iteration 178500, loss = 0.653544
I0521 23:16:40.784391 10174 solver.cpp:253]     Train net output #0: loss = 0.653545 (* 1 = 0.653545 loss)
I0521 23:16:40.784405 10174 sgd_solver.cpp:106] Iteration 178500, lr = 0.0015
I0521 23:16:52.841682 10174 solver.cpp:237] Iteration 179250, loss = 1.38356
I0521 23:16:52.841718 10174 solver.cpp:253]     Train net output #0: loss = 1.38356 (* 1 = 1.38356 loss)
I0521 23:16:52.841735 10174 sgd_solver.cpp:106] Iteration 179250, lr = 0.0015
I0521 23:17:04.901123 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_180000.caffemodel
I0521 23:17:04.953255 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_180000.solverstate
I0521 23:17:04.979768 10174 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 23:18:17.879990 10174 solver.cpp:409]     Test net output #0: accuracy = 0.889517
I0521 23:18:17.880167 10174 solver.cpp:409]     Test net output #1: loss = 0.363649 (* 1 = 0.363649 loss)
I0521 23:18:38.708303 10174 solver.cpp:237] Iteration 180000, loss = 1.10405
I0521 23:18:38.708358 10174 solver.cpp:253]     Train net output #0: loss = 1.10405 (* 1 = 1.10405 loss)
I0521 23:18:38.708372 10174 sgd_solver.cpp:106] Iteration 180000, lr = 0.0015
I0521 23:18:50.833390 10174 solver.cpp:237] Iteration 180750, loss = 1.26971
I0521 23:18:50.833564 10174 solver.cpp:253]     Train net output #0: loss = 1.26971 (* 1 = 1.26971 loss)
I0521 23:18:50.833578 10174 sgd_solver.cpp:106] Iteration 180750, lr = 0.0015
I0521 23:19:02.910842 10174 solver.cpp:237] Iteration 181500, loss = 1.29747
I0521 23:19:02.910879 10174 solver.cpp:253]     Train net output #0: loss = 1.29747 (* 1 = 1.29747 loss)
I0521 23:19:02.910895 10174 sgd_solver.cpp:106] Iteration 181500, lr = 0.0015
I0521 23:19:14.991113 10174 solver.cpp:237] Iteration 182250, loss = 1.18325
I0521 23:19:14.991161 10174 solver.cpp:253]     Train net output #0: loss = 1.18325 (* 1 = 1.18325 loss)
I0521 23:19:14.991176 10174 sgd_solver.cpp:106] Iteration 182250, lr = 0.0015
I0521 23:19:27.062700 10174 solver.cpp:237] Iteration 183000, loss = 1.5742
I0521 23:19:27.062861 10174 solver.cpp:253]     Train net output #0: loss = 1.5742 (* 1 = 1.5742 loss)
I0521 23:19:27.062875 10174 sgd_solver.cpp:106] Iteration 183000, lr = 0.0015
I0521 23:19:39.164132 10174 solver.cpp:237] Iteration 183750, loss = 0.946663
I0521 23:19:39.164180 10174 solver.cpp:253]     Train net output #0: loss = 0.946663 (* 1 = 0.946663 loss)
I0521 23:19:39.164196 10174 sgd_solver.cpp:106] Iteration 183750, lr = 0.0015
I0521 23:19:51.310930 10174 solver.cpp:237] Iteration 184500, loss = 1.5049
I0521 23:19:51.310966 10174 solver.cpp:253]     Train net output #0: loss = 1.5049 (* 1 = 1.5049 loss)
I0521 23:19:51.310982 10174 sgd_solver.cpp:106] Iteration 184500, lr = 0.0015
I0521 23:20:24.327935 10174 solver.cpp:237] Iteration 185250, loss = 1.27018
I0521 23:20:24.328121 10174 solver.cpp:253]     Train net output #0: loss = 1.27019 (* 1 = 1.27019 loss)
I0521 23:20:24.328135 10174 sgd_solver.cpp:106] Iteration 185250, lr = 0.0015
I0521 23:20:36.500998 10174 solver.cpp:237] Iteration 186000, loss = 0.950963
I0521 23:20:36.501034 10174 solver.cpp:253]     Train net output #0: loss = 0.950964 (* 1 = 0.950964 loss)
I0521 23:20:36.501050 10174 sgd_solver.cpp:106] Iteration 186000, lr = 0.0015
I0521 23:20:48.637997 10174 solver.cpp:237] Iteration 186750, loss = 1.40058
I0521 23:20:48.638033 10174 solver.cpp:253]     Train net output #0: loss = 1.40058 (* 1 = 1.40058 loss)
I0521 23:20:48.638046 10174 sgd_solver.cpp:106] Iteration 186750, lr = 0.0015
I0521 23:21:00.761307 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_187500.caffemodel
I0521 23:21:00.812392 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_187500.solverstate
I0521 23:21:00.844218 10174 solver.cpp:237] Iteration 187500, loss = 1.40776
I0521 23:21:00.844265 10174 solver.cpp:253]     Train net output #0: loss = 1.40776 (* 1 = 1.40776 loss)
I0521 23:21:00.844280 10174 sgd_solver.cpp:106] Iteration 187500, lr = 0.0015
I0521 23:21:12.933526 10174 solver.cpp:237] Iteration 188250, loss = 1.09556
I0521 23:21:12.933562 10174 solver.cpp:253]     Train net output #0: loss = 1.09556 (* 1 = 1.09556 loss)
I0521 23:21:12.933578 10174 sgd_solver.cpp:106] Iteration 188250, lr = 0.0015
I0521 23:21:25.099989 10174 solver.cpp:237] Iteration 189000, loss = 1.4672
I0521 23:21:25.100033 10174 solver.cpp:253]     Train net output #0: loss = 1.4672 (* 1 = 1.4672 loss)
I0521 23:21:25.100050 10174 sgd_solver.cpp:106] Iteration 189000, lr = 0.0015
I0521 23:21:37.278461 10174 solver.cpp:237] Iteration 189750, loss = 1.0289
I0521 23:21:37.278628 10174 solver.cpp:253]     Train net output #0: loss = 1.0289 (* 1 = 1.0289 loss)
I0521 23:21:37.278641 10174 sgd_solver.cpp:106] Iteration 189750, lr = 0.0015
I0521 23:22:10.290905 10174 solver.cpp:237] Iteration 190500, loss = 1.38953
I0521 23:22:10.291086 10174 solver.cpp:253]     Train net output #0: loss = 1.38953 (* 1 = 1.38953 loss)
I0521 23:22:10.291102 10174 sgd_solver.cpp:106] Iteration 190500, lr = 0.0015
I0521 23:22:22.430245 10174 solver.cpp:237] Iteration 191250, loss = 0.859295
I0521 23:22:22.430282 10174 solver.cpp:253]     Train net output #0: loss = 0.859296 (* 1 = 0.859296 loss)
I0521 23:22:22.430299 10174 sgd_solver.cpp:106] Iteration 191250, lr = 0.0015
I0521 23:22:34.567945 10174 solver.cpp:237] Iteration 192000, loss = 1.58001
I0521 23:22:34.567993 10174 solver.cpp:253]     Train net output #0: loss = 1.58001 (* 1 = 1.58001 loss)
I0521 23:22:34.568008 10174 sgd_solver.cpp:106] Iteration 192000, lr = 0.0015
I0521 23:22:46.707195 10174 solver.cpp:237] Iteration 192750, loss = 1.25942
I0521 23:22:46.707367 10174 solver.cpp:253]     Train net output #0: loss = 1.25942 (* 1 = 1.25942 loss)
I0521 23:22:46.707382 10174 sgd_solver.cpp:106] Iteration 192750, lr = 0.0015
I0521 23:22:58.853255 10174 solver.cpp:237] Iteration 193500, loss = 0.906964
I0521 23:22:58.853303 10174 solver.cpp:253]     Train net output #0: loss = 0.906965 (* 1 = 0.906965 loss)
I0521 23:22:58.853319 10174 sgd_solver.cpp:106] Iteration 193500, lr = 0.0015
I0521 23:23:11.004719 10174 solver.cpp:237] Iteration 194250, loss = 0.92802
I0521 23:23:11.004755 10174 solver.cpp:253]     Train net output #0: loss = 0.92802 (* 1 = 0.92802 loss)
I0521 23:23:11.004770 10174 sgd_solver.cpp:106] Iteration 194250, lr = 0.0015
I0521 23:23:23.147651 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_195000.caffemodel
I0521 23:23:23.196449 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_195000.solverstate
I0521 23:23:23.221720 10174 solver.cpp:341] Iteration 195000, Testing net (#0)
I0521 23:24:15.145798 10174 solver.cpp:409]     Test net output #0: accuracy = 0.892875
I0521 23:24:15.145979 10174 solver.cpp:409]     Test net output #1: loss = 0.345223 (* 1 = 0.345223 loss)
I0521 23:24:35.969116 10174 solver.cpp:237] Iteration 195000, loss = 1.16774
I0521 23:24:35.969168 10174 solver.cpp:253]     Train net output #0: loss = 1.16774 (* 1 = 1.16774 loss)
I0521 23:24:35.969184 10174 sgd_solver.cpp:106] Iteration 195000, lr = 0.0015
I0521 23:24:48.070148 10174 solver.cpp:237] Iteration 195750, loss = 0.988056
I0521 23:24:48.070317 10174 solver.cpp:253]     Train net output #0: loss = 0.988056 (* 1 = 0.988056 loss)
I0521 23:24:48.070332 10174 sgd_solver.cpp:106] Iteration 195750, lr = 0.0015
I0521 23:25:00.211612 10174 solver.cpp:237] Iteration 196500, loss = 2.10075
I0521 23:25:00.211659 10174 solver.cpp:253]     Train net output #0: loss = 2.10075 (* 1 = 2.10075 loss)
I0521 23:25:00.211675 10174 sgd_solver.cpp:106] Iteration 196500, lr = 0.0015
I0521 23:25:12.349342 10174 solver.cpp:237] Iteration 197250, loss = 1.62538
I0521 23:25:12.349377 10174 solver.cpp:253]     Train net output #0: loss = 1.62538 (* 1 = 1.62538 loss)
I0521 23:25:12.349395 10174 sgd_solver.cpp:106] Iteration 197250, lr = 0.0015
I0521 23:25:24.474400 10174 solver.cpp:237] Iteration 198000, loss = 0.807929
I0521 23:25:24.474575 10174 solver.cpp:253]     Train net output #0: loss = 0.807929 (* 1 = 0.807929 loss)
I0521 23:25:24.474589 10174 sgd_solver.cpp:106] Iteration 198000, lr = 0.0015
I0521 23:25:36.604666 10174 solver.cpp:237] Iteration 198750, loss = 0.812553
I0521 23:25:36.604703 10174 solver.cpp:253]     Train net output #0: loss = 0.812553 (* 1 = 0.812553 loss)
I0521 23:25:36.604719 10174 sgd_solver.cpp:106] Iteration 198750, lr = 0.0015
I0521 23:25:48.746166 10174 solver.cpp:237] Iteration 199500, loss = 1.02285
I0521 23:25:48.746202 10174 solver.cpp:253]     Train net output #0: loss = 1.02285 (* 1 = 1.02285 loss)
I0521 23:25:48.746218 10174 sgd_solver.cpp:106] Iteration 199500, lr = 0.0015
I0521 23:26:21.750772 10174 solver.cpp:237] Iteration 200250, loss = 1.18632
I0521 23:26:21.750958 10174 solver.cpp:253]     Train net output #0: loss = 1.18632 (* 1 = 1.18632 loss)
I0521 23:26:21.750973 10174 sgd_solver.cpp:106] Iteration 200250, lr = 0.0015
I0521 23:26:33.853109 10174 solver.cpp:237] Iteration 201000, loss = 0.924942
I0521 23:26:33.853147 10174 solver.cpp:253]     Train net output #0: loss = 0.924942 (* 1 = 0.924942 loss)
I0521 23:26:33.853163 10174 sgd_solver.cpp:106] Iteration 201000, lr = 0.0015
I0521 23:26:45.998446 10174 solver.cpp:237] Iteration 201750, loss = 1.3712
I0521 23:26:45.998492 10174 solver.cpp:253]     Train net output #0: loss = 1.3712 (* 1 = 1.3712 loss)
I0521 23:26:45.998505 10174 sgd_solver.cpp:106] Iteration 201750, lr = 0.0015
I0521 23:26:58.142423 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_202500.caffemodel
I0521 23:26:58.191375 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_202500.solverstate
I0521 23:26:58.220932 10174 solver.cpp:237] Iteration 202500, loss = 0.841799
I0521 23:26:58.220976 10174 solver.cpp:253]     Train net output #0: loss = 0.841799 (* 1 = 0.841799 loss)
I0521 23:26:58.220990 10174 sgd_solver.cpp:106] Iteration 202500, lr = 0.0015
I0521 23:27:10.363124 10174 solver.cpp:237] Iteration 203250, loss = 1.06104
I0521 23:27:10.363171 10174 solver.cpp:253]     Train net output #0: loss = 1.06104 (* 1 = 1.06104 loss)
I0521 23:27:10.363188 10174 sgd_solver.cpp:106] Iteration 203250, lr = 0.0015
I0521 23:27:22.525240 10174 solver.cpp:237] Iteration 204000, loss = 1.19678
I0521 23:27:22.525276 10174 solver.cpp:253]     Train net output #0: loss = 1.19678 (* 1 = 1.19678 loss)
I0521 23:27:22.525293 10174 sgd_solver.cpp:106] Iteration 204000, lr = 0.0015
I0521 23:27:34.705149 10174 solver.cpp:237] Iteration 204750, loss = 1.08648
I0521 23:27:34.705339 10174 solver.cpp:253]     Train net output #0: loss = 1.08648 (* 1 = 1.08648 loss)
I0521 23:27:34.705354 10174 sgd_solver.cpp:106] Iteration 204750, lr = 0.0015
I0521 23:28:07.759277 10174 solver.cpp:237] Iteration 205500, loss = 1.37625
I0521 23:28:07.759457 10174 solver.cpp:253]     Train net output #0: loss = 1.37625 (* 1 = 1.37625 loss)
I0521 23:28:07.759472 10174 sgd_solver.cpp:106] Iteration 205500, lr = 0.0015
I0521 23:28:19.901285 10174 solver.cpp:237] Iteration 206250, loss = 1.6804
I0521 23:28:19.901329 10174 solver.cpp:253]     Train net output #0: loss = 1.6804 (* 1 = 1.6804 loss)
I0521 23:28:19.901347 10174 sgd_solver.cpp:106] Iteration 206250, lr = 0.0015
I0521 23:28:31.984598 10174 solver.cpp:237] Iteration 207000, loss = 1.04994
I0521 23:28:31.984635 10174 solver.cpp:253]     Train net output #0: loss = 1.04994 (* 1 = 1.04994 loss)
I0521 23:28:31.984650 10174 sgd_solver.cpp:106] Iteration 207000, lr = 0.0015
I0521 23:28:44.072804 10174 solver.cpp:237] Iteration 207750, loss = 1.31725
I0521 23:28:44.072969 10174 solver.cpp:253]     Train net output #0: loss = 1.31725 (* 1 = 1.31725 loss)
I0521 23:28:44.072983 10174 sgd_solver.cpp:106] Iteration 207750, lr = 0.0015
I0521 23:28:56.146525 10174 solver.cpp:237] Iteration 208500, loss = 0.657018
I0521 23:28:56.146572 10174 solver.cpp:253]     Train net output #0: loss = 0.657018 (* 1 = 0.657018 loss)
I0521 23:28:56.146589 10174 sgd_solver.cpp:106] Iteration 208500, lr = 0.0015
I0521 23:29:08.228037 10174 solver.cpp:237] Iteration 209250, loss = 1.21601
I0521 23:29:08.228075 10174 solver.cpp:253]     Train net output #0: loss = 1.21601 (* 1 = 1.21601 loss)
I0521 23:29:08.228091 10174 sgd_solver.cpp:106] Iteration 209250, lr = 0.0015
I0521 23:29:20.300077 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_210000.caffemodel
I0521 23:29:20.349155 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_210000.solverstate
I0521 23:29:20.374567 10174 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 23:30:33.238857 10174 solver.cpp:409]     Test net output #0: accuracy = 0.893751
I0521 23:30:33.239042 10174 solver.cpp:409]     Test net output #1: loss = 0.338291 (* 1 = 0.338291 loss)
I0521 23:30:54.076650 10174 solver.cpp:237] Iteration 210000, loss = 1.97975
I0521 23:30:54.076704 10174 solver.cpp:253]     Train net output #0: loss = 1.97976 (* 1 = 1.97976 loss)
I0521 23:30:54.076719 10174 sgd_solver.cpp:106] Iteration 210000, lr = 0.0015
I0521 23:31:06.271631 10174 solver.cpp:237] Iteration 210750, loss = 0.919313
I0521 23:31:06.271801 10174 solver.cpp:253]     Train net output #0: loss = 0.919314 (* 1 = 0.919314 loss)
I0521 23:31:06.271817 10174 sgd_solver.cpp:106] Iteration 210750, lr = 0.0015
I0521 23:31:18.467033 10174 solver.cpp:237] Iteration 211500, loss = 1.16361
I0521 23:31:18.467079 10174 solver.cpp:253]     Train net output #0: loss = 1.16361 (* 1 = 1.16361 loss)
I0521 23:31:18.467095 10174 sgd_solver.cpp:106] Iteration 211500, lr = 0.0015
I0521 23:31:30.629323 10174 solver.cpp:237] Iteration 212250, loss = 1.21263
I0521 23:31:30.629360 10174 solver.cpp:253]     Train net output #0: loss = 1.21263 (* 1 = 1.21263 loss)
I0521 23:31:30.629377 10174 sgd_solver.cpp:106] Iteration 212250, lr = 0.0015
I0521 23:31:42.801878 10174 solver.cpp:237] Iteration 213000, loss = 1.08604
I0521 23:31:42.802059 10174 solver.cpp:253]     Train net output #0: loss = 1.08604 (* 1 = 1.08604 loss)
I0521 23:31:42.802076 10174 sgd_solver.cpp:106] Iteration 213000, lr = 0.0015
I0521 23:31:54.994540 10174 solver.cpp:237] Iteration 213750, loss = 1.23131
I0521 23:31:54.994576 10174 solver.cpp:253]     Train net output #0: loss = 1.23131 (* 1 = 1.23131 loss)
I0521 23:31:54.994593 10174 sgd_solver.cpp:106] Iteration 213750, lr = 0.0015
I0521 23:32:07.176544 10174 solver.cpp:237] Iteration 214500, loss = 0.99637
I0521 23:32:07.176595 10174 solver.cpp:253]     Train net output #0: loss = 0.996371 (* 1 = 0.996371 loss)
I0521 23:32:07.176609 10174 sgd_solver.cpp:106] Iteration 214500, lr = 0.0015
I0521 23:32:40.207355 10174 solver.cpp:237] Iteration 215250, loss = 1.60206
I0521 23:32:40.207559 10174 solver.cpp:253]     Train net output #0: loss = 1.60206 (* 1 = 1.60206 loss)
I0521 23:32:40.207576 10174 sgd_solver.cpp:106] Iteration 215250, lr = 0.0015
I0521 23:32:52.368839 10174 solver.cpp:237] Iteration 216000, loss = 1.12962
I0521 23:32:52.368875 10174 solver.cpp:253]     Train net output #0: loss = 1.12962 (* 1 = 1.12962 loss)
I0521 23:32:52.368891 10174 sgd_solver.cpp:106] Iteration 216000, lr = 0.0015
I0521 23:33:04.554349 10174 solver.cpp:237] Iteration 216750, loss = 0.856763
I0521 23:33:04.554395 10174 solver.cpp:253]     Train net output #0: loss = 0.856764 (* 1 = 0.856764 loss)
I0521 23:33:04.554410 10174 sgd_solver.cpp:106] Iteration 216750, lr = 0.0015
I0521 23:33:16.758962 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_217500.caffemodel
I0521 23:33:16.809634 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_217500.solverstate
I0521 23:33:16.841720 10174 solver.cpp:237] Iteration 217500, loss = 1.56701
I0521 23:33:16.841768 10174 solver.cpp:253]     Train net output #0: loss = 1.56701 (* 1 = 1.56701 loss)
I0521 23:33:16.841794 10174 sgd_solver.cpp:106] Iteration 217500, lr = 0.0015
I0521 23:33:29.059931 10174 solver.cpp:237] Iteration 218250, loss = 0.836347
I0521 23:33:29.059976 10174 solver.cpp:253]     Train net output #0: loss = 0.836348 (* 1 = 0.836348 loss)
I0521 23:33:29.059991 10174 sgd_solver.cpp:106] Iteration 218250, lr = 0.0015
I0521 23:33:41.333374 10174 solver.cpp:237] Iteration 219000, loss = 2.36491
I0521 23:33:41.333410 10174 solver.cpp:253]     Train net output #0: loss = 2.36491 (* 1 = 2.36491 loss)
I0521 23:33:41.333425 10174 sgd_solver.cpp:106] Iteration 219000, lr = 0.0015
I0521 23:33:53.508952 10174 solver.cpp:237] Iteration 219750, loss = 1.41269
I0521 23:33:53.509136 10174 solver.cpp:253]     Train net output #0: loss = 1.41269 (* 1 = 1.41269 loss)
I0521 23:33:53.509150 10174 sgd_solver.cpp:106] Iteration 219750, lr = 0.0015
I0521 23:34:26.497845 10174 solver.cpp:237] Iteration 220500, loss = 0.843838
I0521 23:34:26.498028 10174 solver.cpp:253]     Train net output #0: loss = 0.84384 (* 1 = 0.84384 loss)
I0521 23:34:26.498044 10174 sgd_solver.cpp:106] Iteration 220500, lr = 0.0015
I0521 23:34:38.630823 10174 solver.cpp:237] Iteration 221250, loss = 1.57566
I0521 23:34:38.630869 10174 solver.cpp:253]     Train net output #0: loss = 1.57566 (* 1 = 1.57566 loss)
I0521 23:34:38.630884 10174 sgd_solver.cpp:106] Iteration 221250, lr = 0.0015
I0521 23:34:50.768234 10174 solver.cpp:237] Iteration 222000, loss = 1.21154
I0521 23:34:50.768270 10174 solver.cpp:253]     Train net output #0: loss = 1.21154 (* 1 = 1.21154 loss)
I0521 23:34:50.768285 10174 sgd_solver.cpp:106] Iteration 222000, lr = 0.0015
I0521 23:35:02.913547 10174 solver.cpp:237] Iteration 222750, loss = 1.36517
I0521 23:35:02.913727 10174 solver.cpp:253]     Train net output #0: loss = 1.36518 (* 1 = 1.36518 loss)
I0521 23:35:02.913743 10174 sgd_solver.cpp:106] Iteration 222750, lr = 0.0015
I0521 23:35:15.054886 10174 solver.cpp:237] Iteration 223500, loss = 1.08561
I0521 23:35:15.054922 10174 solver.cpp:253]     Train net output #0: loss = 1.08562 (* 1 = 1.08562 loss)
I0521 23:35:15.054940 10174 sgd_solver.cpp:106] Iteration 223500, lr = 0.0015
I0521 23:35:27.204008 10174 solver.cpp:237] Iteration 224250, loss = 1.70105
I0521 23:35:27.204051 10174 solver.cpp:253]     Train net output #0: loss = 1.70105 (* 1 = 1.70105 loss)
I0521 23:35:27.204066 10174 sgd_solver.cpp:106] Iteration 224250, lr = 0.0015
I0521 23:35:39.364985 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_225000.caffemodel
I0521 23:35:39.416173 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_225000.solverstate
I0521 23:35:39.443857 10174 solver.cpp:341] Iteration 225000, Testing net (#0)
I0521 23:36:31.190531 10174 solver.cpp:409]     Test net output #0: accuracy = 0.894001
I0521 23:36:31.190714 10174 solver.cpp:409]     Test net output #1: loss = 0.339496 (* 1 = 0.339496 loss)
I0521 23:36:52.044422 10174 solver.cpp:237] Iteration 225000, loss = 1.6118
I0521 23:36:52.044473 10174 solver.cpp:253]     Train net output #0: loss = 1.6118 (* 1 = 1.6118 loss)
I0521 23:36:52.044488 10174 sgd_solver.cpp:106] Iteration 225000, lr = 0.0015
I0521 23:37:04.171133 10174 solver.cpp:237] Iteration 225750, loss = 1.15105
I0521 23:37:04.171295 10174 solver.cpp:253]     Train net output #0: loss = 1.15106 (* 1 = 1.15106 loss)
I0521 23:37:04.171309 10174 sgd_solver.cpp:106] Iteration 225750, lr = 0.0015
I0521 23:37:16.340471 10174 solver.cpp:237] Iteration 226500, loss = 1.08134
I0521 23:37:16.340507 10174 solver.cpp:253]     Train net output #0: loss = 1.08134 (* 1 = 1.08134 loss)
I0521 23:37:16.340522 10174 sgd_solver.cpp:106] Iteration 226500, lr = 0.0015
I0521 23:37:28.505986 10174 solver.cpp:237] Iteration 227250, loss = 0.910021
I0521 23:37:28.506024 10174 solver.cpp:253]     Train net output #0: loss = 0.910022 (* 1 = 0.910022 loss)
I0521 23:37:28.506039 10174 sgd_solver.cpp:106] Iteration 227250, lr = 0.0015
I0521 23:37:40.655184 10174 solver.cpp:237] Iteration 228000, loss = 1.30401
I0521 23:37:40.655364 10174 solver.cpp:253]     Train net output #0: loss = 1.30401 (* 1 = 1.30401 loss)
I0521 23:37:40.655380 10174 sgd_solver.cpp:106] Iteration 228000, lr = 0.0015
I0521 23:37:52.810951 10174 solver.cpp:237] Iteration 228750, loss = 1.27502
I0521 23:37:52.810987 10174 solver.cpp:253]     Train net output #0: loss = 1.27502 (* 1 = 1.27502 loss)
I0521 23:37:52.811003 10174 sgd_solver.cpp:106] Iteration 228750, lr = 0.0015
I0521 23:38:04.953438 10174 solver.cpp:237] Iteration 229500, loss = 1.14417
I0521 23:38:04.953487 10174 solver.cpp:253]     Train net output #0: loss = 1.14418 (* 1 = 1.14418 loss)
I0521 23:38:04.953501 10174 sgd_solver.cpp:106] Iteration 229500, lr = 0.0015
I0521 23:38:37.952443 10174 solver.cpp:237] Iteration 230250, loss = 1.27804
I0521 23:38:37.952631 10174 solver.cpp:253]     Train net output #0: loss = 1.27804 (* 1 = 1.27804 loss)
I0521 23:38:37.952646 10174 sgd_solver.cpp:106] Iteration 230250, lr = 0.0015
I0521 23:38:50.085105 10174 solver.cpp:237] Iteration 231000, loss = 1.15307
I0521 23:38:50.085150 10174 solver.cpp:253]     Train net output #0: loss = 1.15307 (* 1 = 1.15307 loss)
I0521 23:38:50.085165 10174 sgd_solver.cpp:106] Iteration 231000, lr = 0.0015
I0521 23:39:02.261242 10174 solver.cpp:237] Iteration 231750, loss = 1.43184
I0521 23:39:02.261279 10174 solver.cpp:253]     Train net output #0: loss = 1.43185 (* 1 = 1.43185 loss)
I0521 23:39:02.261296 10174 sgd_solver.cpp:106] Iteration 231750, lr = 0.0015
I0521 23:39:14.410754 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_232500.caffemodel
I0521 23:39:14.460506 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_232500.solverstate
I0521 23:39:14.491204 10174 solver.cpp:237] Iteration 232500, loss = 1.04294
I0521 23:39:14.491250 10174 solver.cpp:253]     Train net output #0: loss = 1.04294 (* 1 = 1.04294 loss)
I0521 23:39:14.491263 10174 sgd_solver.cpp:106] Iteration 232500, lr = 0.0015
I0521 23:39:26.658733 10174 solver.cpp:237] Iteration 233250, loss = 0.821441
I0521 23:39:26.658771 10174 solver.cpp:253]     Train net output #0: loss = 0.821442 (* 1 = 0.821442 loss)
I0521 23:39:26.658787 10174 sgd_solver.cpp:106] Iteration 233250, lr = 0.0015
I0521 23:39:38.852000 10174 solver.cpp:237] Iteration 234000, loss = 0.99962
I0521 23:39:38.852049 10174 solver.cpp:253]     Train net output #0: loss = 0.999622 (* 1 = 0.999622 loss)
I0521 23:39:38.852063 10174 sgd_solver.cpp:106] Iteration 234000, lr = 0.0015
I0521 23:39:51.022366 10174 solver.cpp:237] Iteration 234750, loss = 0.941805
I0521 23:39:51.022562 10174 solver.cpp:253]     Train net output #0: loss = 0.941806 (* 1 = 0.941806 loss)
I0521 23:39:51.022578 10174 sgd_solver.cpp:106] Iteration 234750, lr = 0.0015
I0521 23:40:24.066747 10174 solver.cpp:237] Iteration 235500, loss = 1.02464
I0521 23:40:24.066938 10174 solver.cpp:253]     Train net output #0: loss = 1.02465 (* 1 = 1.02465 loss)
I0521 23:40:24.066953 10174 sgd_solver.cpp:106] Iteration 235500, lr = 0.0015
I0521 23:40:36.226883 10174 solver.cpp:237] Iteration 236250, loss = 0.98993
I0521 23:40:36.226929 10174 solver.cpp:253]     Train net output #0: loss = 0.989931 (* 1 = 0.989931 loss)
I0521 23:40:36.226945 10174 sgd_solver.cpp:106] Iteration 236250, lr = 0.0015
I0521 23:40:48.371932 10174 solver.cpp:237] Iteration 237000, loss = 1.12789
I0521 23:40:48.371968 10174 solver.cpp:253]     Train net output #0: loss = 1.12789 (* 1 = 1.12789 loss)
I0521 23:40:48.371984 10174 sgd_solver.cpp:106] Iteration 237000, lr = 0.0015
I0521 23:41:00.453696 10174 solver.cpp:237] Iteration 237750, loss = 1.25909
I0521 23:41:00.453877 10174 solver.cpp:253]     Train net output #0: loss = 1.2591 (* 1 = 1.2591 loss)
I0521 23:41:00.453892 10174 sgd_solver.cpp:106] Iteration 237750, lr = 0.0015
I0521 23:41:12.554728 10174 solver.cpp:237] Iteration 238500, loss = 1.36484
I0521 23:41:12.554764 10174 solver.cpp:253]     Train net output #0: loss = 1.36484 (* 1 = 1.36484 loss)
I0521 23:41:12.554781 10174 sgd_solver.cpp:106] Iteration 238500, lr = 0.0015
I0521 23:41:24.696328 10174 solver.cpp:237] Iteration 239250, loss = 1.40318
I0521 23:41:24.696377 10174 solver.cpp:253]     Train net output #0: loss = 1.40318 (* 1 = 1.40318 loss)
I0521 23:41:24.696391 10174 sgd_solver.cpp:106] Iteration 239250, lr = 0.0015
I0521 23:41:36.831872 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_240000.caffemodel
I0521 23:41:36.880409 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_240000.solverstate
I0521 23:41:36.905920 10174 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 23:42:49.837819 10174 solver.cpp:409]     Test net output #0: accuracy = 0.897733
I0521 23:42:49.838006 10174 solver.cpp:409]     Test net output #1: loss = 0.327911 (* 1 = 0.327911 loss)
I0521 23:43:10.700394 10174 solver.cpp:237] Iteration 240000, loss = 1.08425
I0521 23:43:10.700446 10174 solver.cpp:253]     Train net output #0: loss = 1.08425 (* 1 = 1.08425 loss)
I0521 23:43:10.700461 10174 sgd_solver.cpp:106] Iteration 240000, lr = 0.0015
I0521 23:43:22.903138 10174 solver.cpp:237] Iteration 240750, loss = 0.925764
I0521 23:43:22.903326 10174 solver.cpp:253]     Train net output #0: loss = 0.925765 (* 1 = 0.925765 loss)
I0521 23:43:22.903342 10174 sgd_solver.cpp:106] Iteration 240750, lr = 0.0015
I0521 23:43:35.072338 10174 solver.cpp:237] Iteration 241500, loss = 0.760248
I0521 23:43:35.072376 10174 solver.cpp:253]     Train net output #0: loss = 0.760249 (* 1 = 0.760249 loss)
I0521 23:43:35.072391 10174 sgd_solver.cpp:106] Iteration 241500, lr = 0.0015
I0521 23:43:47.181643 10174 solver.cpp:237] Iteration 242250, loss = 1.3687
I0521 23:43:47.181687 10174 solver.cpp:253]     Train net output #0: loss = 1.3687 (* 1 = 1.3687 loss)
I0521 23:43:47.181700 10174 sgd_solver.cpp:106] Iteration 242250, lr = 0.0015
I0521 23:43:59.296533 10174 solver.cpp:237] Iteration 243000, loss = 0.884068
I0521 23:43:59.296712 10174 solver.cpp:253]     Train net output #0: loss = 0.884069 (* 1 = 0.884069 loss)
I0521 23:43:59.296727 10174 sgd_solver.cpp:106] Iteration 243000, lr = 0.0015
I0521 23:44:11.478911 10174 solver.cpp:237] Iteration 243750, loss = 1.18193
I0521 23:44:11.478953 10174 solver.cpp:253]     Train net output #0: loss = 1.18193 (* 1 = 1.18193 loss)
I0521 23:44:11.478973 10174 sgd_solver.cpp:106] Iteration 243750, lr = 0.0015
I0521 23:44:23.696805 10174 solver.cpp:237] Iteration 244500, loss = 1.39756
I0521 23:44:23.696842 10174 solver.cpp:253]     Train net output #0: loss = 1.39757 (* 1 = 1.39757 loss)
I0521 23:44:23.696856 10174 sgd_solver.cpp:106] Iteration 244500, lr = 0.0015
I0521 23:44:56.801703 10174 solver.cpp:237] Iteration 245250, loss = 1.09506
I0521 23:44:56.801899 10174 solver.cpp:253]     Train net output #0: loss = 1.09506 (* 1 = 1.09506 loss)
I0521 23:44:56.801915 10174 sgd_solver.cpp:106] Iteration 245250, lr = 0.0015
I0521 23:45:09.000288 10174 solver.cpp:237] Iteration 246000, loss = 1.2011
I0521 23:45:09.000334 10174 solver.cpp:253]     Train net output #0: loss = 1.2011 (* 1 = 1.2011 loss)
I0521 23:45:09.000349 10174 sgd_solver.cpp:106] Iteration 246000, lr = 0.0015
I0521 23:45:21.161124 10174 solver.cpp:237] Iteration 246750, loss = 0.789599
I0521 23:45:21.161161 10174 solver.cpp:253]     Train net output #0: loss = 0.7896 (* 1 = 0.7896 loss)
I0521 23:45:21.161178 10174 sgd_solver.cpp:106] Iteration 246750, lr = 0.0015
I0521 23:45:33.328330 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_247500.caffemodel
I0521 23:45:33.377810 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_247500.solverstate
I0521 23:45:33.411134 10174 solver.cpp:237] Iteration 247500, loss = 1.04297
I0521 23:45:33.411180 10174 solver.cpp:253]     Train net output #0: loss = 1.04297 (* 1 = 1.04297 loss)
I0521 23:45:33.411200 10174 sgd_solver.cpp:106] Iteration 247500, lr = 0.0015
I0521 23:45:45.616247 10174 solver.cpp:237] Iteration 248250, loss = 1.41929
I0521 23:45:45.616283 10174 solver.cpp:253]     Train net output #0: loss = 1.41929 (* 1 = 1.41929 loss)
I0521 23:45:45.616297 10174 sgd_solver.cpp:106] Iteration 248250, lr = 0.0015
I0521 23:45:57.807823 10174 solver.cpp:237] Iteration 249000, loss = 0.93747
I0521 23:45:57.807874 10174 solver.cpp:253]     Train net output #0: loss = 0.937471 (* 1 = 0.937471 loss)
I0521 23:45:57.807889 10174 sgd_solver.cpp:106] Iteration 249000, lr = 0.0015
I0521 23:46:09.996086 10174 solver.cpp:237] Iteration 249750, loss = 1.48155
I0521 23:46:09.996260 10174 solver.cpp:253]     Train net output #0: loss = 1.48155 (* 1 = 1.48155 loss)
I0521 23:46:09.996274 10174 sgd_solver.cpp:106] Iteration 249750, lr = 0.0015
I0521 23:46:43.108805 10174 solver.cpp:237] Iteration 250500, loss = 1.01698
I0521 23:46:43.108994 10174 solver.cpp:253]     Train net output #0: loss = 1.01698 (* 1 = 1.01698 loss)
I0521 23:46:43.109009 10174 sgd_solver.cpp:106] Iteration 250500, lr = 0.0015
I0521 23:46:55.275935 10174 solver.cpp:237] Iteration 251250, loss = 1.37643
I0521 23:46:55.275971 10174 solver.cpp:253]     Train net output #0: loss = 1.37643 (* 1 = 1.37643 loss)
I0521 23:46:55.275988 10174 sgd_solver.cpp:106] Iteration 251250, lr = 0.0015
I0521 23:47:07.437623 10174 solver.cpp:237] Iteration 252000, loss = 0.977003
I0521 23:47:07.437672 10174 solver.cpp:253]     Train net output #0: loss = 0.977004 (* 1 = 0.977004 loss)
I0521 23:47:07.437686 10174 sgd_solver.cpp:106] Iteration 252000, lr = 0.0015
I0521 23:47:19.597704 10174 solver.cpp:237] Iteration 252750, loss = 1.21493
I0521 23:47:19.597890 10174 solver.cpp:253]     Train net output #0: loss = 1.21493 (* 1 = 1.21493 loss)
I0521 23:47:19.597906 10174 sgd_solver.cpp:106] Iteration 252750, lr = 0.0015
I0521 23:47:31.753753 10174 solver.cpp:237] Iteration 253500, loss = 1.28193
I0521 23:47:31.753808 10174 solver.cpp:253]     Train net output #0: loss = 1.28193 (* 1 = 1.28193 loss)
I0521 23:47:31.753821 10174 sgd_solver.cpp:106] Iteration 253500, lr = 0.0015
I0521 23:47:43.920121 10174 solver.cpp:237] Iteration 254250, loss = 1.20116
I0521 23:47:43.920157 10174 solver.cpp:253]     Train net output #0: loss = 1.20116 (* 1 = 1.20116 loss)
I0521 23:47:43.920173 10174 sgd_solver.cpp:106] Iteration 254250, lr = 0.0015
I0521 23:47:56.130610 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_255000.caffemodel
I0521 23:47:56.180773 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_255000.solverstate
I0521 23:47:56.207039 10174 solver.cpp:341] Iteration 255000, Testing net (#0)
I0521 23:48:48.146572 10174 solver.cpp:409]     Test net output #0: accuracy = 0.896953
I0521 23:48:48.146757 10174 solver.cpp:409]     Test net output #1: loss = 0.356149 (* 1 = 0.356149 loss)
I0521 23:49:09.034878 10174 solver.cpp:237] Iteration 255000, loss = 0.99968
I0521 23:49:09.034930 10174 solver.cpp:253]     Train net output #0: loss = 0.999681 (* 1 = 0.999681 loss)
I0521 23:49:09.034945 10174 sgd_solver.cpp:106] Iteration 255000, lr = 0.0015
I0521 23:49:21.236883 10174 solver.cpp:237] Iteration 255750, loss = 0.935258
I0521 23:49:21.237068 10174 solver.cpp:253]     Train net output #0: loss = 0.935259 (* 1 = 0.935259 loss)
I0521 23:49:21.237084 10174 sgd_solver.cpp:106] Iteration 255750, lr = 0.0015
I0521 23:49:33.354884 10174 solver.cpp:237] Iteration 256500, loss = 1.26246
I0521 23:49:33.354920 10174 solver.cpp:253]     Train net output #0: loss = 1.26246 (* 1 = 1.26246 loss)
I0521 23:49:33.354933 10174 sgd_solver.cpp:106] Iteration 256500, lr = 0.0015
I0521 23:49:45.522341 10174 solver.cpp:237] Iteration 257250, loss = 1.2705
I0521 23:49:45.522390 10174 solver.cpp:253]     Train net output #0: loss = 1.2705 (* 1 = 1.2705 loss)
I0521 23:49:45.522403 10174 sgd_solver.cpp:106] Iteration 257250, lr = 0.0015
I0521 23:49:57.688547 10174 solver.cpp:237] Iteration 258000, loss = 0.72323
I0521 23:49:57.688721 10174 solver.cpp:253]     Train net output #0: loss = 0.723231 (* 1 = 0.723231 loss)
I0521 23:49:57.688736 10174 sgd_solver.cpp:106] Iteration 258000, lr = 0.0015
I0521 23:50:09.853003 10174 solver.cpp:237] Iteration 258750, loss = 1.35836
I0521 23:50:09.853051 10174 solver.cpp:253]     Train net output #0: loss = 1.35836 (* 1 = 1.35836 loss)
I0521 23:50:09.853067 10174 sgd_solver.cpp:106] Iteration 258750, lr = 0.0015
I0521 23:50:22.014499 10174 solver.cpp:237] Iteration 259500, loss = 1.28176
I0521 23:50:22.014534 10174 solver.cpp:253]     Train net output #0: loss = 1.28176 (* 1 = 1.28176 loss)
I0521 23:50:22.014551 10174 sgd_solver.cpp:106] Iteration 259500, lr = 0.0015
I0521 23:50:55.118613 10174 solver.cpp:237] Iteration 260250, loss = 1.10464
I0521 23:50:55.118803 10174 solver.cpp:253]     Train net output #0: loss = 1.10464 (* 1 = 1.10464 loss)
I0521 23:50:55.118818 10174 sgd_solver.cpp:106] Iteration 260250, lr = 0.0015
I0521 23:51:07.295285 10174 solver.cpp:237] Iteration 261000, loss = 1.02094
I0521 23:51:07.295322 10174 solver.cpp:253]     Train net output #0: loss = 1.02094 (* 1 = 1.02094 loss)
I0521 23:51:07.295337 10174 sgd_solver.cpp:106] Iteration 261000, lr = 0.0015
I0521 23:51:19.476766 10174 solver.cpp:237] Iteration 261750, loss = 1.21833
I0521 23:51:19.476812 10174 solver.cpp:253]     Train net output #0: loss = 1.21833 (* 1 = 1.21833 loss)
I0521 23:51:19.476826 10174 sgd_solver.cpp:106] Iteration 261750, lr = 0.0015
I0521 23:51:31.628762 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_262500.caffemodel
I0521 23:51:31.679811 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_262500.solverstate
I0521 23:51:31.711889 10174 solver.cpp:237] Iteration 262500, loss = 1.33748
I0521 23:51:31.711938 10174 solver.cpp:253]     Train net output #0: loss = 1.33749 (* 1 = 1.33749 loss)
I0521 23:51:31.711952 10174 sgd_solver.cpp:106] Iteration 262500, lr = 0.0015
I0521 23:51:43.879758 10174 solver.cpp:237] Iteration 263250, loss = 1.43155
I0521 23:51:43.879807 10174 solver.cpp:253]     Train net output #0: loss = 1.43155 (* 1 = 1.43155 loss)
I0521 23:51:43.879823 10174 sgd_solver.cpp:106] Iteration 263250, lr = 0.0015
I0521 23:51:56.044342 10174 solver.cpp:237] Iteration 264000, loss = 1.2951
I0521 23:51:56.044378 10174 solver.cpp:253]     Train net output #0: loss = 1.2951 (* 1 = 1.2951 loss)
I0521 23:51:56.044394 10174 sgd_solver.cpp:106] Iteration 264000, lr = 0.0015
I0521 23:52:08.211413 10174 solver.cpp:237] Iteration 264750, loss = 0.8047
I0521 23:52:08.211599 10174 solver.cpp:253]     Train net output #0: loss = 0.804701 (* 1 = 0.804701 loss)
I0521 23:52:08.211616 10174 sgd_solver.cpp:106] Iteration 264750, lr = 0.0015
I0521 23:52:41.271643 10174 solver.cpp:237] Iteration 265500, loss = 1.12436
I0521 23:52:41.271834 10174 solver.cpp:253]     Train net output #0: loss = 1.12436 (* 1 = 1.12436 loss)
I0521 23:52:41.271850 10174 sgd_solver.cpp:106] Iteration 265500, lr = 0.0015
I0521 23:52:53.436945 10174 solver.cpp:237] Iteration 266250, loss = 1.24306
I0521 23:52:53.436981 10174 solver.cpp:253]     Train net output #0: loss = 1.24306 (* 1 = 1.24306 loss)
I0521 23:52:53.436995 10174 sgd_solver.cpp:106] Iteration 266250, lr = 0.0015
I0521 23:53:05.601363 10174 solver.cpp:237] Iteration 267000, loss = 1.35115
I0521 23:53:05.601409 10174 solver.cpp:253]     Train net output #0: loss = 1.35115 (* 1 = 1.35115 loss)
I0521 23:53:05.601423 10174 sgd_solver.cpp:106] Iteration 267000, lr = 0.0015
I0521 23:53:17.772835 10174 solver.cpp:237] Iteration 267750, loss = 0.742255
I0521 23:53:17.773010 10174 solver.cpp:253]     Train net output #0: loss = 0.742256 (* 1 = 0.742256 loss)
I0521 23:53:17.773025 10174 sgd_solver.cpp:106] Iteration 267750, lr = 0.0015
I0521 23:53:29.950598 10174 solver.cpp:237] Iteration 268500, loss = 1.66552
I0521 23:53:29.950647 10174 solver.cpp:253]     Train net output #0: loss = 1.66552 (* 1 = 1.66552 loss)
I0521 23:53:29.950661 10174 sgd_solver.cpp:106] Iteration 268500, lr = 0.0015
I0521 23:53:42.118459 10174 solver.cpp:237] Iteration 269250, loss = 0.688294
I0521 23:53:42.118496 10174 solver.cpp:253]     Train net output #0: loss = 0.688295 (* 1 = 0.688295 loss)
I0521 23:53:42.118511 10174 sgd_solver.cpp:106] Iteration 269250, lr = 0.0015
I0521 23:53:54.265456 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_270000.caffemodel
I0521 23:53:54.316612 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_270000.solverstate
I0521 23:53:54.343804 10174 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 23:55:07.303206 10174 solver.cpp:409]     Test net output #0: accuracy = 0.897923
I0521 23:55:07.303395 10174 solver.cpp:409]     Test net output #1: loss = 0.319164 (* 1 = 0.319164 loss)
I0521 23:55:28.180629 10174 solver.cpp:237] Iteration 270000, loss = 1.01467
I0521 23:55:28.180681 10174 solver.cpp:253]     Train net output #0: loss = 1.01467 (* 1 = 1.01467 loss)
I0521 23:55:28.180696 10174 sgd_solver.cpp:106] Iteration 270000, lr = 0.0015
I0521 23:55:40.336930 10174 solver.cpp:237] Iteration 270750, loss = 0.79816
I0521 23:55:40.337115 10174 solver.cpp:253]     Train net output #0: loss = 0.79816 (* 1 = 0.79816 loss)
I0521 23:55:40.337131 10174 sgd_solver.cpp:106] Iteration 270750, lr = 0.0015
I0521 23:55:52.501248 10174 solver.cpp:237] Iteration 271500, loss = 1.43596
I0521 23:55:52.501292 10174 solver.cpp:253]     Train net output #0: loss = 1.43596 (* 1 = 1.43596 loss)
I0521 23:55:52.501307 10174 sgd_solver.cpp:106] Iteration 271500, lr = 0.0015
I0521 23:56:04.671643 10174 solver.cpp:237] Iteration 272250, loss = 1.32167
I0521 23:56:04.671679 10174 solver.cpp:253]     Train net output #0: loss = 1.32167 (* 1 = 1.32167 loss)
I0521 23:56:04.671694 10174 sgd_solver.cpp:106] Iteration 272250, lr = 0.0015
I0521 23:56:16.835139 10174 solver.cpp:237] Iteration 273000, loss = 0.922445
I0521 23:56:16.835328 10174 solver.cpp:253]     Train net output #0: loss = 0.922446 (* 1 = 0.922446 loss)
I0521 23:56:16.835345 10174 sgd_solver.cpp:106] Iteration 273000, lr = 0.0015
I0521 23:56:28.984443 10174 solver.cpp:237] Iteration 273750, loss = 0.709433
I0521 23:56:28.984479 10174 solver.cpp:253]     Train net output #0: loss = 0.709433 (* 1 = 0.709433 loss)
I0521 23:56:28.984496 10174 sgd_solver.cpp:106] Iteration 273750, lr = 0.0015
I0521 23:56:41.142048 10174 solver.cpp:237] Iteration 274500, loss = 0.923199
I0521 23:56:41.142093 10174 solver.cpp:253]     Train net output #0: loss = 0.923199 (* 1 = 0.923199 loss)
I0521 23:56:41.142112 10174 sgd_solver.cpp:106] Iteration 274500, lr = 0.0015
I0521 23:57:14.094051 10174 solver.cpp:237] Iteration 275250, loss = 1.19435
I0521 23:57:14.094244 10174 solver.cpp:253]     Train net output #0: loss = 1.19435 (* 1 = 1.19435 loss)
I0521 23:57:14.094260 10174 sgd_solver.cpp:106] Iteration 275250, lr = 0.0015
I0521 23:57:26.156266 10174 solver.cpp:237] Iteration 276000, loss = 0.975399
I0521 23:57:26.156304 10174 solver.cpp:253]     Train net output #0: loss = 0.9754 (* 1 = 0.9754 loss)
I0521 23:57:26.156322 10174 sgd_solver.cpp:106] Iteration 276000, lr = 0.0015
I0521 23:57:38.260614 10174 solver.cpp:237] Iteration 276750, loss = 1.49552
I0521 23:57:38.260661 10174 solver.cpp:253]     Train net output #0: loss = 1.49552 (* 1 = 1.49552 loss)
I0521 23:57:38.260678 10174 sgd_solver.cpp:106] Iteration 276750, lr = 0.0015
I0521 23:57:50.341626 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_277500.caffemodel
I0521 23:57:50.390658 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_277500.solverstate
I0521 23:57:50.420783 10174 solver.cpp:237] Iteration 277500, loss = 1.23467
I0521 23:57:50.420825 10174 solver.cpp:253]     Train net output #0: loss = 1.23467 (* 1 = 1.23467 loss)
I0521 23:57:50.420842 10174 sgd_solver.cpp:106] Iteration 277500, lr = 0.0015
I0521 23:58:02.483384 10174 solver.cpp:237] Iteration 278250, loss = 1.10594
I0521 23:58:02.483431 10174 solver.cpp:253]     Train net output #0: loss = 1.10594 (* 1 = 1.10594 loss)
I0521 23:58:02.483448 10174 sgd_solver.cpp:106] Iteration 278250, lr = 0.0015
I0521 23:58:14.679113 10174 solver.cpp:237] Iteration 279000, loss = 0.875159
I0521 23:58:14.679149 10174 solver.cpp:253]     Train net output #0: loss = 0.87516 (* 1 = 0.87516 loss)
I0521 23:58:14.679165 10174 sgd_solver.cpp:106] Iteration 279000, lr = 0.0015
I0521 23:58:26.791621 10174 solver.cpp:237] Iteration 279750, loss = 1.06823
I0521 23:58:26.791811 10174 solver.cpp:253]     Train net output #0: loss = 1.06823 (* 1 = 1.06823 loss)
I0521 23:58:26.791826 10174 sgd_solver.cpp:106] Iteration 279750, lr = 0.0015
I0521 23:58:59.794828 10174 solver.cpp:237] Iteration 280500, loss = 1.10548
I0521 23:58:59.795020 10174 solver.cpp:253]     Train net output #0: loss = 1.10548 (* 1 = 1.10548 loss)
I0521 23:58:59.795037 10174 sgd_solver.cpp:106] Iteration 280500, lr = 0.0015
I0521 23:59:11.923106 10174 solver.cpp:237] Iteration 281250, loss = 1.75495
I0521 23:59:11.923156 10174 solver.cpp:253]     Train net output #0: loss = 1.75495 (* 1 = 1.75495 loss)
I0521 23:59:11.923171 10174 sgd_solver.cpp:106] Iteration 281250, lr = 0.0015
I0521 23:59:24.059381 10174 solver.cpp:237] Iteration 282000, loss = 1.46617
I0521 23:59:24.059417 10174 solver.cpp:253]     Train net output #0: loss = 1.46617 (* 1 = 1.46617 loss)
I0521 23:59:24.059432 10174 sgd_solver.cpp:106] Iteration 282000, lr = 0.0015
I0521 23:59:36.206746 10174 solver.cpp:237] Iteration 282750, loss = 1.32479
I0521 23:59:36.206943 10174 solver.cpp:253]     Train net output #0: loss = 1.32479 (* 1 = 1.32479 loss)
I0521 23:59:36.206959 10174 sgd_solver.cpp:106] Iteration 282750, lr = 0.0015
I0521 23:59:48.344354 10174 solver.cpp:237] Iteration 283500, loss = 0.874994
I0521 23:59:48.344391 10174 solver.cpp:253]     Train net output #0: loss = 0.874994 (* 1 = 0.874994 loss)
I0521 23:59:48.344408 10174 sgd_solver.cpp:106] Iteration 283500, lr = 0.0015
I0522 00:00:00.465276 10174 solver.cpp:237] Iteration 284250, loss = 1.14054
I0522 00:00:00.465314 10174 solver.cpp:253]     Train net output #0: loss = 1.14054 (* 1 = 1.14054 loss)
I0522 00:00:00.465335 10174 sgd_solver.cpp:106] Iteration 284250, lr = 0.0015
I0522 00:00:12.555694 10174 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_285000.caffemodel
I0522 00:00:12.605032 10174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_285000.solverstate
I0522 00:00:12.630270 10174 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 00:01:04.241344 10174 solver.cpp:409]     Test net output #0: accuracy = 0.896851
I0522 00:01:04.241536 10174 solver.cpp:409]     Test net output #1: loss = 0.323785 (* 1 = 0.323785 loss)
I0522 00:01:25.167309 10174 solver.cpp:237] Iteration 285000, loss = 1.81263
I0522 00:01:25.167362 10174 solver.cpp:253]     Train net output #0: loss = 1.81263 (* 1 = 1.81263 loss)
I0522 00:01:25.167377 10174 sgd_solver.cpp:106] Iteration 285000, lr = 0.0015
I0522 00:01:37.376582 10174 solver.cpp:237] Iteration 285750, loss = 0.983812
I0522 00:01:37.376762 10174 solver.cpp:253]     Train net output #0: loss = 0.983813 (* 1 = 0.983813 loss)
I0522 00:01:37.376777 10174 sgd_solver.cpp:106] Iteration 285750, lr = 0.0015
I0522 00:01:49.542249 10174 solver.cpp:237] Iteration 286500, loss = 1.1412
I0522 00:01:49.542294 10174 solver.cpp:253]     Train net output #0: loss = 1.1412 (* 1 = 1.1412 loss)
I0522 00:01:49.542309 10174 sgd_solver.cpp:106] Iteration 286500, lr = 0.0015
I0522 00:02:01.654522 10174 solver.cpp:237] Iteration 287250, loss = 1.28833
I0522 00:02:01.654559 10174 solver.cpp:253]     Train net output #0: loss = 1.28833 (* 1 = 1.28833 loss)
I0522 00:02:01.654575 10174 sgd_solver.cpp:106] Iteration 287250, lr = 0.0015
I0522 00:02:13.774477 10174 solver.cpp:237] Iteration 288000, loss = 1.10683
I0522 00:02:13.774664 10174 solver.cpp:253]     Train net output #0: loss = 1.10683 (* 1 = 1.10683 loss)
I0522 00:02:13.774679 10174 sgd_solver.cpp:106] Iteration 288000, lr = 0.0015
I0522 00:02:25.960484 10174 solver.cpp:237] Iteration 288750, loss = 1.39145
I0522 00:02:25.960520 10174 solver.cpp:253]     Train net output #0: loss = 1.39145 (* 1 = 1.39145 loss)
I0522 00:02:25.960536 10174 sgd_solver.cpp:106] Iteration 288750, lr = 0.0015
I0522 00:02:38.159976 10174 solver.cpp:237] Iteration 289500, loss = 0.932591
I0522 00:02:38.160024 10174 solver.cpp:253]     Train net output #0: loss = 0.932591 (* 1 = 0.932591 loss)
I0522 00:02:38.160038 10174 sgd_solver.cpp:106] Iteration 289500, lr = 0.0015
I0522 00:03:11.213958 10174 solver.cpp:237] Iteration 290250, loss = 1.05418
I0522 00:03:11.214153 10174 solver.cpp:253]     Train net output #0: loss = 1.05418 (* 1 = 1.05418 loss)
I0522 00:03:11.214167 10174 sgd_solver.cpp:106] Iteration 290250, lr = 0.0015
I0522 00:03:23.421475 10174 solver.cpp:237] Iteration 291000, loss = 1.12824
I0522 00:03:23.421524 10174 solver.cpp:253]     Train net output #0: loss = 1.12824 (* 1 = 1.12824 loss)
I0522 00:03:23.421538 10174 sgd_solver.cpp:106] Iteration 291000, lr = 0.0015
I0522 00:03:35.635026 10174 solver.cpp:237] Iteration 291750, loss = 1.46189
I0522 00:03:35.635063 10174 solver.cpp:253]     Train net output #0: loss = 1.46189 (* 1 = 1.46189 loss)
I0522 00:03:35.635076 10174 sgd_solver.cpp:106] Iteration 291750, lr = 0.0015
=>> PBS: job killed: walltime 7242 exceeded limit 7200
aprun: Apid 11242441: Caught signal Terminated, sending to application
*** Aborted at 1463889819 (unix time) try "date -d @1463889819" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x27bb) received by PID 10174 (TID 0x2aaac746f900) from PID 10171; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11242441: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11242441: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11242441: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
aprun: Apid 11242441: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 00812] [c2-1c0s6n2] [Sun May 22 00:03:41 2016] PE RANK 0 exit signal Terminated
Application 11242441 exit codes: 143
Application 11242441 resources: utime ~6303s, stime ~931s, Rss ~5333416, inblocks ~13318068, outblocks ~592963
