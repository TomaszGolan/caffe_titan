2807752
I0522 18:11:16.726493 12554 caffe.cpp:184] Using GPUs 0
I0522 18:11:17.163491 12554 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.002
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271.prototxt"
I0522 18:11:17.165477 12554 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271.prototxt
I0522 18:11:17.186336 12554 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 18:11:17.186395 12554 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 18:11:17.186743 12554 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 18:11:17.186928 12554 layer_factory.hpp:77] Creating layer data_hdf5
I0522 18:11:17.186951 12554 net.cpp:106] Creating Layer data_hdf5
I0522 18:11:17.186966 12554 net.cpp:411] data_hdf5 -> data
I0522 18:11:17.187000 12554 net.cpp:411] data_hdf5 -> label
I0522 18:11:17.187032 12554 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 18:11:17.189129 12554 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 18:11:17.192006 12554 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 18:11:38.733791 12554 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 18:11:38.738967 12554 net.cpp:150] Setting up data_hdf5
I0522 18:11:38.739007 12554 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 18:11:38.739022 12554 net.cpp:157] Top shape: 40 (40)
I0522 18:11:38.739034 12554 net.cpp:165] Memory required for data: 1016160
I0522 18:11:38.739048 12554 layer_factory.hpp:77] Creating layer conv1
I0522 18:11:38.739080 12554 net.cpp:106] Creating Layer conv1
I0522 18:11:38.739092 12554 net.cpp:454] conv1 <- data
I0522 18:11:38.739114 12554 net.cpp:411] conv1 -> conv1
I0522 18:11:39.102278 12554 net.cpp:150] Setting up conv1
I0522 18:11:39.102326 12554 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 18:11:39.102337 12554 net.cpp:165] Memory required for data: 12075360
I0522 18:11:39.102366 12554 layer_factory.hpp:77] Creating layer relu1
I0522 18:11:39.102387 12554 net.cpp:106] Creating Layer relu1
I0522 18:11:39.102398 12554 net.cpp:454] relu1 <- conv1
I0522 18:11:39.102412 12554 net.cpp:397] relu1 -> conv1 (in-place)
I0522 18:11:39.102934 12554 net.cpp:150] Setting up relu1
I0522 18:11:39.102952 12554 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 18:11:39.102962 12554 net.cpp:165] Memory required for data: 23134560
I0522 18:11:39.102972 12554 layer_factory.hpp:77] Creating layer pool1
I0522 18:11:39.102989 12554 net.cpp:106] Creating Layer pool1
I0522 18:11:39.102999 12554 net.cpp:454] pool1 <- conv1
I0522 18:11:39.103013 12554 net.cpp:411] pool1 -> pool1
I0522 18:11:39.103093 12554 net.cpp:150] Setting up pool1
I0522 18:11:39.103107 12554 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 18:11:39.103117 12554 net.cpp:165] Memory required for data: 28664160
I0522 18:11:39.103127 12554 layer_factory.hpp:77] Creating layer conv2
I0522 18:11:39.103150 12554 net.cpp:106] Creating Layer conv2
I0522 18:11:39.103162 12554 net.cpp:454] conv2 <- pool1
I0522 18:11:39.103173 12554 net.cpp:411] conv2 -> conv2
I0522 18:11:39.105870 12554 net.cpp:150] Setting up conv2
I0522 18:11:39.105891 12554 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 18:11:39.105902 12554 net.cpp:165] Memory required for data: 36612960
I0522 18:11:39.105921 12554 layer_factory.hpp:77] Creating layer relu2
I0522 18:11:39.105936 12554 net.cpp:106] Creating Layer relu2
I0522 18:11:39.105947 12554 net.cpp:454] relu2 <- conv2
I0522 18:11:39.105959 12554 net.cpp:397] relu2 -> conv2 (in-place)
I0522 18:11:39.106289 12554 net.cpp:150] Setting up relu2
I0522 18:11:39.106304 12554 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 18:11:39.106313 12554 net.cpp:165] Memory required for data: 44561760
I0522 18:11:39.106324 12554 layer_factory.hpp:77] Creating layer pool2
I0522 18:11:39.106336 12554 net.cpp:106] Creating Layer pool2
I0522 18:11:39.106346 12554 net.cpp:454] pool2 <- conv2
I0522 18:11:39.106359 12554 net.cpp:411] pool2 -> pool2
I0522 18:11:39.106439 12554 net.cpp:150] Setting up pool2
I0522 18:11:39.106453 12554 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 18:11:39.106463 12554 net.cpp:165] Memory required for data: 48536160
I0522 18:11:39.106473 12554 layer_factory.hpp:77] Creating layer conv3
I0522 18:11:39.106492 12554 net.cpp:106] Creating Layer conv3
I0522 18:11:39.106503 12554 net.cpp:454] conv3 <- pool2
I0522 18:11:39.106516 12554 net.cpp:411] conv3 -> conv3
I0522 18:11:39.108474 12554 net.cpp:150] Setting up conv3
I0522 18:11:39.108496 12554 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 18:11:39.108510 12554 net.cpp:165] Memory required for data: 52872800
I0522 18:11:39.108527 12554 layer_factory.hpp:77] Creating layer relu3
I0522 18:11:39.108543 12554 net.cpp:106] Creating Layer relu3
I0522 18:11:39.108553 12554 net.cpp:454] relu3 <- conv3
I0522 18:11:39.108566 12554 net.cpp:397] relu3 -> conv3 (in-place)
I0522 18:11:39.109036 12554 net.cpp:150] Setting up relu3
I0522 18:11:39.109053 12554 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 18:11:39.109064 12554 net.cpp:165] Memory required for data: 57209440
I0522 18:11:39.109074 12554 layer_factory.hpp:77] Creating layer pool3
I0522 18:11:39.109087 12554 net.cpp:106] Creating Layer pool3
I0522 18:11:39.109097 12554 net.cpp:454] pool3 <- conv3
I0522 18:11:39.109109 12554 net.cpp:411] pool3 -> pool3
I0522 18:11:39.109176 12554 net.cpp:150] Setting up pool3
I0522 18:11:39.109189 12554 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 18:11:39.109200 12554 net.cpp:165] Memory required for data: 59377760
I0522 18:11:39.109210 12554 layer_factory.hpp:77] Creating layer conv4
I0522 18:11:39.109225 12554 net.cpp:106] Creating Layer conv4
I0522 18:11:39.109236 12554 net.cpp:454] conv4 <- pool3
I0522 18:11:39.109249 12554 net.cpp:411] conv4 -> conv4
I0522 18:11:39.112015 12554 net.cpp:150] Setting up conv4
I0522 18:11:39.112043 12554 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 18:11:39.112053 12554 net.cpp:165] Memory required for data: 60829280
I0522 18:11:39.112069 12554 layer_factory.hpp:77] Creating layer relu4
I0522 18:11:39.112083 12554 net.cpp:106] Creating Layer relu4
I0522 18:11:39.112093 12554 net.cpp:454] relu4 <- conv4
I0522 18:11:39.112107 12554 net.cpp:397] relu4 -> conv4 (in-place)
I0522 18:11:39.112581 12554 net.cpp:150] Setting up relu4
I0522 18:11:39.112597 12554 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 18:11:39.112608 12554 net.cpp:165] Memory required for data: 62280800
I0522 18:11:39.112618 12554 layer_factory.hpp:77] Creating layer pool4
I0522 18:11:39.112632 12554 net.cpp:106] Creating Layer pool4
I0522 18:11:39.112640 12554 net.cpp:454] pool4 <- conv4
I0522 18:11:39.112653 12554 net.cpp:411] pool4 -> pool4
I0522 18:11:39.112722 12554 net.cpp:150] Setting up pool4
I0522 18:11:39.112735 12554 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 18:11:39.112746 12554 net.cpp:165] Memory required for data: 63006560
I0522 18:11:39.112756 12554 layer_factory.hpp:77] Creating layer ip1
I0522 18:11:39.112777 12554 net.cpp:106] Creating Layer ip1
I0522 18:11:39.112787 12554 net.cpp:454] ip1 <- pool4
I0522 18:11:39.112800 12554 net.cpp:411] ip1 -> ip1
I0522 18:11:39.128325 12554 net.cpp:150] Setting up ip1
I0522 18:11:39.128355 12554 net.cpp:157] Top shape: 40 196 (7840)
I0522 18:11:39.128371 12554 net.cpp:165] Memory required for data: 63037920
I0522 18:11:39.128396 12554 layer_factory.hpp:77] Creating layer relu5
I0522 18:11:39.128410 12554 net.cpp:106] Creating Layer relu5
I0522 18:11:39.128420 12554 net.cpp:454] relu5 <- ip1
I0522 18:11:39.128434 12554 net.cpp:397] relu5 -> ip1 (in-place)
I0522 18:11:39.128778 12554 net.cpp:150] Setting up relu5
I0522 18:11:39.128793 12554 net.cpp:157] Top shape: 40 196 (7840)
I0522 18:11:39.128803 12554 net.cpp:165] Memory required for data: 63069280
I0522 18:11:39.128813 12554 layer_factory.hpp:77] Creating layer drop1
I0522 18:11:39.128834 12554 net.cpp:106] Creating Layer drop1
I0522 18:11:39.128844 12554 net.cpp:454] drop1 <- ip1
I0522 18:11:39.128856 12554 net.cpp:397] drop1 -> ip1 (in-place)
I0522 18:11:39.128916 12554 net.cpp:150] Setting up drop1
I0522 18:11:39.128931 12554 net.cpp:157] Top shape: 40 196 (7840)
I0522 18:11:39.128940 12554 net.cpp:165] Memory required for data: 63100640
I0522 18:11:39.128950 12554 layer_factory.hpp:77] Creating layer ip2
I0522 18:11:39.128968 12554 net.cpp:106] Creating Layer ip2
I0522 18:11:39.128979 12554 net.cpp:454] ip2 <- ip1
I0522 18:11:39.128993 12554 net.cpp:411] ip2 -> ip2
I0522 18:11:39.129456 12554 net.cpp:150] Setting up ip2
I0522 18:11:39.129468 12554 net.cpp:157] Top shape: 40 98 (3920)
I0522 18:11:39.129478 12554 net.cpp:165] Memory required for data: 63116320
I0522 18:11:39.129493 12554 layer_factory.hpp:77] Creating layer relu6
I0522 18:11:39.129505 12554 net.cpp:106] Creating Layer relu6
I0522 18:11:39.129515 12554 net.cpp:454] relu6 <- ip2
I0522 18:11:39.129528 12554 net.cpp:397] relu6 -> ip2 (in-place)
I0522 18:11:39.130046 12554 net.cpp:150] Setting up relu6
I0522 18:11:39.130062 12554 net.cpp:157] Top shape: 40 98 (3920)
I0522 18:11:39.130074 12554 net.cpp:165] Memory required for data: 63132000
I0522 18:11:39.130084 12554 layer_factory.hpp:77] Creating layer drop2
I0522 18:11:39.130097 12554 net.cpp:106] Creating Layer drop2
I0522 18:11:39.130107 12554 net.cpp:454] drop2 <- ip2
I0522 18:11:39.130120 12554 net.cpp:397] drop2 -> ip2 (in-place)
I0522 18:11:39.130162 12554 net.cpp:150] Setting up drop2
I0522 18:11:39.130174 12554 net.cpp:157] Top shape: 40 98 (3920)
I0522 18:11:39.130185 12554 net.cpp:165] Memory required for data: 63147680
I0522 18:11:39.130193 12554 layer_factory.hpp:77] Creating layer ip3
I0522 18:11:39.130208 12554 net.cpp:106] Creating Layer ip3
I0522 18:11:39.130218 12554 net.cpp:454] ip3 <- ip2
I0522 18:11:39.130230 12554 net.cpp:411] ip3 -> ip3
I0522 18:11:39.130439 12554 net.cpp:150] Setting up ip3
I0522 18:11:39.130452 12554 net.cpp:157] Top shape: 40 11 (440)
I0522 18:11:39.130462 12554 net.cpp:165] Memory required for data: 63149440
I0522 18:11:39.130476 12554 layer_factory.hpp:77] Creating layer drop3
I0522 18:11:39.130489 12554 net.cpp:106] Creating Layer drop3
I0522 18:11:39.130499 12554 net.cpp:454] drop3 <- ip3
I0522 18:11:39.130511 12554 net.cpp:397] drop3 -> ip3 (in-place)
I0522 18:11:39.130550 12554 net.cpp:150] Setting up drop3
I0522 18:11:39.130563 12554 net.cpp:157] Top shape: 40 11 (440)
I0522 18:11:39.130574 12554 net.cpp:165] Memory required for data: 63151200
I0522 18:11:39.130584 12554 layer_factory.hpp:77] Creating layer loss
I0522 18:11:39.130604 12554 net.cpp:106] Creating Layer loss
I0522 18:11:39.130614 12554 net.cpp:454] loss <- ip3
I0522 18:11:39.130625 12554 net.cpp:454] loss <- label
I0522 18:11:39.130637 12554 net.cpp:411] loss -> loss
I0522 18:11:39.130655 12554 layer_factory.hpp:77] Creating layer loss
I0522 18:11:39.131299 12554 net.cpp:150] Setting up loss
I0522 18:11:39.131320 12554 net.cpp:157] Top shape: (1)
I0522 18:11:39.131335 12554 net.cpp:160]     with loss weight 1
I0522 18:11:39.131376 12554 net.cpp:165] Memory required for data: 63151204
I0522 18:11:39.131386 12554 net.cpp:226] loss needs backward computation.
I0522 18:11:39.131397 12554 net.cpp:226] drop3 needs backward computation.
I0522 18:11:39.131407 12554 net.cpp:226] ip3 needs backward computation.
I0522 18:11:39.131417 12554 net.cpp:226] drop2 needs backward computation.
I0522 18:11:39.131428 12554 net.cpp:226] relu6 needs backward computation.
I0522 18:11:39.131434 12554 net.cpp:226] ip2 needs backward computation.
I0522 18:11:39.131445 12554 net.cpp:226] drop1 needs backward computation.
I0522 18:11:39.131454 12554 net.cpp:226] relu5 needs backward computation.
I0522 18:11:39.131464 12554 net.cpp:226] ip1 needs backward computation.
I0522 18:11:39.131474 12554 net.cpp:226] pool4 needs backward computation.
I0522 18:11:39.131484 12554 net.cpp:226] relu4 needs backward computation.
I0522 18:11:39.131494 12554 net.cpp:226] conv4 needs backward computation.
I0522 18:11:39.131505 12554 net.cpp:226] pool3 needs backward computation.
I0522 18:11:39.131515 12554 net.cpp:226] relu3 needs backward computation.
I0522 18:11:39.131525 12554 net.cpp:226] conv3 needs backward computation.
I0522 18:11:39.131543 12554 net.cpp:226] pool2 needs backward computation.
I0522 18:11:39.131554 12554 net.cpp:226] relu2 needs backward computation.
I0522 18:11:39.131566 12554 net.cpp:226] conv2 needs backward computation.
I0522 18:11:39.131575 12554 net.cpp:226] pool1 needs backward computation.
I0522 18:11:39.131585 12554 net.cpp:226] relu1 needs backward computation.
I0522 18:11:39.131595 12554 net.cpp:226] conv1 needs backward computation.
I0522 18:11:39.131606 12554 net.cpp:228] data_hdf5 does not need backward computation.
I0522 18:11:39.131616 12554 net.cpp:270] This network produces output loss
I0522 18:11:39.131646 12554 net.cpp:283] Network initialization done.
I0522 18:11:39.133294 12554 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271.prototxt
I0522 18:11:39.133365 12554 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 18:11:39.133719 12554 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 18:11:39.133909 12554 layer_factory.hpp:77] Creating layer data_hdf5
I0522 18:11:39.133924 12554 net.cpp:106] Creating Layer data_hdf5
I0522 18:11:39.133936 12554 net.cpp:411] data_hdf5 -> data
I0522 18:11:39.133954 12554 net.cpp:411] data_hdf5 -> label
I0522 18:11:39.133970 12554 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 18:11:39.135223 12554 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 18:12:00.452456 12554 net.cpp:150] Setting up data_hdf5
I0522 18:12:00.452625 12554 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 18:12:00.452638 12554 net.cpp:157] Top shape: 40 (40)
I0522 18:12:00.452651 12554 net.cpp:165] Memory required for data: 1016160
I0522 18:12:00.452666 12554 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 18:12:00.452693 12554 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 18:12:00.452704 12554 net.cpp:454] label_data_hdf5_1_split <- label
I0522 18:12:00.452719 12554 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 18:12:00.452740 12554 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 18:12:00.452814 12554 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 18:12:00.452827 12554 net.cpp:157] Top shape: 40 (40)
I0522 18:12:00.452839 12554 net.cpp:157] Top shape: 40 (40)
I0522 18:12:00.452849 12554 net.cpp:165] Memory required for data: 1016480
I0522 18:12:00.452859 12554 layer_factory.hpp:77] Creating layer conv1
I0522 18:12:00.452883 12554 net.cpp:106] Creating Layer conv1
I0522 18:12:00.452893 12554 net.cpp:454] conv1 <- data
I0522 18:12:00.452905 12554 net.cpp:411] conv1 -> conv1
I0522 18:12:00.454826 12554 net.cpp:150] Setting up conv1
I0522 18:12:00.454850 12554 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 18:12:00.454862 12554 net.cpp:165] Memory required for data: 12075680
I0522 18:12:00.454882 12554 layer_factory.hpp:77] Creating layer relu1
I0522 18:12:00.454897 12554 net.cpp:106] Creating Layer relu1
I0522 18:12:00.454907 12554 net.cpp:454] relu1 <- conv1
I0522 18:12:00.454921 12554 net.cpp:397] relu1 -> conv1 (in-place)
I0522 18:12:00.455415 12554 net.cpp:150] Setting up relu1
I0522 18:12:00.455431 12554 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 18:12:00.455442 12554 net.cpp:165] Memory required for data: 23134880
I0522 18:12:00.455452 12554 layer_factory.hpp:77] Creating layer pool1
I0522 18:12:00.455468 12554 net.cpp:106] Creating Layer pool1
I0522 18:12:00.455478 12554 net.cpp:454] pool1 <- conv1
I0522 18:12:00.455492 12554 net.cpp:411] pool1 -> pool1
I0522 18:12:00.455566 12554 net.cpp:150] Setting up pool1
I0522 18:12:00.455579 12554 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 18:12:00.455590 12554 net.cpp:165] Memory required for data: 28664480
I0522 18:12:00.455596 12554 layer_factory.hpp:77] Creating layer conv2
I0522 18:12:00.455615 12554 net.cpp:106] Creating Layer conv2
I0522 18:12:00.455624 12554 net.cpp:454] conv2 <- pool1
I0522 18:12:00.455648 12554 net.cpp:411] conv2 -> conv2
I0522 18:12:00.457571 12554 net.cpp:150] Setting up conv2
I0522 18:12:00.457587 12554 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 18:12:00.457597 12554 net.cpp:165] Memory required for data: 36613280
I0522 18:12:00.457614 12554 layer_factory.hpp:77] Creating layer relu2
I0522 18:12:00.457628 12554 net.cpp:106] Creating Layer relu2
I0522 18:12:00.457638 12554 net.cpp:454] relu2 <- conv2
I0522 18:12:00.457651 12554 net.cpp:397] relu2 -> conv2 (in-place)
I0522 18:12:00.457983 12554 net.cpp:150] Setting up relu2
I0522 18:12:00.457998 12554 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 18:12:00.458008 12554 net.cpp:165] Memory required for data: 44562080
I0522 18:12:00.458017 12554 layer_factory.hpp:77] Creating layer pool2
I0522 18:12:00.458031 12554 net.cpp:106] Creating Layer pool2
I0522 18:12:00.458040 12554 net.cpp:454] pool2 <- conv2
I0522 18:12:00.458053 12554 net.cpp:411] pool2 -> pool2
I0522 18:12:00.458124 12554 net.cpp:150] Setting up pool2
I0522 18:12:00.458137 12554 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 18:12:00.458148 12554 net.cpp:165] Memory required for data: 48536480
I0522 18:12:00.458158 12554 layer_factory.hpp:77] Creating layer conv3
I0522 18:12:00.458175 12554 net.cpp:106] Creating Layer conv3
I0522 18:12:00.458186 12554 net.cpp:454] conv3 <- pool2
I0522 18:12:00.458200 12554 net.cpp:411] conv3 -> conv3
I0522 18:12:00.460176 12554 net.cpp:150] Setting up conv3
I0522 18:12:00.460199 12554 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 18:12:00.460212 12554 net.cpp:165] Memory required for data: 52873120
I0522 18:12:00.460244 12554 layer_factory.hpp:77] Creating layer relu3
I0522 18:12:00.460258 12554 net.cpp:106] Creating Layer relu3
I0522 18:12:00.460269 12554 net.cpp:454] relu3 <- conv3
I0522 18:12:00.460283 12554 net.cpp:397] relu3 -> conv3 (in-place)
I0522 18:12:00.460754 12554 net.cpp:150] Setting up relu3
I0522 18:12:00.460770 12554 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 18:12:00.460782 12554 net.cpp:165] Memory required for data: 57209760
I0522 18:12:00.460791 12554 layer_factory.hpp:77] Creating layer pool3
I0522 18:12:00.460804 12554 net.cpp:106] Creating Layer pool3
I0522 18:12:00.460813 12554 net.cpp:454] pool3 <- conv3
I0522 18:12:00.460827 12554 net.cpp:411] pool3 -> pool3
I0522 18:12:00.460898 12554 net.cpp:150] Setting up pool3
I0522 18:12:00.460912 12554 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 18:12:00.460922 12554 net.cpp:165] Memory required for data: 59378080
I0522 18:12:00.460932 12554 layer_factory.hpp:77] Creating layer conv4
I0522 18:12:00.460947 12554 net.cpp:106] Creating Layer conv4
I0522 18:12:00.460958 12554 net.cpp:454] conv4 <- pool3
I0522 18:12:00.460973 12554 net.cpp:411] conv4 -> conv4
I0522 18:12:00.463032 12554 net.cpp:150] Setting up conv4
I0522 18:12:00.463053 12554 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 18:12:00.463066 12554 net.cpp:165] Memory required for data: 60829600
I0522 18:12:00.463081 12554 layer_factory.hpp:77] Creating layer relu4
I0522 18:12:00.463095 12554 net.cpp:106] Creating Layer relu4
I0522 18:12:00.463105 12554 net.cpp:454] relu4 <- conv4
I0522 18:12:00.463119 12554 net.cpp:397] relu4 -> conv4 (in-place)
I0522 18:12:00.463589 12554 net.cpp:150] Setting up relu4
I0522 18:12:00.463605 12554 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 18:12:00.463615 12554 net.cpp:165] Memory required for data: 62281120
I0522 18:12:00.463625 12554 layer_factory.hpp:77] Creating layer pool4
I0522 18:12:00.463639 12554 net.cpp:106] Creating Layer pool4
I0522 18:12:00.463655 12554 net.cpp:454] pool4 <- conv4
I0522 18:12:00.463670 12554 net.cpp:411] pool4 -> pool4
I0522 18:12:00.463742 12554 net.cpp:150] Setting up pool4
I0522 18:12:00.463755 12554 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 18:12:00.463764 12554 net.cpp:165] Memory required for data: 63006880
I0522 18:12:00.463773 12554 layer_factory.hpp:77] Creating layer ip1
I0522 18:12:00.463788 12554 net.cpp:106] Creating Layer ip1
I0522 18:12:00.463798 12554 net.cpp:454] ip1 <- pool4
I0522 18:12:00.463812 12554 net.cpp:411] ip1 -> ip1
I0522 18:12:00.479305 12554 net.cpp:150] Setting up ip1
I0522 18:12:00.479334 12554 net.cpp:157] Top shape: 40 196 (7840)
I0522 18:12:00.479349 12554 net.cpp:165] Memory required for data: 63038240
I0522 18:12:00.479377 12554 layer_factory.hpp:77] Creating layer relu5
I0522 18:12:00.479392 12554 net.cpp:106] Creating Layer relu5
I0522 18:12:00.479403 12554 net.cpp:454] relu5 <- ip1
I0522 18:12:00.479416 12554 net.cpp:397] relu5 -> ip1 (in-place)
I0522 18:12:00.479768 12554 net.cpp:150] Setting up relu5
I0522 18:12:00.479782 12554 net.cpp:157] Top shape: 40 196 (7840)
I0522 18:12:00.479792 12554 net.cpp:165] Memory required for data: 63069600
I0522 18:12:00.479802 12554 layer_factory.hpp:77] Creating layer drop1
I0522 18:12:00.479820 12554 net.cpp:106] Creating Layer drop1
I0522 18:12:00.479830 12554 net.cpp:454] drop1 <- ip1
I0522 18:12:00.479843 12554 net.cpp:397] drop1 -> ip1 (in-place)
I0522 18:12:00.479888 12554 net.cpp:150] Setting up drop1
I0522 18:12:00.479902 12554 net.cpp:157] Top shape: 40 196 (7840)
I0522 18:12:00.479910 12554 net.cpp:165] Memory required for data: 63100960
I0522 18:12:00.479921 12554 layer_factory.hpp:77] Creating layer ip2
I0522 18:12:00.479936 12554 net.cpp:106] Creating Layer ip2
I0522 18:12:00.479946 12554 net.cpp:454] ip2 <- ip1
I0522 18:12:00.479959 12554 net.cpp:411] ip2 -> ip2
I0522 18:12:00.480437 12554 net.cpp:150] Setting up ip2
I0522 18:12:00.480449 12554 net.cpp:157] Top shape: 40 98 (3920)
I0522 18:12:00.480459 12554 net.cpp:165] Memory required for data: 63116640
I0522 18:12:00.480474 12554 layer_factory.hpp:77] Creating layer relu6
I0522 18:12:00.480499 12554 net.cpp:106] Creating Layer relu6
I0522 18:12:00.480510 12554 net.cpp:454] relu6 <- ip2
I0522 18:12:00.480523 12554 net.cpp:397] relu6 -> ip2 (in-place)
I0522 18:12:00.481061 12554 net.cpp:150] Setting up relu6
I0522 18:12:00.481082 12554 net.cpp:157] Top shape: 40 98 (3920)
I0522 18:12:00.481092 12554 net.cpp:165] Memory required for data: 63132320
I0522 18:12:00.481102 12554 layer_factory.hpp:77] Creating layer drop2
I0522 18:12:00.481117 12554 net.cpp:106] Creating Layer drop2
I0522 18:12:00.481127 12554 net.cpp:454] drop2 <- ip2
I0522 18:12:00.481140 12554 net.cpp:397] drop2 -> ip2 (in-place)
I0522 18:12:00.481184 12554 net.cpp:150] Setting up drop2
I0522 18:12:00.481196 12554 net.cpp:157] Top shape: 40 98 (3920)
I0522 18:12:00.481206 12554 net.cpp:165] Memory required for data: 63148000
I0522 18:12:00.481215 12554 layer_factory.hpp:77] Creating layer ip3
I0522 18:12:00.481230 12554 net.cpp:106] Creating Layer ip3
I0522 18:12:00.481240 12554 net.cpp:454] ip3 <- ip2
I0522 18:12:00.481253 12554 net.cpp:411] ip3 -> ip3
I0522 18:12:00.481477 12554 net.cpp:150] Setting up ip3
I0522 18:12:00.481490 12554 net.cpp:157] Top shape: 40 11 (440)
I0522 18:12:00.481500 12554 net.cpp:165] Memory required for data: 63149760
I0522 18:12:00.481515 12554 layer_factory.hpp:77] Creating layer drop3
I0522 18:12:00.481528 12554 net.cpp:106] Creating Layer drop3
I0522 18:12:00.481539 12554 net.cpp:454] drop3 <- ip3
I0522 18:12:00.481551 12554 net.cpp:397] drop3 -> ip3 (in-place)
I0522 18:12:00.481591 12554 net.cpp:150] Setting up drop3
I0522 18:12:00.481605 12554 net.cpp:157] Top shape: 40 11 (440)
I0522 18:12:00.481614 12554 net.cpp:165] Memory required for data: 63151520
I0522 18:12:00.481623 12554 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 18:12:00.481637 12554 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 18:12:00.481647 12554 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 18:12:00.481659 12554 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 18:12:00.481674 12554 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 18:12:00.481747 12554 net.cpp:150] Setting up ip3_drop3_0_split
I0522 18:12:00.481760 12554 net.cpp:157] Top shape: 40 11 (440)
I0522 18:12:00.481773 12554 net.cpp:157] Top shape: 40 11 (440)
I0522 18:12:00.481783 12554 net.cpp:165] Memory required for data: 63155040
I0522 18:12:00.481793 12554 layer_factory.hpp:77] Creating layer accuracy
I0522 18:12:00.481815 12554 net.cpp:106] Creating Layer accuracy
I0522 18:12:00.481825 12554 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 18:12:00.481834 12554 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 18:12:00.481848 12554 net.cpp:411] accuracy -> accuracy
I0522 18:12:00.481873 12554 net.cpp:150] Setting up accuracy
I0522 18:12:00.481885 12554 net.cpp:157] Top shape: (1)
I0522 18:12:00.481895 12554 net.cpp:165] Memory required for data: 63155044
I0522 18:12:00.481905 12554 layer_factory.hpp:77] Creating layer loss
I0522 18:12:00.481917 12554 net.cpp:106] Creating Layer loss
I0522 18:12:00.481928 12554 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 18:12:00.481940 12554 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 18:12:00.481953 12554 net.cpp:411] loss -> loss
I0522 18:12:00.481971 12554 layer_factory.hpp:77] Creating layer loss
I0522 18:12:00.482453 12554 net.cpp:150] Setting up loss
I0522 18:12:00.482466 12554 net.cpp:157] Top shape: (1)
I0522 18:12:00.482476 12554 net.cpp:160]     with loss weight 1
I0522 18:12:00.482494 12554 net.cpp:165] Memory required for data: 63155048
I0522 18:12:00.482506 12554 net.cpp:226] loss needs backward computation.
I0522 18:12:00.482517 12554 net.cpp:228] accuracy does not need backward computation.
I0522 18:12:00.482527 12554 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 18:12:00.482537 12554 net.cpp:226] drop3 needs backward computation.
I0522 18:12:00.482547 12554 net.cpp:226] ip3 needs backward computation.
I0522 18:12:00.482558 12554 net.cpp:226] drop2 needs backward computation.
I0522 18:12:00.482568 12554 net.cpp:226] relu6 needs backward computation.
I0522 18:12:00.482585 12554 net.cpp:226] ip2 needs backward computation.
I0522 18:12:00.482596 12554 net.cpp:226] drop1 needs backward computation.
I0522 18:12:00.482605 12554 net.cpp:226] relu5 needs backward computation.
I0522 18:12:00.482615 12554 net.cpp:226] ip1 needs backward computation.
I0522 18:12:00.482625 12554 net.cpp:226] pool4 needs backward computation.
I0522 18:12:00.482635 12554 net.cpp:226] relu4 needs backward computation.
I0522 18:12:00.482645 12554 net.cpp:226] conv4 needs backward computation.
I0522 18:12:00.482656 12554 net.cpp:226] pool3 needs backward computation.
I0522 18:12:00.482667 12554 net.cpp:226] relu3 needs backward computation.
I0522 18:12:00.482677 12554 net.cpp:226] conv3 needs backward computation.
I0522 18:12:00.482687 12554 net.cpp:226] pool2 needs backward computation.
I0522 18:12:00.482697 12554 net.cpp:226] relu2 needs backward computation.
I0522 18:12:00.482707 12554 net.cpp:226] conv2 needs backward computation.
I0522 18:12:00.482717 12554 net.cpp:226] pool1 needs backward computation.
I0522 18:12:00.482728 12554 net.cpp:226] relu1 needs backward computation.
I0522 18:12:00.482738 12554 net.cpp:226] conv1 needs backward computation.
I0522 18:12:00.482746 12554 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 18:12:00.482758 12554 net.cpp:228] data_hdf5 does not need backward computation.
I0522 18:12:00.482767 12554 net.cpp:270] This network produces output accuracy
I0522 18:12:00.482779 12554 net.cpp:270] This network produces output loss
I0522 18:12:00.482806 12554 net.cpp:283] Network initialization done.
I0522 18:12:00.482940 12554 solver.cpp:60] Solver scaffolding done.
I0522 18:12:00.484079 12554 caffe.cpp:212] Starting Optimization
I0522 18:12:00.484098 12554 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 18:12:00.484112 12554 solver.cpp:289] Learning Rate Policy: fixed
I0522 18:12:00.485340 12554 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 18:12:49.896136 12554 solver.cpp:409]     Test net output #0: accuracy = 0.0627599
I0522 18:12:49.896306 12554 solver.cpp:409]     Test net output #1: loss = 2.39866 (* 1 = 2.39866 loss)
I0522 18:12:49.918869 12554 solver.cpp:237] Iteration 0, loss = 2.40318
I0522 18:12:49.918905 12554 solver.cpp:253]     Train net output #0: loss = 2.40318 (* 1 = 2.40318 loss)
I0522 18:12:49.918922 12554 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I0522 18:12:59.771551 12554 solver.cpp:237] Iteration 375, loss = 2.21078
I0522 18:12:59.771597 12554 solver.cpp:253]     Train net output #0: loss = 2.21078 (* 1 = 2.21078 loss)
I0522 18:12:59.771612 12554 sgd_solver.cpp:106] Iteration 375, lr = 0.002
I0522 18:13:09.616627 12554 solver.cpp:237] Iteration 750, loss = 1.92274
I0522 18:13:09.616663 12554 solver.cpp:253]     Train net output #0: loss = 1.92274 (* 1 = 1.92274 loss)
I0522 18:13:09.616677 12554 sgd_solver.cpp:106] Iteration 750, lr = 0.002
I0522 18:13:19.465597 12554 solver.cpp:237] Iteration 1125, loss = 1.77631
I0522 18:13:19.465632 12554 solver.cpp:253]     Train net output #0: loss = 1.77631 (* 1 = 1.77631 loss)
I0522 18:13:19.465651 12554 sgd_solver.cpp:106] Iteration 1125, lr = 0.002
I0522 18:13:29.312278 12554 solver.cpp:237] Iteration 1500, loss = 1.6558
I0522 18:13:29.312429 12554 solver.cpp:253]     Train net output #0: loss = 1.6558 (* 1 = 1.6558 loss)
I0522 18:13:29.312444 12554 sgd_solver.cpp:106] Iteration 1500, lr = 0.002
I0522 18:13:39.166702 12554 solver.cpp:237] Iteration 1875, loss = 1.88318
I0522 18:13:39.166738 12554 solver.cpp:253]     Train net output #0: loss = 1.88318 (* 1 = 1.88318 loss)
I0522 18:13:39.166754 12554 sgd_solver.cpp:106] Iteration 1875, lr = 0.002
I0522 18:13:49.018110 12554 solver.cpp:237] Iteration 2250, loss = 1.72478
I0522 18:13:49.018152 12554 solver.cpp:253]     Train net output #0: loss = 1.72478 (* 1 = 1.72478 loss)
I0522 18:13:49.018172 12554 sgd_solver.cpp:106] Iteration 2250, lr = 0.002
I0522 18:14:21.017856 12554 solver.cpp:237] Iteration 2625, loss = 1.71773
I0522 18:14:21.018016 12554 solver.cpp:253]     Train net output #0: loss = 1.71773 (* 1 = 1.71773 loss)
I0522 18:14:21.018033 12554 sgd_solver.cpp:106] Iteration 2625, lr = 0.002
I0522 18:14:30.883612 12554 solver.cpp:237] Iteration 3000, loss = 1.40192
I0522 18:14:30.883653 12554 solver.cpp:253]     Train net output #0: loss = 1.40192 (* 1 = 1.40192 loss)
I0522 18:14:30.883666 12554 sgd_solver.cpp:106] Iteration 3000, lr = 0.002
I0522 18:14:40.740671 12554 solver.cpp:237] Iteration 3375, loss = 2.06317
I0522 18:14:40.740722 12554 solver.cpp:253]     Train net output #0: loss = 2.06317 (* 1 = 2.06317 loss)
I0522 18:14:40.740736 12554 sgd_solver.cpp:106] Iteration 3375, lr = 0.002
I0522 18:14:50.574484 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_3750.caffemodel
I0522 18:14:50.634243 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_3750.solverstate
I0522 18:14:50.667632 12554 solver.cpp:237] Iteration 3750, loss = 1.70691
I0522 18:14:50.667682 12554 solver.cpp:253]     Train net output #0: loss = 1.70691 (* 1 = 1.70691 loss)
I0522 18:14:50.667700 12554 sgd_solver.cpp:106] Iteration 3750, lr = 0.002
I0522 18:15:00.525882 12554 solver.cpp:237] Iteration 4125, loss = 1.69907
I0522 18:15:00.526022 12554 solver.cpp:253]     Train net output #0: loss = 1.69907 (* 1 = 1.69907 loss)
I0522 18:15:00.526036 12554 sgd_solver.cpp:106] Iteration 4125, lr = 0.002
I0522 18:15:10.383627 12554 solver.cpp:237] Iteration 4500, loss = 1.3128
I0522 18:15:10.383679 12554 solver.cpp:253]     Train net output #0: loss = 1.3128 (* 1 = 1.3128 loss)
I0522 18:15:10.383697 12554 sgd_solver.cpp:106] Iteration 4500, lr = 0.002
I0522 18:15:20.243408 12554 solver.cpp:237] Iteration 4875, loss = 1.4848
I0522 18:15:20.243444 12554 solver.cpp:253]     Train net output #0: loss = 1.4848 (* 1 = 1.4848 loss)
I0522 18:15:20.243460 12554 sgd_solver.cpp:106] Iteration 4875, lr = 0.002
I0522 18:15:52.256027 12554 solver.cpp:237] Iteration 5250, loss = 1.62375
I0522 18:15:52.256184 12554 solver.cpp:253]     Train net output #0: loss = 1.62375 (* 1 = 1.62375 loss)
I0522 18:15:52.256198 12554 sgd_solver.cpp:106] Iteration 5250, lr = 0.002
I0522 18:16:02.109870 12554 solver.cpp:237] Iteration 5625, loss = 1.19567
I0522 18:16:02.109906 12554 solver.cpp:253]     Train net output #0: loss = 1.19567 (* 1 = 1.19567 loss)
I0522 18:16:02.109925 12554 sgd_solver.cpp:106] Iteration 5625, lr = 0.002
I0522 18:16:11.965142 12554 solver.cpp:237] Iteration 6000, loss = 1.64342
I0522 18:16:11.965178 12554 solver.cpp:253]     Train net output #0: loss = 1.64342 (* 1 = 1.64342 loss)
I0522 18:16:11.965195 12554 sgd_solver.cpp:106] Iteration 6000, lr = 0.002
I0522 18:16:21.826642 12554 solver.cpp:237] Iteration 6375, loss = 1.18281
I0522 18:16:21.826686 12554 solver.cpp:253]     Train net output #0: loss = 1.18281 (* 1 = 1.18281 loss)
I0522 18:16:21.826704 12554 sgd_solver.cpp:106] Iteration 6375, lr = 0.002
I0522 18:16:31.686017 12554 solver.cpp:237] Iteration 6750, loss = 1.6447
I0522 18:16:31.686166 12554 solver.cpp:253]     Train net output #0: loss = 1.6447 (* 1 = 1.6447 loss)
I0522 18:16:31.686179 12554 sgd_solver.cpp:106] Iteration 6750, lr = 0.002
I0522 18:16:41.550273 12554 solver.cpp:237] Iteration 7125, loss = 1.42473
I0522 18:16:41.550308 12554 solver.cpp:253]     Train net output #0: loss = 1.42473 (* 1 = 1.42473 loss)
I0522 18:16:41.550325 12554 sgd_solver.cpp:106] Iteration 7125, lr = 0.002
I0522 18:16:51.385359 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_7500.caffemodel
I0522 18:16:51.442816 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_7500.solverstate
I0522 18:16:51.468981 12554 solver.cpp:341] Iteration 7500, Testing net (#0)
I0522 18:17:39.965266 12554 solver.cpp:409]     Test net output #0: accuracy = 0.78868
I0522 18:17:39.965436 12554 solver.cpp:409]     Test net output #1: loss = 0.740924 (* 1 = 0.740924 loss)
I0522 18:18:02.097224 12554 solver.cpp:237] Iteration 7500, loss = 1.38852
I0522 18:18:02.097276 12554 solver.cpp:253]     Train net output #0: loss = 1.38852 (* 1 = 1.38852 loss)
I0522 18:18:02.097291 12554 sgd_solver.cpp:106] Iteration 7500, lr = 0.002
I0522 18:18:12.012459 12554 solver.cpp:237] Iteration 7875, loss = 1.29657
I0522 18:18:12.012596 12554 solver.cpp:253]     Train net output #0: loss = 1.29657 (* 1 = 1.29657 loss)
I0522 18:18:12.012610 12554 sgd_solver.cpp:106] Iteration 7875, lr = 0.002
I0522 18:18:21.938427 12554 solver.cpp:237] Iteration 8250, loss = 1.35722
I0522 18:18:21.938474 12554 solver.cpp:253]     Train net output #0: loss = 1.35722 (* 1 = 1.35722 loss)
I0522 18:18:21.938489 12554 sgd_solver.cpp:106] Iteration 8250, lr = 0.002
I0522 18:18:31.854915 12554 solver.cpp:237] Iteration 8625, loss = 1.66627
I0522 18:18:31.854953 12554 solver.cpp:253]     Train net output #0: loss = 1.66627 (* 1 = 1.66627 loss)
I0522 18:18:31.854969 12554 sgd_solver.cpp:106] Iteration 8625, lr = 0.002
I0522 18:18:41.777374 12554 solver.cpp:237] Iteration 9000, loss = 1.35406
I0522 18:18:41.777410 12554 solver.cpp:253]     Train net output #0: loss = 1.35406 (* 1 = 1.35406 loss)
I0522 18:18:41.777426 12554 sgd_solver.cpp:106] Iteration 9000, lr = 0.002
I0522 18:18:51.698568 12554 solver.cpp:237] Iteration 9375, loss = 1.28566
I0522 18:18:51.698721 12554 solver.cpp:253]     Train net output #0: loss = 1.28566 (* 1 = 1.28566 loss)
I0522 18:18:51.698735 12554 sgd_solver.cpp:106] Iteration 9375, lr = 0.002
I0522 18:19:01.614995 12554 solver.cpp:237] Iteration 9750, loss = 1.26681
I0522 18:19:01.615031 12554 solver.cpp:253]     Train net output #0: loss = 1.26681 (* 1 = 1.26681 loss)
I0522 18:19:01.615047 12554 sgd_solver.cpp:106] Iteration 9750, lr = 0.002
I0522 18:19:33.685547 12554 solver.cpp:237] Iteration 10125, loss = 1.79102
I0522 18:19:33.685729 12554 solver.cpp:253]     Train net output #0: loss = 1.79102 (* 1 = 1.79102 loss)
I0522 18:19:33.685744 12554 sgd_solver.cpp:106] Iteration 10125, lr = 0.002
I0522 18:19:43.604894 12554 solver.cpp:237] Iteration 10500, loss = 1.28307
I0522 18:19:43.604938 12554 solver.cpp:253]     Train net output #0: loss = 1.28307 (* 1 = 1.28307 loss)
I0522 18:19:43.604955 12554 sgd_solver.cpp:106] Iteration 10500, lr = 0.002
I0522 18:19:53.526801 12554 solver.cpp:237] Iteration 10875, loss = 1.32944
I0522 18:19:53.526836 12554 solver.cpp:253]     Train net output #0: loss = 1.32944 (* 1 = 1.32944 loss)
I0522 18:19:53.526854 12554 sgd_solver.cpp:106] Iteration 10875, lr = 0.002
I0522 18:20:03.418999 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_11250.caffemodel
I0522 18:20:03.478299 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_11250.solverstate
I0522 18:20:03.514854 12554 solver.cpp:237] Iteration 11250, loss = 1.5076
I0522 18:20:03.514904 12554 solver.cpp:253]     Train net output #0: loss = 1.5076 (* 1 = 1.5076 loss)
I0522 18:20:03.514919 12554 sgd_solver.cpp:106] Iteration 11250, lr = 0.002
I0522 18:20:13.435219 12554 solver.cpp:237] Iteration 11625, loss = 1.28823
I0522 18:20:13.435374 12554 solver.cpp:253]     Train net output #0: loss = 1.28823 (* 1 = 1.28823 loss)
I0522 18:20:13.435387 12554 sgd_solver.cpp:106] Iteration 11625, lr = 0.002
I0522 18:20:23.364241 12554 solver.cpp:237] Iteration 12000, loss = 1.42295
I0522 18:20:23.364276 12554 solver.cpp:253]     Train net output #0: loss = 1.42295 (* 1 = 1.42295 loss)
I0522 18:20:23.364294 12554 sgd_solver.cpp:106] Iteration 12000, lr = 0.002
I0522 18:20:33.283601 12554 solver.cpp:237] Iteration 12375, loss = 1.7145
I0522 18:20:33.283658 12554 solver.cpp:253]     Train net output #0: loss = 1.7145 (* 1 = 1.7145 loss)
I0522 18:20:33.283671 12554 sgd_solver.cpp:106] Iteration 12375, lr = 0.002
I0522 18:21:05.376734 12554 solver.cpp:237] Iteration 12750, loss = 1.23181
I0522 18:21:05.376893 12554 solver.cpp:253]     Train net output #0: loss = 1.23181 (* 1 = 1.23181 loss)
I0522 18:21:05.376909 12554 sgd_solver.cpp:106] Iteration 12750, lr = 0.002
I0522 18:21:15.292618 12554 solver.cpp:237] Iteration 13125, loss = 1.47812
I0522 18:21:15.292652 12554 solver.cpp:253]     Train net output #0: loss = 1.47812 (* 1 = 1.47812 loss)
I0522 18:21:15.292672 12554 sgd_solver.cpp:106] Iteration 13125, lr = 0.002
I0522 18:21:25.212790 12554 solver.cpp:237] Iteration 13500, loss = 1.30426
I0522 18:21:25.212838 12554 solver.cpp:253]     Train net output #0: loss = 1.30426 (* 1 = 1.30426 loss)
I0522 18:21:25.212853 12554 sgd_solver.cpp:106] Iteration 13500, lr = 0.002
I0522 18:21:35.131249 12554 solver.cpp:237] Iteration 13875, loss = 1.02963
I0522 18:21:35.131285 12554 solver.cpp:253]     Train net output #0: loss = 1.02963 (* 1 = 1.02963 loss)
I0522 18:21:35.131299 12554 sgd_solver.cpp:106] Iteration 13875, lr = 0.002
I0522 18:21:45.056339 12554 solver.cpp:237] Iteration 14250, loss = 1.31268
I0522 18:21:45.056493 12554 solver.cpp:253]     Train net output #0: loss = 1.31268 (* 1 = 1.31268 loss)
I0522 18:21:45.056507 12554 sgd_solver.cpp:106] Iteration 14250, lr = 0.002
I0522 18:21:54.979012 12554 solver.cpp:237] Iteration 14625, loss = 1.19392
I0522 18:21:54.979048 12554 solver.cpp:253]     Train net output #0: loss = 1.19392 (* 1 = 1.19392 loss)
I0522 18:21:54.979061 12554 sgd_solver.cpp:106] Iteration 14625, lr = 0.002
I0522 18:22:04.871510 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_15000.caffemodel
I0522 18:22:04.930670 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_15000.solverstate
I0522 18:22:04.958866 12554 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 18:23:14.292465 12554 solver.cpp:409]     Test net output #0: accuracy = 0.822799
I0522 18:23:14.292635 12554 solver.cpp:409]     Test net output #1: loss = 0.579276 (* 1 = 0.579276 loss)
I0522 18:23:36.456825 12554 solver.cpp:237] Iteration 15000, loss = 1.25566
I0522 18:23:36.456877 12554 solver.cpp:253]     Train net output #0: loss = 1.25566 (* 1 = 1.25566 loss)
I0522 18:23:36.456895 12554 sgd_solver.cpp:106] Iteration 15000, lr = 0.002
I0522 18:23:46.318826 12554 solver.cpp:237] Iteration 15375, loss = 1.24615
I0522 18:23:46.318987 12554 solver.cpp:253]     Train net output #0: loss = 1.24615 (* 1 = 1.24615 loss)
I0522 18:23:46.319001 12554 sgd_solver.cpp:106] Iteration 15375, lr = 0.002
I0522 18:23:56.183516 12554 solver.cpp:237] Iteration 15750, loss = 1.417
I0522 18:23:56.183555 12554 solver.cpp:253]     Train net output #0: loss = 1.417 (* 1 = 1.417 loss)
I0522 18:23:56.183573 12554 sgd_solver.cpp:106] Iteration 15750, lr = 0.002
I0522 18:24:06.046030 12554 solver.cpp:237] Iteration 16125, loss = 1.29215
I0522 18:24:06.046064 12554 solver.cpp:253]     Train net output #0: loss = 1.29215 (* 1 = 1.29215 loss)
I0522 18:24:06.046082 12554 sgd_solver.cpp:106] Iteration 16125, lr = 0.002
I0522 18:24:15.906592 12554 solver.cpp:237] Iteration 16500, loss = 1.50003
I0522 18:24:15.906638 12554 solver.cpp:253]     Train net output #0: loss = 1.50003 (* 1 = 1.50003 loss)
I0522 18:24:15.906657 12554 sgd_solver.cpp:106] Iteration 16500, lr = 0.002
I0522 18:24:25.771867 12554 solver.cpp:237] Iteration 16875, loss = 1.46946
I0522 18:24:25.772018 12554 solver.cpp:253]     Train net output #0: loss = 1.46946 (* 1 = 1.46946 loss)
I0522 18:24:25.772032 12554 sgd_solver.cpp:106] Iteration 16875, lr = 0.002
I0522 18:24:35.635915 12554 solver.cpp:237] Iteration 17250, loss = 1.34569
I0522 18:24:35.635948 12554 solver.cpp:253]     Train net output #0: loss = 1.34569 (* 1 = 1.34569 loss)
I0522 18:24:35.635965 12554 sgd_solver.cpp:106] Iteration 17250, lr = 0.002
I0522 18:25:07.630468 12554 solver.cpp:237] Iteration 17625, loss = 1.27501
I0522 18:25:07.630627 12554 solver.cpp:253]     Train net output #0: loss = 1.27501 (* 1 = 1.27501 loss)
I0522 18:25:07.630642 12554 sgd_solver.cpp:106] Iteration 17625, lr = 0.002
I0522 18:25:17.498970 12554 solver.cpp:237] Iteration 18000, loss = 1.46012
I0522 18:25:17.499006 12554 solver.cpp:253]     Train net output #0: loss = 1.46012 (* 1 = 1.46012 loss)
I0522 18:25:17.499023 12554 sgd_solver.cpp:106] Iteration 18000, lr = 0.002
I0522 18:25:27.365761 12554 solver.cpp:237] Iteration 18375, loss = 1.22438
I0522 18:25:27.365804 12554 solver.cpp:253]     Train net output #0: loss = 1.22438 (* 1 = 1.22438 loss)
I0522 18:25:27.365823 12554 sgd_solver.cpp:106] Iteration 18375, lr = 0.002
I0522 18:25:37.201748 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_18750.caffemodel
I0522 18:25:37.260375 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_18750.solverstate
I0522 18:25:37.297477 12554 solver.cpp:237] Iteration 18750, loss = 1.96988
I0522 18:25:37.297526 12554 solver.cpp:253]     Train net output #0: loss = 1.96988 (* 1 = 1.96988 loss)
I0522 18:25:37.297541 12554 sgd_solver.cpp:106] Iteration 18750, lr = 0.002
I0522 18:25:47.160459 12554 solver.cpp:237] Iteration 19125, loss = 1.29496
I0522 18:25:47.160614 12554 solver.cpp:253]     Train net output #0: loss = 1.29496 (* 1 = 1.29496 loss)
I0522 18:25:47.160627 12554 sgd_solver.cpp:106] Iteration 19125, lr = 0.002
I0522 18:25:57.019392 12554 solver.cpp:237] Iteration 19500, loss = 1.35123
I0522 18:25:57.019436 12554 solver.cpp:253]     Train net output #0: loss = 1.35123 (* 1 = 1.35123 loss)
I0522 18:25:57.019454 12554 sgd_solver.cpp:106] Iteration 19500, lr = 0.002
I0522 18:26:06.881731 12554 solver.cpp:237] Iteration 19875, loss = 1.48204
I0522 18:26:06.881765 12554 solver.cpp:253]     Train net output #0: loss = 1.48204 (* 1 = 1.48204 loss)
I0522 18:26:06.881779 12554 sgd_solver.cpp:106] Iteration 19875, lr = 0.002
I0522 18:26:38.904078 12554 solver.cpp:237] Iteration 20250, loss = 1.18946
I0522 18:26:38.904258 12554 solver.cpp:253]     Train net output #0: loss = 1.18946 (* 1 = 1.18946 loss)
I0522 18:26:38.904273 12554 sgd_solver.cpp:106] Iteration 20250, lr = 0.002
I0522 18:26:48.770117 12554 solver.cpp:237] Iteration 20625, loss = 1.19253
I0522 18:26:48.770160 12554 solver.cpp:253]     Train net output #0: loss = 1.19253 (* 1 = 1.19253 loss)
I0522 18:26:48.770179 12554 sgd_solver.cpp:106] Iteration 20625, lr = 0.002
I0522 18:26:58.630970 12554 solver.cpp:237] Iteration 21000, loss = 1.08249
I0522 18:26:58.631006 12554 solver.cpp:253]     Train net output #0: loss = 1.08249 (* 1 = 1.08249 loss)
I0522 18:26:58.631023 12554 sgd_solver.cpp:106] Iteration 21000, lr = 0.002
I0522 18:27:08.491211 12554 solver.cpp:237] Iteration 21375, loss = 1.22114
I0522 18:27:08.491252 12554 solver.cpp:253]     Train net output #0: loss = 1.22114 (* 1 = 1.22114 loss)
I0522 18:27:08.491271 12554 sgd_solver.cpp:106] Iteration 21375, lr = 0.002
I0522 18:27:18.361134 12554 solver.cpp:237] Iteration 21750, loss = 1.30452
I0522 18:27:18.361275 12554 solver.cpp:253]     Train net output #0: loss = 1.30452 (* 1 = 1.30452 loss)
I0522 18:27:18.361289 12554 sgd_solver.cpp:106] Iteration 21750, lr = 0.002
I0522 18:27:28.231025 12554 solver.cpp:237] Iteration 22125, loss = 1.00569
I0522 18:27:28.231060 12554 solver.cpp:253]     Train net output #0: loss = 1.00569 (* 1 = 1.00569 loss)
I0522 18:27:28.231075 12554 sgd_solver.cpp:106] Iteration 22125, lr = 0.002
I0522 18:27:38.079413 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_22500.caffemodel
I0522 18:27:38.135535 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_22500.solverstate
I0522 18:27:38.161918 12554 solver.cpp:341] Iteration 22500, Testing net (#0)
I0522 18:28:26.319995 12554 solver.cpp:409]     Test net output #0: accuracy = 0.842687
I0522 18:28:26.320165 12554 solver.cpp:409]     Test net output #1: loss = 0.530932 (* 1 = 0.530932 loss)
I0522 18:28:48.493201 12554 solver.cpp:237] Iteration 22500, loss = 1.1675
I0522 18:28:48.493254 12554 solver.cpp:253]     Train net output #0: loss = 1.1675 (* 1 = 1.1675 loss)
I0522 18:28:48.493269 12554 sgd_solver.cpp:106] Iteration 22500, lr = 0.002
I0522 18:28:58.208991 12554 solver.cpp:237] Iteration 22875, loss = 1.09113
I0522 18:28:58.209142 12554 solver.cpp:253]     Train net output #0: loss = 1.09113 (* 1 = 1.09113 loss)
I0522 18:28:58.209156 12554 sgd_solver.cpp:106] Iteration 22875, lr = 0.002
I0522 18:29:07.924657 12554 solver.cpp:237] Iteration 23250, loss = 1.29356
I0522 18:29:07.924692 12554 solver.cpp:253]     Train net output #0: loss = 1.29356 (* 1 = 1.29356 loss)
I0522 18:29:07.924710 12554 sgd_solver.cpp:106] Iteration 23250, lr = 0.002
I0522 18:29:17.639335 12554 solver.cpp:237] Iteration 23625, loss = 1.43992
I0522 18:29:17.639377 12554 solver.cpp:253]     Train net output #0: loss = 1.43992 (* 1 = 1.43992 loss)
I0522 18:29:17.639397 12554 sgd_solver.cpp:106] Iteration 23625, lr = 0.002
I0522 18:29:27.348917 12554 solver.cpp:237] Iteration 24000, loss = 1.29244
I0522 18:29:27.348953 12554 solver.cpp:253]     Train net output #0: loss = 1.29244 (* 1 = 1.29244 loss)
I0522 18:29:27.348969 12554 sgd_solver.cpp:106] Iteration 24000, lr = 0.002
I0522 18:29:37.059959 12554 solver.cpp:237] Iteration 24375, loss = 1.34618
I0522 18:29:37.060116 12554 solver.cpp:253]     Train net output #0: loss = 1.34618 (* 1 = 1.34618 loss)
I0522 18:29:37.060130 12554 sgd_solver.cpp:106] Iteration 24375, lr = 0.002
I0522 18:29:46.769923 12554 solver.cpp:237] Iteration 24750, loss = 1.03558
I0522 18:29:46.769959 12554 solver.cpp:253]     Train net output #0: loss = 1.03558 (* 1 = 1.03558 loss)
I0522 18:29:46.769978 12554 sgd_solver.cpp:106] Iteration 24750, lr = 0.002
I0522 18:30:18.722277 12554 solver.cpp:237] Iteration 25125, loss = 1.28814
I0522 18:30:18.722456 12554 solver.cpp:253]     Train net output #0: loss = 1.28814 (* 1 = 1.28814 loss)
I0522 18:30:18.722472 12554 sgd_solver.cpp:106] Iteration 25125, lr = 0.002
I0522 18:30:28.445201 12554 solver.cpp:237] Iteration 25500, loss = 1.13909
I0522 18:30:28.445248 12554 solver.cpp:253]     Train net output #0: loss = 1.13909 (* 1 = 1.13909 loss)
I0522 18:30:28.445266 12554 sgd_solver.cpp:106] Iteration 25500, lr = 0.002
I0522 18:30:38.162253 12554 solver.cpp:237] Iteration 25875, loss = 1.15807
I0522 18:30:38.162291 12554 solver.cpp:253]     Train net output #0: loss = 1.15807 (* 1 = 1.15807 loss)
I0522 18:30:38.162307 12554 sgd_solver.cpp:106] Iteration 25875, lr = 0.002
I0522 18:30:47.852046 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_26250.caffemodel
I0522 18:30:47.907495 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_26250.solverstate
I0522 18:30:47.942405 12554 solver.cpp:237] Iteration 26250, loss = 1.19868
I0522 18:30:47.942446 12554 solver.cpp:253]     Train net output #0: loss = 1.19868 (* 1 = 1.19868 loss)
I0522 18:30:47.942461 12554 sgd_solver.cpp:106] Iteration 26250, lr = 0.002
I0522 18:30:57.659512 12554 solver.cpp:237] Iteration 26625, loss = 1.42089
I0522 18:30:57.659677 12554 solver.cpp:253]     Train net output #0: loss = 1.42089 (* 1 = 1.42089 loss)
I0522 18:30:57.659692 12554 sgd_solver.cpp:106] Iteration 26625, lr = 0.002
I0522 18:31:07.376083 12554 solver.cpp:237] Iteration 27000, loss = 0.962274
I0522 18:31:07.376119 12554 solver.cpp:253]     Train net output #0: loss = 0.962274 (* 1 = 0.962274 loss)
I0522 18:31:07.376137 12554 sgd_solver.cpp:106] Iteration 27000, lr = 0.002
I0522 18:31:17.092656 12554 solver.cpp:237] Iteration 27375, loss = 1.06066
I0522 18:31:17.092701 12554 solver.cpp:253]     Train net output #0: loss = 1.06066 (* 1 = 1.06066 loss)
I0522 18:31:17.092718 12554 sgd_solver.cpp:106] Iteration 27375, lr = 0.002
I0522 18:31:49.047791 12554 solver.cpp:237] Iteration 27750, loss = 1.22027
I0522 18:31:49.047956 12554 solver.cpp:253]     Train net output #0: loss = 1.22027 (* 1 = 1.22027 loss)
I0522 18:31:49.047971 12554 sgd_solver.cpp:106] Iteration 27750, lr = 0.002
I0522 18:31:58.756865 12554 solver.cpp:237] Iteration 28125, loss = 1.16669
I0522 18:31:58.756901 12554 solver.cpp:253]     Train net output #0: loss = 1.16669 (* 1 = 1.16669 loss)
I0522 18:31:58.756916 12554 sgd_solver.cpp:106] Iteration 28125, lr = 0.002
I0522 18:32:08.471834 12554 solver.cpp:237] Iteration 28500, loss = 1.45234
I0522 18:32:08.471882 12554 solver.cpp:253]     Train net output #0: loss = 1.45234 (* 1 = 1.45234 loss)
I0522 18:32:08.471896 12554 sgd_solver.cpp:106] Iteration 28500, lr = 0.002
I0522 18:32:18.188535 12554 solver.cpp:237] Iteration 28875, loss = 1.32295
I0522 18:32:18.188570 12554 solver.cpp:253]     Train net output #0: loss = 1.32295 (* 1 = 1.32295 loss)
I0522 18:32:18.188587 12554 sgd_solver.cpp:106] Iteration 28875, lr = 0.002
I0522 18:32:27.904620 12554 solver.cpp:237] Iteration 29250, loss = 1.16828
I0522 18:32:27.904762 12554 solver.cpp:253]     Train net output #0: loss = 1.16828 (* 1 = 1.16828 loss)
I0522 18:32:27.904777 12554 sgd_solver.cpp:106] Iteration 29250, lr = 0.002
I0522 18:32:37.619308 12554 solver.cpp:237] Iteration 29625, loss = 1.24579
I0522 18:32:37.619356 12554 solver.cpp:253]     Train net output #0: loss = 1.24579 (* 1 = 1.24579 loss)
I0522 18:32:37.619371 12554 sgd_solver.cpp:106] Iteration 29625, lr = 0.002
I0522 18:32:47.311224 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_30000.caffemodel
I0522 18:32:47.367313 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_30000.solverstate
I0522 18:32:47.393939 12554 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 18:33:56.841012 12554 solver.cpp:409]     Test net output #0: accuracy = 0.85282
I0522 18:33:56.841187 12554 solver.cpp:409]     Test net output #1: loss = 0.437272 (* 1 = 0.437272 loss)
I0522 18:34:19.028015 12554 solver.cpp:237] Iteration 30000, loss = 1.4393
I0522 18:34:19.028069 12554 solver.cpp:253]     Train net output #0: loss = 1.4393 (* 1 = 1.4393 loss)
I0522 18:34:19.028085 12554 sgd_solver.cpp:106] Iteration 30000, lr = 0.002
I0522 18:34:28.834738 12554 solver.cpp:237] Iteration 30375, loss = 1.28401
I0522 18:34:28.834887 12554 solver.cpp:253]     Train net output #0: loss = 1.28401 (* 1 = 1.28401 loss)
I0522 18:34:28.834900 12554 sgd_solver.cpp:106] Iteration 30375, lr = 0.002
I0522 18:34:38.633612 12554 solver.cpp:237] Iteration 30750, loss = 1.27238
I0522 18:34:38.633658 12554 solver.cpp:253]     Train net output #0: loss = 1.27238 (* 1 = 1.27238 loss)
I0522 18:34:38.633676 12554 sgd_solver.cpp:106] Iteration 30750, lr = 0.002
I0522 18:34:48.410082 12554 solver.cpp:237] Iteration 31125, loss = 1.23581
I0522 18:34:48.410118 12554 solver.cpp:253]     Train net output #0: loss = 1.23581 (* 1 = 1.23581 loss)
I0522 18:34:48.410135 12554 sgd_solver.cpp:106] Iteration 31125, lr = 0.002
I0522 18:34:58.191763 12554 solver.cpp:237] Iteration 31500, loss = 1.08563
I0522 18:34:58.191799 12554 solver.cpp:253]     Train net output #0: loss = 1.08563 (* 1 = 1.08563 loss)
I0522 18:34:58.191812 12554 sgd_solver.cpp:106] Iteration 31500, lr = 0.002
I0522 18:35:07.968998 12554 solver.cpp:237] Iteration 31875, loss = 1.41343
I0522 18:35:07.969151 12554 solver.cpp:253]     Train net output #0: loss = 1.41343 (* 1 = 1.41343 loss)
I0522 18:35:07.969164 12554 sgd_solver.cpp:106] Iteration 31875, lr = 0.002
I0522 18:35:17.749377 12554 solver.cpp:237] Iteration 32250, loss = 1.06177
I0522 18:35:17.749413 12554 solver.cpp:253]     Train net output #0: loss = 1.06177 (* 1 = 1.06177 loss)
I0522 18:35:17.749426 12554 sgd_solver.cpp:106] Iteration 32250, lr = 0.002
I0522 18:35:49.677732 12554 solver.cpp:237] Iteration 32625, loss = 0.986526
I0522 18:35:49.677902 12554 solver.cpp:253]     Train net output #0: loss = 0.986526 (* 1 = 0.986526 loss)
I0522 18:35:49.677918 12554 sgd_solver.cpp:106] Iteration 32625, lr = 0.002
I0522 18:35:59.476202 12554 solver.cpp:237] Iteration 33000, loss = 1.32218
I0522 18:35:59.476248 12554 solver.cpp:253]     Train net output #0: loss = 1.32218 (* 1 = 1.32218 loss)
I0522 18:35:59.476266 12554 sgd_solver.cpp:106] Iteration 33000, lr = 0.002
I0522 18:36:09.283920 12554 solver.cpp:237] Iteration 33375, loss = 1.14274
I0522 18:36:09.283956 12554 solver.cpp:253]     Train net output #0: loss = 1.14274 (* 1 = 1.14274 loss)
I0522 18:36:09.283972 12554 sgd_solver.cpp:106] Iteration 33375, lr = 0.002
I0522 18:36:19.059698 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_33750.caffemodel
I0522 18:36:19.118437 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_33750.solverstate
I0522 18:36:19.155485 12554 solver.cpp:237] Iteration 33750, loss = 1.51303
I0522 18:36:19.155536 12554 solver.cpp:253]     Train net output #0: loss = 1.51303 (* 1 = 1.51303 loss)
I0522 18:36:19.155550 12554 sgd_solver.cpp:106] Iteration 33750, lr = 0.002
I0522 18:36:28.956944 12554 solver.cpp:237] Iteration 34125, loss = 1.03184
I0522 18:36:28.957090 12554 solver.cpp:253]     Train net output #0: loss = 1.03184 (* 1 = 1.03184 loss)
I0522 18:36:28.957104 12554 sgd_solver.cpp:106] Iteration 34125, lr = 0.002
I0522 18:36:38.759264 12554 solver.cpp:237] Iteration 34500, loss = 1.13025
I0522 18:36:38.759299 12554 solver.cpp:253]     Train net output #0: loss = 1.13025 (* 1 = 1.13025 loss)
I0522 18:36:38.759316 12554 sgd_solver.cpp:106] Iteration 34500, lr = 0.002
I0522 18:36:48.561784 12554 solver.cpp:237] Iteration 34875, loss = 1.15329
I0522 18:36:48.561825 12554 solver.cpp:253]     Train net output #0: loss = 1.15329 (* 1 = 1.15329 loss)
I0522 18:36:48.561844 12554 sgd_solver.cpp:106] Iteration 34875, lr = 0.002
I0522 18:37:20.523632 12554 solver.cpp:237] Iteration 35250, loss = 1.15066
I0522 18:37:20.523815 12554 solver.cpp:253]     Train net output #0: loss = 1.15066 (* 1 = 1.15066 loss)
I0522 18:37:20.523831 12554 sgd_solver.cpp:106] Iteration 35250, lr = 0.002
I0522 18:37:30.327723 12554 solver.cpp:237] Iteration 35625, loss = 1.39038
I0522 18:37:30.327759 12554 solver.cpp:253]     Train net output #0: loss = 1.39038 (* 1 = 1.39038 loss)
I0522 18:37:30.327775 12554 sgd_solver.cpp:106] Iteration 35625, lr = 0.002
I0522 18:37:40.129772 12554 solver.cpp:237] Iteration 36000, loss = 1.38184
I0522 18:37:40.129814 12554 solver.cpp:253]     Train net output #0: loss = 1.38184 (* 1 = 1.38184 loss)
I0522 18:37:40.129834 12554 sgd_solver.cpp:106] Iteration 36000, lr = 0.002
I0522 18:37:49.937350 12554 solver.cpp:237] Iteration 36375, loss = 0.93859
I0522 18:37:49.937386 12554 solver.cpp:253]     Train net output #0: loss = 0.93859 (* 1 = 0.93859 loss)
I0522 18:37:49.937402 12554 sgd_solver.cpp:106] Iteration 36375, lr = 0.002
I0522 18:37:59.734825 12554 solver.cpp:237] Iteration 36750, loss = 1.25222
I0522 18:37:59.735002 12554 solver.cpp:253]     Train net output #0: loss = 1.25222 (* 1 = 1.25222 loss)
I0522 18:37:59.735015 12554 sgd_solver.cpp:106] Iteration 36750, lr = 0.002
I0522 18:38:09.536356 12554 solver.cpp:237] Iteration 37125, loss = 1.21469
I0522 18:38:09.536391 12554 solver.cpp:253]     Train net output #0: loss = 1.21469 (* 1 = 1.21469 loss)
I0522 18:38:09.536408 12554 sgd_solver.cpp:106] Iteration 37125, lr = 0.002
I0522 18:38:19.316169 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_37500.caffemodel
I0522 18:38:19.375247 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_37500.solverstate
I0522 18:38:19.404350 12554 solver.cpp:341] Iteration 37500, Testing net (#0)
I0522 18:39:07.928279 12554 solver.cpp:409]     Test net output #0: accuracy = 0.865493
I0522 18:39:07.928454 12554 solver.cpp:409]     Test net output #1: loss = 0.440534 (* 1 = 0.440534 loss)
I0522 18:39:28.857548 12554 solver.cpp:237] Iteration 37500, loss = 1.07718
I0522 18:39:28.857601 12554 solver.cpp:253]     Train net output #0: loss = 1.07718 (* 1 = 1.07718 loss)
I0522 18:39:28.857616 12554 sgd_solver.cpp:106] Iteration 37500, lr = 0.002
I0522 18:39:38.562702 12554 solver.cpp:237] Iteration 37875, loss = 1.04294
I0522 18:39:38.562865 12554 solver.cpp:253]     Train net output #0: loss = 1.04294 (* 1 = 1.04294 loss)
I0522 18:39:38.562877 12554 sgd_solver.cpp:106] Iteration 37875, lr = 0.002
I0522 18:39:48.272490 12554 solver.cpp:237] Iteration 38250, loss = 1.46328
I0522 18:39:48.272524 12554 solver.cpp:253]     Train net output #0: loss = 1.46328 (* 1 = 1.46328 loss)
I0522 18:39:48.272542 12554 sgd_solver.cpp:106] Iteration 38250, lr = 0.002
I0522 18:39:57.972455 12554 solver.cpp:237] Iteration 38625, loss = 1.26898
I0522 18:39:57.972489 12554 solver.cpp:253]     Train net output #0: loss = 1.26898 (* 1 = 1.26898 loss)
I0522 18:39:57.972507 12554 sgd_solver.cpp:106] Iteration 38625, lr = 0.002
I0522 18:40:07.677047 12554 solver.cpp:237] Iteration 39000, loss = 1.13943
I0522 18:40:07.677093 12554 solver.cpp:253]     Train net output #0: loss = 1.13943 (* 1 = 1.13943 loss)
I0522 18:40:07.677110 12554 sgd_solver.cpp:106] Iteration 39000, lr = 0.002
I0522 18:40:17.383422 12554 solver.cpp:237] Iteration 39375, loss = 1.26532
I0522 18:40:17.383577 12554 solver.cpp:253]     Train net output #0: loss = 1.26532 (* 1 = 1.26532 loss)
I0522 18:40:17.383591 12554 sgd_solver.cpp:106] Iteration 39375, lr = 0.002
I0522 18:40:27.086439 12554 solver.cpp:237] Iteration 39750, loss = 1.02658
I0522 18:40:27.086486 12554 solver.cpp:253]     Train net output #0: loss = 1.02658 (* 1 = 1.02658 loss)
I0522 18:40:27.086503 12554 sgd_solver.cpp:106] Iteration 39750, lr = 0.002
I0522 18:40:57.725879 12554 solver.cpp:237] Iteration 40125, loss = 1.22113
I0522 18:40:57.726052 12554 solver.cpp:253]     Train net output #0: loss = 1.22113 (* 1 = 1.22113 loss)
I0522 18:40:57.726068 12554 sgd_solver.cpp:106] Iteration 40125, lr = 0.002
I0522 18:41:07.430637 12554 solver.cpp:237] Iteration 40500, loss = 1.12527
I0522 18:41:07.430672 12554 solver.cpp:253]     Train net output #0: loss = 1.12527 (* 1 = 1.12527 loss)
I0522 18:41:07.430686 12554 sgd_solver.cpp:106] Iteration 40500, lr = 0.002
I0522 18:41:17.132870 12554 solver.cpp:237] Iteration 40875, loss = 1.33171
I0522 18:41:17.132916 12554 solver.cpp:253]     Train net output #0: loss = 1.33171 (* 1 = 1.33171 loss)
I0522 18:41:17.132933 12554 sgd_solver.cpp:106] Iteration 40875, lr = 0.002
I0522 18:41:26.812084 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_41250.caffemodel
I0522 18:41:26.867419 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_41250.solverstate
I0522 18:41:26.902206 12554 solver.cpp:237] Iteration 41250, loss = 1.09311
I0522 18:41:26.902246 12554 solver.cpp:253]     Train net output #0: loss = 1.09311 (* 1 = 1.09311 loss)
I0522 18:41:26.902267 12554 sgd_solver.cpp:106] Iteration 41250, lr = 0.002
I0522 18:41:36.606710 12554 solver.cpp:237] Iteration 41625, loss = 1.31521
I0522 18:41:36.606863 12554 solver.cpp:253]     Train net output #0: loss = 1.31521 (* 1 = 1.31521 loss)
I0522 18:41:36.606878 12554 sgd_solver.cpp:106] Iteration 41625, lr = 0.002
I0522 18:41:46.311532 12554 solver.cpp:237] Iteration 42000, loss = 1.12905
I0522 18:41:46.311579 12554 solver.cpp:253]     Train net output #0: loss = 1.12905 (* 1 = 1.12905 loss)
I0522 18:41:46.311594 12554 sgd_solver.cpp:106] Iteration 42000, lr = 0.002
I0522 18:41:56.012271 12554 solver.cpp:237] Iteration 42375, loss = 1.19483
I0522 18:41:56.012306 12554 solver.cpp:253]     Train net output #0: loss = 1.19483 (* 1 = 1.19483 loss)
I0522 18:41:56.012322 12554 sgd_solver.cpp:106] Iteration 42375, lr = 0.002
I0522 18:42:26.643162 12554 solver.cpp:237] Iteration 42750, loss = 1.25152
I0522 18:42:26.643337 12554 solver.cpp:253]     Train net output #0: loss = 1.25152 (* 1 = 1.25152 loss)
I0522 18:42:26.643353 12554 sgd_solver.cpp:106] Iteration 42750, lr = 0.002
I0522 18:42:36.348100 12554 solver.cpp:237] Iteration 43125, loss = 0.828987
I0522 18:42:36.348147 12554 solver.cpp:253]     Train net output #0: loss = 0.828987 (* 1 = 0.828987 loss)
I0522 18:42:36.348163 12554 sgd_solver.cpp:106] Iteration 43125, lr = 0.002
I0522 18:42:46.051995 12554 solver.cpp:237] Iteration 43500, loss = 1.25451
I0522 18:42:46.052026 12554 solver.cpp:253]     Train net output #0: loss = 1.25451 (* 1 = 1.25451 loss)
I0522 18:42:46.052039 12554 sgd_solver.cpp:106] Iteration 43500, lr = 0.002
I0522 18:42:55.757962 12554 solver.cpp:237] Iteration 43875, loss = 1.29027
I0522 18:42:55.757997 12554 solver.cpp:253]     Train net output #0: loss = 1.29027 (* 1 = 1.29027 loss)
I0522 18:42:55.758014 12554 sgd_solver.cpp:106] Iteration 43875, lr = 0.002
I0522 18:43:05.465339 12554 solver.cpp:237] Iteration 44250, loss = 1.22794
I0522 18:43:05.465497 12554 solver.cpp:253]     Train net output #0: loss = 1.22794 (* 1 = 1.22794 loss)
I0522 18:43:05.465510 12554 sgd_solver.cpp:106] Iteration 44250, lr = 0.002
I0522 18:43:15.175166 12554 solver.cpp:237] Iteration 44625, loss = 1.2505
I0522 18:43:15.175200 12554 solver.cpp:253]     Train net output #0: loss = 1.2505 (* 1 = 1.2505 loss)
I0522 18:43:15.175218 12554 sgd_solver.cpp:106] Iteration 44625, lr = 0.002
I0522 18:43:24.851461 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_45000.caffemodel
I0522 18:43:24.908191 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_45000.solverstate
I0522 18:43:24.934578 12554 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 18:44:34.390352 12554 solver.cpp:409]     Test net output #0: accuracy = 0.87016
I0522 18:44:34.390532 12554 solver.cpp:409]     Test net output #1: loss = 0.406589 (* 1 = 0.406589 loss)
I0522 18:44:55.291515 12554 solver.cpp:237] Iteration 45000, loss = 1.01742
I0522 18:44:55.291568 12554 solver.cpp:253]     Train net output #0: loss = 1.01742 (* 1 = 1.01742 loss)
I0522 18:44:55.291582 12554 sgd_solver.cpp:106] Iteration 45000, lr = 0.002
I0522 18:45:05.159665 12554 solver.cpp:237] Iteration 45375, loss = 1.18265
I0522 18:45:05.159835 12554 solver.cpp:253]     Train net output #0: loss = 1.18265 (* 1 = 1.18265 loss)
I0522 18:45:05.159849 12554 sgd_solver.cpp:106] Iteration 45375, lr = 0.002
I0522 18:45:15.029923 12554 solver.cpp:237] Iteration 45750, loss = 1.19998
I0522 18:45:15.029954 12554 solver.cpp:253]     Train net output #0: loss = 1.19998 (* 1 = 1.19998 loss)
I0522 18:45:15.029970 12554 sgd_solver.cpp:106] Iteration 45750, lr = 0.002
I0522 18:45:24.892511 12554 solver.cpp:237] Iteration 46125, loss = 1.41925
I0522 18:45:24.892547 12554 solver.cpp:253]     Train net output #0: loss = 1.41925 (* 1 = 1.41925 loss)
I0522 18:45:24.892563 12554 sgd_solver.cpp:106] Iteration 46125, lr = 0.002
I0522 18:45:34.759289 12554 solver.cpp:237] Iteration 46500, loss = 1.27684
I0522 18:45:34.759335 12554 solver.cpp:253]     Train net output #0: loss = 1.27684 (* 1 = 1.27684 loss)
I0522 18:45:34.759347 12554 sgd_solver.cpp:106] Iteration 46500, lr = 0.002
I0522 18:45:44.634603 12554 solver.cpp:237] Iteration 46875, loss = 1.31133
I0522 18:45:44.634752 12554 solver.cpp:253]     Train net output #0: loss = 1.31133 (* 1 = 1.31133 loss)
I0522 18:45:44.634766 12554 sgd_solver.cpp:106] Iteration 46875, lr = 0.002
I0522 18:45:54.497987 12554 solver.cpp:237] Iteration 47250, loss = 1.39448
I0522 18:45:54.498034 12554 solver.cpp:253]     Train net output #0: loss = 1.39448 (* 1 = 1.39448 loss)
I0522 18:45:54.498050 12554 sgd_solver.cpp:106] Iteration 47250, lr = 0.002
I0522 18:46:25.287725 12554 solver.cpp:237] Iteration 47625, loss = 1.21013
I0522 18:46:25.287896 12554 solver.cpp:253]     Train net output #0: loss = 1.21013 (* 1 = 1.21013 loss)
I0522 18:46:25.287911 12554 sgd_solver.cpp:106] Iteration 47625, lr = 0.002
I0522 18:46:35.158032 12554 solver.cpp:237] Iteration 48000, loss = 0.868414
I0522 18:46:35.158067 12554 solver.cpp:253]     Train net output #0: loss = 0.868414 (* 1 = 0.868414 loss)
I0522 18:46:35.158085 12554 sgd_solver.cpp:106] Iteration 48000, lr = 0.002
I0522 18:46:45.019814 12554 solver.cpp:237] Iteration 48375, loss = 1.51298
I0522 18:46:45.019862 12554 solver.cpp:253]     Train net output #0: loss = 1.51298 (* 1 = 1.51298 loss)
I0522 18:46:45.019879 12554 sgd_solver.cpp:106] Iteration 48375, lr = 0.002
I0522 18:46:54.864578 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_48750.caffemodel
I0522 18:46:54.920976 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_48750.solverstate
I0522 18:46:54.954082 12554 solver.cpp:237] Iteration 48750, loss = 1.26484
I0522 18:46:54.954128 12554 solver.cpp:253]     Train net output #0: loss = 1.26484 (* 1 = 1.26484 loss)
I0522 18:46:54.954144 12554 sgd_solver.cpp:106] Iteration 48750, lr = 0.002
I0522 18:47:04.826220 12554 solver.cpp:237] Iteration 49125, loss = 1.1868
I0522 18:47:04.826383 12554 solver.cpp:253]     Train net output #0: loss = 1.1868 (* 1 = 1.1868 loss)
I0522 18:47:04.826397 12554 sgd_solver.cpp:106] Iteration 49125, lr = 0.002
I0522 18:47:14.693790 12554 solver.cpp:237] Iteration 49500, loss = 1.14854
I0522 18:47:14.693838 12554 solver.cpp:253]     Train net output #0: loss = 1.14854 (* 1 = 1.14854 loss)
I0522 18:47:14.693852 12554 sgd_solver.cpp:106] Iteration 49500, lr = 0.002
I0522 18:47:24.562418 12554 solver.cpp:237] Iteration 49875, loss = 0.891322
I0522 18:47:24.562455 12554 solver.cpp:253]     Train net output #0: loss = 0.891322 (* 1 = 0.891322 loss)
I0522 18:47:24.562469 12554 sgd_solver.cpp:106] Iteration 49875, lr = 0.002
I0522 18:47:55.375830 12554 solver.cpp:237] Iteration 50250, loss = 1.14548
I0522 18:47:55.376003 12554 solver.cpp:253]     Train net output #0: loss = 1.14548 (* 1 = 1.14548 loss)
I0522 18:47:55.376019 12554 sgd_solver.cpp:106] Iteration 50250, lr = 0.002
I0522 18:48:05.218933 12554 solver.cpp:237] Iteration 50625, loss = 1.2889
I0522 18:48:05.218976 12554 solver.cpp:253]     Train net output #0: loss = 1.2889 (* 1 = 1.2889 loss)
I0522 18:48:05.218994 12554 sgd_solver.cpp:106] Iteration 50625, lr = 0.002
I0522 18:48:15.064282 12554 solver.cpp:237] Iteration 51000, loss = 1.40951
I0522 18:48:15.064318 12554 solver.cpp:253]     Train net output #0: loss = 1.40951 (* 1 = 1.40951 loss)
I0522 18:48:15.064334 12554 sgd_solver.cpp:106] Iteration 51000, lr = 0.002
I0522 18:48:24.897756 12554 solver.cpp:237] Iteration 51375, loss = 1.23002
I0522 18:48:24.897795 12554 solver.cpp:253]     Train net output #0: loss = 1.23002 (* 1 = 1.23002 loss)
I0522 18:48:24.897815 12554 sgd_solver.cpp:106] Iteration 51375, lr = 0.002
I0522 18:48:34.734223 12554 solver.cpp:237] Iteration 51750, loss = 1.18531
I0522 18:48:34.734374 12554 solver.cpp:253]     Train net output #0: loss = 1.18531 (* 1 = 1.18531 loss)
I0522 18:48:34.734387 12554 sgd_solver.cpp:106] Iteration 51750, lr = 0.002
I0522 18:48:44.570627 12554 solver.cpp:237] Iteration 52125, loss = 1.13658
I0522 18:48:44.570662 12554 solver.cpp:253]     Train net output #0: loss = 1.13658 (* 1 = 1.13658 loss)
I0522 18:48:44.570678 12554 sgd_solver.cpp:106] Iteration 52125, lr = 0.002
I0522 18:48:54.386780 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_52500.caffemodel
I0522 18:48:54.443044 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_52500.solverstate
I0522 18:48:54.469835 12554 solver.cpp:341] Iteration 52500, Testing net (#0)
I0522 18:49:42.661484 12554 solver.cpp:409]     Test net output #0: accuracy = 0.87246
I0522 18:49:42.661648 12554 solver.cpp:409]     Test net output #1: loss = 0.412191 (* 1 = 0.412191 loss)
I0522 18:50:03.599066 12554 solver.cpp:237] Iteration 52500, loss = 1.07308
I0522 18:50:03.599120 12554 solver.cpp:253]     Train net output #0: loss = 1.07308 (* 1 = 1.07308 loss)
I0522 18:50:03.599136 12554 sgd_solver.cpp:106] Iteration 52500, lr = 0.002
I0522 18:50:13.455623 12554 solver.cpp:237] Iteration 52875, loss = 1.18643
I0522 18:50:13.455787 12554 solver.cpp:253]     Train net output #0: loss = 1.18643 (* 1 = 1.18643 loss)
I0522 18:50:13.455801 12554 sgd_solver.cpp:106] Iteration 52875, lr = 0.002
I0522 18:50:23.306777 12554 solver.cpp:237] Iteration 53250, loss = 1.20093
I0522 18:50:23.306812 12554 solver.cpp:253]     Train net output #0: loss = 1.20094 (* 1 = 1.20094 loss)
I0522 18:50:23.306829 12554 sgd_solver.cpp:106] Iteration 53250, lr = 0.002
I0522 18:50:33.194309 12554 solver.cpp:237] Iteration 53625, loss = 1.00493
I0522 18:50:33.194357 12554 solver.cpp:253]     Train net output #0: loss = 1.00493 (* 1 = 1.00493 loss)
I0522 18:50:33.194375 12554 sgd_solver.cpp:106] Iteration 53625, lr = 0.002
I0522 18:50:43.098618 12554 solver.cpp:237] Iteration 54000, loss = 1.27777
I0522 18:50:43.098654 12554 solver.cpp:253]     Train net output #0: loss = 1.27777 (* 1 = 1.27777 loss)
I0522 18:50:43.098670 12554 sgd_solver.cpp:106] Iteration 54000, lr = 0.002
I0522 18:50:53.008833 12554 solver.cpp:237] Iteration 54375, loss = 0.930403
I0522 18:50:53.009009 12554 solver.cpp:253]     Train net output #0: loss = 0.930403 (* 1 = 0.930403 loss)
I0522 18:50:53.009024 12554 sgd_solver.cpp:106] Iteration 54375, lr = 0.002
I0522 18:51:02.919991 12554 solver.cpp:237] Iteration 54750, loss = 1.16618
I0522 18:51:02.920025 12554 solver.cpp:253]     Train net output #0: loss = 1.16618 (* 1 = 1.16618 loss)
I0522 18:51:02.920043 12554 sgd_solver.cpp:106] Iteration 54750, lr = 0.002
I0522 18:51:33.792223 12554 solver.cpp:237] Iteration 55125, loss = 1.26669
I0522 18:51:33.792399 12554 solver.cpp:253]     Train net output #0: loss = 1.26669 (* 1 = 1.26669 loss)
I0522 18:51:33.792414 12554 sgd_solver.cpp:106] Iteration 55125, lr = 0.002
I0522 18:51:43.696389 12554 solver.cpp:237] Iteration 55500, loss = 1.27067
I0522 18:51:43.696431 12554 solver.cpp:253]     Train net output #0: loss = 1.27067 (* 1 = 1.27067 loss)
I0522 18:51:43.696451 12554 sgd_solver.cpp:106] Iteration 55500, lr = 0.002
I0522 18:51:53.598145 12554 solver.cpp:237] Iteration 55875, loss = 0.822561
I0522 18:51:53.598182 12554 solver.cpp:253]     Train net output #0: loss = 0.822561 (* 1 = 0.822561 loss)
I0522 18:51:53.598197 12554 sgd_solver.cpp:106] Iteration 55875, lr = 0.002
I0522 18:52:03.482570 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_56250.caffemodel
I0522 18:52:03.541071 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_56250.solverstate
I0522 18:52:03.578227 12554 solver.cpp:237] Iteration 56250, loss = 1.35974
I0522 18:52:03.578274 12554 solver.cpp:253]     Train net output #0: loss = 1.35974 (* 1 = 1.35974 loss)
I0522 18:52:03.578294 12554 sgd_solver.cpp:106] Iteration 56250, lr = 0.002
I0522 18:52:13.483405 12554 solver.cpp:237] Iteration 56625, loss = 1.26294
I0522 18:52:13.483572 12554 solver.cpp:253]     Train net output #0: loss = 1.26294 (* 1 = 1.26294 loss)
I0522 18:52:13.483585 12554 sgd_solver.cpp:106] Iteration 56625, lr = 0.002
I0522 18:52:23.392807 12554 solver.cpp:237] Iteration 57000, loss = 1.39955
I0522 18:52:23.392843 12554 solver.cpp:253]     Train net output #0: loss = 1.39955 (* 1 = 1.39955 loss)
I0522 18:52:23.392860 12554 sgd_solver.cpp:106] Iteration 57000, lr = 0.002
I0522 18:52:33.300449 12554 solver.cpp:237] Iteration 57375, loss = 1.28115
I0522 18:52:33.300498 12554 solver.cpp:253]     Train net output #0: loss = 1.28115 (* 1 = 1.28115 loss)
I0522 18:52:33.300514 12554 sgd_solver.cpp:106] Iteration 57375, lr = 0.002
I0522 18:53:04.126144 12554 solver.cpp:237] Iteration 57750, loss = 1.23262
I0522 18:53:04.126313 12554 solver.cpp:253]     Train net output #0: loss = 1.23262 (* 1 = 1.23262 loss)
I0522 18:53:04.126328 12554 sgd_solver.cpp:106] Iteration 57750, lr = 0.002
I0522 18:53:14.028803 12554 solver.cpp:237] Iteration 58125, loss = 1.25127
I0522 18:53:14.028838 12554 solver.cpp:253]     Train net output #0: loss = 1.25127 (* 1 = 1.25127 loss)
I0522 18:53:14.028856 12554 sgd_solver.cpp:106] Iteration 58125, lr = 0.002
I0522 18:53:23.932123 12554 solver.cpp:237] Iteration 58500, loss = 1.23949
I0522 18:53:23.932171 12554 solver.cpp:253]     Train net output #0: loss = 1.23949 (* 1 = 1.23949 loss)
I0522 18:53:23.932188 12554 sgd_solver.cpp:106] Iteration 58500, lr = 0.002
I0522 18:53:33.834846 12554 solver.cpp:237] Iteration 58875, loss = 1.37121
I0522 18:53:33.834882 12554 solver.cpp:253]     Train net output #0: loss = 1.37121 (* 1 = 1.37121 loss)
I0522 18:53:33.834899 12554 sgd_solver.cpp:106] Iteration 58875, lr = 0.002
I0522 18:53:43.737624 12554 solver.cpp:237] Iteration 59250, loss = 1.00343
I0522 18:53:43.737778 12554 solver.cpp:253]     Train net output #0: loss = 1.00343 (* 1 = 1.00343 loss)
I0522 18:53:43.737792 12554 sgd_solver.cpp:106] Iteration 59250, lr = 0.002
I0522 18:53:53.644457 12554 solver.cpp:237] Iteration 59625, loss = 1.04598
I0522 18:53:53.644497 12554 solver.cpp:253]     Train net output #0: loss = 1.04598 (* 1 = 1.04598 loss)
I0522 18:53:53.644515 12554 sgd_solver.cpp:106] Iteration 59625, lr = 0.002
I0522 18:54:03.533116 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_60000.caffemodel
I0522 18:54:03.589423 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_60000.solverstate
I0522 18:54:03.615725 12554 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 18:55:13.044039 12554 solver.cpp:409]     Test net output #0: accuracy = 0.878793
I0522 18:55:13.044220 12554 solver.cpp:409]     Test net output #1: loss = 0.385035 (* 1 = 0.385035 loss)
I0522 18:55:33.964259 12554 solver.cpp:237] Iteration 60000, loss = 1.03667
I0522 18:55:33.964311 12554 solver.cpp:253]     Train net output #0: loss = 1.03667 (* 1 = 1.03667 loss)
I0522 18:55:33.964326 12554 sgd_solver.cpp:106] Iteration 60000, lr = 0.002
I0522 18:55:43.775393 12554 solver.cpp:237] Iteration 60375, loss = 1.1611
I0522 18:55:43.775548 12554 solver.cpp:253]     Train net output #0: loss = 1.1611 (* 1 = 1.1611 loss)
I0522 18:55:43.775563 12554 sgd_solver.cpp:106] Iteration 60375, lr = 0.002
I0522 18:55:53.596041 12554 solver.cpp:237] Iteration 60750, loss = 1.34406
I0522 18:55:53.596089 12554 solver.cpp:253]     Train net output #0: loss = 1.34406 (* 1 = 1.34406 loss)
I0522 18:55:53.596103 12554 sgd_solver.cpp:106] Iteration 60750, lr = 0.002
I0522 18:56:03.418118 12554 solver.cpp:237] Iteration 61125, loss = 1.24772
I0522 18:56:03.418154 12554 solver.cpp:253]     Train net output #0: loss = 1.24772 (* 1 = 1.24772 loss)
I0522 18:56:03.418170 12554 sgd_solver.cpp:106] Iteration 61125, lr = 0.002
I0522 18:56:13.235184 12554 solver.cpp:237] Iteration 61500, loss = 1.17138
I0522 18:56:13.235219 12554 solver.cpp:253]     Train net output #0: loss = 1.17138 (* 1 = 1.17138 loss)
I0522 18:56:13.235236 12554 sgd_solver.cpp:106] Iteration 61500, lr = 0.002
I0522 18:56:23.060528 12554 solver.cpp:237] Iteration 61875, loss = 1.23742
I0522 18:56:23.060701 12554 solver.cpp:253]     Train net output #0: loss = 1.23742 (* 1 = 1.23742 loss)
I0522 18:56:23.060715 12554 sgd_solver.cpp:106] Iteration 61875, lr = 0.002
I0522 18:56:32.877604 12554 solver.cpp:237] Iteration 62250, loss = 1.06647
I0522 18:56:32.877638 12554 solver.cpp:253]     Train net output #0: loss = 1.06647 (* 1 = 1.06647 loss)
I0522 18:56:32.877656 12554 sgd_solver.cpp:106] Iteration 62250, lr = 0.002
I0522 18:57:03.644177 12554 solver.cpp:237] Iteration 62625, loss = 1.07523
I0522 18:57:03.644356 12554 solver.cpp:253]     Train net output #0: loss = 1.07523 (* 1 = 1.07523 loss)
I0522 18:57:03.644371 12554 sgd_solver.cpp:106] Iteration 62625, lr = 0.002
I0522 18:57:13.462149 12554 solver.cpp:237] Iteration 63000, loss = 0.702918
I0522 18:57:13.462196 12554 solver.cpp:253]     Train net output #0: loss = 0.702918 (* 1 = 0.702918 loss)
I0522 18:57:13.462213 12554 sgd_solver.cpp:106] Iteration 63000, lr = 0.002
I0522 18:57:23.278415 12554 solver.cpp:237] Iteration 63375, loss = 1.19428
I0522 18:57:23.278451 12554 solver.cpp:253]     Train net output #0: loss = 1.19428 (* 1 = 1.19428 loss)
I0522 18:57:23.278468 12554 sgd_solver.cpp:106] Iteration 63375, lr = 0.002
I0522 18:57:33.077512 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_63750.caffemodel
I0522 18:57:33.133815 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_63750.solverstate
I0522 18:57:33.168674 12554 solver.cpp:237] Iteration 63750, loss = 0.814267
I0522 18:57:33.168720 12554 solver.cpp:253]     Train net output #0: loss = 0.814267 (* 1 = 0.814267 loss)
I0522 18:57:33.168735 12554 sgd_solver.cpp:106] Iteration 63750, lr = 0.002
I0522 18:57:42.990643 12554 solver.cpp:237] Iteration 64125, loss = 1.23143
I0522 18:57:42.990808 12554 solver.cpp:253]     Train net output #0: loss = 1.23143 (* 1 = 1.23143 loss)
I0522 18:57:42.990823 12554 sgd_solver.cpp:106] Iteration 64125, lr = 0.002
I0522 18:57:52.808084 12554 solver.cpp:237] Iteration 64500, loss = 1.12488
I0522 18:57:52.808118 12554 solver.cpp:253]     Train net output #0: loss = 1.12488 (* 1 = 1.12488 loss)
I0522 18:57:52.808135 12554 sgd_solver.cpp:106] Iteration 64500, lr = 0.002
I0522 18:58:02.624737 12554 solver.cpp:237] Iteration 64875, loss = 0.94509
I0522 18:58:02.624776 12554 solver.cpp:253]     Train net output #0: loss = 0.945091 (* 1 = 0.945091 loss)
I0522 18:58:02.624797 12554 sgd_solver.cpp:106] Iteration 64875, lr = 0.002
I0522 18:58:33.367578 12554 solver.cpp:237] Iteration 65250, loss = 1.44992
I0522 18:58:33.367761 12554 solver.cpp:253]     Train net output #0: loss = 1.44992 (* 1 = 1.44992 loss)
I0522 18:58:33.367777 12554 sgd_solver.cpp:106] Iteration 65250, lr = 0.002
I0522 18:58:43.187798 12554 solver.cpp:237] Iteration 65625, loss = 1.50814
I0522 18:58:43.187834 12554 solver.cpp:253]     Train net output #0: loss = 1.50814 (* 1 = 1.50814 loss)
I0522 18:58:43.187851 12554 sgd_solver.cpp:106] Iteration 65625, lr = 0.002
I0522 18:58:53.006850 12554 solver.cpp:237] Iteration 66000, loss = 0.860847
I0522 18:58:53.006897 12554 solver.cpp:253]     Train net output #0: loss = 0.860847 (* 1 = 0.860847 loss)
I0522 18:58:53.006913 12554 sgd_solver.cpp:106] Iteration 66000, lr = 0.002
I0522 18:59:02.825800 12554 solver.cpp:237] Iteration 66375, loss = 1.25607
I0522 18:59:02.825836 12554 solver.cpp:253]     Train net output #0: loss = 1.25607 (* 1 = 1.25607 loss)
I0522 18:59:02.825853 12554 sgd_solver.cpp:106] Iteration 66375, lr = 0.002
I0522 18:59:12.641816 12554 solver.cpp:237] Iteration 66750, loss = 1.18377
I0522 18:59:12.641993 12554 solver.cpp:253]     Train net output #0: loss = 1.18377 (* 1 = 1.18377 loss)
I0522 18:59:12.642006 12554 sgd_solver.cpp:106] Iteration 66750, lr = 0.002
I0522 18:59:22.463062 12554 solver.cpp:237] Iteration 67125, loss = 1.27278
I0522 18:59:22.463096 12554 solver.cpp:253]     Train net output #0: loss = 1.27278 (* 1 = 1.27278 loss)
I0522 18:59:22.463114 12554 sgd_solver.cpp:106] Iteration 67125, lr = 0.002
I0522 18:59:32.254293 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_67500.caffemodel
I0522 18:59:32.310104 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_67500.solverstate
I0522 18:59:32.336818 12554 solver.cpp:341] Iteration 67500, Testing net (#0)
I0522 19:00:20.861466 12554 solver.cpp:409]     Test net output #0: accuracy = 0.87958
I0522 19:00:20.861631 12554 solver.cpp:409]     Test net output #1: loss = 0.399761 (* 1 = 0.399761 loss)
I0522 19:00:41.740294 12554 solver.cpp:237] Iteration 67500, loss = 1.11479
I0522 19:00:41.740346 12554 solver.cpp:253]     Train net output #0: loss = 1.11479 (* 1 = 1.11479 loss)
I0522 19:00:41.740361 12554 sgd_solver.cpp:106] Iteration 67500, lr = 0.002
I0522 19:00:51.491817 12554 solver.cpp:237] Iteration 67875, loss = 1.21089
I0522 19:00:51.491971 12554 solver.cpp:253]     Train net output #0: loss = 1.21089 (* 1 = 1.21089 loss)
I0522 19:00:51.491986 12554 sgd_solver.cpp:106] Iteration 67875, lr = 0.002
I0522 19:01:01.243180 12554 solver.cpp:237] Iteration 68250, loss = 1.38892
I0522 19:01:01.243222 12554 solver.cpp:253]     Train net output #0: loss = 1.38892 (* 1 = 1.38892 loss)
I0522 19:01:01.243242 12554 sgd_solver.cpp:106] Iteration 68250, lr = 0.002
I0522 19:01:10.991339 12554 solver.cpp:237] Iteration 68625, loss = 1.05928
I0522 19:01:10.991376 12554 solver.cpp:253]     Train net output #0: loss = 1.05928 (* 1 = 1.05928 loss)
I0522 19:01:10.991394 12554 sgd_solver.cpp:106] Iteration 68625, lr = 0.002
I0522 19:01:20.742090 12554 solver.cpp:237] Iteration 69000, loss = 1.17441
I0522 19:01:20.742137 12554 solver.cpp:253]     Train net output #0: loss = 1.17441 (* 1 = 1.17441 loss)
I0522 19:01:20.742152 12554 sgd_solver.cpp:106] Iteration 69000, lr = 0.002
I0522 19:01:30.489675 12554 solver.cpp:237] Iteration 69375, loss = 1.27998
I0522 19:01:30.489838 12554 solver.cpp:253]     Train net output #0: loss = 1.27998 (* 1 = 1.27998 loss)
I0522 19:01:30.489852 12554 sgd_solver.cpp:106] Iteration 69375, lr = 0.002
I0522 19:01:40.238525 12554 solver.cpp:237] Iteration 69750, loss = 0.97803
I0522 19:01:40.238560 12554 solver.cpp:253]     Train net output #0: loss = 0.97803 (* 1 = 0.97803 loss)
I0522 19:01:40.238579 12554 sgd_solver.cpp:106] Iteration 69750, lr = 0.002
I0522 19:02:10.879360 12554 solver.cpp:237] Iteration 70125, loss = 1.21237
I0522 19:02:10.879540 12554 solver.cpp:253]     Train net output #0: loss = 1.21237 (* 1 = 1.21237 loss)
I0522 19:02:10.879556 12554 sgd_solver.cpp:106] Iteration 70125, lr = 0.002
I0522 19:02:20.626440 12554 solver.cpp:237] Iteration 70500, loss = 1.09154
I0522 19:02:20.626473 12554 solver.cpp:253]     Train net output #0: loss = 1.09155 (* 1 = 1.09155 loss)
I0522 19:02:20.626492 12554 sgd_solver.cpp:106] Iteration 70500, lr = 0.002
I0522 19:02:30.375614 12554 solver.cpp:237] Iteration 70875, loss = 1.28707
I0522 19:02:30.375655 12554 solver.cpp:253]     Train net output #0: loss = 1.28707 (* 1 = 1.28707 loss)
I0522 19:02:30.375669 12554 sgd_solver.cpp:106] Iteration 70875, lr = 0.002
I0522 19:02:40.096238 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_71250.caffemodel
I0522 19:02:40.154644 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_71250.solverstate
I0522 19:02:40.191975 12554 solver.cpp:237] Iteration 71250, loss = 1.30192
I0522 19:02:40.192025 12554 solver.cpp:253]     Train net output #0: loss = 1.30192 (* 1 = 1.30192 loss)
I0522 19:02:40.192042 12554 sgd_solver.cpp:106] Iteration 71250, lr = 0.002
I0522 19:02:49.941201 12554 solver.cpp:237] Iteration 71625, loss = 1.10223
I0522 19:02:49.941357 12554 solver.cpp:253]     Train net output #0: loss = 1.10223 (* 1 = 1.10223 loss)
I0522 19:02:49.941371 12554 sgd_solver.cpp:106] Iteration 71625, lr = 0.002
I0522 19:02:59.692673 12554 solver.cpp:237] Iteration 72000, loss = 1.60992
I0522 19:02:59.692723 12554 solver.cpp:253]     Train net output #0: loss = 1.60992 (* 1 = 1.60992 loss)
I0522 19:02:59.692739 12554 sgd_solver.cpp:106] Iteration 72000, lr = 0.002
I0522 19:03:09.434201 12554 solver.cpp:237] Iteration 72375, loss = 1.1851
I0522 19:03:09.434237 12554 solver.cpp:253]     Train net output #0: loss = 1.1851 (* 1 = 1.1851 loss)
I0522 19:03:09.434249 12554 sgd_solver.cpp:106] Iteration 72375, lr = 0.002
I0522 19:03:40.074988 12554 solver.cpp:237] Iteration 72750, loss = 1.21849
I0522 19:03:40.075166 12554 solver.cpp:253]     Train net output #0: loss = 1.21849 (* 1 = 1.21849 loss)
I0522 19:03:40.075182 12554 sgd_solver.cpp:106] Iteration 72750, lr = 0.002
I0522 19:03:49.823987 12554 solver.cpp:237] Iteration 73125, loss = 1.399
I0522 19:03:49.824030 12554 solver.cpp:253]     Train net output #0: loss = 1.399 (* 1 = 1.399 loss)
I0522 19:03:49.824049 12554 sgd_solver.cpp:106] Iteration 73125, lr = 0.002
I0522 19:03:59.573313 12554 solver.cpp:237] Iteration 73500, loss = 1.25885
I0522 19:03:59.573349 12554 solver.cpp:253]     Train net output #0: loss = 1.25885 (* 1 = 1.25885 loss)
I0522 19:03:59.573362 12554 sgd_solver.cpp:106] Iteration 73500, lr = 0.002
I0522 19:04:09.317709 12554 solver.cpp:237] Iteration 73875, loss = 1.3512
I0522 19:04:09.317745 12554 solver.cpp:253]     Train net output #0: loss = 1.3512 (* 1 = 1.3512 loss)
I0522 19:04:09.317762 12554 sgd_solver.cpp:106] Iteration 73875, lr = 0.002
I0522 19:04:19.063926 12554 solver.cpp:237] Iteration 74250, loss = 1.22722
I0522 19:04:19.064098 12554 solver.cpp:253]     Train net output #0: loss = 1.22722 (* 1 = 1.22722 loss)
I0522 19:04:19.064112 12554 sgd_solver.cpp:106] Iteration 74250, lr = 0.002
I0522 19:04:28.809168 12554 solver.cpp:237] Iteration 74625, loss = 1.47616
I0522 19:04:28.809203 12554 solver.cpp:253]     Train net output #0: loss = 1.47616 (* 1 = 1.47616 loss)
I0522 19:04:28.809221 12554 sgd_solver.cpp:106] Iteration 74625, lr = 0.002
I0522 19:04:38.528209 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_75000.caffemodel
I0522 19:04:38.586374 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_75000.solverstate
I0522 19:04:38.615417 12554 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 19:05:48.035120 12554 solver.cpp:409]     Test net output #0: accuracy = 0.874053
I0522 19:05:48.035302 12554 solver.cpp:409]     Test net output #1: loss = 0.399859 (* 1 = 0.399859 loss)
I0522 19:06:08.905650 12554 solver.cpp:237] Iteration 75000, loss = 1.19785
I0522 19:06:08.905704 12554 solver.cpp:253]     Train net output #0: loss = 1.19785 (* 1 = 1.19785 loss)
I0522 19:06:08.905720 12554 sgd_solver.cpp:106] Iteration 75000, lr = 0.002
I0522 19:06:18.758237 12554 solver.cpp:237] Iteration 75375, loss = 1.19006
I0522 19:06:18.758405 12554 solver.cpp:253]     Train net output #0: loss = 1.19006 (* 1 = 1.19006 loss)
I0522 19:06:18.758419 12554 sgd_solver.cpp:106] Iteration 75375, lr = 0.002
I0522 19:06:28.615851 12554 solver.cpp:237] Iteration 75750, loss = 1.3109
I0522 19:06:28.615886 12554 solver.cpp:253]     Train net output #0: loss = 1.3109 (* 1 = 1.3109 loss)
I0522 19:06:28.615903 12554 sgd_solver.cpp:106] Iteration 75750, lr = 0.002
I0522 19:06:38.475200 12554 solver.cpp:237] Iteration 76125, loss = 1.36527
I0522 19:06:38.475237 12554 solver.cpp:253]     Train net output #0: loss = 1.36527 (* 1 = 1.36527 loss)
I0522 19:06:38.475252 12554 sgd_solver.cpp:106] Iteration 76125, lr = 0.002
I0522 19:06:48.329730 12554 solver.cpp:237] Iteration 76500, loss = 1.16423
I0522 19:06:48.329768 12554 solver.cpp:253]     Train net output #0: loss = 1.16423 (* 1 = 1.16423 loss)
I0522 19:06:48.329789 12554 sgd_solver.cpp:106] Iteration 76500, lr = 0.002
I0522 19:06:58.185540 12554 solver.cpp:237] Iteration 76875, loss = 1.19774
I0522 19:06:58.185695 12554 solver.cpp:253]     Train net output #0: loss = 1.19774 (* 1 = 1.19774 loss)
I0522 19:06:58.185709 12554 sgd_solver.cpp:106] Iteration 76875, lr = 0.002
I0522 19:07:08.044119 12554 solver.cpp:237] Iteration 77250, loss = 1.2831
I0522 19:07:08.044165 12554 solver.cpp:253]     Train net output #0: loss = 1.2831 (* 1 = 1.2831 loss)
I0522 19:07:08.044183 12554 sgd_solver.cpp:106] Iteration 77250, lr = 0.002
I0522 19:07:38.759341 12554 solver.cpp:237] Iteration 77625, loss = 1.5559
I0522 19:07:38.759516 12554 solver.cpp:253]     Train net output #0: loss = 1.5559 (* 1 = 1.5559 loss)
I0522 19:07:38.759531 12554 sgd_solver.cpp:106] Iteration 77625, lr = 0.002
I0522 19:07:48.614497 12554 solver.cpp:237] Iteration 78000, loss = 0.77918
I0522 19:07:48.614533 12554 solver.cpp:253]     Train net output #0: loss = 0.77918 (* 1 = 0.77918 loss)
I0522 19:07:48.614549 12554 sgd_solver.cpp:106] Iteration 78000, lr = 0.002
I0522 19:07:58.462716 12554 solver.cpp:237] Iteration 78375, loss = 1.70704
I0522 19:07:58.462759 12554 solver.cpp:253]     Train net output #0: loss = 1.70704 (* 1 = 1.70704 loss)
I0522 19:07:58.462777 12554 sgd_solver.cpp:106] Iteration 78375, lr = 0.002
I0522 19:08:08.295100 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_78750.caffemodel
I0522 19:08:08.355882 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_78750.solverstate
I0522 19:08:08.390439 12554 solver.cpp:237] Iteration 78750, loss = 1.09061
I0522 19:08:08.390486 12554 solver.cpp:253]     Train net output #0: loss = 1.09061 (* 1 = 1.09061 loss)
I0522 19:08:08.390501 12554 sgd_solver.cpp:106] Iteration 78750, lr = 0.002
I0522 19:08:18.254427 12554 solver.cpp:237] Iteration 79125, loss = 1.25775
I0522 19:08:18.254598 12554 solver.cpp:253]     Train net output #0: loss = 1.25775 (* 1 = 1.25775 loss)
I0522 19:08:18.254612 12554 sgd_solver.cpp:106] Iteration 79125, lr = 0.002
I0522 19:08:28.117861 12554 solver.cpp:237] Iteration 79500, loss = 1.56786
I0522 19:08:28.117900 12554 solver.cpp:253]     Train net output #0: loss = 1.56786 (* 1 = 1.56786 loss)
I0522 19:08:28.117921 12554 sgd_solver.cpp:106] Iteration 79500, lr = 0.002
I0522 19:08:37.982235 12554 solver.cpp:237] Iteration 79875, loss = 1.32944
I0522 19:08:37.982271 12554 solver.cpp:253]     Train net output #0: loss = 1.32944 (* 1 = 1.32944 loss)
I0522 19:08:37.982287 12554 sgd_solver.cpp:106] Iteration 79875, lr = 0.002
I0522 19:09:08.730226 12554 solver.cpp:237] Iteration 80250, loss = 1.13859
I0522 19:09:08.730409 12554 solver.cpp:253]     Train net output #0: loss = 1.13859 (* 1 = 1.13859 loss)
I0522 19:09:08.730424 12554 sgd_solver.cpp:106] Iteration 80250, lr = 0.002
I0522 19:09:18.595978 12554 solver.cpp:237] Iteration 80625, loss = 1.05917
I0522 19:09:18.596022 12554 solver.cpp:253]     Train net output #0: loss = 1.05917 (* 1 = 1.05917 loss)
I0522 19:09:18.596038 12554 sgd_solver.cpp:106] Iteration 80625, lr = 0.002
I0522 19:09:28.454203 12554 solver.cpp:237] Iteration 81000, loss = 1.41782
I0522 19:09:28.454239 12554 solver.cpp:253]     Train net output #0: loss = 1.41782 (* 1 = 1.41782 loss)
I0522 19:09:28.454257 12554 sgd_solver.cpp:106] Iteration 81000, lr = 0.002
I0522 19:09:38.314417 12554 solver.cpp:237] Iteration 81375, loss = 1.53445
I0522 19:09:38.314465 12554 solver.cpp:253]     Train net output #0: loss = 1.53445 (* 1 = 1.53445 loss)
I0522 19:09:38.314477 12554 sgd_solver.cpp:106] Iteration 81375, lr = 0.002
I0522 19:09:48.172657 12554 solver.cpp:237] Iteration 81750, loss = 1.15009
I0522 19:09:48.172816 12554 solver.cpp:253]     Train net output #0: loss = 1.15009 (* 1 = 1.15009 loss)
I0522 19:09:48.172829 12554 sgd_solver.cpp:106] Iteration 81750, lr = 0.002
I0522 19:09:58.030732 12554 solver.cpp:237] Iteration 82125, loss = 1.10411
I0522 19:09:58.030766 12554 solver.cpp:253]     Train net output #0: loss = 1.10411 (* 1 = 1.10411 loss)
I0522 19:09:58.030784 12554 sgd_solver.cpp:106] Iteration 82125, lr = 0.002
I0522 19:10:07.864506 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_82500.caffemodel
I0522 19:10:07.922992 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_82500.solverstate
I0522 19:10:07.949576 12554 solver.cpp:341] Iteration 82500, Testing net (#0)
I0522 19:10:56.122550 12554 solver.cpp:409]     Test net output #0: accuracy = 0.884286
I0522 19:10:56.122735 12554 solver.cpp:409]     Test net output #1: loss = 0.368791 (* 1 = 0.368791 loss)
I0522 19:11:17.028193 12554 solver.cpp:237] Iteration 82500, loss = 1.04659
I0522 19:11:17.028249 12554 solver.cpp:253]     Train net output #0: loss = 1.04659 (* 1 = 1.04659 loss)
I0522 19:11:17.028262 12554 sgd_solver.cpp:106] Iteration 82500, lr = 0.002
I0522 19:11:26.933128 12554 solver.cpp:237] Iteration 82875, loss = 1.34125
I0522 19:11:26.933290 12554 solver.cpp:253]     Train net output #0: loss = 1.34125 (* 1 = 1.34125 loss)
I0522 19:11:26.933305 12554 sgd_solver.cpp:106] Iteration 82875, lr = 0.002
I0522 19:11:36.842999 12554 solver.cpp:237] Iteration 83250, loss = 1.19672
I0522 19:11:36.843034 12554 solver.cpp:253]     Train net output #0: loss = 1.19672 (* 1 = 1.19672 loss)
I0522 19:11:36.843051 12554 sgd_solver.cpp:106] Iteration 83250, lr = 0.002
I0522 19:11:46.755007 12554 solver.cpp:237] Iteration 83625, loss = 1.06273
I0522 19:11:46.755049 12554 solver.cpp:253]     Train net output #0: loss = 1.06273 (* 1 = 1.06273 loss)
I0522 19:11:46.755069 12554 sgd_solver.cpp:106] Iteration 83625, lr = 0.002
I0522 19:11:56.665799 12554 solver.cpp:237] Iteration 84000, loss = 1.0386
I0522 19:11:56.665834 12554 solver.cpp:253]     Train net output #0: loss = 1.0386 (* 1 = 1.0386 loss)
I0522 19:11:56.665848 12554 sgd_solver.cpp:106] Iteration 84000, lr = 0.002
I0522 19:12:06.568169 12554 solver.cpp:237] Iteration 84375, loss = 1.30908
I0522 19:12:06.568338 12554 solver.cpp:253]     Train net output #0: loss = 1.30908 (* 1 = 1.30908 loss)
I0522 19:12:06.568352 12554 sgd_solver.cpp:106] Iteration 84375, lr = 0.002
I0522 19:12:16.473917 12554 solver.cpp:237] Iteration 84750, loss = 1.24825
I0522 19:12:16.473961 12554 solver.cpp:253]     Train net output #0: loss = 1.24825 (* 1 = 1.24825 loss)
I0522 19:12:16.473976 12554 sgd_solver.cpp:106] Iteration 84750, lr = 0.002
I0522 19:12:47.276669 12554 solver.cpp:237] Iteration 85125, loss = 1.16798
I0522 19:12:47.276849 12554 solver.cpp:253]     Train net output #0: loss = 1.16798 (* 1 = 1.16798 loss)
I0522 19:12:47.276865 12554 sgd_solver.cpp:106] Iteration 85125, lr = 0.002
I0522 19:12:57.184172 12554 solver.cpp:237] Iteration 85500, loss = 0.900626
I0522 19:12:57.184219 12554 solver.cpp:253]     Train net output #0: loss = 0.900626 (* 1 = 0.900626 loss)
I0522 19:12:57.184239 12554 sgd_solver.cpp:106] Iteration 85500, lr = 0.002
I0522 19:13:07.091085 12554 solver.cpp:237] Iteration 85875, loss = 1.25747
I0522 19:13:07.091121 12554 solver.cpp:253]     Train net output #0: loss = 1.25747 (* 1 = 1.25747 loss)
I0522 19:13:07.091137 12554 sgd_solver.cpp:106] Iteration 85875, lr = 0.002
I0522 19:13:16.971072 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_86250.caffemodel
I0522 19:13:17.027454 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_86250.solverstate
I0522 19:13:17.061969 12554 solver.cpp:237] Iteration 86250, loss = 1.01166
I0522 19:13:17.062010 12554 solver.cpp:253]     Train net output #0: loss = 1.01166 (* 1 = 1.01166 loss)
I0522 19:13:17.062031 12554 sgd_solver.cpp:106] Iteration 86250, lr = 0.002
I0522 19:13:26.981235 12554 solver.cpp:237] Iteration 86625, loss = 1.04351
I0522 19:13:26.981410 12554 solver.cpp:253]     Train net output #0: loss = 1.04351 (* 1 = 1.04351 loss)
I0522 19:13:26.981423 12554 sgd_solver.cpp:106] Iteration 86625, lr = 0.002
I0522 19:13:36.881484 12554 solver.cpp:237] Iteration 87000, loss = 1.13924
I0522 19:13:36.881518 12554 solver.cpp:253]     Train net output #0: loss = 1.13924 (* 1 = 1.13924 loss)
I0522 19:13:36.881537 12554 sgd_solver.cpp:106] Iteration 87000, lr = 0.002
I0522 19:13:46.794020 12554 solver.cpp:237] Iteration 87375, loss = 1.2761
I0522 19:13:46.794070 12554 solver.cpp:253]     Train net output #0: loss = 1.2761 (* 1 = 1.2761 loss)
I0522 19:13:46.794087 12554 sgd_solver.cpp:106] Iteration 87375, lr = 0.002
I0522 19:14:17.598829 12554 solver.cpp:237] Iteration 87750, loss = 1.37507
I0522 19:14:17.599005 12554 solver.cpp:253]     Train net output #0: loss = 1.37507 (* 1 = 1.37507 loss)
I0522 19:14:17.599020 12554 sgd_solver.cpp:106] Iteration 87750, lr = 0.002
I0522 19:14:27.511168 12554 solver.cpp:237] Iteration 88125, loss = 0.901093
I0522 19:14:27.511204 12554 solver.cpp:253]     Train net output #0: loss = 0.901093 (* 1 = 0.901093 loss)
I0522 19:14:27.511221 12554 sgd_solver.cpp:106] Iteration 88125, lr = 0.002
I0522 19:14:37.415725 12554 solver.cpp:237] Iteration 88500, loss = 1.43354
I0522 19:14:37.415767 12554 solver.cpp:253]     Train net output #0: loss = 1.43354 (* 1 = 1.43354 loss)
I0522 19:14:37.415786 12554 sgd_solver.cpp:106] Iteration 88500, lr = 0.002
I0522 19:14:47.333668 12554 solver.cpp:237] Iteration 88875, loss = 0.554192
I0522 19:14:47.333705 12554 solver.cpp:253]     Train net output #0: loss = 0.554193 (* 1 = 0.554193 loss)
I0522 19:14:47.333721 12554 sgd_solver.cpp:106] Iteration 88875, lr = 0.002
I0522 19:14:57.244182 12554 solver.cpp:237] Iteration 89250, loss = 1.37863
I0522 19:14:57.244360 12554 solver.cpp:253]     Train net output #0: loss = 1.37863 (* 1 = 1.37863 loss)
I0522 19:14:57.244374 12554 sgd_solver.cpp:106] Iteration 89250, lr = 0.002
I0522 19:15:07.153049 12554 solver.cpp:237] Iteration 89625, loss = 1.01004
I0522 19:15:07.153097 12554 solver.cpp:253]     Train net output #0: loss = 1.01004 (* 1 = 1.01004 loss)
I0522 19:15:07.153115 12554 sgd_solver.cpp:106] Iteration 89625, lr = 0.002
I0522 19:15:17.041316 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_90000.caffemodel
I0522 19:15:17.098393 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_90000.solverstate
I0522 19:15:17.124910 12554 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 19:16:26.514554 12554 solver.cpp:409]     Test net output #0: accuracy = 0.88356
I0522 19:16:26.514734 12554 solver.cpp:409]     Test net output #1: loss = 0.37382 (* 1 = 0.37382 loss)
I0522 19:16:47.373646 12554 solver.cpp:237] Iteration 90000, loss = 0.951984
I0522 19:16:47.373699 12554 solver.cpp:253]     Train net output #0: loss = 0.951984 (* 1 = 0.951984 loss)
I0522 19:16:47.373715 12554 sgd_solver.cpp:106] Iteration 90000, lr = 0.002
I0522 19:16:57.191376 12554 solver.cpp:237] Iteration 90375, loss = 1.00902
I0522 19:16:57.191541 12554 solver.cpp:253]     Train net output #0: loss = 1.00902 (* 1 = 1.00902 loss)
I0522 19:16:57.191555 12554 sgd_solver.cpp:106] Iteration 90375, lr = 0.002
I0522 19:17:07.006441 12554 solver.cpp:237] Iteration 90750, loss = 1.21116
I0522 19:17:07.006487 12554 solver.cpp:253]     Train net output #0: loss = 1.21116 (* 1 = 1.21116 loss)
I0522 19:17:07.006502 12554 sgd_solver.cpp:106] Iteration 90750, lr = 0.002
I0522 19:17:16.826926 12554 solver.cpp:237] Iteration 91125, loss = 1.20313
I0522 19:17:16.826962 12554 solver.cpp:253]     Train net output #0: loss = 1.20313 (* 1 = 1.20313 loss)
I0522 19:17:16.826978 12554 sgd_solver.cpp:106] Iteration 91125, lr = 0.002
I0522 19:17:26.641990 12554 solver.cpp:237] Iteration 91500, loss = 1.22933
I0522 19:17:26.642026 12554 solver.cpp:253]     Train net output #0: loss = 1.22934 (* 1 = 1.22934 loss)
I0522 19:17:26.642040 12554 sgd_solver.cpp:106] Iteration 91500, lr = 0.002
I0522 19:17:36.467141 12554 solver.cpp:237] Iteration 91875, loss = 1.0034
I0522 19:17:36.467321 12554 solver.cpp:253]     Train net output #0: loss = 1.0034 (* 1 = 1.0034 loss)
I0522 19:17:36.467335 12554 sgd_solver.cpp:106] Iteration 91875, lr = 0.002
I0522 19:17:46.290567 12554 solver.cpp:237] Iteration 92250, loss = 1.12052
I0522 19:17:46.290601 12554 solver.cpp:253]     Train net output #0: loss = 1.12052 (* 1 = 1.12052 loss)
I0522 19:17:46.290619 12554 sgd_solver.cpp:106] Iteration 92250, lr = 0.002
I0522 19:18:16.988999 12554 solver.cpp:237] Iteration 92625, loss = 1.08649
I0522 19:18:16.989181 12554 solver.cpp:253]     Train net output #0: loss = 1.08649 (* 1 = 1.08649 loss)
I0522 19:18:16.989197 12554 sgd_solver.cpp:106] Iteration 92625, lr = 0.002
I0522 19:18:26.804311 12554 solver.cpp:237] Iteration 93000, loss = 1.13666
I0522 19:18:26.804357 12554 solver.cpp:253]     Train net output #0: loss = 1.13666 (* 1 = 1.13666 loss)
I0522 19:18:26.804374 12554 sgd_solver.cpp:106] Iteration 93000, lr = 0.002
I0522 19:18:36.619132 12554 solver.cpp:237] Iteration 93375, loss = 1.04598
I0522 19:18:36.619166 12554 solver.cpp:253]     Train net output #0: loss = 1.04598 (* 1 = 1.04598 loss)
I0522 19:18:36.619184 12554 sgd_solver.cpp:106] Iteration 93375, lr = 0.002
I0522 19:18:46.412986 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_93750.caffemodel
I0522 19:18:46.470686 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_93750.solverstate
I0522 19:18:46.507710 12554 solver.cpp:237] Iteration 93750, loss = 1.67649
I0522 19:18:46.507757 12554 solver.cpp:253]     Train net output #0: loss = 1.67649 (* 1 = 1.67649 loss)
I0522 19:18:46.507774 12554 sgd_solver.cpp:106] Iteration 93750, lr = 0.002
I0522 19:18:56.326292 12554 solver.cpp:237] Iteration 94125, loss = 1.25035
I0522 19:18:56.326486 12554 solver.cpp:253]     Train net output #0: loss = 1.25035 (* 1 = 1.25035 loss)
I0522 19:18:56.326501 12554 sgd_solver.cpp:106] Iteration 94125, lr = 0.002
I0522 19:19:06.144666 12554 solver.cpp:237] Iteration 94500, loss = 0.974931
I0522 19:19:06.144702 12554 solver.cpp:253]     Train net output #0: loss = 0.974931 (* 1 = 0.974931 loss)
I0522 19:19:06.144719 12554 sgd_solver.cpp:106] Iteration 94500, lr = 0.002
I0522 19:19:15.964069 12554 solver.cpp:237] Iteration 94875, loss = 1.24352
I0522 19:19:15.964117 12554 solver.cpp:253]     Train net output #0: loss = 1.24352 (* 1 = 1.24352 loss)
I0522 19:19:15.964134 12554 sgd_solver.cpp:106] Iteration 94875, lr = 0.002
I0522 19:19:46.647809 12554 solver.cpp:237] Iteration 95250, loss = 1.06402
I0522 19:19:46.647992 12554 solver.cpp:253]     Train net output #0: loss = 1.06402 (* 1 = 1.06402 loss)
I0522 19:19:46.648008 12554 sgd_solver.cpp:106] Iteration 95250, lr = 0.002
I0522 19:19:56.467138 12554 solver.cpp:237] Iteration 95625, loss = 1.27145
I0522 19:19:56.467172 12554 solver.cpp:253]     Train net output #0: loss = 1.27145 (* 1 = 1.27145 loss)
I0522 19:19:56.467190 12554 sgd_solver.cpp:106] Iteration 95625, lr = 0.002
I0522 19:20:06.281030 12554 solver.cpp:237] Iteration 96000, loss = 1.2953
I0522 19:20:06.281077 12554 solver.cpp:253]     Train net output #0: loss = 1.2953 (* 1 = 1.2953 loss)
I0522 19:20:06.281093 12554 sgd_solver.cpp:106] Iteration 96000, lr = 0.002
I0522 19:20:16.095348 12554 solver.cpp:237] Iteration 96375, loss = 1.16901
I0522 19:20:16.095384 12554 solver.cpp:253]     Train net output #0: loss = 1.16901 (* 1 = 1.16901 loss)
I0522 19:20:16.095402 12554 sgd_solver.cpp:106] Iteration 96375, lr = 0.002
I0522 19:20:25.911178 12554 solver.cpp:237] Iteration 96750, loss = 1.33618
I0522 19:20:25.911339 12554 solver.cpp:253]     Train net output #0: loss = 1.33618 (* 1 = 1.33618 loss)
I0522 19:20:25.911352 12554 sgd_solver.cpp:106] Iteration 96750, lr = 0.002
I0522 19:20:35.738689 12554 solver.cpp:237] Iteration 97125, loss = 1.01913
I0522 19:20:35.738736 12554 solver.cpp:253]     Train net output #0: loss = 1.01913 (* 1 = 1.01913 loss)
I0522 19:20:35.738754 12554 sgd_solver.cpp:106] Iteration 97125, lr = 0.002
I0522 19:20:45.523679 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_97500.caffemodel
I0522 19:20:45.579666 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_97500.solverstate
I0522 19:20:45.606183 12554 solver.cpp:341] Iteration 97500, Testing net (#0)
I0522 19:21:34.124357 12554 solver.cpp:409]     Test net output #0: accuracy = 0.8851
I0522 19:21:34.124536 12554 solver.cpp:409]     Test net output #1: loss = 0.36068 (* 1 = 0.36068 loss)
I0522 19:21:55.004432 12554 solver.cpp:237] Iteration 97500, loss = 1.01932
I0522 19:21:55.004485 12554 solver.cpp:253]     Train net output #0: loss = 1.01932 (* 1 = 1.01932 loss)
I0522 19:21:55.004500 12554 sgd_solver.cpp:106] Iteration 97500, lr = 0.002
I0522 19:22:04.758888 12554 solver.cpp:237] Iteration 97875, loss = 1.02705
I0522 19:22:04.759075 12554 solver.cpp:253]     Train net output #0: loss = 1.02705 (* 1 = 1.02705 loss)
I0522 19:22:04.759089 12554 sgd_solver.cpp:106] Iteration 97875, lr = 0.002
I0522 19:22:14.506862 12554 solver.cpp:237] Iteration 98250, loss = 1.21459
I0522 19:22:14.506911 12554 solver.cpp:253]     Train net output #0: loss = 1.21459 (* 1 = 1.21459 loss)
I0522 19:22:14.506928 12554 sgd_solver.cpp:106] Iteration 98250, lr = 0.002
I0522 19:22:24.257483 12554 solver.cpp:237] Iteration 98625, loss = 1.02733
I0522 19:22:24.257517 12554 solver.cpp:253]     Train net output #0: loss = 1.02733 (* 1 = 1.02733 loss)
I0522 19:22:24.257535 12554 sgd_solver.cpp:106] Iteration 98625, lr = 0.002
I0522 19:22:34.011957 12554 solver.cpp:237] Iteration 99000, loss = 1.20191
I0522 19:22:34.012006 12554 solver.cpp:253]     Train net output #0: loss = 1.20191 (* 1 = 1.20191 loss)
I0522 19:22:34.012020 12554 sgd_solver.cpp:106] Iteration 99000, lr = 0.002
I0522 19:22:43.763012 12554 solver.cpp:237] Iteration 99375, loss = 1.019
I0522 19:22:43.763177 12554 solver.cpp:253]     Train net output #0: loss = 1.019 (* 1 = 1.019 loss)
I0522 19:22:43.763190 12554 sgd_solver.cpp:106] Iteration 99375, lr = 0.002
I0522 19:22:53.506927 12554 solver.cpp:237] Iteration 99750, loss = 1.00248
I0522 19:22:53.506960 12554 solver.cpp:253]     Train net output #0: loss = 1.00248 (* 1 = 1.00248 loss)
I0522 19:22:53.506978 12554 sgd_solver.cpp:106] Iteration 99750, lr = 0.002
I0522 19:23:24.138226 12554 solver.cpp:237] Iteration 100125, loss = 1.15598
I0522 19:23:24.138411 12554 solver.cpp:253]     Train net output #0: loss = 1.15598 (* 1 = 1.15598 loss)
I0522 19:23:24.138427 12554 sgd_solver.cpp:106] Iteration 100125, lr = 0.002
I0522 19:23:33.877434 12554 solver.cpp:237] Iteration 100500, loss = 0.754247
I0522 19:23:33.877470 12554 solver.cpp:253]     Train net output #0: loss = 0.754247 (* 1 = 0.754247 loss)
I0522 19:23:33.877485 12554 sgd_solver.cpp:106] Iteration 100500, lr = 0.002
I0522 19:23:43.622565 12554 solver.cpp:237] Iteration 100875, loss = 1.30021
I0522 19:23:43.622601 12554 solver.cpp:253]     Train net output #0: loss = 1.30021 (* 1 = 1.30021 loss)
I0522 19:23:43.622618 12554 sgd_solver.cpp:106] Iteration 100875, lr = 0.002
I0522 19:23:53.338738 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_101250.caffemodel
I0522 19:23:53.394575 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_101250.solverstate
I0522 19:23:53.428735 12554 solver.cpp:237] Iteration 101250, loss = 1.01934
I0522 19:23:53.428773 12554 solver.cpp:253]     Train net output #0: loss = 1.01934 (* 1 = 1.01934 loss)
I0522 19:23:53.428797 12554 sgd_solver.cpp:106] Iteration 101250, lr = 0.002
I0522 19:24:03.178617 12554 solver.cpp:237] Iteration 101625, loss = 1.10921
I0522 19:24:03.178782 12554 solver.cpp:253]     Train net output #0: loss = 1.10921 (* 1 = 1.10921 loss)
I0522 19:24:03.178797 12554 sgd_solver.cpp:106] Iteration 101625, lr = 0.002
I0522 19:24:12.929956 12554 solver.cpp:237] Iteration 102000, loss = 1.06422
I0522 19:24:12.930003 12554 solver.cpp:253]     Train net output #0: loss = 1.06422 (* 1 = 1.06422 loss)
I0522 19:24:12.930017 12554 sgd_solver.cpp:106] Iteration 102000, lr = 0.002
I0522 19:24:22.677899 12554 solver.cpp:237] Iteration 102375, loss = 1.13864
I0522 19:24:22.677935 12554 solver.cpp:253]     Train net output #0: loss = 1.13864 (* 1 = 1.13864 loss)
I0522 19:24:22.677952 12554 sgd_solver.cpp:106] Iteration 102375, lr = 0.002
I0522 19:24:53.328814 12554 solver.cpp:237] Iteration 102750, loss = 1.18446
I0522 19:24:53.328999 12554 solver.cpp:253]     Train net output #0: loss = 1.18446 (* 1 = 1.18446 loss)
I0522 19:24:53.329015 12554 sgd_solver.cpp:106] Iteration 102750, lr = 0.002
I0522 19:25:03.071859 12554 solver.cpp:237] Iteration 103125, loss = 1.57255
I0522 19:25:03.071908 12554 solver.cpp:253]     Train net output #0: loss = 1.57255 (* 1 = 1.57255 loss)
I0522 19:25:03.071924 12554 sgd_solver.cpp:106] Iteration 103125, lr = 0.002
I0522 19:25:12.817657 12554 solver.cpp:237] Iteration 103500, loss = 1.16826
I0522 19:25:12.817693 12554 solver.cpp:253]     Train net output #0: loss = 1.16826 (* 1 = 1.16826 loss)
I0522 19:25:12.817710 12554 sgd_solver.cpp:106] Iteration 103500, lr = 0.002
I0522 19:25:22.568647 12554 solver.cpp:237] Iteration 103875, loss = 1.22749
I0522 19:25:22.568682 12554 solver.cpp:253]     Train net output #0: loss = 1.22749 (* 1 = 1.22749 loss)
I0522 19:25:22.568698 12554 sgd_solver.cpp:106] Iteration 103875, lr = 0.002
I0522 19:25:32.317792 12554 solver.cpp:237] Iteration 104250, loss = 1.18702
I0522 19:25:32.317977 12554 solver.cpp:253]     Train net output #0: loss = 1.18702 (* 1 = 1.18702 loss)
I0522 19:25:32.317991 12554 sgd_solver.cpp:106] Iteration 104250, lr = 0.002
I0522 19:25:42.067672 12554 solver.cpp:237] Iteration 104625, loss = 1.18467
I0522 19:25:42.067708 12554 solver.cpp:253]     Train net output #0: loss = 1.18467 (* 1 = 1.18467 loss)
I0522 19:25:42.067724 12554 sgd_solver.cpp:106] Iteration 104625, lr = 0.002
I0522 19:25:51.794343 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_105000.caffemodel
I0522 19:25:51.849763 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_105000.solverstate
I0522 19:25:51.875301 12554 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 19:27:01.266103 12554 solver.cpp:409]     Test net output #0: accuracy = 0.886666
I0522 19:27:01.266296 12554 solver.cpp:409]     Test net output #1: loss = 0.364702 (* 1 = 0.364702 loss)
I0522 19:27:22.124811 12554 solver.cpp:237] Iteration 105000, loss = 0.945957
I0522 19:27:22.124866 12554 solver.cpp:253]     Train net output #0: loss = 0.945957 (* 1 = 0.945957 loss)
I0522 19:27:22.124881 12554 sgd_solver.cpp:106] Iteration 105000, lr = 0.002
I0522 19:27:31.974550 12554 solver.cpp:237] Iteration 105375, loss = 1.05212
I0522 19:27:31.974723 12554 solver.cpp:253]     Train net output #0: loss = 1.05212 (* 1 = 1.05212 loss)
I0522 19:27:31.974737 12554 sgd_solver.cpp:106] Iteration 105375, lr = 0.002
I0522 19:27:41.831029 12554 solver.cpp:237] Iteration 105750, loss = 0.996391
I0522 19:27:41.831065 12554 solver.cpp:253]     Train net output #0: loss = 0.996391 (* 1 = 0.996391 loss)
I0522 19:27:41.831082 12554 sgd_solver.cpp:106] Iteration 105750, lr = 0.002
I0522 19:27:51.681900 12554 solver.cpp:237] Iteration 106125, loss = 1.31635
I0522 19:27:51.681936 12554 solver.cpp:253]     Train net output #0: loss = 1.31635 (* 1 = 1.31635 loss)
I0522 19:27:51.681951 12554 sgd_solver.cpp:106] Iteration 106125, lr = 0.002
I0522 19:28:01.534592 12554 solver.cpp:237] Iteration 106500, loss = 0.952581
I0522 19:28:01.534641 12554 solver.cpp:253]     Train net output #0: loss = 0.952582 (* 1 = 0.952582 loss)
I0522 19:28:01.534657 12554 sgd_solver.cpp:106] Iteration 106500, lr = 0.002
I0522 19:28:11.394666 12554 solver.cpp:237] Iteration 106875, loss = 1.18986
I0522 19:28:11.394829 12554 solver.cpp:253]     Train net output #0: loss = 1.18986 (* 1 = 1.18986 loss)
I0522 19:28:11.394842 12554 sgd_solver.cpp:106] Iteration 106875, lr = 0.002
I0522 19:28:21.247330 12554 solver.cpp:237] Iteration 107250, loss = 1.12157
I0522 19:28:21.247365 12554 solver.cpp:253]     Train net output #0: loss = 1.12157 (* 1 = 1.12157 loss)
I0522 19:28:21.247382 12554 sgd_solver.cpp:106] Iteration 107250, lr = 0.002
I0522 19:28:51.970618 12554 solver.cpp:237] Iteration 107625, loss = 1.18329
I0522 19:28:51.970800 12554 solver.cpp:253]     Train net output #0: loss = 1.18329 (* 1 = 1.18329 loss)
I0522 19:28:51.970816 12554 sgd_solver.cpp:106] Iteration 107625, lr = 0.002
I0522 19:29:01.823333 12554 solver.cpp:237] Iteration 108000, loss = 1.24824
I0522 19:29:01.823369 12554 solver.cpp:253]     Train net output #0: loss = 1.24824 (* 1 = 1.24824 loss)
I0522 19:29:01.823386 12554 sgd_solver.cpp:106] Iteration 108000, lr = 0.002
I0522 19:29:11.675055 12554 solver.cpp:237] Iteration 108375, loss = 1.02441
I0522 19:29:11.675091 12554 solver.cpp:253]     Train net output #0: loss = 1.02441 (* 1 = 1.02441 loss)
I0522 19:29:11.675107 12554 sgd_solver.cpp:106] Iteration 108375, lr = 0.002
I0522 19:29:21.515460 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_108750.caffemodel
I0522 19:29:21.574498 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_108750.solverstate
I0522 19:29:21.610638 12554 solver.cpp:237] Iteration 108750, loss = 1.2368
I0522 19:29:21.610689 12554 solver.cpp:253]     Train net output #0: loss = 1.2368 (* 1 = 1.2368 loss)
I0522 19:29:21.610703 12554 sgd_solver.cpp:106] Iteration 108750, lr = 0.002
I0522 19:29:31.464239 12554 solver.cpp:237] Iteration 109125, loss = 1.28064
I0522 19:29:31.464418 12554 solver.cpp:253]     Train net output #0: loss = 1.28064 (* 1 = 1.28064 loss)
I0522 19:29:31.464432 12554 sgd_solver.cpp:106] Iteration 109125, lr = 0.002
I0522 19:29:41.319496 12554 solver.cpp:237] Iteration 109500, loss = 1.34823
I0522 19:29:41.319545 12554 solver.cpp:253]     Train net output #0: loss = 1.34823 (* 1 = 1.34823 loss)
I0522 19:29:41.319562 12554 sgd_solver.cpp:106] Iteration 109500, lr = 0.002
I0522 19:29:51.177716 12554 solver.cpp:237] Iteration 109875, loss = 1.06427
I0522 19:29:51.177752 12554 solver.cpp:253]     Train net output #0: loss = 1.06427 (* 1 = 1.06427 loss)
I0522 19:29:51.177768 12554 sgd_solver.cpp:106] Iteration 109875, lr = 0.002
I0522 19:30:21.914564 12554 solver.cpp:237] Iteration 110250, loss = 1.04273
I0522 19:30:21.914752 12554 solver.cpp:253]     Train net output #0: loss = 1.04273 (* 1 = 1.04273 loss)
I0522 19:30:21.914767 12554 sgd_solver.cpp:106] Iteration 110250, lr = 0.002
I0522 19:30:31.769410 12554 solver.cpp:237] Iteration 110625, loss = 1.35792
I0522 19:30:31.769449 12554 solver.cpp:253]     Train net output #0: loss = 1.35792 (* 1 = 1.35792 loss)
I0522 19:30:31.769472 12554 sgd_solver.cpp:106] Iteration 110625, lr = 0.002
I0522 19:30:41.620174 12554 solver.cpp:237] Iteration 111000, loss = 1.31033
I0522 19:30:41.620210 12554 solver.cpp:253]     Train net output #0: loss = 1.31033 (* 1 = 1.31033 loss)
I0522 19:30:41.620223 12554 sgd_solver.cpp:106] Iteration 111000, lr = 0.002
I0522 19:30:51.481056 12554 solver.cpp:237] Iteration 111375, loss = 0.981403
I0522 19:30:51.481093 12554 solver.cpp:253]     Train net output #0: loss = 0.981404 (* 1 = 0.981404 loss)
I0522 19:30:51.481106 12554 sgd_solver.cpp:106] Iteration 111375, lr = 0.002
I0522 19:31:01.334231 12554 solver.cpp:237] Iteration 111750, loss = 0.949478
I0522 19:31:01.334408 12554 solver.cpp:253]     Train net output #0: loss = 0.949479 (* 1 = 0.949479 loss)
I0522 19:31:01.334421 12554 sgd_solver.cpp:106] Iteration 111750, lr = 0.002
I0522 19:31:11.195365 12554 solver.cpp:237] Iteration 112125, loss = 1.57983
I0522 19:31:11.195400 12554 solver.cpp:253]     Train net output #0: loss = 1.57983 (* 1 = 1.57983 loss)
I0522 19:31:11.195418 12554 sgd_solver.cpp:106] Iteration 112125, lr = 0.002
I0522 19:31:21.014322 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_112500.caffemodel
I0522 19:31:21.073204 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_112500.solverstate
I0522 19:31:21.101024 12554 solver.cpp:341] Iteration 112500, Testing net (#0)
I0522 19:32:09.236282 12554 solver.cpp:409]     Test net output #0: accuracy = 0.891373
I0522 19:32:09.236475 12554 solver.cpp:409]     Test net output #1: loss = 0.367046 (* 1 = 0.367046 loss)
I0522 19:32:30.105943 12554 solver.cpp:237] Iteration 112500, loss = 1.06851
I0522 19:32:30.105998 12554 solver.cpp:253]     Train net output #0: loss = 1.06851 (* 1 = 1.06851 loss)
I0522 19:32:30.106012 12554 sgd_solver.cpp:106] Iteration 112500, lr = 0.002
I0522 19:32:39.818892 12554 solver.cpp:237] Iteration 112875, loss = 1.26052
I0522 19:32:39.819072 12554 solver.cpp:253]     Train net output #0: loss = 1.26052 (* 1 = 1.26052 loss)
I0522 19:32:39.819085 12554 sgd_solver.cpp:106] Iteration 112875, lr = 0.002
I0522 19:32:49.521522 12554 solver.cpp:237] Iteration 113250, loss = 1.80012
I0522 19:32:49.521558 12554 solver.cpp:253]     Train net output #0: loss = 1.80012 (* 1 = 1.80012 loss)
I0522 19:32:49.521574 12554 sgd_solver.cpp:106] Iteration 113250, lr = 0.002
I0522 19:32:59.216789 12554 solver.cpp:237] Iteration 113625, loss = 1.46825
I0522 19:32:59.216831 12554 solver.cpp:253]     Train net output #0: loss = 1.46825 (* 1 = 1.46825 loss)
I0522 19:32:59.216850 12554 sgd_solver.cpp:106] Iteration 113625, lr = 0.002
I0522 19:33:08.910820 12554 solver.cpp:237] Iteration 114000, loss = 1.35576
I0522 19:33:08.910856 12554 solver.cpp:253]     Train net output #0: loss = 1.35576 (* 1 = 1.35576 loss)
I0522 19:33:08.910871 12554 sgd_solver.cpp:106] Iteration 114000, lr = 0.002
I0522 19:33:18.604392 12554 solver.cpp:237] Iteration 114375, loss = 1.10033
I0522 19:33:18.604557 12554 solver.cpp:253]     Train net output #0: loss = 1.10033 (* 1 = 1.10033 loss)
I0522 19:33:18.604570 12554 sgd_solver.cpp:106] Iteration 114375, lr = 0.002
I0522 19:33:28.296304 12554 solver.cpp:237] Iteration 114750, loss = 1.10137
I0522 19:33:28.296349 12554 solver.cpp:253]     Train net output #0: loss = 1.10137 (* 1 = 1.10137 loss)
I0522 19:33:28.296366 12554 sgd_solver.cpp:106] Iteration 114750, lr = 0.002
I0522 19:33:58.865180 12554 solver.cpp:237] Iteration 115125, loss = 1.23873
I0522 19:33:58.865365 12554 solver.cpp:253]     Train net output #0: loss = 1.23873 (* 1 = 1.23873 loss)
I0522 19:33:58.865381 12554 sgd_solver.cpp:106] Iteration 115125, lr = 0.002
I0522 19:34:08.556174 12554 solver.cpp:237] Iteration 115500, loss = 1.11761
I0522 19:34:08.556210 12554 solver.cpp:253]     Train net output #0: loss = 1.11761 (* 1 = 1.11761 loss)
I0522 19:34:08.556223 12554 sgd_solver.cpp:106] Iteration 115500, lr = 0.002
I0522 19:34:18.245398 12554 solver.cpp:237] Iteration 115875, loss = 1.53798
I0522 19:34:18.245437 12554 solver.cpp:253]     Train net output #0: loss = 1.53798 (* 1 = 1.53798 loss)
I0522 19:34:18.245456 12554 sgd_solver.cpp:106] Iteration 115875, lr = 0.002
I0522 19:34:27.911366 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_116250.caffemodel
I0522 19:34:27.967039 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_116250.solverstate
I0522 19:34:28.001184 12554 solver.cpp:237] Iteration 116250, loss = 1.1788
I0522 19:34:28.001230 12554 solver.cpp:253]     Train net output #0: loss = 1.1788 (* 1 = 1.1788 loss)
I0522 19:34:28.001245 12554 sgd_solver.cpp:106] Iteration 116250, lr = 0.002
I0522 19:34:37.695292 12554 solver.cpp:237] Iteration 116625, loss = 1.25085
I0522 19:34:37.695487 12554 solver.cpp:253]     Train net output #0: loss = 1.25085 (* 1 = 1.25085 loss)
I0522 19:34:37.695502 12554 sgd_solver.cpp:106] Iteration 116625, lr = 0.002
I0522 19:34:47.386622 12554 solver.cpp:237] Iteration 117000, loss = 0.963635
I0522 19:34:47.386658 12554 solver.cpp:253]     Train net output #0: loss = 0.963636 (* 1 = 0.963636 loss)
I0522 19:34:47.386675 12554 sgd_solver.cpp:106] Iteration 117000, lr = 0.002
I0522 19:34:57.078578 12554 solver.cpp:237] Iteration 117375, loss = 1.31125
I0522 19:34:57.078614 12554 solver.cpp:253]     Train net output #0: loss = 1.31125 (* 1 = 1.31125 loss)
I0522 19:34:57.078629 12554 sgd_solver.cpp:106] Iteration 117375, lr = 0.002
I0522 19:35:27.644722 12554 solver.cpp:237] Iteration 117750, loss = 1.15898
I0522 19:35:27.644918 12554 solver.cpp:253]     Train net output #0: loss = 1.15898 (* 1 = 1.15898 loss)
I0522 19:35:27.644934 12554 sgd_solver.cpp:106] Iteration 117750, lr = 0.002
I0522 19:35:37.361626 12554 solver.cpp:237] Iteration 118125, loss = 1.22363
I0522 19:35:37.361661 12554 solver.cpp:253]     Train net output #0: loss = 1.22363 (* 1 = 1.22363 loss)
I0522 19:35:37.361676 12554 sgd_solver.cpp:106] Iteration 118125, lr = 0.002
I0522 19:35:47.073379 12554 solver.cpp:237] Iteration 118500, loss = 1.40105
I0522 19:35:47.073415 12554 solver.cpp:253]     Train net output #0: loss = 1.40105 (* 1 = 1.40105 loss)
I0522 19:35:47.073429 12554 sgd_solver.cpp:106] Iteration 118500, lr = 0.002
I0522 19:35:56.793117 12554 solver.cpp:237] Iteration 118875, loss = 1.12538
I0522 19:35:56.793155 12554 solver.cpp:253]     Train net output #0: loss = 1.12538 (* 1 = 1.12538 loss)
I0522 19:35:56.793177 12554 sgd_solver.cpp:106] Iteration 118875, lr = 0.002
I0522 19:36:06.520053 12554 solver.cpp:237] Iteration 119250, loss = 1.39579
I0522 19:36:06.520221 12554 solver.cpp:253]     Train net output #0: loss = 1.39579 (* 1 = 1.39579 loss)
I0522 19:36:06.520236 12554 sgd_solver.cpp:106] Iteration 119250, lr = 0.002
I0522 19:36:16.239188 12554 solver.cpp:237] Iteration 119625, loss = 1.01852
I0522 19:36:16.239223 12554 solver.cpp:253]     Train net output #0: loss = 1.01852 (* 1 = 1.01852 loss)
I0522 19:36:16.239241 12554 sgd_solver.cpp:106] Iteration 119625, lr = 0.002
I0522 19:36:25.928555 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_120000.caffemodel
I0522 19:36:25.984644 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_120000.solverstate
I0522 19:36:26.010284 12554 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 19:37:35.408344 12554 solver.cpp:409]     Test net output #0: accuracy = 0.890413
I0522 19:37:35.408538 12554 solver.cpp:409]     Test net output #1: loss = 0.345213 (* 1 = 0.345213 loss)
I0522 19:37:56.285317 12554 solver.cpp:237] Iteration 120000, loss = 0.958675
I0522 19:37:56.285372 12554 solver.cpp:253]     Train net output #0: loss = 0.958675 (* 1 = 0.958675 loss)
I0522 19:37:56.285387 12554 sgd_solver.cpp:106] Iteration 120000, lr = 0.002
I0522 19:38:06.012387 12554 solver.cpp:237] Iteration 120375, loss = 1.30495
I0522 19:38:06.012569 12554 solver.cpp:253]     Train net output #0: loss = 1.30495 (* 1 = 1.30495 loss)
I0522 19:38:06.012583 12554 sgd_solver.cpp:106] Iteration 120375, lr = 0.002
I0522 19:38:15.736677 12554 solver.cpp:237] Iteration 120750, loss = 1.12285
I0522 19:38:15.736712 12554 solver.cpp:253]     Train net output #0: loss = 1.12285 (* 1 = 1.12285 loss)
I0522 19:38:15.736729 12554 sgd_solver.cpp:106] Iteration 120750, lr = 0.002
I0522 19:38:25.453694 12554 solver.cpp:237] Iteration 121125, loss = 1.21019
I0522 19:38:25.453743 12554 solver.cpp:253]     Train net output #0: loss = 1.21019 (* 1 = 1.21019 loss)
I0522 19:38:25.453761 12554 sgd_solver.cpp:106] Iteration 121125, lr = 0.002
I0522 19:38:35.169199 12554 solver.cpp:237] Iteration 121500, loss = 1.26411
I0522 19:38:35.169235 12554 solver.cpp:253]     Train net output #0: loss = 1.26411 (* 1 = 1.26411 loss)
I0522 19:38:35.169251 12554 sgd_solver.cpp:106] Iteration 121500, lr = 0.002
I0522 19:38:44.887930 12554 solver.cpp:237] Iteration 121875, loss = 1.11972
I0522 19:38:44.888110 12554 solver.cpp:253]     Train net output #0: loss = 1.11972 (* 1 = 1.11972 loss)
I0522 19:38:44.888123 12554 sgd_solver.cpp:106] Iteration 121875, lr = 0.002
I0522 19:38:54.603333 12554 solver.cpp:237] Iteration 122250, loss = 1.17986
I0522 19:38:54.603375 12554 solver.cpp:253]     Train net output #0: loss = 1.17986 (* 1 = 1.17986 loss)
I0522 19:38:54.603390 12554 sgd_solver.cpp:106] Iteration 122250, lr = 0.002
I0522 19:39:25.187547 12554 solver.cpp:237] Iteration 122625, loss = 1.14367
I0522 19:39:25.187750 12554 solver.cpp:253]     Train net output #0: loss = 1.14367 (* 1 = 1.14367 loss)
I0522 19:39:25.187767 12554 sgd_solver.cpp:106] Iteration 122625, lr = 0.002
I0522 19:39:34.894584 12554 solver.cpp:237] Iteration 123000, loss = 1.01977
I0522 19:39:34.894618 12554 solver.cpp:253]     Train net output #0: loss = 1.01977 (* 1 = 1.01977 loss)
I0522 19:39:34.894637 12554 sgd_solver.cpp:106] Iteration 123000, lr = 0.002
I0522 19:39:44.612068 12554 solver.cpp:237] Iteration 123375, loss = 1.576
I0522 19:39:44.612113 12554 solver.cpp:253]     Train net output #0: loss = 1.576 (* 1 = 1.576 loss)
I0522 19:39:44.612128 12554 sgd_solver.cpp:106] Iteration 123375, lr = 0.002
I0522 19:39:54.299289 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_123750.caffemodel
I0522 19:39:54.355690 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_123750.solverstate
I0522 19:39:54.389775 12554 solver.cpp:237] Iteration 123750, loss = 1.21069
I0522 19:39:54.389819 12554 solver.cpp:253]     Train net output #0: loss = 1.21069 (* 1 = 1.21069 loss)
I0522 19:39:54.389833 12554 sgd_solver.cpp:106] Iteration 123750, lr = 0.002
I0522 19:40:04.112642 12554 solver.cpp:237] Iteration 124125, loss = 1.17996
I0522 19:40:04.112828 12554 solver.cpp:253]     Train net output #0: loss = 1.17996 (* 1 = 1.17996 loss)
I0522 19:40:04.112843 12554 sgd_solver.cpp:106] Iteration 124125, lr = 0.002
I0522 19:40:13.815016 12554 solver.cpp:237] Iteration 124500, loss = 1.16896
I0522 19:40:13.815050 12554 solver.cpp:253]     Train net output #0: loss = 1.16897 (* 1 = 1.16897 loss)
I0522 19:40:13.815069 12554 sgd_solver.cpp:106] Iteration 124500, lr = 0.002
I0522 19:40:23.516037 12554 solver.cpp:237] Iteration 124875, loss = 0.953988
I0522 19:40:23.516069 12554 solver.cpp:253]     Train net output #0: loss = 0.953988 (* 1 = 0.953988 loss)
I0522 19:40:23.516083 12554 sgd_solver.cpp:106] Iteration 124875, lr = 0.002
I0522 19:40:54.143651 12554 solver.cpp:237] Iteration 125250, loss = 1.55122
I0522 19:40:54.143841 12554 solver.cpp:253]     Train net output #0: loss = 1.55122 (* 1 = 1.55122 loss)
I0522 19:40:54.143857 12554 sgd_solver.cpp:106] Iteration 125250, lr = 0.002
I0522 19:41:03.841639 12554 solver.cpp:237] Iteration 125625, loss = 1.13788
I0522 19:41:03.841675 12554 solver.cpp:253]     Train net output #0: loss = 1.13788 (* 1 = 1.13788 loss)
I0522 19:41:03.841688 12554 sgd_solver.cpp:106] Iteration 125625, lr = 0.002
I0522 19:41:13.536540 12554 solver.cpp:237] Iteration 126000, loss = 1.04502
I0522 19:41:13.536576 12554 solver.cpp:253]     Train net output #0: loss = 1.04502 (* 1 = 1.04502 loss)
I0522 19:41:13.536592 12554 sgd_solver.cpp:106] Iteration 126000, lr = 0.002
I0522 19:41:23.237958 12554 solver.cpp:237] Iteration 126375, loss = 1.06341
I0522 19:41:23.238003 12554 solver.cpp:253]     Train net output #0: loss = 1.06341 (* 1 = 1.06341 loss)
I0522 19:41:23.238018 12554 sgd_solver.cpp:106] Iteration 126375, lr = 0.002
I0522 19:41:32.942275 12554 solver.cpp:237] Iteration 126750, loss = 0.74343
I0522 19:41:32.942441 12554 solver.cpp:253]     Train net output #0: loss = 0.743431 (* 1 = 0.743431 loss)
I0522 19:41:32.942456 12554 sgd_solver.cpp:106] Iteration 126750, lr = 0.002
I0522 19:41:42.647908 12554 solver.cpp:237] Iteration 127125, loss = 1.0533
I0522 19:41:42.647954 12554 solver.cpp:253]     Train net output #0: loss = 1.0533 (* 1 = 1.0533 loss)
I0522 19:41:42.647969 12554 sgd_solver.cpp:106] Iteration 127125, lr = 0.002
I0522 19:41:52.315762 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_127500.caffemodel
I0522 19:41:52.371706 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_127500.solverstate
I0522 19:41:52.397364 12554 solver.cpp:341] Iteration 127500, Testing net (#0)
I0522 19:42:41.027438 12554 solver.cpp:409]     Test net output #0: accuracy = 0.889913
I0522 19:42:41.027631 12554 solver.cpp:409]     Test net output #1: loss = 0.34878 (* 1 = 0.34878 loss)
I0522 19:43:01.962435 12554 solver.cpp:237] Iteration 127500, loss = 0.996556
I0522 19:43:01.962489 12554 solver.cpp:253]     Train net output #0: loss = 0.996556 (* 1 = 0.996556 loss)
I0522 19:43:01.962505 12554 sgd_solver.cpp:106] Iteration 127500, lr = 0.002
I0522 19:43:11.841912 12554 solver.cpp:237] Iteration 127875, loss = 0.961055
I0522 19:43:11.842089 12554 solver.cpp:253]     Train net output #0: loss = 0.961056 (* 1 = 0.961056 loss)
I0522 19:43:11.842103 12554 sgd_solver.cpp:106] Iteration 127875, lr = 0.002
I0522 19:43:21.716181 12554 solver.cpp:237] Iteration 128250, loss = 1.50891
I0522 19:43:21.716214 12554 solver.cpp:253]     Train net output #0: loss = 1.50891 (* 1 = 1.50891 loss)
I0522 19:43:21.716233 12554 sgd_solver.cpp:106] Iteration 128250, lr = 0.002
I0522 19:43:31.595903 12554 solver.cpp:237] Iteration 128625, loss = 1.13548
I0522 19:43:31.595942 12554 solver.cpp:253]     Train net output #0: loss = 1.13548 (* 1 = 1.13548 loss)
I0522 19:43:31.595964 12554 sgd_solver.cpp:106] Iteration 128625, lr = 0.002
I0522 19:43:41.475106 12554 solver.cpp:237] Iteration 129000, loss = 1.28361
I0522 19:43:41.475142 12554 solver.cpp:253]     Train net output #0: loss = 1.28361 (* 1 = 1.28361 loss)
I0522 19:43:41.475158 12554 sgd_solver.cpp:106] Iteration 129000, lr = 0.002
I0522 19:43:51.355370 12554 solver.cpp:237] Iteration 129375, loss = 1.04459
I0522 19:43:51.355553 12554 solver.cpp:253]     Train net output #0: loss = 1.04459 (* 1 = 1.04459 loss)
I0522 19:43:51.355567 12554 sgd_solver.cpp:106] Iteration 129375, lr = 0.002
I0522 19:44:01.238587 12554 solver.cpp:237] Iteration 129750, loss = 1.26493
I0522 19:44:01.238623 12554 solver.cpp:253]     Train net output #0: loss = 1.26493 (* 1 = 1.26493 loss)
I0522 19:44:01.238641 12554 sgd_solver.cpp:106] Iteration 129750, lr = 0.002
I0522 19:44:32.039417 12554 solver.cpp:237] Iteration 130125, loss = 1.23418
I0522 19:44:32.039609 12554 solver.cpp:253]     Train net output #0: loss = 1.23418 (* 1 = 1.23418 loss)
I0522 19:44:32.039625 12554 sgd_solver.cpp:106] Iteration 130125, lr = 0.002
I0522 19:44:41.912093 12554 solver.cpp:237] Iteration 130500, loss = 0.841424
I0522 19:44:41.912137 12554 solver.cpp:253]     Train net output #0: loss = 0.841424 (* 1 = 0.841424 loss)
I0522 19:44:41.912154 12554 sgd_solver.cpp:106] Iteration 130500, lr = 0.002
I0522 19:44:51.794103 12554 solver.cpp:237] Iteration 130875, loss = 0.991913
I0522 19:44:51.794138 12554 solver.cpp:253]     Train net output #0: loss = 0.991914 (* 1 = 0.991914 loss)
I0522 19:44:51.794157 12554 sgd_solver.cpp:106] Iteration 130875, lr = 0.002
I0522 19:45:01.649060 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_131250.caffemodel
I0522 19:45:01.709003 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_131250.solverstate
I0522 19:45:01.755241 12554 solver.cpp:237] Iteration 131250, loss = 1.26648
I0522 19:45:01.755291 12554 solver.cpp:253]     Train net output #0: loss = 1.26648 (* 1 = 1.26648 loss)
I0522 19:45:01.755306 12554 sgd_solver.cpp:106] Iteration 131250, lr = 0.002
I0522 19:45:11.626310 12554 solver.cpp:237] Iteration 131625, loss = 1.10177
I0522 19:45:11.626497 12554 solver.cpp:253]     Train net output #0: loss = 1.10177 (* 1 = 1.10177 loss)
I0522 19:45:11.626510 12554 sgd_solver.cpp:106] Iteration 131625, lr = 0.002
I0522 19:45:21.501255 12554 solver.cpp:237] Iteration 132000, loss = 1.03612
I0522 19:45:21.501289 12554 solver.cpp:253]     Train net output #0: loss = 1.03612 (* 1 = 1.03612 loss)
I0522 19:45:21.501303 12554 sgd_solver.cpp:106] Iteration 132000, lr = 0.002
I0522 19:45:31.378078 12554 solver.cpp:237] Iteration 132375, loss = 1.07146
I0522 19:45:31.378129 12554 solver.cpp:253]     Train net output #0: loss = 1.07146 (* 1 = 1.07146 loss)
I0522 19:45:31.378144 12554 sgd_solver.cpp:106] Iteration 132375, lr = 0.002
I0522 19:46:02.116045 12554 solver.cpp:237] Iteration 132750, loss = 0.836035
I0522 19:46:02.116238 12554 solver.cpp:253]     Train net output #0: loss = 0.836035 (* 1 = 0.836035 loss)
I0522 19:46:02.116255 12554 sgd_solver.cpp:106] Iteration 132750, lr = 0.002
I0522 19:46:11.997901 12554 solver.cpp:237] Iteration 133125, loss = 1.03874
I0522 19:46:11.997936 12554 solver.cpp:253]     Train net output #0: loss = 1.03874 (* 1 = 1.03874 loss)
I0522 19:46:11.997954 12554 sgd_solver.cpp:106] Iteration 133125, lr = 0.002
I0522 19:46:21.881077 12554 solver.cpp:237] Iteration 133500, loss = 1.01326
I0522 19:46:21.881121 12554 solver.cpp:253]     Train net output #0: loss = 1.01326 (* 1 = 1.01326 loss)
I0522 19:46:21.881139 12554 sgd_solver.cpp:106] Iteration 133500, lr = 0.002
I0522 19:46:31.767001 12554 solver.cpp:237] Iteration 133875, loss = 1.4666
I0522 19:46:31.767038 12554 solver.cpp:253]     Train net output #0: loss = 1.4666 (* 1 = 1.4666 loss)
I0522 19:46:31.767050 12554 sgd_solver.cpp:106] Iteration 133875, lr = 0.002
I0522 19:46:41.637498 12554 solver.cpp:237] Iteration 134250, loss = 1.21737
I0522 19:46:41.637667 12554 solver.cpp:253]     Train net output #0: loss = 1.21738 (* 1 = 1.21738 loss)
I0522 19:46:41.637681 12554 sgd_solver.cpp:106] Iteration 134250, lr = 0.002
I0522 19:46:51.440917 12554 solver.cpp:237] Iteration 134625, loss = 0.830153
I0522 19:46:51.440963 12554 solver.cpp:253]     Train net output #0: loss = 0.830153 (* 1 = 0.830153 loss)
I0522 19:46:51.440978 12554 sgd_solver.cpp:106] Iteration 134625, lr = 0.002
I0522 19:47:01.223839 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_135000.caffemodel
I0522 19:47:01.282815 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_135000.solverstate
I0522 19:47:01.314198 12554 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 19:48:10.659520 12554 solver.cpp:409]     Test net output #0: accuracy = 0.893225
I0522 19:48:10.659716 12554 solver.cpp:409]     Test net output #1: loss = 0.334356 (* 1 = 0.334356 loss)
I0522 19:48:31.549221 12554 solver.cpp:237] Iteration 135000, loss = 1.10227
I0522 19:48:31.549274 12554 solver.cpp:253]     Train net output #0: loss = 1.10227 (* 1 = 1.10227 loss)
I0522 19:48:31.549288 12554 sgd_solver.cpp:106] Iteration 135000, lr = 0.002
I0522 19:48:41.445842 12554 solver.cpp:237] Iteration 135375, loss = 1.18915
I0522 19:48:41.446019 12554 solver.cpp:253]     Train net output #0: loss = 1.18915 (* 1 = 1.18915 loss)
I0522 19:48:41.446033 12554 sgd_solver.cpp:106] Iteration 135375, lr = 0.002
I0522 19:48:51.340533 12554 solver.cpp:237] Iteration 135750, loss = 1.06219
I0522 19:48:51.340574 12554 solver.cpp:253]     Train net output #0: loss = 1.06219 (* 1 = 1.06219 loss)
I0522 19:48:51.340593 12554 sgd_solver.cpp:106] Iteration 135750, lr = 0.002
I0522 19:49:01.235288 12554 solver.cpp:237] Iteration 136125, loss = 1.04323
I0522 19:49:01.235323 12554 solver.cpp:253]     Train net output #0: loss = 1.04323 (* 1 = 1.04323 loss)
I0522 19:49:01.235342 12554 sgd_solver.cpp:106] Iteration 136125, lr = 0.002
I0522 19:49:11.131029 12554 solver.cpp:237] Iteration 136500, loss = 1.35984
I0522 19:49:11.131064 12554 solver.cpp:253]     Train net output #0: loss = 1.35984 (* 1 = 1.35984 loss)
I0522 19:49:11.131081 12554 sgd_solver.cpp:106] Iteration 136500, lr = 0.002
I0522 19:49:21.026811 12554 solver.cpp:237] Iteration 136875, loss = 0.925416
I0522 19:49:21.026996 12554 solver.cpp:253]     Train net output #0: loss = 0.925416 (* 1 = 0.925416 loss)
I0522 19:49:21.027010 12554 sgd_solver.cpp:106] Iteration 136875, lr = 0.002
I0522 19:49:30.918617 12554 solver.cpp:237] Iteration 137250, loss = 0.92008
I0522 19:49:30.918653 12554 solver.cpp:253]     Train net output #0: loss = 0.920081 (* 1 = 0.920081 loss)
I0522 19:49:30.918670 12554 sgd_solver.cpp:106] Iteration 137250, lr = 0.002
I0522 19:50:01.720304 12554 solver.cpp:237] Iteration 137625, loss = 1.05623
I0522 19:50:01.720501 12554 solver.cpp:253]     Train net output #0: loss = 1.05623 (* 1 = 1.05623 loss)
I0522 19:50:01.720516 12554 sgd_solver.cpp:106] Iteration 137625, lr = 0.002
I0522 19:50:11.616924 12554 solver.cpp:237] Iteration 138000, loss = 0.852203
I0522 19:50:11.616963 12554 solver.cpp:253]     Train net output #0: loss = 0.852203 (* 1 = 0.852203 loss)
I0522 19:50:11.616981 12554 sgd_solver.cpp:106] Iteration 138000, lr = 0.002
I0522 19:50:21.510987 12554 solver.cpp:237] Iteration 138375, loss = 1.03976
I0522 19:50:21.511023 12554 solver.cpp:253]     Train net output #0: loss = 1.03976 (* 1 = 1.03976 loss)
I0522 19:50:21.511039 12554 sgd_solver.cpp:106] Iteration 138375, lr = 0.002
I0522 19:50:31.373608 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_138750.caffemodel
I0522 19:50:31.430418 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_138750.solverstate
I0522 19:50:31.464442 12554 solver.cpp:237] Iteration 138750, loss = 1.10597
I0522 19:50:31.464481 12554 solver.cpp:253]     Train net output #0: loss = 1.10597 (* 1 = 1.10597 loss)
I0522 19:50:31.464500 12554 sgd_solver.cpp:106] Iteration 138750, lr = 0.002
I0522 19:50:41.360641 12554 solver.cpp:237] Iteration 139125, loss = 0.95289
I0522 19:50:41.360818 12554 solver.cpp:253]     Train net output #0: loss = 0.952891 (* 1 = 0.952891 loss)
I0522 19:50:41.360832 12554 sgd_solver.cpp:106] Iteration 139125, lr = 0.002
I0522 19:50:51.258404 12554 solver.cpp:237] Iteration 139500, loss = 1.0788
I0522 19:50:51.258440 12554 solver.cpp:253]     Train net output #0: loss = 1.0788 (* 1 = 1.0788 loss)
I0522 19:50:51.258456 12554 sgd_solver.cpp:106] Iteration 139500, lr = 0.002
I0522 19:51:01.154009 12554 solver.cpp:237] Iteration 139875, loss = 0.962829
I0522 19:51:01.154057 12554 solver.cpp:253]     Train net output #0: loss = 0.96283 (* 1 = 0.96283 loss)
I0522 19:51:01.154074 12554 sgd_solver.cpp:106] Iteration 139875, lr = 0.002
I0522 19:51:31.951669 12554 solver.cpp:237] Iteration 140250, loss = 1.16265
I0522 19:51:31.951864 12554 solver.cpp:253]     Train net output #0: loss = 1.16265 (* 1 = 1.16265 loss)
I0522 19:51:31.951880 12554 sgd_solver.cpp:106] Iteration 140250, lr = 0.002
I0522 19:51:41.846961 12554 solver.cpp:237] Iteration 140625, loss = 1.15185
I0522 19:51:41.847002 12554 solver.cpp:253]     Train net output #0: loss = 1.15185 (* 1 = 1.15185 loss)
I0522 19:51:41.847023 12554 sgd_solver.cpp:106] Iteration 140625, lr = 0.002
I0522 19:51:51.744249 12554 solver.cpp:237] Iteration 141000, loss = 1.00806
I0522 19:51:51.744284 12554 solver.cpp:253]     Train net output #0: loss = 1.00806 (* 1 = 1.00806 loss)
I0522 19:51:51.744299 12554 sgd_solver.cpp:106] Iteration 141000, lr = 0.002
I0522 19:52:01.637930 12554 solver.cpp:237] Iteration 141375, loss = 1.33941
I0522 19:52:01.637966 12554 solver.cpp:253]     Train net output #0: loss = 1.33942 (* 1 = 1.33942 loss)
I0522 19:52:01.637982 12554 sgd_solver.cpp:106] Iteration 141375, lr = 0.002
I0522 19:52:11.533462 12554 solver.cpp:237] Iteration 141750, loss = 1.19334
I0522 19:52:11.533656 12554 solver.cpp:253]     Train net output #0: loss = 1.19334 (* 1 = 1.19334 loss)
I0522 19:52:11.533671 12554 sgd_solver.cpp:106] Iteration 141750, lr = 0.002
I0522 19:52:21.430825 12554 solver.cpp:237] Iteration 142125, loss = 1.30909
I0522 19:52:21.430860 12554 solver.cpp:253]     Train net output #0: loss = 1.30909 (* 1 = 1.30909 loss)
I0522 19:52:21.430877 12554 sgd_solver.cpp:106] Iteration 142125, lr = 0.002
I0522 19:52:31.300585 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_142500.caffemodel
I0522 19:52:31.357372 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_142500.solverstate
I0522 19:52:31.382841 12554 solver.cpp:341] Iteration 142500, Testing net (#0)
I0522 19:53:19.622195 12554 solver.cpp:409]     Test net output #0: accuracy = 0.891014
I0522 19:53:19.622388 12554 solver.cpp:409]     Test net output #1: loss = 0.339619 (* 1 = 0.339619 loss)
I0522 19:53:40.525153 12554 solver.cpp:237] Iteration 142500, loss = 0.914959
I0522 19:53:40.525207 12554 solver.cpp:253]     Train net output #0: loss = 0.914959 (* 1 = 0.914959 loss)
I0522 19:53:40.525223 12554 sgd_solver.cpp:106] Iteration 142500, lr = 0.002
I0522 19:53:50.490562 12554 solver.cpp:237] Iteration 142875, loss = 1.19239
I0522 19:53:50.490749 12554 solver.cpp:253]     Train net output #0: loss = 1.19239 (* 1 = 1.19239 loss)
I0522 19:53:50.490764 12554 sgd_solver.cpp:106] Iteration 142875, lr = 0.002
I0522 19:54:00.448576 12554 solver.cpp:237] Iteration 143250, loss = 1.21875
I0522 19:54:00.448611 12554 solver.cpp:253]     Train net output #0: loss = 1.21876 (* 1 = 1.21876 loss)
I0522 19:54:00.448628 12554 sgd_solver.cpp:106] Iteration 143250, lr = 0.002
I0522 19:54:10.415686 12554 solver.cpp:237] Iteration 143625, loss = 1.00382
I0522 19:54:10.415721 12554 solver.cpp:253]     Train net output #0: loss = 1.00382 (* 1 = 1.00382 loss)
I0522 19:54:10.415740 12554 sgd_solver.cpp:106] Iteration 143625, lr = 0.002
I0522 19:54:20.381044 12554 solver.cpp:237] Iteration 144000, loss = 1.28019
I0522 19:54:20.381090 12554 solver.cpp:253]     Train net output #0: loss = 1.28019 (* 1 = 1.28019 loss)
I0522 19:54:20.381108 12554 sgd_solver.cpp:106] Iteration 144000, lr = 0.002
I0522 19:54:30.351604 12554 solver.cpp:237] Iteration 144375, loss = 1.07555
I0522 19:54:30.351794 12554 solver.cpp:253]     Train net output #0: loss = 1.07555 (* 1 = 1.07555 loss)
I0522 19:54:30.351807 12554 sgd_solver.cpp:106] Iteration 144375, lr = 0.002
I0522 19:54:40.314622 12554 solver.cpp:237] Iteration 144750, loss = 1.00254
I0522 19:54:40.314671 12554 solver.cpp:253]     Train net output #0: loss = 1.00254 (* 1 = 1.00254 loss)
I0522 19:54:40.314687 12554 sgd_solver.cpp:106] Iteration 144750, lr = 0.002
I0522 19:55:11.184090 12554 solver.cpp:237] Iteration 145125, loss = 1.33574
I0522 19:55:11.184288 12554 solver.cpp:253]     Train net output #0: loss = 1.33575 (* 1 = 1.33575 loss)
I0522 19:55:11.184303 12554 sgd_solver.cpp:106] Iteration 145125, lr = 0.002
I0522 19:55:21.142523 12554 solver.cpp:237] Iteration 145500, loss = 1.33108
I0522 19:55:21.142557 12554 solver.cpp:253]     Train net output #0: loss = 1.33108 (* 1 = 1.33108 loss)
I0522 19:55:21.142575 12554 sgd_solver.cpp:106] Iteration 145500, lr = 0.002
I0522 19:55:31.104260 12554 solver.cpp:237] Iteration 145875, loss = 1.25818
I0522 19:55:31.104300 12554 solver.cpp:253]     Train net output #0: loss = 1.25818 (* 1 = 1.25818 loss)
I0522 19:55:31.104321 12554 sgd_solver.cpp:106] Iteration 145875, lr = 0.002
I0522 19:55:41.048782 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_146250.caffemodel
I0522 19:55:41.105212 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_146250.solverstate
I0522 19:55:41.138553 12554 solver.cpp:237] Iteration 146250, loss = 1.14742
I0522 19:55:41.138594 12554 solver.cpp:253]     Train net output #0: loss = 1.14742 (* 1 = 1.14742 loss)
I0522 19:55:41.138612 12554 sgd_solver.cpp:106] Iteration 146250, lr = 0.002
I0522 19:55:51.096863 12554 solver.cpp:237] Iteration 146625, loss = 1.09547
I0522 19:55:51.097051 12554 solver.cpp:253]     Train net output #0: loss = 1.09547 (* 1 = 1.09547 loss)
I0522 19:55:51.097065 12554 sgd_solver.cpp:106] Iteration 146625, lr = 0.002
I0522 19:56:01.057129 12554 solver.cpp:237] Iteration 147000, loss = 1.20833
I0522 19:56:01.057173 12554 solver.cpp:253]     Train net output #0: loss = 1.20834 (* 1 = 1.20834 loss)
I0522 19:56:01.057193 12554 sgd_solver.cpp:106] Iteration 147000, lr = 0.002
I0522 19:56:11.015063 12554 solver.cpp:237] Iteration 147375, loss = 0.880443
I0522 19:56:11.015100 12554 solver.cpp:253]     Train net output #0: loss = 0.880444 (* 1 = 0.880444 loss)
I0522 19:56:11.015113 12554 sgd_solver.cpp:106] Iteration 147375, lr = 0.002
I0522 19:56:41.894961 12554 solver.cpp:237] Iteration 147750, loss = 1.23232
I0522 19:56:41.895159 12554 solver.cpp:253]     Train net output #0: loss = 1.23232 (* 1 = 1.23232 loss)
I0522 19:56:41.895174 12554 sgd_solver.cpp:106] Iteration 147750, lr = 0.002
I0522 19:56:51.860630 12554 solver.cpp:237] Iteration 148125, loss = 1.39345
I0522 19:56:51.860666 12554 solver.cpp:253]     Train net output #0: loss = 1.39345 (* 1 = 1.39345 loss)
I0522 19:56:51.860683 12554 sgd_solver.cpp:106] Iteration 148125, lr = 0.002
I0522 19:57:01.824456 12554 solver.cpp:237] Iteration 148500, loss = 1.27792
I0522 19:57:01.824492 12554 solver.cpp:253]     Train net output #0: loss = 1.27792 (* 1 = 1.27792 loss)
I0522 19:57:01.824509 12554 sgd_solver.cpp:106] Iteration 148500, lr = 0.002
I0522 19:57:11.792109 12554 solver.cpp:237] Iteration 148875, loss = 1.35682
I0522 19:57:11.792155 12554 solver.cpp:253]     Train net output #0: loss = 1.35682 (* 1 = 1.35682 loss)
I0522 19:57:11.792173 12554 sgd_solver.cpp:106] Iteration 148875, lr = 0.002
I0522 19:57:21.757755 12554 solver.cpp:237] Iteration 149250, loss = 1.20508
I0522 19:57:21.757943 12554 solver.cpp:253]     Train net output #0: loss = 1.20508 (* 1 = 1.20508 loss)
I0522 19:57:21.757957 12554 sgd_solver.cpp:106] Iteration 149250, lr = 0.002
I0522 19:57:31.719380 12554 solver.cpp:237] Iteration 149625, loss = 1.23232
I0522 19:57:31.719415 12554 solver.cpp:253]     Train net output #0: loss = 1.23232 (* 1 = 1.23232 loss)
I0522 19:57:31.719429 12554 sgd_solver.cpp:106] Iteration 149625, lr = 0.002
I0522 19:57:41.657701 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_150000.caffemodel
I0522 19:57:41.717098 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_150000.solverstate
I0522 19:57:41.745666 12554 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 19:58:51.202949 12554 solver.cpp:409]     Test net output #0: accuracy = 0.89226
I0522 19:58:51.203140 12554 solver.cpp:409]     Test net output #1: loss = 0.342123 (* 1 = 0.342123 loss)
I0522 19:59:12.112335 12554 solver.cpp:237] Iteration 150000, loss = 1.24474
I0522 19:59:12.112387 12554 solver.cpp:253]     Train net output #0: loss = 1.24474 (* 1 = 1.24474 loss)
I0522 19:59:12.112406 12554 sgd_solver.cpp:106] Iteration 150000, lr = 0.002
I0522 19:59:21.809942 12554 solver.cpp:237] Iteration 150375, loss = 1.136
I0522 19:59:21.810122 12554 solver.cpp:253]     Train net output #0: loss = 1.136 (* 1 = 1.136 loss)
I0522 19:59:21.810137 12554 sgd_solver.cpp:106] Iteration 150375, lr = 0.002
I0522 19:59:31.511539 12554 solver.cpp:237] Iteration 150750, loss = 1.25122
I0522 19:59:31.511574 12554 solver.cpp:253]     Train net output #0: loss = 1.25122 (* 1 = 1.25122 loss)
I0522 19:59:31.511592 12554 sgd_solver.cpp:106] Iteration 150750, lr = 0.002
I0522 19:59:41.211989 12554 solver.cpp:237] Iteration 151125, loss = 1.21696
I0522 19:59:41.212035 12554 solver.cpp:253]     Train net output #0: loss = 1.21696 (* 1 = 1.21696 loss)
I0522 19:59:41.212054 12554 sgd_solver.cpp:106] Iteration 151125, lr = 0.002
I0522 19:59:50.909307 12554 solver.cpp:237] Iteration 151500, loss = 1.16596
I0522 19:59:50.909342 12554 solver.cpp:253]     Train net output #0: loss = 1.16596 (* 1 = 1.16596 loss)
I0522 19:59:50.909358 12554 sgd_solver.cpp:106] Iteration 151500, lr = 0.002
I0522 20:00:00.611127 12554 solver.cpp:237] Iteration 151875, loss = 1.11849
I0522 20:00:00.611312 12554 solver.cpp:253]     Train net output #0: loss = 1.11849 (* 1 = 1.11849 loss)
I0522 20:00:00.611326 12554 sgd_solver.cpp:106] Iteration 151875, lr = 0.002
I0522 20:00:10.306773 12554 solver.cpp:237] Iteration 152250, loss = 1.36435
I0522 20:00:10.306823 12554 solver.cpp:253]     Train net output #0: loss = 1.36435 (* 1 = 1.36435 loss)
I0522 20:00:10.306839 12554 sgd_solver.cpp:106] Iteration 152250, lr = 0.002
I0522 20:00:40.944450 12554 solver.cpp:237] Iteration 152625, loss = 1.0876
I0522 20:00:40.944645 12554 solver.cpp:253]     Train net output #0: loss = 1.0876 (* 1 = 1.0876 loss)
I0522 20:00:40.944661 12554 sgd_solver.cpp:106] Iteration 152625, lr = 0.002
I0522 20:00:50.643100 12554 solver.cpp:237] Iteration 153000, loss = 1.0753
I0522 20:00:50.643134 12554 solver.cpp:253]     Train net output #0: loss = 1.0753 (* 1 = 1.0753 loss)
I0522 20:00:50.643152 12554 sgd_solver.cpp:106] Iteration 153000, lr = 0.002
I0522 20:01:00.337282 12554 solver.cpp:237] Iteration 153375, loss = 1.85634
I0522 20:01:00.337330 12554 solver.cpp:253]     Train net output #0: loss = 1.85634 (* 1 = 1.85634 loss)
I0522 20:01:00.337345 12554 sgd_solver.cpp:106] Iteration 153375, lr = 0.002
I0522 20:01:10.004525 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_153750.caffemodel
I0522 20:01:10.061134 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_153750.solverstate
I0522 20:01:10.095124 12554 solver.cpp:237] Iteration 153750, loss = 0.947821
I0522 20:01:10.095170 12554 solver.cpp:253]     Train net output #0: loss = 0.947822 (* 1 = 0.947822 loss)
I0522 20:01:10.095186 12554 sgd_solver.cpp:106] Iteration 153750, lr = 0.002
I0522 20:01:19.785075 12554 solver.cpp:237] Iteration 154125, loss = 1.15401
I0522 20:01:19.785267 12554 solver.cpp:253]     Train net output #0: loss = 1.15401 (* 1 = 1.15401 loss)
I0522 20:01:19.785281 12554 sgd_solver.cpp:106] Iteration 154125, lr = 0.002
I0522 20:01:29.484060 12554 solver.cpp:237] Iteration 154500, loss = 1.04162
I0522 20:01:29.484091 12554 solver.cpp:253]     Train net output #0: loss = 1.04162 (* 1 = 1.04162 loss)
I0522 20:01:29.484107 12554 sgd_solver.cpp:106] Iteration 154500, lr = 0.002
I0522 20:01:39.182611 12554 solver.cpp:237] Iteration 154875, loss = 1.38599
I0522 20:01:39.182646 12554 solver.cpp:253]     Train net output #0: loss = 1.38599 (* 1 = 1.38599 loss)
I0522 20:01:39.182663 12554 sgd_solver.cpp:106] Iteration 154875, lr = 0.002
I0522 20:02:09.762912 12554 solver.cpp:237] Iteration 155250, loss = 1.1001
I0522 20:02:09.763108 12554 solver.cpp:253]     Train net output #0: loss = 1.1001 (* 1 = 1.1001 loss)
I0522 20:02:09.763124 12554 sgd_solver.cpp:106] Iteration 155250, lr = 0.002
I0522 20:02:19.473489 12554 solver.cpp:237] Iteration 155625, loss = 1.02219
I0522 20:02:19.473523 12554 solver.cpp:253]     Train net output #0: loss = 1.02219 (* 1 = 1.02219 loss)
I0522 20:02:19.473541 12554 sgd_solver.cpp:106] Iteration 155625, lr = 0.002
I0522 20:02:29.174942 12554 solver.cpp:237] Iteration 156000, loss = 1.48596
I0522 20:02:29.174978 12554 solver.cpp:253]     Train net output #0: loss = 1.48596 (* 1 = 1.48596 loss)
I0522 20:02:29.174994 12554 sgd_solver.cpp:106] Iteration 156000, lr = 0.002
I0522 20:02:38.876175 12554 solver.cpp:237] Iteration 156375, loss = 1.07518
I0522 20:02:38.876226 12554 solver.cpp:253]     Train net output #0: loss = 1.07519 (* 1 = 1.07519 loss)
I0522 20:02:38.876240 12554 sgd_solver.cpp:106] Iteration 156375, lr = 0.002
I0522 20:02:48.583776 12554 solver.cpp:237] Iteration 156750, loss = 1.06312
I0522 20:02:48.583964 12554 solver.cpp:253]     Train net output #0: loss = 1.06312 (* 1 = 1.06312 loss)
I0522 20:02:48.583978 12554 sgd_solver.cpp:106] Iteration 156750, lr = 0.002
I0522 20:02:58.280864 12554 solver.cpp:237] Iteration 157125, loss = 1.50308
I0522 20:02:58.280907 12554 solver.cpp:253]     Train net output #0: loss = 1.50308 (* 1 = 1.50308 loss)
I0522 20:02:58.280925 12554 sgd_solver.cpp:106] Iteration 157125, lr = 0.002
I0522 20:03:07.947218 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_157500.caffemodel
I0522 20:03:08.003518 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_157500.solverstate
I0522 20:03:08.029054 12554 solver.cpp:341] Iteration 157500, Testing net (#0)
I0522 20:03:56.545469 12554 solver.cpp:409]     Test net output #0: accuracy = 0.892793
I0522 20:03:56.545665 12554 solver.cpp:409]     Test net output #1: loss = 0.334354 (* 1 = 0.334354 loss)
I0522 20:04:17.407126 12554 solver.cpp:237] Iteration 157500, loss = 1.18453
I0522 20:04:17.407178 12554 solver.cpp:253]     Train net output #0: loss = 1.18453 (* 1 = 1.18453 loss)
I0522 20:04:17.407193 12554 sgd_solver.cpp:106] Iteration 157500, lr = 0.002
I0522 20:04:27.212327 12554 solver.cpp:237] Iteration 157875, loss = 1.34674
I0522 20:04:27.212509 12554 solver.cpp:253]     Train net output #0: loss = 1.34674 (* 1 = 1.34674 loss)
I0522 20:04:27.212523 12554 sgd_solver.cpp:106] Iteration 157875, lr = 0.002
I0522 20:04:37.016508 12554 solver.cpp:237] Iteration 158250, loss = 0.921182
I0522 20:04:37.016552 12554 solver.cpp:253]     Train net output #0: loss = 0.921183 (* 1 = 0.921183 loss)
I0522 20:04:37.016573 12554 sgd_solver.cpp:106] Iteration 158250, lr = 0.002
I0522 20:04:46.824713 12554 solver.cpp:237] Iteration 158625, loss = 1.25335
I0522 20:04:46.824748 12554 solver.cpp:253]     Train net output #0: loss = 1.25335 (* 1 = 1.25335 loss)
I0522 20:04:46.824766 12554 sgd_solver.cpp:106] Iteration 158625, lr = 0.002
I0522 20:04:56.633443 12554 solver.cpp:237] Iteration 159000, loss = 1.10971
I0522 20:04:56.633481 12554 solver.cpp:253]     Train net output #0: loss = 1.10971 (* 1 = 1.10971 loss)
I0522 20:04:56.633493 12554 sgd_solver.cpp:106] Iteration 159000, lr = 0.002
I0522 20:05:06.441476 12554 solver.cpp:237] Iteration 159375, loss = 1.07327
I0522 20:05:06.441669 12554 solver.cpp:253]     Train net output #0: loss = 1.07327 (* 1 = 1.07327 loss)
I0522 20:05:06.441684 12554 sgd_solver.cpp:106] Iteration 159375, lr = 0.002
I0522 20:05:16.246335 12554 solver.cpp:237] Iteration 159750, loss = 0.946939
I0522 20:05:16.246371 12554 solver.cpp:253]     Train net output #0: loss = 0.946939 (* 1 = 0.946939 loss)
I0522 20:05:16.246386 12554 sgd_solver.cpp:106] Iteration 159750, lr = 0.002
I0522 20:05:46.955497 12554 solver.cpp:237] Iteration 160125, loss = 1.19543
I0522 20:05:46.955708 12554 solver.cpp:253]     Train net output #0: loss = 1.19543 (* 1 = 1.19543 loss)
I0522 20:05:46.955724 12554 sgd_solver.cpp:106] Iteration 160125, lr = 0.002
I0522 20:05:56.761562 12554 solver.cpp:237] Iteration 160500, loss = 1.1495
I0522 20:05:56.761602 12554 solver.cpp:253]     Train net output #0: loss = 1.1495 (* 1 = 1.1495 loss)
I0522 20:05:56.761623 12554 sgd_solver.cpp:106] Iteration 160500, lr = 0.002
I0522 20:06:06.570436 12554 solver.cpp:237] Iteration 160875, loss = 1.3888
I0522 20:06:06.570472 12554 solver.cpp:253]     Train net output #0: loss = 1.3888 (* 1 = 1.3888 loss)
I0522 20:06:06.570487 12554 sgd_solver.cpp:106] Iteration 160875, lr = 0.002
I0522 20:06:16.348634 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_161250.caffemodel
I0522 20:06:16.404700 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_161250.solverstate
I0522 20:06:16.438163 12554 solver.cpp:237] Iteration 161250, loss = 1.00725
I0522 20:06:16.438208 12554 solver.cpp:253]     Train net output #0: loss = 1.00725 (* 1 = 1.00725 loss)
I0522 20:06:16.438222 12554 sgd_solver.cpp:106] Iteration 161250, lr = 0.002
I0522 20:06:26.245743 12554 solver.cpp:237] Iteration 161625, loss = 0.798047
I0522 20:06:26.245949 12554 solver.cpp:253]     Train net output #0: loss = 0.798048 (* 1 = 0.798048 loss)
I0522 20:06:26.245964 12554 sgd_solver.cpp:106] Iteration 161625, lr = 0.002
I0522 20:06:36.048077 12554 solver.cpp:237] Iteration 162000, loss = 1.12537
I0522 20:06:36.048112 12554 solver.cpp:253]     Train net output #0: loss = 1.12537 (* 1 = 1.12537 loss)
I0522 20:06:36.048130 12554 sgd_solver.cpp:106] Iteration 162000, lr = 0.002
I0522 20:06:45.853541 12554 solver.cpp:237] Iteration 162375, loss = 1.40907
I0522 20:06:45.853585 12554 solver.cpp:253]     Train net output #0: loss = 1.40907 (* 1 = 1.40907 loss)
I0522 20:06:45.853605 12554 sgd_solver.cpp:106] Iteration 162375, lr = 0.002
I0522 20:07:16.537983 12554 solver.cpp:237] Iteration 162750, loss = 1.48536
I0522 20:07:16.538185 12554 solver.cpp:253]     Train net output #0: loss = 1.48536 (* 1 = 1.48536 loss)
I0522 20:07:16.538203 12554 sgd_solver.cpp:106] Iteration 162750, lr = 0.002
I0522 20:07:26.341645 12554 solver.cpp:237] Iteration 163125, loss = 1.30929
I0522 20:07:26.341680 12554 solver.cpp:253]     Train net output #0: loss = 1.30929 (* 1 = 1.30929 loss)
I0522 20:07:26.341694 12554 sgd_solver.cpp:106] Iteration 163125, lr = 0.002
I0522 20:07:36.142745 12554 solver.cpp:237] Iteration 163500, loss = 1.10221
I0522 20:07:36.142793 12554 solver.cpp:253]     Train net output #0: loss = 1.10221 (* 1 = 1.10221 loss)
I0522 20:07:36.142807 12554 sgd_solver.cpp:106] Iteration 163500, lr = 0.002
I0522 20:07:45.952445 12554 solver.cpp:237] Iteration 163875, loss = 1.29933
I0522 20:07:45.952481 12554 solver.cpp:253]     Train net output #0: loss = 1.29933 (* 1 = 1.29933 loss)
I0522 20:07:45.952494 12554 sgd_solver.cpp:106] Iteration 163875, lr = 0.002
I0522 20:07:55.754845 12554 solver.cpp:237] Iteration 164250, loss = 1.28271
I0522 20:07:55.755022 12554 solver.cpp:253]     Train net output #0: loss = 1.28271 (* 1 = 1.28271 loss)
I0522 20:07:55.755034 12554 sgd_solver.cpp:106] Iteration 164250, lr = 0.002
I0522 20:08:05.561421 12554 solver.cpp:237] Iteration 164625, loss = 1.34091
I0522 20:08:05.561461 12554 solver.cpp:253]     Train net output #0: loss = 1.34091 (* 1 = 1.34091 loss)
I0522 20:08:05.561482 12554 sgd_solver.cpp:106] Iteration 164625, lr = 0.002
I0522 20:08:15.343464 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_165000.caffemodel
I0522 20:08:15.399785 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_165000.solverstate
I0522 20:08:15.425612 12554 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 20:09:24.780659 12554 solver.cpp:409]     Test net output #0: accuracy = 0.89232
I0522 20:09:24.780855 12554 solver.cpp:409]     Test net output #1: loss = 0.342563 (* 1 = 0.342563 loss)
I0522 20:09:45.651710 12554 solver.cpp:237] Iteration 165000, loss = 1.20927
I0522 20:09:45.651762 12554 solver.cpp:253]     Train net output #0: loss = 1.20927 (* 1 = 1.20927 loss)
I0522 20:09:45.651777 12554 sgd_solver.cpp:106] Iteration 165000, lr = 0.002
I0522 20:09:55.542925 12554 solver.cpp:237] Iteration 165375, loss = 0.935708
I0522 20:09:55.543121 12554 solver.cpp:253]     Train net output #0: loss = 0.935708 (* 1 = 0.935708 loss)
I0522 20:09:55.543135 12554 sgd_solver.cpp:106] Iteration 165375, lr = 0.002
I0522 20:10:05.439802 12554 solver.cpp:237] Iteration 165750, loss = 1.28101
I0522 20:10:05.439849 12554 solver.cpp:253]     Train net output #0: loss = 1.28101 (* 1 = 1.28101 loss)
I0522 20:10:05.439867 12554 sgd_solver.cpp:106] Iteration 165750, lr = 0.002
I0522 20:10:15.327277 12554 solver.cpp:237] Iteration 166125, loss = 1.10776
I0522 20:10:15.327313 12554 solver.cpp:253]     Train net output #0: loss = 1.10776 (* 1 = 1.10776 loss)
I0522 20:10:15.327330 12554 sgd_solver.cpp:106] Iteration 166125, lr = 0.002
I0522 20:10:25.217226 12554 solver.cpp:237] Iteration 166500, loss = 1.2422
I0522 20:10:25.217262 12554 solver.cpp:253]     Train net output #0: loss = 1.2422 (* 1 = 1.2422 loss)
I0522 20:10:25.217278 12554 sgd_solver.cpp:106] Iteration 166500, lr = 0.002
I0522 20:10:35.115805 12554 solver.cpp:237] Iteration 166875, loss = 1.3214
I0522 20:10:35.116000 12554 solver.cpp:253]     Train net output #0: loss = 1.3214 (* 1 = 1.3214 loss)
I0522 20:10:35.116014 12554 sgd_solver.cpp:106] Iteration 166875, lr = 0.002
I0522 20:10:45.012646 12554 solver.cpp:237] Iteration 167250, loss = 1.0228
I0522 20:10:45.012681 12554 solver.cpp:253]     Train net output #0: loss = 1.0228 (* 1 = 1.0228 loss)
I0522 20:10:45.012698 12554 sgd_solver.cpp:106] Iteration 167250, lr = 0.002
I0522 20:11:15.777736 12554 solver.cpp:237] Iteration 167625, loss = 1.41212
I0522 20:11:15.777936 12554 solver.cpp:253]     Train net output #0: loss = 1.41212 (* 1 = 1.41212 loss)
I0522 20:11:15.777952 12554 sgd_solver.cpp:106] Iteration 167625, lr = 0.002
I0522 20:11:25.679669 12554 solver.cpp:237] Iteration 168000, loss = 1.23407
I0522 20:11:25.679710 12554 solver.cpp:253]     Train net output #0: loss = 1.23407 (* 1 = 1.23407 loss)
I0522 20:11:25.679728 12554 sgd_solver.cpp:106] Iteration 168000, lr = 0.002
I0522 20:11:35.573966 12554 solver.cpp:237] Iteration 168375, loss = 1.00081
I0522 20:11:35.574002 12554 solver.cpp:253]     Train net output #0: loss = 1.00081 (* 1 = 1.00081 loss)
I0522 20:11:35.574018 12554 sgd_solver.cpp:106] Iteration 168375, lr = 0.002
I0522 20:11:45.443159 12554 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_168750.caffemodel
I0522 20:11:45.502611 12554 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_168750.solverstate
I0522 20:11:45.538528 12554 solver.cpp:237] Iteration 168750, loss = 1.14775
I0522 20:11:45.538574 12554 solver.cpp:253]     Train net output #0: loss = 1.14776 (* 1 = 1.14776 loss)
I0522 20:11:45.538594 12554 sgd_solver.cpp:106] Iteration 168750, lr = 0.002
aprun: Apid 11250237: Caught signal Terminated, sending to application
*** Aborted at 1463962310 (unix time) try "date -d @1463962310" if you are using GNU date ***
=>> PBS: job killed: walltime 7245 exceeded limit 7200
aprun: Apid 11250237: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11250237: Caught signal Terminated, sending to application
*** SIGTERM (@0x3107) received by PID 12554 (TID 0x2aaac746f900) from PID 12551; stack trace: ***
aprun: Apid 11250237: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11250237: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11250237: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11250237: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11250237: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11250237: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
aprun: Apid 11250237: Caught signal Terminated, sending to application
