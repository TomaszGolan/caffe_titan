2806963
I0521 19:40:44.183743  7510 caffe.cpp:184] Using GPUs 0
I0521 19:40:44.607775  7510 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.005
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864.prototxt"
I0521 19:40:44.610970  7510 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864.prototxt
I0521 19:40:44.748586  7510 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 19:40:44.748646  7510 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 19:40:44.749002  7510 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 19:40:44.749181  7510 layer_factory.hpp:77] Creating layer data_hdf5
I0521 19:40:44.749203  7510 net.cpp:106] Creating Layer data_hdf5
I0521 19:40:44.749217  7510 net.cpp:411] data_hdf5 -> data
I0521 19:40:44.749250  7510 net.cpp:411] data_hdf5 -> label
I0521 19:40:44.749282  7510 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 19:40:44.750519  7510 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 19:40:44.780124  7510 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 19:41:06.316781  7510 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 19:41:06.321955  7510 net.cpp:150] Setting up data_hdf5
I0521 19:41:06.321995  7510 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 19:41:06.322010  7510 net.cpp:157] Top shape: 10 (10)
I0521 19:41:06.322022  7510 net.cpp:165] Memory required for data: 254040
I0521 19:41:06.322036  7510 layer_factory.hpp:77] Creating layer conv1
I0521 19:41:06.322070  7510 net.cpp:106] Creating Layer conv1
I0521 19:41:06.322082  7510 net.cpp:454] conv1 <- data
I0521 19:41:06.322103  7510 net.cpp:411] conv1 -> conv1
I0521 19:41:06.685190  7510 net.cpp:150] Setting up conv1
I0521 19:41:06.685237  7510 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 19:41:06.685250  7510 net.cpp:165] Memory required for data: 3018840
I0521 19:41:06.685278  7510 layer_factory.hpp:77] Creating layer relu1
I0521 19:41:06.685299  7510 net.cpp:106] Creating Layer relu1
I0521 19:41:06.685310  7510 net.cpp:454] relu1 <- conv1
I0521 19:41:06.685324  7510 net.cpp:397] relu1 -> conv1 (in-place)
I0521 19:41:06.685852  7510 net.cpp:150] Setting up relu1
I0521 19:41:06.685868  7510 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 19:41:06.685879  7510 net.cpp:165] Memory required for data: 5783640
I0521 19:41:06.685890  7510 layer_factory.hpp:77] Creating layer pool1
I0521 19:41:06.685906  7510 net.cpp:106] Creating Layer pool1
I0521 19:41:06.685916  7510 net.cpp:454] pool1 <- conv1
I0521 19:41:06.685930  7510 net.cpp:411] pool1 -> pool1
I0521 19:41:06.686010  7510 net.cpp:150] Setting up pool1
I0521 19:41:06.686024  7510 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 19:41:06.686034  7510 net.cpp:165] Memory required for data: 7166040
I0521 19:41:06.686043  7510 layer_factory.hpp:77] Creating layer conv2
I0521 19:41:06.686065  7510 net.cpp:106] Creating Layer conv2
I0521 19:41:06.686075  7510 net.cpp:454] conv2 <- pool1
I0521 19:41:06.686089  7510 net.cpp:411] conv2 -> conv2
I0521 19:41:06.688778  7510 net.cpp:150] Setting up conv2
I0521 19:41:06.688807  7510 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 19:41:06.688817  7510 net.cpp:165] Memory required for data: 9153240
I0521 19:41:06.688835  7510 layer_factory.hpp:77] Creating layer relu2
I0521 19:41:06.688849  7510 net.cpp:106] Creating Layer relu2
I0521 19:41:06.688859  7510 net.cpp:454] relu2 <- conv2
I0521 19:41:06.688882  7510 net.cpp:397] relu2 -> conv2 (in-place)
I0521 19:41:06.689214  7510 net.cpp:150] Setting up relu2
I0521 19:41:06.689229  7510 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 19:41:06.689239  7510 net.cpp:165] Memory required for data: 11140440
I0521 19:41:06.689249  7510 layer_factory.hpp:77] Creating layer pool2
I0521 19:41:06.689261  7510 net.cpp:106] Creating Layer pool2
I0521 19:41:06.689271  7510 net.cpp:454] pool2 <- conv2
I0521 19:41:06.689285  7510 net.cpp:411] pool2 -> pool2
I0521 19:41:06.689364  7510 net.cpp:150] Setting up pool2
I0521 19:41:06.689378  7510 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 19:41:06.689388  7510 net.cpp:165] Memory required for data: 12134040
I0521 19:41:06.689395  7510 layer_factory.hpp:77] Creating layer conv3
I0521 19:41:06.689414  7510 net.cpp:106] Creating Layer conv3
I0521 19:41:06.689424  7510 net.cpp:454] conv3 <- pool2
I0521 19:41:06.689436  7510 net.cpp:411] conv3 -> conv3
I0521 19:41:06.691522  7510 net.cpp:150] Setting up conv3
I0521 19:41:06.691546  7510 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 19:41:06.691558  7510 net.cpp:165] Memory required for data: 13218200
I0521 19:41:06.691577  7510 layer_factory.hpp:77] Creating layer relu3
I0521 19:41:06.691593  7510 net.cpp:106] Creating Layer relu3
I0521 19:41:06.691603  7510 net.cpp:454] relu3 <- conv3
I0521 19:41:06.691615  7510 net.cpp:397] relu3 -> conv3 (in-place)
I0521 19:41:06.692080  7510 net.cpp:150] Setting up relu3
I0521 19:41:06.692098  7510 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 19:41:06.692109  7510 net.cpp:165] Memory required for data: 14302360
I0521 19:41:06.692119  7510 layer_factory.hpp:77] Creating layer pool3
I0521 19:41:06.692132  7510 net.cpp:106] Creating Layer pool3
I0521 19:41:06.692142  7510 net.cpp:454] pool3 <- conv3
I0521 19:41:06.692155  7510 net.cpp:411] pool3 -> pool3
I0521 19:41:06.692222  7510 net.cpp:150] Setting up pool3
I0521 19:41:06.692235  7510 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 19:41:06.692245  7510 net.cpp:165] Memory required for data: 14844440
I0521 19:41:06.692252  7510 layer_factory.hpp:77] Creating layer conv4
I0521 19:41:06.692270  7510 net.cpp:106] Creating Layer conv4
I0521 19:41:06.692281  7510 net.cpp:454] conv4 <- pool3
I0521 19:41:06.692293  7510 net.cpp:411] conv4 -> conv4
I0521 19:41:06.695019  7510 net.cpp:150] Setting up conv4
I0521 19:41:06.695041  7510 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 19:41:06.695052  7510 net.cpp:165] Memory required for data: 15207320
I0521 19:41:06.695067  7510 layer_factory.hpp:77] Creating layer relu4
I0521 19:41:06.695082  7510 net.cpp:106] Creating Layer relu4
I0521 19:41:06.695092  7510 net.cpp:454] relu4 <- conv4
I0521 19:41:06.695104  7510 net.cpp:397] relu4 -> conv4 (in-place)
I0521 19:41:06.695600  7510 net.cpp:150] Setting up relu4
I0521 19:41:06.695616  7510 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 19:41:06.695626  7510 net.cpp:165] Memory required for data: 15570200
I0521 19:41:06.695637  7510 layer_factory.hpp:77] Creating layer pool4
I0521 19:41:06.695650  7510 net.cpp:106] Creating Layer pool4
I0521 19:41:06.695660  7510 net.cpp:454] pool4 <- conv4
I0521 19:41:06.695673  7510 net.cpp:411] pool4 -> pool4
I0521 19:41:06.695741  7510 net.cpp:150] Setting up pool4
I0521 19:41:06.695755  7510 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 19:41:06.695765  7510 net.cpp:165] Memory required for data: 15751640
I0521 19:41:06.695773  7510 layer_factory.hpp:77] Creating layer ip1
I0521 19:41:06.695794  7510 net.cpp:106] Creating Layer ip1
I0521 19:41:06.695804  7510 net.cpp:454] ip1 <- pool4
I0521 19:41:06.695817  7510 net.cpp:411] ip1 -> ip1
I0521 19:41:06.711256  7510 net.cpp:150] Setting up ip1
I0521 19:41:06.711283  7510 net.cpp:157] Top shape: 10 196 (1960)
I0521 19:41:06.711295  7510 net.cpp:165] Memory required for data: 15759480
I0521 19:41:06.711318  7510 layer_factory.hpp:77] Creating layer relu5
I0521 19:41:06.711333  7510 net.cpp:106] Creating Layer relu5
I0521 19:41:06.711343  7510 net.cpp:454] relu5 <- ip1
I0521 19:41:06.711355  7510 net.cpp:397] relu5 -> ip1 (in-place)
I0521 19:41:06.711699  7510 net.cpp:150] Setting up relu5
I0521 19:41:06.711714  7510 net.cpp:157] Top shape: 10 196 (1960)
I0521 19:41:06.711724  7510 net.cpp:165] Memory required for data: 15767320
I0521 19:41:06.711733  7510 layer_factory.hpp:77] Creating layer drop1
I0521 19:41:06.711755  7510 net.cpp:106] Creating Layer drop1
I0521 19:41:06.711765  7510 net.cpp:454] drop1 <- ip1
I0521 19:41:06.711777  7510 net.cpp:397] drop1 -> ip1 (in-place)
I0521 19:41:06.711838  7510 net.cpp:150] Setting up drop1
I0521 19:41:06.711850  7510 net.cpp:157] Top shape: 10 196 (1960)
I0521 19:41:06.711859  7510 net.cpp:165] Memory required for data: 15775160
I0521 19:41:06.711869  7510 layer_factory.hpp:77] Creating layer ip2
I0521 19:41:06.711889  7510 net.cpp:106] Creating Layer ip2
I0521 19:41:06.711899  7510 net.cpp:454] ip2 <- ip1
I0521 19:41:06.711911  7510 net.cpp:411] ip2 -> ip2
I0521 19:41:06.712376  7510 net.cpp:150] Setting up ip2
I0521 19:41:06.712389  7510 net.cpp:157] Top shape: 10 98 (980)
I0521 19:41:06.712399  7510 net.cpp:165] Memory required for data: 15779080
I0521 19:41:06.712414  7510 layer_factory.hpp:77] Creating layer relu6
I0521 19:41:06.712426  7510 net.cpp:106] Creating Layer relu6
I0521 19:41:06.712436  7510 net.cpp:454] relu6 <- ip2
I0521 19:41:06.712448  7510 net.cpp:397] relu6 -> ip2 (in-place)
I0521 19:41:06.712975  7510 net.cpp:150] Setting up relu6
I0521 19:41:06.712991  7510 net.cpp:157] Top shape: 10 98 (980)
I0521 19:41:06.713001  7510 net.cpp:165] Memory required for data: 15783000
I0521 19:41:06.713011  7510 layer_factory.hpp:77] Creating layer drop2
I0521 19:41:06.713024  7510 net.cpp:106] Creating Layer drop2
I0521 19:41:06.713033  7510 net.cpp:454] drop2 <- ip2
I0521 19:41:06.713045  7510 net.cpp:397] drop2 -> ip2 (in-place)
I0521 19:41:06.713089  7510 net.cpp:150] Setting up drop2
I0521 19:41:06.713102  7510 net.cpp:157] Top shape: 10 98 (980)
I0521 19:41:06.713112  7510 net.cpp:165] Memory required for data: 15786920
I0521 19:41:06.713122  7510 layer_factory.hpp:77] Creating layer ip3
I0521 19:41:06.713135  7510 net.cpp:106] Creating Layer ip3
I0521 19:41:06.713145  7510 net.cpp:454] ip3 <- ip2
I0521 19:41:06.713157  7510 net.cpp:411] ip3 -> ip3
I0521 19:41:06.713366  7510 net.cpp:150] Setting up ip3
I0521 19:41:06.713377  7510 net.cpp:157] Top shape: 10 11 (110)
I0521 19:41:06.713387  7510 net.cpp:165] Memory required for data: 15787360
I0521 19:41:06.713402  7510 layer_factory.hpp:77] Creating layer drop3
I0521 19:41:06.713415  7510 net.cpp:106] Creating Layer drop3
I0521 19:41:06.713425  7510 net.cpp:454] drop3 <- ip3
I0521 19:41:06.713438  7510 net.cpp:397] drop3 -> ip3 (in-place)
I0521 19:41:06.713475  7510 net.cpp:150] Setting up drop3
I0521 19:41:06.713488  7510 net.cpp:157] Top shape: 10 11 (110)
I0521 19:41:06.713498  7510 net.cpp:165] Memory required for data: 15787800
I0521 19:41:06.713507  7510 layer_factory.hpp:77] Creating layer loss
I0521 19:41:06.713526  7510 net.cpp:106] Creating Layer loss
I0521 19:41:06.713536  7510 net.cpp:454] loss <- ip3
I0521 19:41:06.713547  7510 net.cpp:454] loss <- label
I0521 19:41:06.713559  7510 net.cpp:411] loss -> loss
I0521 19:41:06.713577  7510 layer_factory.hpp:77] Creating layer loss
I0521 19:41:06.714220  7510 net.cpp:150] Setting up loss
I0521 19:41:06.714241  7510 net.cpp:157] Top shape: (1)
I0521 19:41:06.714253  7510 net.cpp:160]     with loss weight 1
I0521 19:41:06.714296  7510 net.cpp:165] Memory required for data: 15787804
I0521 19:41:06.714308  7510 net.cpp:226] loss needs backward computation.
I0521 19:41:06.714318  7510 net.cpp:226] drop3 needs backward computation.
I0521 19:41:06.714329  7510 net.cpp:226] ip3 needs backward computation.
I0521 19:41:06.714339  7510 net.cpp:226] drop2 needs backward computation.
I0521 19:41:06.714347  7510 net.cpp:226] relu6 needs backward computation.
I0521 19:41:06.714357  7510 net.cpp:226] ip2 needs backward computation.
I0521 19:41:06.714367  7510 net.cpp:226] drop1 needs backward computation.
I0521 19:41:06.714377  7510 net.cpp:226] relu5 needs backward computation.
I0521 19:41:06.714387  7510 net.cpp:226] ip1 needs backward computation.
I0521 19:41:06.714397  7510 net.cpp:226] pool4 needs backward computation.
I0521 19:41:06.714407  7510 net.cpp:226] relu4 needs backward computation.
I0521 19:41:06.714416  7510 net.cpp:226] conv4 needs backward computation.
I0521 19:41:06.714426  7510 net.cpp:226] pool3 needs backward computation.
I0521 19:41:06.714437  7510 net.cpp:226] relu3 needs backward computation.
I0521 19:41:06.714447  7510 net.cpp:226] conv3 needs backward computation.
I0521 19:41:06.714467  7510 net.cpp:226] pool2 needs backward computation.
I0521 19:41:06.714478  7510 net.cpp:226] relu2 needs backward computation.
I0521 19:41:06.714488  7510 net.cpp:226] conv2 needs backward computation.
I0521 19:41:06.714498  7510 net.cpp:226] pool1 needs backward computation.
I0521 19:41:06.714509  7510 net.cpp:226] relu1 needs backward computation.
I0521 19:41:06.714519  7510 net.cpp:226] conv1 needs backward computation.
I0521 19:41:06.714530  7510 net.cpp:228] data_hdf5 does not need backward computation.
I0521 19:41:06.714540  7510 net.cpp:270] This network produces output loss
I0521 19:41:06.714563  7510 net.cpp:283] Network initialization done.
I0521 19:41:06.716223  7510 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864.prototxt
I0521 19:41:06.716295  7510 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 19:41:06.716645  7510 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 19:41:06.716835  7510 layer_factory.hpp:77] Creating layer data_hdf5
I0521 19:41:06.716850  7510 net.cpp:106] Creating Layer data_hdf5
I0521 19:41:06.716862  7510 net.cpp:411] data_hdf5 -> data
I0521 19:41:06.716894  7510 net.cpp:411] data_hdf5 -> label
I0521 19:41:06.716910  7510 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 19:41:06.718189  7510 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 19:41:28.019793  7510 net.cpp:150] Setting up data_hdf5
I0521 19:41:28.019959  7510 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 19:41:28.019973  7510 net.cpp:157] Top shape: 10 (10)
I0521 19:41:28.019986  7510 net.cpp:165] Memory required for data: 254040
I0521 19:41:28.019999  7510 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 19:41:28.020027  7510 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 19:41:28.020038  7510 net.cpp:454] label_data_hdf5_1_split <- label
I0521 19:41:28.020052  7510 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 19:41:28.020074  7510 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 19:41:28.020146  7510 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 19:41:28.020160  7510 net.cpp:157] Top shape: 10 (10)
I0521 19:41:28.020172  7510 net.cpp:157] Top shape: 10 (10)
I0521 19:41:28.020181  7510 net.cpp:165] Memory required for data: 254120
I0521 19:41:28.020191  7510 layer_factory.hpp:77] Creating layer conv1
I0521 19:41:28.020213  7510 net.cpp:106] Creating Layer conv1
I0521 19:41:28.020225  7510 net.cpp:454] conv1 <- data
I0521 19:41:28.020239  7510 net.cpp:411] conv1 -> conv1
I0521 19:41:28.022177  7510 net.cpp:150] Setting up conv1
I0521 19:41:28.022200  7510 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 19:41:28.022213  7510 net.cpp:165] Memory required for data: 3018920
I0521 19:41:28.022233  7510 layer_factory.hpp:77] Creating layer relu1
I0521 19:41:28.022248  7510 net.cpp:106] Creating Layer relu1
I0521 19:41:28.022258  7510 net.cpp:454] relu1 <- conv1
I0521 19:41:28.022270  7510 net.cpp:397] relu1 -> conv1 (in-place)
I0521 19:41:28.022775  7510 net.cpp:150] Setting up relu1
I0521 19:41:28.022792  7510 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 19:41:28.022802  7510 net.cpp:165] Memory required for data: 5783720
I0521 19:41:28.022812  7510 layer_factory.hpp:77] Creating layer pool1
I0521 19:41:28.022828  7510 net.cpp:106] Creating Layer pool1
I0521 19:41:28.022838  7510 net.cpp:454] pool1 <- conv1
I0521 19:41:28.022851  7510 net.cpp:411] pool1 -> pool1
I0521 19:41:28.022925  7510 net.cpp:150] Setting up pool1
I0521 19:41:28.022938  7510 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 19:41:28.022948  7510 net.cpp:165] Memory required for data: 7166120
I0521 19:41:28.022959  7510 layer_factory.hpp:77] Creating layer conv2
I0521 19:41:28.022976  7510 net.cpp:106] Creating Layer conv2
I0521 19:41:28.022986  7510 net.cpp:454] conv2 <- pool1
I0521 19:41:28.023000  7510 net.cpp:411] conv2 -> conv2
I0521 19:41:28.024907  7510 net.cpp:150] Setting up conv2
I0521 19:41:28.024924  7510 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 19:41:28.024940  7510 net.cpp:165] Memory required for data: 9153320
I0521 19:41:28.024960  7510 layer_factory.hpp:77] Creating layer relu2
I0521 19:41:28.024973  7510 net.cpp:106] Creating Layer relu2
I0521 19:41:28.024983  7510 net.cpp:454] relu2 <- conv2
I0521 19:41:28.024996  7510 net.cpp:397] relu2 -> conv2 (in-place)
I0521 19:41:28.025331  7510 net.cpp:150] Setting up relu2
I0521 19:41:28.025344  7510 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 19:41:28.025354  7510 net.cpp:165] Memory required for data: 11140520
I0521 19:41:28.025364  7510 layer_factory.hpp:77] Creating layer pool2
I0521 19:41:28.025377  7510 net.cpp:106] Creating Layer pool2
I0521 19:41:28.025388  7510 net.cpp:454] pool2 <- conv2
I0521 19:41:28.025399  7510 net.cpp:411] pool2 -> pool2
I0521 19:41:28.025472  7510 net.cpp:150] Setting up pool2
I0521 19:41:28.025485  7510 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 19:41:28.025495  7510 net.cpp:165] Memory required for data: 12134120
I0521 19:41:28.025506  7510 layer_factory.hpp:77] Creating layer conv3
I0521 19:41:28.025523  7510 net.cpp:106] Creating Layer conv3
I0521 19:41:28.025534  7510 net.cpp:454] conv3 <- pool2
I0521 19:41:28.025548  7510 net.cpp:411] conv3 -> conv3
I0521 19:41:28.027546  7510 net.cpp:150] Setting up conv3
I0521 19:41:28.027570  7510 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 19:41:28.027581  7510 net.cpp:165] Memory required for data: 13218280
I0521 19:41:28.027600  7510 layer_factory.hpp:77] Creating layer relu3
I0521 19:41:28.027626  7510 net.cpp:106] Creating Layer relu3
I0521 19:41:28.027637  7510 net.cpp:454] relu3 <- conv3
I0521 19:41:28.027650  7510 net.cpp:397] relu3 -> conv3 (in-place)
I0521 19:41:28.028122  7510 net.cpp:150] Setting up relu3
I0521 19:41:28.028138  7510 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 19:41:28.028149  7510 net.cpp:165] Memory required for data: 14302440
I0521 19:41:28.028158  7510 layer_factory.hpp:77] Creating layer pool3
I0521 19:41:28.028172  7510 net.cpp:106] Creating Layer pool3
I0521 19:41:28.028182  7510 net.cpp:454] pool3 <- conv3
I0521 19:41:28.028194  7510 net.cpp:411] pool3 -> pool3
I0521 19:41:28.028265  7510 net.cpp:150] Setting up pool3
I0521 19:41:28.028278  7510 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 19:41:28.028288  7510 net.cpp:165] Memory required for data: 14844520
I0521 19:41:28.028298  7510 layer_factory.hpp:77] Creating layer conv4
I0521 19:41:28.028316  7510 net.cpp:106] Creating Layer conv4
I0521 19:41:28.028326  7510 net.cpp:454] conv4 <- pool3
I0521 19:41:28.028339  7510 net.cpp:411] conv4 -> conv4
I0521 19:41:28.030416  7510 net.cpp:150] Setting up conv4
I0521 19:41:28.030437  7510 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 19:41:28.030447  7510 net.cpp:165] Memory required for data: 15207400
I0521 19:41:28.030462  7510 layer_factory.hpp:77] Creating layer relu4
I0521 19:41:28.030475  7510 net.cpp:106] Creating Layer relu4
I0521 19:41:28.030485  7510 net.cpp:454] relu4 <- conv4
I0521 19:41:28.030498  7510 net.cpp:397] relu4 -> conv4 (in-place)
I0521 19:41:28.030964  7510 net.cpp:150] Setting up relu4
I0521 19:41:28.030980  7510 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 19:41:28.030990  7510 net.cpp:165] Memory required for data: 15570280
I0521 19:41:28.031000  7510 layer_factory.hpp:77] Creating layer pool4
I0521 19:41:28.031013  7510 net.cpp:106] Creating Layer pool4
I0521 19:41:28.031023  7510 net.cpp:454] pool4 <- conv4
I0521 19:41:28.031036  7510 net.cpp:411] pool4 -> pool4
I0521 19:41:28.031108  7510 net.cpp:150] Setting up pool4
I0521 19:41:28.031121  7510 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 19:41:28.031131  7510 net.cpp:165] Memory required for data: 15751720
I0521 19:41:28.031139  7510 layer_factory.hpp:77] Creating layer ip1
I0521 19:41:28.031155  7510 net.cpp:106] Creating Layer ip1
I0521 19:41:28.031165  7510 net.cpp:454] ip1 <- pool4
I0521 19:41:28.031179  7510 net.cpp:411] ip1 -> ip1
I0521 19:41:28.046608  7510 net.cpp:150] Setting up ip1
I0521 19:41:28.046636  7510 net.cpp:157] Top shape: 10 196 (1960)
I0521 19:41:28.046648  7510 net.cpp:165] Memory required for data: 15759560
I0521 19:41:28.046670  7510 layer_factory.hpp:77] Creating layer relu5
I0521 19:41:28.046685  7510 net.cpp:106] Creating Layer relu5
I0521 19:41:28.046695  7510 net.cpp:454] relu5 <- ip1
I0521 19:41:28.046708  7510 net.cpp:397] relu5 -> ip1 (in-place)
I0521 19:41:28.047056  7510 net.cpp:150] Setting up relu5
I0521 19:41:28.047070  7510 net.cpp:157] Top shape: 10 196 (1960)
I0521 19:41:28.047081  7510 net.cpp:165] Memory required for data: 15767400
I0521 19:41:28.047091  7510 layer_factory.hpp:77] Creating layer drop1
I0521 19:41:28.047109  7510 net.cpp:106] Creating Layer drop1
I0521 19:41:28.047119  7510 net.cpp:454] drop1 <- ip1
I0521 19:41:28.047132  7510 net.cpp:397] drop1 -> ip1 (in-place)
I0521 19:41:28.047178  7510 net.cpp:150] Setting up drop1
I0521 19:41:28.047190  7510 net.cpp:157] Top shape: 10 196 (1960)
I0521 19:41:28.047199  7510 net.cpp:165] Memory required for data: 15775240
I0521 19:41:28.047209  7510 layer_factory.hpp:77] Creating layer ip2
I0521 19:41:28.047224  7510 net.cpp:106] Creating Layer ip2
I0521 19:41:28.047232  7510 net.cpp:454] ip2 <- ip1
I0521 19:41:28.047246  7510 net.cpp:411] ip2 -> ip2
I0521 19:41:28.047724  7510 net.cpp:150] Setting up ip2
I0521 19:41:28.047736  7510 net.cpp:157] Top shape: 10 98 (980)
I0521 19:41:28.047746  7510 net.cpp:165] Memory required for data: 15779160
I0521 19:41:28.047761  7510 layer_factory.hpp:77] Creating layer relu6
I0521 19:41:28.047786  7510 net.cpp:106] Creating Layer relu6
I0521 19:41:28.047796  7510 net.cpp:454] relu6 <- ip2
I0521 19:41:28.047809  7510 net.cpp:397] relu6 -> ip2 (in-place)
I0521 19:41:28.048337  7510 net.cpp:150] Setting up relu6
I0521 19:41:28.048353  7510 net.cpp:157] Top shape: 10 98 (980)
I0521 19:41:28.048363  7510 net.cpp:165] Memory required for data: 15783080
I0521 19:41:28.048374  7510 layer_factory.hpp:77] Creating layer drop2
I0521 19:41:28.048388  7510 net.cpp:106] Creating Layer drop2
I0521 19:41:28.048398  7510 net.cpp:454] drop2 <- ip2
I0521 19:41:28.048410  7510 net.cpp:397] drop2 -> ip2 (in-place)
I0521 19:41:28.048454  7510 net.cpp:150] Setting up drop2
I0521 19:41:28.048467  7510 net.cpp:157] Top shape: 10 98 (980)
I0521 19:41:28.048477  7510 net.cpp:165] Memory required for data: 15787000
I0521 19:41:28.048486  7510 layer_factory.hpp:77] Creating layer ip3
I0521 19:41:28.048501  7510 net.cpp:106] Creating Layer ip3
I0521 19:41:28.048511  7510 net.cpp:454] ip3 <- ip2
I0521 19:41:28.048524  7510 net.cpp:411] ip3 -> ip3
I0521 19:41:28.048746  7510 net.cpp:150] Setting up ip3
I0521 19:41:28.048759  7510 net.cpp:157] Top shape: 10 11 (110)
I0521 19:41:28.048769  7510 net.cpp:165] Memory required for data: 15787440
I0521 19:41:28.048784  7510 layer_factory.hpp:77] Creating layer drop3
I0521 19:41:28.048797  7510 net.cpp:106] Creating Layer drop3
I0521 19:41:28.048806  7510 net.cpp:454] drop3 <- ip3
I0521 19:41:28.048820  7510 net.cpp:397] drop3 -> ip3 (in-place)
I0521 19:41:28.048861  7510 net.cpp:150] Setting up drop3
I0521 19:41:28.048882  7510 net.cpp:157] Top shape: 10 11 (110)
I0521 19:41:28.048892  7510 net.cpp:165] Memory required for data: 15787880
I0521 19:41:28.048902  7510 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 19:41:28.048915  7510 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 19:41:28.048925  7510 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 19:41:28.048936  7510 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 19:41:28.048951  7510 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 19:41:28.049024  7510 net.cpp:150] Setting up ip3_drop3_0_split
I0521 19:41:28.049037  7510 net.cpp:157] Top shape: 10 11 (110)
I0521 19:41:28.049051  7510 net.cpp:157] Top shape: 10 11 (110)
I0521 19:41:28.049060  7510 net.cpp:165] Memory required for data: 15788760
I0521 19:41:28.049070  7510 layer_factory.hpp:77] Creating layer accuracy
I0521 19:41:28.049093  7510 net.cpp:106] Creating Layer accuracy
I0521 19:41:28.049103  7510 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 19:41:28.049113  7510 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 19:41:28.049127  7510 net.cpp:411] accuracy -> accuracy
I0521 19:41:28.049151  7510 net.cpp:150] Setting up accuracy
I0521 19:41:28.049165  7510 net.cpp:157] Top shape: (1)
I0521 19:41:28.049175  7510 net.cpp:165] Memory required for data: 15788764
I0521 19:41:28.049183  7510 layer_factory.hpp:77] Creating layer loss
I0521 19:41:28.049197  7510 net.cpp:106] Creating Layer loss
I0521 19:41:28.049207  7510 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 19:41:28.049218  7510 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 19:41:28.049232  7510 net.cpp:411] loss -> loss
I0521 19:41:28.049249  7510 layer_factory.hpp:77] Creating layer loss
I0521 19:41:28.049736  7510 net.cpp:150] Setting up loss
I0521 19:41:28.049749  7510 net.cpp:157] Top shape: (1)
I0521 19:41:28.049759  7510 net.cpp:160]     with loss weight 1
I0521 19:41:28.049777  7510 net.cpp:165] Memory required for data: 15788768
I0521 19:41:28.049787  7510 net.cpp:226] loss needs backward computation.
I0521 19:41:28.049798  7510 net.cpp:228] accuracy does not need backward computation.
I0521 19:41:28.049809  7510 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 19:41:28.049819  7510 net.cpp:226] drop3 needs backward computation.
I0521 19:41:28.049830  7510 net.cpp:226] ip3 needs backward computation.
I0521 19:41:28.049840  7510 net.cpp:226] drop2 needs backward computation.
I0521 19:41:28.049850  7510 net.cpp:226] relu6 needs backward computation.
I0521 19:41:28.049868  7510 net.cpp:226] ip2 needs backward computation.
I0521 19:41:28.049880  7510 net.cpp:226] drop1 needs backward computation.
I0521 19:41:28.049890  7510 net.cpp:226] relu5 needs backward computation.
I0521 19:41:28.049899  7510 net.cpp:226] ip1 needs backward computation.
I0521 19:41:28.049909  7510 net.cpp:226] pool4 needs backward computation.
I0521 19:41:28.049919  7510 net.cpp:226] relu4 needs backward computation.
I0521 19:41:28.049928  7510 net.cpp:226] conv4 needs backward computation.
I0521 19:41:28.049937  7510 net.cpp:226] pool3 needs backward computation.
I0521 19:41:28.049948  7510 net.cpp:226] relu3 needs backward computation.
I0521 19:41:28.049958  7510 net.cpp:226] conv3 needs backward computation.
I0521 19:41:28.049968  7510 net.cpp:226] pool2 needs backward computation.
I0521 19:41:28.049978  7510 net.cpp:226] relu2 needs backward computation.
I0521 19:41:28.049988  7510 net.cpp:226] conv2 needs backward computation.
I0521 19:41:28.049998  7510 net.cpp:226] pool1 needs backward computation.
I0521 19:41:28.050009  7510 net.cpp:226] relu1 needs backward computation.
I0521 19:41:28.050019  7510 net.cpp:226] conv1 needs backward computation.
I0521 19:41:28.050030  7510 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 19:41:28.050042  7510 net.cpp:228] data_hdf5 does not need backward computation.
I0521 19:41:28.050052  7510 net.cpp:270] This network produces output accuracy
I0521 19:41:28.050063  7510 net.cpp:270] This network produces output loss
I0521 19:41:28.050092  7510 net.cpp:283] Network initialization done.
I0521 19:41:28.050226  7510 solver.cpp:60] Solver scaffolding done.
I0521 19:41:28.051364  7510 caffe.cpp:212] Starting Optimization
I0521 19:41:28.051383  7510 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 19:41:28.051395  7510 solver.cpp:289] Learning Rate Policy: fixed
I0521 19:41:28.052461  7510 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 19:42:28.488610  7510 solver.cpp:409]     Test net output #0: accuracy = 0.105466
I0521 19:42:28.488775  7510 solver.cpp:409]     Test net output #1: loss = 2.39724 (* 1 = 2.39724 loss)
I0521 19:42:28.506522  7510 solver.cpp:237] Iteration 0, loss = 2.38933
I0521 19:42:28.506558  7510 solver.cpp:253]     Train net output #0: loss = 2.38933 (* 1 = 2.38933 loss)
I0521 19:42:28.506577  7510 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0521 19:42:45.278362  7510 solver.cpp:237] Iteration 1500, loss = 1.95164
I0521 19:42:45.278409  7510 solver.cpp:253]     Train net output #0: loss = 1.95164 (* 1 = 1.95164 loss)
I0521 19:42:45.278422  7510 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0521 19:43:02.037865  7510 solver.cpp:237] Iteration 3000, loss = 1.91051
I0521 19:43:02.038029  7510 solver.cpp:253]     Train net output #0: loss = 1.91051 (* 1 = 1.91051 loss)
I0521 19:43:02.038043  7510 sgd_solver.cpp:106] Iteration 3000, lr = 0.005
I0521 19:43:18.795969  7510 solver.cpp:237] Iteration 4500, loss = 1.93874
I0521 19:43:18.796005  7510 solver.cpp:253]     Train net output #0: loss = 1.93874 (* 1 = 1.93874 loss)
I0521 19:43:18.796018  7510 sgd_solver.cpp:106] Iteration 4500, lr = 0.005
I0521 19:43:35.569473  7510 solver.cpp:237] Iteration 6000, loss = 1.38172
I0521 19:43:35.569629  7510 solver.cpp:253]     Train net output #0: loss = 1.38172 (* 1 = 1.38172 loss)
I0521 19:43:35.569644  7510 sgd_solver.cpp:106] Iteration 6000, lr = 0.005
I0521 19:43:52.301132  7510 solver.cpp:237] Iteration 7500, loss = 1.00186
I0521 19:43:52.301177  7510 solver.cpp:253]     Train net output #0: loss = 1.00186 (* 1 = 1.00186 loss)
I0521 19:43:52.301189  7510 sgd_solver.cpp:106] Iteration 7500, lr = 0.005
I0521 19:44:09.049005  7510 solver.cpp:237] Iteration 9000, loss = 1.13793
I0521 19:44:09.049142  7510 solver.cpp:253]     Train net output #0: loss = 1.13794 (* 1 = 1.13794 loss)
I0521 19:44:09.049155  7510 sgd_solver.cpp:106] Iteration 9000, lr = 0.005
I0521 19:44:47.948825  7510 solver.cpp:237] Iteration 10500, loss = 1.08009
I0521 19:44:47.948992  7510 solver.cpp:253]     Train net output #0: loss = 1.08009 (* 1 = 1.08009 loss)
I0521 19:44:47.949007  7510 sgd_solver.cpp:106] Iteration 10500, lr = 0.005
I0521 19:45:04.700275  7510 solver.cpp:237] Iteration 12000, loss = 1.13297
I0521 19:45:04.700320  7510 solver.cpp:253]     Train net output #0: loss = 1.13297 (* 1 = 1.13297 loss)
I0521 19:45:04.700338  7510 sgd_solver.cpp:106] Iteration 12000, lr = 0.005
I0521 19:45:21.463709  7510 solver.cpp:237] Iteration 13500, loss = 1.93242
I0521 19:45:21.463848  7510 solver.cpp:253]     Train net output #0: loss = 1.93242 (* 1 = 1.93242 loss)
I0521 19:45:21.463861  7510 sgd_solver.cpp:106] Iteration 13500, lr = 0.005
I0521 19:45:38.231519  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_15000.caffemodel
I0521 19:45:38.281010  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_15000.solverstate
I0521 19:45:38.309842  7510 solver.cpp:237] Iteration 15000, loss = 0.907811
I0521 19:45:38.309888  7510 solver.cpp:253]     Train net output #0: loss = 0.907814 (* 1 = 0.907814 loss)
I0521 19:45:38.309902  7510 sgd_solver.cpp:106] Iteration 15000, lr = 0.005
I0521 19:45:55.072760  7510 solver.cpp:237] Iteration 16500, loss = 1.36688
I0521 19:45:55.072921  7510 solver.cpp:253]     Train net output #0: loss = 1.36688 (* 1 = 1.36688 loss)
I0521 19:45:55.072935  7510 sgd_solver.cpp:106] Iteration 16500, lr = 0.005
I0521 19:46:11.843204  7510 solver.cpp:237] Iteration 18000, loss = 0.918708
I0521 19:46:11.843241  7510 solver.cpp:253]     Train net output #0: loss = 0.918712 (* 1 = 0.918712 loss)
I0521 19:46:11.843257  7510 sgd_solver.cpp:106] Iteration 18000, lr = 0.005
I0521 19:46:28.591471  7510 solver.cpp:237] Iteration 19500, loss = 2.22312
I0521 19:46:28.591624  7510 solver.cpp:253]     Train net output #0: loss = 2.22312 (* 1 = 2.22312 loss)
I0521 19:46:28.591639  7510 sgd_solver.cpp:106] Iteration 19500, lr = 0.005
I0521 19:47:07.503772  7510 solver.cpp:237] Iteration 21000, loss = 1.19439
I0521 19:47:07.503934  7510 solver.cpp:253]     Train net output #0: loss = 1.19439 (* 1 = 1.19439 loss)
I0521 19:47:07.503947  7510 sgd_solver.cpp:106] Iteration 21000, lr = 0.005
I0521 19:47:24.270789  7510 solver.cpp:237] Iteration 22500, loss = 0.980117
I0521 19:47:24.270826  7510 solver.cpp:253]     Train net output #0: loss = 0.980121 (* 1 = 0.980121 loss)
I0521 19:47:24.270843  7510 sgd_solver.cpp:106] Iteration 22500, lr = 0.005
I0521 19:47:41.013769  7510 solver.cpp:237] Iteration 24000, loss = 1.23299
I0521 19:47:41.013929  7510 solver.cpp:253]     Train net output #0: loss = 1.233 (* 1 = 1.233 loss)
I0521 19:47:41.013943  7510 sgd_solver.cpp:106] Iteration 24000, lr = 0.005
I0521 19:47:57.792984  7510 solver.cpp:237] Iteration 25500, loss = 1.41361
I0521 19:47:57.793032  7510 solver.cpp:253]     Train net output #0: loss = 1.41361 (* 1 = 1.41361 loss)
I0521 19:47:57.793050  7510 sgd_solver.cpp:106] Iteration 25500, lr = 0.005
I0521 19:48:14.543977  7510 solver.cpp:237] Iteration 27000, loss = 1.45317
I0521 19:48:14.544119  7510 solver.cpp:253]     Train net output #0: loss = 1.45318 (* 1 = 1.45318 loss)
I0521 19:48:14.544133  7510 sgd_solver.cpp:106] Iteration 27000, lr = 0.005
I0521 19:48:31.200769  7510 solver.cpp:237] Iteration 28500, loss = 1.96195
I0521 19:48:31.200820  7510 solver.cpp:253]     Train net output #0: loss = 1.96196 (* 1 = 1.96196 loss)
I0521 19:48:31.200835  7510 sgd_solver.cpp:106] Iteration 28500, lr = 0.005
I0521 19:48:47.835508  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_30000.caffemodel
I0521 19:48:47.883114  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_30000.solverstate
I0521 19:48:47.909322  7510 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 19:49:47.364609  7510 solver.cpp:409]     Test net output #0: accuracy = 0.858332
I0521 19:49:47.364765  7510 solver.cpp:409]     Test net output #1: loss = 0.451767 (* 1 = 0.451767 loss)
I0521 19:50:09.557765  7510 solver.cpp:237] Iteration 30000, loss = 1.17454
I0521 19:50:09.557819  7510 solver.cpp:253]     Train net output #0: loss = 1.17454 (* 1 = 1.17454 loss)
I0521 19:50:09.557833  7510 sgd_solver.cpp:106] Iteration 30000, lr = 0.005
I0521 19:50:26.592468  7510 solver.cpp:237] Iteration 31500, loss = 0.643207
I0521 19:50:26.592625  7510 solver.cpp:253]     Train net output #0: loss = 0.64321 (* 1 = 0.64321 loss)
I0521 19:50:26.592640  7510 sgd_solver.cpp:106] Iteration 31500, lr = 0.005
I0521 19:50:43.638051  7510 solver.cpp:237] Iteration 33000, loss = 1.78506
I0521 19:50:43.638087  7510 solver.cpp:253]     Train net output #0: loss = 1.78506 (* 1 = 1.78506 loss)
I0521 19:50:43.638103  7510 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I0521 19:51:00.661020  7510 solver.cpp:237] Iteration 34500, loss = 1.36258
I0521 19:51:00.661170  7510 solver.cpp:253]     Train net output #0: loss = 1.36259 (* 1 = 1.36259 loss)
I0521 19:51:00.661185  7510 sgd_solver.cpp:106] Iteration 34500, lr = 0.005
I0521 19:51:17.698930  7510 solver.cpp:237] Iteration 36000, loss = 0.97404
I0521 19:51:17.698977  7510 solver.cpp:253]     Train net output #0: loss = 0.974043 (* 1 = 0.974043 loss)
I0521 19:51:17.698994  7510 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I0521 19:51:34.747445  7510 solver.cpp:237] Iteration 37500, loss = 1.33807
I0521 19:51:34.747586  7510 solver.cpp:253]     Train net output #0: loss = 1.33807 (* 1 = 1.33807 loss)
I0521 19:51:34.747599  7510 sgd_solver.cpp:106] Iteration 37500, lr = 0.005
I0521 19:51:51.776561  7510 solver.cpp:237] Iteration 39000, loss = 1.19862
I0521 19:51:51.776628  7510 solver.cpp:253]     Train net output #0: loss = 1.19863 (* 1 = 1.19863 loss)
I0521 19:51:51.776643  7510 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I0521 19:52:31.001618  7510 solver.cpp:237] Iteration 40500, loss = 1.41736
I0521 19:52:31.001781  7510 solver.cpp:253]     Train net output #0: loss = 1.41736 (* 1 = 1.41736 loss)
I0521 19:52:31.001796  7510 sgd_solver.cpp:106] Iteration 40500, lr = 0.005
I0521 19:52:48.044283  7510 solver.cpp:237] Iteration 42000, loss = 1.37964
I0521 19:52:48.044320  7510 solver.cpp:253]     Train net output #0: loss = 1.37964 (* 1 = 1.37964 loss)
I0521 19:52:48.044337  7510 sgd_solver.cpp:106] Iteration 42000, lr = 0.005
I0521 19:53:05.085623  7510 solver.cpp:237] Iteration 43500, loss = 1.44708
I0521 19:53:05.085785  7510 solver.cpp:253]     Train net output #0: loss = 1.44709 (* 1 = 1.44709 loss)
I0521 19:53:05.085798  7510 sgd_solver.cpp:106] Iteration 43500, lr = 0.005
I0521 19:53:22.138608  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_45000.caffemodel
I0521 19:53:22.186218  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_45000.solverstate
I0521 19:53:22.217938  7510 solver.cpp:237] Iteration 45000, loss = 1.15052
I0521 19:53:22.217988  7510 solver.cpp:253]     Train net output #0: loss = 1.15052 (* 1 = 1.15052 loss)
I0521 19:53:22.218003  7510 sgd_solver.cpp:106] Iteration 45000, lr = 0.005
I0521 19:53:39.236891  7510 solver.cpp:237] Iteration 46500, loss = 1.27789
I0521 19:53:39.237035  7510 solver.cpp:253]     Train net output #0: loss = 1.27789 (* 1 = 1.27789 loss)
I0521 19:53:39.237049  7510 sgd_solver.cpp:106] Iteration 46500, lr = 0.005
I0521 19:53:56.269486  7510 solver.cpp:237] Iteration 48000, loss = 1.64544
I0521 19:53:56.269534  7510 solver.cpp:253]     Train net output #0: loss = 1.64544 (* 1 = 1.64544 loss)
I0521 19:53:56.269547  7510 sgd_solver.cpp:106] Iteration 48000, lr = 0.005
I0521 19:54:13.310349  7510 solver.cpp:237] Iteration 49500, loss = 1.33981
I0521 19:54:13.310503  7510 solver.cpp:253]     Train net output #0: loss = 1.33981 (* 1 = 1.33981 loss)
I0521 19:54:13.310518  7510 sgd_solver.cpp:106] Iteration 49500, lr = 0.005
I0521 19:54:52.499886  7510 solver.cpp:237] Iteration 51000, loss = 2.17168
I0521 19:54:52.500051  7510 solver.cpp:253]     Train net output #0: loss = 2.17168 (* 1 = 2.17168 loss)
I0521 19:54:52.500066  7510 sgd_solver.cpp:106] Iteration 51000, lr = 0.005
I0521 19:55:09.548537  7510 solver.cpp:237] Iteration 52500, loss = 0.647025
I0521 19:55:09.548581  7510 solver.cpp:253]     Train net output #0: loss = 0.647027 (* 1 = 0.647027 loss)
I0521 19:55:09.548596  7510 sgd_solver.cpp:106] Iteration 52500, lr = 0.005
I0521 19:55:26.595085  7510 solver.cpp:237] Iteration 54000, loss = 1.51823
I0521 19:55:26.595239  7510 solver.cpp:253]     Train net output #0: loss = 1.51823 (* 1 = 1.51823 loss)
I0521 19:55:26.595253  7510 sgd_solver.cpp:106] Iteration 54000, lr = 0.005
I0521 19:55:43.653648  7510 solver.cpp:237] Iteration 55500, loss = 0.639222
I0521 19:55:43.653686  7510 solver.cpp:253]     Train net output #0: loss = 0.639223 (* 1 = 0.639223 loss)
I0521 19:55:43.653702  7510 sgd_solver.cpp:106] Iteration 55500, lr = 0.005
I0521 19:56:00.711464  7510 solver.cpp:237] Iteration 57000, loss = 1.75145
I0521 19:56:00.711616  7510 solver.cpp:253]     Train net output #0: loss = 1.75145 (* 1 = 1.75145 loss)
I0521 19:56:00.711629  7510 sgd_solver.cpp:106] Iteration 57000, lr = 0.005
I0521 19:56:17.754251  7510 solver.cpp:237] Iteration 58500, loss = 0.934739
I0521 19:56:17.754304  7510 solver.cpp:253]     Train net output #0: loss = 0.93474 (* 1 = 0.93474 loss)
I0521 19:56:17.754318  7510 sgd_solver.cpp:106] Iteration 58500, lr = 0.005
I0521 19:56:34.778033  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_60000.caffemodel
I0521 19:56:34.827231  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_60000.solverstate
I0521 19:56:34.855826  7510 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 19:57:55.402055  7510 solver.cpp:409]     Test net output #0: accuracy = 0.858221
I0521 19:57:55.402209  7510 solver.cpp:409]     Test net output #1: loss = 0.530082 (* 1 = 0.530082 loss)
I0521 19:58:17.563786  7510 solver.cpp:237] Iteration 60000, loss = 1.47478
I0521 19:58:17.563840  7510 solver.cpp:253]     Train net output #0: loss = 1.47478 (* 1 = 1.47478 loss)
I0521 19:58:17.563855  7510 sgd_solver.cpp:106] Iteration 60000, lr = 0.005
I0521 19:58:34.196072  7510 solver.cpp:237] Iteration 61500, loss = 0.786965
I0521 19:58:34.196246  7510 solver.cpp:253]     Train net output #0: loss = 0.786966 (* 1 = 0.786966 loss)
I0521 19:58:34.196260  7510 sgd_solver.cpp:106] Iteration 61500, lr = 0.005
I0521 19:58:50.818913  7510 solver.cpp:237] Iteration 63000, loss = 1.71192
I0521 19:58:50.818960  7510 solver.cpp:253]     Train net output #0: loss = 1.71192 (* 1 = 1.71192 loss)
I0521 19:58:50.818977  7510 sgd_solver.cpp:106] Iteration 63000, lr = 0.005
I0521 19:59:07.419282  7510 solver.cpp:237] Iteration 64500, loss = 1.0707
I0521 19:59:07.419423  7510 solver.cpp:253]     Train net output #0: loss = 1.07071 (* 1 = 1.07071 loss)
I0521 19:59:07.419437  7510 sgd_solver.cpp:106] Iteration 64500, lr = 0.005
I0521 19:59:24.029392  7510 solver.cpp:237] Iteration 66000, loss = 0.895658
I0521 19:59:24.029439  7510 solver.cpp:253]     Train net output #0: loss = 0.895661 (* 1 = 0.895661 loss)
I0521 19:59:24.029453  7510 sgd_solver.cpp:106] Iteration 66000, lr = 0.005
I0521 19:59:40.702867  7510 solver.cpp:237] Iteration 67500, loss = 1.5001
I0521 19:59:40.703016  7510 solver.cpp:253]     Train net output #0: loss = 1.5001 (* 1 = 1.5001 loss)
I0521 19:59:40.703030  7510 sgd_solver.cpp:106] Iteration 67500, lr = 0.005
I0521 19:59:57.469154  7510 solver.cpp:237] Iteration 69000, loss = 1.31372
I0521 19:59:57.469192  7510 solver.cpp:253]     Train net output #0: loss = 1.31372 (* 1 = 1.31372 loss)
I0521 19:59:57.469208  7510 sgd_solver.cpp:106] Iteration 69000, lr = 0.005
I0521 20:00:36.372371  7510 solver.cpp:237] Iteration 70500, loss = 1.04263
I0521 20:00:36.372539  7510 solver.cpp:253]     Train net output #0: loss = 1.04263 (* 1 = 1.04263 loss)
I0521 20:00:36.372552  7510 sgd_solver.cpp:106] Iteration 70500, lr = 0.005
I0521 20:00:53.101459  7510 solver.cpp:237] Iteration 72000, loss = 0.994736
I0521 20:00:53.101512  7510 solver.cpp:253]     Train net output #0: loss = 0.994737 (* 1 = 0.994737 loss)
I0521 20:00:53.101526  7510 sgd_solver.cpp:106] Iteration 72000, lr = 0.005
I0521 20:01:09.871177  7510 solver.cpp:237] Iteration 73500, loss = 0.910043
I0521 20:01:09.871321  7510 solver.cpp:253]     Train net output #0: loss = 0.910044 (* 1 = 0.910044 loss)
I0521 20:01:09.871335  7510 sgd_solver.cpp:106] Iteration 73500, lr = 0.005
I0521 20:01:26.615340  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_75000.caffemodel
I0521 20:01:26.662889  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_75000.solverstate
I0521 20:01:26.694844  7510 solver.cpp:237] Iteration 75000, loss = 0.83654
I0521 20:01:26.694895  7510 solver.cpp:253]     Train net output #0: loss = 0.836541 (* 1 = 0.836541 loss)
I0521 20:01:26.694911  7510 sgd_solver.cpp:106] Iteration 75000, lr = 0.005
I0521 20:01:43.478535  7510 solver.cpp:237] Iteration 76500, loss = 1.58248
I0521 20:01:43.478698  7510 solver.cpp:253]     Train net output #0: loss = 1.58248 (* 1 = 1.58248 loss)
I0521 20:01:43.478711  7510 sgd_solver.cpp:106] Iteration 76500, lr = 0.005
I0521 20:02:00.253435  7510 solver.cpp:237] Iteration 78000, loss = 1.54827
I0521 20:02:00.253471  7510 solver.cpp:253]     Train net output #0: loss = 1.54827 (* 1 = 1.54827 loss)
I0521 20:02:00.253489  7510 sgd_solver.cpp:106] Iteration 78000, lr = 0.005
I0521 20:02:17.030300  7510 solver.cpp:237] Iteration 79500, loss = 1.57276
I0521 20:02:17.030457  7510 solver.cpp:253]     Train net output #0: loss = 1.57276 (* 1 = 1.57276 loss)
I0521 20:02:17.030473  7510 sgd_solver.cpp:106] Iteration 79500, lr = 0.005
I0521 20:02:56.032605  7510 solver.cpp:237] Iteration 81000, loss = 0.592312
I0521 20:02:56.032774  7510 solver.cpp:253]     Train net output #0: loss = 0.592315 (* 1 = 0.592315 loss)
I0521 20:02:56.032789  7510 sgd_solver.cpp:106] Iteration 81000, lr = 0.005
I0521 20:03:12.777607  7510 solver.cpp:237] Iteration 82500, loss = 0.903243
I0521 20:03:12.777644  7510 solver.cpp:253]     Train net output #0: loss = 0.903247 (* 1 = 0.903247 loss)
I0521 20:03:12.777659  7510 sgd_solver.cpp:106] Iteration 82500, lr = 0.005
I0521 20:03:29.519511  7510 solver.cpp:237] Iteration 84000, loss = 1.22318
I0521 20:03:29.519660  7510 solver.cpp:253]     Train net output #0: loss = 1.22318 (* 1 = 1.22318 loss)
I0521 20:03:29.519675  7510 sgd_solver.cpp:106] Iteration 84000, lr = 0.005
I0521 20:03:46.265727  7510 solver.cpp:237] Iteration 85500, loss = 1.16119
I0521 20:03:46.265770  7510 solver.cpp:253]     Train net output #0: loss = 1.16119 (* 1 = 1.16119 loss)
I0521 20:03:46.265784  7510 sgd_solver.cpp:106] Iteration 85500, lr = 0.005
I0521 20:04:03.013977  7510 solver.cpp:237] Iteration 87000, loss = 0.881912
I0521 20:04:03.014116  7510 solver.cpp:253]     Train net output #0: loss = 0.881916 (* 1 = 0.881916 loss)
I0521 20:04:03.014129  7510 sgd_solver.cpp:106] Iteration 87000, lr = 0.005
I0521 20:04:19.759356  7510 solver.cpp:237] Iteration 88500, loss = 1.03112
I0521 20:04:19.759404  7510 solver.cpp:253]     Train net output #0: loss = 1.03112 (* 1 = 1.03112 loss)
I0521 20:04:19.759419  7510 sgd_solver.cpp:106] Iteration 88500, lr = 0.005
I0521 20:04:36.497859  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_90000.caffemodel
I0521 20:04:36.543190  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_90000.solverstate
I0521 20:04:36.569353  7510 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 20:05:35.655030  7510 solver.cpp:409]     Test net output #0: accuracy = 0.857154
I0521 20:05:35.655190  7510 solver.cpp:409]     Test net output #1: loss = 0.502909 (* 1 = 0.502909 loss)
I0521 20:05:57.823129  7510 solver.cpp:237] Iteration 90000, loss = 1.12533
I0521 20:05:57.823184  7510 solver.cpp:253]     Train net output #0: loss = 1.12533 (* 1 = 1.12533 loss)
I0521 20:05:57.823197  7510 sgd_solver.cpp:106] Iteration 90000, lr = 0.005
I0521 20:06:14.985673  7510 solver.cpp:237] Iteration 91500, loss = 0.711488
I0521 20:06:14.985824  7510 solver.cpp:253]     Train net output #0: loss = 0.711491 (* 1 = 0.711491 loss)
I0521 20:06:14.985838  7510 sgd_solver.cpp:106] Iteration 91500, lr = 0.005
I0521 20:06:32.153311  7510 solver.cpp:237] Iteration 93000, loss = 1.39538
I0521 20:06:32.153355  7510 solver.cpp:253]     Train net output #0: loss = 1.39538 (* 1 = 1.39538 loss)
I0521 20:06:32.153372  7510 sgd_solver.cpp:106] Iteration 93000, lr = 0.005
I0521 20:06:49.032680  7510 solver.cpp:237] Iteration 94500, loss = 1.63516
I0521 20:06:49.032847  7510 solver.cpp:253]     Train net output #0: loss = 1.63517 (* 1 = 1.63517 loss)
I0521 20:06:49.032869  7510 sgd_solver.cpp:106] Iteration 94500, lr = 0.005
I0521 20:07:05.611392  7510 solver.cpp:237] Iteration 96000, loss = 1.13612
I0521 20:07:05.611439  7510 solver.cpp:253]     Train net output #0: loss = 1.13612 (* 1 = 1.13612 loss)
I0521 20:07:05.611455  7510 sgd_solver.cpp:106] Iteration 96000, lr = 0.005
I0521 20:07:22.212306  7510 solver.cpp:237] Iteration 97500, loss = 1.10339
I0521 20:07:22.212450  7510 solver.cpp:253]     Train net output #0: loss = 1.10339 (* 1 = 1.10339 loss)
I0521 20:07:22.212462  7510 sgd_solver.cpp:106] Iteration 97500, lr = 0.005
I0521 20:07:38.808300  7510 solver.cpp:237] Iteration 99000, loss = 1.33252
I0521 20:07:38.808347  7510 solver.cpp:253]     Train net output #0: loss = 1.33253 (* 1 = 1.33253 loss)
I0521 20:07:38.808362  7510 sgd_solver.cpp:106] Iteration 99000, lr = 0.005
I0521 20:08:17.628540  7510 solver.cpp:237] Iteration 100500, loss = 1.14561
I0521 20:08:17.628733  7510 solver.cpp:253]     Train net output #0: loss = 1.14561 (* 1 = 1.14561 loss)
I0521 20:08:17.628748  7510 sgd_solver.cpp:106] Iteration 100500, lr = 0.005
I0521 20:08:34.228549  7510 solver.cpp:237] Iteration 102000, loss = 0.911789
I0521 20:08:34.228600  7510 solver.cpp:253]     Train net output #0: loss = 0.911792 (* 1 = 0.911792 loss)
I0521 20:08:34.228613  7510 sgd_solver.cpp:106] Iteration 102000, lr = 0.005
I0521 20:08:50.851413  7510 solver.cpp:237] Iteration 103500, loss = 1.33969
I0521 20:08:50.851570  7510 solver.cpp:253]     Train net output #0: loss = 1.33969 (* 1 = 1.33969 loss)
I0521 20:08:50.851584  7510 sgd_solver.cpp:106] Iteration 103500, lr = 0.005
I0521 20:09:07.458158  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_105000.caffemodel
I0521 20:09:07.503628  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_105000.solverstate
I0521 20:09:07.532407  7510 solver.cpp:237] Iteration 105000, loss = 1.79631
I0521 20:09:07.532454  7510 solver.cpp:253]     Train net output #0: loss = 1.79631 (* 1 = 1.79631 loss)
I0521 20:09:07.532469  7510 sgd_solver.cpp:106] Iteration 105000, lr = 0.005
I0521 20:09:24.118472  7510 solver.cpp:237] Iteration 106500, loss = 1.40791
I0521 20:09:24.118644  7510 solver.cpp:253]     Train net output #0: loss = 1.40791 (* 1 = 1.40791 loss)
I0521 20:09:24.118659  7510 sgd_solver.cpp:106] Iteration 106500, lr = 0.005
I0521 20:09:40.708030  7510 solver.cpp:237] Iteration 108000, loss = 0.876657
I0521 20:09:40.708077  7510 solver.cpp:253]     Train net output #0: loss = 0.87666 (* 1 = 0.87666 loss)
I0521 20:09:40.708094  7510 sgd_solver.cpp:106] Iteration 108000, lr = 0.005
I0521 20:09:57.290441  7510 solver.cpp:237] Iteration 109500, loss = 1.27393
I0521 20:09:57.290587  7510 solver.cpp:253]     Train net output #0: loss = 1.27393 (* 1 = 1.27393 loss)
I0521 20:09:57.290601  7510 sgd_solver.cpp:106] Iteration 109500, lr = 0.005
I0521 20:10:36.053357  7510 solver.cpp:237] Iteration 111000, loss = 0.87947
I0521 20:10:36.053525  7510 solver.cpp:253]     Train net output #0: loss = 0.879473 (* 1 = 0.879473 loss)
I0521 20:10:36.053539  7510 sgd_solver.cpp:106] Iteration 111000, lr = 0.005
I0521 20:10:52.670256  7510 solver.cpp:237] Iteration 112500, loss = 1.28317
I0521 20:10:52.670302  7510 solver.cpp:253]     Train net output #0: loss = 1.28318 (* 1 = 1.28318 loss)
I0521 20:10:52.670315  7510 sgd_solver.cpp:106] Iteration 112500, lr = 0.005
I0521 20:11:09.250792  7510 solver.cpp:237] Iteration 114000, loss = 1.30142
I0521 20:11:09.250934  7510 solver.cpp:253]     Train net output #0: loss = 1.30142 (* 1 = 1.30142 loss)
I0521 20:11:09.250948  7510 sgd_solver.cpp:106] Iteration 114000, lr = 0.005
I0521 20:11:25.854971  7510 solver.cpp:237] Iteration 115500, loss = 1.39834
I0521 20:11:25.855015  7510 solver.cpp:253]     Train net output #0: loss = 1.39834 (* 1 = 1.39834 loss)
I0521 20:11:25.855027  7510 sgd_solver.cpp:106] Iteration 115500, lr = 0.005
I0521 20:11:42.456935  7510 solver.cpp:237] Iteration 117000, loss = 0.913281
I0521 20:11:42.457085  7510 solver.cpp:253]     Train net output #0: loss = 0.913283 (* 1 = 0.913283 loss)
I0521 20:11:42.457099  7510 sgd_solver.cpp:106] Iteration 117000, lr = 0.005
I0521 20:11:59.072000  7510 solver.cpp:237] Iteration 118500, loss = 1.51707
I0521 20:11:59.072037  7510 solver.cpp:253]     Train net output #0: loss = 1.51707 (* 1 = 1.51707 loss)
I0521 20:11:59.072052  7510 sgd_solver.cpp:106] Iteration 118500, lr = 0.005
I0521 20:12:15.663282  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_120000.caffemodel
I0521 20:12:15.711333  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_120000.solverstate
I0521 20:12:15.736611  7510 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 20:13:35.940884  7510 solver.cpp:409]     Test net output #0: accuracy = 0.873684
I0521 20:13:35.941052  7510 solver.cpp:409]     Test net output #1: loss = 0.424766 (* 1 = 0.424766 loss)
I0521 20:13:58.084617  7510 solver.cpp:237] Iteration 120000, loss = 1.51702
I0521 20:13:58.084669  7510 solver.cpp:253]     Train net output #0: loss = 1.51702 (* 1 = 1.51702 loss)
I0521 20:13:58.084686  7510 sgd_solver.cpp:106] Iteration 120000, lr = 0.005
I0521 20:14:15.156481  7510 solver.cpp:237] Iteration 121500, loss = 0.96545
I0521 20:14:15.156651  7510 solver.cpp:253]     Train net output #0: loss = 0.965452 (* 1 = 0.965452 loss)
I0521 20:14:15.156666  7510 sgd_solver.cpp:106] Iteration 121500, lr = 0.005
I0521 20:14:32.307073  7510 solver.cpp:237] Iteration 123000, loss = 0.843156
I0521 20:14:32.307111  7510 solver.cpp:253]     Train net output #0: loss = 0.843159 (* 1 = 0.843159 loss)
I0521 20:14:32.307123  7510 sgd_solver.cpp:106] Iteration 123000, lr = 0.005
I0521 20:14:49.461921  7510 solver.cpp:237] Iteration 124500, loss = 1.61965
I0521 20:14:49.462077  7510 solver.cpp:253]     Train net output #0: loss = 1.61965 (* 1 = 1.61965 loss)
I0521 20:14:49.462093  7510 sgd_solver.cpp:106] Iteration 124500, lr = 0.005
I0521 20:15:06.626893  7510 solver.cpp:237] Iteration 126000, loss = 1.02981
I0521 20:15:06.626934  7510 solver.cpp:253]     Train net output #0: loss = 1.02981 (* 1 = 1.02981 loss)
I0521 20:15:06.626955  7510 sgd_solver.cpp:106] Iteration 126000, lr = 0.005
I0521 20:15:23.807438  7510 solver.cpp:237] Iteration 127500, loss = 1.16887
I0521 20:15:23.807584  7510 solver.cpp:253]     Train net output #0: loss = 1.16887 (* 1 = 1.16887 loss)
I0521 20:15:23.807596  7510 sgd_solver.cpp:106] Iteration 127500, lr = 0.005
I0521 20:15:40.985429  7510 solver.cpp:237] Iteration 129000, loss = 1.21656
I0521 20:15:40.985478  7510 solver.cpp:253]     Train net output #0: loss = 1.21656 (* 1 = 1.21656 loss)
I0521 20:15:40.985492  7510 sgd_solver.cpp:106] Iteration 129000, lr = 0.005
I0521 20:16:20.385577  7510 solver.cpp:237] Iteration 130500, loss = 0.81464
I0521 20:16:20.385748  7510 solver.cpp:253]     Train net output #0: loss = 0.81464 (* 1 = 0.81464 loss)
I0521 20:16:20.385762  7510 sgd_solver.cpp:106] Iteration 130500, lr = 0.005
I0521 20:16:37.549175  7510 solver.cpp:237] Iteration 132000, loss = 0.989572
I0521 20:16:37.549206  7510 solver.cpp:253]     Train net output #0: loss = 0.989571 (* 1 = 0.989571 loss)
I0521 20:16:37.549221  7510 sgd_solver.cpp:106] Iteration 132000, lr = 0.005
I0521 20:16:54.756229  7510 solver.cpp:237] Iteration 133500, loss = 1.21212
I0521 20:16:54.756392  7510 solver.cpp:253]     Train net output #0: loss = 1.21212 (* 1 = 1.21212 loss)
I0521 20:16:54.756405  7510 sgd_solver.cpp:106] Iteration 133500, lr = 0.005
I0521 20:17:11.891588  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_135000.caffemodel
I0521 20:17:11.944188  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_135000.solverstate
I0521 20:17:11.974786  7510 solver.cpp:237] Iteration 135000, loss = 1.49422
I0521 20:17:11.974838  7510 solver.cpp:253]     Train net output #0: loss = 1.49422 (* 1 = 1.49422 loss)
I0521 20:17:11.974853  7510 sgd_solver.cpp:106] Iteration 135000, lr = 0.005
I0521 20:17:29.120450  7510 solver.cpp:237] Iteration 136500, loss = 1.5175
I0521 20:17:29.120604  7510 solver.cpp:253]     Train net output #0: loss = 1.5175 (* 1 = 1.5175 loss)
I0521 20:17:29.120618  7510 sgd_solver.cpp:106] Iteration 136500, lr = 0.005
I0521 20:17:46.278947  7510 solver.cpp:237] Iteration 138000, loss = 2.275
I0521 20:17:46.278998  7510 solver.cpp:253]     Train net output #0: loss = 2.275 (* 1 = 2.275 loss)
I0521 20:17:46.279012  7510 sgd_solver.cpp:106] Iteration 138000, lr = 0.005
I0521 20:18:03.422740  7510 solver.cpp:237] Iteration 139500, loss = 1.15544
I0521 20:18:03.422909  7510 solver.cpp:253]     Train net output #0: loss = 1.15543 (* 1 = 1.15543 loss)
I0521 20:18:03.422924  7510 sgd_solver.cpp:106] Iteration 139500, lr = 0.005
I0521 20:18:42.744398  7510 solver.cpp:237] Iteration 141000, loss = 0.385978
I0521 20:18:42.744572  7510 solver.cpp:253]     Train net output #0: loss = 0.385979 (* 1 = 0.385979 loss)
I0521 20:18:42.744587  7510 sgd_solver.cpp:106] Iteration 141000, lr = 0.005
I0521 20:18:59.919955  7510 solver.cpp:237] Iteration 142500, loss = 1.25925
I0521 20:18:59.920001  7510 solver.cpp:253]     Train net output #0: loss = 1.25925 (* 1 = 1.25925 loss)
I0521 20:18:59.920017  7510 sgd_solver.cpp:106] Iteration 142500, lr = 0.005
I0521 20:19:17.097359  7510 solver.cpp:237] Iteration 144000, loss = 1.4007
I0521 20:19:17.097517  7510 solver.cpp:253]     Train net output #0: loss = 1.4007 (* 1 = 1.4007 loss)
I0521 20:19:17.097532  7510 sgd_solver.cpp:106] Iteration 144000, lr = 0.005
I0521 20:19:34.256469  7510 solver.cpp:237] Iteration 145500, loss = 1.99015
I0521 20:19:34.256503  7510 solver.cpp:253]     Train net output #0: loss = 1.99016 (* 1 = 1.99016 loss)
I0521 20:19:34.256521  7510 sgd_solver.cpp:106] Iteration 145500, lr = 0.005
I0521 20:19:51.446890  7510 solver.cpp:237] Iteration 147000, loss = 1.69554
I0521 20:19:51.447053  7510 solver.cpp:253]     Train net output #0: loss = 1.69554 (* 1 = 1.69554 loss)
I0521 20:19:51.447068  7510 sgd_solver.cpp:106] Iteration 147000, lr = 0.005
I0521 20:20:08.627640  7510 solver.cpp:237] Iteration 148500, loss = 0.964203
I0521 20:20:08.627686  7510 solver.cpp:253]     Train net output #0: loss = 0.964204 (* 1 = 0.964204 loss)
I0521 20:20:08.627702  7510 sgd_solver.cpp:106] Iteration 148500, lr = 0.005
I0521 20:20:25.773336  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_150000.caffemodel
I0521 20:20:25.821442  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_150000.solverstate
I0521 20:20:25.848990  7510 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 20:21:25.063905  7510 solver.cpp:409]     Test net output #0: accuracy = 0.863609
I0521 20:21:25.064069  7510 solver.cpp:409]     Test net output #1: loss = 0.477896 (* 1 = 0.477896 loss)
I0521 20:21:45.899408  7510 solver.cpp:237] Iteration 150000, loss = 0.776848
I0521 20:21:45.899463  7510 solver.cpp:253]     Train net output #0: loss = 0.776849 (* 1 = 0.776849 loss)
I0521 20:21:45.899478  7510 sgd_solver.cpp:106] Iteration 150000, lr = 0.005
I0521 20:22:02.517911  7510 solver.cpp:237] Iteration 151500, loss = 1.7684
I0521 20:22:02.518061  7510 solver.cpp:253]     Train net output #0: loss = 1.7684 (* 1 = 1.7684 loss)
I0521 20:22:02.518074  7510 sgd_solver.cpp:106] Iteration 151500, lr = 0.005
I0521 20:22:19.120857  7510 solver.cpp:237] Iteration 153000, loss = 1.58566
I0521 20:22:19.120910  7510 solver.cpp:253]     Train net output #0: loss = 1.58566 (* 1 = 1.58566 loss)
I0521 20:22:19.120925  7510 sgd_solver.cpp:106] Iteration 153000, lr = 0.005
I0521 20:22:35.732254  7510 solver.cpp:237] Iteration 154500, loss = 1.02056
I0521 20:22:35.732415  7510 solver.cpp:253]     Train net output #0: loss = 1.02056 (* 1 = 1.02056 loss)
I0521 20:22:35.732429  7510 sgd_solver.cpp:106] Iteration 154500, lr = 0.005
I0521 20:22:52.306174  7510 solver.cpp:237] Iteration 156000, loss = 0.84368
I0521 20:22:52.306210  7510 solver.cpp:253]     Train net output #0: loss = 0.84368 (* 1 = 0.84368 loss)
I0521 20:22:52.306226  7510 sgd_solver.cpp:106] Iteration 156000, lr = 0.005
I0521 20:23:08.896829  7510 solver.cpp:237] Iteration 157500, loss = 0.957163
I0521 20:23:08.897011  7510 solver.cpp:253]     Train net output #0: loss = 0.957163 (* 1 = 0.957163 loss)
I0521 20:23:08.897027  7510 sgd_solver.cpp:106] Iteration 157500, lr = 0.005
I0521 20:23:25.537797  7510 solver.cpp:237] Iteration 159000, loss = 1.8199
I0521 20:23:25.537843  7510 solver.cpp:253]     Train net output #0: loss = 1.8199 (* 1 = 1.8199 loss)
I0521 20:23:25.537859  7510 sgd_solver.cpp:106] Iteration 159000, lr = 0.005
I0521 20:24:03.009716  7510 solver.cpp:237] Iteration 160500, loss = 0.703637
I0521 20:24:03.009884  7510 solver.cpp:253]     Train net output #0: loss = 0.703636 (* 1 = 0.703636 loss)
I0521 20:24:03.009901  7510 sgd_solver.cpp:106] Iteration 160500, lr = 0.005
I0521 20:24:19.613109  7510 solver.cpp:237] Iteration 162000, loss = 1.23743
I0521 20:24:19.613159  7510 solver.cpp:253]     Train net output #0: loss = 1.23743 (* 1 = 1.23743 loss)
I0521 20:24:19.613174  7510 sgd_solver.cpp:106] Iteration 162000, lr = 0.005
I0521 20:24:36.223742  7510 solver.cpp:237] Iteration 163500, loss = 1.56327
I0521 20:24:36.223904  7510 solver.cpp:253]     Train net output #0: loss = 1.56327 (* 1 = 1.56327 loss)
I0521 20:24:36.223918  7510 sgd_solver.cpp:106] Iteration 163500, lr = 0.005
I0521 20:24:52.829129  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_165000.caffemodel
I0521 20:24:52.874991  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_165000.solverstate
I0521 20:24:52.903312  7510 solver.cpp:237] Iteration 165000, loss = 0.583442
I0521 20:24:52.903359  7510 solver.cpp:253]     Train net output #0: loss = 0.583442 (* 1 = 0.583442 loss)
I0521 20:24:52.903373  7510 sgd_solver.cpp:106] Iteration 165000, lr = 0.005
I0521 20:25:09.521317  7510 solver.cpp:237] Iteration 166500, loss = 1.4669
I0521 20:25:09.521481  7510 solver.cpp:253]     Train net output #0: loss = 1.4669 (* 1 = 1.4669 loss)
I0521 20:25:09.521495  7510 sgd_solver.cpp:106] Iteration 166500, lr = 0.005
I0521 20:25:26.157531  7510 solver.cpp:237] Iteration 168000, loss = 0.679752
I0521 20:25:26.157583  7510 solver.cpp:253]     Train net output #0: loss = 0.679753 (* 1 = 0.679753 loss)
I0521 20:25:26.157598  7510 sgd_solver.cpp:106] Iteration 168000, lr = 0.005
I0521 20:25:42.766218  7510 solver.cpp:237] Iteration 169500, loss = 1.16746
I0521 20:25:42.766371  7510 solver.cpp:253]     Train net output #0: loss = 1.16746 (* 1 = 1.16746 loss)
I0521 20:25:42.766383  7510 sgd_solver.cpp:106] Iteration 169500, lr = 0.005
I0521 20:26:20.258745  7510 solver.cpp:237] Iteration 171000, loss = 0.82457
I0521 20:26:20.258918  7510 solver.cpp:253]     Train net output #0: loss = 0.824571 (* 1 = 0.824571 loss)
I0521 20:26:20.258931  7510 sgd_solver.cpp:106] Iteration 171000, lr = 0.005
I0521 20:26:36.877941  7510 solver.cpp:237] Iteration 172500, loss = 0.965063
I0521 20:26:36.877977  7510 solver.cpp:253]     Train net output #0: loss = 0.965064 (* 1 = 0.965064 loss)
I0521 20:26:36.877995  7510 sgd_solver.cpp:106] Iteration 172500, lr = 0.005
I0521 20:26:53.540644  7510 solver.cpp:237] Iteration 174000, loss = 0.977392
I0521 20:26:53.540802  7510 solver.cpp:253]     Train net output #0: loss = 0.977394 (* 1 = 0.977394 loss)
I0521 20:26:53.540815  7510 sgd_solver.cpp:106] Iteration 174000, lr = 0.005
I0521 20:27:10.122752  7510 solver.cpp:237] Iteration 175500, loss = 0.96393
I0521 20:27:10.122798  7510 solver.cpp:253]     Train net output #0: loss = 0.963932 (* 1 = 0.963932 loss)
I0521 20:27:10.122812  7510 sgd_solver.cpp:106] Iteration 175500, lr = 0.005
I0521 20:27:26.741711  7510 solver.cpp:237] Iteration 177000, loss = 1.79758
I0521 20:27:26.741859  7510 solver.cpp:253]     Train net output #0: loss = 1.79758 (* 1 = 1.79758 loss)
I0521 20:27:26.741873  7510 sgd_solver.cpp:106] Iteration 177000, lr = 0.005
I0521 20:27:43.330296  7510 solver.cpp:237] Iteration 178500, loss = 1.43262
I0521 20:27:43.330346  7510 solver.cpp:253]     Train net output #0: loss = 1.43262 (* 1 = 1.43262 loss)
I0521 20:27:43.330360  7510 sgd_solver.cpp:106] Iteration 178500, lr = 0.005
I0521 20:27:59.908377  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_180000.caffemodel
I0521 20:27:59.954252  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_180000.solverstate
I0521 20:27:59.979666  7510 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 20:29:19.999984  7510 solver.cpp:409]     Test net output #0: accuracy = 0.869656
I0521 20:29:20.000147  7510 solver.cpp:409]     Test net output #1: loss = 0.489725 (* 1 = 0.489725 loss)
I0521 20:29:40.830219  7510 solver.cpp:237] Iteration 180000, loss = 0.710907
I0521 20:29:40.830272  7510 solver.cpp:253]     Train net output #0: loss = 0.710909 (* 1 = 0.710909 loss)
I0521 20:29:40.830287  7510 sgd_solver.cpp:106] Iteration 180000, lr = 0.005
I0521 20:29:57.415107  7510 solver.cpp:237] Iteration 181500, loss = 1.68224
I0521 20:29:57.415273  7510 solver.cpp:253]     Train net output #0: loss = 1.68224 (* 1 = 1.68224 loss)
I0521 20:29:57.415287  7510 sgd_solver.cpp:106] Iteration 181500, lr = 0.005
I0521 20:30:13.976982  7510 solver.cpp:237] Iteration 183000, loss = 0.78589
I0521 20:30:13.977030  7510 solver.cpp:253]     Train net output #0: loss = 0.785892 (* 1 = 0.785892 loss)
I0521 20:30:13.977046  7510 sgd_solver.cpp:106] Iteration 183000, lr = 0.005
I0521 20:30:30.584051  7510 solver.cpp:237] Iteration 184500, loss = 1.16376
I0521 20:30:30.584221  7510 solver.cpp:253]     Train net output #0: loss = 1.16377 (* 1 = 1.16377 loss)
I0521 20:30:30.584235  7510 sgd_solver.cpp:106] Iteration 184500, lr = 0.005
I0521 20:30:47.162041  7510 solver.cpp:237] Iteration 186000, loss = 1.03116
I0521 20:30:47.162077  7510 solver.cpp:253]     Train net output #0: loss = 1.03116 (* 1 = 1.03116 loss)
I0521 20:30:47.162093  7510 sgd_solver.cpp:106] Iteration 186000, lr = 0.005
I0521 20:31:03.753922  7510 solver.cpp:237] Iteration 187500, loss = 1.07944
I0521 20:31:03.754081  7510 solver.cpp:253]     Train net output #0: loss = 1.07944 (* 1 = 1.07944 loss)
I0521 20:31:03.754093  7510 sgd_solver.cpp:106] Iteration 187500, lr = 0.005
I0521 20:31:20.380771  7510 solver.cpp:237] Iteration 189000, loss = 0.998633
I0521 20:31:20.380815  7510 solver.cpp:253]     Train net output #0: loss = 0.998635 (* 1 = 0.998635 loss)
I0521 20:31:20.380831  7510 sgd_solver.cpp:106] Iteration 189000, lr = 0.005
I0521 20:31:57.815227  7510 solver.cpp:237] Iteration 190500, loss = 1.51684
I0521 20:31:57.815399  7510 solver.cpp:253]     Train net output #0: loss = 1.51684 (* 1 = 1.51684 loss)
I0521 20:31:57.815413  7510 sgd_solver.cpp:106] Iteration 190500, lr = 0.005
I0521 20:32:14.418329  7510 solver.cpp:237] Iteration 192000, loss = 1.04297
I0521 20:32:14.418376  7510 solver.cpp:253]     Train net output #0: loss = 1.04297 (* 1 = 1.04297 loss)
I0521 20:32:14.418392  7510 sgd_solver.cpp:106] Iteration 192000, lr = 0.005
I0521 20:32:31.022104  7510 solver.cpp:237] Iteration 193500, loss = 0.825985
I0521 20:32:31.022266  7510 solver.cpp:253]     Train net output #0: loss = 0.825988 (* 1 = 0.825988 loss)
I0521 20:32:31.022281  7510 sgd_solver.cpp:106] Iteration 193500, lr = 0.005
I0521 20:32:47.598659  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_195000.caffemodel
I0521 20:32:47.644716  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_195000.solverstate
I0521 20:32:47.673882  7510 solver.cpp:237] Iteration 195000, loss = 0.729529
I0521 20:32:47.673928  7510 solver.cpp:253]     Train net output #0: loss = 0.729532 (* 1 = 0.729532 loss)
I0521 20:32:47.673944  7510 sgd_solver.cpp:106] Iteration 195000, lr = 0.005
I0521 20:33:04.319383  7510 solver.cpp:237] Iteration 196500, loss = 1.69354
I0521 20:33:04.319571  7510 solver.cpp:253]     Train net output #0: loss = 1.69355 (* 1 = 1.69355 loss)
I0521 20:33:04.319586  7510 sgd_solver.cpp:106] Iteration 196500, lr = 0.005
I0521 20:33:20.940743  7510 solver.cpp:237] Iteration 198000, loss = 0.646317
I0521 20:33:20.940794  7510 solver.cpp:253]     Train net output #0: loss = 0.646321 (* 1 = 0.646321 loss)
I0521 20:33:20.940809  7510 sgd_solver.cpp:106] Iteration 198000, lr = 0.005
I0521 20:33:37.545467  7510 solver.cpp:237] Iteration 199500, loss = 0.844934
I0521 20:33:37.545620  7510 solver.cpp:253]     Train net output #0: loss = 0.844938 (* 1 = 0.844938 loss)
I0521 20:33:37.545635  7510 sgd_solver.cpp:106] Iteration 199500, lr = 0.005
I0521 20:34:14.952121  7510 solver.cpp:237] Iteration 201000, loss = 1.23551
I0521 20:34:14.952293  7510 solver.cpp:253]     Train net output #0: loss = 1.23551 (* 1 = 1.23551 loss)
I0521 20:34:14.952307  7510 sgd_solver.cpp:106] Iteration 201000, lr = 0.005
I0521 20:34:31.593247  7510 solver.cpp:237] Iteration 202500, loss = 1.29237
I0521 20:34:31.593284  7510 solver.cpp:253]     Train net output #0: loss = 1.29237 (* 1 = 1.29237 loss)
I0521 20:34:31.593297  7510 sgd_solver.cpp:106] Iteration 202500, lr = 0.005
I0521 20:34:48.213742  7510 solver.cpp:237] Iteration 204000, loss = 1.86385
I0521 20:34:48.213901  7510 solver.cpp:253]     Train net output #0: loss = 1.86385 (* 1 = 1.86385 loss)
I0521 20:34:48.213914  7510 sgd_solver.cpp:106] Iteration 204000, lr = 0.005
I0521 20:35:04.840219  7510 solver.cpp:237] Iteration 205500, loss = 0.864909
I0521 20:35:04.840265  7510 solver.cpp:253]     Train net output #0: loss = 0.864913 (* 1 = 0.864913 loss)
I0521 20:35:04.840278  7510 sgd_solver.cpp:106] Iteration 205500, lr = 0.005
I0521 20:35:21.458245  7510 solver.cpp:237] Iteration 207000, loss = 1.35525
I0521 20:35:21.458395  7510 solver.cpp:253]     Train net output #0: loss = 1.35526 (* 1 = 1.35526 loss)
I0521 20:35:21.458407  7510 sgd_solver.cpp:106] Iteration 207000, lr = 0.005
I0521 20:35:38.418556  7510 solver.cpp:237] Iteration 208500, loss = 1.62577
I0521 20:35:38.418599  7510 solver.cpp:253]     Train net output #0: loss = 1.62577 (* 1 = 1.62577 loss)
I0521 20:35:38.418614  7510 sgd_solver.cpp:106] Iteration 208500, lr = 0.005
I0521 20:35:55.427857  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_210000.caffemodel
I0521 20:35:55.474205  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_210000.solverstate
I0521 20:35:55.499173  7510 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 20:36:54.470082  7510 solver.cpp:409]     Test net output #0: accuracy = 0.866363
I0521 20:36:54.470247  7510 solver.cpp:409]     Test net output #1: loss = 0.456736 (* 1 = 0.456736 loss)
I0521 20:37:15.320116  7510 solver.cpp:237] Iteration 210000, loss = 1.29276
I0521 20:37:15.320170  7510 solver.cpp:253]     Train net output #0: loss = 1.29276 (* 1 = 1.29276 loss)
I0521 20:37:15.320185  7510 sgd_solver.cpp:106] Iteration 210000, lr = 0.005
I0521 20:37:32.081293  7510 solver.cpp:237] Iteration 211500, loss = 0.595429
I0521 20:37:32.081467  7510 solver.cpp:253]     Train net output #0: loss = 0.595434 (* 1 = 0.595434 loss)
I0521 20:37:32.081481  7510 sgd_solver.cpp:106] Iteration 211500, lr = 0.005
I0521 20:37:48.826990  7510 solver.cpp:237] Iteration 213000, loss = 0.920464
I0521 20:37:48.827028  7510 solver.cpp:253]     Train net output #0: loss = 0.920467 (* 1 = 0.920467 loss)
I0521 20:37:48.827041  7510 sgd_solver.cpp:106] Iteration 213000, lr = 0.005
I0521 20:38:05.562086  7510 solver.cpp:237] Iteration 214500, loss = 2.13445
I0521 20:38:05.562260  7510 solver.cpp:253]     Train net output #0: loss = 2.13445 (* 1 = 2.13445 loss)
I0521 20:38:05.562275  7510 sgd_solver.cpp:106] Iteration 214500, lr = 0.005
I0521 20:38:22.304538  7510 solver.cpp:237] Iteration 216000, loss = 1.05253
I0521 20:38:22.304585  7510 solver.cpp:253]     Train net output #0: loss = 1.05253 (* 1 = 1.05253 loss)
I0521 20:38:22.304600  7510 sgd_solver.cpp:106] Iteration 216000, lr = 0.005
I0521 20:38:39.076499  7510 solver.cpp:237] Iteration 217500, loss = 1.21988
I0521 20:38:39.076650  7510 solver.cpp:253]     Train net output #0: loss = 1.21989 (* 1 = 1.21989 loss)
I0521 20:38:39.076664  7510 sgd_solver.cpp:106] Iteration 217500, lr = 0.005
I0521 20:38:55.800237  7510 solver.cpp:237] Iteration 219000, loss = 1.25227
I0521 20:38:55.800285  7510 solver.cpp:253]     Train net output #0: loss = 1.25227 (* 1 = 1.25227 loss)
I0521 20:38:55.800300  7510 sgd_solver.cpp:106] Iteration 219000, lr = 0.005
I0521 20:39:33.240450  7510 solver.cpp:237] Iteration 220500, loss = 1.08707
I0521 20:39:33.240629  7510 solver.cpp:253]     Train net output #0: loss = 1.08708 (* 1 = 1.08708 loss)
I0521 20:39:33.240644  7510 sgd_solver.cpp:106] Iteration 220500, lr = 0.005
I0521 20:39:49.859539  7510 solver.cpp:237] Iteration 222000, loss = 1.40306
I0521 20:39:49.859588  7510 solver.cpp:253]     Train net output #0: loss = 1.40306 (* 1 = 1.40306 loss)
I0521 20:39:49.859602  7510 sgd_solver.cpp:106] Iteration 222000, lr = 0.005
I0521 20:40:06.454463  7510 solver.cpp:237] Iteration 223500, loss = 0.995724
I0521 20:40:06.454630  7510 solver.cpp:253]     Train net output #0: loss = 0.995727 (* 1 = 0.995727 loss)
I0521 20:40:06.454644  7510 sgd_solver.cpp:106] Iteration 223500, lr = 0.005
I0521 20:40:23.037683  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_225000.caffemodel
I0521 20:40:23.085232  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_225000.solverstate
I0521 20:40:23.115751  7510 solver.cpp:237] Iteration 225000, loss = 0.85312
I0521 20:40:23.115804  7510 solver.cpp:253]     Train net output #0: loss = 0.853124 (* 1 = 0.853124 loss)
I0521 20:40:23.115818  7510 sgd_solver.cpp:106] Iteration 225000, lr = 0.005
I0521 20:40:39.687319  7510 solver.cpp:237] Iteration 226500, loss = 1.01945
I0521 20:40:39.687489  7510 solver.cpp:253]     Train net output #0: loss = 1.01945 (* 1 = 1.01945 loss)
I0521 20:40:39.687505  7510 sgd_solver.cpp:106] Iteration 226500, lr = 0.005
I0521 20:40:56.367704  7510 solver.cpp:237] Iteration 228000, loss = 1.00718
I0521 20:40:56.367754  7510 solver.cpp:253]     Train net output #0: loss = 1.00718 (* 1 = 1.00718 loss)
I0521 20:40:56.367769  7510 sgd_solver.cpp:106] Iteration 228000, lr = 0.005
I0521 20:41:13.301384  7510 solver.cpp:237] Iteration 229500, loss = 0.977766
I0521 20:41:13.301540  7510 solver.cpp:253]     Train net output #0: loss = 0.977769 (* 1 = 0.977769 loss)
I0521 20:41:13.301554  7510 sgd_solver.cpp:106] Iteration 229500, lr = 0.005
I0521 20:41:51.089972  7510 solver.cpp:237] Iteration 231000, loss = 1.13512
I0521 20:41:51.090147  7510 solver.cpp:253]     Train net output #0: loss = 1.13512 (* 1 = 1.13512 loss)
I0521 20:41:51.090160  7510 sgd_solver.cpp:106] Iteration 231000, lr = 0.005
I0521 20:42:08.077050  7510 solver.cpp:237] Iteration 232500, loss = 0.99376
I0521 20:42:08.077092  7510 solver.cpp:253]     Train net output #0: loss = 0.993762 (* 1 = 0.993762 loss)
I0521 20:42:08.077116  7510 sgd_solver.cpp:106] Iteration 232500, lr = 0.005
I0521 20:42:25.006521  7510 solver.cpp:237] Iteration 234000, loss = 1.38387
I0521 20:42:25.006667  7510 solver.cpp:253]     Train net output #0: loss = 1.38387 (* 1 = 1.38387 loss)
I0521 20:42:25.006681  7510 sgd_solver.cpp:106] Iteration 234000, lr = 0.005
I0521 20:42:41.951699  7510 solver.cpp:237] Iteration 235500, loss = 1.16246
I0521 20:42:41.951741  7510 solver.cpp:253]     Train net output #0: loss = 1.16246 (* 1 = 1.16246 loss)
I0521 20:42:41.951758  7510 sgd_solver.cpp:106] Iteration 235500, lr = 0.005
I0521 20:42:58.880640  7510 solver.cpp:237] Iteration 237000, loss = 0.958378
I0521 20:42:58.880822  7510 solver.cpp:253]     Train net output #0: loss = 0.958381 (* 1 = 0.958381 loss)
I0521 20:42:58.880836  7510 sgd_solver.cpp:106] Iteration 237000, lr = 0.005
I0521 20:43:15.835660  7510 solver.cpp:237] Iteration 238500, loss = 1.56072
I0521 20:43:15.835695  7510 solver.cpp:253]     Train net output #0: loss = 1.56072 (* 1 = 1.56072 loss)
I0521 20:43:15.835712  7510 sgd_solver.cpp:106] Iteration 238500, lr = 0.005
I0521 20:43:32.759645  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_240000.caffemodel
I0521 20:43:32.805603  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_240000.solverstate
I0521 20:43:32.830777  7510 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 20:44:52.957187  7510 solver.cpp:409]     Test net output #0: accuracy = 0.867423
I0521 20:44:52.957361  7510 solver.cpp:409]     Test net output #1: loss = 0.446685 (* 1 = 0.446685 loss)
I0521 20:45:13.813207  7510 solver.cpp:237] Iteration 240000, loss = 0.967529
I0521 20:45:13.813261  7510 solver.cpp:253]     Train net output #0: loss = 0.967532 (* 1 = 0.967532 loss)
I0521 20:45:13.813277  7510 sgd_solver.cpp:106] Iteration 240000, lr = 0.005
I0521 20:45:30.619814  7510 solver.cpp:237] Iteration 241500, loss = 0.716249
I0521 20:45:30.619984  7510 solver.cpp:253]     Train net output #0: loss = 0.716252 (* 1 = 0.716252 loss)
I0521 20:45:30.619999  7510 sgd_solver.cpp:106] Iteration 241500, lr = 0.005
I0521 20:45:47.501051  7510 solver.cpp:237] Iteration 243000, loss = 2.61186
I0521 20:45:47.501087  7510 solver.cpp:253]     Train net output #0: loss = 2.61186 (* 1 = 2.61186 loss)
I0521 20:45:47.501104  7510 sgd_solver.cpp:106] Iteration 243000, lr = 0.005
I0521 20:46:04.405138  7510 solver.cpp:237] Iteration 244500, loss = 1.20686
I0521 20:46:04.405300  7510 solver.cpp:253]     Train net output #0: loss = 1.20686 (* 1 = 1.20686 loss)
I0521 20:46:04.405318  7510 sgd_solver.cpp:106] Iteration 244500, lr = 0.005
I0521 20:46:21.249157  7510 solver.cpp:237] Iteration 246000, loss = 1.14794
I0521 20:46:21.249207  7510 solver.cpp:253]     Train net output #0: loss = 1.14794 (* 1 = 1.14794 loss)
I0521 20:46:21.249220  7510 sgd_solver.cpp:106] Iteration 246000, lr = 0.005
I0521 20:46:38.181190  7510 solver.cpp:237] Iteration 247500, loss = 1.1317
I0521 20:46:38.181344  7510 solver.cpp:253]     Train net output #0: loss = 1.13171 (* 1 = 1.13171 loss)
I0521 20:46:38.181357  7510 sgd_solver.cpp:106] Iteration 247500, lr = 0.005
I0521 20:46:55.075645  7510 solver.cpp:237] Iteration 249000, loss = 0.565704
I0521 20:46:55.075693  7510 solver.cpp:253]     Train net output #0: loss = 0.565706 (* 1 = 0.565706 loss)
I0521 20:46:55.075707  7510 sgd_solver.cpp:106] Iteration 249000, lr = 0.005
I0521 20:47:32.835602  7510 solver.cpp:237] Iteration 250500, loss = 0.834012
I0521 20:47:32.835798  7510 solver.cpp:253]     Train net output #0: loss = 0.834012 (* 1 = 0.834012 loss)
I0521 20:47:32.835811  7510 sgd_solver.cpp:106] Iteration 250500, lr = 0.005
I0521 20:47:49.735064  7510 solver.cpp:237] Iteration 252000, loss = 1.36056
I0521 20:47:49.735101  7510 solver.cpp:253]     Train net output #0: loss = 1.36056 (* 1 = 1.36056 loss)
I0521 20:47:49.735117  7510 sgd_solver.cpp:106] Iteration 252000, lr = 0.005
I0521 20:48:06.594251  7510 solver.cpp:237] Iteration 253500, loss = 1.43695
I0521 20:48:06.594422  7510 solver.cpp:253]     Train net output #0: loss = 1.43695 (* 1 = 1.43695 loss)
I0521 20:48:06.594439  7510 sgd_solver.cpp:106] Iteration 253500, lr = 0.005
I0521 20:48:23.428853  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_255000.caffemodel
I0521 20:48:23.475411  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_255000.solverstate
I0521 20:48:23.504320  7510 solver.cpp:237] Iteration 255000, loss = 1.86082
I0521 20:48:23.504369  7510 solver.cpp:253]     Train net output #0: loss = 1.86082 (* 1 = 1.86082 loss)
I0521 20:48:23.504384  7510 sgd_solver.cpp:106] Iteration 255000, lr = 0.005
I0521 20:48:40.314769  7510 solver.cpp:237] Iteration 256500, loss = 1.11321
I0521 20:48:40.314939  7510 solver.cpp:253]     Train net output #0: loss = 1.11321 (* 1 = 1.11321 loss)
I0521 20:48:40.314954  7510 sgd_solver.cpp:106] Iteration 256500, lr = 0.005
I0521 20:48:57.188426  7510 solver.cpp:237] Iteration 258000, loss = 0.999547
I0521 20:48:57.188478  7510 solver.cpp:253]     Train net output #0: loss = 0.999548 (* 1 = 0.999548 loss)
I0521 20:48:57.188493  7510 sgd_solver.cpp:106] Iteration 258000, lr = 0.005
I0521 20:49:14.023478  7510 solver.cpp:237] Iteration 259500, loss = 1.11248
I0521 20:49:14.023650  7510 solver.cpp:253]     Train net output #0: loss = 1.11248 (* 1 = 1.11248 loss)
I0521 20:49:14.023664  7510 sgd_solver.cpp:106] Iteration 259500, lr = 0.005
I0521 20:49:51.510538  7510 solver.cpp:237] Iteration 261000, loss = 1.08307
I0521 20:49:51.510712  7510 solver.cpp:253]     Train net output #0: loss = 1.08307 (* 1 = 1.08307 loss)
I0521 20:49:51.510726  7510 sgd_solver.cpp:106] Iteration 261000, lr = 0.005
I0521 20:50:08.090376  7510 solver.cpp:237] Iteration 262500, loss = 2.4116
I0521 20:50:08.090425  7510 solver.cpp:253]     Train net output #0: loss = 2.4116 (* 1 = 2.4116 loss)
I0521 20:50:08.090437  7510 sgd_solver.cpp:106] Iteration 262500, lr = 0.005
I0521 20:50:24.687867  7510 solver.cpp:237] Iteration 264000, loss = 1.6944
I0521 20:50:24.688022  7510 solver.cpp:253]     Train net output #0: loss = 1.6944 (* 1 = 1.6944 loss)
I0521 20:50:24.688035  7510 sgd_solver.cpp:106] Iteration 264000, lr = 0.005
I0521 20:50:41.298182  7510 solver.cpp:237] Iteration 265500, loss = 1.16776
I0521 20:50:41.298231  7510 solver.cpp:253]     Train net output #0: loss = 1.16776 (* 1 = 1.16776 loss)
I0521 20:50:41.298245  7510 sgd_solver.cpp:106] Iteration 265500, lr = 0.005
I0521 20:50:57.894728  7510 solver.cpp:237] Iteration 267000, loss = 0.754367
I0521 20:50:57.894896  7510 solver.cpp:253]     Train net output #0: loss = 0.754369 (* 1 = 0.754369 loss)
I0521 20:50:57.894909  7510 sgd_solver.cpp:106] Iteration 267000, lr = 0.005
I0521 20:51:14.501929  7510 solver.cpp:237] Iteration 268500, loss = 1.78753
I0521 20:51:14.501965  7510 solver.cpp:253]     Train net output #0: loss = 1.78753 (* 1 = 1.78753 loss)
I0521 20:51:14.501978  7510 sgd_solver.cpp:106] Iteration 268500, lr = 0.005
I0521 20:51:31.095398  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_270000.caffemodel
I0521 20:51:31.140879  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_270000.solverstate
I0521 20:51:31.166208  7510 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 20:52:30.666306  7510 solver.cpp:409]     Test net output #0: accuracy = 0.872758
I0521 20:52:30.666465  7510 solver.cpp:409]     Test net output #1: loss = 0.41444 (* 1 = 0.41444 loss)
I0521 20:52:51.550417  7510 solver.cpp:237] Iteration 270000, loss = 2.34742
I0521 20:52:51.550472  7510 solver.cpp:253]     Train net output #0: loss = 2.34742 (* 1 = 2.34742 loss)
I0521 20:52:51.550487  7510 sgd_solver.cpp:106] Iteration 270000, lr = 0.005
I0521 20:53:08.711576  7510 solver.cpp:237] Iteration 271500, loss = 1.79786
I0521 20:53:08.711752  7510 solver.cpp:253]     Train net output #0: loss = 1.79786 (* 1 = 1.79786 loss)
I0521 20:53:08.711766  7510 sgd_solver.cpp:106] Iteration 271500, lr = 0.005
I0521 20:53:25.881184  7510 solver.cpp:237] Iteration 273000, loss = 1.16874
I0521 20:53:25.881233  7510 solver.cpp:253]     Train net output #0: loss = 1.16874 (* 1 = 1.16874 loss)
I0521 20:53:25.881250  7510 sgd_solver.cpp:106] Iteration 273000, lr = 0.005
I0521 20:53:43.051496  7510 solver.cpp:237] Iteration 274500, loss = 1.21343
I0521 20:53:43.051662  7510 solver.cpp:253]     Train net output #0: loss = 1.21343 (* 1 = 1.21343 loss)
I0521 20:53:43.051676  7510 sgd_solver.cpp:106] Iteration 274500, lr = 0.005
I0521 20:54:00.225389  7510 solver.cpp:237] Iteration 276000, loss = 1.58829
I0521 20:54:00.225438  7510 solver.cpp:253]     Train net output #0: loss = 1.58829 (* 1 = 1.58829 loss)
I0521 20:54:00.225453  7510 sgd_solver.cpp:106] Iteration 276000, lr = 0.005
I0521 20:54:17.391054  7510 solver.cpp:237] Iteration 277500, loss = 0.858694
I0521 20:54:17.391232  7510 solver.cpp:253]     Train net output #0: loss = 0.858696 (* 1 = 0.858696 loss)
I0521 20:54:17.391247  7510 sgd_solver.cpp:106] Iteration 277500, lr = 0.005
I0521 20:54:34.596230  7510 solver.cpp:237] Iteration 279000, loss = 0.976989
I0521 20:54:34.596268  7510 solver.cpp:253]     Train net output #0: loss = 0.97699 (* 1 = 0.97699 loss)
I0521 20:54:34.596283  7510 sgd_solver.cpp:106] Iteration 279000, lr = 0.005
I0521 20:55:12.654800  7510 solver.cpp:237] Iteration 280500, loss = 0.676414
I0521 20:55:12.654983  7510 solver.cpp:253]     Train net output #0: loss = 0.676416 (* 1 = 0.676416 loss)
I0521 20:55:12.654996  7510 sgd_solver.cpp:106] Iteration 280500, lr = 0.005
I0521 20:55:29.812780  7510 solver.cpp:237] Iteration 282000, loss = 1.08605
I0521 20:55:29.812825  7510 solver.cpp:253]     Train net output #0: loss = 1.08605 (* 1 = 1.08605 loss)
I0521 20:55:29.812842  7510 sgd_solver.cpp:106] Iteration 282000, lr = 0.005
I0521 20:55:46.989892  7510 solver.cpp:237] Iteration 283500, loss = 0.751965
I0521 20:55:46.990044  7510 solver.cpp:253]     Train net output #0: loss = 0.751968 (* 1 = 0.751968 loss)
I0521 20:55:46.990058  7510 sgd_solver.cpp:106] Iteration 283500, lr = 0.005
I0521 20:56:04.175832  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_285000.caffemodel
I0521 20:56:04.224253  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_285000.solverstate
I0521 20:56:04.255062  7510 solver.cpp:237] Iteration 285000, loss = 2.54288
I0521 20:56:04.255113  7510 solver.cpp:253]     Train net output #0: loss = 2.54288 (* 1 = 2.54288 loss)
I0521 20:56:04.255127  7510 sgd_solver.cpp:106] Iteration 285000, lr = 0.005
I0521 20:56:21.431864  7510 solver.cpp:237] Iteration 286500, loss = 0.795365
I0521 20:56:21.432039  7510 solver.cpp:253]     Train net output #0: loss = 0.795368 (* 1 = 0.795368 loss)
I0521 20:56:21.432052  7510 sgd_solver.cpp:106] Iteration 286500, lr = 0.005
I0521 20:56:38.561180  7510 solver.cpp:237] Iteration 288000, loss = 2.76743
I0521 20:56:38.561216  7510 solver.cpp:253]     Train net output #0: loss = 2.76743 (* 1 = 2.76743 loss)
I0521 20:56:38.561233  7510 sgd_solver.cpp:106] Iteration 288000, lr = 0.005
I0521 20:56:55.724761  7510 solver.cpp:237] Iteration 289500, loss = 1.01841
I0521 20:56:55.724933  7510 solver.cpp:253]     Train net output #0: loss = 1.01841 (* 1 = 1.01841 loss)
I0521 20:56:55.724947  7510 sgd_solver.cpp:106] Iteration 289500, lr = 0.005
I0521 20:57:33.747440  7510 solver.cpp:237] Iteration 291000, loss = 1.01605
I0521 20:57:33.747622  7510 solver.cpp:253]     Train net output #0: loss = 1.01605 (* 1 = 1.01605 loss)
I0521 20:57:33.747635  7510 sgd_solver.cpp:106] Iteration 291000, lr = 0.005
I0521 20:57:50.907945  7510 solver.cpp:237] Iteration 292500, loss = 1.29037
I0521 20:57:50.907980  7510 solver.cpp:253]     Train net output #0: loss = 1.29037 (* 1 = 1.29037 loss)
I0521 20:57:50.907999  7510 sgd_solver.cpp:106] Iteration 292500, lr = 0.005
I0521 20:58:08.058606  7510 solver.cpp:237] Iteration 294000, loss = 2.08281
I0521 20:58:08.058781  7510 solver.cpp:253]     Train net output #0: loss = 2.08281 (* 1 = 2.08281 loss)
I0521 20:58:08.058795  7510 sgd_solver.cpp:106] Iteration 294000, lr = 0.005
I0521 20:58:25.244067  7510 solver.cpp:237] Iteration 295500, loss = 1.96551
I0521 20:58:25.244115  7510 solver.cpp:253]     Train net output #0: loss = 1.96551 (* 1 = 1.96551 loss)
I0521 20:58:25.244129  7510 sgd_solver.cpp:106] Iteration 295500, lr = 0.005
I0521 20:58:42.431849  7510 solver.cpp:237] Iteration 297000, loss = 1.72171
I0521 20:58:42.432009  7510 solver.cpp:253]     Train net output #0: loss = 1.72171 (* 1 = 1.72171 loss)
I0521 20:58:42.432023  7510 sgd_solver.cpp:106] Iteration 297000, lr = 0.005
I0521 20:58:59.610095  7510 solver.cpp:237] Iteration 298500, loss = 1.04357
I0521 20:58:59.610141  7510 solver.cpp:253]     Train net output #0: loss = 1.04357 (* 1 = 1.04357 loss)
I0521 20:58:59.610154  7510 sgd_solver.cpp:106] Iteration 298500, lr = 0.005
I0521 20:59:16.791721  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_300000.caffemodel
I0521 20:59:16.839684  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_300000.solverstate
I0521 20:59:16.867440  7510 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 21:00:37.041525  7510 solver.cpp:409]     Test net output #0: accuracy = 0.855205
I0521 21:00:37.041703  7510 solver.cpp:409]     Test net output #1: loss = 0.488185 (* 1 = 0.488185 loss)
I0521 21:00:57.944007  7510 solver.cpp:237] Iteration 300000, loss = 1.10363
I0521 21:00:57.944061  7510 solver.cpp:253]     Train net output #0: loss = 1.10363 (* 1 = 1.10363 loss)
I0521 21:00:57.944075  7510 sgd_solver.cpp:106] Iteration 300000, lr = 0.005
I0521 21:01:14.560158  7510 solver.cpp:237] Iteration 301500, loss = 1.38078
I0521 21:01:14.560322  7510 solver.cpp:253]     Train net output #0: loss = 1.38078 (* 1 = 1.38078 loss)
I0521 21:01:14.560336  7510 sgd_solver.cpp:106] Iteration 301500, lr = 0.005
I0521 21:01:31.185369  7510 solver.cpp:237] Iteration 303000, loss = 1.19781
I0521 21:01:31.185420  7510 solver.cpp:253]     Train net output #0: loss = 1.19781 (* 1 = 1.19781 loss)
I0521 21:01:31.185433  7510 sgd_solver.cpp:106] Iteration 303000, lr = 0.005
I0521 21:01:47.800117  7510 solver.cpp:237] Iteration 304500, loss = 1.4493
I0521 21:01:47.800288  7510 solver.cpp:253]     Train net output #0: loss = 1.4493 (* 1 = 1.4493 loss)
I0521 21:01:47.800302  7510 sgd_solver.cpp:106] Iteration 304500, lr = 0.005
I0521 21:02:04.430706  7510 solver.cpp:237] Iteration 306000, loss = 1.01904
I0521 21:02:04.430742  7510 solver.cpp:253]     Train net output #0: loss = 1.01904 (* 1 = 1.01904 loss)
I0521 21:02:04.430764  7510 sgd_solver.cpp:106] Iteration 306000, lr = 0.005
I0521 21:02:21.049943  7510 solver.cpp:237] Iteration 307500, loss = 1.41868
I0521 21:02:21.050102  7510 solver.cpp:253]     Train net output #0: loss = 1.41868 (* 1 = 1.41868 loss)
I0521 21:02:21.050117  7510 sgd_solver.cpp:106] Iteration 307500, lr = 0.005
I0521 21:02:37.673141  7510 solver.cpp:237] Iteration 309000, loss = 1.7069
I0521 21:02:37.673187  7510 solver.cpp:253]     Train net output #0: loss = 1.7069 (* 1 = 1.7069 loss)
I0521 21:02:37.673202  7510 sgd_solver.cpp:106] Iteration 309000, lr = 0.005
I0521 21:03:15.134011  7510 solver.cpp:237] Iteration 310500, loss = 0.927639
I0521 21:03:15.134193  7510 solver.cpp:253]     Train net output #0: loss = 0.92764 (* 1 = 0.92764 loss)
I0521 21:03:15.134209  7510 sgd_solver.cpp:106] Iteration 310500, lr = 0.005
I0521 21:03:31.767861  7510 solver.cpp:237] Iteration 312000, loss = 1.02289
I0521 21:03:31.767910  7510 solver.cpp:253]     Train net output #0: loss = 1.0229 (* 1 = 1.0229 loss)
I0521 21:03:31.767925  7510 sgd_solver.cpp:106] Iteration 312000, lr = 0.005
I0521 21:03:48.378139  7510 solver.cpp:237] Iteration 313500, loss = 1.94967
I0521 21:03:48.378329  7510 solver.cpp:253]     Train net output #0: loss = 1.94967 (* 1 = 1.94967 loss)
I0521 21:03:48.378343  7510 sgd_solver.cpp:106] Iteration 313500, lr = 0.005
I0521 21:04:04.970083  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_315000.caffemodel
I0521 21:04:05.015396  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_315000.solverstate
I0521 21:04:05.044147  7510 solver.cpp:237] Iteration 315000, loss = 0.61416
I0521 21:04:05.044194  7510 solver.cpp:253]     Train net output #0: loss = 0.614161 (* 1 = 0.614161 loss)
I0521 21:04:05.044209  7510 sgd_solver.cpp:106] Iteration 315000, lr = 0.005
I0521 21:04:21.640990  7510 solver.cpp:237] Iteration 316500, loss = 0.894327
I0521 21:04:21.641162  7510 solver.cpp:253]     Train net output #0: loss = 0.894328 (* 1 = 0.894328 loss)
I0521 21:04:21.641177  7510 sgd_solver.cpp:106] Iteration 316500, lr = 0.005
I0521 21:04:38.424418  7510 solver.cpp:237] Iteration 318000, loss = 0.824343
I0521 21:04:38.424463  7510 solver.cpp:253]     Train net output #0: loss = 0.824344 (* 1 = 0.824344 loss)
I0521 21:04:38.424484  7510 sgd_solver.cpp:106] Iteration 318000, lr = 0.005
I0521 21:04:55.287525  7510 solver.cpp:237] Iteration 319500, loss = 1.23076
I0521 21:04:55.287683  7510 solver.cpp:253]     Train net output #0: loss = 1.23076 (* 1 = 1.23076 loss)
I0521 21:04:55.287698  7510 sgd_solver.cpp:106] Iteration 319500, lr = 0.005
I0521 21:05:33.019093  7510 solver.cpp:237] Iteration 321000, loss = 0.683369
I0521 21:05:33.019273  7510 solver.cpp:253]     Train net output #0: loss = 0.68337 (* 1 = 0.68337 loss)
I0521 21:05:33.019287  7510 sgd_solver.cpp:106] Iteration 321000, lr = 0.005
I0521 21:05:49.836295  7510 solver.cpp:237] Iteration 322500, loss = 1.12941
I0521 21:05:49.836331  7510 solver.cpp:253]     Train net output #0: loss = 1.12941 (* 1 = 1.12941 loss)
I0521 21:05:49.836347  7510 sgd_solver.cpp:106] Iteration 322500, lr = 0.005
I0521 21:06:06.648253  7510 solver.cpp:237] Iteration 324000, loss = 1.13233
I0521 21:06:06.648423  7510 solver.cpp:253]     Train net output #0: loss = 1.13233 (* 1 = 1.13233 loss)
I0521 21:06:06.648437  7510 sgd_solver.cpp:106] Iteration 324000, lr = 0.005
I0521 21:06:23.482146  7510 solver.cpp:237] Iteration 325500, loss = 1.22439
I0521 21:06:23.482190  7510 solver.cpp:253]     Train net output #0: loss = 1.22439 (* 1 = 1.22439 loss)
I0521 21:06:23.482204  7510 sgd_solver.cpp:106] Iteration 325500, lr = 0.005
I0521 21:06:40.298081  7510 solver.cpp:237] Iteration 327000, loss = 1.18251
I0521 21:06:40.309599  7510 solver.cpp:253]     Train net output #0: loss = 1.18252 (* 1 = 1.18252 loss)
I0521 21:06:40.309615  7510 sgd_solver.cpp:106] Iteration 327000, lr = 0.005
I0521 21:06:57.113893  7510 solver.cpp:237] Iteration 328500, loss = 1.59887
I0521 21:06:57.113929  7510 solver.cpp:253]     Train net output #0: loss = 1.59887 (* 1 = 1.59887 loss)
I0521 21:06:57.113942  7510 sgd_solver.cpp:106] Iteration 328500, lr = 0.005
I0521 21:07:13.977843  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_330000.caffemodel
I0521 21:07:14.023529  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_330000.solverstate
I0521 21:07:14.049393  7510 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 21:08:13.286672  7510 solver.cpp:409]     Test net output #0: accuracy = 0.872366
I0521 21:08:13.286850  7510 solver.cpp:409]     Test net output #1: loss = 0.410478 (* 1 = 0.410478 loss)
I0521 21:08:34.166788  7510 solver.cpp:237] Iteration 330000, loss = 1.26501
I0521 21:08:34.166841  7510 solver.cpp:253]     Train net output #0: loss = 1.26501 (* 1 = 1.26501 loss)
I0521 21:08:34.166857  7510 sgd_solver.cpp:106] Iteration 330000, lr = 0.005
I0521 21:08:50.771692  7510 solver.cpp:237] Iteration 331500, loss = 0.57512
I0521 21:08:50.771879  7510 solver.cpp:253]     Train net output #0: loss = 0.575122 (* 1 = 0.575122 loss)
I0521 21:08:50.771894  7510 sgd_solver.cpp:106] Iteration 331500, lr = 0.005
I0521 21:09:07.359966  7510 solver.cpp:237] Iteration 333000, loss = 0.889641
I0521 21:09:07.360002  7510 solver.cpp:253]     Train net output #0: loss = 0.889644 (* 1 = 0.889644 loss)
I0521 21:09:07.360018  7510 sgd_solver.cpp:106] Iteration 333000, lr = 0.005
I0521 21:09:23.955171  7510 solver.cpp:237] Iteration 334500, loss = 1.48375
I0521 21:09:23.955344  7510 solver.cpp:253]     Train net output #0: loss = 1.48375 (* 1 = 1.48375 loss)
I0521 21:09:23.955358  7510 sgd_solver.cpp:106] Iteration 334500, lr = 0.005
I0521 21:09:40.544024  7510 solver.cpp:237] Iteration 336000, loss = 1.23187
I0521 21:09:40.544065  7510 solver.cpp:253]     Train net output #0: loss = 1.23187 (* 1 = 1.23187 loss)
I0521 21:09:40.544085  7510 sgd_solver.cpp:106] Iteration 336000, lr = 0.005
I0521 21:09:57.168336  7510 solver.cpp:237] Iteration 337500, loss = 1.57952
I0521 21:09:57.168493  7510 solver.cpp:253]     Train net output #0: loss = 1.57952 (* 1 = 1.57952 loss)
I0521 21:09:57.168508  7510 sgd_solver.cpp:106] Iteration 337500, lr = 0.005
I0521 21:10:13.757486  7510 solver.cpp:237] Iteration 339000, loss = 1.17075
I0521 21:10:13.757534  7510 solver.cpp:253]     Train net output #0: loss = 1.17075 (* 1 = 1.17075 loss)
I0521 21:10:13.757550  7510 sgd_solver.cpp:106] Iteration 339000, lr = 0.005
I0521 21:10:51.312168  7510 solver.cpp:237] Iteration 340500, loss = 1.72029
I0521 21:10:51.312347  7510 solver.cpp:253]     Train net output #0: loss = 1.72029 (* 1 = 1.72029 loss)
I0521 21:10:51.312361  7510 sgd_solver.cpp:106] Iteration 340500, lr = 0.005
I0521 21:11:07.905174  7510 solver.cpp:237] Iteration 342000, loss = 0.98405
I0521 21:11:07.905210  7510 solver.cpp:253]     Train net output #0: loss = 0.984052 (* 1 = 0.984052 loss)
I0521 21:11:07.905225  7510 sgd_solver.cpp:106] Iteration 342000, lr = 0.005
I0521 21:11:24.542855  7510 solver.cpp:237] Iteration 343500, loss = 1.46896
I0521 21:11:24.543020  7510 solver.cpp:253]     Train net output #0: loss = 1.46896 (* 1 = 1.46896 loss)
I0521 21:11:24.543033  7510 sgd_solver.cpp:106] Iteration 343500, lr = 0.005
I0521 21:11:41.167302  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_345000.caffemodel
I0521 21:11:41.213279  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_345000.solverstate
I0521 21:11:41.241657  7510 solver.cpp:237] Iteration 345000, loss = 1.01232
I0521 21:11:41.241698  7510 solver.cpp:253]     Train net output #0: loss = 1.01232 (* 1 = 1.01232 loss)
I0521 21:11:41.241721  7510 sgd_solver.cpp:106] Iteration 345000, lr = 0.005
I0521 21:11:57.876713  7510 solver.cpp:237] Iteration 346500, loss = 1.08024
I0521 21:11:57.876883  7510 solver.cpp:253]     Train net output #0: loss = 1.08024 (* 1 = 1.08024 loss)
I0521 21:11:57.876898  7510 sgd_solver.cpp:106] Iteration 346500, lr = 0.005
I0521 21:12:14.502832  7510 solver.cpp:237] Iteration 348000, loss = 1.55457
I0521 21:12:14.502879  7510 solver.cpp:253]     Train net output #0: loss = 1.55457 (* 1 = 1.55457 loss)
I0521 21:12:14.502895  7510 sgd_solver.cpp:106] Iteration 348000, lr = 0.005
I0521 21:12:31.242869  7510 solver.cpp:237] Iteration 349500, loss = 1.17577
I0521 21:12:31.243044  7510 solver.cpp:253]     Train net output #0: loss = 1.17577 (* 1 = 1.17577 loss)
I0521 21:12:31.243058  7510 sgd_solver.cpp:106] Iteration 349500, lr = 0.005
I0521 21:13:09.125422  7510 solver.cpp:237] Iteration 351000, loss = 1.26782
I0521 21:13:09.125615  7510 solver.cpp:253]     Train net output #0: loss = 1.26782 (* 1 = 1.26782 loss)
I0521 21:13:09.125629  7510 sgd_solver.cpp:106] Iteration 351000, lr = 0.005
I0521 21:13:26.160514  7510 solver.cpp:237] Iteration 352500, loss = 1.37821
I0521 21:13:26.160558  7510 solver.cpp:253]     Train net output #0: loss = 1.37821 (* 1 = 1.37821 loss)
I0521 21:13:26.160575  7510 sgd_solver.cpp:106] Iteration 352500, lr = 0.005
I0521 21:13:43.128968  7510 solver.cpp:237] Iteration 354000, loss = 1.23731
I0521 21:13:43.129128  7510 solver.cpp:253]     Train net output #0: loss = 1.23731 (* 1 = 1.23731 loss)
I0521 21:13:43.129142  7510 sgd_solver.cpp:106] Iteration 354000, lr = 0.005
I0521 21:14:00.136775  7510 solver.cpp:237] Iteration 355500, loss = 0.758792
I0521 21:14:00.136824  7510 solver.cpp:253]     Train net output #0: loss = 0.758788 (* 1 = 0.758788 loss)
I0521 21:14:00.136838  7510 sgd_solver.cpp:106] Iteration 355500, lr = 0.005
I0521 21:14:17.192737  7510 solver.cpp:237] Iteration 357000, loss = 1.08242
I0521 21:14:17.192914  7510 solver.cpp:253]     Train net output #0: loss = 1.08241 (* 1 = 1.08241 loss)
I0521 21:14:17.192927  7510 sgd_solver.cpp:106] Iteration 357000, lr = 0.005
I0521 21:14:34.230695  7510 solver.cpp:237] Iteration 358500, loss = 0.721209
I0521 21:14:34.230732  7510 solver.cpp:253]     Train net output #0: loss = 0.721205 (* 1 = 0.721205 loss)
I0521 21:14:34.230748  7510 sgd_solver.cpp:106] Iteration 358500, lr = 0.005
I0521 21:14:51.259431  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_360000.caffemodel
I0521 21:14:51.305562  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_360000.solverstate
I0521 21:14:51.330715  7510 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 21:16:11.477413  7510 solver.cpp:409]     Test net output #0: accuracy = 0.866672
I0521 21:16:11.477593  7510 solver.cpp:409]     Test net output #1: loss = 0.477218 (* 1 = 0.477218 loss)
I0521 21:16:32.335996  7510 solver.cpp:237] Iteration 360000, loss = 1.86932
I0521 21:16:32.336050  7510 solver.cpp:253]     Train net output #0: loss = 1.86932 (* 1 = 1.86932 loss)
I0521 21:16:32.336064  7510 sgd_solver.cpp:106] Iteration 360000, lr = 0.005
I0521 21:16:49.075709  7510 solver.cpp:237] Iteration 361500, loss = 0.964261
I0521 21:16:49.075886  7510 solver.cpp:253]     Train net output #0: loss = 0.964257 (* 1 = 0.964257 loss)
I0521 21:16:49.075901  7510 sgd_solver.cpp:106] Iteration 361500, lr = 0.005
I0521 21:17:05.829669  7510 solver.cpp:237] Iteration 363000, loss = 1.90862
I0521 21:17:05.829715  7510 solver.cpp:253]     Train net output #0: loss = 1.90862 (* 1 = 1.90862 loss)
I0521 21:17:05.829732  7510 sgd_solver.cpp:106] Iteration 363000, lr = 0.005
I0521 21:17:22.560423  7510 solver.cpp:237] Iteration 364500, loss = 1.07448
I0521 21:17:22.560585  7510 solver.cpp:253]     Train net output #0: loss = 1.07447 (* 1 = 1.07447 loss)
I0521 21:17:22.560598  7510 sgd_solver.cpp:106] Iteration 364500, lr = 0.005
I0521 21:17:39.315155  7510 solver.cpp:237] Iteration 366000, loss = 1.23315
I0521 21:17:39.315198  7510 solver.cpp:253]     Train net output #0: loss = 1.23315 (* 1 = 1.23315 loss)
I0521 21:17:39.315213  7510 sgd_solver.cpp:106] Iteration 366000, lr = 0.005
I0521 21:17:56.059051  7510 solver.cpp:237] Iteration 367500, loss = 1.5135
I0521 21:17:56.059222  7510 solver.cpp:253]     Train net output #0: loss = 1.51349 (* 1 = 1.51349 loss)
I0521 21:17:56.059236  7510 sgd_solver.cpp:106] Iteration 367500, lr = 0.005
I0521 21:18:12.833019  7510 solver.cpp:237] Iteration 369000, loss = 1.47374
I0521 21:18:12.833053  7510 solver.cpp:253]     Train net output #0: loss = 1.47374 (* 1 = 1.47374 loss)
I0521 21:18:12.833070  7510 sgd_solver.cpp:106] Iteration 369000, lr = 0.005
I0521 21:18:50.421597  7510 solver.cpp:237] Iteration 370500, loss = 1.68045
I0521 21:18:50.421789  7510 solver.cpp:253]     Train net output #0: loss = 1.68045 (* 1 = 1.68045 loss)
I0521 21:18:50.421803  7510 sgd_solver.cpp:106] Iteration 370500, lr = 0.005
I0521 21:19:07.181187  7510 solver.cpp:237] Iteration 372000, loss = 0.819283
I0521 21:19:07.181224  7510 solver.cpp:253]     Train net output #0: loss = 0.819278 (* 1 = 0.819278 loss)
I0521 21:19:07.181241  7510 sgd_solver.cpp:106] Iteration 372000, lr = 0.005
I0521 21:19:23.925354  7510 solver.cpp:237] Iteration 373500, loss = 1.34707
I0521 21:19:23.925535  7510 solver.cpp:253]     Train net output #0: loss = 1.34707 (* 1 = 1.34707 loss)
I0521 21:19:23.925550  7510 sgd_solver.cpp:106] Iteration 373500, lr = 0.005
I0521 21:19:40.687836  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_375000.caffemodel
I0521 21:19:40.735175  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_375000.solverstate
I0521 21:19:40.765650  7510 solver.cpp:237] Iteration 375000, loss = 0.833589
I0521 21:19:40.765702  7510 solver.cpp:253]     Train net output #0: loss = 0.833585 (* 1 = 0.833585 loss)
I0521 21:19:40.765715  7510 sgd_solver.cpp:106] Iteration 375000, lr = 0.005
I0521 21:19:57.517462  7510 solver.cpp:237] Iteration 376500, loss = 1.75628
I0521 21:19:57.517629  7510 solver.cpp:253]     Train net output #0: loss = 1.75628 (* 1 = 1.75628 loss)
I0521 21:19:57.517643  7510 sgd_solver.cpp:106] Iteration 376500, lr = 0.005
I0521 21:20:14.263272  7510 solver.cpp:237] Iteration 378000, loss = 0.949658
I0521 21:20:14.263324  7510 solver.cpp:253]     Train net output #0: loss = 0.949654 (* 1 = 0.949654 loss)
I0521 21:20:14.263339  7510 sgd_solver.cpp:106] Iteration 378000, lr = 0.005
I0521 21:20:31.010676  7510 solver.cpp:237] Iteration 379500, loss = 1.74612
I0521 21:20:31.010855  7510 solver.cpp:253]     Train net output #0: loss = 1.74612 (* 1 = 1.74612 loss)
I0521 21:20:31.010869  7510 sgd_solver.cpp:106] Iteration 379500, lr = 0.005
I0521 21:21:08.619902  7510 solver.cpp:237] Iteration 381000, loss = 0.874853
I0521 21:21:08.620090  7510 solver.cpp:253]     Train net output #0: loss = 0.874849 (* 1 = 0.874849 loss)
I0521 21:21:08.620105  7510 sgd_solver.cpp:106] Iteration 381000, lr = 0.005
I0521 21:21:25.399484  7510 solver.cpp:237] Iteration 382500, loss = 1.19198
I0521 21:21:25.399530  7510 solver.cpp:253]     Train net output #0: loss = 1.19198 (* 1 = 1.19198 loss)
I0521 21:21:25.399547  7510 sgd_solver.cpp:106] Iteration 382500, lr = 0.005
I0521 21:21:42.167481  7510 solver.cpp:237] Iteration 384000, loss = 0.792136
I0521 21:21:42.167662  7510 solver.cpp:253]     Train net output #0: loss = 0.792131 (* 1 = 0.792131 loss)
I0521 21:21:42.167676  7510 sgd_solver.cpp:106] Iteration 384000, lr = 0.005
I0521 21:21:58.948182  7510 solver.cpp:237] Iteration 385500, loss = 1.12197
I0521 21:21:58.948218  7510 solver.cpp:253]     Train net output #0: loss = 1.12197 (* 1 = 1.12197 loss)
I0521 21:21:58.948232  7510 sgd_solver.cpp:106] Iteration 385500, lr = 0.005
I0521 21:22:15.706198  7510 solver.cpp:237] Iteration 387000, loss = 1.28072
I0521 21:22:15.706378  7510 solver.cpp:253]     Train net output #0: loss = 1.28071 (* 1 = 1.28071 loss)
I0521 21:22:15.706393  7510 sgd_solver.cpp:106] Iteration 387000, lr = 0.005
I0521 21:22:32.457667  7510 solver.cpp:237] Iteration 388500, loss = 0.537532
I0521 21:22:32.457711  7510 solver.cpp:253]     Train net output #0: loss = 0.537528 (* 1 = 0.537528 loss)
I0521 21:22:32.457731  7510 sgd_solver.cpp:106] Iteration 388500, lr = 0.005
I0521 21:22:49.214260  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_390000.caffemodel
I0521 21:22:49.260356  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_390000.solverstate
I0521 21:22:49.285753  7510 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 21:23:48.463356  7510 solver.cpp:409]     Test net output #0: accuracy = 0.876771
I0521 21:23:48.463538  7510 solver.cpp:409]     Test net output #1: loss = 0.431392 (* 1 = 0.431392 loss)
I0521 21:24:09.299238  7510 solver.cpp:237] Iteration 390000, loss = 1.21756
I0521 21:24:09.299293  7510 solver.cpp:253]     Train net output #0: loss = 1.21756 (* 1 = 1.21756 loss)
I0521 21:24:09.299307  7510 sgd_solver.cpp:106] Iteration 390000, lr = 0.005
I0521 21:24:26.253715  7510 solver.cpp:237] Iteration 391500, loss = 0.71547
I0521 21:24:26.253900  7510 solver.cpp:253]     Train net output #0: loss = 0.715466 (* 1 = 0.715466 loss)
I0521 21:24:26.253913  7510 sgd_solver.cpp:106] Iteration 391500, lr = 0.005
I0521 21:24:43.149811  7510 solver.cpp:237] Iteration 393000, loss = 1.17976
I0521 21:24:43.149858  7510 solver.cpp:253]     Train net output #0: loss = 1.17976 (* 1 = 1.17976 loss)
I0521 21:24:43.149873  7510 sgd_solver.cpp:106] Iteration 393000, lr = 0.005
I0521 21:25:00.082984  7510 solver.cpp:237] Iteration 394500, loss = 1.36266
I0521 21:25:00.083158  7510 solver.cpp:253]     Train net output #0: loss = 1.36266 (* 1 = 1.36266 loss)
I0521 21:25:00.083173  7510 sgd_solver.cpp:106] Iteration 394500, lr = 0.005
I0521 21:25:17.008162  7510 solver.cpp:237] Iteration 396000, loss = 0.987727
I0521 21:25:17.008210  7510 solver.cpp:253]     Train net output #0: loss = 0.987722 (* 1 = 0.987722 loss)
I0521 21:25:17.008226  7510 sgd_solver.cpp:106] Iteration 396000, lr = 0.005
I0521 21:25:33.946394  7510 solver.cpp:237] Iteration 397500, loss = 1.02419
I0521 21:25:33.946573  7510 solver.cpp:253]     Train net output #0: loss = 1.02418 (* 1 = 1.02418 loss)
I0521 21:25:33.946589  7510 sgd_solver.cpp:106] Iteration 397500, lr = 0.005
I0521 21:25:50.910929  7510 solver.cpp:237] Iteration 399000, loss = 1.53666
I0521 21:25:50.910974  7510 solver.cpp:253]     Train net output #0: loss = 1.53666 (* 1 = 1.53666 loss)
I0521 21:25:50.910991  7510 sgd_solver.cpp:106] Iteration 399000, lr = 0.005
I0521 21:26:28.736071  7510 solver.cpp:237] Iteration 400500, loss = 1.07486
I0521 21:26:28.736256  7510 solver.cpp:253]     Train net output #0: loss = 1.07485 (* 1 = 1.07485 loss)
I0521 21:26:28.736270  7510 sgd_solver.cpp:106] Iteration 400500, lr = 0.005
I0521 21:26:45.680635  7510 solver.cpp:237] Iteration 402000, loss = 0.930699
I0521 21:26:45.680682  7510 solver.cpp:253]     Train net output #0: loss = 0.930695 (* 1 = 0.930695 loss)
I0521 21:26:45.680698  7510 sgd_solver.cpp:106] Iteration 402000, lr = 0.005
I0521 21:27:02.609844  7510 solver.cpp:237] Iteration 403500, loss = 0.631463
I0521 21:27:02.610008  7510 solver.cpp:253]     Train net output #0: loss = 0.631459 (* 1 = 0.631459 loss)
I0521 21:27:02.610020  7510 sgd_solver.cpp:106] Iteration 403500, lr = 0.005
I0521 21:27:19.559252  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_405000.caffemodel
I0521 21:27:19.605319  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_405000.solverstate
I0521 21:27:19.634152  7510 solver.cpp:237] Iteration 405000, loss = 1.3451
I0521 21:27:19.634197  7510 solver.cpp:253]     Train net output #0: loss = 1.34509 (* 1 = 1.34509 loss)
I0521 21:27:19.634212  7510 sgd_solver.cpp:106] Iteration 405000, lr = 0.005
I0521 21:27:36.579998  7510 solver.cpp:237] Iteration 406500, loss = 0.763176
I0521 21:27:36.580175  7510 solver.cpp:253]     Train net output #0: loss = 0.763173 (* 1 = 0.763173 loss)
I0521 21:27:36.580190  7510 sgd_solver.cpp:106] Iteration 406500, lr = 0.005
I0521 21:27:53.535020  7510 solver.cpp:237] Iteration 408000, loss = 1.06037
I0521 21:27:53.535058  7510 solver.cpp:253]     Train net output #0: loss = 1.06036 (* 1 = 1.06036 loss)
I0521 21:27:53.535073  7510 sgd_solver.cpp:106] Iteration 408000, lr = 0.005
I0521 21:28:10.471467  7510 solver.cpp:237] Iteration 409500, loss = 0.898897
I0521 21:28:10.471652  7510 solver.cpp:253]     Train net output #0: loss = 0.898896 (* 1 = 0.898896 loss)
I0521 21:28:10.471667  7510 sgd_solver.cpp:106] Iteration 409500, lr = 0.005
I0521 21:28:48.285429  7510 solver.cpp:237] Iteration 411000, loss = 1.69498
I0521 21:28:48.285614  7510 solver.cpp:253]     Train net output #0: loss = 1.69498 (* 1 = 1.69498 loss)
I0521 21:28:48.285629  7510 sgd_solver.cpp:106] Iteration 411000, lr = 0.005
I0521 21:29:05.245815  7510 solver.cpp:237] Iteration 412500, loss = 2.02014
I0521 21:29:05.245849  7510 solver.cpp:253]     Train net output #0: loss = 2.02014 (* 1 = 2.02014 loss)
I0521 21:29:05.245867  7510 sgd_solver.cpp:106] Iteration 412500, lr = 0.005
I0521 21:29:22.198273  7510 solver.cpp:237] Iteration 414000, loss = 2.42813
I0521 21:29:22.198437  7510 solver.cpp:253]     Train net output #0: loss = 2.42813 (* 1 = 2.42813 loss)
I0521 21:29:22.198451  7510 sgd_solver.cpp:106] Iteration 414000, lr = 0.005
I0521 21:29:39.181109  7510 solver.cpp:237] Iteration 415500, loss = 1.8718
I0521 21:29:39.181156  7510 solver.cpp:253]     Train net output #0: loss = 1.87179 (* 1 = 1.87179 loss)
I0521 21:29:39.181170  7510 sgd_solver.cpp:106] Iteration 415500, lr = 0.005
I0521 21:29:56.100072  7510 solver.cpp:237] Iteration 417000, loss = 1.33351
I0521 21:29:56.100240  7510 solver.cpp:253]     Train net output #0: loss = 1.33351 (* 1 = 1.33351 loss)
I0521 21:29:56.100255  7510 sgd_solver.cpp:106] Iteration 417000, lr = 0.005
I0521 21:30:13.057288  7510 solver.cpp:237] Iteration 418500, loss = 1.37214
I0521 21:30:13.057332  7510 solver.cpp:253]     Train net output #0: loss = 1.37214 (* 1 = 1.37214 loss)
I0521 21:30:13.057348  7510 sgd_solver.cpp:106] Iteration 418500, lr = 0.005
I0521 21:30:29.979252  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_420000.caffemodel
I0521 21:30:30.025188  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_420000.solverstate
I0521 21:30:30.050446  7510 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 21:31:50.267418  7510 solver.cpp:409]     Test net output #0: accuracy = 0.873977
I0521 21:31:50.267606  7510 solver.cpp:409]     Test net output #1: loss = 0.406375 (* 1 = 0.406375 loss)
I0521 21:32:11.152988  7510 solver.cpp:237] Iteration 420000, loss = 1.53893
I0521 21:32:11.153041  7510 solver.cpp:253]     Train net output #0: loss = 1.53893 (* 1 = 1.53893 loss)
I0521 21:32:11.153059  7510 sgd_solver.cpp:106] Iteration 420000, lr = 0.005
I0521 21:32:27.772311  7510 solver.cpp:237] Iteration 421500, loss = 1.19673
I0521 21:32:27.772482  7510 solver.cpp:253]     Train net output #0: loss = 1.19673 (* 1 = 1.19673 loss)
I0521 21:32:27.772496  7510 sgd_solver.cpp:106] Iteration 421500, lr = 0.005
I0521 21:32:44.374436  7510 solver.cpp:237] Iteration 423000, loss = 0.639706
I0521 21:32:44.374485  7510 solver.cpp:253]     Train net output #0: loss = 0.639706 (* 1 = 0.639706 loss)
I0521 21:32:44.374497  7510 sgd_solver.cpp:106] Iteration 423000, lr = 0.005
I0521 21:33:00.993546  7510 solver.cpp:237] Iteration 424500, loss = 1.31128
I0521 21:33:00.993726  7510 solver.cpp:253]     Train net output #0: loss = 1.31128 (* 1 = 1.31128 loss)
I0521 21:33:00.993741  7510 sgd_solver.cpp:106] Iteration 424500, lr = 0.005
I0521 21:33:17.598500  7510 solver.cpp:237] Iteration 426000, loss = 0.825721
I0521 21:33:17.598536  7510 solver.cpp:253]     Train net output #0: loss = 0.825722 (* 1 = 0.825722 loss)
I0521 21:33:17.598551  7510 sgd_solver.cpp:106] Iteration 426000, lr = 0.005
I0521 21:33:34.173817  7510 solver.cpp:237] Iteration 427500, loss = 1.02762
I0521 21:33:34.174000  7510 solver.cpp:253]     Train net output #0: loss = 1.02762 (* 1 = 1.02762 loss)
I0521 21:33:34.174013  7510 sgd_solver.cpp:106] Iteration 427500, lr = 0.005
I0521 21:33:50.767541  7510 solver.cpp:237] Iteration 429000, loss = 1.08844
I0521 21:33:50.767576  7510 solver.cpp:253]     Train net output #0: loss = 1.08844 (* 1 = 1.08844 loss)
I0521 21:33:50.767597  7510 sgd_solver.cpp:106] Iteration 429000, lr = 0.005
I0521 21:34:28.257248  7510 solver.cpp:237] Iteration 430500, loss = 0.801919
I0521 21:34:28.257438  7510 solver.cpp:253]     Train net output #0: loss = 0.801921 (* 1 = 0.801921 loss)
I0521 21:34:28.257455  7510 sgd_solver.cpp:106] Iteration 430500, lr = 0.005
I0521 21:34:44.837609  7510 solver.cpp:237] Iteration 432000, loss = 1.37663
I0521 21:34:44.837656  7510 solver.cpp:253]     Train net output #0: loss = 1.37663 (* 1 = 1.37663 loss)
I0521 21:34:44.837671  7510 sgd_solver.cpp:106] Iteration 432000, lr = 0.005
I0521 21:35:01.449373  7510 solver.cpp:237] Iteration 433500, loss = 0.776075
I0521 21:35:01.449548  7510 solver.cpp:253]     Train net output #0: loss = 0.776077 (* 1 = 0.776077 loss)
I0521 21:35:01.449563  7510 sgd_solver.cpp:106] Iteration 433500, lr = 0.005
I0521 21:35:18.071691  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_435000.caffemodel
I0521 21:35:18.119798  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_435000.solverstate
I0521 21:35:18.150606  7510 solver.cpp:237] Iteration 435000, loss = 2.2021
I0521 21:35:18.150658  7510 solver.cpp:253]     Train net output #0: loss = 2.2021 (* 1 = 2.2021 loss)
I0521 21:35:18.150673  7510 sgd_solver.cpp:106] Iteration 435000, lr = 0.005
I0521 21:35:34.772856  7510 solver.cpp:237] Iteration 436500, loss = 1.21056
I0521 21:35:34.773049  7510 solver.cpp:253]     Train net output #0: loss = 1.21057 (* 1 = 1.21057 loss)
I0521 21:35:34.773063  7510 sgd_solver.cpp:106] Iteration 436500, lr = 0.005
I0521 21:35:51.379717  7510 solver.cpp:237] Iteration 438000, loss = 2.44371
I0521 21:35:51.379762  7510 solver.cpp:253]     Train net output #0: loss = 2.44372 (* 1 = 2.44372 loss)
I0521 21:35:51.379776  7510 sgd_solver.cpp:106] Iteration 438000, lr = 0.005
I0521 21:36:08.006973  7510 solver.cpp:237] Iteration 439500, loss = 1.60925
I0521 21:36:08.007136  7510 solver.cpp:253]     Train net output #0: loss = 1.60926 (* 1 = 1.60926 loss)
I0521 21:36:08.007150  7510 sgd_solver.cpp:106] Iteration 439500, lr = 0.005
I0521 21:36:45.485654  7510 solver.cpp:237] Iteration 441000, loss = 1.12795
I0521 21:36:45.485838  7510 solver.cpp:253]     Train net output #0: loss = 1.12796 (* 1 = 1.12796 loss)
I0521 21:36:45.485852  7510 sgd_solver.cpp:106] Iteration 441000, lr = 0.005
I0521 21:37:02.077754  7510 solver.cpp:237] Iteration 442500, loss = 1.39683
I0521 21:37:02.077790  7510 solver.cpp:253]     Train net output #0: loss = 1.39683 (* 1 = 1.39683 loss)
I0521 21:37:02.077803  7510 sgd_solver.cpp:106] Iteration 442500, lr = 0.005
I0521 21:37:18.674532  7510 solver.cpp:237] Iteration 444000, loss = 1.69278
I0521 21:37:18.674711  7510 solver.cpp:253]     Train net output #0: loss = 1.69278 (* 1 = 1.69278 loss)
I0521 21:37:18.674726  7510 sgd_solver.cpp:106] Iteration 444000, lr = 0.005
I0521 21:37:35.277276  7510 solver.cpp:237] Iteration 445500, loss = 1.11993
I0521 21:37:35.277324  7510 solver.cpp:253]     Train net output #0: loss = 1.11993 (* 1 = 1.11993 loss)
I0521 21:37:35.277341  7510 sgd_solver.cpp:106] Iteration 445500, lr = 0.005
I0521 21:37:51.882637  7510 solver.cpp:237] Iteration 447000, loss = 1.62825
I0521 21:37:51.882805  7510 solver.cpp:253]     Train net output #0: loss = 1.62826 (* 1 = 1.62826 loss)
I0521 21:37:51.882818  7510 sgd_solver.cpp:106] Iteration 447000, lr = 0.005
I0521 21:38:08.481554  7510 solver.cpp:237] Iteration 448500, loss = 1.55885
I0521 21:38:08.481606  7510 solver.cpp:253]     Train net output #0: loss = 1.55885 (* 1 = 1.55885 loss)
I0521 21:38:08.481619  7510 sgd_solver.cpp:106] Iteration 448500, lr = 0.005
I0521 21:38:25.042678  7510 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_450000.caffemodel
I0521 21:38:25.090524  7510 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0050_2016-05-20T15.48.52.831864_iter_450000.solverstate
I0521 21:38:25.117705  7510 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 21:39:24.233042  7510 solver.cpp:409]     Test net output #0: accuracy = 0.878846
I0521 21:39:24.233228  7510 solver.cpp:409]     Test net output #1: loss = 0.397728 (* 1 = 0.397728 loss)
I0521 21:39:45.085860  7510 solver.cpp:237] Iteration 450000, loss = 0.888676
I0521 21:39:45.085913  7510 solver.cpp:253]     Train net output #0: loss = 0.888676 (* 1 = 0.888676 loss)
I0521 21:39:45.085930  7510 sgd_solver.cpp:106] Iteration 450000, lr = 0.005
I0521 21:40:02.134992  7510 solver.cpp:237] Iteration 451500, loss = 0.814294
I0521 21:40:02.135177  7510 solver.cpp:253]     Train net output #0: loss = 0.814294 (* 1 = 0.814294 loss)
I0521 21:40:02.135191  7510 sgd_solver.cpp:106] Iteration 451500, lr = 0.005
I0521 21:40:19.169248  7510 solver.cpp:237] Iteration 453000, loss = 1.34003
I0521 21:40:19.169284  7510 solver.cpp:253]     Train net output #0: loss = 1.34003 (* 1 = 1.34003 loss)
I0521 21:40:19.169301  7510 sgd_solver.cpp:106] Iteration 453000, lr = 0.005
I0521 21:40:36.191332  7510 solver.cpp:237] Iteration 454500, loss = 1.5101
I0521 21:40:36.191515  7510 solver.cpp:253]     Train net output #0: loss = 1.5101 (* 1 = 1.5101 loss)
I0521 21:40:36.191531  7510 sgd_solver.cpp:106] Iteration 454500, lr = 0.005
I0521 21:40:53.218194  7510 solver.cpp:237] Iteration 456000, loss = 1.00581
I0521 21:40:53.218242  7510 solver.cpp:253]     Train net output #0: loss = 1.00581 (* 1 = 1.00581 loss)
I0521 21:40:53.218261  7510 sgd_solver.cpp:106] Iteration 456000, lr = 0.005
aprun: Apid 11241321: Caught signal Terminated, sending to application
*** Aborted at 1463881264 (unix time) try "date -d @1463881264" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11241321: Caught signal Terminated, sending to application
*** SIGTERM (@0x1d53) received by PID 7510 (TID 0x2aaac746f900) from PID 7507; stack trace: ***
aprun: Apid 11241321: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7230 exceeded limit 7200
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
aprun: Apid 11241321: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11241321: Caught signal Terminated, sending to application
