2810278
I0525 10:54:23.229305 22426 caffe.cpp:184] Using GPUs 0
I0525 10:54:23.652701 22426 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.0045
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180.prototxt"
I0525 10:54:23.654932 22426 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180.prototxt
I0525 10:54:23.674895 22426 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 10:54:23.674954 22426 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 10:54:23.675305 22426 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 10:54:23.675484 22426 layer_factory.hpp:77] Creating layer data_hdf5
I0525 10:54:23.675508 22426 net.cpp:106] Creating Layer data_hdf5
I0525 10:54:23.675523 22426 net.cpp:411] data_hdf5 -> data
I0525 10:54:23.675555 22426 net.cpp:411] data_hdf5 -> label
I0525 10:54:23.675587 22426 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 10:54:23.676991 22426 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 10:54:23.679256 22426 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 10:54:45.263025 22426 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 10:54:45.268244 22426 net.cpp:150] Setting up data_hdf5
I0525 10:54:45.268283 22426 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 10:54:45.268297 22426 net.cpp:157] Top shape: 90 (90)
I0525 10:54:45.268311 22426 net.cpp:165] Memory required for data: 2286360
I0525 10:54:45.268324 22426 layer_factory.hpp:77] Creating layer conv1
I0525 10:54:45.268358 22426 net.cpp:106] Creating Layer conv1
I0525 10:54:45.268369 22426 net.cpp:454] conv1 <- data
I0525 10:54:45.268391 22426 net.cpp:411] conv1 -> conv1
I0525 10:54:45.635874 22426 net.cpp:150] Setting up conv1
I0525 10:54:45.635921 22426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 10:54:45.635931 22426 net.cpp:165] Memory required for data: 27169560
I0525 10:54:45.635959 22426 layer_factory.hpp:77] Creating layer relu1
I0525 10:54:45.635980 22426 net.cpp:106] Creating Layer relu1
I0525 10:54:45.635992 22426 net.cpp:454] relu1 <- conv1
I0525 10:54:45.636004 22426 net.cpp:397] relu1 -> conv1 (in-place)
I0525 10:54:45.636518 22426 net.cpp:150] Setting up relu1
I0525 10:54:45.636534 22426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 10:54:45.636544 22426 net.cpp:165] Memory required for data: 52052760
I0525 10:54:45.636555 22426 layer_factory.hpp:77] Creating layer pool1
I0525 10:54:45.636571 22426 net.cpp:106] Creating Layer pool1
I0525 10:54:45.636581 22426 net.cpp:454] pool1 <- conv1
I0525 10:54:45.636595 22426 net.cpp:411] pool1 -> pool1
I0525 10:54:45.636674 22426 net.cpp:150] Setting up pool1
I0525 10:54:45.636688 22426 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 10:54:45.636696 22426 net.cpp:165] Memory required for data: 64494360
I0525 10:54:45.636704 22426 layer_factory.hpp:77] Creating layer conv2
I0525 10:54:45.636726 22426 net.cpp:106] Creating Layer conv2
I0525 10:54:45.636737 22426 net.cpp:454] conv2 <- pool1
I0525 10:54:45.636750 22426 net.cpp:411] conv2 -> conv2
I0525 10:54:45.639477 22426 net.cpp:150] Setting up conv2
I0525 10:54:45.639505 22426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 10:54:45.639515 22426 net.cpp:165] Memory required for data: 82379160
I0525 10:54:45.639534 22426 layer_factory.hpp:77] Creating layer relu2
I0525 10:54:45.639549 22426 net.cpp:106] Creating Layer relu2
I0525 10:54:45.639559 22426 net.cpp:454] relu2 <- conv2
I0525 10:54:45.639571 22426 net.cpp:397] relu2 -> conv2 (in-place)
I0525 10:54:45.639902 22426 net.cpp:150] Setting up relu2
I0525 10:54:45.639917 22426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 10:54:45.639927 22426 net.cpp:165] Memory required for data: 100263960
I0525 10:54:45.639937 22426 layer_factory.hpp:77] Creating layer pool2
I0525 10:54:45.639950 22426 net.cpp:106] Creating Layer pool2
I0525 10:54:45.639960 22426 net.cpp:454] pool2 <- conv2
I0525 10:54:45.639972 22426 net.cpp:411] pool2 -> pool2
I0525 10:54:45.640053 22426 net.cpp:150] Setting up pool2
I0525 10:54:45.640066 22426 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 10:54:45.640076 22426 net.cpp:165] Memory required for data: 109206360
I0525 10:54:45.640084 22426 layer_factory.hpp:77] Creating layer conv3
I0525 10:54:45.640102 22426 net.cpp:106] Creating Layer conv3
I0525 10:54:45.640112 22426 net.cpp:454] conv3 <- pool2
I0525 10:54:45.640126 22426 net.cpp:411] conv3 -> conv3
I0525 10:54:45.642047 22426 net.cpp:150] Setting up conv3
I0525 10:54:45.642066 22426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 10:54:45.642079 22426 net.cpp:165] Memory required for data: 118963800
I0525 10:54:45.642099 22426 layer_factory.hpp:77] Creating layer relu3
I0525 10:54:45.642115 22426 net.cpp:106] Creating Layer relu3
I0525 10:54:45.642125 22426 net.cpp:454] relu3 <- conv3
I0525 10:54:45.642138 22426 net.cpp:397] relu3 -> conv3 (in-place)
I0525 10:54:45.642603 22426 net.cpp:150] Setting up relu3
I0525 10:54:45.642621 22426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 10:54:45.642632 22426 net.cpp:165] Memory required for data: 128721240
I0525 10:54:45.642642 22426 layer_factory.hpp:77] Creating layer pool3
I0525 10:54:45.642654 22426 net.cpp:106] Creating Layer pool3
I0525 10:54:45.642664 22426 net.cpp:454] pool3 <- conv3
I0525 10:54:45.642678 22426 net.cpp:411] pool3 -> pool3
I0525 10:54:45.642745 22426 net.cpp:150] Setting up pool3
I0525 10:54:45.642757 22426 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 10:54:45.642767 22426 net.cpp:165] Memory required for data: 133599960
I0525 10:54:45.642774 22426 layer_factory.hpp:77] Creating layer conv4
I0525 10:54:45.642792 22426 net.cpp:106] Creating Layer conv4
I0525 10:54:45.642802 22426 net.cpp:454] conv4 <- pool3
I0525 10:54:45.642817 22426 net.cpp:411] conv4 -> conv4
I0525 10:54:45.645764 22426 net.cpp:150] Setting up conv4
I0525 10:54:45.645793 22426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 10:54:45.645804 22426 net.cpp:165] Memory required for data: 136865880
I0525 10:54:45.645819 22426 layer_factory.hpp:77] Creating layer relu4
I0525 10:54:45.645834 22426 net.cpp:106] Creating Layer relu4
I0525 10:54:45.645844 22426 net.cpp:454] relu4 <- conv4
I0525 10:54:45.645858 22426 net.cpp:397] relu4 -> conv4 (in-place)
I0525 10:54:45.646320 22426 net.cpp:150] Setting up relu4
I0525 10:54:45.646337 22426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 10:54:45.646347 22426 net.cpp:165] Memory required for data: 140131800
I0525 10:54:45.646358 22426 layer_factory.hpp:77] Creating layer pool4
I0525 10:54:45.646370 22426 net.cpp:106] Creating Layer pool4
I0525 10:54:45.646380 22426 net.cpp:454] pool4 <- conv4
I0525 10:54:45.646394 22426 net.cpp:411] pool4 -> pool4
I0525 10:54:45.646461 22426 net.cpp:150] Setting up pool4
I0525 10:54:45.646474 22426 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 10:54:45.646484 22426 net.cpp:165] Memory required for data: 141764760
I0525 10:54:45.646494 22426 layer_factory.hpp:77] Creating layer ip1
I0525 10:54:45.646514 22426 net.cpp:106] Creating Layer ip1
I0525 10:54:45.646524 22426 net.cpp:454] ip1 <- pool4
I0525 10:54:45.646535 22426 net.cpp:411] ip1 -> ip1
I0525 10:54:45.662142 22426 net.cpp:150] Setting up ip1
I0525 10:54:45.662170 22426 net.cpp:157] Top shape: 90 196 (17640)
I0525 10:54:45.662185 22426 net.cpp:165] Memory required for data: 141835320
I0525 10:54:45.662207 22426 layer_factory.hpp:77] Creating layer relu5
I0525 10:54:45.662222 22426 net.cpp:106] Creating Layer relu5
I0525 10:54:45.662232 22426 net.cpp:454] relu5 <- ip1
I0525 10:54:45.662246 22426 net.cpp:397] relu5 -> ip1 (in-place)
I0525 10:54:45.662588 22426 net.cpp:150] Setting up relu5
I0525 10:54:45.662602 22426 net.cpp:157] Top shape: 90 196 (17640)
I0525 10:54:45.662612 22426 net.cpp:165] Memory required for data: 141905880
I0525 10:54:45.662623 22426 layer_factory.hpp:77] Creating layer drop1
I0525 10:54:45.662644 22426 net.cpp:106] Creating Layer drop1
I0525 10:54:45.662654 22426 net.cpp:454] drop1 <- ip1
I0525 10:54:45.662667 22426 net.cpp:397] drop1 -> ip1 (in-place)
I0525 10:54:45.662726 22426 net.cpp:150] Setting up drop1
I0525 10:54:45.662739 22426 net.cpp:157] Top shape: 90 196 (17640)
I0525 10:54:45.662750 22426 net.cpp:165] Memory required for data: 141976440
I0525 10:54:45.662760 22426 layer_factory.hpp:77] Creating layer ip2
I0525 10:54:45.662777 22426 net.cpp:106] Creating Layer ip2
I0525 10:54:45.662787 22426 net.cpp:454] ip2 <- ip1
I0525 10:54:45.662801 22426 net.cpp:411] ip2 -> ip2
I0525 10:54:45.663264 22426 net.cpp:150] Setting up ip2
I0525 10:54:45.663277 22426 net.cpp:157] Top shape: 90 98 (8820)
I0525 10:54:45.663287 22426 net.cpp:165] Memory required for data: 142011720
I0525 10:54:45.663303 22426 layer_factory.hpp:77] Creating layer relu6
I0525 10:54:45.663316 22426 net.cpp:106] Creating Layer relu6
I0525 10:54:45.663326 22426 net.cpp:454] relu6 <- ip2
I0525 10:54:45.663337 22426 net.cpp:397] relu6 -> ip2 (in-place)
I0525 10:54:45.663857 22426 net.cpp:150] Setting up relu6
I0525 10:54:45.663873 22426 net.cpp:157] Top shape: 90 98 (8820)
I0525 10:54:45.663883 22426 net.cpp:165] Memory required for data: 142047000
I0525 10:54:45.663893 22426 layer_factory.hpp:77] Creating layer drop2
I0525 10:54:45.663908 22426 net.cpp:106] Creating Layer drop2
I0525 10:54:45.663918 22426 net.cpp:454] drop2 <- ip2
I0525 10:54:45.663929 22426 net.cpp:397] drop2 -> ip2 (in-place)
I0525 10:54:45.663972 22426 net.cpp:150] Setting up drop2
I0525 10:54:45.663985 22426 net.cpp:157] Top shape: 90 98 (8820)
I0525 10:54:45.663995 22426 net.cpp:165] Memory required for data: 142082280
I0525 10:54:45.664005 22426 layer_factory.hpp:77] Creating layer ip3
I0525 10:54:45.664018 22426 net.cpp:106] Creating Layer ip3
I0525 10:54:45.664028 22426 net.cpp:454] ip3 <- ip2
I0525 10:54:45.664041 22426 net.cpp:411] ip3 -> ip3
I0525 10:54:45.664248 22426 net.cpp:150] Setting up ip3
I0525 10:54:45.664261 22426 net.cpp:157] Top shape: 90 11 (990)
I0525 10:54:45.664271 22426 net.cpp:165] Memory required for data: 142086240
I0525 10:54:45.664286 22426 layer_factory.hpp:77] Creating layer drop3
I0525 10:54:45.664299 22426 net.cpp:106] Creating Layer drop3
I0525 10:54:45.664309 22426 net.cpp:454] drop3 <- ip3
I0525 10:54:45.664320 22426 net.cpp:397] drop3 -> ip3 (in-place)
I0525 10:54:45.664357 22426 net.cpp:150] Setting up drop3
I0525 10:54:45.664371 22426 net.cpp:157] Top shape: 90 11 (990)
I0525 10:54:45.664381 22426 net.cpp:165] Memory required for data: 142090200
I0525 10:54:45.664391 22426 layer_factory.hpp:77] Creating layer loss
I0525 10:54:45.664407 22426 net.cpp:106] Creating Layer loss
I0525 10:54:45.664417 22426 net.cpp:454] loss <- ip3
I0525 10:54:45.664428 22426 net.cpp:454] loss <- label
I0525 10:54:45.664440 22426 net.cpp:411] loss -> loss
I0525 10:54:45.664458 22426 layer_factory.hpp:77] Creating layer loss
I0525 10:54:45.665107 22426 net.cpp:150] Setting up loss
I0525 10:54:45.665127 22426 net.cpp:157] Top shape: (1)
I0525 10:54:45.665141 22426 net.cpp:160]     with loss weight 1
I0525 10:54:45.665184 22426 net.cpp:165] Memory required for data: 142090204
I0525 10:54:45.665194 22426 net.cpp:226] loss needs backward computation.
I0525 10:54:45.665205 22426 net.cpp:226] drop3 needs backward computation.
I0525 10:54:45.665215 22426 net.cpp:226] ip3 needs backward computation.
I0525 10:54:45.665226 22426 net.cpp:226] drop2 needs backward computation.
I0525 10:54:45.665236 22426 net.cpp:226] relu6 needs backward computation.
I0525 10:54:45.665246 22426 net.cpp:226] ip2 needs backward computation.
I0525 10:54:45.665256 22426 net.cpp:226] drop1 needs backward computation.
I0525 10:54:45.665266 22426 net.cpp:226] relu5 needs backward computation.
I0525 10:54:45.665276 22426 net.cpp:226] ip1 needs backward computation.
I0525 10:54:45.665285 22426 net.cpp:226] pool4 needs backward computation.
I0525 10:54:45.665297 22426 net.cpp:226] relu4 needs backward computation.
I0525 10:54:45.665305 22426 net.cpp:226] conv4 needs backward computation.
I0525 10:54:45.665316 22426 net.cpp:226] pool3 needs backward computation.
I0525 10:54:45.665326 22426 net.cpp:226] relu3 needs backward computation.
I0525 10:54:45.665345 22426 net.cpp:226] conv3 needs backward computation.
I0525 10:54:45.665356 22426 net.cpp:226] pool2 needs backward computation.
I0525 10:54:45.665367 22426 net.cpp:226] relu2 needs backward computation.
I0525 10:54:45.665377 22426 net.cpp:226] conv2 needs backward computation.
I0525 10:54:45.665388 22426 net.cpp:226] pool1 needs backward computation.
I0525 10:54:45.665398 22426 net.cpp:226] relu1 needs backward computation.
I0525 10:54:45.665407 22426 net.cpp:226] conv1 needs backward computation.
I0525 10:54:45.665418 22426 net.cpp:228] data_hdf5 does not need backward computation.
I0525 10:54:45.665428 22426 net.cpp:270] This network produces output loss
I0525 10:54:45.665452 22426 net.cpp:283] Network initialization done.
I0525 10:54:45.667151 22426 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180.prototxt
I0525 10:54:45.667297 22426 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 10:54:45.667651 22426 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 10:54:45.667842 22426 layer_factory.hpp:77] Creating layer data_hdf5
I0525 10:54:45.667857 22426 net.cpp:106] Creating Layer data_hdf5
I0525 10:54:45.667870 22426 net.cpp:411] data_hdf5 -> data
I0525 10:54:45.667886 22426 net.cpp:411] data_hdf5 -> label
I0525 10:54:45.667903 22426 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 10:54:45.669160 22426 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 10:55:07.015331 22426 net.cpp:150] Setting up data_hdf5
I0525 10:55:07.015496 22426 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 10:55:07.015509 22426 net.cpp:157] Top shape: 90 (90)
I0525 10:55:07.015522 22426 net.cpp:165] Memory required for data: 2286360
I0525 10:55:07.015534 22426 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 10:55:07.015563 22426 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 10:55:07.015573 22426 net.cpp:454] label_data_hdf5_1_split <- label
I0525 10:55:07.015588 22426 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 10:55:07.015609 22426 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 10:55:07.015683 22426 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 10:55:07.015697 22426 net.cpp:157] Top shape: 90 (90)
I0525 10:55:07.015709 22426 net.cpp:157] Top shape: 90 (90)
I0525 10:55:07.015718 22426 net.cpp:165] Memory required for data: 2287080
I0525 10:55:07.015728 22426 layer_factory.hpp:77] Creating layer conv1
I0525 10:55:07.015750 22426 net.cpp:106] Creating Layer conv1
I0525 10:55:07.015760 22426 net.cpp:454] conv1 <- data
I0525 10:55:07.015775 22426 net.cpp:411] conv1 -> conv1
I0525 10:55:07.017736 22426 net.cpp:150] Setting up conv1
I0525 10:55:07.017760 22426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 10:55:07.017772 22426 net.cpp:165] Memory required for data: 27170280
I0525 10:55:07.017792 22426 layer_factory.hpp:77] Creating layer relu1
I0525 10:55:07.017807 22426 net.cpp:106] Creating Layer relu1
I0525 10:55:07.017817 22426 net.cpp:454] relu1 <- conv1
I0525 10:55:07.017830 22426 net.cpp:397] relu1 -> conv1 (in-place)
I0525 10:55:07.018327 22426 net.cpp:150] Setting up relu1
I0525 10:55:07.018344 22426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 10:55:07.018354 22426 net.cpp:165] Memory required for data: 52053480
I0525 10:55:07.018365 22426 layer_factory.hpp:77] Creating layer pool1
I0525 10:55:07.018381 22426 net.cpp:106] Creating Layer pool1
I0525 10:55:07.018390 22426 net.cpp:454] pool1 <- conv1
I0525 10:55:07.018404 22426 net.cpp:411] pool1 -> pool1
I0525 10:55:07.018478 22426 net.cpp:150] Setting up pool1
I0525 10:55:07.018492 22426 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 10:55:07.018501 22426 net.cpp:165] Memory required for data: 64495080
I0525 10:55:07.018512 22426 layer_factory.hpp:77] Creating layer conv2
I0525 10:55:07.018529 22426 net.cpp:106] Creating Layer conv2
I0525 10:55:07.018540 22426 net.cpp:454] conv2 <- pool1
I0525 10:55:07.018554 22426 net.cpp:411] conv2 -> conv2
I0525 10:55:07.020465 22426 net.cpp:150] Setting up conv2
I0525 10:55:07.020488 22426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 10:55:07.020500 22426 net.cpp:165] Memory required for data: 82379880
I0525 10:55:07.020517 22426 layer_factory.hpp:77] Creating layer relu2
I0525 10:55:07.020531 22426 net.cpp:106] Creating Layer relu2
I0525 10:55:07.020541 22426 net.cpp:454] relu2 <- conv2
I0525 10:55:07.020553 22426 net.cpp:397] relu2 -> conv2 (in-place)
I0525 10:55:07.020889 22426 net.cpp:150] Setting up relu2
I0525 10:55:07.020903 22426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 10:55:07.020913 22426 net.cpp:165] Memory required for data: 100264680
I0525 10:55:07.020923 22426 layer_factory.hpp:77] Creating layer pool2
I0525 10:55:07.020936 22426 net.cpp:106] Creating Layer pool2
I0525 10:55:07.020946 22426 net.cpp:454] pool2 <- conv2
I0525 10:55:07.020967 22426 net.cpp:411] pool2 -> pool2
I0525 10:55:07.021039 22426 net.cpp:150] Setting up pool2
I0525 10:55:07.021052 22426 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 10:55:07.021062 22426 net.cpp:165] Memory required for data: 109207080
I0525 10:55:07.021072 22426 layer_factory.hpp:77] Creating layer conv3
I0525 10:55:07.021092 22426 net.cpp:106] Creating Layer conv3
I0525 10:55:07.021102 22426 net.cpp:454] conv3 <- pool2
I0525 10:55:07.021116 22426 net.cpp:411] conv3 -> conv3
I0525 10:55:07.023092 22426 net.cpp:150] Setting up conv3
I0525 10:55:07.023110 22426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 10:55:07.023120 22426 net.cpp:165] Memory required for data: 118964520
I0525 10:55:07.023154 22426 layer_factory.hpp:77] Creating layer relu3
I0525 10:55:07.023166 22426 net.cpp:106] Creating Layer relu3
I0525 10:55:07.023176 22426 net.cpp:454] relu3 <- conv3
I0525 10:55:07.023190 22426 net.cpp:397] relu3 -> conv3 (in-place)
I0525 10:55:07.023658 22426 net.cpp:150] Setting up relu3
I0525 10:55:07.023674 22426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 10:55:07.023684 22426 net.cpp:165] Memory required for data: 128721960
I0525 10:55:07.023694 22426 layer_factory.hpp:77] Creating layer pool3
I0525 10:55:07.023707 22426 net.cpp:106] Creating Layer pool3
I0525 10:55:07.023717 22426 net.cpp:454] pool3 <- conv3
I0525 10:55:07.023730 22426 net.cpp:411] pool3 -> pool3
I0525 10:55:07.023800 22426 net.cpp:150] Setting up pool3
I0525 10:55:07.023813 22426 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 10:55:07.023823 22426 net.cpp:165] Memory required for data: 133600680
I0525 10:55:07.023833 22426 layer_factory.hpp:77] Creating layer conv4
I0525 10:55:07.023851 22426 net.cpp:106] Creating Layer conv4
I0525 10:55:07.023861 22426 net.cpp:454] conv4 <- pool3
I0525 10:55:07.023874 22426 net.cpp:411] conv4 -> conv4
I0525 10:55:07.025959 22426 net.cpp:150] Setting up conv4
I0525 10:55:07.025975 22426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 10:55:07.025985 22426 net.cpp:165] Memory required for data: 136866600
I0525 10:55:07.026002 22426 layer_factory.hpp:77] Creating layer relu4
I0525 10:55:07.026016 22426 net.cpp:106] Creating Layer relu4
I0525 10:55:07.026026 22426 net.cpp:454] relu4 <- conv4
I0525 10:55:07.026039 22426 net.cpp:397] relu4 -> conv4 (in-place)
I0525 10:55:07.026515 22426 net.cpp:150] Setting up relu4
I0525 10:55:07.026530 22426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 10:55:07.026540 22426 net.cpp:165] Memory required for data: 140132520
I0525 10:55:07.026551 22426 layer_factory.hpp:77] Creating layer pool4
I0525 10:55:07.026563 22426 net.cpp:106] Creating Layer pool4
I0525 10:55:07.026573 22426 net.cpp:454] pool4 <- conv4
I0525 10:55:07.026587 22426 net.cpp:411] pool4 -> pool4
I0525 10:55:07.026657 22426 net.cpp:150] Setting up pool4
I0525 10:55:07.026670 22426 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 10:55:07.026680 22426 net.cpp:165] Memory required for data: 141765480
I0525 10:55:07.026690 22426 layer_factory.hpp:77] Creating layer ip1
I0525 10:55:07.026705 22426 net.cpp:106] Creating Layer ip1
I0525 10:55:07.026715 22426 net.cpp:454] ip1 <- pool4
I0525 10:55:07.026729 22426 net.cpp:411] ip1 -> ip1
I0525 10:55:07.042248 22426 net.cpp:150] Setting up ip1
I0525 10:55:07.042276 22426 net.cpp:157] Top shape: 90 196 (17640)
I0525 10:55:07.042289 22426 net.cpp:165] Memory required for data: 141836040
I0525 10:55:07.042311 22426 layer_factory.hpp:77] Creating layer relu5
I0525 10:55:07.042326 22426 net.cpp:106] Creating Layer relu5
I0525 10:55:07.042336 22426 net.cpp:454] relu5 <- ip1
I0525 10:55:07.042351 22426 net.cpp:397] relu5 -> ip1 (in-place)
I0525 10:55:07.042701 22426 net.cpp:150] Setting up relu5
I0525 10:55:07.042714 22426 net.cpp:157] Top shape: 90 196 (17640)
I0525 10:55:07.042723 22426 net.cpp:165] Memory required for data: 141906600
I0525 10:55:07.042733 22426 layer_factory.hpp:77] Creating layer drop1
I0525 10:55:07.042752 22426 net.cpp:106] Creating Layer drop1
I0525 10:55:07.042762 22426 net.cpp:454] drop1 <- ip1
I0525 10:55:07.042775 22426 net.cpp:397] drop1 -> ip1 (in-place)
I0525 10:55:07.042824 22426 net.cpp:150] Setting up drop1
I0525 10:55:07.042836 22426 net.cpp:157] Top shape: 90 196 (17640)
I0525 10:55:07.042847 22426 net.cpp:165] Memory required for data: 141977160
I0525 10:55:07.042856 22426 layer_factory.hpp:77] Creating layer ip2
I0525 10:55:07.042871 22426 net.cpp:106] Creating Layer ip2
I0525 10:55:07.042881 22426 net.cpp:454] ip2 <- ip1
I0525 10:55:07.042896 22426 net.cpp:411] ip2 -> ip2
I0525 10:55:07.043373 22426 net.cpp:150] Setting up ip2
I0525 10:55:07.043386 22426 net.cpp:157] Top shape: 90 98 (8820)
I0525 10:55:07.043396 22426 net.cpp:165] Memory required for data: 142012440
I0525 10:55:07.043412 22426 layer_factory.hpp:77] Creating layer relu6
I0525 10:55:07.043438 22426 net.cpp:106] Creating Layer relu6
I0525 10:55:07.043448 22426 net.cpp:454] relu6 <- ip2
I0525 10:55:07.043462 22426 net.cpp:397] relu6 -> ip2 (in-place)
I0525 10:55:07.043998 22426 net.cpp:150] Setting up relu6
I0525 10:55:07.044014 22426 net.cpp:157] Top shape: 90 98 (8820)
I0525 10:55:07.044024 22426 net.cpp:165] Memory required for data: 142047720
I0525 10:55:07.044035 22426 layer_factory.hpp:77] Creating layer drop2
I0525 10:55:07.044049 22426 net.cpp:106] Creating Layer drop2
I0525 10:55:07.044059 22426 net.cpp:454] drop2 <- ip2
I0525 10:55:07.044072 22426 net.cpp:397] drop2 -> ip2 (in-place)
I0525 10:55:07.044116 22426 net.cpp:150] Setting up drop2
I0525 10:55:07.044129 22426 net.cpp:157] Top shape: 90 98 (8820)
I0525 10:55:07.044138 22426 net.cpp:165] Memory required for data: 142083000
I0525 10:55:07.044148 22426 layer_factory.hpp:77] Creating layer ip3
I0525 10:55:07.044163 22426 net.cpp:106] Creating Layer ip3
I0525 10:55:07.044173 22426 net.cpp:454] ip3 <- ip2
I0525 10:55:07.044186 22426 net.cpp:411] ip3 -> ip3
I0525 10:55:07.044409 22426 net.cpp:150] Setting up ip3
I0525 10:55:07.044422 22426 net.cpp:157] Top shape: 90 11 (990)
I0525 10:55:07.044431 22426 net.cpp:165] Memory required for data: 142086960
I0525 10:55:07.044447 22426 layer_factory.hpp:77] Creating layer drop3
I0525 10:55:07.044461 22426 net.cpp:106] Creating Layer drop3
I0525 10:55:07.044471 22426 net.cpp:454] drop3 <- ip3
I0525 10:55:07.044483 22426 net.cpp:397] drop3 -> ip3 (in-place)
I0525 10:55:07.044525 22426 net.cpp:150] Setting up drop3
I0525 10:55:07.044538 22426 net.cpp:157] Top shape: 90 11 (990)
I0525 10:55:07.044548 22426 net.cpp:165] Memory required for data: 142090920
I0525 10:55:07.044558 22426 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 10:55:07.044570 22426 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 10:55:07.044580 22426 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 10:55:07.044594 22426 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 10:55:07.044608 22426 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 10:55:07.044682 22426 net.cpp:150] Setting up ip3_drop3_0_split
I0525 10:55:07.044695 22426 net.cpp:157] Top shape: 90 11 (990)
I0525 10:55:07.044708 22426 net.cpp:157] Top shape: 90 11 (990)
I0525 10:55:07.044718 22426 net.cpp:165] Memory required for data: 142098840
I0525 10:55:07.044725 22426 layer_factory.hpp:77] Creating layer accuracy
I0525 10:55:07.044747 22426 net.cpp:106] Creating Layer accuracy
I0525 10:55:07.044756 22426 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 10:55:07.044769 22426 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 10:55:07.044781 22426 net.cpp:411] accuracy -> accuracy
I0525 10:55:07.044806 22426 net.cpp:150] Setting up accuracy
I0525 10:55:07.044817 22426 net.cpp:157] Top shape: (1)
I0525 10:55:07.044827 22426 net.cpp:165] Memory required for data: 142098844
I0525 10:55:07.044837 22426 layer_factory.hpp:77] Creating layer loss
I0525 10:55:07.044850 22426 net.cpp:106] Creating Layer loss
I0525 10:55:07.044860 22426 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 10:55:07.044872 22426 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 10:55:07.044885 22426 net.cpp:411] loss -> loss
I0525 10:55:07.044903 22426 layer_factory.hpp:77] Creating layer loss
I0525 10:55:07.045402 22426 net.cpp:150] Setting up loss
I0525 10:55:07.045415 22426 net.cpp:157] Top shape: (1)
I0525 10:55:07.045424 22426 net.cpp:160]     with loss weight 1
I0525 10:55:07.045444 22426 net.cpp:165] Memory required for data: 142098848
I0525 10:55:07.045454 22426 net.cpp:226] loss needs backward computation.
I0525 10:55:07.045464 22426 net.cpp:228] accuracy does not need backward computation.
I0525 10:55:07.045476 22426 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 10:55:07.045486 22426 net.cpp:226] drop3 needs backward computation.
I0525 10:55:07.045496 22426 net.cpp:226] ip3 needs backward computation.
I0525 10:55:07.045507 22426 net.cpp:226] drop2 needs backward computation.
I0525 10:55:07.045517 22426 net.cpp:226] relu6 needs backward computation.
I0525 10:55:07.045534 22426 net.cpp:226] ip2 needs backward computation.
I0525 10:55:07.045545 22426 net.cpp:226] drop1 needs backward computation.
I0525 10:55:07.045554 22426 net.cpp:226] relu5 needs backward computation.
I0525 10:55:07.045564 22426 net.cpp:226] ip1 needs backward computation.
I0525 10:55:07.045573 22426 net.cpp:226] pool4 needs backward computation.
I0525 10:55:07.045584 22426 net.cpp:226] relu4 needs backward computation.
I0525 10:55:07.045594 22426 net.cpp:226] conv4 needs backward computation.
I0525 10:55:07.045604 22426 net.cpp:226] pool3 needs backward computation.
I0525 10:55:07.045615 22426 net.cpp:226] relu3 needs backward computation.
I0525 10:55:07.045625 22426 net.cpp:226] conv3 needs backward computation.
I0525 10:55:07.045635 22426 net.cpp:226] pool2 needs backward computation.
I0525 10:55:07.045645 22426 net.cpp:226] relu2 needs backward computation.
I0525 10:55:07.045655 22426 net.cpp:226] conv2 needs backward computation.
I0525 10:55:07.045665 22426 net.cpp:226] pool1 needs backward computation.
I0525 10:55:07.045675 22426 net.cpp:226] relu1 needs backward computation.
I0525 10:55:07.045686 22426 net.cpp:226] conv1 needs backward computation.
I0525 10:55:07.045696 22426 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 10:55:07.045708 22426 net.cpp:228] data_hdf5 does not need backward computation.
I0525 10:55:07.045718 22426 net.cpp:270] This network produces output accuracy
I0525 10:55:07.045728 22426 net.cpp:270] This network produces output loss
I0525 10:55:07.045756 22426 net.cpp:283] Network initialization done.
I0525 10:55:07.045889 22426 solver.cpp:60] Solver scaffolding done.
I0525 10:55:07.047024 22426 caffe.cpp:212] Starting Optimization
I0525 10:55:07.047039 22426 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 10:55:07.047050 22426 solver.cpp:289] Learning Rate Policy: fixed
I0525 10:55:07.048116 22426 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 10:55:55.104205 22426 solver.cpp:409]     Test net output #0: accuracy = 0.0702012
I0525 10:55:55.104364 22426 solver.cpp:409]     Test net output #1: loss = 2.39827 (* 1 = 2.39827 loss)
I0525 10:55:55.135462 22426 solver.cpp:237] Iteration 0, loss = 2.40003
I0525 10:55:55.135499 22426 solver.cpp:253]     Train net output #0: loss = 2.40003 (* 1 = 2.40003 loss)
I0525 10:55:55.135516 22426 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0525 10:56:03.969981 22426 solver.cpp:237] Iteration 166, loss = 2.26327
I0525 10:56:03.970017 22426 solver.cpp:253]     Train net output #0: loss = 2.26327 (* 1 = 2.26327 loss)
I0525 10:56:03.970032 22426 sgd_solver.cpp:106] Iteration 166, lr = 0.0045
I0525 10:56:12.819723 22426 solver.cpp:237] Iteration 332, loss = 2.11511
I0525 10:56:12.819771 22426 solver.cpp:253]     Train net output #0: loss = 2.11511 (* 1 = 2.11511 loss)
I0525 10:56:12.819787 22426 sgd_solver.cpp:106] Iteration 332, lr = 0.0045
I0525 10:56:21.673271 22426 solver.cpp:237] Iteration 498, loss = 2.11654
I0525 10:56:21.673305 22426 solver.cpp:253]     Train net output #0: loss = 2.11654 (* 1 = 2.11654 loss)
I0525 10:56:21.673323 22426 sgd_solver.cpp:106] Iteration 498, lr = 0.0045
I0525 10:56:30.520685 22426 solver.cpp:237] Iteration 664, loss = 1.81163
I0525 10:56:30.520833 22426 solver.cpp:253]     Train net output #0: loss = 1.81163 (* 1 = 1.81163 loss)
I0525 10:56:30.520846 22426 sgd_solver.cpp:106] Iteration 664, lr = 0.0045
I0525 10:56:39.363625 22426 solver.cpp:237] Iteration 830, loss = 1.79044
I0525 10:56:39.363667 22426 solver.cpp:253]     Train net output #0: loss = 1.79044 (* 1 = 1.79044 loss)
I0525 10:56:39.363685 22426 sgd_solver.cpp:106] Iteration 830, lr = 0.0045
I0525 10:56:48.200086 22426 solver.cpp:237] Iteration 996, loss = 1.70422
I0525 10:56:48.200122 22426 solver.cpp:253]     Train net output #0: loss = 1.70422 (* 1 = 1.70422 loss)
I0525 10:56:48.200139 22426 sgd_solver.cpp:106] Iteration 996, lr = 0.0045
I0525 10:57:19.184334 22426 solver.cpp:237] Iteration 1162, loss = 1.47333
I0525 10:57:19.184492 22426 solver.cpp:253]     Train net output #0: loss = 1.47333 (* 1 = 1.47333 loss)
I0525 10:57:19.184506 22426 sgd_solver.cpp:106] Iteration 1162, lr = 0.0045
I0525 10:57:28.034967 22426 solver.cpp:237] Iteration 1328, loss = 1.69454
I0525 10:57:28.035012 22426 solver.cpp:253]     Train net output #0: loss = 1.69454 (* 1 = 1.69454 loss)
I0525 10:57:28.035028 22426 sgd_solver.cpp:106] Iteration 1328, lr = 0.0045
I0525 10:57:36.891386 22426 solver.cpp:237] Iteration 1494, loss = 1.57242
I0525 10:57:36.891422 22426 solver.cpp:253]     Train net output #0: loss = 1.57242 (* 1 = 1.57242 loss)
I0525 10:57:36.891438 22426 sgd_solver.cpp:106] Iteration 1494, lr = 0.0045
I0525 10:57:45.737465 22426 solver.cpp:237] Iteration 1660, loss = 1.73773
I0525 10:57:45.737500 22426 solver.cpp:253]     Train net output #0: loss = 1.73773 (* 1 = 1.73773 loss)
I0525 10:57:45.737517 22426 sgd_solver.cpp:106] Iteration 1660, lr = 0.0045
I0525 10:57:46.003631 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_1666.caffemodel
I0525 10:57:46.082895 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_1666.solverstate
I0525 10:57:54.661137 22426 solver.cpp:237] Iteration 1826, loss = 1.55274
I0525 10:57:54.661293 22426 solver.cpp:253]     Train net output #0: loss = 1.55274 (* 1 = 1.55274 loss)
I0525 10:57:54.661308 22426 sgd_solver.cpp:106] Iteration 1826, lr = 0.0045
I0525 10:58:03.506373 22426 solver.cpp:237] Iteration 1992, loss = 1.66506
I0525 10:58:03.506407 22426 solver.cpp:253]     Train net output #0: loss = 1.66506 (* 1 = 1.66506 loss)
I0525 10:58:03.506424 22426 sgd_solver.cpp:106] Iteration 1992, lr = 0.0045
I0525 10:58:12.356024 22426 solver.cpp:237] Iteration 2158, loss = 1.80934
I0525 10:58:12.356060 22426 solver.cpp:253]     Train net output #0: loss = 1.80934 (* 1 = 1.80934 loss)
I0525 10:58:12.356077 22426 sgd_solver.cpp:106] Iteration 2158, lr = 0.0045
I0525 10:58:43.369531 22426 solver.cpp:237] Iteration 2324, loss = 1.57339
I0525 10:58:43.369695 22426 solver.cpp:253]     Train net output #0: loss = 1.57339 (* 1 = 1.57339 loss)
I0525 10:58:43.369711 22426 sgd_solver.cpp:106] Iteration 2324, lr = 0.0045
I0525 10:58:52.215613 22426 solver.cpp:237] Iteration 2490, loss = 1.69715
I0525 10:58:52.215649 22426 solver.cpp:253]     Train net output #0: loss = 1.69715 (* 1 = 1.69715 loss)
I0525 10:58:52.215665 22426 sgd_solver.cpp:106] Iteration 2490, lr = 0.0045
I0525 10:59:01.068330 22426 solver.cpp:237] Iteration 2656, loss = 1.48576
I0525 10:59:01.068366 22426 solver.cpp:253]     Train net output #0: loss = 1.48576 (* 1 = 1.48576 loss)
I0525 10:59:01.068380 22426 sgd_solver.cpp:106] Iteration 2656, lr = 0.0045
I0525 10:59:09.909777 22426 solver.cpp:237] Iteration 2822, loss = 1.20638
I0525 10:59:09.909826 22426 solver.cpp:253]     Train net output #0: loss = 1.20638 (* 1 = 1.20638 loss)
I0525 10:59:09.909842 22426 sgd_solver.cpp:106] Iteration 2822, lr = 0.0045
I0525 10:59:18.754160 22426 solver.cpp:237] Iteration 2988, loss = 1.6275
I0525 10:59:18.754307 22426 solver.cpp:253]     Train net output #0: loss = 1.6275 (* 1 = 1.6275 loss)
I0525 10:59:18.754323 22426 sgd_solver.cpp:106] Iteration 2988, lr = 0.0045
I0525 10:59:27.594136 22426 solver.cpp:237] Iteration 3154, loss = 1.30982
I0525 10:59:27.594172 22426 solver.cpp:253]     Train net output #0: loss = 1.30982 (* 1 = 1.30982 loss)
I0525 10:59:27.594189 22426 sgd_solver.cpp:106] Iteration 3154, lr = 0.0045
I0525 10:59:36.442590 22426 solver.cpp:237] Iteration 3320, loss = 1.59092
I0525 10:59:36.442631 22426 solver.cpp:253]     Train net output #0: loss = 1.59092 (* 1 = 1.59092 loss)
I0525 10:59:36.442649 22426 sgd_solver.cpp:106] Iteration 3320, lr = 0.0045
I0525 10:59:37.027839 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_3332.caffemodel
I0525 10:59:37.103868 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_3332.solverstate
I0525 10:59:37.147430 22426 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 11:00:24.317602 22426 solver.cpp:409]     Test net output #0: accuracy = 0.772563
I0525 11:00:24.317761 22426 solver.cpp:409]     Test net output #1: loss = 0.779868 (* 1 = 0.779868 loss)
I0525 11:00:54.628916 22426 solver.cpp:237] Iteration 3486, loss = 1.33338
I0525 11:00:54.629081 22426 solver.cpp:253]     Train net output #0: loss = 1.33338 (* 1 = 1.33338 loss)
I0525 11:00:54.629096 22426 sgd_solver.cpp:106] Iteration 3486, lr = 0.0045
I0525 11:01:03.468443 22426 solver.cpp:237] Iteration 3652, loss = 1.4135
I0525 11:01:03.468478 22426 solver.cpp:253]     Train net output #0: loss = 1.4135 (* 1 = 1.4135 loss)
I0525 11:01:03.468495 22426 sgd_solver.cpp:106] Iteration 3652, lr = 0.0045
I0525 11:01:12.314015 22426 solver.cpp:237] Iteration 3818, loss = 1.39675
I0525 11:01:12.314060 22426 solver.cpp:253]     Train net output #0: loss = 1.39675 (* 1 = 1.39675 loss)
I0525 11:01:12.314075 22426 sgd_solver.cpp:106] Iteration 3818, lr = 0.0045
I0525 11:01:21.146040 22426 solver.cpp:237] Iteration 3984, loss = 1.5117
I0525 11:01:21.146076 22426 solver.cpp:253]     Train net output #0: loss = 1.5117 (* 1 = 1.5117 loss)
I0525 11:01:21.146090 22426 sgd_solver.cpp:106] Iteration 3984, lr = 0.0045
I0525 11:01:29.997375 22426 solver.cpp:237] Iteration 4150, loss = 1.35824
I0525 11:01:29.997509 22426 solver.cpp:253]     Train net output #0: loss = 1.35824 (* 1 = 1.35824 loss)
I0525 11:01:29.997524 22426 sgd_solver.cpp:106] Iteration 4150, lr = 0.0045
I0525 11:01:38.839145 22426 solver.cpp:237] Iteration 4316, loss = 1.51282
I0525 11:01:38.839184 22426 solver.cpp:253]     Train net output #0: loss = 1.51282 (* 1 = 1.51282 loss)
I0525 11:01:38.839205 22426 sgd_solver.cpp:106] Iteration 4316, lr = 0.0045
I0525 11:02:09.840481 22426 solver.cpp:237] Iteration 4482, loss = 1.57745
I0525 11:02:09.840641 22426 solver.cpp:253]     Train net output #0: loss = 1.57745 (* 1 = 1.57745 loss)
I0525 11:02:09.840657 22426 sgd_solver.cpp:106] Iteration 4482, lr = 0.0045
I0525 11:02:18.683820 22426 solver.cpp:237] Iteration 4648, loss = 1.51435
I0525 11:02:18.683854 22426 solver.cpp:253]     Train net output #0: loss = 1.51435 (* 1 = 1.51435 loss)
I0525 11:02:18.683871 22426 sgd_solver.cpp:106] Iteration 4648, lr = 0.0045
I0525 11:02:27.521478 22426 solver.cpp:237] Iteration 4814, loss = 1.28257
I0525 11:02:27.521518 22426 solver.cpp:253]     Train net output #0: loss = 1.28257 (* 1 = 1.28257 loss)
I0525 11:02:27.521539 22426 sgd_solver.cpp:106] Iteration 4814, lr = 0.0045
I0525 11:02:36.355705 22426 solver.cpp:237] Iteration 4980, loss = 1.45127
I0525 11:02:36.355739 22426 solver.cpp:253]     Train net output #0: loss = 1.45127 (* 1 = 1.45127 loss)
I0525 11:02:36.355756 22426 sgd_solver.cpp:106] Iteration 4980, lr = 0.0045
I0525 11:02:37.261173 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_4998.caffemodel
I0525 11:02:37.337460 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_4998.solverstate
I0525 11:02:45.262084 22426 solver.cpp:237] Iteration 5146, loss = 1.53187
I0525 11:02:45.262251 22426 solver.cpp:253]     Train net output #0: loss = 1.53187 (* 1 = 1.53187 loss)
I0525 11:02:45.262266 22426 sgd_solver.cpp:106] Iteration 5146, lr = 0.0045
I0525 11:02:54.105432 22426 solver.cpp:237] Iteration 5312, loss = 1.26677
I0525 11:02:54.105473 22426 solver.cpp:253]     Train net output #0: loss = 1.26677 (* 1 = 1.26677 loss)
I0525 11:02:54.105489 22426 sgd_solver.cpp:106] Iteration 5312, lr = 0.0045
I0525 11:03:02.943699 22426 solver.cpp:237] Iteration 5478, loss = 1.26765
I0525 11:03:02.943737 22426 solver.cpp:253]     Train net output #0: loss = 1.26765 (* 1 = 1.26765 loss)
I0525 11:03:02.943750 22426 sgd_solver.cpp:106] Iteration 5478, lr = 0.0045
I0525 11:03:33.922389 22426 solver.cpp:237] Iteration 5644, loss = 1.4801
I0525 11:03:33.922551 22426 solver.cpp:253]     Train net output #0: loss = 1.4801 (* 1 = 1.4801 loss)
I0525 11:03:33.922567 22426 sgd_solver.cpp:106] Iteration 5644, lr = 0.0045
I0525 11:03:42.758363 22426 solver.cpp:237] Iteration 5810, loss = 1.31923
I0525 11:03:42.758411 22426 solver.cpp:253]     Train net output #0: loss = 1.31923 (* 1 = 1.31923 loss)
I0525 11:03:42.758425 22426 sgd_solver.cpp:106] Iteration 5810, lr = 0.0045
I0525 11:03:51.592329 22426 solver.cpp:237] Iteration 5976, loss = 1.38772
I0525 11:03:51.592365 22426 solver.cpp:253]     Train net output #0: loss = 1.38772 (* 1 = 1.38772 loss)
I0525 11:03:51.592378 22426 sgd_solver.cpp:106] Iteration 5976, lr = 0.0045
I0525 11:04:00.435830 22426 solver.cpp:237] Iteration 6142, loss = 1.57427
I0525 11:04:00.435866 22426 solver.cpp:253]     Train net output #0: loss = 1.57427 (* 1 = 1.57427 loss)
I0525 11:04:00.435879 22426 sgd_solver.cpp:106] Iteration 6142, lr = 0.0045
I0525 11:04:09.273517 22426 solver.cpp:237] Iteration 6308, loss = 1.48168
I0525 11:04:09.273666 22426 solver.cpp:253]     Train net output #0: loss = 1.48168 (* 1 = 1.48168 loss)
I0525 11:04:09.273680 22426 sgd_solver.cpp:106] Iteration 6308, lr = 0.0045
I0525 11:04:18.116442 22426 solver.cpp:237] Iteration 6474, loss = 1.3283
I0525 11:04:18.116477 22426 solver.cpp:253]     Train net output #0: loss = 1.3283 (* 1 = 1.3283 loss)
I0525 11:04:18.116492 22426 sgd_solver.cpp:106] Iteration 6474, lr = 0.0045
I0525 11:04:26.955694 22426 solver.cpp:237] Iteration 6640, loss = 1.32342
I0525 11:04:26.955729 22426 solver.cpp:253]     Train net output #0: loss = 1.32342 (* 1 = 1.32342 loss)
I0525 11:04:26.955745 22426 sgd_solver.cpp:106] Iteration 6640, lr = 0.0045
I0525 11:04:28.178417 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_6664.caffemodel
I0525 11:04:28.255204 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_6664.solverstate
I0525 11:04:28.351465 22426 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 11:05:36.275653 22426 solver.cpp:409]     Test net output #0: accuracy = 0.828204
I0525 11:05:36.275822 22426 solver.cpp:409]     Test net output #1: loss = 0.563768 (* 1 = 0.563768 loss)
I0525 11:06:05.908860 22426 solver.cpp:237] Iteration 6806, loss = 1.27196
I0525 11:06:05.908910 22426 solver.cpp:253]     Train net output #0: loss = 1.27196 (* 1 = 1.27196 loss)
I0525 11:06:05.908926 22426 sgd_solver.cpp:106] Iteration 6806, lr = 0.0045
I0525 11:06:14.744777 22426 solver.cpp:237] Iteration 6972, loss = 1.27938
I0525 11:06:14.744937 22426 solver.cpp:253]     Train net output #0: loss = 1.27938 (* 1 = 1.27938 loss)
I0525 11:06:14.744951 22426 sgd_solver.cpp:106] Iteration 6972, lr = 0.0045
I0525 11:06:23.580772 22426 solver.cpp:237] Iteration 7138, loss = 1.2033
I0525 11:06:23.580807 22426 solver.cpp:253]     Train net output #0: loss = 1.2033 (* 1 = 1.2033 loss)
I0525 11:06:23.580821 22426 sgd_solver.cpp:106] Iteration 7138, lr = 0.0045
I0525 11:06:32.422204 22426 solver.cpp:237] Iteration 7304, loss = 1.32161
I0525 11:06:32.422240 22426 solver.cpp:253]     Train net output #0: loss = 1.32161 (* 1 = 1.32161 loss)
I0525 11:06:32.422255 22426 sgd_solver.cpp:106] Iteration 7304, lr = 0.0045
I0525 11:06:41.264636 22426 solver.cpp:237] Iteration 7470, loss = 1.44192
I0525 11:06:41.264679 22426 solver.cpp:253]     Train net output #0: loss = 1.44192 (* 1 = 1.44192 loss)
I0525 11:06:41.264694 22426 sgd_solver.cpp:106] Iteration 7470, lr = 0.0045
I0525 11:06:50.098347 22426 solver.cpp:237] Iteration 7636, loss = 1.31541
I0525 11:06:50.098496 22426 solver.cpp:253]     Train net output #0: loss = 1.31541 (* 1 = 1.31541 loss)
I0525 11:06:50.098511 22426 sgd_solver.cpp:106] Iteration 7636, lr = 0.0045
I0525 11:07:21.079682 22426 solver.cpp:237] Iteration 7802, loss = 1.40086
I0525 11:07:21.079844 22426 solver.cpp:253]     Train net output #0: loss = 1.40086 (* 1 = 1.40086 loss)
I0525 11:07:21.079860 22426 sgd_solver.cpp:106] Iteration 7802, lr = 0.0045
I0525 11:07:29.917762 22426 solver.cpp:237] Iteration 7968, loss = 1.37479
I0525 11:07:29.917807 22426 solver.cpp:253]     Train net output #0: loss = 1.37479 (* 1 = 1.37479 loss)
I0525 11:07:29.917822 22426 sgd_solver.cpp:106] Iteration 7968, lr = 0.0045
I0525 11:07:38.747113 22426 solver.cpp:237] Iteration 8134, loss = 1.38473
I0525 11:07:38.747149 22426 solver.cpp:253]     Train net output #0: loss = 1.38473 (* 1 = 1.38473 loss)
I0525 11:07:38.747166 22426 sgd_solver.cpp:106] Iteration 8134, lr = 0.0045
I0525 11:07:47.585906 22426 solver.cpp:237] Iteration 8300, loss = 1.30056
I0525 11:07:47.585942 22426 solver.cpp:253]     Train net output #0: loss = 1.30056 (* 1 = 1.30056 loss)
I0525 11:07:47.585955 22426 sgd_solver.cpp:106] Iteration 8300, lr = 0.0045
I0525 11:07:49.130074 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_8330.caffemodel
I0525 11:07:49.207439 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_8330.solverstate
I0525 11:07:56.495051 22426 solver.cpp:237] Iteration 8466, loss = 1.41666
I0525 11:07:56.495213 22426 solver.cpp:253]     Train net output #0: loss = 1.41666 (* 1 = 1.41666 loss)
I0525 11:07:56.495228 22426 sgd_solver.cpp:106] Iteration 8466, lr = 0.0045
I0525 11:08:05.326834 22426 solver.cpp:237] Iteration 8632, loss = 1.31963
I0525 11:08:05.326870 22426 solver.cpp:253]     Train net output #0: loss = 1.31963 (* 1 = 1.31963 loss)
I0525 11:08:05.326887 22426 sgd_solver.cpp:106] Iteration 8632, lr = 0.0045
I0525 11:08:14.179726 22426 solver.cpp:237] Iteration 8798, loss = 1.28627
I0525 11:08:14.179764 22426 solver.cpp:253]     Train net output #0: loss = 1.28627 (* 1 = 1.28627 loss)
I0525 11:08:14.179780 22426 sgd_solver.cpp:106] Iteration 8798, lr = 0.0045
I0525 11:08:45.172933 22426 solver.cpp:237] Iteration 8964, loss = 1.33421
I0525 11:08:45.173112 22426 solver.cpp:253]     Train net output #0: loss = 1.33421 (* 1 = 1.33421 loss)
I0525 11:08:45.173128 22426 sgd_solver.cpp:106] Iteration 8964, lr = 0.0045
I0525 11:08:54.022979 22426 solver.cpp:237] Iteration 9130, loss = 1.60232
I0525 11:08:54.023015 22426 solver.cpp:253]     Train net output #0: loss = 1.60232 (* 1 = 1.60232 loss)
I0525 11:08:54.023027 22426 sgd_solver.cpp:106] Iteration 9130, lr = 0.0045
I0525 11:09:02.867136 22426 solver.cpp:237] Iteration 9296, loss = 1.2018
I0525 11:09:02.867171 22426 solver.cpp:253]     Train net output #0: loss = 1.2018 (* 1 = 1.2018 loss)
I0525 11:09:02.867187 22426 sgd_solver.cpp:106] Iteration 9296, lr = 0.0045
I0525 11:09:11.702366 22426 solver.cpp:237] Iteration 9462, loss = 1.36373
I0525 11:09:11.702401 22426 solver.cpp:253]     Train net output #0: loss = 1.36373 (* 1 = 1.36373 loss)
I0525 11:09:11.702424 22426 sgd_solver.cpp:106] Iteration 9462, lr = 0.0045
I0525 11:09:20.533566 22426 solver.cpp:237] Iteration 9628, loss = 1.16642
I0525 11:09:20.533706 22426 solver.cpp:253]     Train net output #0: loss = 1.16642 (* 1 = 1.16642 loss)
I0525 11:09:20.533720 22426 sgd_solver.cpp:106] Iteration 9628, lr = 0.0045
I0525 11:09:29.378876 22426 solver.cpp:237] Iteration 9794, loss = 1.20259
I0525 11:09:29.378911 22426 solver.cpp:253]     Train net output #0: loss = 1.20259 (* 1 = 1.20259 loss)
I0525 11:09:29.378928 22426 sgd_solver.cpp:106] Iteration 9794, lr = 0.0045
I0525 11:09:38.224814 22426 solver.cpp:237] Iteration 9960, loss = 1.27303
I0525 11:09:38.224845 22426 solver.cpp:253]     Train net output #0: loss = 1.27303 (* 1 = 1.27303 loss)
I0525 11:09:38.224869 22426 sgd_solver.cpp:106] Iteration 9960, lr = 0.0045
I0525 11:09:40.087168 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_9996.caffemodel
I0525 11:09:40.161242 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_9996.solverstate
I0525 11:09:40.308753 22426 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 11:10:27.061715 22426 solver.cpp:409]     Test net output #0: accuracy = 0.844512
I0525 11:10:27.061875 22426 solver.cpp:409]     Test net output #1: loss = 0.510666 (* 1 = 0.510666 loss)
I0525 11:10:55.991657 22426 solver.cpp:237] Iteration 10126, loss = 1.10612
I0525 11:10:55.991705 22426 solver.cpp:253]     Train net output #0: loss = 1.10612 (* 1 = 1.10612 loss)
I0525 11:10:55.991719 22426 sgd_solver.cpp:106] Iteration 10126, lr = 0.0045
I0525 11:11:04.837505 22426 solver.cpp:237] Iteration 10292, loss = 1.17762
I0525 11:11:04.837666 22426 solver.cpp:253]     Train net output #0: loss = 1.17762 (* 1 = 1.17762 loss)
I0525 11:11:04.837679 22426 sgd_solver.cpp:106] Iteration 10292, lr = 0.0045
I0525 11:11:13.686378 22426 solver.cpp:237] Iteration 10458, loss = 1.29856
I0525 11:11:13.686424 22426 solver.cpp:253]     Train net output #0: loss = 1.29856 (* 1 = 1.29856 loss)
I0525 11:11:13.686440 22426 sgd_solver.cpp:106] Iteration 10458, lr = 0.0045
I0525 11:11:22.533321 22426 solver.cpp:237] Iteration 10624, loss = 1.05627
I0525 11:11:22.533356 22426 solver.cpp:253]     Train net output #0: loss = 1.05627 (* 1 = 1.05627 loss)
I0525 11:11:22.533373 22426 sgd_solver.cpp:106] Iteration 10624, lr = 0.0045
I0525 11:11:31.375157 22426 solver.cpp:237] Iteration 10790, loss = 1.21752
I0525 11:11:31.375193 22426 solver.cpp:253]     Train net output #0: loss = 1.21752 (* 1 = 1.21752 loss)
I0525 11:11:31.375206 22426 sgd_solver.cpp:106] Iteration 10790, lr = 0.0045
I0525 11:11:40.219988 22426 solver.cpp:237] Iteration 10956, loss = 1.20737
I0525 11:11:40.220149 22426 solver.cpp:253]     Train net output #0: loss = 1.20737 (* 1 = 1.20737 loss)
I0525 11:11:40.220163 22426 sgd_solver.cpp:106] Iteration 10956, lr = 0.0045
I0525 11:12:11.238025 22426 solver.cpp:237] Iteration 11122, loss = 1.13241
I0525 11:12:11.238199 22426 solver.cpp:253]     Train net output #0: loss = 1.13241 (* 1 = 1.13241 loss)
I0525 11:12:11.238214 22426 sgd_solver.cpp:106] Iteration 11122, lr = 0.0045
I0525 11:12:20.085584 22426 solver.cpp:237] Iteration 11288, loss = 1.07168
I0525 11:12:20.085619 22426 solver.cpp:253]     Train net output #0: loss = 1.07168 (* 1 = 1.07168 loss)
I0525 11:12:20.085636 22426 sgd_solver.cpp:106] Iteration 11288, lr = 0.0045
I0525 11:12:28.932917 22426 solver.cpp:237] Iteration 11454, loss = 1.19755
I0525 11:12:28.932953 22426 solver.cpp:253]     Train net output #0: loss = 1.19755 (* 1 = 1.19755 loss)
I0525 11:12:28.932976 22426 sgd_solver.cpp:106] Iteration 11454, lr = 0.0045
I0525 11:12:37.776175 22426 solver.cpp:237] Iteration 11620, loss = 1.38477
I0525 11:12:37.776211 22426 solver.cpp:253]     Train net output #0: loss = 1.38477 (* 1 = 1.38477 loss)
I0525 11:12:37.776226 22426 sgd_solver.cpp:106] Iteration 11620, lr = 0.0045
I0525 11:12:39.961278 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_11662.caffemodel
I0525 11:12:40.036154 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_11662.solverstate
I0525 11:12:46.691252 22426 solver.cpp:237] Iteration 11786, loss = 1.10045
I0525 11:12:46.691407 22426 solver.cpp:253]     Train net output #0: loss = 1.10045 (* 1 = 1.10045 loss)
I0525 11:12:46.691421 22426 sgd_solver.cpp:106] Iteration 11786, lr = 0.0045
I0525 11:12:55.547505 22426 solver.cpp:237] Iteration 11952, loss = 1.26135
I0525 11:12:55.547552 22426 solver.cpp:253]     Train net output #0: loss = 1.26135 (* 1 = 1.26135 loss)
I0525 11:12:55.547569 22426 sgd_solver.cpp:106] Iteration 11952, lr = 0.0045
I0525 11:13:04.390959 22426 solver.cpp:237] Iteration 12118, loss = 1.4074
I0525 11:13:04.390995 22426 solver.cpp:253]     Train net output #0: loss = 1.4074 (* 1 = 1.4074 loss)
I0525 11:13:04.391010 22426 sgd_solver.cpp:106] Iteration 12118, lr = 0.0045
I0525 11:13:35.430402 22426 solver.cpp:237] Iteration 12284, loss = 1.23465
I0525 11:13:35.430563 22426 solver.cpp:253]     Train net output #0: loss = 1.23465 (* 1 = 1.23465 loss)
I0525 11:13:35.430579 22426 sgd_solver.cpp:106] Iteration 12284, lr = 0.0045
I0525 11:13:44.275373 22426 solver.cpp:237] Iteration 12450, loss = 1.42711
I0525 11:13:44.275416 22426 solver.cpp:253]     Train net output #0: loss = 1.42711 (* 1 = 1.42711 loss)
I0525 11:13:44.275435 22426 sgd_solver.cpp:106] Iteration 12450, lr = 0.0045
I0525 11:13:53.128058 22426 solver.cpp:237] Iteration 12616, loss = 1.24328
I0525 11:13:53.128094 22426 solver.cpp:253]     Train net output #0: loss = 1.24328 (* 1 = 1.24328 loss)
I0525 11:13:53.128108 22426 sgd_solver.cpp:106] Iteration 12616, lr = 0.0045
I0525 11:14:01.971103 22426 solver.cpp:237] Iteration 12782, loss = 1.27842
I0525 11:14:01.971138 22426 solver.cpp:253]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I0525 11:14:01.971154 22426 sgd_solver.cpp:106] Iteration 12782, lr = 0.0045
I0525 11:14:10.824143 22426 solver.cpp:237] Iteration 12948, loss = 1.35853
I0525 11:14:10.824295 22426 solver.cpp:253]     Train net output #0: loss = 1.35853 (* 1 = 1.35853 loss)
I0525 11:14:10.824309 22426 sgd_solver.cpp:106] Iteration 12948, lr = 0.0045
I0525 11:14:19.672633 22426 solver.cpp:237] Iteration 13114, loss = 1.38529
I0525 11:14:19.672668 22426 solver.cpp:253]     Train net output #0: loss = 1.38529 (* 1 = 1.38529 loss)
I0525 11:14:19.672686 22426 sgd_solver.cpp:106] Iteration 13114, lr = 0.0045
I0525 11:14:28.513679 22426 solver.cpp:237] Iteration 13280, loss = 1.24514
I0525 11:14:28.513715 22426 solver.cpp:253]     Train net output #0: loss = 1.24514 (* 1 = 1.24514 loss)
I0525 11:14:28.513731 22426 sgd_solver.cpp:106] Iteration 13280, lr = 0.0045
I0525 11:14:31.022312 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_13328.caffemodel
I0525 11:14:31.096565 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_13328.solverstate
I0525 11:14:31.299026 22426 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 11:15:39.269652 22426 solver.cpp:409]     Test net output #0: accuracy = 0.850761
I0525 11:15:39.269819 22426 solver.cpp:409]     Test net output #1: loss = 0.516071 (* 1 = 0.516071 loss)
I0525 11:16:07.525971 22426 solver.cpp:237] Iteration 13446, loss = 1.2211
I0525 11:16:07.526020 22426 solver.cpp:253]     Train net output #0: loss = 1.2211 (* 1 = 1.2211 loss)
I0525 11:16:07.526036 22426 sgd_solver.cpp:106] Iteration 13446, lr = 0.0045
I0525 11:16:16.388106 22426 solver.cpp:237] Iteration 13612, loss = 1.18319
I0525 11:16:16.388262 22426 solver.cpp:253]     Train net output #0: loss = 1.18319 (* 1 = 1.18319 loss)
I0525 11:16:16.388276 22426 sgd_solver.cpp:106] Iteration 13612, lr = 0.0045
I0525 11:16:25.230759 22426 solver.cpp:237] Iteration 13778, loss = 1.22199
I0525 11:16:25.230795 22426 solver.cpp:253]     Train net output #0: loss = 1.22199 (* 1 = 1.22199 loss)
I0525 11:16:25.230810 22426 sgd_solver.cpp:106] Iteration 13778, lr = 0.0045
I0525 11:16:34.074884 22426 solver.cpp:237] Iteration 13944, loss = 1.36068
I0525 11:16:34.074919 22426 solver.cpp:253]     Train net output #0: loss = 1.36068 (* 1 = 1.36068 loss)
I0525 11:16:34.074935 22426 sgd_solver.cpp:106] Iteration 13944, lr = 0.0045
I0525 11:16:42.921435 22426 solver.cpp:237] Iteration 14110, loss = 1.36333
I0525 11:16:42.921480 22426 solver.cpp:253]     Train net output #0: loss = 1.36333 (* 1 = 1.36333 loss)
I0525 11:16:42.921495 22426 sgd_solver.cpp:106] Iteration 14110, lr = 0.0045
I0525 11:16:51.769192 22426 solver.cpp:237] Iteration 14276, loss = 1.14075
I0525 11:16:51.769342 22426 solver.cpp:253]     Train net output #0: loss = 1.14075 (* 1 = 1.14075 loss)
I0525 11:16:51.769357 22426 sgd_solver.cpp:106] Iteration 14276, lr = 0.0045
I0525 11:17:00.624743 22426 solver.cpp:237] Iteration 14442, loss = 1.18188
I0525 11:17:00.624790 22426 solver.cpp:253]     Train net output #0: loss = 1.18188 (* 1 = 1.18188 loss)
I0525 11:17:00.624804 22426 sgd_solver.cpp:106] Iteration 14442, lr = 0.0045
I0525 11:17:31.666446 22426 solver.cpp:237] Iteration 14608, loss = 1.36256
I0525 11:17:31.666627 22426 solver.cpp:253]     Train net output #0: loss = 1.36256 (* 1 = 1.36256 loss)
I0525 11:17:31.666642 22426 sgd_solver.cpp:106] Iteration 14608, lr = 0.0045
I0525 11:17:40.520169 22426 solver.cpp:237] Iteration 14774, loss = 1.48971
I0525 11:17:40.520205 22426 solver.cpp:253]     Train net output #0: loss = 1.48971 (* 1 = 1.48971 loss)
I0525 11:17:40.520221 22426 sgd_solver.cpp:106] Iteration 14774, lr = 0.0045
I0525 11:17:49.356572 22426 solver.cpp:237] Iteration 14940, loss = 1.0983
I0525 11:17:49.356608 22426 solver.cpp:253]     Train net output #0: loss = 1.0983 (* 1 = 1.0983 loss)
I0525 11:17:49.356621 22426 sgd_solver.cpp:106] Iteration 14940, lr = 0.0045
I0525 11:17:52.187327 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_14994.caffemodel
I0525 11:17:52.264248 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_14994.solverstate
I0525 11:17:58.278576 22426 solver.cpp:237] Iteration 15106, loss = 1.16314
I0525 11:17:58.278627 22426 solver.cpp:253]     Train net output #0: loss = 1.16314 (* 1 = 1.16314 loss)
I0525 11:17:58.278641 22426 sgd_solver.cpp:106] Iteration 15106, lr = 0.0045
I0525 11:18:07.124399 22426 solver.cpp:237] Iteration 15272, loss = 1.40316
I0525 11:18:07.124547 22426 solver.cpp:253]     Train net output #0: loss = 1.40316 (* 1 = 1.40316 loss)
I0525 11:18:07.124560 22426 sgd_solver.cpp:106] Iteration 15272, lr = 0.0045
I0525 11:18:15.980170 22426 solver.cpp:237] Iteration 15438, loss = 1.12375
I0525 11:18:15.980222 22426 solver.cpp:253]     Train net output #0: loss = 1.12375 (* 1 = 1.12375 loss)
I0525 11:18:15.980237 22426 sgd_solver.cpp:106] Iteration 15438, lr = 0.0045
I0525 11:18:46.986448 22426 solver.cpp:237] Iteration 15604, loss = 1.48355
I0525 11:18:46.986621 22426 solver.cpp:253]     Train net output #0: loss = 1.48355 (* 1 = 1.48355 loss)
I0525 11:18:46.986637 22426 sgd_solver.cpp:106] Iteration 15604, lr = 0.0045
I0525 11:18:55.840025 22426 solver.cpp:237] Iteration 15770, loss = 1.29505
I0525 11:18:55.840060 22426 solver.cpp:253]     Train net output #0: loss = 1.29505 (* 1 = 1.29505 loss)
I0525 11:18:55.840076 22426 sgd_solver.cpp:106] Iteration 15770, lr = 0.0045
I0525 11:19:04.695772 22426 solver.cpp:237] Iteration 15936, loss = 1.19446
I0525 11:19:04.695816 22426 solver.cpp:253]     Train net output #0: loss = 1.19446 (* 1 = 1.19446 loss)
I0525 11:19:04.695830 22426 sgd_solver.cpp:106] Iteration 15936, lr = 0.0045
I0525 11:19:13.545532 22426 solver.cpp:237] Iteration 16102, loss = 1.01974
I0525 11:19:13.545568 22426 solver.cpp:253]     Train net output #0: loss = 1.01974 (* 1 = 1.01974 loss)
I0525 11:19:13.545584 22426 sgd_solver.cpp:106] Iteration 16102, lr = 0.0045
I0525 11:19:22.395992 22426 solver.cpp:237] Iteration 16268, loss = 1.3146
I0525 11:19:22.396134 22426 solver.cpp:253]     Train net output #0: loss = 1.3146 (* 1 = 1.3146 loss)
I0525 11:19:22.396147 22426 sgd_solver.cpp:106] Iteration 16268, lr = 0.0045
I0525 11:19:31.241112 22426 solver.cpp:237] Iteration 16434, loss = 1.13047
I0525 11:19:31.241153 22426 solver.cpp:253]     Train net output #0: loss = 1.13047 (* 1 = 1.13047 loss)
I0525 11:19:31.241169 22426 sgd_solver.cpp:106] Iteration 16434, lr = 0.0045
I0525 11:19:40.089228 22426 solver.cpp:237] Iteration 16600, loss = 1.29181
I0525 11:19:40.089263 22426 solver.cpp:253]     Train net output #0: loss = 1.29181 (* 1 = 1.29181 loss)
I0525 11:19:40.089280 22426 sgd_solver.cpp:106] Iteration 16600, lr = 0.0045
I0525 11:19:43.235071 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_16660.caffemodel
I0525 11:19:43.311337 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_16660.solverstate
I0525 11:19:43.570885 22426 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 11:20:30.708241 22426 solver.cpp:409]     Test net output #0: accuracy = 0.870564
I0525 11:20:30.708403 22426 solver.cpp:409]     Test net output #1: loss = 0.443562 (* 1 = 0.443562 loss)
I0525 11:20:56.973704 22426 solver.cpp:237] Iteration 16766, loss = 1.23778
I0525 11:20:56.973753 22426 solver.cpp:253]     Train net output #0: loss = 1.23778 (* 1 = 1.23778 loss)
I0525 11:20:56.973770 22426 sgd_solver.cpp:106] Iteration 16766, lr = 0.0045
I0525 11:21:05.819316 22426 solver.cpp:237] Iteration 16932, loss = 1.00778
I0525 11:21:05.819464 22426 solver.cpp:253]     Train net output #0: loss = 1.00778 (* 1 = 1.00778 loss)
I0525 11:21:05.819478 22426 sgd_solver.cpp:106] Iteration 16932, lr = 0.0045
I0525 11:21:14.668831 22426 solver.cpp:237] Iteration 17098, loss = 1.08489
I0525 11:21:14.668877 22426 solver.cpp:253]     Train net output #0: loss = 1.08489 (* 1 = 1.08489 loss)
I0525 11:21:14.668895 22426 sgd_solver.cpp:106] Iteration 17098, lr = 0.0045
I0525 11:21:23.518841 22426 solver.cpp:237] Iteration 17264, loss = 1.40142
I0525 11:21:23.518877 22426 solver.cpp:253]     Train net output #0: loss = 1.40142 (* 1 = 1.40142 loss)
I0525 11:21:23.518893 22426 sgd_solver.cpp:106] Iteration 17264, lr = 0.0045
I0525 11:21:32.374104 22426 solver.cpp:237] Iteration 17430, loss = 1.26813
I0525 11:21:32.374138 22426 solver.cpp:253]     Train net output #0: loss = 1.26813 (* 1 = 1.26813 loss)
I0525 11:21:32.374155 22426 sgd_solver.cpp:106] Iteration 17430, lr = 0.0045
I0525 11:21:41.231806 22426 solver.cpp:237] Iteration 17596, loss = 1.18211
I0525 11:21:41.231966 22426 solver.cpp:253]     Train net output #0: loss = 1.18211 (* 1 = 1.18211 loss)
I0525 11:21:41.231979 22426 sgd_solver.cpp:106] Iteration 17596, lr = 0.0045
I0525 11:21:50.071988 22426 solver.cpp:237] Iteration 17762, loss = 1.19183
I0525 11:21:50.072022 22426 solver.cpp:253]     Train net output #0: loss = 1.19183 (* 1 = 1.19183 loss)
I0525 11:21:50.072038 22426 sgd_solver.cpp:106] Iteration 17762, lr = 0.0045
I0525 11:22:19.768105 22426 solver.cpp:237] Iteration 17928, loss = 1.17756
I0525 11:22:19.768271 22426 solver.cpp:253]     Train net output #0: loss = 1.17756 (* 1 = 1.17756 loss)
I0525 11:22:19.768285 22426 sgd_solver.cpp:106] Iteration 17928, lr = 0.0045
I0525 11:22:28.616664 22426 solver.cpp:237] Iteration 18094, loss = 1.21218
I0525 11:22:28.616708 22426 solver.cpp:253]     Train net output #0: loss = 1.21218 (* 1 = 1.21218 loss)
I0525 11:22:28.616722 22426 sgd_solver.cpp:106] Iteration 18094, lr = 0.0045
I0525 11:22:37.459175 22426 solver.cpp:237] Iteration 18260, loss = 1.28852
I0525 11:22:37.459209 22426 solver.cpp:253]     Train net output #0: loss = 1.28852 (* 1 = 1.28852 loss)
I0525 11:22:37.459228 22426 sgd_solver.cpp:106] Iteration 18260, lr = 0.0045
I0525 11:22:40.926458 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_18326.caffemodel
I0525 11:22:41.000757 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_18326.solverstate
I0525 11:22:46.366643 22426 solver.cpp:237] Iteration 18426, loss = 1.30606
I0525 11:22:46.366688 22426 solver.cpp:253]     Train net output #0: loss = 1.30606 (* 1 = 1.30606 loss)
I0525 11:22:46.366704 22426 sgd_solver.cpp:106] Iteration 18426, lr = 0.0045
I0525 11:22:55.214857 22426 solver.cpp:237] Iteration 18592, loss = 1.33652
I0525 11:22:55.215016 22426 solver.cpp:253]     Train net output #0: loss = 1.33652 (* 1 = 1.33652 loss)
I0525 11:22:55.215030 22426 sgd_solver.cpp:106] Iteration 18592, lr = 0.0045
I0525 11:23:04.067400 22426 solver.cpp:237] Iteration 18758, loss = 1.16889
I0525 11:23:04.067435 22426 solver.cpp:253]     Train net output #0: loss = 1.16889 (* 1 = 1.16889 loss)
I0525 11:23:04.067452 22426 sgd_solver.cpp:106] Iteration 18758, lr = 0.0045
I0525 11:23:33.745789 22426 solver.cpp:237] Iteration 18924, loss = 1.28655
I0525 11:23:33.745952 22426 solver.cpp:253]     Train net output #0: loss = 1.28655 (* 1 = 1.28655 loss)
I0525 11:23:33.745968 22426 sgd_solver.cpp:106] Iteration 18924, lr = 0.0045
I0525 11:23:42.590005 22426 solver.cpp:237] Iteration 19090, loss = 1.42682
I0525 11:23:42.590047 22426 solver.cpp:253]     Train net output #0: loss = 1.42682 (* 1 = 1.42682 loss)
I0525 11:23:42.590065 22426 sgd_solver.cpp:106] Iteration 19090, lr = 0.0045
I0525 11:23:51.438700 22426 solver.cpp:237] Iteration 19256, loss = 1.05951
I0525 11:23:51.438735 22426 solver.cpp:253]     Train net output #0: loss = 1.05951 (* 1 = 1.05951 loss)
I0525 11:23:51.438752 22426 sgd_solver.cpp:106] Iteration 19256, lr = 0.0045
I0525 11:24:00.282538 22426 solver.cpp:237] Iteration 19422, loss = 1.13456
I0525 11:24:00.282573 22426 solver.cpp:253]     Train net output #0: loss = 1.13456 (* 1 = 1.13456 loss)
I0525 11:24:00.282587 22426 sgd_solver.cpp:106] Iteration 19422, lr = 0.0045
I0525 11:24:09.142624 22426 solver.cpp:237] Iteration 19588, loss = 1.22167
I0525 11:24:09.142778 22426 solver.cpp:253]     Train net output #0: loss = 1.22167 (* 1 = 1.22167 loss)
I0525 11:24:09.142791 22426 sgd_solver.cpp:106] Iteration 19588, lr = 0.0045
I0525 11:24:17.988231 22426 solver.cpp:237] Iteration 19754, loss = 0.96608
I0525 11:24:17.988266 22426 solver.cpp:253]     Train net output #0: loss = 0.96608 (* 1 = 0.96608 loss)
I0525 11:24:17.988279 22426 sgd_solver.cpp:106] Iteration 19754, lr = 0.0045
I0525 11:24:26.839465 22426 solver.cpp:237] Iteration 19920, loss = 1.0597
I0525 11:24:26.839500 22426 solver.cpp:253]     Train net output #0: loss = 1.0597 (* 1 = 1.0597 loss)
I0525 11:24:26.839516 22426 sgd_solver.cpp:106] Iteration 19920, lr = 0.0045
I0525 11:24:30.621299 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_19992.caffemodel
I0525 11:24:30.695626 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_19992.solverstate
I0525 11:24:31.005120 22426 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 11:25:38.968456 22426 solver.cpp:409]     Test net output #0: accuracy = 0.875007
I0525 11:25:38.968639 22426 solver.cpp:409]     Test net output #1: loss = 0.401491 (* 1 = 0.401491 loss)
I0525 11:26:04.493393 22426 solver.cpp:237] Iteration 20086, loss = 1.35331
I0525 11:26:04.493443 22426 solver.cpp:253]     Train net output #0: loss = 1.35331 (* 1 = 1.35331 loss)
I0525 11:26:04.493458 22426 sgd_solver.cpp:106] Iteration 20086, lr = 0.0045
I0525 11:26:13.340880 22426 solver.cpp:237] Iteration 20252, loss = 1.20792
I0525 11:26:13.341056 22426 solver.cpp:253]     Train net output #0: loss = 1.20792 (* 1 = 1.20792 loss)
I0525 11:26:13.341070 22426 sgd_solver.cpp:106] Iteration 20252, lr = 0.0045
I0525 11:26:22.194828 22426 solver.cpp:237] Iteration 20418, loss = 1.06137
I0525 11:26:22.194864 22426 solver.cpp:253]     Train net output #0: loss = 1.06137 (* 1 = 1.06137 loss)
I0525 11:26:22.194880 22426 sgd_solver.cpp:106] Iteration 20418, lr = 0.0045
I0525 11:26:31.043968 22426 solver.cpp:237] Iteration 20584, loss = 1.4206
I0525 11:26:31.044004 22426 solver.cpp:253]     Train net output #0: loss = 1.4206 (* 1 = 1.4206 loss)
I0525 11:26:31.044020 22426 sgd_solver.cpp:106] Iteration 20584, lr = 0.0045
I0525 11:26:39.896422 22426 solver.cpp:237] Iteration 20750, loss = 1.28289
I0525 11:26:39.896468 22426 solver.cpp:253]     Train net output #0: loss = 1.28289 (* 1 = 1.28289 loss)
I0525 11:26:39.896486 22426 sgd_solver.cpp:106] Iteration 20750, lr = 0.0045
I0525 11:26:48.754282 22426 solver.cpp:237] Iteration 20916, loss = 1.18412
I0525 11:26:48.754428 22426 solver.cpp:253]     Train net output #0: loss = 1.18412 (* 1 = 1.18412 loss)
I0525 11:26:48.754443 22426 sgd_solver.cpp:106] Iteration 20916, lr = 0.0045
I0525 11:26:57.599261 22426 solver.cpp:237] Iteration 21082, loss = 1.28532
I0525 11:26:57.599295 22426 solver.cpp:253]     Train net output #0: loss = 1.28532 (* 1 = 1.28532 loss)
I0525 11:26:57.599311 22426 sgd_solver.cpp:106] Iteration 21082, lr = 0.0045
I0525 11:27:27.312080 22426 solver.cpp:237] Iteration 21248, loss = 1.29055
I0525 11:27:27.312249 22426 solver.cpp:253]     Train net output #0: loss = 1.29055 (* 1 = 1.29055 loss)
I0525 11:27:27.312264 22426 sgd_solver.cpp:106] Iteration 21248, lr = 0.0045
I0525 11:27:36.161180 22426 solver.cpp:237] Iteration 21414, loss = 1.12709
I0525 11:27:36.161214 22426 solver.cpp:253]     Train net output #0: loss = 1.12709 (* 1 = 1.12709 loss)
I0525 11:27:36.161228 22426 sgd_solver.cpp:106] Iteration 21414, lr = 0.0045
I0525 11:27:45.009090 22426 solver.cpp:237] Iteration 21580, loss = 1.27075
I0525 11:27:45.009126 22426 solver.cpp:253]     Train net output #0: loss = 1.27075 (* 1 = 1.27075 loss)
I0525 11:27:45.009142 22426 sgd_solver.cpp:106] Iteration 21580, lr = 0.0045
I0525 11:27:49.115875 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_21658.caffemodel
I0525 11:27:49.190052 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_21658.solverstate
I0525 11:27:53.932935 22426 solver.cpp:237] Iteration 21746, loss = 1.1931
I0525 11:27:53.932987 22426 solver.cpp:253]     Train net output #0: loss = 1.1931 (* 1 = 1.1931 loss)
I0525 11:27:53.933007 22426 sgd_solver.cpp:106] Iteration 21746, lr = 0.0045
I0525 11:28:02.785413 22426 solver.cpp:237] Iteration 21912, loss = 1.22738
I0525 11:28:02.785574 22426 solver.cpp:253]     Train net output #0: loss = 1.22738 (* 1 = 1.22738 loss)
I0525 11:28:02.785589 22426 sgd_solver.cpp:106] Iteration 21912, lr = 0.0045
I0525 11:28:11.627463 22426 solver.cpp:237] Iteration 22078, loss = 1.34947
I0525 11:28:11.627498 22426 solver.cpp:253]     Train net output #0: loss = 1.34947 (* 1 = 1.34947 loss)
I0525 11:28:11.627516 22426 sgd_solver.cpp:106] Iteration 22078, lr = 0.0045
I0525 11:28:41.340550 22426 solver.cpp:237] Iteration 22244, loss = 1.11765
I0525 11:28:41.340725 22426 solver.cpp:253]     Train net output #0: loss = 1.11765 (* 1 = 1.11765 loss)
I0525 11:28:41.340739 22426 sgd_solver.cpp:106] Iteration 22244, lr = 0.0045
I0525 11:28:50.184991 22426 solver.cpp:237] Iteration 22410, loss = 1.38189
I0525 11:28:50.185026 22426 solver.cpp:253]     Train net output #0: loss = 1.38189 (* 1 = 1.38189 loss)
I0525 11:28:50.185045 22426 sgd_solver.cpp:106] Iteration 22410, lr = 0.0045
I0525 11:28:59.035305 22426 solver.cpp:237] Iteration 22576, loss = 1.13817
I0525 11:28:59.035341 22426 solver.cpp:253]     Train net output #0: loss = 1.13817 (* 1 = 1.13817 loss)
I0525 11:28:59.035356 22426 sgd_solver.cpp:106] Iteration 22576, lr = 0.0045
I0525 11:29:07.884665 22426 solver.cpp:237] Iteration 22742, loss = 1.18916
I0525 11:29:07.884711 22426 solver.cpp:253]     Train net output #0: loss = 1.18916 (* 1 = 1.18916 loss)
I0525 11:29:07.884727 22426 sgd_solver.cpp:106] Iteration 22742, lr = 0.0045
I0525 11:29:16.737810 22426 solver.cpp:237] Iteration 22908, loss = 0.980245
I0525 11:29:16.737959 22426 solver.cpp:253]     Train net output #0: loss = 0.980245 (* 1 = 0.980245 loss)
I0525 11:29:16.737974 22426 sgd_solver.cpp:106] Iteration 22908, lr = 0.0045
I0525 11:29:25.594557 22426 solver.cpp:237] Iteration 23074, loss = 1.12115
I0525 11:29:25.594591 22426 solver.cpp:253]     Train net output #0: loss = 1.12115 (* 1 = 1.12115 loss)
I0525 11:29:25.594605 22426 sgd_solver.cpp:106] Iteration 23074, lr = 0.0045
I0525 11:29:34.450285 22426 solver.cpp:237] Iteration 23240, loss = 1.02823
I0525 11:29:34.450332 22426 solver.cpp:253]     Train net output #0: loss = 1.02823 (* 1 = 1.02823 loss)
I0525 11:29:34.450350 22426 sgd_solver.cpp:106] Iteration 23240, lr = 0.0045
I0525 11:29:38.871117 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_23324.caffemodel
I0525 11:29:38.955998 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_23324.solverstate
I0525 11:29:39.321228 22426 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 11:30:26.102474 22426 solver.cpp:409]     Test net output #0: accuracy = 0.871478
I0525 11:30:26.102641 22426 solver.cpp:409]     Test net output #1: loss = 0.434234 (* 1 = 0.434234 loss)
I0525 11:30:50.979635 22426 solver.cpp:237] Iteration 23406, loss = 1.13647
I0525 11:30:50.979684 22426 solver.cpp:253]     Train net output #0: loss = 1.13647 (* 1 = 1.13647 loss)
I0525 11:30:50.979701 22426 sgd_solver.cpp:106] Iteration 23406, lr = 0.0045
I0525 11:30:59.830708 22426 solver.cpp:237] Iteration 23572, loss = 1.053
I0525 11:30:59.830858 22426 solver.cpp:253]     Train net output #0: loss = 1.053 (* 1 = 1.053 loss)
I0525 11:30:59.830873 22426 sgd_solver.cpp:106] Iteration 23572, lr = 0.0045
I0525 11:31:08.676476 22426 solver.cpp:237] Iteration 23738, loss = 1.13149
I0525 11:31:08.676511 22426 solver.cpp:253]     Train net output #0: loss = 1.13149 (* 1 = 1.13149 loss)
I0525 11:31:08.676528 22426 sgd_solver.cpp:106] Iteration 23738, lr = 0.0045
I0525 11:31:17.525496 22426 solver.cpp:237] Iteration 23904, loss = 1.08257
I0525 11:31:17.525542 22426 solver.cpp:253]     Train net output #0: loss = 1.08257 (* 1 = 1.08257 loss)
I0525 11:31:17.525557 22426 sgd_solver.cpp:106] Iteration 23904, lr = 0.0045
I0525 11:31:26.373847 22426 solver.cpp:237] Iteration 24070, loss = 1.25447
I0525 11:31:26.373881 22426 solver.cpp:253]     Train net output #0: loss = 1.25447 (* 1 = 1.25447 loss)
I0525 11:31:26.373898 22426 sgd_solver.cpp:106] Iteration 24070, lr = 0.0045
I0525 11:31:35.223042 22426 solver.cpp:237] Iteration 24236, loss = 1.18299
I0525 11:31:35.223217 22426 solver.cpp:253]     Train net output #0: loss = 1.18299 (* 1 = 1.18299 loss)
I0525 11:31:35.223229 22426 sgd_solver.cpp:106] Iteration 24236, lr = 0.0045
I0525 11:31:44.068341 22426 solver.cpp:237] Iteration 24402, loss = 1.34957
I0525 11:31:44.068377 22426 solver.cpp:253]     Train net output #0: loss = 1.34957 (* 1 = 1.34957 loss)
I0525 11:31:44.068393 22426 sgd_solver.cpp:106] Iteration 24402, lr = 0.0045
I0525 11:32:13.750552 22426 solver.cpp:237] Iteration 24568, loss = 1.17742
I0525 11:32:13.750725 22426 solver.cpp:253]     Train net output #0: loss = 1.17742 (* 1 = 1.17742 loss)
I0525 11:32:13.750741 22426 sgd_solver.cpp:106] Iteration 24568, lr = 0.0045
I0525 11:32:22.590498 22426 solver.cpp:237] Iteration 24734, loss = 1.23471
I0525 11:32:22.590533 22426 solver.cpp:253]     Train net output #0: loss = 1.23471 (* 1 = 1.23471 loss)
I0525 11:32:22.590548 22426 sgd_solver.cpp:106] Iteration 24734, lr = 0.0045
I0525 11:32:31.431968 22426 solver.cpp:237] Iteration 24900, loss = 1.33244
I0525 11:32:31.432008 22426 solver.cpp:253]     Train net output #0: loss = 1.33244 (* 1 = 1.33244 loss)
I0525 11:32:31.432024 22426 sgd_solver.cpp:106] Iteration 24900, lr = 0.0045
I0525 11:32:36.171378 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_24990.caffemodel
I0525 11:32:36.247505 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_24990.solverstate
I0525 11:32:40.344676 22426 solver.cpp:237] Iteration 25066, loss = 1.20086
I0525 11:32:40.344720 22426 solver.cpp:253]     Train net output #0: loss = 1.20086 (* 1 = 1.20086 loss)
I0525 11:32:40.344739 22426 sgd_solver.cpp:106] Iteration 25066, lr = 0.0045
I0525 11:32:49.182380 22426 solver.cpp:237] Iteration 25232, loss = 1.23079
I0525 11:32:49.182534 22426 solver.cpp:253]     Train net output #0: loss = 1.23079 (* 1 = 1.23079 loss)
I0525 11:32:49.182548 22426 sgd_solver.cpp:106] Iteration 25232, lr = 0.0045
I0525 11:32:58.034176 22426 solver.cpp:237] Iteration 25398, loss = 1.3254
I0525 11:32:58.034224 22426 solver.cpp:253]     Train net output #0: loss = 1.3254 (* 1 = 1.3254 loss)
I0525 11:32:58.034240 22426 sgd_solver.cpp:106] Iteration 25398, lr = 0.0045
I0525 11:33:27.726338 22426 solver.cpp:237] Iteration 25564, loss = 1.36786
I0525 11:33:27.726508 22426 solver.cpp:253]     Train net output #0: loss = 1.36786 (* 1 = 1.36786 loss)
I0525 11:33:27.726522 22426 sgd_solver.cpp:106] Iteration 25564, lr = 0.0045
I0525 11:33:36.573859 22426 solver.cpp:237] Iteration 25730, loss = 1.26119
I0525 11:33:36.573894 22426 solver.cpp:253]     Train net output #0: loss = 1.26119 (* 1 = 1.26119 loss)
I0525 11:33:36.573907 22426 sgd_solver.cpp:106] Iteration 25730, lr = 0.0045
I0525 11:33:45.417726 22426 solver.cpp:237] Iteration 25896, loss = 1.07362
I0525 11:33:45.417769 22426 solver.cpp:253]     Train net output #0: loss = 1.07362 (* 1 = 1.07362 loss)
I0525 11:33:45.417788 22426 sgd_solver.cpp:106] Iteration 25896, lr = 0.0045
I0525 11:33:54.271347 22426 solver.cpp:237] Iteration 26062, loss = 1.14024
I0525 11:33:54.271384 22426 solver.cpp:253]     Train net output #0: loss = 1.14024 (* 1 = 1.14024 loss)
I0525 11:33:54.271399 22426 sgd_solver.cpp:106] Iteration 26062, lr = 0.0045
I0525 11:34:03.123667 22426 solver.cpp:237] Iteration 26228, loss = 1.20381
I0525 11:34:03.123826 22426 solver.cpp:253]     Train net output #0: loss = 1.20381 (* 1 = 1.20381 loss)
I0525 11:34:03.123839 22426 sgd_solver.cpp:106] Iteration 26228, lr = 0.0045
I0525 11:34:11.963047 22426 solver.cpp:237] Iteration 26394, loss = 1.12231
I0525 11:34:11.963091 22426 solver.cpp:253]     Train net output #0: loss = 1.12231 (* 1 = 1.12231 loss)
I0525 11:34:11.963109 22426 sgd_solver.cpp:106] Iteration 26394, lr = 0.0045
I0525 11:34:20.805124 22426 solver.cpp:237] Iteration 26560, loss = 1.36689
I0525 11:34:20.805160 22426 solver.cpp:253]     Train net output #0: loss = 1.36689 (* 1 = 1.36689 loss)
I0525 11:34:20.805177 22426 sgd_solver.cpp:106] Iteration 26560, lr = 0.0045
I0525 11:34:25.868849 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_26656.caffemodel
I0525 11:34:25.942847 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_26656.solverstate
I0525 11:34:26.359391 22426 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 11:35:34.328929 22426 solver.cpp:409]     Test net output #0: accuracy = 0.881003
I0525 11:35:34.329105 22426 solver.cpp:409]     Test net output #1: loss = 0.379576 (* 1 = 0.379576 loss)
I0525 11:35:58.477181 22426 solver.cpp:237] Iteration 26726, loss = 1.06026
I0525 11:35:58.477231 22426 solver.cpp:253]     Train net output #0: loss = 1.06026 (* 1 = 1.06026 loss)
I0525 11:35:58.477248 22426 sgd_solver.cpp:106] Iteration 26726, lr = 0.0045
I0525 11:36:07.321725 22426 solver.cpp:237] Iteration 26892, loss = 1.12132
I0525 11:36:07.321884 22426 solver.cpp:253]     Train net output #0: loss = 1.12132 (* 1 = 1.12132 loss)
I0525 11:36:07.321897 22426 sgd_solver.cpp:106] Iteration 26892, lr = 0.0045
I0525 11:36:16.155807 22426 solver.cpp:237] Iteration 27058, loss = 1.25352
I0525 11:36:16.155845 22426 solver.cpp:253]     Train net output #0: loss = 1.25352 (* 1 = 1.25352 loss)
I0525 11:36:16.155866 22426 sgd_solver.cpp:106] Iteration 27058, lr = 0.0045
I0525 11:36:24.991677 22426 solver.cpp:237] Iteration 27224, loss = 1.15094
I0525 11:36:24.991713 22426 solver.cpp:253]     Train net output #0: loss = 1.15094 (* 1 = 1.15094 loss)
I0525 11:36:24.991729 22426 sgd_solver.cpp:106] Iteration 27224, lr = 0.0045
I0525 11:36:33.842878 22426 solver.cpp:237] Iteration 27390, loss = 0.895115
I0525 11:36:33.842914 22426 solver.cpp:253]     Train net output #0: loss = 0.895115 (* 1 = 0.895115 loss)
I0525 11:36:33.842931 22426 sgd_solver.cpp:106] Iteration 27390, lr = 0.0045
I0525 11:36:42.678781 22426 solver.cpp:237] Iteration 27556, loss = 1.28588
I0525 11:36:42.678946 22426 solver.cpp:253]     Train net output #0: loss = 1.28588 (* 1 = 1.28588 loss)
I0525 11:36:42.678961 22426 sgd_solver.cpp:106] Iteration 27556, lr = 0.0045
I0525 11:36:51.518272 22426 solver.cpp:237] Iteration 27722, loss = 1.25716
I0525 11:36:51.518306 22426 solver.cpp:253]     Train net output #0: loss = 1.25716 (* 1 = 1.25716 loss)
I0525 11:36:51.518323 22426 sgd_solver.cpp:106] Iteration 27722, lr = 0.0045
I0525 11:37:21.205906 22426 solver.cpp:237] Iteration 27888, loss = 1.24634
I0525 11:37:21.206075 22426 solver.cpp:253]     Train net output #0: loss = 1.24634 (* 1 = 1.24634 loss)
I0525 11:37:21.206090 22426 sgd_solver.cpp:106] Iteration 27888, lr = 0.0045
I0525 11:37:30.048352 22426 solver.cpp:237] Iteration 28054, loss = 1.17775
I0525 11:37:30.048399 22426 solver.cpp:253]     Train net output #0: loss = 1.17775 (* 1 = 1.17775 loss)
I0525 11:37:30.048413 22426 sgd_solver.cpp:106] Iteration 28054, lr = 0.0045
I0525 11:37:38.882727 22426 solver.cpp:237] Iteration 28220, loss = 1.27678
I0525 11:37:38.882762 22426 solver.cpp:253]     Train net output #0: loss = 1.27678 (* 1 = 1.27678 loss)
I0525 11:37:38.882779 22426 sgd_solver.cpp:106] Iteration 28220, lr = 0.0045
I0525 11:37:44.261003 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_28322.caffemodel
I0525 11:37:44.336032 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_28322.solverstate
I0525 11:37:47.784466 22426 solver.cpp:237] Iteration 28386, loss = 1.25643
I0525 11:37:47.784512 22426 solver.cpp:253]     Train net output #0: loss = 1.25643 (* 1 = 1.25643 loss)
I0525 11:37:47.784528 22426 sgd_solver.cpp:106] Iteration 28386, lr = 0.0045
I0525 11:37:56.626986 22426 solver.cpp:237] Iteration 28552, loss = 1.01527
I0525 11:37:56.627171 22426 solver.cpp:253]     Train net output #0: loss = 1.01527 (* 1 = 1.01527 loss)
I0525 11:37:56.627185 22426 sgd_solver.cpp:106] Iteration 28552, lr = 0.0045
I0525 11:38:05.468027 22426 solver.cpp:237] Iteration 28718, loss = 1.29529
I0525 11:38:05.468062 22426 solver.cpp:253]     Train net output #0: loss = 1.29529 (* 1 = 1.29529 loss)
I0525 11:38:05.468078 22426 sgd_solver.cpp:106] Iteration 28718, lr = 0.0045
I0525 11:38:14.307586 22426 solver.cpp:237] Iteration 28884, loss = 1.10012
I0525 11:38:14.307621 22426 solver.cpp:253]     Train net output #0: loss = 1.10012 (* 1 = 1.10012 loss)
I0525 11:38:14.307638 22426 sgd_solver.cpp:106] Iteration 28884, lr = 0.0045
I0525 11:38:44.004201 22426 solver.cpp:237] Iteration 29050, loss = 1.13892
I0525 11:38:44.004370 22426 solver.cpp:253]     Train net output #0: loss = 1.13892 (* 1 = 1.13892 loss)
I0525 11:38:44.004384 22426 sgd_solver.cpp:106] Iteration 29050, lr = 0.0045
I0525 11:38:52.848601 22426 solver.cpp:237] Iteration 29216, loss = 1.09905
I0525 11:38:52.848636 22426 solver.cpp:253]     Train net output #0: loss = 1.09905 (* 1 = 1.09905 loss)
I0525 11:38:52.848652 22426 sgd_solver.cpp:106] Iteration 29216, lr = 0.0045
I0525 11:39:01.682648 22426 solver.cpp:237] Iteration 29382, loss = 1.0306
I0525 11:39:01.682683 22426 solver.cpp:253]     Train net output #0: loss = 1.0306 (* 1 = 1.0306 loss)
I0525 11:39:01.682700 22426 sgd_solver.cpp:106] Iteration 29382, lr = 0.0045
I0525 11:39:10.522287 22426 solver.cpp:237] Iteration 29548, loss = 1.24669
I0525 11:39:10.522325 22426 solver.cpp:253]     Train net output #0: loss = 1.24669 (* 1 = 1.24669 loss)
I0525 11:39:10.522346 22426 sgd_solver.cpp:106] Iteration 29548, lr = 0.0045
I0525 11:39:19.365937 22426 solver.cpp:237] Iteration 29714, loss = 1.19777
I0525 11:39:19.366089 22426 solver.cpp:253]     Train net output #0: loss = 1.19777 (* 1 = 1.19777 loss)
I0525 11:39:19.366103 22426 sgd_solver.cpp:106] Iteration 29714, lr = 0.0045
I0525 11:39:28.208158 22426 solver.cpp:237] Iteration 29880, loss = 1.14164
I0525 11:39:28.208194 22426 solver.cpp:253]     Train net output #0: loss = 1.14164 (* 1 = 1.14164 loss)
I0525 11:39:28.208210 22426 sgd_solver.cpp:106] Iteration 29880, lr = 0.0045
I0525 11:39:33.901235 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_29988.caffemodel
I0525 11:39:33.975692 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_29988.solverstate
I0525 11:39:34.444169 22426 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 11:40:21.562252 22426 solver.cpp:409]     Test net output #0: accuracy = 0.881463
I0525 11:40:21.562420 22426 solver.cpp:409]     Test net output #1: loss = 0.38722 (* 1 = 0.38722 loss)
I0525 11:40:45.033701 22426 solver.cpp:237] Iteration 30046, loss = 1.23704
I0525 11:40:45.033751 22426 solver.cpp:253]     Train net output #0: loss = 1.23704 (* 1 = 1.23704 loss)
I0525 11:40:45.033766 22426 sgd_solver.cpp:106] Iteration 30046, lr = 0.0045
I0525 11:40:53.878571 22426 solver.cpp:237] Iteration 30212, loss = 1.28281
I0525 11:40:53.878727 22426 solver.cpp:253]     Train net output #0: loss = 1.28281 (* 1 = 1.28281 loss)
I0525 11:40:53.878741 22426 sgd_solver.cpp:106] Iteration 30212, lr = 0.0045
I0525 11:41:02.710930 22426 solver.cpp:237] Iteration 30378, loss = 1.17871
I0525 11:41:02.710965 22426 solver.cpp:253]     Train net output #0: loss = 1.17871 (* 1 = 1.17871 loss)
I0525 11:41:02.710983 22426 sgd_solver.cpp:106] Iteration 30378, lr = 0.0045
I0525 11:41:11.558940 22426 solver.cpp:237] Iteration 30544, loss = 1.27507
I0525 11:41:11.558987 22426 solver.cpp:253]     Train net output #0: loss = 1.27507 (* 1 = 1.27507 loss)
I0525 11:41:11.559003 22426 sgd_solver.cpp:106] Iteration 30544, lr = 0.0045
I0525 11:41:20.398792 22426 solver.cpp:237] Iteration 30710, loss = 1.03739
I0525 11:41:20.398828 22426 solver.cpp:253]     Train net output #0: loss = 1.03739 (* 1 = 1.03739 loss)
I0525 11:41:20.398843 22426 sgd_solver.cpp:106] Iteration 30710, lr = 0.0045
I0525 11:41:29.229956 22426 solver.cpp:237] Iteration 30876, loss = 1.03895
I0525 11:41:29.230129 22426 solver.cpp:253]     Train net output #0: loss = 1.03895 (* 1 = 1.03895 loss)
I0525 11:41:29.230144 22426 sgd_solver.cpp:106] Iteration 30876, lr = 0.0045
I0525 11:41:38.067800 22426 solver.cpp:237] Iteration 31042, loss = 1.11075
I0525 11:41:38.067844 22426 solver.cpp:253]     Train net output #0: loss = 1.11075 (* 1 = 1.11075 loss)
I0525 11:41:38.067858 22426 sgd_solver.cpp:106] Iteration 31042, lr = 0.0045
I0525 11:42:07.740450 22426 solver.cpp:237] Iteration 31208, loss = 1.23688
I0525 11:42:07.740627 22426 solver.cpp:253]     Train net output #0: loss = 1.23688 (* 1 = 1.23688 loss)
I0525 11:42:07.740641 22426 sgd_solver.cpp:106] Iteration 31208, lr = 0.0045
I0525 11:42:16.584822 22426 solver.cpp:237] Iteration 31374, loss = 1.15719
I0525 11:42:16.584856 22426 solver.cpp:253]     Train net output #0: loss = 1.15719 (* 1 = 1.15719 loss)
I0525 11:42:16.584873 22426 sgd_solver.cpp:106] Iteration 31374, lr = 0.0045
I0525 11:42:25.432790 22426 solver.cpp:237] Iteration 31540, loss = 1.23087
I0525 11:42:25.432838 22426 solver.cpp:253]     Train net output #0: loss = 1.23087 (* 1 = 1.23087 loss)
I0525 11:42:25.432853 22426 sgd_solver.cpp:106] Iteration 31540, lr = 0.0045
I0525 11:42:31.449586 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_31654.caffemodel
I0525 11:42:31.527366 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_31654.solverstate
I0525 11:42:34.341352 22426 solver.cpp:237] Iteration 31706, loss = 1.20918
I0525 11:42:34.341395 22426 solver.cpp:253]     Train net output #0: loss = 1.20918 (* 1 = 1.20918 loss)
I0525 11:42:34.341415 22426 sgd_solver.cpp:106] Iteration 31706, lr = 0.0045
I0525 11:42:43.182026 22426 solver.cpp:237] Iteration 31872, loss = 1.06472
I0525 11:42:43.182194 22426 solver.cpp:253]     Train net output #0: loss = 1.06472 (* 1 = 1.06472 loss)
I0525 11:42:43.182209 22426 sgd_solver.cpp:106] Iteration 31872, lr = 0.0045
I0525 11:42:52.025547 22426 solver.cpp:237] Iteration 32038, loss = 1.15756
I0525 11:42:52.025588 22426 solver.cpp:253]     Train net output #0: loss = 1.15756 (* 1 = 1.15756 loss)
I0525 11:42:52.025609 22426 sgd_solver.cpp:106] Iteration 32038, lr = 0.0045
I0525 11:43:00.860160 22426 solver.cpp:237] Iteration 32204, loss = 1.32131
I0525 11:43:00.860196 22426 solver.cpp:253]     Train net output #0: loss = 1.32131 (* 1 = 1.32131 loss)
I0525 11:43:00.860211 22426 sgd_solver.cpp:106] Iteration 32204, lr = 0.0045
I0525 11:43:30.590525 22426 solver.cpp:237] Iteration 32370, loss = 1.10042
I0525 11:43:30.590703 22426 solver.cpp:253]     Train net output #0: loss = 1.10042 (* 1 = 1.10042 loss)
I0525 11:43:30.590718 22426 sgd_solver.cpp:106] Iteration 32370, lr = 0.0045
I0525 11:43:39.432399 22426 solver.cpp:237] Iteration 32536, loss = 1.14228
I0525 11:43:39.432435 22426 solver.cpp:253]     Train net output #0: loss = 1.14228 (* 1 = 1.14228 loss)
I0525 11:43:39.432449 22426 sgd_solver.cpp:106] Iteration 32536, lr = 0.0045
I0525 11:43:48.274119 22426 solver.cpp:237] Iteration 32702, loss = 1.34117
I0525 11:43:48.274160 22426 solver.cpp:253]     Train net output #0: loss = 1.34117 (* 1 = 1.34117 loss)
I0525 11:43:48.274175 22426 sgd_solver.cpp:106] Iteration 32702, lr = 0.0045
I0525 11:43:57.111182 22426 solver.cpp:237] Iteration 32868, loss = 1.33424
I0525 11:43:57.111217 22426 solver.cpp:253]     Train net output #0: loss = 1.33424 (* 1 = 1.33424 loss)
I0525 11:43:57.111233 22426 sgd_solver.cpp:106] Iteration 32868, lr = 0.0045
I0525 11:44:05.951431 22426 solver.cpp:237] Iteration 33034, loss = 1.28848
I0525 11:44:05.951611 22426 solver.cpp:253]     Train net output #0: loss = 1.28848 (* 1 = 1.28848 loss)
I0525 11:44:05.951625 22426 sgd_solver.cpp:106] Iteration 33034, lr = 0.0045
I0525 11:44:14.790877 22426 solver.cpp:237] Iteration 33200, loss = 1.2761
I0525 11:44:14.790911 22426 solver.cpp:253]     Train net output #0: loss = 1.2761 (* 1 = 1.2761 loss)
I0525 11:44:14.790930 22426 sgd_solver.cpp:106] Iteration 33200, lr = 0.0045
I0525 11:44:21.128722 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_33320.caffemodel
I0525 11:44:21.204946 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_33320.solverstate
I0525 11:44:21.730207 22426 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 11:45:29.797924 22426 solver.cpp:409]     Test net output #0: accuracy = 0.887119
I0525 11:45:29.798094 22426 solver.cpp:409]     Test net output #1: loss = 0.371935 (* 1 = 0.371935 loss)
I0525 11:45:52.617264 22426 solver.cpp:237] Iteration 33366, loss = 1.29087
I0525 11:45:52.617314 22426 solver.cpp:253]     Train net output #0: loss = 1.29087 (* 1 = 1.29087 loss)
I0525 11:45:52.617331 22426 sgd_solver.cpp:106] Iteration 33366, lr = 0.0045
I0525 11:46:01.461668 22426 solver.cpp:237] Iteration 33532, loss = 1.24524
I0525 11:46:01.461827 22426 solver.cpp:253]     Train net output #0: loss = 1.24524 (* 1 = 1.24524 loss)
I0525 11:46:01.461840 22426 sgd_solver.cpp:106] Iteration 33532, lr = 0.0045
I0525 11:46:10.308738 22426 solver.cpp:237] Iteration 33698, loss = 1.02968
I0525 11:46:10.308779 22426 solver.cpp:253]     Train net output #0: loss = 1.02968 (* 1 = 1.02968 loss)
I0525 11:46:10.308799 22426 sgd_solver.cpp:106] Iteration 33698, lr = 0.0045
I0525 11:46:19.153791 22426 solver.cpp:237] Iteration 33864, loss = 1.11461
I0525 11:46:19.153827 22426 solver.cpp:253]     Train net output #0: loss = 1.11461 (* 1 = 1.11461 loss)
I0525 11:46:19.153843 22426 sgd_solver.cpp:106] Iteration 33864, lr = 0.0045
I0525 11:46:27.998695 22426 solver.cpp:237] Iteration 34030, loss = 1.04392
I0525 11:46:27.998729 22426 solver.cpp:253]     Train net output #0: loss = 1.04392 (* 1 = 1.04392 loss)
I0525 11:46:27.998746 22426 sgd_solver.cpp:106] Iteration 34030, lr = 0.0045
I0525 11:46:36.842540 22426 solver.cpp:237] Iteration 34196, loss = 1.01632
I0525 11:46:36.842700 22426 solver.cpp:253]     Train net output #0: loss = 1.01632 (* 1 = 1.01632 loss)
I0525 11:46:36.842713 22426 sgd_solver.cpp:106] Iteration 34196, lr = 0.0045
I0525 11:46:45.686060 22426 solver.cpp:237] Iteration 34362, loss = 1.0196
I0525 11:46:45.686095 22426 solver.cpp:253]     Train net output #0: loss = 1.0196 (* 1 = 1.0196 loss)
I0525 11:46:45.686110 22426 sgd_solver.cpp:106] Iteration 34362, lr = 0.0045
I0525 11:47:15.396728 22426 solver.cpp:237] Iteration 34528, loss = 1.29543
I0525 11:47:15.396901 22426 solver.cpp:253]     Train net output #0: loss = 1.29543 (* 1 = 1.29543 loss)
I0525 11:47:15.396917 22426 sgd_solver.cpp:106] Iteration 34528, lr = 0.0045
I0525 11:47:24.244067 22426 solver.cpp:237] Iteration 34694, loss = 1.4089
I0525 11:47:24.244102 22426 solver.cpp:253]     Train net output #0: loss = 1.4089 (* 1 = 1.4089 loss)
I0525 11:47:24.244117 22426 sgd_solver.cpp:106] Iteration 34694, lr = 0.0045
I0525 11:47:33.097961 22426 solver.cpp:237] Iteration 34860, loss = 1.29893
I0525 11:47:33.098006 22426 solver.cpp:253]     Train net output #0: loss = 1.29893 (* 1 = 1.29893 loss)
I0525 11:47:33.098022 22426 sgd_solver.cpp:106] Iteration 34860, lr = 0.0045
I0525 11:47:39.757902 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_34986.caffemodel
I0525 11:47:39.832219 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_34986.solverstate
I0525 11:47:42.005357 22426 solver.cpp:237] Iteration 35026, loss = 1.01354
I0525 11:47:42.005398 22426 solver.cpp:253]     Train net output #0: loss = 1.01354 (* 1 = 1.01354 loss)
I0525 11:47:42.005419 22426 sgd_solver.cpp:106] Iteration 35026, lr = 0.0045
I0525 11:47:50.856425 22426 solver.cpp:237] Iteration 35192, loss = 1.02664
I0525 11:47:50.856598 22426 solver.cpp:253]     Train net output #0: loss = 1.02664 (* 1 = 1.02664 loss)
I0525 11:47:50.856613 22426 sgd_solver.cpp:106] Iteration 35192, lr = 0.0045
I0525 11:47:59.705302 22426 solver.cpp:237] Iteration 35358, loss = 0.914968
I0525 11:47:59.705337 22426 solver.cpp:253]     Train net output #0: loss = 0.914968 (* 1 = 0.914968 loss)
I0525 11:47:59.705350 22426 sgd_solver.cpp:106] Iteration 35358, lr = 0.0045
I0525 11:48:08.553740 22426 solver.cpp:237] Iteration 35524, loss = 1.25484
I0525 11:48:08.553776 22426 solver.cpp:253]     Train net output #0: loss = 1.25484 (* 1 = 1.25484 loss)
I0525 11:48:08.553792 22426 sgd_solver.cpp:106] Iteration 35524, lr = 0.0045
I0525 11:48:38.257560 22426 solver.cpp:237] Iteration 35690, loss = 1.17577
I0525 11:48:38.257735 22426 solver.cpp:253]     Train net output #0: loss = 1.17577 (* 1 = 1.17577 loss)
I0525 11:48:38.257750 22426 sgd_solver.cpp:106] Iteration 35690, lr = 0.0045
I0525 11:48:47.105392 22426 solver.cpp:237] Iteration 35856, loss = 1.12242
I0525 11:48:47.105437 22426 solver.cpp:253]     Train net output #0: loss = 1.12242 (* 1 = 1.12242 loss)
I0525 11:48:47.105456 22426 sgd_solver.cpp:106] Iteration 35856, lr = 0.0045
I0525 11:48:55.954634 22426 solver.cpp:237] Iteration 36022, loss = 1.29899
I0525 11:48:55.954670 22426 solver.cpp:253]     Train net output #0: loss = 1.29899 (* 1 = 1.29899 loss)
I0525 11:48:55.954686 22426 sgd_solver.cpp:106] Iteration 36022, lr = 0.0045
I0525 11:49:04.799896 22426 solver.cpp:237] Iteration 36188, loss = 1.16571
I0525 11:49:04.799940 22426 solver.cpp:253]     Train net output #0: loss = 1.16571 (* 1 = 1.16571 loss)
I0525 11:49:04.799955 22426 sgd_solver.cpp:106] Iteration 36188, lr = 0.0045
I0525 11:49:13.635762 22426 solver.cpp:237] Iteration 36354, loss = 1.26796
I0525 11:49:13.635929 22426 solver.cpp:253]     Train net output #0: loss = 1.26796 (* 1 = 1.26796 loss)
I0525 11:49:13.635942 22426 sgd_solver.cpp:106] Iteration 36354, lr = 0.0045
I0525 11:49:22.478615 22426 solver.cpp:237] Iteration 36520, loss = 1.03105
I0525 11:49:22.478649 22426 solver.cpp:253]     Train net output #0: loss = 1.03105 (* 1 = 1.03105 loss)
I0525 11:49:22.478667 22426 sgd_solver.cpp:106] Iteration 36520, lr = 0.0045
I0525 11:49:29.457176 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_36652.caffemodel
I0525 11:49:29.531353 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_36652.solverstate
I0525 11:49:30.107715 22426 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 11:50:17.003248 22426 solver.cpp:409]     Test net output #0: accuracy = 0.886292
I0525 11:50:17.003422 22426 solver.cpp:409]     Test net output #1: loss = 0.36703 (* 1 = 0.36703 loss)
I0525 11:50:39.131585 22426 solver.cpp:237] Iteration 36686, loss = 1.36323
I0525 11:50:39.131635 22426 solver.cpp:253]     Train net output #0: loss = 1.36323 (* 1 = 1.36323 loss)
I0525 11:50:39.131651 22426 sgd_solver.cpp:106] Iteration 36686, lr = 0.0045
I0525 11:50:47.976356 22426 solver.cpp:237] Iteration 36852, loss = 1.16922
I0525 11:50:47.976531 22426 solver.cpp:253]     Train net output #0: loss = 1.16922 (* 1 = 1.16922 loss)
I0525 11:50:47.976546 22426 sgd_solver.cpp:106] Iteration 36852, lr = 0.0045
I0525 11:50:56.835615 22426 solver.cpp:237] Iteration 37018, loss = 1.02821
I0525 11:50:56.835650 22426 solver.cpp:253]     Train net output #0: loss = 1.02821 (* 1 = 1.02821 loss)
I0525 11:50:56.835664 22426 sgd_solver.cpp:106] Iteration 37018, lr = 0.0045
I0525 11:51:05.685094 22426 solver.cpp:237] Iteration 37184, loss = 1.01587
I0525 11:51:05.685129 22426 solver.cpp:253]     Train net output #0: loss = 1.01587 (* 1 = 1.01587 loss)
I0525 11:51:05.685142 22426 sgd_solver.cpp:106] Iteration 37184, lr = 0.0045
I0525 11:51:14.533167 22426 solver.cpp:237] Iteration 37350, loss = 1.09877
I0525 11:51:14.533215 22426 solver.cpp:253]     Train net output #0: loss = 1.09877 (* 1 = 1.09877 loss)
I0525 11:51:14.533229 22426 sgd_solver.cpp:106] Iteration 37350, lr = 0.0045
I0525 11:51:23.389631 22426 solver.cpp:237] Iteration 37516, loss = 1.42954
I0525 11:51:23.389788 22426 solver.cpp:253]     Train net output #0: loss = 1.42954 (* 1 = 1.42954 loss)
I0525 11:51:23.389801 22426 sgd_solver.cpp:106] Iteration 37516, lr = 0.0045
I0525 11:51:32.234114 22426 solver.cpp:237] Iteration 37682, loss = 1.03319
I0525 11:51:32.234148 22426 solver.cpp:253]     Train net output #0: loss = 1.03319 (* 1 = 1.03319 loss)
I0525 11:51:32.234165 22426 sgd_solver.cpp:106] Iteration 37682, lr = 0.0045
I0525 11:52:01.979380 22426 solver.cpp:237] Iteration 37848, loss = 1.25193
I0525 11:52:01.979557 22426 solver.cpp:253]     Train net output #0: loss = 1.25193 (* 1 = 1.25193 loss)
I0525 11:52:01.979571 22426 sgd_solver.cpp:106] Iteration 37848, lr = 0.0045
I0525 11:52:10.834370 22426 solver.cpp:237] Iteration 38014, loss = 1.26984
I0525 11:52:10.834405 22426 solver.cpp:253]     Train net output #0: loss = 1.26984 (* 1 = 1.26984 loss)
I0525 11:52:10.834421 22426 sgd_solver.cpp:106] Iteration 38014, lr = 0.0045
I0525 11:52:19.694001 22426 solver.cpp:237] Iteration 38180, loss = 1.00697
I0525 11:52:19.694037 22426 solver.cpp:253]     Train net output #0: loss = 1.00697 (* 1 = 1.00697 loss)
I0525 11:52:19.694053 22426 sgd_solver.cpp:106] Iteration 38180, lr = 0.0045
I0525 11:52:27.001502 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_38318.caffemodel
I0525 11:52:27.081634 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_38318.solverstate
I0525 11:52:28.619436 22426 solver.cpp:237] Iteration 38346, loss = 1.28026
I0525 11:52:28.619480 22426 solver.cpp:253]     Train net output #0: loss = 1.28026 (* 1 = 1.28026 loss)
I0525 11:52:28.619495 22426 sgd_solver.cpp:106] Iteration 38346, lr = 0.0045
I0525 11:52:37.473472 22426 solver.cpp:237] Iteration 38512, loss = 1.35696
I0525 11:52:37.473634 22426 solver.cpp:253]     Train net output #0: loss = 1.35696 (* 1 = 1.35696 loss)
I0525 11:52:37.473647 22426 sgd_solver.cpp:106] Iteration 38512, lr = 0.0045
I0525 11:52:46.321782 22426 solver.cpp:237] Iteration 38678, loss = 1.04362
I0525 11:52:46.321817 22426 solver.cpp:253]     Train net output #0: loss = 1.04362 (* 1 = 1.04362 loss)
I0525 11:52:46.321831 22426 sgd_solver.cpp:106] Iteration 38678, lr = 0.0045
I0525 11:52:55.181305 22426 solver.cpp:237] Iteration 38844, loss = 0.957634
I0525 11:52:55.181352 22426 solver.cpp:253]     Train net output #0: loss = 0.957634 (* 1 = 0.957634 loss)
I0525 11:52:55.181366 22426 sgd_solver.cpp:106] Iteration 38844, lr = 0.0045
I0525 11:53:24.930881 22426 solver.cpp:237] Iteration 39010, loss = 1.37057
I0525 11:53:24.931066 22426 solver.cpp:253]     Train net output #0: loss = 1.37057 (* 1 = 1.37057 loss)
I0525 11:53:24.931082 22426 sgd_solver.cpp:106] Iteration 39010, lr = 0.0045
I0525 11:53:33.782034 22426 solver.cpp:237] Iteration 39176, loss = 1.23811
I0525 11:53:33.782068 22426 solver.cpp:253]     Train net output #0: loss = 1.23811 (* 1 = 1.23811 loss)
I0525 11:53:33.782085 22426 sgd_solver.cpp:106] Iteration 39176, lr = 0.0045
I0525 11:53:42.642114 22426 solver.cpp:237] Iteration 39342, loss = 1.40807
I0525 11:53:42.642163 22426 solver.cpp:253]     Train net output #0: loss = 1.40807 (* 1 = 1.40807 loss)
I0525 11:53:42.642179 22426 sgd_solver.cpp:106] Iteration 39342, lr = 0.0045
I0525 11:53:51.496032 22426 solver.cpp:237] Iteration 39508, loss = 1.24894
I0525 11:53:51.496068 22426 solver.cpp:253]     Train net output #0: loss = 1.24894 (* 1 = 1.24894 loss)
I0525 11:53:51.496084 22426 sgd_solver.cpp:106] Iteration 39508, lr = 0.0045
I0525 11:54:00.343768 22426 solver.cpp:237] Iteration 39674, loss = 1.37712
I0525 11:54:00.343930 22426 solver.cpp:253]     Train net output #0: loss = 1.37712 (* 1 = 1.37712 loss)
I0525 11:54:00.343945 22426 sgd_solver.cpp:106] Iteration 39674, lr = 0.0045
I0525 11:54:09.196854 22426 solver.cpp:237] Iteration 39840, loss = 0.996302
I0525 11:54:09.196892 22426 solver.cpp:253]     Train net output #0: loss = 0.996302 (* 1 = 0.996302 loss)
I0525 11:54:09.196913 22426 sgd_solver.cpp:106] Iteration 39840, lr = 0.0045
I0525 11:54:16.826244 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_39984.caffemodel
I0525 11:54:16.904585 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_39984.solverstate
I0525 11:54:17.536872 22426 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 11:55:25.586494 22426 solver.cpp:409]     Test net output #0: accuracy = 0.881363
I0525 11:55:25.586669 22426 solver.cpp:409]     Test net output #1: loss = 0.395329 (* 1 = 0.395329 loss)
I0525 11:55:46.986327 22426 solver.cpp:237] Iteration 40006, loss = 1.01414
I0525 11:55:46.986377 22426 solver.cpp:253]     Train net output #0: loss = 1.01414 (* 1 = 1.01414 loss)
I0525 11:55:46.986393 22426 sgd_solver.cpp:106] Iteration 40006, lr = 0.0045
I0525 11:55:55.839974 22426 solver.cpp:237] Iteration 40172, loss = 1.1256
I0525 11:55:55.840137 22426 solver.cpp:253]     Train net output #0: loss = 1.1256 (* 1 = 1.1256 loss)
I0525 11:55:55.840150 22426 sgd_solver.cpp:106] Iteration 40172, lr = 0.0045
I0525 11:56:04.687865 22426 solver.cpp:237] Iteration 40338, loss = 1.1521
I0525 11:56:04.687898 22426 solver.cpp:253]     Train net output #0: loss = 1.1521 (* 1 = 1.1521 loss)
I0525 11:56:04.687916 22426 sgd_solver.cpp:106] Iteration 40338, lr = 0.0045
I0525 11:56:13.535457 22426 solver.cpp:237] Iteration 40504, loss = 1.20077
I0525 11:56:13.535501 22426 solver.cpp:253]     Train net output #0: loss = 1.20077 (* 1 = 1.20077 loss)
I0525 11:56:13.535518 22426 sgd_solver.cpp:106] Iteration 40504, lr = 0.0045
I0525 11:56:22.388909 22426 solver.cpp:237] Iteration 40670, loss = 1.13169
I0525 11:56:22.388944 22426 solver.cpp:253]     Train net output #0: loss = 1.13169 (* 1 = 1.13169 loss)
I0525 11:56:22.388967 22426 sgd_solver.cpp:106] Iteration 40670, lr = 0.0045
I0525 11:56:31.239372 22426 solver.cpp:237] Iteration 40836, loss = 1.49604
I0525 11:56:31.239529 22426 solver.cpp:253]     Train net output #0: loss = 1.49604 (* 1 = 1.49604 loss)
I0525 11:56:31.239542 22426 sgd_solver.cpp:106] Iteration 40836, lr = 0.0045
I0525 11:56:40.086781 22426 solver.cpp:237] Iteration 41002, loss = 1.10148
I0525 11:56:40.086824 22426 solver.cpp:253]     Train net output #0: loss = 1.10148 (* 1 = 1.10148 loss)
I0525 11:56:40.086839 22426 sgd_solver.cpp:106] Iteration 41002, lr = 0.0045
I0525 11:57:09.792440 22426 solver.cpp:237] Iteration 41168, loss = 1.24491
I0525 11:57:09.792624 22426 solver.cpp:253]     Train net output #0: loss = 1.24491 (* 1 = 1.24491 loss)
I0525 11:57:09.792639 22426 sgd_solver.cpp:106] Iteration 41168, lr = 0.0045
I0525 11:57:18.651312 22426 solver.cpp:237] Iteration 41334, loss = 1.11616
I0525 11:57:18.651346 22426 solver.cpp:253]     Train net output #0: loss = 1.11616 (* 1 = 1.11616 loss)
I0525 11:57:18.651365 22426 sgd_solver.cpp:106] Iteration 41334, lr = 0.0045
I0525 11:57:27.496464 22426 solver.cpp:237] Iteration 41500, loss = 0.970767
I0525 11:57:27.496507 22426 solver.cpp:253]     Train net output #0: loss = 0.970767 (* 1 = 0.970767 loss)
I0525 11:57:27.496525 22426 sgd_solver.cpp:106] Iteration 41500, lr = 0.0045
I0525 11:57:35.445756 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_41650.caffemodel
I0525 11:57:35.522483 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_41650.solverstate
I0525 11:57:36.419373 22426 solver.cpp:237] Iteration 41666, loss = 1.20406
I0525 11:57:36.419422 22426 solver.cpp:253]     Train net output #0: loss = 1.20406 (* 1 = 1.20406 loss)
I0525 11:57:36.419438 22426 sgd_solver.cpp:106] Iteration 41666, lr = 0.0045
I0525 11:57:45.279820 22426 solver.cpp:237] Iteration 41832, loss = 1.19154
I0525 11:57:45.279985 22426 solver.cpp:253]     Train net output #0: loss = 1.19154 (* 1 = 1.19154 loss)
I0525 11:57:45.279999 22426 sgd_solver.cpp:106] Iteration 41832, lr = 0.0045
I0525 11:57:54.125341 22426 solver.cpp:237] Iteration 41998, loss = 1.2481
I0525 11:57:54.125387 22426 solver.cpp:253]     Train net output #0: loss = 1.2481 (* 1 = 1.2481 loss)
I0525 11:57:54.125406 22426 sgd_solver.cpp:106] Iteration 41998, lr = 0.0045
I0525 11:58:02.973590 22426 solver.cpp:237] Iteration 42164, loss = 0.946007
I0525 11:58:02.973625 22426 solver.cpp:253]     Train net output #0: loss = 0.946007 (* 1 = 0.946007 loss)
I0525 11:58:02.973642 22426 sgd_solver.cpp:106] Iteration 42164, lr = 0.0045
I0525 11:58:32.657837 22426 solver.cpp:237] Iteration 42330, loss = 1.24215
I0525 11:58:32.658016 22426 solver.cpp:253]     Train net output #0: loss = 1.24215 (* 1 = 1.24215 loss)
I0525 11:58:32.658030 22426 sgd_solver.cpp:106] Iteration 42330, lr = 0.0045
I0525 11:58:41.506764 22426 solver.cpp:237] Iteration 42496, loss = 1.16173
I0525 11:58:41.506806 22426 solver.cpp:253]     Train net output #0: loss = 1.16173 (* 1 = 1.16173 loss)
I0525 11:58:41.506824 22426 sgd_solver.cpp:106] Iteration 42496, lr = 0.0045
I0525 11:58:50.350955 22426 solver.cpp:237] Iteration 42662, loss = 1.17687
I0525 11:58:50.350989 22426 solver.cpp:253]     Train net output #0: loss = 1.17687 (* 1 = 1.17687 loss)
I0525 11:58:50.351004 22426 sgd_solver.cpp:106] Iteration 42662, lr = 0.0045
I0525 11:58:59.204872 22426 solver.cpp:237] Iteration 42828, loss = 0.988464
I0525 11:58:59.204908 22426 solver.cpp:253]     Train net output #0: loss = 0.988464 (* 1 = 0.988464 loss)
I0525 11:58:59.204924 22426 sgd_solver.cpp:106] Iteration 42828, lr = 0.0045
I0525 11:59:08.057929 22426 solver.cpp:237] Iteration 42994, loss = 1.16856
I0525 11:59:08.058097 22426 solver.cpp:253]     Train net output #0: loss = 1.16856 (* 1 = 1.16856 loss)
I0525 11:59:08.058111 22426 sgd_solver.cpp:106] Iteration 42994, lr = 0.0045
I0525 11:59:16.908759 22426 solver.cpp:237] Iteration 43160, loss = 1.40877
I0525 11:59:16.908793 22426 solver.cpp:253]     Train net output #0: loss = 1.40877 (* 1 = 1.40877 loss)
I0525 11:59:16.908812 22426 sgd_solver.cpp:106] Iteration 43160, lr = 0.0045
I0525 11:59:25.168903 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_43316.caffemodel
I0525 11:59:25.244709 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_43316.solverstate
I0525 11:59:25.819897 22426 solver.cpp:237] Iteration 43326, loss = 1.0743
I0525 11:59:25.819942 22426 solver.cpp:253]     Train net output #0: loss = 1.0743 (* 1 = 1.0743 loss)
I0525 11:59:25.819958 22426 sgd_solver.cpp:106] Iteration 43326, lr = 0.0045
I0525 11:59:25.926271 22426 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 12:00:13.102908 22426 solver.cpp:409]     Test net output #0: accuracy = 0.888967
I0525 12:00:13.103099 22426 solver.cpp:409]     Test net output #1: loss = 0.361454 (* 1 = 0.361454 loss)
I0525 12:00:42.700083 22426 solver.cpp:237] Iteration 43492, loss = 1.02932
I0525 12:00:42.700134 22426 solver.cpp:253]     Train net output #0: loss = 1.02932 (* 1 = 1.02932 loss)
I0525 12:00:42.700147 22426 sgd_solver.cpp:106] Iteration 43492, lr = 0.0045
I0525 12:00:51.553431 22426 solver.cpp:237] Iteration 43658, loss = 1.05654
I0525 12:00:51.553607 22426 solver.cpp:253]     Train net output #0: loss = 1.05654 (* 1 = 1.05654 loss)
I0525 12:00:51.553622 22426 sgd_solver.cpp:106] Iteration 43658, lr = 0.0045
I0525 12:01:00.400199 22426 solver.cpp:237] Iteration 43824, loss = 1.15545
I0525 12:01:00.400234 22426 solver.cpp:253]     Train net output #0: loss = 1.15545 (* 1 = 1.15545 loss)
I0525 12:01:00.400250 22426 sgd_solver.cpp:106] Iteration 43824, lr = 0.0045
I0525 12:01:09.245225 22426 solver.cpp:237] Iteration 43990, loss = 1.23316
I0525 12:01:09.245261 22426 solver.cpp:253]     Train net output #0: loss = 1.23316 (* 1 = 1.23316 loss)
I0525 12:01:09.245276 22426 sgd_solver.cpp:106] Iteration 43990, lr = 0.0045
I0525 12:01:18.088914 22426 solver.cpp:237] Iteration 44156, loss = 1.10471
I0525 12:01:18.088963 22426 solver.cpp:253]     Train net output #0: loss = 1.10471 (* 1 = 1.10471 loss)
I0525 12:01:18.088979 22426 sgd_solver.cpp:106] Iteration 44156, lr = 0.0045
I0525 12:01:26.924708 22426 solver.cpp:237] Iteration 44322, loss = 0.936947
I0525 12:01:26.924868 22426 solver.cpp:253]     Train net output #0: loss = 0.936947 (* 1 = 0.936947 loss)
I0525 12:01:26.924883 22426 sgd_solver.cpp:106] Iteration 44322, lr = 0.0045
I0525 12:01:56.656702 22426 solver.cpp:237] Iteration 44488, loss = 1.01737
I0525 12:01:56.656752 22426 solver.cpp:253]     Train net output #0: loss = 1.01737 (* 1 = 1.01737 loss)
I0525 12:01:56.656769 22426 sgd_solver.cpp:106] Iteration 44488, lr = 0.0045
I0525 12:02:05.499382 22426 solver.cpp:237] Iteration 44654, loss = 1.24153
I0525 12:02:05.499565 22426 solver.cpp:253]     Train net output #0: loss = 1.24153 (* 1 = 1.24153 loss)
I0525 12:02:05.499579 22426 sgd_solver.cpp:106] Iteration 44654, lr = 0.0045
I0525 12:02:14.352442 22426 solver.cpp:237] Iteration 44820, loss = 1.20306
I0525 12:02:14.352478 22426 solver.cpp:253]     Train net output #0: loss = 1.20306 (* 1 = 1.20306 loss)
I0525 12:02:14.352494 22426 sgd_solver.cpp:106] Iteration 44820, lr = 0.0045
I0525 12:02:22.935675 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_44982.caffemodel
I0525 12:02:23.010617 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_44982.solverstate
I0525 12:02:23.266643 22426 solver.cpp:237] Iteration 44986, loss = 1.22078
I0525 12:02:23.266687 22426 solver.cpp:253]     Train net output #0: loss = 1.22078 (* 1 = 1.22078 loss)
I0525 12:02:23.266703 22426 sgd_solver.cpp:106] Iteration 44986, lr = 0.0045
I0525 12:02:32.124814 22426 solver.cpp:237] Iteration 45152, loss = 0.928356
I0525 12:02:32.124855 22426 solver.cpp:253]     Train net output #0: loss = 0.928356 (* 1 = 0.928356 loss)
I0525 12:02:32.124869 22426 sgd_solver.cpp:106] Iteration 45152, lr = 0.0045
I0525 12:02:40.975150 22426 solver.cpp:237] Iteration 45318, loss = 1.06453
I0525 12:02:40.975311 22426 solver.cpp:253]     Train net output #0: loss = 1.06453 (* 1 = 1.06453 loss)
I0525 12:02:40.975325 22426 sgd_solver.cpp:106] Iteration 45318, lr = 0.0045
I0525 12:02:49.832499 22426 solver.cpp:237] Iteration 45484, loss = 1.29569
I0525 12:02:49.832547 22426 solver.cpp:253]     Train net output #0: loss = 1.29569 (* 1 = 1.29569 loss)
I0525 12:02:49.832562 22426 sgd_solver.cpp:106] Iteration 45484, lr = 0.0045
I0525 12:03:19.496495 22426 solver.cpp:237] Iteration 45650, loss = 1.33723
I0525 12:03:19.496685 22426 solver.cpp:253]     Train net output #0: loss = 1.33723 (* 1 = 1.33723 loss)
I0525 12:03:19.496700 22426 sgd_solver.cpp:106] Iteration 45650, lr = 0.0045
I0525 12:03:28.342558 22426 solver.cpp:237] Iteration 45816, loss = 1.25404
I0525 12:03:28.342594 22426 solver.cpp:253]     Train net output #0: loss = 1.25404 (* 1 = 1.25404 loss)
I0525 12:03:28.342607 22426 sgd_solver.cpp:106] Iteration 45816, lr = 0.0045
I0525 12:03:37.177474 22426 solver.cpp:237] Iteration 45982, loss = 1.11323
I0525 12:03:37.177510 22426 solver.cpp:253]     Train net output #0: loss = 1.11323 (* 1 = 1.11323 loss)
I0525 12:03:37.177525 22426 sgd_solver.cpp:106] Iteration 45982, lr = 0.0045
I0525 12:03:46.020135 22426 solver.cpp:237] Iteration 46148, loss = 1.34446
I0525 12:03:46.020172 22426 solver.cpp:253]     Train net output #0: loss = 1.34446 (* 1 = 1.34446 loss)
I0525 12:03:46.020193 22426 sgd_solver.cpp:106] Iteration 46148, lr = 0.0045
I0525 12:03:54.868072 22426 solver.cpp:237] Iteration 46314, loss = 1.284
I0525 12:03:54.868228 22426 solver.cpp:253]     Train net output #0: loss = 1.284 (* 1 = 1.284 loss)
I0525 12:03:54.868242 22426 sgd_solver.cpp:106] Iteration 46314, lr = 0.0045
I0525 12:04:03.717486 22426 solver.cpp:237] Iteration 46480, loss = 1.29066
I0525 12:04:03.717521 22426 solver.cpp:253]     Train net output #0: loss = 1.29066 (* 1 = 1.29066 loss)
I0525 12:04:03.717538 22426 sgd_solver.cpp:106] Iteration 46480, lr = 0.0045
I0525 12:04:12.571416 22426 solver.cpp:237] Iteration 46646, loss = 1.21498
I0525 12:04:12.571462 22426 solver.cpp:253]     Train net output #0: loss = 1.21498 (* 1 = 1.21498 loss)
I0525 12:04:12.571476 22426 sgd_solver.cpp:106] Iteration 46646, lr = 0.0045
I0525 12:04:12.625355 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_46648.caffemodel
I0525 12:04:12.700711 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_46648.solverstate
I0525 12:04:13.436246 22426 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 12:05:21.402516 22426 solver.cpp:409]     Test net output #0: accuracy = 0.891608
I0525 12:05:21.402705 22426 solver.cpp:409]     Test net output #1: loss = 0.349273 (* 1 = 0.349273 loss)
I0525 12:05:50.201234 22426 solver.cpp:237] Iteration 46812, loss = 1.21748
I0525 12:05:50.201282 22426 solver.cpp:253]     Train net output #0: loss = 1.21748 (* 1 = 1.21748 loss)
I0525 12:05:50.201302 22426 sgd_solver.cpp:106] Iteration 46812, lr = 0.0045
I0525 12:05:59.051554 22426 solver.cpp:237] Iteration 46978, loss = 1.053
I0525 12:05:59.051722 22426 solver.cpp:253]     Train net output #0: loss = 1.053 (* 1 = 1.053 loss)
I0525 12:05:59.051735 22426 sgd_solver.cpp:106] Iteration 46978, lr = 0.0045
I0525 12:06:07.902705 22426 solver.cpp:237] Iteration 47144, loss = 1.06877
I0525 12:06:07.902740 22426 solver.cpp:253]     Train net output #0: loss = 1.06877 (* 1 = 1.06877 loss)
I0525 12:06:07.902755 22426 sgd_solver.cpp:106] Iteration 47144, lr = 0.0045
I0525 12:06:16.746460 22426 solver.cpp:237] Iteration 47310, loss = 1.18023
I0525 12:06:16.746496 22426 solver.cpp:253]     Train net output #0: loss = 1.18023 (* 1 = 1.18023 loss)
I0525 12:06:16.746520 22426 sgd_solver.cpp:106] Iteration 47310, lr = 0.0045
I0525 12:06:25.589296 22426 solver.cpp:237] Iteration 47476, loss = 1.32994
I0525 12:06:25.589332 22426 solver.cpp:253]     Train net output #0: loss = 1.32994 (* 1 = 1.32994 loss)
I0525 12:06:25.589350 22426 sgd_solver.cpp:106] Iteration 47476, lr = 0.0045
I0525 12:06:34.439453 22426 solver.cpp:237] Iteration 47642, loss = 1.36607
I0525 12:06:34.439625 22426 solver.cpp:253]     Train net output #0: loss = 1.36607 (* 1 = 1.36607 loss)
I0525 12:06:34.439638 22426 sgd_solver.cpp:106] Iteration 47642, lr = 0.0045
I0525 12:07:04.146188 22426 solver.cpp:237] Iteration 47808, loss = 1.16834
I0525 12:07:04.146237 22426 solver.cpp:253]     Train net output #0: loss = 1.16834 (* 1 = 1.16834 loss)
I0525 12:07:04.146255 22426 sgd_solver.cpp:106] Iteration 47808, lr = 0.0045
I0525 12:07:12.996497 22426 solver.cpp:237] Iteration 47974, loss = 1.246
I0525 12:07:12.996666 22426 solver.cpp:253]     Train net output #0: loss = 1.246 (* 1 = 1.246 loss)
I0525 12:07:12.996681 22426 sgd_solver.cpp:106] Iteration 47974, lr = 0.0045
I0525 12:07:21.851198 22426 solver.cpp:237] Iteration 48140, loss = 1.0464
I0525 12:07:21.851233 22426 solver.cpp:253]     Train net output #0: loss = 1.0464 (* 1 = 1.0464 loss)
I0525 12:07:21.851249 22426 sgd_solver.cpp:106] Iteration 48140, lr = 0.0045
I0525 12:07:30.705464 22426 solver.cpp:237] Iteration 48306, loss = 1.27428
I0525 12:07:30.705502 22426 solver.cpp:253]     Train net output #0: loss = 1.27428 (* 1 = 1.27428 loss)
I0525 12:07:30.705520 22426 sgd_solver.cpp:106] Iteration 48306, lr = 0.0045
I0525 12:07:31.079556 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_48314.caffemodel
I0525 12:07:31.156689 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_48314.solverstate
I0525 12:07:39.622442 22426 solver.cpp:237] Iteration 48472, loss = 1.14039
I0525 12:07:39.622493 22426 solver.cpp:253]     Train net output #0: loss = 1.14039 (* 1 = 1.14039 loss)
I0525 12:07:39.622509 22426 sgd_solver.cpp:106] Iteration 48472, lr = 0.0045
I0525 12:07:48.477056 22426 solver.cpp:237] Iteration 48638, loss = 0.980195
I0525 12:07:48.477226 22426 solver.cpp:253]     Train net output #0: loss = 0.980195 (* 1 = 0.980195 loss)
I0525 12:07:48.477239 22426 sgd_solver.cpp:106] Iteration 48638, lr = 0.0045
I0525 12:07:57.326037 22426 solver.cpp:237] Iteration 48804, loss = 1.32461
I0525 12:07:57.326072 22426 solver.cpp:253]     Train net output #0: loss = 1.32461 (* 1 = 1.32461 loss)
I0525 12:07:57.326092 22426 sgd_solver.cpp:106] Iteration 48804, lr = 0.0045
I0525 12:08:27.018916 22426 solver.cpp:237] Iteration 48970, loss = 1.38375
I0525 12:08:27.019098 22426 solver.cpp:253]     Train net output #0: loss = 1.38375 (* 1 = 1.38375 loss)
I0525 12:08:27.019114 22426 sgd_solver.cpp:106] Iteration 48970, lr = 0.0045
I0525 12:08:35.860599 22426 solver.cpp:237] Iteration 49136, loss = 1.3213
I0525 12:08:35.860636 22426 solver.cpp:253]     Train net output #0: loss = 1.3213 (* 1 = 1.3213 loss)
I0525 12:08:35.860651 22426 sgd_solver.cpp:106] Iteration 49136, lr = 0.0045
I0525 12:08:44.719260 22426 solver.cpp:237] Iteration 49302, loss = 1.22853
I0525 12:08:44.719302 22426 solver.cpp:253]     Train net output #0: loss = 1.22853 (* 1 = 1.22853 loss)
I0525 12:08:44.719322 22426 sgd_solver.cpp:106] Iteration 49302, lr = 0.0045
I0525 12:08:53.563801 22426 solver.cpp:237] Iteration 49468, loss = 1.24148
I0525 12:08:53.563837 22426 solver.cpp:253]     Train net output #0: loss = 1.24148 (* 1 = 1.24148 loss)
I0525 12:08:53.563853 22426 sgd_solver.cpp:106] Iteration 49468, lr = 0.0045
I0525 12:09:02.396108 22426 solver.cpp:237] Iteration 49634, loss = 1.27558
I0525 12:09:02.396270 22426 solver.cpp:253]     Train net output #0: loss = 1.27558 (* 1 = 1.27558 loss)
I0525 12:09:02.396284 22426 sgd_solver.cpp:106] Iteration 49634, lr = 0.0045
I0525 12:09:11.242444 22426 solver.cpp:237] Iteration 49800, loss = 1.03833
I0525 12:09:11.242485 22426 solver.cpp:253]     Train net output #0: loss = 1.03833 (* 1 = 1.03833 loss)
I0525 12:09:11.242502 22426 sgd_solver.cpp:106] Iteration 49800, lr = 0.0045
I0525 12:09:20.085592 22426 solver.cpp:237] Iteration 49966, loss = 1.01112
I0525 12:09:20.085628 22426 solver.cpp:253]     Train net output #0: loss = 1.01112 (* 1 = 1.01112 loss)
I0525 12:09:20.085644 22426 sgd_solver.cpp:106] Iteration 49966, lr = 0.0045
I0525 12:09:20.779922 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_49980.caffemodel
I0525 12:09:20.857067 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_49980.solverstate
I0525 12:09:21.646685 22426 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 12:10:08.428058 22426 solver.cpp:409]     Test net output #0: accuracy = 0.892115
I0525 12:10:08.428249 22426 solver.cpp:409]     Test net output #1: loss = 0.336387 (* 1 = 0.336387 loss)
I0525 12:10:36.615968 22426 solver.cpp:237] Iteration 50132, loss = 0.989555
I0525 12:10:36.616019 22426 solver.cpp:253]     Train net output #0: loss = 0.989555 (* 1 = 0.989555 loss)
I0525 12:10:36.616036 22426 sgd_solver.cpp:106] Iteration 50132, lr = 0.0045
I0525 12:10:45.450738 22426 solver.cpp:237] Iteration 50298, loss = 1.26716
I0525 12:10:45.450914 22426 solver.cpp:253]     Train net output #0: loss = 1.26716 (* 1 = 1.26716 loss)
I0525 12:10:45.450929 22426 sgd_solver.cpp:106] Iteration 50298, lr = 0.0045
I0525 12:10:54.293062 22426 solver.cpp:237] Iteration 50464, loss = 1.20445
I0525 12:10:54.293097 22426 solver.cpp:253]     Train net output #0: loss = 1.20445 (* 1 = 1.20445 loss)
I0525 12:10:54.293110 22426 sgd_solver.cpp:106] Iteration 50464, lr = 0.0045
I0525 12:11:03.134268 22426 solver.cpp:237] Iteration 50630, loss = 1.06848
I0525 12:11:03.134304 22426 solver.cpp:253]     Train net output #0: loss = 1.06848 (* 1 = 1.06848 loss)
I0525 12:11:03.134320 22426 sgd_solver.cpp:106] Iteration 50630, lr = 0.0045
I0525 12:11:11.966150 22426 solver.cpp:237] Iteration 50796, loss = 1.36202
I0525 12:11:11.966188 22426 solver.cpp:253]     Train net output #0: loss = 1.36202 (* 1 = 1.36202 loss)
I0525 12:11:11.966209 22426 sgd_solver.cpp:106] Iteration 50796, lr = 0.0045
I0525 12:11:20.804124 22426 solver.cpp:237] Iteration 50962, loss = 1.27488
I0525 12:11:20.804286 22426 solver.cpp:253]     Train net output #0: loss = 1.27488 (* 1 = 1.27488 loss)
I0525 12:11:20.804299 22426 sgd_solver.cpp:106] Iteration 50962, lr = 0.0045
I0525 12:11:50.513373 22426 solver.cpp:237] Iteration 51128, loss = 1.04968
I0525 12:11:50.513424 22426 solver.cpp:253]     Train net output #0: loss = 1.04968 (* 1 = 1.04968 loss)
I0525 12:11:50.513439 22426 sgd_solver.cpp:106] Iteration 51128, lr = 0.0045
I0525 12:11:59.352139 22426 solver.cpp:237] Iteration 51294, loss = 1.1478
I0525 12:11:59.352308 22426 solver.cpp:253]     Train net output #0: loss = 1.1478 (* 1 = 1.1478 loss)
I0525 12:11:59.352322 22426 sgd_solver.cpp:106] Iteration 51294, lr = 0.0045
I0525 12:12:08.197408 22426 solver.cpp:237] Iteration 51460, loss = 0.963203
I0525 12:12:08.197453 22426 solver.cpp:253]     Train net output #0: loss = 0.963203 (* 1 = 0.963203 loss)
I0525 12:12:08.197468 22426 sgd_solver.cpp:106] Iteration 51460, lr = 0.0045
I0525 12:12:17.036690 22426 solver.cpp:237] Iteration 51626, loss = 0.92127
I0525 12:12:17.036726 22426 solver.cpp:253]     Train net output #0: loss = 0.92127 (* 1 = 0.92127 loss)
I0525 12:12:17.036742 22426 sgd_solver.cpp:106] Iteration 51626, lr = 0.0045
I0525 12:12:18.048980 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_51646.caffemodel
I0525 12:12:18.123739 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_51646.solverstate
I0525 12:12:25.946094 22426 solver.cpp:237] Iteration 51792, loss = 1.06733
I0525 12:12:25.946142 22426 solver.cpp:253]     Train net output #0: loss = 1.06733 (* 1 = 1.06733 loss)
I0525 12:12:25.946159 22426 sgd_solver.cpp:106] Iteration 51792, lr = 0.0045
I0525 12:12:34.793551 22426 solver.cpp:237] Iteration 51958, loss = 1.23288
I0525 12:12:34.793728 22426 solver.cpp:253]     Train net output #0: loss = 1.23288 (* 1 = 1.23288 loss)
I0525 12:12:34.793742 22426 sgd_solver.cpp:106] Iteration 51958, lr = 0.0045
I0525 12:12:43.630314 22426 solver.cpp:237] Iteration 52124, loss = 1.11297
I0525 12:12:43.630348 22426 solver.cpp:253]     Train net output #0: loss = 1.11297 (* 1 = 1.11297 loss)
I0525 12:12:43.630365 22426 sgd_solver.cpp:106] Iteration 52124, lr = 0.0045
I0525 12:13:13.386489 22426 solver.cpp:237] Iteration 52290, loss = 1.16101
I0525 12:13:13.386677 22426 solver.cpp:253]     Train net output #0: loss = 1.16101 (* 1 = 1.16101 loss)
I0525 12:13:13.386694 22426 sgd_solver.cpp:106] Iteration 52290, lr = 0.0045
I0525 12:13:22.231845 22426 solver.cpp:237] Iteration 52456, loss = 1.18284
I0525 12:13:22.231895 22426 solver.cpp:253]     Train net output #0: loss = 1.18284 (* 1 = 1.18284 loss)
I0525 12:13:22.231909 22426 sgd_solver.cpp:106] Iteration 52456, lr = 0.0045
I0525 12:13:31.064832 22426 solver.cpp:237] Iteration 52622, loss = 1.0336
I0525 12:13:31.064867 22426 solver.cpp:253]     Train net output #0: loss = 1.0336 (* 1 = 1.0336 loss)
I0525 12:13:31.064884 22426 sgd_solver.cpp:106] Iteration 52622, lr = 0.0045
I0525 12:13:39.906793 22426 solver.cpp:237] Iteration 52788, loss = 1.07911
I0525 12:13:39.906838 22426 solver.cpp:253]     Train net output #0: loss = 1.07911 (* 1 = 1.07911 loss)
I0525 12:13:39.906853 22426 sgd_solver.cpp:106] Iteration 52788, lr = 0.0045
I0525 12:13:48.751056 22426 solver.cpp:237] Iteration 52954, loss = 1.03557
I0525 12:13:48.751224 22426 solver.cpp:253]     Train net output #0: loss = 1.03557 (* 1 = 1.03557 loss)
I0525 12:13:48.751240 22426 sgd_solver.cpp:106] Iteration 52954, lr = 0.0045
I0525 12:13:57.602027 22426 solver.cpp:237] Iteration 53120, loss = 1.08796
I0525 12:13:57.602062 22426 solver.cpp:253]     Train net output #0: loss = 1.08796 (* 1 = 1.08796 loss)
I0525 12:13:57.602079 22426 sgd_solver.cpp:106] Iteration 53120, lr = 0.0045
I0525 12:14:06.442852 22426 solver.cpp:237] Iteration 53286, loss = 1.20459
I0525 12:14:06.442890 22426 solver.cpp:253]     Train net output #0: loss = 1.20459 (* 1 = 1.20459 loss)
I0525 12:14:06.442910 22426 sgd_solver.cpp:106] Iteration 53286, lr = 0.0045
I0525 12:14:07.778820 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_53312.caffemodel
I0525 12:14:07.853986 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_53312.solverstate
I0525 12:14:08.697973 22426 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 12:15:16.741734 22426 solver.cpp:409]     Test net output #0: accuracy = 0.894596
I0525 12:15:16.741921 22426 solver.cpp:409]     Test net output #1: loss = 0.351366 (* 1 = 0.351366 loss)
I0525 12:15:44.189930 22426 solver.cpp:237] Iteration 53452, loss = 1.25328
I0525 12:15:44.189980 22426 solver.cpp:253]     Train net output #0: loss = 1.25328 (* 1 = 1.25328 loss)
I0525 12:15:44.189996 22426 sgd_solver.cpp:106] Iteration 53452, lr = 0.0045
I0525 12:15:53.029988 22426 solver.cpp:237] Iteration 53618, loss = 1.1082
I0525 12:15:53.030159 22426 solver.cpp:253]     Train net output #0: loss = 1.1082 (* 1 = 1.1082 loss)
I0525 12:15:53.030174 22426 sgd_solver.cpp:106] Iteration 53618, lr = 0.0045
I0525 12:16:01.875579 22426 solver.cpp:237] Iteration 53784, loss = 1.01429
I0525 12:16:01.875615 22426 solver.cpp:253]     Train net output #0: loss = 1.01429 (* 1 = 1.01429 loss)
I0525 12:16:01.875632 22426 sgd_solver.cpp:106] Iteration 53784, lr = 0.0045
I0525 12:16:10.713836 22426 solver.cpp:237] Iteration 53950, loss = 1.06105
I0525 12:16:10.713877 22426 solver.cpp:253]     Train net output #0: loss = 1.06105 (* 1 = 1.06105 loss)
I0525 12:16:10.713894 22426 sgd_solver.cpp:106] Iteration 53950, lr = 0.0045
I0525 12:16:19.553148 22426 solver.cpp:237] Iteration 54116, loss = 0.996665
I0525 12:16:19.553184 22426 solver.cpp:253]     Train net output #0: loss = 0.996665 (* 1 = 0.996665 loss)
I0525 12:16:19.553200 22426 sgd_solver.cpp:106] Iteration 54116, lr = 0.0045
I0525 12:16:28.389875 22426 solver.cpp:237] Iteration 54282, loss = 1.0084
I0525 12:16:28.390050 22426 solver.cpp:253]     Train net output #0: loss = 1.0084 (* 1 = 1.0084 loss)
I0525 12:16:28.390064 22426 sgd_solver.cpp:106] Iteration 54282, lr = 0.0045
I0525 12:16:58.091672 22426 solver.cpp:237] Iteration 54448, loss = 0.915931
I0525 12:16:58.091724 22426 solver.cpp:253]     Train net output #0: loss = 0.915931 (* 1 = 0.915931 loss)
I0525 12:16:58.091738 22426 sgd_solver.cpp:106] Iteration 54448, lr = 0.0045
I0525 12:17:06.936517 22426 solver.cpp:237] Iteration 54614, loss = 1.08322
I0525 12:17:06.936697 22426 solver.cpp:253]     Train net output #0: loss = 1.08322 (* 1 = 1.08322 loss)
I0525 12:17:06.936712 22426 sgd_solver.cpp:106] Iteration 54614, lr = 0.0045
I0525 12:17:15.785002 22426 solver.cpp:237] Iteration 54780, loss = 1.13437
I0525 12:17:15.785037 22426 solver.cpp:253]     Train net output #0: loss = 1.13437 (* 1 = 1.13437 loss)
I0525 12:17:15.785053 22426 sgd_solver.cpp:106] Iteration 54780, lr = 0.0045
I0525 12:17:24.622872 22426 solver.cpp:237] Iteration 54946, loss = 1.07304
I0525 12:17:24.622913 22426 solver.cpp:253]     Train net output #0: loss = 1.07304 (* 1 = 1.07304 loss)
I0525 12:17:24.622927 22426 sgd_solver.cpp:106] Iteration 54946, lr = 0.0045
I0525 12:17:26.270877 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_54978.caffemodel
I0525 12:17:26.345114 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_54978.solverstate
I0525 12:17:33.527091 22426 solver.cpp:237] Iteration 55112, loss = 1.15718
I0525 12:17:33.527137 22426 solver.cpp:253]     Train net output #0: loss = 1.15718 (* 1 = 1.15718 loss)
I0525 12:17:33.527154 22426 sgd_solver.cpp:106] Iteration 55112, lr = 0.0045
I0525 12:17:42.357486 22426 solver.cpp:237] Iteration 55278, loss = 1.14091
I0525 12:17:42.357656 22426 solver.cpp:253]     Train net output #0: loss = 1.14091 (* 1 = 1.14091 loss)
I0525 12:17:42.357671 22426 sgd_solver.cpp:106] Iteration 55278, lr = 0.0045
I0525 12:17:51.209825 22426 solver.cpp:237] Iteration 55444, loss = 1.16255
I0525 12:17:51.209869 22426 solver.cpp:253]     Train net output #0: loss = 1.16255 (* 1 = 1.16255 loss)
I0525 12:17:51.209887 22426 sgd_solver.cpp:106] Iteration 55444, lr = 0.0045
I0525 12:18:20.932473 22426 solver.cpp:237] Iteration 55610, loss = 1.24027
I0525 12:18:20.932658 22426 solver.cpp:253]     Train net output #0: loss = 1.24027 (* 1 = 1.24027 loss)
I0525 12:18:20.932673 22426 sgd_solver.cpp:106] Iteration 55610, lr = 0.0045
I0525 12:18:29.775908 22426 solver.cpp:237] Iteration 55776, loss = 1.17323
I0525 12:18:29.775943 22426 solver.cpp:253]     Train net output #0: loss = 1.17323 (* 1 = 1.17323 loss)
I0525 12:18:29.775959 22426 sgd_solver.cpp:106] Iteration 55776, lr = 0.0045
I0525 12:18:38.614621 22426 solver.cpp:237] Iteration 55942, loss = 1.01446
I0525 12:18:38.614656 22426 solver.cpp:253]     Train net output #0: loss = 1.01446 (* 1 = 1.01446 loss)
I0525 12:18:38.614675 22426 sgd_solver.cpp:106] Iteration 55942, lr = 0.0045
I0525 12:18:47.458729 22426 solver.cpp:237] Iteration 56108, loss = 1.20292
I0525 12:18:47.458765 22426 solver.cpp:253]     Train net output #0: loss = 1.20292 (* 1 = 1.20292 loss)
I0525 12:18:47.458786 22426 sgd_solver.cpp:106] Iteration 56108, lr = 0.0045
I0525 12:18:56.297222 22426 solver.cpp:237] Iteration 56274, loss = 1.24198
I0525 12:18:56.297385 22426 solver.cpp:253]     Train net output #0: loss = 1.24198 (* 1 = 1.24198 loss)
I0525 12:18:56.297399 22426 sgd_solver.cpp:106] Iteration 56274, lr = 0.0045
I0525 12:19:05.141305 22426 solver.cpp:237] Iteration 56440, loss = 1.11431
I0525 12:19:05.141347 22426 solver.cpp:253]     Train net output #0: loss = 1.11431 (* 1 = 1.11431 loss)
I0525 12:19:05.141368 22426 sgd_solver.cpp:106] Iteration 56440, lr = 0.0045
I0525 12:19:13.980469 22426 solver.cpp:237] Iteration 56606, loss = 1.2925
I0525 12:19:13.980504 22426 solver.cpp:253]     Train net output #0: loss = 1.2925 (* 1 = 1.2925 loss)
I0525 12:19:13.980520 22426 sgd_solver.cpp:106] Iteration 56606, lr = 0.0045
I0525 12:19:15.952651 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_56644.caffemodel
I0525 12:19:16.028745 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_56644.solverstate
I0525 12:19:16.927037 22426 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 12:20:04.080135 22426 solver.cpp:409]     Test net output #0: accuracy = 0.895589
I0525 12:20:04.080329 22426 solver.cpp:409]     Test net output #1: loss = 0.341737 (* 1 = 0.341737 loss)
I0525 12:20:30.851357 22426 solver.cpp:237] Iteration 56772, loss = 1.31381
I0525 12:20:30.851407 22426 solver.cpp:253]     Train net output #0: loss = 1.31381 (* 1 = 1.31381 loss)
I0525 12:20:30.851423 22426 sgd_solver.cpp:106] Iteration 56772, lr = 0.0045
I0525 12:20:39.693138 22426 solver.cpp:237] Iteration 56938, loss = 1.28927
I0525 12:20:39.693308 22426 solver.cpp:253]     Train net output #0: loss = 1.28927 (* 1 = 1.28927 loss)
I0525 12:20:39.693321 22426 sgd_solver.cpp:106] Iteration 56938, lr = 0.0045
I0525 12:20:48.547857 22426 solver.cpp:237] Iteration 57104, loss = 1.06108
I0525 12:20:48.547904 22426 solver.cpp:253]     Train net output #0: loss = 1.06108 (* 1 = 1.06108 loss)
I0525 12:20:48.547919 22426 sgd_solver.cpp:106] Iteration 57104, lr = 0.0045
I0525 12:20:57.394990 22426 solver.cpp:237] Iteration 57270, loss = 0.97816
I0525 12:20:57.395026 22426 solver.cpp:253]     Train net output #0: loss = 0.97816 (* 1 = 0.97816 loss)
I0525 12:20:57.395042 22426 sgd_solver.cpp:106] Iteration 57270, lr = 0.0045
I0525 12:21:06.238737 22426 solver.cpp:237] Iteration 57436, loss = 1.06556
I0525 12:21:06.238772 22426 solver.cpp:253]     Train net output #0: loss = 1.06556 (* 1 = 1.06556 loss)
I0525 12:21:06.238785 22426 sgd_solver.cpp:106] Iteration 57436, lr = 0.0045
I0525 12:21:15.085031 22426 solver.cpp:237] Iteration 57602, loss = 1.38651
I0525 12:21:15.085216 22426 solver.cpp:253]     Train net output #0: loss = 1.38651 (* 1 = 1.38651 loss)
I0525 12:21:15.085230 22426 sgd_solver.cpp:106] Iteration 57602, lr = 0.0045
I0525 12:21:23.936980 22426 solver.cpp:237] Iteration 57768, loss = 1.04121
I0525 12:21:23.937014 22426 solver.cpp:253]     Train net output #0: loss = 1.04121 (* 1 = 1.04121 loss)
I0525 12:21:23.937031 22426 sgd_solver.cpp:106] Iteration 57768, lr = 0.0045
I0525 12:21:53.634913 22426 solver.cpp:237] Iteration 57934, loss = 1.03985
I0525 12:21:53.635102 22426 solver.cpp:253]     Train net output #0: loss = 1.03985 (* 1 = 1.03985 loss)
I0525 12:21:53.635118 22426 sgd_solver.cpp:106] Iteration 57934, lr = 0.0045
I0525 12:22:02.492285 22426 solver.cpp:237] Iteration 58100, loss = 1.06473
I0525 12:22:02.492324 22426 solver.cpp:253]     Train net output #0: loss = 1.06473 (* 1 = 1.06473 loss)
I0525 12:22:02.492347 22426 sgd_solver.cpp:106] Iteration 58100, lr = 0.0045
I0525 12:22:11.339200 22426 solver.cpp:237] Iteration 58266, loss = 1.11035
I0525 12:22:11.339236 22426 solver.cpp:253]     Train net output #0: loss = 1.11035 (* 1 = 1.11035 loss)
I0525 12:22:11.339251 22426 sgd_solver.cpp:106] Iteration 58266, lr = 0.0045
I0525 12:22:13.630233 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_58310.caffemodel
I0525 12:22:13.707516 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_58310.solverstate
I0525 12:22:20.259999 22426 solver.cpp:237] Iteration 58432, loss = 1.12791
I0525 12:22:20.260047 22426 solver.cpp:253]     Train net output #0: loss = 1.12791 (* 1 = 1.12791 loss)
I0525 12:22:20.260062 22426 sgd_solver.cpp:106] Iteration 58432, lr = 0.0045
I0525 12:22:29.108005 22426 solver.cpp:237] Iteration 58598, loss = 1.1692
I0525 12:22:29.108203 22426 solver.cpp:253]     Train net output #0: loss = 1.1692 (* 1 = 1.1692 loss)
I0525 12:22:29.108217 22426 sgd_solver.cpp:106] Iteration 58598, lr = 0.0045
I0525 12:22:37.956194 22426 solver.cpp:237] Iteration 58764, loss = 1.13228
I0525 12:22:37.956228 22426 solver.cpp:253]     Train net output #0: loss = 1.13228 (* 1 = 1.13228 loss)
I0525 12:22:37.956241 22426 sgd_solver.cpp:106] Iteration 58764, lr = 0.0045
I0525 12:23:07.650118 22426 solver.cpp:237] Iteration 58930, loss = 1.07957
I0525 12:23:07.650308 22426 solver.cpp:253]     Train net output #0: loss = 1.07957 (* 1 = 1.07957 loss)
I0525 12:23:07.650323 22426 sgd_solver.cpp:106] Iteration 58930, lr = 0.0045
I0525 12:23:16.499119 22426 solver.cpp:237] Iteration 59096, loss = 1.22882
I0525 12:23:16.499166 22426 solver.cpp:253]     Train net output #0: loss = 1.22882 (* 1 = 1.22882 loss)
I0525 12:23:16.499178 22426 sgd_solver.cpp:106] Iteration 59096, lr = 0.0045
I0525 12:23:25.345995 22426 solver.cpp:237] Iteration 59262, loss = 1.48421
I0525 12:23:25.346031 22426 solver.cpp:253]     Train net output #0: loss = 1.48421 (* 1 = 1.48421 loss)
I0525 12:23:25.346046 22426 sgd_solver.cpp:106] Iteration 59262, lr = 0.0045
I0525 12:23:34.199908 22426 solver.cpp:237] Iteration 59428, loss = 1.14002
I0525 12:23:34.199944 22426 solver.cpp:253]     Train net output #0: loss = 1.14002 (* 1 = 1.14002 loss)
I0525 12:23:34.199959 22426 sgd_solver.cpp:106] Iteration 59428, lr = 0.0045
I0525 12:23:43.046525 22426 solver.cpp:237] Iteration 59594, loss = 1.12222
I0525 12:23:43.046700 22426 solver.cpp:253]     Train net output #0: loss = 1.12222 (* 1 = 1.12222 loss)
I0525 12:23:43.046715 22426 sgd_solver.cpp:106] Iteration 59594, lr = 0.0045
I0525 12:23:51.891026 22426 solver.cpp:237] Iteration 59760, loss = 1.5503
I0525 12:23:51.891060 22426 solver.cpp:253]     Train net output #0: loss = 1.5503 (* 1 = 1.5503 loss)
I0525 12:23:51.891077 22426 sgd_solver.cpp:106] Iteration 59760, lr = 0.0045
I0525 12:24:00.735451 22426 solver.cpp:237] Iteration 59926, loss = 1.40087
I0525 12:24:00.735487 22426 solver.cpp:253]     Train net output #0: loss = 1.40087 (* 1 = 1.40087 loss)
I0525 12:24:00.735503 22426 sgd_solver.cpp:106] Iteration 59926, lr = 0.0045
I0525 12:24:03.352480 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_59976.caffemodel
I0525 12:24:03.428442 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_59976.solverstate
I0525 12:24:04.385285 22426 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 12:25:12.394521 22426 solver.cpp:409]     Test net output #0: accuracy = 0.897124
I0525 12:25:12.394721 22426 solver.cpp:409]     Test net output #1: loss = 0.337129 (* 1 = 0.337129 loss)
I0525 12:25:38.479092 22426 solver.cpp:237] Iteration 60092, loss = 1.02674
I0525 12:25:38.479142 22426 solver.cpp:253]     Train net output #0: loss = 1.02674 (* 1 = 1.02674 loss)
I0525 12:25:38.479156 22426 sgd_solver.cpp:106] Iteration 60092, lr = 0.0045
I0525 12:25:47.329468 22426 solver.cpp:237] Iteration 60258, loss = 1.09526
I0525 12:25:47.329653 22426 solver.cpp:253]     Train net output #0: loss = 1.09526 (* 1 = 1.09526 loss)
I0525 12:25:47.329668 22426 sgd_solver.cpp:106] Iteration 60258, lr = 0.0045
I0525 12:25:56.188694 22426 solver.cpp:237] Iteration 60424, loss = 1.24097
I0525 12:25:56.188727 22426 solver.cpp:253]     Train net output #0: loss = 1.24097 (* 1 = 1.24097 loss)
I0525 12:25:56.188745 22426 sgd_solver.cpp:106] Iteration 60424, lr = 0.0045
I0525 12:26:05.039753 22426 solver.cpp:237] Iteration 60590, loss = 1.09454
I0525 12:26:05.039789 22426 solver.cpp:253]     Train net output #0: loss = 1.09454 (* 1 = 1.09454 loss)
I0525 12:26:05.039805 22426 sgd_solver.cpp:106] Iteration 60590, lr = 0.0045
I0525 12:26:13.893406 22426 solver.cpp:237] Iteration 60756, loss = 1.0325
I0525 12:26:13.893440 22426 solver.cpp:253]     Train net output #0: loss = 1.0325 (* 1 = 1.0325 loss)
I0525 12:26:13.893462 22426 sgd_solver.cpp:106] Iteration 60756, lr = 0.0045
I0525 12:26:22.743497 22426 solver.cpp:237] Iteration 60922, loss = 1.16397
I0525 12:26:22.743675 22426 solver.cpp:253]     Train net output #0: loss = 1.16397 (* 1 = 1.16397 loss)
I0525 12:26:22.743690 22426 sgd_solver.cpp:106] Iteration 60922, lr = 0.0045
I0525 12:26:31.588157 22426 solver.cpp:237] Iteration 61088, loss = 1.10877
I0525 12:26:31.588192 22426 solver.cpp:253]     Train net output #0: loss = 1.10877 (* 1 = 1.10877 loss)
I0525 12:26:31.588207 22426 sgd_solver.cpp:106] Iteration 61088, lr = 0.0045
I0525 12:27:01.289228 22426 solver.cpp:237] Iteration 61254, loss = 1.03542
I0525 12:27:01.289417 22426 solver.cpp:253]     Train net output #0: loss = 1.03542 (* 1 = 1.03542 loss)
I0525 12:27:01.289430 22426 sgd_solver.cpp:106] Iteration 61254, lr = 0.0045
I0525 12:27:10.147806 22426 solver.cpp:237] Iteration 61420, loss = 1.18905
I0525 12:27:10.147841 22426 solver.cpp:253]     Train net output #0: loss = 1.18905 (* 1 = 1.18905 loss)
I0525 12:27:10.147857 22426 sgd_solver.cpp:106] Iteration 61420, lr = 0.0045
I0525 12:27:18.999589 22426 solver.cpp:237] Iteration 61586, loss = 1.16391
I0525 12:27:18.999624 22426 solver.cpp:253]     Train net output #0: loss = 1.16391 (* 1 = 1.16391 loss)
I0525 12:27:18.999639 22426 sgd_solver.cpp:106] Iteration 61586, lr = 0.0045
I0525 12:27:21.930884 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_61642.caffemodel
I0525 12:27:22.005344 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_61642.solverstate
I0525 12:27:27.909891 22426 solver.cpp:237] Iteration 61752, loss = 1.24144
I0525 12:27:27.909940 22426 solver.cpp:253]     Train net output #0: loss = 1.24144 (* 1 = 1.24144 loss)
I0525 12:27:27.909957 22426 sgd_solver.cpp:106] Iteration 61752, lr = 0.0045
I0525 12:27:36.763840 22426 solver.cpp:237] Iteration 61918, loss = 1.12531
I0525 12:27:36.764014 22426 solver.cpp:253]     Train net output #0: loss = 1.12531 (* 1 = 1.12531 loss)
I0525 12:27:36.764027 22426 sgd_solver.cpp:106] Iteration 61918, lr = 0.0045
I0525 12:27:45.615057 22426 solver.cpp:237] Iteration 62084, loss = 1.08824
I0525 12:27:45.615092 22426 solver.cpp:253]     Train net output #0: loss = 1.08824 (* 1 = 1.08824 loss)
I0525 12:27:45.615111 22426 sgd_solver.cpp:106] Iteration 62084, lr = 0.0045
I0525 12:28:15.307060 22426 solver.cpp:237] Iteration 62250, loss = 1.12885
I0525 12:28:15.307250 22426 solver.cpp:253]     Train net output #0: loss = 1.12885 (* 1 = 1.12885 loss)
I0525 12:28:15.307263 22426 sgd_solver.cpp:106] Iteration 62250, lr = 0.0045
I0525 12:28:24.159847 22426 solver.cpp:237] Iteration 62416, loss = 1.01251
I0525 12:28:24.159881 22426 solver.cpp:253]     Train net output #0: loss = 1.01251 (* 1 = 1.01251 loss)
I0525 12:28:24.159900 22426 sgd_solver.cpp:106] Iteration 62416, lr = 0.0045
I0525 12:28:33.009263 22426 solver.cpp:237] Iteration 62582, loss = 1.01848
I0525 12:28:33.009299 22426 solver.cpp:253]     Train net output #0: loss = 1.01848 (* 1 = 1.01848 loss)
I0525 12:28:33.009315 22426 sgd_solver.cpp:106] Iteration 62582, lr = 0.0045
I0525 12:28:41.865414 22426 solver.cpp:237] Iteration 62748, loss = 1.02229
I0525 12:28:41.865458 22426 solver.cpp:253]     Train net output #0: loss = 1.02229 (* 1 = 1.02229 loss)
I0525 12:28:41.865478 22426 sgd_solver.cpp:106] Iteration 62748, lr = 0.0045
I0525 12:28:50.720410 22426 solver.cpp:237] Iteration 62914, loss = 1.26841
I0525 12:28:50.720588 22426 solver.cpp:253]     Train net output #0: loss = 1.26841 (* 1 = 1.26841 loss)
I0525 12:28:50.720602 22426 sgd_solver.cpp:106] Iteration 62914, lr = 0.0045
I0525 12:28:59.565521 22426 solver.cpp:237] Iteration 63080, loss = 1.29815
I0525 12:28:59.565554 22426 solver.cpp:253]     Train net output #0: loss = 1.29815 (* 1 = 1.29815 loss)
I0525 12:28:59.565572 22426 sgd_solver.cpp:106] Iteration 63080, lr = 0.0045
I0525 12:29:08.408978 22426 solver.cpp:237] Iteration 63246, loss = 1.17291
I0525 12:29:08.409018 22426 solver.cpp:253]     Train net output #0: loss = 1.17291 (* 1 = 1.17291 loss)
I0525 12:29:08.409037 22426 sgd_solver.cpp:106] Iteration 63246, lr = 0.0045
I0525 12:29:11.651767 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_63308.caffemodel
I0525 12:29:11.726462 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_63308.solverstate
I0525 12:29:12.727776 22426 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 12:29:59.549473 22426 solver.cpp:409]     Test net output #0: accuracy = 0.89681
I0525 12:29:59.549674 22426 solver.cpp:409]     Test net output #1: loss = 0.348429 (* 1 = 0.348429 loss)
I0525 12:30:24.922725 22426 solver.cpp:237] Iteration 63412, loss = 1.13506
I0525 12:30:24.922775 22426 solver.cpp:253]     Train net output #0: loss = 1.13506 (* 1 = 1.13506 loss)
I0525 12:30:24.922788 22426 sgd_solver.cpp:106] Iteration 63412, lr = 0.0045
I0525 12:30:33.766389 22426 solver.cpp:237] Iteration 63578, loss = 1.1709
I0525 12:30:33.766563 22426 solver.cpp:253]     Train net output #0: loss = 1.1709 (* 1 = 1.1709 loss)
I0525 12:30:33.766577 22426 sgd_solver.cpp:106] Iteration 63578, lr = 0.0045
I0525 12:30:42.614542 22426 solver.cpp:237] Iteration 63744, loss = 1.01589
I0525 12:30:42.614578 22426 solver.cpp:253]     Train net output #0: loss = 1.01589 (* 1 = 1.01589 loss)
I0525 12:30:42.614594 22426 sgd_solver.cpp:106] Iteration 63744, lr = 0.0045
I0525 12:30:51.456470 22426 solver.cpp:237] Iteration 63910, loss = 1.15328
I0525 12:30:51.456516 22426 solver.cpp:253]     Train net output #0: loss = 1.15328 (* 1 = 1.15328 loss)
I0525 12:30:51.456532 22426 sgd_solver.cpp:106] Iteration 63910, lr = 0.0045
I0525 12:31:00.306769 22426 solver.cpp:237] Iteration 64076, loss = 1.06441
I0525 12:31:00.306805 22426 solver.cpp:253]     Train net output #0: loss = 1.06441 (* 1 = 1.06441 loss)
I0525 12:31:00.306820 22426 sgd_solver.cpp:106] Iteration 64076, lr = 0.0045
I0525 12:31:09.145396 22426 solver.cpp:237] Iteration 64242, loss = 1.22893
I0525 12:31:09.145570 22426 solver.cpp:253]     Train net output #0: loss = 1.22893 (* 1 = 1.22893 loss)
I0525 12:31:09.145582 22426 sgd_solver.cpp:106] Iteration 64242, lr = 0.0045
I0525 12:31:17.993784 22426 solver.cpp:237] Iteration 64408, loss = 1.2355
I0525 12:31:17.993829 22426 solver.cpp:253]     Train net output #0: loss = 1.2355 (* 1 = 1.2355 loss)
I0525 12:31:17.993845 22426 sgd_solver.cpp:106] Iteration 64408, lr = 0.0045
I0525 12:31:47.686846 22426 solver.cpp:237] Iteration 64574, loss = 1.19991
I0525 12:31:47.687036 22426 solver.cpp:253]     Train net output #0: loss = 1.19991 (* 1 = 1.19991 loss)
I0525 12:31:47.687050 22426 sgd_solver.cpp:106] Iteration 64574, lr = 0.0045
I0525 12:31:56.533774 22426 solver.cpp:237] Iteration 64740, loss = 1.27629
I0525 12:31:56.533809 22426 solver.cpp:253]     Train net output #0: loss = 1.27629 (* 1 = 1.27629 loss)
I0525 12:31:56.533826 22426 sgd_solver.cpp:106] Iteration 64740, lr = 0.0045
I0525 12:32:05.381737 22426 solver.cpp:237] Iteration 64906, loss = 1.27499
I0525 12:32:05.381783 22426 solver.cpp:253]     Train net output #0: loss = 1.27499 (* 1 = 1.27499 loss)
I0525 12:32:05.381798 22426 sgd_solver.cpp:106] Iteration 64906, lr = 0.0045
I0525 12:32:08.957473 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_64974.caffemodel
I0525 12:32:09.033246 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_64974.solverstate
I0525 12:32:14.301141 22426 solver.cpp:237] Iteration 65072, loss = 1.21445
I0525 12:32:14.301189 22426 solver.cpp:253]     Train net output #0: loss = 1.21445 (* 1 = 1.21445 loss)
I0525 12:32:14.301205 22426 sgd_solver.cpp:106] Iteration 65072, lr = 0.0045
I0525 12:32:23.147047 22426 solver.cpp:237] Iteration 65238, loss = 1.34588
I0525 12:32:23.147233 22426 solver.cpp:253]     Train net output #0: loss = 1.34588 (* 1 = 1.34588 loss)
I0525 12:32:23.147246 22426 sgd_solver.cpp:106] Iteration 65238, lr = 0.0045
I0525 12:32:31.991061 22426 solver.cpp:237] Iteration 65404, loss = 1.14135
I0525 12:32:31.991109 22426 solver.cpp:253]     Train net output #0: loss = 1.14135 (* 1 = 1.14135 loss)
I0525 12:32:31.991125 22426 sgd_solver.cpp:106] Iteration 65404, lr = 0.0045
I0525 12:33:01.691453 22426 solver.cpp:237] Iteration 65570, loss = 1.15038
I0525 12:33:01.691647 22426 solver.cpp:253]     Train net output #0: loss = 1.15038 (* 1 = 1.15038 loss)
I0525 12:33:01.691661 22426 sgd_solver.cpp:106] Iteration 65570, lr = 0.0045
I0525 12:33:10.530725 22426 solver.cpp:237] Iteration 65736, loss = 1.21125
I0525 12:33:10.530760 22426 solver.cpp:253]     Train net output #0: loss = 1.21125 (* 1 = 1.21125 loss)
I0525 12:33:10.530777 22426 sgd_solver.cpp:106] Iteration 65736, lr = 0.0045
I0525 12:33:19.382494 22426 solver.cpp:237] Iteration 65902, loss = 1.1874
I0525 12:33:19.382545 22426 solver.cpp:253]     Train net output #0: loss = 1.1874 (* 1 = 1.1874 loss)
I0525 12:33:19.382558 22426 sgd_solver.cpp:106] Iteration 65902, lr = 0.0045
I0525 12:33:28.223029 22426 solver.cpp:237] Iteration 66068, loss = 1.33403
I0525 12:33:28.223065 22426 solver.cpp:253]     Train net output #0: loss = 1.33403 (* 1 = 1.33403 loss)
I0525 12:33:28.223081 22426 sgd_solver.cpp:106] Iteration 66068, lr = 0.0045
I0525 12:33:37.078578 22426 solver.cpp:237] Iteration 66234, loss = 1.1457
I0525 12:33:37.078750 22426 solver.cpp:253]     Train net output #0: loss = 1.1457 (* 1 = 1.1457 loss)
I0525 12:33:37.078764 22426 sgd_solver.cpp:106] Iteration 66234, lr = 0.0045
I0525 12:33:45.933486 22426 solver.cpp:237] Iteration 66400, loss = 1.15196
I0525 12:33:45.933529 22426 solver.cpp:253]     Train net output #0: loss = 1.15196 (* 1 = 1.15196 loss)
I0525 12:33:45.933549 22426 sgd_solver.cpp:106] Iteration 66400, lr = 0.0045
I0525 12:33:54.781925 22426 solver.cpp:237] Iteration 66566, loss = 1.17725
I0525 12:33:54.781960 22426 solver.cpp:253]     Train net output #0: loss = 1.17725 (* 1 = 1.17725 loss)
I0525 12:33:54.781973 22426 sgd_solver.cpp:106] Iteration 66566, lr = 0.0045
I0525 12:33:58.677954 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_66640.caffemodel
I0525 12:33:58.754741 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_66640.solverstate
I0525 12:33:59.810519 22426 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 12:35:07.850046 22426 solver.cpp:409]     Test net output #0: accuracy = 0.89563
I0525 12:35:07.850236 22426 solver.cpp:409]     Test net output #1: loss = 0.356675 (* 1 = 0.356675 loss)
I0525 12:35:32.597626 22426 solver.cpp:237] Iteration 66732, loss = 1.23553
I0525 12:35:32.597677 22426 solver.cpp:253]     Train net output #0: loss = 1.23553 (* 1 = 1.23553 loss)
I0525 12:35:32.597692 22426 sgd_solver.cpp:106] Iteration 66732, lr = 0.0045
I0525 12:35:41.447696 22426 solver.cpp:237] Iteration 66898, loss = 1.08489
I0525 12:35:41.447881 22426 solver.cpp:253]     Train net output #0: loss = 1.08489 (* 1 = 1.08489 loss)
I0525 12:35:41.447896 22426 sgd_solver.cpp:106] Iteration 66898, lr = 0.0045
I0525 12:35:50.294314 22426 solver.cpp:237] Iteration 67064, loss = 0.974857
I0525 12:35:50.294353 22426 solver.cpp:253]     Train net output #0: loss = 0.974857 (* 1 = 0.974857 loss)
I0525 12:35:50.294373 22426 sgd_solver.cpp:106] Iteration 67064, lr = 0.0045
I0525 12:35:59.148789 22426 solver.cpp:237] Iteration 67230, loss = 1.05925
I0525 12:35:59.148824 22426 solver.cpp:253]     Train net output #0: loss = 1.05925 (* 1 = 1.05925 loss)
I0525 12:35:59.148840 22426 sgd_solver.cpp:106] Iteration 67230, lr = 0.0045
I0525 12:36:07.991384 22426 solver.cpp:237] Iteration 67396, loss = 1.23345
I0525 12:36:07.991420 22426 solver.cpp:253]     Train net output #0: loss = 1.23345 (* 1 = 1.23345 loss)
I0525 12:36:07.991437 22426 sgd_solver.cpp:106] Iteration 67396, lr = 0.0045
I0525 12:36:16.850153 22426 solver.cpp:237] Iteration 67562, loss = 1.26639
I0525 12:36:16.850338 22426 solver.cpp:253]     Train net output #0: loss = 1.26639 (* 1 = 1.26639 loss)
I0525 12:36:16.850353 22426 sgd_solver.cpp:106] Iteration 67562, lr = 0.0045
I0525 12:36:25.701211 22426 solver.cpp:237] Iteration 67728, loss = 1.15455
I0525 12:36:25.701246 22426 solver.cpp:253]     Train net output #0: loss = 1.15455 (* 1 = 1.15455 loss)
I0525 12:36:25.701261 22426 sgd_solver.cpp:106] Iteration 67728, lr = 0.0045
I0525 12:36:55.405611 22426 solver.cpp:237] Iteration 67894, loss = 1.04176
I0525 12:36:55.405807 22426 solver.cpp:253]     Train net output #0: loss = 1.04176 (* 1 = 1.04176 loss)
I0525 12:36:55.405823 22426 sgd_solver.cpp:106] Iteration 67894, lr = 0.0045
I0525 12:37:04.252892 22426 solver.cpp:237] Iteration 68060, loss = 1.21369
I0525 12:37:04.252936 22426 solver.cpp:253]     Train net output #0: loss = 1.21369 (* 1 = 1.21369 loss)
I0525 12:37:04.252953 22426 sgd_solver.cpp:106] Iteration 68060, lr = 0.0045
I0525 12:37:13.098525 22426 solver.cpp:237] Iteration 68226, loss = 1.25191
I0525 12:37:13.098562 22426 solver.cpp:253]     Train net output #0: loss = 1.25191 (* 1 = 1.25191 loss)
I0525 12:37:13.098574 22426 sgd_solver.cpp:106] Iteration 68226, lr = 0.0045
I0525 12:37:17.309267 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_68306.caffemodel
I0525 12:37:17.383328 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_68306.solverstate
I0525 12:37:22.005892 22426 solver.cpp:237] Iteration 68392, loss = 1.46294
I0525 12:37:22.005935 22426 solver.cpp:253]     Train net output #0: loss = 1.46294 (* 1 = 1.46294 loss)
I0525 12:37:22.005950 22426 sgd_solver.cpp:106] Iteration 68392, lr = 0.0045
I0525 12:37:30.850343 22426 solver.cpp:237] Iteration 68558, loss = 1.09729
I0525 12:37:30.850529 22426 solver.cpp:253]     Train net output #0: loss = 1.09729 (* 1 = 1.09729 loss)
I0525 12:37:30.850543 22426 sgd_solver.cpp:106] Iteration 68558, lr = 0.0045
I0525 12:37:39.694113 22426 solver.cpp:237] Iteration 68724, loss = 1.09142
I0525 12:37:39.694149 22426 solver.cpp:253]     Train net output #0: loss = 1.09142 (* 1 = 1.09142 loss)
I0525 12:37:39.694167 22426 sgd_solver.cpp:106] Iteration 68724, lr = 0.0045
I0525 12:38:09.409996 22426 solver.cpp:237] Iteration 68890, loss = 1.16097
I0525 12:38:09.410194 22426 solver.cpp:253]     Train net output #0: loss = 1.16097 (* 1 = 1.16097 loss)
I0525 12:38:09.410210 22426 sgd_solver.cpp:106] Iteration 68890, lr = 0.0045
I0525 12:38:18.255344 22426 solver.cpp:237] Iteration 69056, loss = 1.193
I0525 12:38:18.255388 22426 solver.cpp:253]     Train net output #0: loss = 1.193 (* 1 = 1.193 loss)
I0525 12:38:18.255403 22426 sgd_solver.cpp:106] Iteration 69056, lr = 0.0045
I0525 12:38:27.098589 22426 solver.cpp:237] Iteration 69222, loss = 1.14477
I0525 12:38:27.098624 22426 solver.cpp:253]     Train net output #0: loss = 1.14477 (* 1 = 1.14477 loss)
I0525 12:38:27.098639 22426 sgd_solver.cpp:106] Iteration 69222, lr = 0.0045
I0525 12:38:35.941185 22426 solver.cpp:237] Iteration 69388, loss = 1.36146
I0525 12:38:35.941221 22426 solver.cpp:253]     Train net output #0: loss = 1.36146 (* 1 = 1.36146 loss)
I0525 12:38:35.941237 22426 sgd_solver.cpp:106] Iteration 69388, lr = 0.0045
I0525 12:38:44.798595 22426 solver.cpp:237] Iteration 69554, loss = 1.08392
I0525 12:38:44.798794 22426 solver.cpp:253]     Train net output #0: loss = 1.08392 (* 1 = 1.08392 loss)
I0525 12:38:44.798809 22426 sgd_solver.cpp:106] Iteration 69554, lr = 0.0045
I0525 12:38:53.649361 22426 solver.cpp:237] Iteration 69720, loss = 1.10021
I0525 12:38:53.649396 22426 solver.cpp:253]     Train net output #0: loss = 1.10021 (* 1 = 1.10021 loss)
I0525 12:38:53.649411 22426 sgd_solver.cpp:106] Iteration 69720, lr = 0.0045
I0525 12:39:02.498133 22426 solver.cpp:237] Iteration 69886, loss = 1.07406
I0525 12:39:02.498169 22426 solver.cpp:253]     Train net output #0: loss = 1.07406 (* 1 = 1.07406 loss)
I0525 12:39:02.498185 22426 sgd_solver.cpp:106] Iteration 69886, lr = 0.0045
I0525 12:39:07.022665 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_69972.caffemodel
I0525 12:39:07.096882 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_69972.solverstate
I0525 12:39:08.207514 22426 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 12:39:55.380121 22426 solver.cpp:409]     Test net output #0: accuracy = 0.896043
I0525 12:39:55.380314 22426 solver.cpp:409]     Test net output #1: loss = 0.333093 (* 1 = 0.333093 loss)
I0525 12:40:19.377542 22426 solver.cpp:237] Iteration 70052, loss = 1.12433
I0525 12:40:19.377593 22426 solver.cpp:253]     Train net output #0: loss = 1.12433 (* 1 = 1.12433 loss)
I0525 12:40:19.377609 22426 sgd_solver.cpp:106] Iteration 70052, lr = 0.0045
I0525 12:40:28.220094 22426 solver.cpp:237] Iteration 70218, loss = 1.0879
I0525 12:40:28.220280 22426 solver.cpp:253]     Train net output #0: loss = 1.0879 (* 1 = 1.0879 loss)
I0525 12:40:28.220294 22426 sgd_solver.cpp:106] Iteration 70218, lr = 0.0045
I0525 12:40:37.062492 22426 solver.cpp:237] Iteration 70384, loss = 1.23089
I0525 12:40:37.062526 22426 solver.cpp:253]     Train net output #0: loss = 1.23089 (* 1 = 1.23089 loss)
I0525 12:40:37.062544 22426 sgd_solver.cpp:106] Iteration 70384, lr = 0.0045
I0525 12:40:45.898326 22426 solver.cpp:237] Iteration 70550, loss = 1.37895
I0525 12:40:45.898371 22426 solver.cpp:253]     Train net output #0: loss = 1.37895 (* 1 = 1.37895 loss)
I0525 12:40:45.898386 22426 sgd_solver.cpp:106] Iteration 70550, lr = 0.0045
I0525 12:40:54.746155 22426 solver.cpp:237] Iteration 70716, loss = 1.08621
I0525 12:40:54.746191 22426 solver.cpp:253]     Train net output #0: loss = 1.08621 (* 1 = 1.08621 loss)
I0525 12:40:54.746207 22426 sgd_solver.cpp:106] Iteration 70716, lr = 0.0045
I0525 12:41:03.594317 22426 solver.cpp:237] Iteration 70882, loss = 1.11074
I0525 12:41:03.594488 22426 solver.cpp:253]     Train net output #0: loss = 1.11074 (* 1 = 1.11074 loss)
I0525 12:41:03.594502 22426 sgd_solver.cpp:106] Iteration 70882, lr = 0.0045
I0525 12:41:12.437481 22426 solver.cpp:237] Iteration 71048, loss = 1.12803
I0525 12:41:12.437525 22426 solver.cpp:253]     Train net output #0: loss = 1.12803 (* 1 = 1.12803 loss)
I0525 12:41:12.437542 22426 sgd_solver.cpp:106] Iteration 71048, lr = 0.0045
I0525 12:41:42.156044 22426 solver.cpp:237] Iteration 71214, loss = 1.42977
I0525 12:41:42.156250 22426 solver.cpp:253]     Train net output #0: loss = 1.42977 (* 1 = 1.42977 loss)
I0525 12:41:42.156263 22426 sgd_solver.cpp:106] Iteration 71214, lr = 0.0045
I0525 12:41:51.004420 22426 solver.cpp:237] Iteration 71380, loss = 1.38145
I0525 12:41:51.004456 22426 solver.cpp:253]     Train net output #0: loss = 1.38145 (* 1 = 1.38145 loss)
I0525 12:41:51.004473 22426 sgd_solver.cpp:106] Iteration 71380, lr = 0.0045
I0525 12:41:59.852461 22426 solver.cpp:237] Iteration 71546, loss = 1.00244
I0525 12:41:59.852510 22426 solver.cpp:253]     Train net output #0: loss = 1.00244 (* 1 = 1.00244 loss)
I0525 12:41:59.852525 22426 sgd_solver.cpp:106] Iteration 71546, lr = 0.0045
I0525 12:42:04.707733 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_71638.caffemodel
I0525 12:42:04.782994 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_71638.solverstate
I0525 12:42:08.772168 22426 solver.cpp:237] Iteration 71712, loss = 1.34528
I0525 12:42:08.772214 22426 solver.cpp:253]     Train net output #0: loss = 1.34528 (* 1 = 1.34528 loss)
I0525 12:42:08.772228 22426 sgd_solver.cpp:106] Iteration 71712, lr = 0.0045
I0525 12:42:17.626353 22426 solver.cpp:237] Iteration 71878, loss = 0.86353
I0525 12:42:17.626551 22426 solver.cpp:253]     Train net output #0: loss = 0.86353 (* 1 = 0.86353 loss)
I0525 12:42:17.626565 22426 sgd_solver.cpp:106] Iteration 71878, lr = 0.0045
I0525 12:42:26.477382 22426 solver.cpp:237] Iteration 72044, loss = 1.21192
I0525 12:42:26.477428 22426 solver.cpp:253]     Train net output #0: loss = 1.21192 (* 1 = 1.21192 loss)
I0525 12:42:26.477447 22426 sgd_solver.cpp:106] Iteration 72044, lr = 0.0045
I0525 12:42:35.330152 22426 solver.cpp:237] Iteration 72210, loss = 0.957118
I0525 12:42:35.330188 22426 solver.cpp:253]     Train net output #0: loss = 0.957118 (* 1 = 0.957118 loss)
I0525 12:42:35.330204 22426 sgd_solver.cpp:106] Iteration 72210, lr = 0.0045
I0525 12:43:05.052456 22426 solver.cpp:237] Iteration 72376, loss = 1.21697
I0525 12:43:05.052666 22426 solver.cpp:253]     Train net output #0: loss = 1.21697 (* 1 = 1.21697 loss)
I0525 12:43:05.052681 22426 sgd_solver.cpp:106] Iteration 72376, lr = 0.0045
I0525 12:43:13.905855 22426 solver.cpp:237] Iteration 72542, loss = 1.06592
I0525 12:43:13.905890 22426 solver.cpp:253]     Train net output #0: loss = 1.06592 (* 1 = 1.06592 loss)
I0525 12:43:13.905906 22426 sgd_solver.cpp:106] Iteration 72542, lr = 0.0045
I0525 12:43:22.756075 22426 solver.cpp:237] Iteration 72708, loss = 1.15472
I0525 12:43:22.756108 22426 solver.cpp:253]     Train net output #0: loss = 1.15472 (* 1 = 1.15472 loss)
I0525 12:43:22.756134 22426 sgd_solver.cpp:106] Iteration 72708, lr = 0.0045
I0525 12:43:31.599211 22426 solver.cpp:237] Iteration 72874, loss = 1.21273
I0525 12:43:31.599246 22426 solver.cpp:253]     Train net output #0: loss = 1.21273 (* 1 = 1.21273 loss)
I0525 12:43:31.599259 22426 sgd_solver.cpp:106] Iteration 72874, lr = 0.0045
I0525 12:43:40.444815 22426 solver.cpp:237] Iteration 73040, loss = 1.10283
I0525 12:43:40.445013 22426 solver.cpp:253]     Train net output #0: loss = 1.10283 (* 1 = 1.10283 loss)
I0525 12:43:40.445026 22426 sgd_solver.cpp:106] Iteration 73040, lr = 0.0045
I0525 12:43:49.289515 22426 solver.cpp:237] Iteration 73206, loss = 1.28453
I0525 12:43:49.289551 22426 solver.cpp:253]     Train net output #0: loss = 1.28453 (* 1 = 1.28453 loss)
I0525 12:43:49.289567 22426 sgd_solver.cpp:106] Iteration 73206, lr = 0.0045
I0525 12:43:54.466754 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_73304.caffemodel
I0525 12:43:54.542526 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_73304.solverstate
I0525 12:43:55.710031 22426 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 12:45:03.760926 22426 solver.cpp:409]     Test net output #0: accuracy = 0.898251
I0525 12:45:03.761139 22426 solver.cpp:409]     Test net output #1: loss = 0.337185 (* 1 = 0.337185 loss)
I0525 12:45:27.104090 22426 solver.cpp:237] Iteration 73372, loss = 1.28821
I0525 12:45:27.104140 22426 solver.cpp:253]     Train net output #0: loss = 1.28821 (* 1 = 1.28821 loss)
I0525 12:45:27.104156 22426 sgd_solver.cpp:106] Iteration 73372, lr = 0.0045
I0525 12:45:35.938074 22426 solver.cpp:237] Iteration 73538, loss = 1.04183
I0525 12:45:35.938266 22426 solver.cpp:253]     Train net output #0: loss = 1.04183 (* 1 = 1.04183 loss)
I0525 12:45:35.938279 22426 sgd_solver.cpp:106] Iteration 73538, lr = 0.0045
I0525 12:45:44.784183 22426 solver.cpp:237] Iteration 73704, loss = 1.35468
I0525 12:45:44.784226 22426 solver.cpp:253]     Train net output #0: loss = 1.35468 (* 1 = 1.35468 loss)
I0525 12:45:44.784240 22426 sgd_solver.cpp:106] Iteration 73704, lr = 0.0045
I0525 12:45:53.621814 22426 solver.cpp:237] Iteration 73870, loss = 1.18297
I0525 12:45:53.621850 22426 solver.cpp:253]     Train net output #0: loss = 1.18297 (* 1 = 1.18297 loss)
I0525 12:45:53.621868 22426 sgd_solver.cpp:106] Iteration 73870, lr = 0.0045
I0525 12:46:02.465242 22426 solver.cpp:237] Iteration 74036, loss = 1.21056
I0525 12:46:02.465277 22426 solver.cpp:253]     Train net output #0: loss = 1.21056 (* 1 = 1.21056 loss)
I0525 12:46:02.465293 22426 sgd_solver.cpp:106] Iteration 74036, lr = 0.0045
I0525 12:46:11.310600 22426 solver.cpp:237] Iteration 74202, loss = 0.956728
I0525 12:46:11.310788 22426 solver.cpp:253]     Train net output #0: loss = 0.956728 (* 1 = 0.956728 loss)
I0525 12:46:11.310802 22426 sgd_solver.cpp:106] Iteration 74202, lr = 0.0045
I0525 12:46:20.147028 22426 solver.cpp:237] Iteration 74368, loss = 1.12225
I0525 12:46:20.147063 22426 solver.cpp:253]     Train net output #0: loss = 1.12225 (* 1 = 1.12225 loss)
I0525 12:46:20.147080 22426 sgd_solver.cpp:106] Iteration 74368, lr = 0.0045
I0525 12:46:49.851610 22426 solver.cpp:237] Iteration 74534, loss = 1.12531
I0525 12:46:49.851810 22426 solver.cpp:253]     Train net output #0: loss = 1.12531 (* 1 = 1.12531 loss)
I0525 12:46:49.851824 22426 sgd_solver.cpp:106] Iteration 74534, lr = 0.0045
I0525 12:46:58.691987 22426 solver.cpp:237] Iteration 74700, loss = 1.12871
I0525 12:46:58.692021 22426 solver.cpp:253]     Train net output #0: loss = 1.12871 (* 1 = 1.12871 loss)
I0525 12:46:58.692039 22426 sgd_solver.cpp:106] Iteration 74700, lr = 0.0045
I0525 12:47:07.532939 22426 solver.cpp:237] Iteration 74866, loss = 0.901455
I0525 12:47:07.532979 22426 solver.cpp:253]     Train net output #0: loss = 0.901455 (* 1 = 0.901455 loss)
I0525 12:47:07.532999 22426 sgd_solver.cpp:106] Iteration 74866, lr = 0.0045
I0525 12:47:13.019448 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_74970.caffemodel
I0525 12:47:13.097021 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_74970.solverstate
I0525 12:47:16.444146 22426 solver.cpp:237] Iteration 75032, loss = 1.01328
I0525 12:47:16.444195 22426 solver.cpp:253]     Train net output #0: loss = 1.01328 (* 1 = 1.01328 loss)
I0525 12:47:16.444212 22426 sgd_solver.cpp:106] Iteration 75032, lr = 0.0045
I0525 12:47:25.287945 22426 solver.cpp:237] Iteration 75198, loss = 1.05247
I0525 12:47:25.288138 22426 solver.cpp:253]     Train net output #0: loss = 1.05247 (* 1 = 1.05247 loss)
I0525 12:47:25.288152 22426 sgd_solver.cpp:106] Iteration 75198, lr = 0.0045
I0525 12:47:34.122294 22426 solver.cpp:237] Iteration 75364, loss = 1.18785
I0525 12:47:34.122330 22426 solver.cpp:253]     Train net output #0: loss = 1.18785 (* 1 = 1.18785 loss)
I0525 12:47:34.122349 22426 sgd_solver.cpp:106] Iteration 75364, lr = 0.0045
I0525 12:47:42.962524 22426 solver.cpp:237] Iteration 75530, loss = 1.13016
I0525 12:47:42.962559 22426 solver.cpp:253]     Train net output #0: loss = 1.13016 (* 1 = 1.13016 loss)
I0525 12:47:42.962575 22426 sgd_solver.cpp:106] Iteration 75530, lr = 0.0045
I0525 12:48:12.654764 22426 solver.cpp:237] Iteration 75696, loss = 1.08436
I0525 12:48:12.654983 22426 solver.cpp:253]     Train net output #0: loss = 1.08436 (* 1 = 1.08436 loss)
I0525 12:48:12.654999 22426 sgd_solver.cpp:106] Iteration 75696, lr = 0.0045
I0525 12:48:21.493800 22426 solver.cpp:237] Iteration 75862, loss = 1.35171
I0525 12:48:21.493837 22426 solver.cpp:253]     Train net output #0: loss = 1.35171 (* 1 = 1.35171 loss)
I0525 12:48:21.493859 22426 sgd_solver.cpp:106] Iteration 75862, lr = 0.0045
I0525 12:48:30.339545 22426 solver.cpp:237] Iteration 76028, loss = 1.15885
I0525 12:48:30.339581 22426 solver.cpp:253]     Train net output #0: loss = 1.15885 (* 1 = 1.15885 loss)
I0525 12:48:30.339597 22426 sgd_solver.cpp:106] Iteration 76028, lr = 0.0045
I0525 12:48:39.172255 22426 solver.cpp:237] Iteration 76194, loss = 1.09352
I0525 12:48:39.172289 22426 solver.cpp:253]     Train net output #0: loss = 1.09352 (* 1 = 1.09352 loss)
I0525 12:48:39.172305 22426 sgd_solver.cpp:106] Iteration 76194, lr = 0.0045
I0525 12:48:48.011592 22426 solver.cpp:237] Iteration 76360, loss = 1.29445
I0525 12:48:48.011791 22426 solver.cpp:253]     Train net output #0: loss = 1.29445 (* 1 = 1.29445 loss)
I0525 12:48:48.011806 22426 sgd_solver.cpp:106] Iteration 76360, lr = 0.0045
I0525 12:48:56.839792 22426 solver.cpp:237] Iteration 76526, loss = 1.24648
I0525 12:48:56.839828 22426 solver.cpp:253]     Train net output #0: loss = 1.24648 (* 1 = 1.24648 loss)
I0525 12:48:56.839843 22426 sgd_solver.cpp:106] Iteration 76526, lr = 0.0045
I0525 12:49:02.640022 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_76636.caffemodel
I0525 12:49:02.715476 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_76636.solverstate
I0525 12:49:03.928326 22426 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 12:49:50.720494 22426 solver.cpp:409]     Test net output #0: accuracy = 0.899525
I0525 12:49:50.720703 22426 solver.cpp:409]     Test net output #1: loss = 0.320668 (* 1 = 0.320668 loss)
I0525 12:50:13.391957 22426 solver.cpp:237] Iteration 76692, loss = 1.20872
I0525 12:50:13.392007 22426 solver.cpp:253]     Train net output #0: loss = 1.20872 (* 1 = 1.20872 loss)
I0525 12:50:13.392024 22426 sgd_solver.cpp:106] Iteration 76692, lr = 0.0045
I0525 12:50:22.226439 22426 solver.cpp:237] Iteration 76858, loss = 1.20633
I0525 12:50:22.226634 22426 solver.cpp:253]     Train net output #0: loss = 1.20633 (* 1 = 1.20633 loss)
I0525 12:50:22.226647 22426 sgd_solver.cpp:106] Iteration 76858, lr = 0.0045
I0525 12:50:31.069681 22426 solver.cpp:237] Iteration 77024, loss = 1.05715
I0525 12:50:31.069716 22426 solver.cpp:253]     Train net output #0: loss = 1.05715 (* 1 = 1.05715 loss)
I0525 12:50:31.069730 22426 sgd_solver.cpp:106] Iteration 77024, lr = 0.0045
I0525 12:50:39.905479 22426 solver.cpp:237] Iteration 77190, loss = 1.22975
I0525 12:50:39.905514 22426 solver.cpp:253]     Train net output #0: loss = 1.22975 (* 1 = 1.22975 loss)
I0525 12:50:39.905531 22426 sgd_solver.cpp:106] Iteration 77190, lr = 0.0045
I0525 12:50:48.733598 22426 solver.cpp:237] Iteration 77356, loss = 1.16613
I0525 12:50:48.733644 22426 solver.cpp:253]     Train net output #0: loss = 1.16613 (* 1 = 1.16613 loss)
I0525 12:50:48.733662 22426 sgd_solver.cpp:106] Iteration 77356, lr = 0.0045
I0525 12:50:57.575590 22426 solver.cpp:237] Iteration 77522, loss = 1.26504
I0525 12:50:57.575769 22426 solver.cpp:253]     Train net output #0: loss = 1.26504 (* 1 = 1.26504 loss)
I0525 12:50:57.575783 22426 sgd_solver.cpp:106] Iteration 77522, lr = 0.0045
I0525 12:51:06.414643 22426 solver.cpp:237] Iteration 77688, loss = 1.30402
I0525 12:51:06.414676 22426 solver.cpp:253]     Train net output #0: loss = 1.30402 (* 1 = 1.30402 loss)
I0525 12:51:06.414693 22426 sgd_solver.cpp:106] Iteration 77688, lr = 0.0045
I0525 12:51:36.111259 22426 solver.cpp:237] Iteration 77854, loss = 1.0327
I0525 12:51:36.111466 22426 solver.cpp:253]     Train net output #0: loss = 1.0327 (* 1 = 1.0327 loss)
I0525 12:51:36.111481 22426 sgd_solver.cpp:106] Iteration 77854, lr = 0.0045
I0525 12:51:44.951424 22426 solver.cpp:237] Iteration 78020, loss = 1.14607
I0525 12:51:44.951459 22426 solver.cpp:253]     Train net output #0: loss = 1.14607 (* 1 = 1.14607 loss)
I0525 12:51:44.951477 22426 sgd_solver.cpp:106] Iteration 78020, lr = 0.0045
I0525 12:51:53.795227 22426 solver.cpp:237] Iteration 78186, loss = 0.944547
I0525 12:51:53.795261 22426 solver.cpp:253]     Train net output #0: loss = 0.944547 (* 1 = 0.944547 loss)
I0525 12:51:53.795277 22426 sgd_solver.cpp:106] Iteration 78186, lr = 0.0045
I0525 12:51:59.925658 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_78302.caffemodel
I0525 12:52:00.001366 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_78302.solverstate
I0525 12:52:02.708021 22426 solver.cpp:237] Iteration 78352, loss = 1.07666
I0525 12:52:02.708065 22426 solver.cpp:253]     Train net output #0: loss = 1.07666 (* 1 = 1.07666 loss)
I0525 12:52:02.708086 22426 sgd_solver.cpp:106] Iteration 78352, lr = 0.0045
I0525 12:52:11.554921 22426 solver.cpp:237] Iteration 78518, loss = 0.963214
I0525 12:52:11.555104 22426 solver.cpp:253]     Train net output #0: loss = 0.963214 (* 1 = 0.963214 loss)
I0525 12:52:11.555119 22426 sgd_solver.cpp:106] Iteration 78518, lr = 0.0045
I0525 12:52:20.399690 22426 solver.cpp:237] Iteration 78684, loss = 1.15415
I0525 12:52:20.399724 22426 solver.cpp:253]     Train net output #0: loss = 1.15415 (* 1 = 1.15415 loss)
I0525 12:52:20.399741 22426 sgd_solver.cpp:106] Iteration 78684, lr = 0.0045
I0525 12:52:29.241076 22426 solver.cpp:237] Iteration 78850, loss = 1.16559
I0525 12:52:29.241118 22426 solver.cpp:253]     Train net output #0: loss = 1.16559 (* 1 = 1.16559 loss)
I0525 12:52:29.241135 22426 sgd_solver.cpp:106] Iteration 78850, lr = 0.0045
I0525 12:52:58.931748 22426 solver.cpp:237] Iteration 79016, loss = 1.07338
I0525 12:52:58.931946 22426 solver.cpp:253]     Train net output #0: loss = 1.07338 (* 1 = 1.07338 loss)
I0525 12:52:58.931960 22426 sgd_solver.cpp:106] Iteration 79016, lr = 0.0045
I0525 12:53:07.773739 22426 solver.cpp:237] Iteration 79182, loss = 1.01553
I0525 12:53:07.773773 22426 solver.cpp:253]     Train net output #0: loss = 1.01553 (* 1 = 1.01553 loss)
I0525 12:53:07.773790 22426 sgd_solver.cpp:106] Iteration 79182, lr = 0.0045
I0525 12:53:16.607786 22426 solver.cpp:237] Iteration 79348, loss = 1.0778
I0525 12:53:16.607825 22426 solver.cpp:253]     Train net output #0: loss = 1.0778 (* 1 = 1.0778 loss)
I0525 12:53:16.607848 22426 sgd_solver.cpp:106] Iteration 79348, lr = 0.0045
I0525 12:53:25.438889 22426 solver.cpp:237] Iteration 79514, loss = 0.907759
I0525 12:53:25.438925 22426 solver.cpp:253]     Train net output #0: loss = 0.907759 (* 1 = 0.907759 loss)
I0525 12:53:25.438941 22426 sgd_solver.cpp:106] Iteration 79514, lr = 0.0045
I0525 12:53:34.274106 22426 solver.cpp:237] Iteration 79680, loss = 1.0926
I0525 12:53:34.274283 22426 solver.cpp:253]     Train net output #0: loss = 1.0926 (* 1 = 1.0926 loss)
I0525 12:53:34.274296 22426 sgd_solver.cpp:106] Iteration 79680, lr = 0.0045
I0525 12:53:43.114895 22426 solver.cpp:237] Iteration 79846, loss = 0.982863
I0525 12:53:43.114943 22426 solver.cpp:253]     Train net output #0: loss = 0.982863 (* 1 = 0.982863 loss)
I0525 12:53:43.114959 22426 sgd_solver.cpp:106] Iteration 79846, lr = 0.0045
I0525 12:53:49.561493 22426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_79968.caffemodel
I0525 12:53:49.635946 22426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0045_2016-05-20T15.49.23.235180_iter_79968.solverstate
I0525 12:53:50.905757 22426 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11263652: Caught signal Terminated, sending to application
*** Aborted at 1464195256 (unix time) try "date -d @1464195256" if you are using GNU date ***
PC: @     0x2aaac5e9bb24 (unknown)
*** SIGTERM (@0x5797) received by PID 22426 (TID 0x2aaac746f900) from PID 22423; stack trace: ***
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7204 exceeded limit 7200
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @     0x2aaac5e9bb24 (unknown)
    @     0x2aaac5e9c9d5 inflate
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11263652: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
aprun: Apid 11263652: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02257] [c4-1c0s7n3] [Wed May 25 12:54:18 2016] PE RANK 0 exit signal Terminated
Application 11263652 exit codes: 143
Application 11263652 resources: utime ~6205s, stime ~988s, Rss ~5332588, inblocks ~16309488, outblocks ~740498
