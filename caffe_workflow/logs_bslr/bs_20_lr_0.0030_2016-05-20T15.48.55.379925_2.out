2812386
I0526 17:08:48.990001 13044 caffe.cpp:184] Using GPUs 0
I0526 17:08:49.415447 13044 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.003
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925.prototxt"
I0526 17:08:49.417378 13044 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925.prototxt
I0526 17:08:49.432154 13044 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 17:08:49.432214 13044 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 17:08:49.432562 13044 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 17:08:49.432742 13044 layer_factory.hpp:77] Creating layer data_hdf5
I0526 17:08:49.432766 13044 net.cpp:106] Creating Layer data_hdf5
I0526 17:08:49.432781 13044 net.cpp:411] data_hdf5 -> data
I0526 17:08:49.432816 13044 net.cpp:411] data_hdf5 -> label
I0526 17:08:49.432848 13044 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 17:08:49.448279 13044 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 17:08:49.465545 13044 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 17:09:11.065168 13044 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 17:09:11.070356 13044 net.cpp:150] Setting up data_hdf5
I0526 17:09:11.070397 13044 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 17:09:11.070411 13044 net.cpp:157] Top shape: 20 (20)
I0526 17:09:11.070423 13044 net.cpp:165] Memory required for data: 508080
I0526 17:09:11.070437 13044 layer_factory.hpp:77] Creating layer conv1
I0526 17:09:11.070471 13044 net.cpp:106] Creating Layer conv1
I0526 17:09:11.070482 13044 net.cpp:454] conv1 <- data
I0526 17:09:11.070502 13044 net.cpp:411] conv1 -> conv1
I0526 17:09:13.828749 13044 net.cpp:150] Setting up conv1
I0526 17:09:13.828791 13044 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 17:09:13.828805 13044 net.cpp:165] Memory required for data: 6037680
I0526 17:09:13.828835 13044 layer_factory.hpp:77] Creating layer relu1
I0526 17:09:13.828856 13044 net.cpp:106] Creating Layer relu1
I0526 17:09:13.828867 13044 net.cpp:454] relu1 <- conv1
I0526 17:09:13.828881 13044 net.cpp:397] relu1 -> conv1 (in-place)
I0526 17:09:13.829402 13044 net.cpp:150] Setting up relu1
I0526 17:09:13.829418 13044 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 17:09:13.829429 13044 net.cpp:165] Memory required for data: 11567280
I0526 17:09:13.829440 13044 layer_factory.hpp:77] Creating layer pool1
I0526 17:09:13.829457 13044 net.cpp:106] Creating Layer pool1
I0526 17:09:13.829468 13044 net.cpp:454] pool1 <- conv1
I0526 17:09:13.829483 13044 net.cpp:411] pool1 -> pool1
I0526 17:09:13.829563 13044 net.cpp:150] Setting up pool1
I0526 17:09:13.829577 13044 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 17:09:13.829587 13044 net.cpp:165] Memory required for data: 14332080
I0526 17:09:13.829598 13044 layer_factory.hpp:77] Creating layer conv2
I0526 17:09:13.829620 13044 net.cpp:106] Creating Layer conv2
I0526 17:09:13.829630 13044 net.cpp:454] conv2 <- pool1
I0526 17:09:13.829643 13044 net.cpp:411] conv2 -> conv2
I0526 17:09:13.832427 13044 net.cpp:150] Setting up conv2
I0526 17:09:13.832455 13044 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 17:09:13.832466 13044 net.cpp:165] Memory required for data: 18306480
I0526 17:09:13.832485 13044 layer_factory.hpp:77] Creating layer relu2
I0526 17:09:13.832500 13044 net.cpp:106] Creating Layer relu2
I0526 17:09:13.832510 13044 net.cpp:454] relu2 <- conv2
I0526 17:09:13.832523 13044 net.cpp:397] relu2 -> conv2 (in-place)
I0526 17:09:13.832855 13044 net.cpp:150] Setting up relu2
I0526 17:09:13.832870 13044 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 17:09:13.832880 13044 net.cpp:165] Memory required for data: 22280880
I0526 17:09:13.832890 13044 layer_factory.hpp:77] Creating layer pool2
I0526 17:09:13.832902 13044 net.cpp:106] Creating Layer pool2
I0526 17:09:13.832912 13044 net.cpp:454] pool2 <- conv2
I0526 17:09:13.832924 13044 net.cpp:411] pool2 -> pool2
I0526 17:09:13.833005 13044 net.cpp:150] Setting up pool2
I0526 17:09:13.833024 13044 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 17:09:13.833034 13044 net.cpp:165] Memory required for data: 24268080
I0526 17:09:13.833045 13044 layer_factory.hpp:77] Creating layer conv3
I0526 17:09:13.833060 13044 net.cpp:106] Creating Layer conv3
I0526 17:09:13.833070 13044 net.cpp:454] conv3 <- pool2
I0526 17:09:13.833084 13044 net.cpp:411] conv3 -> conv3
I0526 17:09:13.835031 13044 net.cpp:150] Setting up conv3
I0526 17:09:13.835054 13044 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 17:09:13.835069 13044 net.cpp:165] Memory required for data: 26436400
I0526 17:09:13.835088 13044 layer_factory.hpp:77] Creating layer relu3
I0526 17:09:13.835103 13044 net.cpp:106] Creating Layer relu3
I0526 17:09:13.835114 13044 net.cpp:454] relu3 <- conv3
I0526 17:09:13.835126 13044 net.cpp:397] relu3 -> conv3 (in-place)
I0526 17:09:13.835607 13044 net.cpp:150] Setting up relu3
I0526 17:09:13.835623 13044 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 17:09:13.835634 13044 net.cpp:165] Memory required for data: 28604720
I0526 17:09:13.835644 13044 layer_factory.hpp:77] Creating layer pool3
I0526 17:09:13.835657 13044 net.cpp:106] Creating Layer pool3
I0526 17:09:13.835667 13044 net.cpp:454] pool3 <- conv3
I0526 17:09:13.835680 13044 net.cpp:411] pool3 -> pool3
I0526 17:09:13.835748 13044 net.cpp:150] Setting up pool3
I0526 17:09:13.835762 13044 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 17:09:13.835772 13044 net.cpp:165] Memory required for data: 29688880
I0526 17:09:13.835780 13044 layer_factory.hpp:77] Creating layer conv4
I0526 17:09:13.835798 13044 net.cpp:106] Creating Layer conv4
I0526 17:09:13.835808 13044 net.cpp:454] conv4 <- pool3
I0526 17:09:13.835822 13044 net.cpp:411] conv4 -> conv4
I0526 17:09:13.838542 13044 net.cpp:150] Setting up conv4
I0526 17:09:13.838570 13044 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 17:09:13.838580 13044 net.cpp:165] Memory required for data: 30414640
I0526 17:09:13.838595 13044 layer_factory.hpp:77] Creating layer relu4
I0526 17:09:13.838609 13044 net.cpp:106] Creating Layer relu4
I0526 17:09:13.838619 13044 net.cpp:454] relu4 <- conv4
I0526 17:09:13.838632 13044 net.cpp:397] relu4 -> conv4 (in-place)
I0526 17:09:13.839098 13044 net.cpp:150] Setting up relu4
I0526 17:09:13.839114 13044 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 17:09:13.839125 13044 net.cpp:165] Memory required for data: 31140400
I0526 17:09:13.839135 13044 layer_factory.hpp:77] Creating layer pool4
I0526 17:09:13.839148 13044 net.cpp:106] Creating Layer pool4
I0526 17:09:13.839159 13044 net.cpp:454] pool4 <- conv4
I0526 17:09:13.839171 13044 net.cpp:411] pool4 -> pool4
I0526 17:09:13.839239 13044 net.cpp:150] Setting up pool4
I0526 17:09:13.839253 13044 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 17:09:13.839263 13044 net.cpp:165] Memory required for data: 31503280
I0526 17:09:13.839273 13044 layer_factory.hpp:77] Creating layer ip1
I0526 17:09:13.839293 13044 net.cpp:106] Creating Layer ip1
I0526 17:09:13.839303 13044 net.cpp:454] ip1 <- pool4
I0526 17:09:13.839318 13044 net.cpp:411] ip1 -> ip1
I0526 17:09:13.854794 13044 net.cpp:150] Setting up ip1
I0526 17:09:13.854822 13044 net.cpp:157] Top shape: 20 196 (3920)
I0526 17:09:13.854835 13044 net.cpp:165] Memory required for data: 31518960
I0526 17:09:13.854856 13044 layer_factory.hpp:77] Creating layer relu5
I0526 17:09:13.854871 13044 net.cpp:106] Creating Layer relu5
I0526 17:09:13.854882 13044 net.cpp:454] relu5 <- ip1
I0526 17:09:13.854895 13044 net.cpp:397] relu5 -> ip1 (in-place)
I0526 17:09:13.855235 13044 net.cpp:150] Setting up relu5
I0526 17:09:13.855249 13044 net.cpp:157] Top shape: 20 196 (3920)
I0526 17:09:13.855260 13044 net.cpp:165] Memory required for data: 31534640
I0526 17:09:13.855270 13044 layer_factory.hpp:77] Creating layer drop1
I0526 17:09:13.855293 13044 net.cpp:106] Creating Layer drop1
I0526 17:09:13.855303 13044 net.cpp:454] drop1 <- ip1
I0526 17:09:13.855315 13044 net.cpp:397] drop1 -> ip1 (in-place)
I0526 17:09:13.855376 13044 net.cpp:150] Setting up drop1
I0526 17:09:13.855388 13044 net.cpp:157] Top shape: 20 196 (3920)
I0526 17:09:13.855398 13044 net.cpp:165] Memory required for data: 31550320
I0526 17:09:13.855408 13044 layer_factory.hpp:77] Creating layer ip2
I0526 17:09:13.855427 13044 net.cpp:106] Creating Layer ip2
I0526 17:09:13.855437 13044 net.cpp:454] ip2 <- ip1
I0526 17:09:13.855451 13044 net.cpp:411] ip2 -> ip2
I0526 17:09:13.855921 13044 net.cpp:150] Setting up ip2
I0526 17:09:13.855934 13044 net.cpp:157] Top shape: 20 98 (1960)
I0526 17:09:13.855944 13044 net.cpp:165] Memory required for data: 31558160
I0526 17:09:13.855960 13044 layer_factory.hpp:77] Creating layer relu6
I0526 17:09:13.855973 13044 net.cpp:106] Creating Layer relu6
I0526 17:09:13.855983 13044 net.cpp:454] relu6 <- ip2
I0526 17:09:13.855994 13044 net.cpp:397] relu6 -> ip2 (in-place)
I0526 17:09:13.856514 13044 net.cpp:150] Setting up relu6
I0526 17:09:13.856531 13044 net.cpp:157] Top shape: 20 98 (1960)
I0526 17:09:13.856541 13044 net.cpp:165] Memory required for data: 31566000
I0526 17:09:13.856551 13044 layer_factory.hpp:77] Creating layer drop2
I0526 17:09:13.856565 13044 net.cpp:106] Creating Layer drop2
I0526 17:09:13.856575 13044 net.cpp:454] drop2 <- ip2
I0526 17:09:13.856587 13044 net.cpp:397] drop2 -> ip2 (in-place)
I0526 17:09:13.856631 13044 net.cpp:150] Setting up drop2
I0526 17:09:13.856642 13044 net.cpp:157] Top shape: 20 98 (1960)
I0526 17:09:13.856653 13044 net.cpp:165] Memory required for data: 31573840
I0526 17:09:13.856662 13044 layer_factory.hpp:77] Creating layer ip3
I0526 17:09:13.856675 13044 net.cpp:106] Creating Layer ip3
I0526 17:09:13.856685 13044 net.cpp:454] ip3 <- ip2
I0526 17:09:13.856698 13044 net.cpp:411] ip3 -> ip3
I0526 17:09:13.856909 13044 net.cpp:150] Setting up ip3
I0526 17:09:13.856922 13044 net.cpp:157] Top shape: 20 11 (220)
I0526 17:09:13.856932 13044 net.cpp:165] Memory required for data: 31574720
I0526 17:09:13.856947 13044 layer_factory.hpp:77] Creating layer drop3
I0526 17:09:13.856961 13044 net.cpp:106] Creating Layer drop3
I0526 17:09:13.856969 13044 net.cpp:454] drop3 <- ip3
I0526 17:09:13.856982 13044 net.cpp:397] drop3 -> ip3 (in-place)
I0526 17:09:13.857022 13044 net.cpp:150] Setting up drop3
I0526 17:09:13.857034 13044 net.cpp:157] Top shape: 20 11 (220)
I0526 17:09:13.857044 13044 net.cpp:165] Memory required for data: 31575600
I0526 17:09:13.857054 13044 layer_factory.hpp:77] Creating layer loss
I0526 17:09:13.857074 13044 net.cpp:106] Creating Layer loss
I0526 17:09:13.857084 13044 net.cpp:454] loss <- ip3
I0526 17:09:13.857095 13044 net.cpp:454] loss <- label
I0526 17:09:13.857107 13044 net.cpp:411] loss -> loss
I0526 17:09:13.857125 13044 layer_factory.hpp:77] Creating layer loss
I0526 17:09:13.857769 13044 net.cpp:150] Setting up loss
I0526 17:09:13.857784 13044 net.cpp:157] Top shape: (1)
I0526 17:09:13.857795 13044 net.cpp:160]     with loss weight 1
I0526 17:09:13.857837 13044 net.cpp:165] Memory required for data: 31575604
I0526 17:09:13.857847 13044 net.cpp:226] loss needs backward computation.
I0526 17:09:13.857858 13044 net.cpp:226] drop3 needs backward computation.
I0526 17:09:13.857868 13044 net.cpp:226] ip3 needs backward computation.
I0526 17:09:13.857879 13044 net.cpp:226] drop2 needs backward computation.
I0526 17:09:13.857889 13044 net.cpp:226] relu6 needs backward computation.
I0526 17:09:13.857899 13044 net.cpp:226] ip2 needs backward computation.
I0526 17:09:13.857910 13044 net.cpp:226] drop1 needs backward computation.
I0526 17:09:13.857919 13044 net.cpp:226] relu5 needs backward computation.
I0526 17:09:13.857929 13044 net.cpp:226] ip1 needs backward computation.
I0526 17:09:13.857939 13044 net.cpp:226] pool4 needs backward computation.
I0526 17:09:13.857949 13044 net.cpp:226] relu4 needs backward computation.
I0526 17:09:13.857959 13044 net.cpp:226] conv4 needs backward computation.
I0526 17:09:13.857969 13044 net.cpp:226] pool3 needs backward computation.
I0526 17:09:13.857980 13044 net.cpp:226] relu3 needs backward computation.
I0526 17:09:13.857987 13044 net.cpp:226] conv3 needs backward computation.
I0526 17:09:13.858007 13044 net.cpp:226] pool2 needs backward computation.
I0526 17:09:13.858018 13044 net.cpp:226] relu2 needs backward computation.
I0526 17:09:13.858028 13044 net.cpp:226] conv2 needs backward computation.
I0526 17:09:13.858039 13044 net.cpp:226] pool1 needs backward computation.
I0526 17:09:13.858049 13044 net.cpp:226] relu1 needs backward computation.
I0526 17:09:13.858059 13044 net.cpp:226] conv1 needs backward computation.
I0526 17:09:13.858070 13044 net.cpp:228] data_hdf5 does not need backward computation.
I0526 17:09:13.858079 13044 net.cpp:270] This network produces output loss
I0526 17:09:13.858103 13044 net.cpp:283] Network initialization done.
I0526 17:09:13.859705 13044 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925.prototxt
I0526 17:09:13.859777 13044 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 17:09:13.860131 13044 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 17:09:13.860319 13044 layer_factory.hpp:77] Creating layer data_hdf5
I0526 17:09:13.860334 13044 net.cpp:106] Creating Layer data_hdf5
I0526 17:09:13.860347 13044 net.cpp:411] data_hdf5 -> data
I0526 17:09:13.860364 13044 net.cpp:411] data_hdf5 -> label
I0526 17:09:13.860380 13044 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 17:09:13.877400 13044 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 17:09:35.251886 13044 net.cpp:150] Setting up data_hdf5
I0526 17:09:35.252049 13044 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 17:09:35.252064 13044 net.cpp:157] Top shape: 20 (20)
I0526 17:09:35.252076 13044 net.cpp:165] Memory required for data: 508080
I0526 17:09:35.252090 13044 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 17:09:35.252118 13044 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 17:09:35.252130 13044 net.cpp:454] label_data_hdf5_1_split <- label
I0526 17:09:35.252145 13044 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 17:09:35.252166 13044 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 17:09:35.252239 13044 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 17:09:35.252254 13044 net.cpp:157] Top shape: 20 (20)
I0526 17:09:35.252265 13044 net.cpp:157] Top shape: 20 (20)
I0526 17:09:35.252274 13044 net.cpp:165] Memory required for data: 508240
I0526 17:09:35.252282 13044 layer_factory.hpp:77] Creating layer conv1
I0526 17:09:35.252305 13044 net.cpp:106] Creating Layer conv1
I0526 17:09:35.252315 13044 net.cpp:454] conv1 <- data
I0526 17:09:35.252331 13044 net.cpp:411] conv1 -> conv1
I0526 17:09:35.254272 13044 net.cpp:150] Setting up conv1
I0526 17:09:35.254297 13044 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 17:09:35.254307 13044 net.cpp:165] Memory required for data: 6037840
I0526 17:09:35.254328 13044 layer_factory.hpp:77] Creating layer relu1
I0526 17:09:35.254343 13044 net.cpp:106] Creating Layer relu1
I0526 17:09:35.254354 13044 net.cpp:454] relu1 <- conv1
I0526 17:09:35.254365 13044 net.cpp:397] relu1 -> conv1 (in-place)
I0526 17:09:35.254863 13044 net.cpp:150] Setting up relu1
I0526 17:09:35.254879 13044 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 17:09:35.254890 13044 net.cpp:165] Memory required for data: 11567440
I0526 17:09:35.254900 13044 layer_factory.hpp:77] Creating layer pool1
I0526 17:09:35.254916 13044 net.cpp:106] Creating Layer pool1
I0526 17:09:35.254926 13044 net.cpp:454] pool1 <- conv1
I0526 17:09:35.254940 13044 net.cpp:411] pool1 -> pool1
I0526 17:09:35.255014 13044 net.cpp:150] Setting up pool1
I0526 17:09:35.255028 13044 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 17:09:35.255038 13044 net.cpp:165] Memory required for data: 14332240
I0526 17:09:35.255049 13044 layer_factory.hpp:77] Creating layer conv2
I0526 17:09:35.255067 13044 net.cpp:106] Creating Layer conv2
I0526 17:09:35.255079 13044 net.cpp:454] conv2 <- pool1
I0526 17:09:35.255092 13044 net.cpp:411] conv2 -> conv2
I0526 17:09:35.257010 13044 net.cpp:150] Setting up conv2
I0526 17:09:35.257035 13044 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 17:09:35.257045 13044 net.cpp:165] Memory required for data: 18306640
I0526 17:09:35.257063 13044 layer_factory.hpp:77] Creating layer relu2
I0526 17:09:35.257076 13044 net.cpp:106] Creating Layer relu2
I0526 17:09:35.257086 13044 net.cpp:454] relu2 <- conv2
I0526 17:09:35.257099 13044 net.cpp:397] relu2 -> conv2 (in-place)
I0526 17:09:35.257429 13044 net.cpp:150] Setting up relu2
I0526 17:09:35.257443 13044 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 17:09:35.257454 13044 net.cpp:165] Memory required for data: 22281040
I0526 17:09:35.257465 13044 layer_factory.hpp:77] Creating layer pool2
I0526 17:09:35.257478 13044 net.cpp:106] Creating Layer pool2
I0526 17:09:35.257488 13044 net.cpp:454] pool2 <- conv2
I0526 17:09:35.257500 13044 net.cpp:411] pool2 -> pool2
I0526 17:09:35.257572 13044 net.cpp:150] Setting up pool2
I0526 17:09:35.257586 13044 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 17:09:35.257596 13044 net.cpp:165] Memory required for data: 24268240
I0526 17:09:35.257603 13044 layer_factory.hpp:77] Creating layer conv3
I0526 17:09:35.257623 13044 net.cpp:106] Creating Layer conv3
I0526 17:09:35.257634 13044 net.cpp:454] conv3 <- pool2
I0526 17:09:35.257648 13044 net.cpp:411] conv3 -> conv3
I0526 17:09:35.259620 13044 net.cpp:150] Setting up conv3
I0526 17:09:35.259644 13044 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 17:09:35.259655 13044 net.cpp:165] Memory required for data: 26436560
I0526 17:09:35.259673 13044 layer_factory.hpp:77] Creating layer relu3
I0526 17:09:35.259701 13044 net.cpp:106] Creating Layer relu3
I0526 17:09:35.259711 13044 net.cpp:454] relu3 <- conv3
I0526 17:09:35.259726 13044 net.cpp:397] relu3 -> conv3 (in-place)
I0526 17:09:35.260200 13044 net.cpp:150] Setting up relu3
I0526 17:09:35.260215 13044 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 17:09:35.260226 13044 net.cpp:165] Memory required for data: 28604880
I0526 17:09:35.260236 13044 layer_factory.hpp:77] Creating layer pool3
I0526 17:09:35.260248 13044 net.cpp:106] Creating Layer pool3
I0526 17:09:35.260258 13044 net.cpp:454] pool3 <- conv3
I0526 17:09:35.260272 13044 net.cpp:411] pool3 -> pool3
I0526 17:09:35.260344 13044 net.cpp:150] Setting up pool3
I0526 17:09:35.260356 13044 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 17:09:35.260366 13044 net.cpp:165] Memory required for data: 29689040
I0526 17:09:35.260375 13044 layer_factory.hpp:77] Creating layer conv4
I0526 17:09:35.260392 13044 net.cpp:106] Creating Layer conv4
I0526 17:09:35.260403 13044 net.cpp:454] conv4 <- pool3
I0526 17:09:35.260417 13044 net.cpp:411] conv4 -> conv4
I0526 17:09:35.262472 13044 net.cpp:150] Setting up conv4
I0526 17:09:35.262495 13044 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 17:09:35.262507 13044 net.cpp:165] Memory required for data: 30414800
I0526 17:09:35.262522 13044 layer_factory.hpp:77] Creating layer relu4
I0526 17:09:35.262537 13044 net.cpp:106] Creating Layer relu4
I0526 17:09:35.262547 13044 net.cpp:454] relu4 <- conv4
I0526 17:09:35.262559 13044 net.cpp:397] relu4 -> conv4 (in-place)
I0526 17:09:35.263031 13044 net.cpp:150] Setting up relu4
I0526 17:09:35.263046 13044 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 17:09:35.263057 13044 net.cpp:165] Memory required for data: 31140560
I0526 17:09:35.263067 13044 layer_factory.hpp:77] Creating layer pool4
I0526 17:09:35.263080 13044 net.cpp:106] Creating Layer pool4
I0526 17:09:35.263089 13044 net.cpp:454] pool4 <- conv4
I0526 17:09:35.263103 13044 net.cpp:411] pool4 -> pool4
I0526 17:09:35.263175 13044 net.cpp:150] Setting up pool4
I0526 17:09:35.263190 13044 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 17:09:35.263198 13044 net.cpp:165] Memory required for data: 31503440
I0526 17:09:35.263207 13044 layer_factory.hpp:77] Creating layer ip1
I0526 17:09:35.263222 13044 net.cpp:106] Creating Layer ip1
I0526 17:09:35.263233 13044 net.cpp:454] ip1 <- pool4
I0526 17:09:35.263247 13044 net.cpp:411] ip1 -> ip1
I0526 17:09:35.278626 13044 net.cpp:150] Setting up ip1
I0526 17:09:35.278655 13044 net.cpp:157] Top shape: 20 196 (3920)
I0526 17:09:35.278666 13044 net.cpp:165] Memory required for data: 31519120
I0526 17:09:35.278687 13044 layer_factory.hpp:77] Creating layer relu5
I0526 17:09:35.278702 13044 net.cpp:106] Creating Layer relu5
I0526 17:09:35.278712 13044 net.cpp:454] relu5 <- ip1
I0526 17:09:35.278725 13044 net.cpp:397] relu5 -> ip1 (in-place)
I0526 17:09:35.279072 13044 net.cpp:150] Setting up relu5
I0526 17:09:35.279086 13044 net.cpp:157] Top shape: 20 196 (3920)
I0526 17:09:35.279095 13044 net.cpp:165] Memory required for data: 31534800
I0526 17:09:35.279106 13044 layer_factory.hpp:77] Creating layer drop1
I0526 17:09:35.279124 13044 net.cpp:106] Creating Layer drop1
I0526 17:09:35.279134 13044 net.cpp:454] drop1 <- ip1
I0526 17:09:35.279147 13044 net.cpp:397] drop1 -> ip1 (in-place)
I0526 17:09:35.279193 13044 net.cpp:150] Setting up drop1
I0526 17:09:35.279206 13044 net.cpp:157] Top shape: 20 196 (3920)
I0526 17:09:35.279217 13044 net.cpp:165] Memory required for data: 31550480
I0526 17:09:35.279227 13044 layer_factory.hpp:77] Creating layer ip2
I0526 17:09:35.279240 13044 net.cpp:106] Creating Layer ip2
I0526 17:09:35.279250 13044 net.cpp:454] ip2 <- ip1
I0526 17:09:35.279264 13044 net.cpp:411] ip2 -> ip2
I0526 17:09:35.279750 13044 net.cpp:150] Setting up ip2
I0526 17:09:35.279763 13044 net.cpp:157] Top shape: 20 98 (1960)
I0526 17:09:35.279773 13044 net.cpp:165] Memory required for data: 31558320
I0526 17:09:35.279788 13044 layer_factory.hpp:77] Creating layer relu6
I0526 17:09:35.279813 13044 net.cpp:106] Creating Layer relu6
I0526 17:09:35.279822 13044 net.cpp:454] relu6 <- ip2
I0526 17:09:35.279835 13044 net.cpp:397] relu6 -> ip2 (in-place)
I0526 17:09:35.280371 13044 net.cpp:150] Setting up relu6
I0526 17:09:35.280387 13044 net.cpp:157] Top shape: 20 98 (1960)
I0526 17:09:35.280395 13044 net.cpp:165] Memory required for data: 31566160
I0526 17:09:35.280405 13044 layer_factory.hpp:77] Creating layer drop2
I0526 17:09:35.280419 13044 net.cpp:106] Creating Layer drop2
I0526 17:09:35.280428 13044 net.cpp:454] drop2 <- ip2
I0526 17:09:35.280442 13044 net.cpp:397] drop2 -> ip2 (in-place)
I0526 17:09:35.280485 13044 net.cpp:150] Setting up drop2
I0526 17:09:35.280498 13044 net.cpp:157] Top shape: 20 98 (1960)
I0526 17:09:35.280508 13044 net.cpp:165] Memory required for data: 31574000
I0526 17:09:35.280519 13044 layer_factory.hpp:77] Creating layer ip3
I0526 17:09:35.280534 13044 net.cpp:106] Creating Layer ip3
I0526 17:09:35.280544 13044 net.cpp:454] ip3 <- ip2
I0526 17:09:35.280557 13044 net.cpp:411] ip3 -> ip3
I0526 17:09:35.280782 13044 net.cpp:150] Setting up ip3
I0526 17:09:35.280796 13044 net.cpp:157] Top shape: 20 11 (220)
I0526 17:09:35.280805 13044 net.cpp:165] Memory required for data: 31574880
I0526 17:09:35.280820 13044 layer_factory.hpp:77] Creating layer drop3
I0526 17:09:35.280833 13044 net.cpp:106] Creating Layer drop3
I0526 17:09:35.280843 13044 net.cpp:454] drop3 <- ip3
I0526 17:09:35.280855 13044 net.cpp:397] drop3 -> ip3 (in-place)
I0526 17:09:35.280896 13044 net.cpp:150] Setting up drop3
I0526 17:09:35.280908 13044 net.cpp:157] Top shape: 20 11 (220)
I0526 17:09:35.280917 13044 net.cpp:165] Memory required for data: 31575760
I0526 17:09:35.280927 13044 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 17:09:35.280941 13044 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 17:09:35.280951 13044 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 17:09:35.280963 13044 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 17:09:35.280978 13044 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 17:09:35.281052 13044 net.cpp:150] Setting up ip3_drop3_0_split
I0526 17:09:35.281065 13044 net.cpp:157] Top shape: 20 11 (220)
I0526 17:09:35.281077 13044 net.cpp:157] Top shape: 20 11 (220)
I0526 17:09:35.281086 13044 net.cpp:165] Memory required for data: 31577520
I0526 17:09:35.281095 13044 layer_factory.hpp:77] Creating layer accuracy
I0526 17:09:35.281116 13044 net.cpp:106] Creating Layer accuracy
I0526 17:09:35.281127 13044 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 17:09:35.281138 13044 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 17:09:35.281152 13044 net.cpp:411] accuracy -> accuracy
I0526 17:09:35.281175 13044 net.cpp:150] Setting up accuracy
I0526 17:09:35.281188 13044 net.cpp:157] Top shape: (1)
I0526 17:09:35.281198 13044 net.cpp:165] Memory required for data: 31577524
I0526 17:09:35.281208 13044 layer_factory.hpp:77] Creating layer loss
I0526 17:09:35.281221 13044 net.cpp:106] Creating Layer loss
I0526 17:09:35.281232 13044 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 17:09:35.281244 13044 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 17:09:35.281256 13044 net.cpp:411] loss -> loss
I0526 17:09:35.281273 13044 layer_factory.hpp:77] Creating layer loss
I0526 17:09:35.281756 13044 net.cpp:150] Setting up loss
I0526 17:09:35.281770 13044 net.cpp:157] Top shape: (1)
I0526 17:09:35.281780 13044 net.cpp:160]     with loss weight 1
I0526 17:09:35.281798 13044 net.cpp:165] Memory required for data: 31577528
I0526 17:09:35.281808 13044 net.cpp:226] loss needs backward computation.
I0526 17:09:35.281819 13044 net.cpp:228] accuracy does not need backward computation.
I0526 17:09:35.281831 13044 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 17:09:35.281841 13044 net.cpp:226] drop3 needs backward computation.
I0526 17:09:35.281848 13044 net.cpp:226] ip3 needs backward computation.
I0526 17:09:35.281859 13044 net.cpp:226] drop2 needs backward computation.
I0526 17:09:35.281869 13044 net.cpp:226] relu6 needs backward computation.
I0526 17:09:35.281886 13044 net.cpp:226] ip2 needs backward computation.
I0526 17:09:35.281896 13044 net.cpp:226] drop1 needs backward computation.
I0526 17:09:35.281906 13044 net.cpp:226] relu5 needs backward computation.
I0526 17:09:35.281915 13044 net.cpp:226] ip1 needs backward computation.
I0526 17:09:35.281926 13044 net.cpp:226] pool4 needs backward computation.
I0526 17:09:35.281936 13044 net.cpp:226] relu4 needs backward computation.
I0526 17:09:35.281946 13044 net.cpp:226] conv4 needs backward computation.
I0526 17:09:35.281957 13044 net.cpp:226] pool3 needs backward computation.
I0526 17:09:35.281967 13044 net.cpp:226] relu3 needs backward computation.
I0526 17:09:35.281978 13044 net.cpp:226] conv3 needs backward computation.
I0526 17:09:35.281988 13044 net.cpp:226] pool2 needs backward computation.
I0526 17:09:35.281998 13044 net.cpp:226] relu2 needs backward computation.
I0526 17:09:35.282008 13044 net.cpp:226] conv2 needs backward computation.
I0526 17:09:35.282018 13044 net.cpp:226] pool1 needs backward computation.
I0526 17:09:35.282029 13044 net.cpp:226] relu1 needs backward computation.
I0526 17:09:35.282039 13044 net.cpp:226] conv1 needs backward computation.
I0526 17:09:35.282050 13044 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 17:09:35.282063 13044 net.cpp:228] data_hdf5 does not need backward computation.
I0526 17:09:35.282073 13044 net.cpp:270] This network produces output accuracy
I0526 17:09:35.282083 13044 net.cpp:270] This network produces output loss
I0526 17:09:35.282114 13044 net.cpp:283] Network initialization done.
I0526 17:09:35.282246 13044 solver.cpp:60] Solver scaffolding done.
I0526 17:09:35.283381 13044 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_285000.solverstate
I0526 17:09:35.518646 13044 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 17:09:35.524145 13044 caffe.cpp:212] Starting Optimization
I0526 17:09:35.524184 13044 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 17:09:35.524196 13044 solver.cpp:289] Learning Rate Policy: fixed
I0526 17:09:35.525586 13044 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 17:10:28.454637 13044 solver.cpp:409]     Test net output #0: accuracy = 0.89179
I0526 17:10:28.454787 13044 solver.cpp:409]     Test net output #1: loss = 0.354171 (* 1 = 0.354171 loss)
I0526 17:10:28.473881 13044 solver.cpp:237] Iteration 285000, loss = 0.998806
I0526 17:10:28.473918 13044 solver.cpp:253]     Train net output #0: loss = 0.998806 (* 1 = 0.998806 loss)
I0526 17:10:28.473937 13044 sgd_solver.cpp:106] Iteration 285000, lr = 0.003
I0526 17:10:40.642670 13044 solver.cpp:237] Iteration 285750, loss = 0.947095
I0526 17:10:40.642707 13044 solver.cpp:253]     Train net output #0: loss = 0.947095 (* 1 = 0.947095 loss)
I0526 17:10:40.642721 13044 sgd_solver.cpp:106] Iteration 285750, lr = 0.003
I0526 17:10:52.852438 13044 solver.cpp:237] Iteration 286500, loss = 1.27664
I0526 17:10:52.852485 13044 solver.cpp:253]     Train net output #0: loss = 1.27664 (* 1 = 1.27664 loss)
I0526 17:10:52.852499 13044 sgd_solver.cpp:106] Iteration 286500, lr = 0.003
I0526 17:11:05.045938 13044 solver.cpp:237] Iteration 287250, loss = 1.21174
I0526 17:11:05.046087 13044 solver.cpp:253]     Train net output #0: loss = 1.21174 (* 1 = 1.21174 loss)
I0526 17:11:05.046103 13044 sgd_solver.cpp:106] Iteration 287250, lr = 0.003
I0526 17:11:17.190847 13044 solver.cpp:237] Iteration 288000, loss = 1.33805
I0526 17:11:17.190882 13044 solver.cpp:253]     Train net output #0: loss = 1.33805 (* 1 = 1.33805 loss)
I0526 17:11:17.190896 13044 sgd_solver.cpp:106] Iteration 288000, lr = 0.003
I0526 17:11:29.326453 13044 solver.cpp:237] Iteration 288750, loss = 1.38948
I0526 17:11:29.326494 13044 solver.cpp:253]     Train net output #0: loss = 1.38948 (* 1 = 1.38948 loss)
I0526 17:11:29.326508 13044 sgd_solver.cpp:106] Iteration 288750, lr = 0.003
I0526 17:11:41.480646 13044 solver.cpp:237] Iteration 289500, loss = 1.50548
I0526 17:11:41.480798 13044 solver.cpp:253]     Train net output #0: loss = 1.50548 (* 1 = 1.50548 loss)
I0526 17:11:41.480811 13044 sgd_solver.cpp:106] Iteration 289500, lr = 0.003
I0526 17:12:15.726447 13044 solver.cpp:237] Iteration 290250, loss = 1.07217
I0526 17:12:15.726604 13044 solver.cpp:253]     Train net output #0: loss = 1.07217 (* 1 = 1.07217 loss)
I0526 17:12:15.726619 13044 sgd_solver.cpp:106] Iteration 290250, lr = 0.003
I0526 17:12:27.756865 13044 solver.cpp:237] Iteration 291000, loss = 1.28216
I0526 17:12:27.756901 13044 solver.cpp:253]     Train net output #0: loss = 1.28216 (* 1 = 1.28216 loss)
I0526 17:12:27.756918 13044 sgd_solver.cpp:106] Iteration 291000, lr = 0.003
I0526 17:12:39.863662 13044 solver.cpp:237] Iteration 291750, loss = 1.73413
I0526 17:12:39.863709 13044 solver.cpp:253]     Train net output #0: loss = 1.73413 (* 1 = 1.73413 loss)
I0526 17:12:39.863723 13044 sgd_solver.cpp:106] Iteration 291750, lr = 0.003
I0526 17:12:51.978421 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_292500.caffemodel
I0526 17:12:52.029634 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_292500.solverstate
I0526 17:12:52.061790 13044 solver.cpp:237] Iteration 292500, loss = 0.977467
I0526 17:12:52.061838 13044 solver.cpp:253]     Train net output #0: loss = 0.977467 (* 1 = 0.977467 loss)
I0526 17:12:52.061858 13044 sgd_solver.cpp:106] Iteration 292500, lr = 0.003
I0526 17:13:04.178136 13044 solver.cpp:237] Iteration 293250, loss = 1.56379
I0526 17:13:04.178182 13044 solver.cpp:253]     Train net output #0: loss = 1.56379 (* 1 = 1.56379 loss)
I0526 17:13:04.178196 13044 sgd_solver.cpp:106] Iteration 293250, lr = 0.003
I0526 17:13:16.305904 13044 solver.cpp:237] Iteration 294000, loss = 0.994585
I0526 17:13:16.305941 13044 solver.cpp:253]     Train net output #0: loss = 0.994584 (* 1 = 0.994584 loss)
I0526 17:13:16.305958 13044 sgd_solver.cpp:106] Iteration 294000, lr = 0.003
I0526 17:13:28.441682 13044 solver.cpp:237] Iteration 294750, loss = 1.01154
I0526 17:13:28.441835 13044 solver.cpp:253]     Train net output #0: loss = 1.01154 (* 1 = 1.01154 loss)
I0526 17:13:28.441850 13044 sgd_solver.cpp:106] Iteration 294750, lr = 0.003
I0526 17:14:02.704202 13044 solver.cpp:237] Iteration 295500, loss = 1.13748
I0526 17:14:02.704376 13044 solver.cpp:253]     Train net output #0: loss = 1.13748 (* 1 = 1.13748 loss)
I0526 17:14:02.704392 13044 sgd_solver.cpp:106] Iteration 295500, lr = 0.003
I0526 17:14:14.880928 13044 solver.cpp:237] Iteration 296250, loss = 1.17282
I0526 17:14:14.880971 13044 solver.cpp:253]     Train net output #0: loss = 1.17282 (* 1 = 1.17282 loss)
I0526 17:14:14.880985 13044 sgd_solver.cpp:106] Iteration 296250, lr = 0.003
I0526 17:14:26.998409 13044 solver.cpp:237] Iteration 297000, loss = 1.00469
I0526 17:14:26.998445 13044 solver.cpp:253]     Train net output #0: loss = 1.00469 (* 1 = 1.00469 loss)
I0526 17:14:26.998458 13044 sgd_solver.cpp:106] Iteration 297000, lr = 0.003
I0526 17:14:39.116155 13044 solver.cpp:237] Iteration 297750, loss = 1.34449
I0526 17:14:39.116303 13044 solver.cpp:253]     Train net output #0: loss = 1.34449 (* 1 = 1.34449 loss)
I0526 17:14:39.116317 13044 sgd_solver.cpp:106] Iteration 297750, lr = 0.003
I0526 17:14:51.313760 13044 solver.cpp:237] Iteration 298500, loss = 1.19993
I0526 17:14:51.313796 13044 solver.cpp:253]     Train net output #0: loss = 1.19993 (* 1 = 1.19993 loss)
I0526 17:14:51.313809 13044 sgd_solver.cpp:106] Iteration 298500, lr = 0.003
I0526 17:15:03.433595 13044 solver.cpp:237] Iteration 299250, loss = 1.34312
I0526 17:15:03.433645 13044 solver.cpp:253]     Train net output #0: loss = 1.34312 (* 1 = 1.34312 loss)
I0526 17:15:03.433658 13044 sgd_solver.cpp:106] Iteration 299250, lr = 0.003
I0526 17:15:15.495087 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_300000.caffemodel
I0526 17:15:15.545728 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_300000.solverstate
I0526 17:15:15.572662 13044 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 17:16:07.647707 13044 solver.cpp:409]     Test net output #0: accuracy = 0.900713
I0526 17:16:07.647863 13044 solver.cpp:409]     Test net output #1: loss = 0.320295 (* 1 = 0.320295 loss)
I0526 17:16:29.791929 13044 solver.cpp:237] Iteration 300000, loss = 1.51221
I0526 17:16:29.791982 13044 solver.cpp:253]     Train net output #0: loss = 1.51221 (* 1 = 1.51221 loss)
I0526 17:16:29.792002 13044 sgd_solver.cpp:106] Iteration 300000, lr = 0.003
I0526 17:16:41.961292 13044 solver.cpp:237] Iteration 300750, loss = 1.18061
I0526 17:16:41.961438 13044 solver.cpp:253]     Train net output #0: loss = 1.18061 (* 1 = 1.18061 loss)
I0526 17:16:41.961452 13044 sgd_solver.cpp:106] Iteration 300750, lr = 0.003
I0526 17:16:54.106297 13044 solver.cpp:237] Iteration 301500, loss = 1.36739
I0526 17:16:54.106343 13044 solver.cpp:253]     Train net output #0: loss = 1.36739 (* 1 = 1.36739 loss)
I0526 17:16:54.106355 13044 sgd_solver.cpp:106] Iteration 301500, lr = 0.003
I0526 17:17:06.278707 13044 solver.cpp:237] Iteration 302250, loss = 1.21429
I0526 17:17:06.278743 13044 solver.cpp:253]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0526 17:17:06.278761 13044 sgd_solver.cpp:106] Iteration 302250, lr = 0.003
I0526 17:17:18.467027 13044 solver.cpp:237] Iteration 303000, loss = 1.57143
I0526 17:17:18.467172 13044 solver.cpp:253]     Train net output #0: loss = 1.57143 (* 1 = 1.57143 loss)
I0526 17:17:18.467186 13044 sgd_solver.cpp:106] Iteration 303000, lr = 0.003
I0526 17:17:30.632360 13044 solver.cpp:237] Iteration 303750, loss = 1.58517
I0526 17:17:30.632396 13044 solver.cpp:253]     Train net output #0: loss = 1.58517 (* 1 = 1.58517 loss)
I0526 17:17:30.632411 13044 sgd_solver.cpp:106] Iteration 303750, lr = 0.003
I0526 17:17:42.759685 13044 solver.cpp:237] Iteration 304500, loss = 1.24108
I0526 17:17:42.759732 13044 solver.cpp:253]     Train net output #0: loss = 1.24108 (* 1 = 1.24108 loss)
I0526 17:17:42.759745 13044 sgd_solver.cpp:106] Iteration 304500, lr = 0.003
I0526 17:18:17.127059 13044 solver.cpp:237] Iteration 305250, loss = 1.03101
I0526 17:18:17.127233 13044 solver.cpp:253]     Train net output #0: loss = 1.03101 (* 1 = 1.03101 loss)
I0526 17:18:17.127246 13044 sgd_solver.cpp:106] Iteration 305250, lr = 0.003
I0526 17:18:29.269071 13044 solver.cpp:237] Iteration 306000, loss = 1.15914
I0526 17:18:29.269119 13044 solver.cpp:253]     Train net output #0: loss = 1.15914 (* 1 = 1.15914 loss)
I0526 17:18:29.269134 13044 sgd_solver.cpp:106] Iteration 306000, lr = 0.003
I0526 17:18:41.392344 13044 solver.cpp:237] Iteration 306750, loss = 0.724354
I0526 17:18:41.392381 13044 solver.cpp:253]     Train net output #0: loss = 0.724354 (* 1 = 0.724354 loss)
I0526 17:18:41.392395 13044 sgd_solver.cpp:106] Iteration 306750, lr = 0.003
I0526 17:18:53.542973 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_307500.caffemodel
I0526 17:18:53.594717 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_307500.solverstate
I0526 17:18:53.627264 13044 solver.cpp:237] Iteration 307500, loss = 1.13654
I0526 17:18:53.627310 13044 solver.cpp:253]     Train net output #0: loss = 1.13654 (* 1 = 1.13654 loss)
I0526 17:18:53.627332 13044 sgd_solver.cpp:106] Iteration 307500, lr = 0.003
I0526 17:19:05.822057 13044 solver.cpp:237] Iteration 308250, loss = 1.08484
I0526 17:19:05.822093 13044 solver.cpp:253]     Train net output #0: loss = 1.08484 (* 1 = 1.08484 loss)
I0526 17:19:05.822106 13044 sgd_solver.cpp:106] Iteration 308250, lr = 0.003
I0526 17:19:18.001127 13044 solver.cpp:237] Iteration 309000, loss = 0.960372
I0526 17:19:18.001176 13044 solver.cpp:253]     Train net output #0: loss = 0.960372 (* 1 = 0.960372 loss)
I0526 17:19:18.001190 13044 sgd_solver.cpp:106] Iteration 309000, lr = 0.003
I0526 17:19:30.188189 13044 solver.cpp:237] Iteration 309750, loss = 1.08038
I0526 17:19:30.188333 13044 solver.cpp:253]     Train net output #0: loss = 1.08038 (* 1 = 1.08038 loss)
I0526 17:19:30.188346 13044 sgd_solver.cpp:106] Iteration 309750, lr = 0.003
I0526 17:20:04.601728 13044 solver.cpp:237] Iteration 310500, loss = 0.967377
I0526 17:20:04.601889 13044 solver.cpp:253]     Train net output #0: loss = 0.967378 (* 1 = 0.967378 loss)
I0526 17:20:04.601904 13044 sgd_solver.cpp:106] Iteration 310500, lr = 0.003
I0526 17:20:16.817890 13044 solver.cpp:237] Iteration 311250, loss = 1.47516
I0526 17:20:16.817926 13044 solver.cpp:253]     Train net output #0: loss = 1.47516 (* 1 = 1.47516 loss)
I0526 17:20:16.817942 13044 sgd_solver.cpp:106] Iteration 311250, lr = 0.003
I0526 17:20:29.019881 13044 solver.cpp:237] Iteration 312000, loss = 0.553591
I0526 17:20:29.019927 13044 solver.cpp:253]     Train net output #0: loss = 0.553591 (* 1 = 0.553591 loss)
I0526 17:20:29.019942 13044 sgd_solver.cpp:106] Iteration 312000, lr = 0.003
I0526 17:20:41.198196 13044 solver.cpp:237] Iteration 312750, loss = 1.15078
I0526 17:20:41.198335 13044 solver.cpp:253]     Train net output #0: loss = 1.15078 (* 1 = 1.15078 loss)
I0526 17:20:41.198350 13044 sgd_solver.cpp:106] Iteration 312750, lr = 0.003
I0526 17:20:53.373554 13044 solver.cpp:237] Iteration 313500, loss = 1.21005
I0526 17:20:53.373596 13044 solver.cpp:253]     Train net output #0: loss = 1.21005 (* 1 = 1.21005 loss)
I0526 17:20:53.373610 13044 sgd_solver.cpp:106] Iteration 313500, lr = 0.003
I0526 17:21:05.518668 13044 solver.cpp:237] Iteration 314250, loss = 0.900454
I0526 17:21:05.518705 13044 solver.cpp:253]     Train net output #0: loss = 0.900454 (* 1 = 0.900454 loss)
I0526 17:21:05.518723 13044 sgd_solver.cpp:106] Iteration 314250, lr = 0.003
I0526 17:21:17.684160 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_315000.caffemodel
I0526 17:21:17.739445 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_315000.solverstate
I0526 17:21:17.768015 13044 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 17:22:30.593304 13044 solver.cpp:409]     Test net output #0: accuracy = 0.900705
I0526 17:22:30.593462 13044 solver.cpp:409]     Test net output #1: loss = 0.332445 (* 1 = 0.332445 loss)
I0526 17:22:52.784674 13044 solver.cpp:237] Iteration 315000, loss = 1.32739
I0526 17:22:52.784728 13044 solver.cpp:253]     Train net output #0: loss = 1.32739 (* 1 = 1.32739 loss)
I0526 17:22:52.784744 13044 sgd_solver.cpp:106] Iteration 315000, lr = 0.003
I0526 17:23:05.016175 13044 solver.cpp:237] Iteration 315750, loss = 0.892993
I0526 17:23:05.016336 13044 solver.cpp:253]     Train net output #0: loss = 0.892993 (* 1 = 0.892993 loss)
I0526 17:23:05.016352 13044 sgd_solver.cpp:106] Iteration 315750, lr = 0.003
I0526 17:23:17.270277 13044 solver.cpp:237] Iteration 316500, loss = 1.23131
I0526 17:23:17.270314 13044 solver.cpp:253]     Train net output #0: loss = 1.23131 (* 1 = 1.23131 loss)
I0526 17:23:17.270328 13044 sgd_solver.cpp:106] Iteration 316500, lr = 0.003
I0526 17:23:29.518450 13044 solver.cpp:237] Iteration 317250, loss = 1.30484
I0526 17:23:29.518498 13044 solver.cpp:253]     Train net output #0: loss = 1.30484 (* 1 = 1.30484 loss)
I0526 17:23:29.518512 13044 sgd_solver.cpp:106] Iteration 317250, lr = 0.003
I0526 17:23:41.751785 13044 solver.cpp:237] Iteration 318000, loss = 1.05274
I0526 17:23:41.751925 13044 solver.cpp:253]     Train net output #0: loss = 1.05274 (* 1 = 1.05274 loss)
I0526 17:23:41.751941 13044 sgd_solver.cpp:106] Iteration 318000, lr = 0.003
I0526 17:23:53.872783 13044 solver.cpp:237] Iteration 318750, loss = 1.32404
I0526 17:23:53.872829 13044 solver.cpp:253]     Train net output #0: loss = 1.32404 (* 1 = 1.32404 loss)
I0526 17:23:53.872843 13044 sgd_solver.cpp:106] Iteration 318750, lr = 0.003
I0526 17:24:05.987704 13044 solver.cpp:237] Iteration 319500, loss = 1.28959
I0526 17:24:05.987741 13044 solver.cpp:253]     Train net output #0: loss = 1.28959 (* 1 = 1.28959 loss)
I0526 17:24:05.987754 13044 sgd_solver.cpp:106] Iteration 319500, lr = 0.003
I0526 17:24:40.353236 13044 solver.cpp:237] Iteration 320250, loss = 1.03703
I0526 17:24:40.353396 13044 solver.cpp:253]     Train net output #0: loss = 1.03703 (* 1 = 1.03703 loss)
I0526 17:24:40.353410 13044 sgd_solver.cpp:106] Iteration 320250, lr = 0.003
I0526 17:24:52.520519 13044 solver.cpp:237] Iteration 321000, loss = 1.15977
I0526 17:24:52.520553 13044 solver.cpp:253]     Train net output #0: loss = 1.15977 (* 1 = 1.15977 loss)
I0526 17:24:52.520572 13044 sgd_solver.cpp:106] Iteration 321000, lr = 0.003
I0526 17:25:04.686146 13044 solver.cpp:237] Iteration 321750, loss = 1.2323
I0526 17:25:04.686194 13044 solver.cpp:253]     Train net output #0: loss = 1.2323 (* 1 = 1.2323 loss)
I0526 17:25:04.686209 13044 sgd_solver.cpp:106] Iteration 321750, lr = 0.003
I0526 17:25:16.796968 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_322500.caffemodel
I0526 17:25:16.848286 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_322500.solverstate
I0526 17:25:16.880774 13044 solver.cpp:237] Iteration 322500, loss = 1.39466
I0526 17:25:16.880825 13044 solver.cpp:253]     Train net output #0: loss = 1.39466 (* 1 = 1.39466 loss)
I0526 17:25:16.880838 13044 sgd_solver.cpp:106] Iteration 322500, lr = 0.003
I0526 17:25:28.999831 13044 solver.cpp:237] Iteration 323250, loss = 1.12936
I0526 17:25:28.999873 13044 solver.cpp:253]     Train net output #0: loss = 1.12936 (* 1 = 1.12936 loss)
I0526 17:25:28.999891 13044 sgd_solver.cpp:106] Iteration 323250, lr = 0.003
I0526 17:25:41.190806 13044 solver.cpp:237] Iteration 324000, loss = 1.12155
I0526 17:25:41.190841 13044 solver.cpp:253]     Train net output #0: loss = 1.12155 (* 1 = 1.12155 loss)
I0526 17:25:41.190855 13044 sgd_solver.cpp:106] Iteration 324000, lr = 0.003
I0526 17:25:53.395112 13044 solver.cpp:237] Iteration 324750, loss = 0.817573
I0526 17:25:53.395275 13044 solver.cpp:253]     Train net output #0: loss = 0.817573 (* 1 = 0.817573 loss)
I0526 17:25:53.395290 13044 sgd_solver.cpp:106] Iteration 324750, lr = 0.003
I0526 17:26:27.780221 13044 solver.cpp:237] Iteration 325500, loss = 1.36044
I0526 17:26:27.780380 13044 solver.cpp:253]     Train net output #0: loss = 1.36044 (* 1 = 1.36044 loss)
I0526 17:26:27.780393 13044 sgd_solver.cpp:106] Iteration 325500, lr = 0.003
I0526 17:26:40.031388 13044 solver.cpp:237] Iteration 326250, loss = 1.5897
I0526 17:26:40.031424 13044 solver.cpp:253]     Train net output #0: loss = 1.5897 (* 1 = 1.5897 loss)
I0526 17:26:40.031440 13044 sgd_solver.cpp:106] Iteration 326250, lr = 0.003
I0526 17:26:52.253146 13044 solver.cpp:237] Iteration 327000, loss = 1.43915
I0526 17:26:52.253195 13044 solver.cpp:253]     Train net output #0: loss = 1.43915 (* 1 = 1.43915 loss)
I0526 17:26:52.253207 13044 sgd_solver.cpp:106] Iteration 327000, lr = 0.003
I0526 17:27:04.463348 13044 solver.cpp:237] Iteration 327750, loss = 1.25485
I0526 17:27:04.463490 13044 solver.cpp:253]     Train net output #0: loss = 1.25485 (* 1 = 1.25485 loss)
I0526 17:27:04.463505 13044 sgd_solver.cpp:106] Iteration 327750, lr = 0.003
I0526 17:27:16.715497 13044 solver.cpp:237] Iteration 328500, loss = 1.20957
I0526 17:27:16.715548 13044 solver.cpp:253]     Train net output #0: loss = 1.20957 (* 1 = 1.20957 loss)
I0526 17:27:16.715564 13044 sgd_solver.cpp:106] Iteration 328500, lr = 0.003
I0526 17:27:28.965765 13044 solver.cpp:237] Iteration 329250, loss = 0.673459
I0526 17:27:28.965802 13044 solver.cpp:253]     Train net output #0: loss = 0.673458 (* 1 = 0.673458 loss)
I0526 17:27:28.965818 13044 sgd_solver.cpp:106] Iteration 329250, lr = 0.003
I0526 17:27:41.204757 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_330000.caffemodel
I0526 17:27:41.253684 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_330000.solverstate
I0526 17:27:41.279036 13044 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 17:28:32.904209 13044 solver.cpp:409]     Test net output #0: accuracy = 0.901665
I0526 17:28:32.904369 13044 solver.cpp:409]     Test net output #1: loss = 0.315917 (* 1 = 0.315917 loss)
I0526 17:28:55.091327 13044 solver.cpp:237] Iteration 330000, loss = 0.744852
I0526 17:28:55.091380 13044 solver.cpp:253]     Train net output #0: loss = 0.744852 (* 1 = 0.744852 loss)
I0526 17:28:55.091394 13044 sgd_solver.cpp:106] Iteration 330000, lr = 0.003
I0526 17:29:07.324777 13044 solver.cpp:237] Iteration 330750, loss = 1.23216
I0526 17:29:07.324930 13044 solver.cpp:253]     Train net output #0: loss = 1.23216 (* 1 = 1.23216 loss)
I0526 17:29:07.324944 13044 sgd_solver.cpp:106] Iteration 330750, lr = 0.003
I0526 17:29:19.503114 13044 solver.cpp:237] Iteration 331500, loss = 1.12076
I0526 17:29:19.503157 13044 solver.cpp:253]     Train net output #0: loss = 1.12076 (* 1 = 1.12076 loss)
I0526 17:29:19.503175 13044 sgd_solver.cpp:106] Iteration 331500, lr = 0.003
I0526 17:29:31.674363 13044 solver.cpp:237] Iteration 332250, loss = 1.112
I0526 17:29:31.674399 13044 solver.cpp:253]     Train net output #0: loss = 1.112 (* 1 = 1.112 loss)
I0526 17:29:31.674417 13044 sgd_solver.cpp:106] Iteration 332250, lr = 0.003
I0526 17:29:43.882048 13044 solver.cpp:237] Iteration 333000, loss = 1.13057
I0526 17:29:43.882203 13044 solver.cpp:253]     Train net output #0: loss = 1.13057 (* 1 = 1.13057 loss)
I0526 17:29:43.882218 13044 sgd_solver.cpp:106] Iteration 333000, lr = 0.003
I0526 17:29:56.095525 13044 solver.cpp:237] Iteration 333750, loss = 1.3402
I0526 17:29:56.095561 13044 solver.cpp:253]     Train net output #0: loss = 1.3402 (* 1 = 1.3402 loss)
I0526 17:29:56.095574 13044 sgd_solver.cpp:106] Iteration 333750, lr = 0.003
I0526 17:30:08.288177 13044 solver.cpp:237] Iteration 334500, loss = 1.18919
I0526 17:30:08.288219 13044 solver.cpp:253]     Train net output #0: loss = 1.18919 (* 1 = 1.18919 loss)
I0526 17:30:08.288233 13044 sgd_solver.cpp:106] Iteration 334500, lr = 0.003
I0526 17:30:42.718163 13044 solver.cpp:237] Iteration 335250, loss = 1.34548
I0526 17:30:42.718333 13044 solver.cpp:253]     Train net output #0: loss = 1.34548 (* 1 = 1.34548 loss)
I0526 17:30:42.718346 13044 sgd_solver.cpp:106] Iteration 335250, lr = 0.003
I0526 17:30:54.902815 13044 solver.cpp:237] Iteration 336000, loss = 0.68084
I0526 17:30:54.902858 13044 solver.cpp:253]     Train net output #0: loss = 0.68084 (* 1 = 0.68084 loss)
I0526 17:30:54.902873 13044 sgd_solver.cpp:106] Iteration 336000, lr = 0.003
I0526 17:31:07.098273 13044 solver.cpp:237] Iteration 336750, loss = 1.44101
I0526 17:31:07.098309 13044 solver.cpp:253]     Train net output #0: loss = 1.44101 (* 1 = 1.44101 loss)
I0526 17:31:07.098322 13044 sgd_solver.cpp:106] Iteration 336750, lr = 0.003
I0526 17:31:19.315024 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_337500.caffemodel
I0526 17:31:19.364969 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_337500.solverstate
I0526 17:31:19.395701 13044 solver.cpp:237] Iteration 337500, loss = 1.17846
I0526 17:31:19.395745 13044 solver.cpp:253]     Train net output #0: loss = 1.17846 (* 1 = 1.17846 loss)
I0526 17:31:19.395758 13044 sgd_solver.cpp:106] Iteration 337500, lr = 0.003
I0526 17:31:31.652283 13044 solver.cpp:237] Iteration 338250, loss = 1.13049
I0526 17:31:31.652319 13044 solver.cpp:253]     Train net output #0: loss = 1.13048 (* 1 = 1.13048 loss)
I0526 17:31:31.652338 13044 sgd_solver.cpp:106] Iteration 338250, lr = 0.003
I0526 17:31:43.856911 13044 solver.cpp:237] Iteration 339000, loss = 1.37215
I0526 17:31:43.856956 13044 solver.cpp:253]     Train net output #0: loss = 1.37215 (* 1 = 1.37215 loss)
I0526 17:31:43.856969 13044 sgd_solver.cpp:106] Iteration 339000, lr = 0.003
I0526 17:31:56.084657 13044 solver.cpp:237] Iteration 339750, loss = 1.17176
I0526 17:31:56.084806 13044 solver.cpp:253]     Train net output #0: loss = 1.17176 (* 1 = 1.17176 loss)
I0526 17:31:56.084820 13044 sgd_solver.cpp:106] Iteration 339750, lr = 0.003
I0526 17:32:30.489496 13044 solver.cpp:237] Iteration 340500, loss = 0.998881
I0526 17:32:30.489667 13044 solver.cpp:253]     Train net output #0: loss = 0.998881 (* 1 = 0.998881 loss)
I0526 17:32:30.489683 13044 sgd_solver.cpp:106] Iteration 340500, lr = 0.003
I0526 17:32:42.700670 13044 solver.cpp:237] Iteration 341250, loss = 1.39877
I0526 17:32:42.700716 13044 solver.cpp:253]     Train net output #0: loss = 1.39877 (* 1 = 1.39877 loss)
I0526 17:32:42.700729 13044 sgd_solver.cpp:106] Iteration 341250, lr = 0.003
I0526 17:32:54.908038 13044 solver.cpp:237] Iteration 342000, loss = 1.64981
I0526 17:32:54.908074 13044 solver.cpp:253]     Train net output #0: loss = 1.64981 (* 1 = 1.64981 loss)
I0526 17:32:54.908092 13044 sgd_solver.cpp:106] Iteration 342000, lr = 0.003
I0526 17:33:07.116801 13044 solver.cpp:237] Iteration 342750, loss = 1.12694
I0526 17:33:07.116955 13044 solver.cpp:253]     Train net output #0: loss = 1.12694 (* 1 = 1.12694 loss)
I0526 17:33:07.116971 13044 sgd_solver.cpp:106] Iteration 342750, lr = 0.003
I0526 17:33:19.327028 13044 solver.cpp:237] Iteration 343500, loss = 1.03107
I0526 17:33:19.327064 13044 solver.cpp:253]     Train net output #0: loss = 1.03107 (* 1 = 1.03107 loss)
I0526 17:33:19.327076 13044 sgd_solver.cpp:106] Iteration 343500, lr = 0.003
I0526 17:33:31.541635 13044 solver.cpp:237] Iteration 344250, loss = 1.38234
I0526 17:33:31.541678 13044 solver.cpp:253]     Train net output #0: loss = 1.38234 (* 1 = 1.38234 loss)
I0526 17:33:31.541692 13044 sgd_solver.cpp:106] Iteration 344250, lr = 0.003
I0526 17:33:43.766204 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_345000.caffemodel
I0526 17:33:43.815940 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_345000.solverstate
I0526 17:33:43.841156 13044 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 17:34:56.585690 13044 solver.cpp:409]     Test net output #0: accuracy = 0.899713
I0526 17:34:56.585855 13044 solver.cpp:409]     Test net output #1: loss = 0.31774 (* 1 = 0.31774 loss)
I0526 17:35:18.790488 13044 solver.cpp:237] Iteration 345000, loss = 0.724518
I0526 17:35:18.790540 13044 solver.cpp:253]     Train net output #0: loss = 0.724517 (* 1 = 0.724517 loss)
I0526 17:35:18.790555 13044 sgd_solver.cpp:106] Iteration 345000, lr = 0.003
I0526 17:35:31.024565 13044 solver.cpp:237] Iteration 345750, loss = 0.906174
I0526 17:35:31.024749 13044 solver.cpp:253]     Train net output #0: loss = 0.906173 (* 1 = 0.906173 loss)
I0526 17:35:31.024765 13044 sgd_solver.cpp:106] Iteration 345750, lr = 0.003
I0526 17:35:43.225497 13044 solver.cpp:237] Iteration 346500, loss = 0.753953
I0526 17:35:43.225534 13044 solver.cpp:253]     Train net output #0: loss = 0.753952 (* 1 = 0.753952 loss)
I0526 17:35:43.225549 13044 sgd_solver.cpp:106] Iteration 346500, lr = 0.003
I0526 17:35:55.430748 13044 solver.cpp:237] Iteration 347250, loss = 0.78218
I0526 17:35:55.430795 13044 solver.cpp:253]     Train net output #0: loss = 0.782179 (* 1 = 0.782179 loss)
I0526 17:35:55.430812 13044 sgd_solver.cpp:106] Iteration 347250, lr = 0.003
I0526 17:36:07.594759 13044 solver.cpp:237] Iteration 348000, loss = 0.931668
I0526 17:36:07.594905 13044 solver.cpp:253]     Train net output #0: loss = 0.931667 (* 1 = 0.931667 loss)
I0526 17:36:07.594920 13044 sgd_solver.cpp:106] Iteration 348000, lr = 0.003
I0526 17:36:19.752774 13044 solver.cpp:237] Iteration 348750, loss = 0.921782
I0526 17:36:19.752822 13044 solver.cpp:253]     Train net output #0: loss = 0.921781 (* 1 = 0.921781 loss)
I0526 17:36:19.752837 13044 sgd_solver.cpp:106] Iteration 348750, lr = 0.003
I0526 17:36:31.949440 13044 solver.cpp:237] Iteration 349500, loss = 0.957321
I0526 17:36:31.949476 13044 solver.cpp:253]     Train net output #0: loss = 0.957321 (* 1 = 0.957321 loss)
I0526 17:36:31.949489 13044 sgd_solver.cpp:106] Iteration 349500, lr = 0.003
I0526 17:37:06.457989 13044 solver.cpp:237] Iteration 350250, loss = 1.2503
I0526 17:37:06.458171 13044 solver.cpp:253]     Train net output #0: loss = 1.2503 (* 1 = 1.2503 loss)
I0526 17:37:06.458186 13044 sgd_solver.cpp:106] Iteration 350250, lr = 0.003
I0526 17:37:18.666529 13044 solver.cpp:237] Iteration 351000, loss = 1.29962
I0526 17:37:18.666576 13044 solver.cpp:253]     Train net output #0: loss = 1.29962 (* 1 = 1.29962 loss)
I0526 17:37:18.666591 13044 sgd_solver.cpp:106] Iteration 351000, lr = 0.003
I0526 17:37:30.852520 13044 solver.cpp:237] Iteration 351750, loss = 1.34498
I0526 17:37:30.852556 13044 solver.cpp:253]     Train net output #0: loss = 1.34498 (* 1 = 1.34498 loss)
I0526 17:37:30.852569 13044 sgd_solver.cpp:106] Iteration 351750, lr = 0.003
I0526 17:37:43.025568 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_352500.caffemodel
I0526 17:37:43.076622 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_352500.solverstate
I0526 17:37:43.109589 13044 solver.cpp:237] Iteration 352500, loss = 1.14193
I0526 17:37:43.109640 13044 solver.cpp:253]     Train net output #0: loss = 1.14193 (* 1 = 1.14193 loss)
I0526 17:37:43.109657 13044 sgd_solver.cpp:106] Iteration 352500, lr = 0.003
I0526 17:37:55.322341 13044 solver.cpp:237] Iteration 353250, loss = 0.64558
I0526 17:37:55.322378 13044 solver.cpp:253]     Train net output #0: loss = 0.64558 (* 1 = 0.64558 loss)
I0526 17:37:55.322394 13044 sgd_solver.cpp:106] Iteration 353250, lr = 0.003
I0526 17:38:07.543016 13044 solver.cpp:237] Iteration 354000, loss = 2.03822
I0526 17:38:07.543064 13044 solver.cpp:253]     Train net output #0: loss = 2.03822 (* 1 = 2.03822 loss)
I0526 17:38:07.543077 13044 sgd_solver.cpp:106] Iteration 354000, lr = 0.003
I0526 17:38:19.771970 13044 solver.cpp:237] Iteration 354750, loss = 1.07072
I0526 17:38:19.772130 13044 solver.cpp:253]     Train net output #0: loss = 1.07072 (* 1 = 1.07072 loss)
I0526 17:38:19.772143 13044 sgd_solver.cpp:106] Iteration 354750, lr = 0.003
I0526 17:38:54.210944 13044 solver.cpp:237] Iteration 355500, loss = 0.927447
I0526 17:38:54.211114 13044 solver.cpp:253]     Train net output #0: loss = 0.927447 (* 1 = 0.927447 loss)
I0526 17:38:54.211130 13044 sgd_solver.cpp:106] Iteration 355500, lr = 0.003
I0526 17:39:06.417238 13044 solver.cpp:237] Iteration 356250, loss = 1.34357
I0526 17:39:06.417274 13044 solver.cpp:253]     Train net output #0: loss = 1.34357 (* 1 = 1.34357 loss)
I0526 17:39:06.417291 13044 sgd_solver.cpp:106] Iteration 356250, lr = 0.003
I0526 17:39:18.598613 13044 solver.cpp:237] Iteration 357000, loss = 1.35727
I0526 17:39:18.598659 13044 solver.cpp:253]     Train net output #0: loss = 1.35727 (* 1 = 1.35727 loss)
I0526 17:39:18.598675 13044 sgd_solver.cpp:106] Iteration 357000, lr = 0.003
I0526 17:39:30.839843 13044 solver.cpp:237] Iteration 357750, loss = 1.56036
I0526 17:39:30.840003 13044 solver.cpp:253]     Train net output #0: loss = 1.56036 (* 1 = 1.56036 loss)
I0526 17:39:30.840018 13044 sgd_solver.cpp:106] Iteration 357750, lr = 0.003
I0526 17:39:43.077730 13044 solver.cpp:237] Iteration 358500, loss = 0.784482
I0526 17:39:43.077780 13044 solver.cpp:253]     Train net output #0: loss = 0.784481 (* 1 = 0.784481 loss)
I0526 17:39:43.077795 13044 sgd_solver.cpp:106] Iteration 358500, lr = 0.003
I0526 17:39:55.206418 13044 solver.cpp:237] Iteration 359250, loss = 1.29388
I0526 17:39:55.206454 13044 solver.cpp:253]     Train net output #0: loss = 1.29388 (* 1 = 1.29388 loss)
I0526 17:39:55.206470 13044 sgd_solver.cpp:106] Iteration 359250, lr = 0.003
I0526 17:40:07.362228 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_360000.caffemodel
I0526 17:40:07.413780 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_360000.solverstate
I0526 17:40:07.441514 13044 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 17:40:59.461305 13044 solver.cpp:409]     Test net output #0: accuracy = 0.901651
I0526 17:40:59.461468 13044 solver.cpp:409]     Test net output #1: loss = 0.319987 (* 1 = 0.319987 loss)
I0526 17:41:20.358142 13044 solver.cpp:237] Iteration 360000, loss = 1.132
I0526 17:41:20.358194 13044 solver.cpp:253]     Train net output #0: loss = 1.132 (* 1 = 1.132 loss)
I0526 17:41:20.358208 13044 sgd_solver.cpp:106] Iteration 360000, lr = 0.003
I0526 17:41:32.520293 13044 solver.cpp:237] Iteration 360750, loss = 0.964927
I0526 17:41:32.520447 13044 solver.cpp:253]     Train net output #0: loss = 0.964926 (* 1 = 0.964926 loss)
I0526 17:41:32.520462 13044 sgd_solver.cpp:106] Iteration 360750, lr = 0.003
I0526 17:41:44.686619 13044 solver.cpp:237] Iteration 361500, loss = 1.35942
I0526 17:41:44.686667 13044 solver.cpp:253]     Train net output #0: loss = 1.35942 (* 1 = 1.35942 loss)
I0526 17:41:44.686683 13044 sgd_solver.cpp:106] Iteration 361500, lr = 0.003
I0526 17:41:56.878377 13044 solver.cpp:237] Iteration 362250, loss = 0.975466
I0526 17:41:56.878414 13044 solver.cpp:253]     Train net output #0: loss = 0.975465 (* 1 = 0.975465 loss)
I0526 17:41:56.878432 13044 sgd_solver.cpp:106] Iteration 362250, lr = 0.003
I0526 17:42:09.080292 13044 solver.cpp:237] Iteration 363000, loss = 0.841046
I0526 17:42:09.080462 13044 solver.cpp:253]     Train net output #0: loss = 0.841045 (* 1 = 0.841045 loss)
I0526 17:42:09.080476 13044 sgd_solver.cpp:106] Iteration 363000, lr = 0.003
I0526 17:42:21.271442 13044 solver.cpp:237] Iteration 363750, loss = 1.20024
I0526 17:42:21.271478 13044 solver.cpp:253]     Train net output #0: loss = 1.20024 (* 1 = 1.20024 loss)
I0526 17:42:21.271492 13044 sgd_solver.cpp:106] Iteration 363750, lr = 0.003
I0526 17:42:33.459985 13044 solver.cpp:237] Iteration 364500, loss = 1.30474
I0526 17:42:33.460022 13044 solver.cpp:253]     Train net output #0: loss = 1.30474 (* 1 = 1.30474 loss)
I0526 17:42:33.460041 13044 sgd_solver.cpp:106] Iteration 364500, lr = 0.003
I0526 17:43:06.557162 13044 solver.cpp:237] Iteration 365250, loss = 1.58549
I0526 17:43:06.557328 13044 solver.cpp:253]     Train net output #0: loss = 1.58549 (* 1 = 1.58549 loss)
I0526 17:43:06.557343 13044 sgd_solver.cpp:106] Iteration 365250, lr = 0.003
I0526 17:43:18.802862 13044 solver.cpp:237] Iteration 366000, loss = 0.95091
I0526 17:43:18.802899 13044 solver.cpp:253]     Train net output #0: loss = 0.95091 (* 1 = 0.95091 loss)
I0526 17:43:18.802917 13044 sgd_solver.cpp:106] Iteration 366000, lr = 0.003
I0526 17:43:31.047018 13044 solver.cpp:237] Iteration 366750, loss = 2.14758
I0526 17:43:31.047061 13044 solver.cpp:253]     Train net output #0: loss = 2.14758 (* 1 = 2.14758 loss)
I0526 17:43:31.047075 13044 sgd_solver.cpp:106] Iteration 366750, lr = 0.003
I0526 17:43:43.248785 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_367500.caffemodel
I0526 17:43:43.298926 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_367500.solverstate
I0526 17:43:43.329501 13044 solver.cpp:237] Iteration 367500, loss = 0.772071
I0526 17:43:43.329546 13044 solver.cpp:253]     Train net output #0: loss = 0.772071 (* 1 = 0.772071 loss)
I0526 17:43:43.329560 13044 sgd_solver.cpp:106] Iteration 367500, lr = 0.003
I0526 17:43:55.562646 13044 solver.cpp:237] Iteration 368250, loss = 1.3064
I0526 17:43:55.562687 13044 solver.cpp:253]     Train net output #0: loss = 1.3064 (* 1 = 1.3064 loss)
I0526 17:43:55.562700 13044 sgd_solver.cpp:106] Iteration 368250, lr = 0.003
I0526 17:44:07.774401 13044 solver.cpp:237] Iteration 369000, loss = 0.845848
I0526 17:44:07.774437 13044 solver.cpp:253]     Train net output #0: loss = 0.845847 (* 1 = 0.845847 loss)
I0526 17:44:07.774453 13044 sgd_solver.cpp:106] Iteration 369000, lr = 0.003
I0526 17:44:19.959776 13044 solver.cpp:237] Iteration 369750, loss = 0.872303
I0526 17:44:19.959940 13044 solver.cpp:253]     Train net output #0: loss = 0.872302 (* 1 = 0.872302 loss)
I0526 17:44:19.959954 13044 sgd_solver.cpp:106] Iteration 369750, lr = 0.003
I0526 17:44:53.036659 13044 solver.cpp:237] Iteration 370500, loss = 0.760804
I0526 17:44:53.036831 13044 solver.cpp:253]     Train net output #0: loss = 0.760803 (* 1 = 0.760803 loss)
I0526 17:44:53.036846 13044 sgd_solver.cpp:106] Iteration 370500, lr = 0.003
I0526 17:45:05.233103 13044 solver.cpp:237] Iteration 371250, loss = 1.05606
I0526 17:45:05.233150 13044 solver.cpp:253]     Train net output #0: loss = 1.05606 (* 1 = 1.05606 loss)
I0526 17:45:05.233165 13044 sgd_solver.cpp:106] Iteration 371250, lr = 0.003
I0526 17:45:17.468657 13044 solver.cpp:237] Iteration 372000, loss = 0.726808
I0526 17:45:17.468693 13044 solver.cpp:253]     Train net output #0: loss = 0.726807 (* 1 = 0.726807 loss)
I0526 17:45:17.468706 13044 sgd_solver.cpp:106] Iteration 372000, lr = 0.003
I0526 17:45:29.706850 13044 solver.cpp:237] Iteration 372750, loss = 0.953762
I0526 17:45:29.707026 13044 solver.cpp:253]     Train net output #0: loss = 0.953761 (* 1 = 0.953761 loss)
I0526 17:45:29.707041 13044 sgd_solver.cpp:106] Iteration 372750, lr = 0.003
I0526 17:45:41.916893 13044 solver.cpp:237] Iteration 373500, loss = 0.991126
I0526 17:45:41.916930 13044 solver.cpp:253]     Train net output #0: loss = 0.991125 (* 1 = 0.991125 loss)
I0526 17:45:41.916944 13044 sgd_solver.cpp:106] Iteration 373500, lr = 0.003
I0526 17:45:54.082135 13044 solver.cpp:237] Iteration 374250, loss = 1.5309
I0526 17:45:54.082182 13044 solver.cpp:253]     Train net output #0: loss = 1.5309 (* 1 = 1.5309 loss)
I0526 17:45:54.082196 13044 sgd_solver.cpp:106] Iteration 374250, lr = 0.003
I0526 17:46:06.223580 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_375000.caffemodel
I0526 17:46:06.273214 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_375000.solverstate
I0526 17:46:06.300344 13044 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 17:47:19.058769 13044 solver.cpp:409]     Test net output #0: accuracy = 0.904298
I0526 17:47:19.058933 13044 solver.cpp:409]     Test net output #1: loss = 0.307663 (* 1 = 0.307663 loss)
I0526 17:47:39.915750 13044 solver.cpp:237] Iteration 375000, loss = 1.18633
I0526 17:47:39.915802 13044 solver.cpp:253]     Train net output #0: loss = 1.18633 (* 1 = 1.18633 loss)
I0526 17:47:39.915819 13044 sgd_solver.cpp:106] Iteration 375000, lr = 0.003
I0526 17:47:52.093901 13044 solver.cpp:237] Iteration 375750, loss = 0.851234
I0526 17:47:52.094059 13044 solver.cpp:253]     Train net output #0: loss = 0.851234 (* 1 = 0.851234 loss)
I0526 17:47:52.094074 13044 sgd_solver.cpp:106] Iteration 375750, lr = 0.003
I0526 17:48:04.286289 13044 solver.cpp:237] Iteration 376500, loss = 1.20554
I0526 17:48:04.286334 13044 solver.cpp:253]     Train net output #0: loss = 1.20554 (* 1 = 1.20554 loss)
I0526 17:48:04.286346 13044 sgd_solver.cpp:106] Iteration 376500, lr = 0.003
I0526 17:48:16.520854 13044 solver.cpp:237] Iteration 377250, loss = 0.997929
I0526 17:48:16.520890 13044 solver.cpp:253]     Train net output #0: loss = 0.997929 (* 1 = 0.997929 loss)
I0526 17:48:16.520905 13044 sgd_solver.cpp:106] Iteration 377250, lr = 0.003
I0526 17:48:28.738039 13044 solver.cpp:237] Iteration 378000, loss = 1.15788
I0526 17:48:28.738198 13044 solver.cpp:253]     Train net output #0: loss = 1.15788 (* 1 = 1.15788 loss)
I0526 17:48:28.738214 13044 sgd_solver.cpp:106] Iteration 378000, lr = 0.003
I0526 17:48:40.950542 13044 solver.cpp:237] Iteration 378750, loss = 0.976998
I0526 17:48:40.950579 13044 solver.cpp:253]     Train net output #0: loss = 0.976998 (* 1 = 0.976998 loss)
I0526 17:48:40.950592 13044 sgd_solver.cpp:106] Iteration 378750, lr = 0.003
I0526 17:48:53.140393 13044 solver.cpp:237] Iteration 379500, loss = 1.35881
I0526 17:48:53.140441 13044 solver.cpp:253]     Train net output #0: loss = 1.35881 (* 1 = 1.35881 loss)
I0526 17:48:53.140455 13044 sgd_solver.cpp:106] Iteration 379500, lr = 0.003
I0526 17:49:26.199687 13044 solver.cpp:237] Iteration 380250, loss = 1.17541
I0526 17:49:26.199851 13044 solver.cpp:253]     Train net output #0: loss = 1.17541 (* 1 = 1.17541 loss)
I0526 17:49:26.199867 13044 sgd_solver.cpp:106] Iteration 380250, lr = 0.003
I0526 17:49:38.365342 13044 solver.cpp:237] Iteration 381000, loss = 1.11939
I0526 17:49:38.365383 13044 solver.cpp:253]     Train net output #0: loss = 1.11939 (* 1 = 1.11939 loss)
I0526 17:49:38.365396 13044 sgd_solver.cpp:106] Iteration 381000, lr = 0.003
I0526 17:49:50.530207 13044 solver.cpp:237] Iteration 381750, loss = 1.28382
I0526 17:49:50.530243 13044 solver.cpp:253]     Train net output #0: loss = 1.28382 (* 1 = 1.28382 loss)
I0526 17:49:50.530261 13044 sgd_solver.cpp:106] Iteration 381750, lr = 0.003
I0526 17:50:02.722286 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_382500.caffemodel
I0526 17:50:02.777524 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_382500.solverstate
I0526 17:50:02.811230 13044 solver.cpp:237] Iteration 382500, loss = 1.17021
I0526 17:50:02.811277 13044 solver.cpp:253]     Train net output #0: loss = 1.17021 (* 1 = 1.17021 loss)
I0526 17:50:02.811297 13044 sgd_solver.cpp:106] Iteration 382500, lr = 0.003
I0526 17:50:14.980648 13044 solver.cpp:237] Iteration 383250, loss = 1.13113
I0526 17:50:14.980684 13044 solver.cpp:253]     Train net output #0: loss = 1.13113 (* 1 = 1.13113 loss)
I0526 17:50:14.980701 13044 sgd_solver.cpp:106] Iteration 383250, lr = 0.003
I0526 17:50:27.108914 13044 solver.cpp:237] Iteration 384000, loss = 1.1334
I0526 17:50:27.108950 13044 solver.cpp:253]     Train net output #0: loss = 1.1334 (* 1 = 1.1334 loss)
I0526 17:50:27.108964 13044 sgd_solver.cpp:106] Iteration 384000, lr = 0.003
I0526 17:50:39.262748 13044 solver.cpp:237] Iteration 384750, loss = 1.28427
I0526 17:50:39.262913 13044 solver.cpp:253]     Train net output #0: loss = 1.28427 (* 1 = 1.28427 loss)
I0526 17:50:39.262928 13044 sgd_solver.cpp:106] Iteration 384750, lr = 0.003
I0526 17:51:12.377190 13044 solver.cpp:237] Iteration 385500, loss = 0.913047
I0526 17:51:12.377363 13044 solver.cpp:253]     Train net output #0: loss = 0.913047 (* 1 = 0.913047 loss)
I0526 17:51:12.377378 13044 sgd_solver.cpp:106] Iteration 385500, lr = 0.003
I0526 17:51:24.555343 13044 solver.cpp:237] Iteration 386250, loss = 1.40527
I0526 17:51:24.555389 13044 solver.cpp:253]     Train net output #0: loss = 1.40527 (* 1 = 1.40527 loss)
I0526 17:51:24.555402 13044 sgd_solver.cpp:106] Iteration 386250, lr = 0.003
I0526 17:51:36.693883 13044 solver.cpp:237] Iteration 387000, loss = 1.33294
I0526 17:51:36.693918 13044 solver.cpp:253]     Train net output #0: loss = 1.33294 (* 1 = 1.33294 loss)
I0526 17:51:36.693936 13044 sgd_solver.cpp:106] Iteration 387000, lr = 0.003
I0526 17:51:48.831650 13044 solver.cpp:237] Iteration 387750, loss = 1.15284
I0526 17:51:48.831816 13044 solver.cpp:253]     Train net output #0: loss = 1.15284 (* 1 = 1.15284 loss)
I0526 17:51:48.831830 13044 sgd_solver.cpp:106] Iteration 387750, lr = 0.003
I0526 17:52:00.982481 13044 solver.cpp:237] Iteration 388500, loss = 1.09568
I0526 17:52:00.982517 13044 solver.cpp:253]     Train net output #0: loss = 1.09568 (* 1 = 1.09568 loss)
I0526 17:52:00.982533 13044 sgd_solver.cpp:106] Iteration 388500, lr = 0.003
I0526 17:52:13.185683 13044 solver.cpp:237] Iteration 389250, loss = 0.756595
I0526 17:52:13.185729 13044 solver.cpp:253]     Train net output #0: loss = 0.756595 (* 1 = 0.756595 loss)
I0526 17:52:13.185741 13044 sgd_solver.cpp:106] Iteration 389250, lr = 0.003
I0526 17:52:25.340559 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_390000.caffemodel
I0526 17:52:25.390827 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_390000.solverstate
I0526 17:52:25.417309 13044 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 17:53:17.081437 13044 solver.cpp:409]     Test net output #0: accuracy = 0.897365
I0526 17:53:17.081609 13044 solver.cpp:409]     Test net output #1: loss = 0.344264 (* 1 = 0.344264 loss)
I0526 17:53:37.969873 13044 solver.cpp:237] Iteration 390000, loss = 1.29912
I0526 17:53:37.969925 13044 solver.cpp:253]     Train net output #0: loss = 1.29913 (* 1 = 1.29913 loss)
I0526 17:53:37.969941 13044 sgd_solver.cpp:106] Iteration 390000, lr = 0.003
I0526 17:53:50.124538 13044 solver.cpp:237] Iteration 390750, loss = 1.05319
I0526 17:53:50.124704 13044 solver.cpp:253]     Train net output #0: loss = 1.05319 (* 1 = 1.05319 loss)
I0526 17:53:50.124718 13044 sgd_solver.cpp:106] Iteration 390750, lr = 0.003
I0526 17:54:02.299679 13044 solver.cpp:237] Iteration 391500, loss = 1.25757
I0526 17:54:02.299715 13044 solver.cpp:253]     Train net output #0: loss = 1.25757 (* 1 = 1.25757 loss)
I0526 17:54:02.299731 13044 sgd_solver.cpp:106] Iteration 391500, lr = 0.003
I0526 17:54:14.439285 13044 solver.cpp:237] Iteration 392250, loss = 1.20183
I0526 17:54:14.439329 13044 solver.cpp:253]     Train net output #0: loss = 1.20183 (* 1 = 1.20183 loss)
I0526 17:54:14.439347 13044 sgd_solver.cpp:106] Iteration 392250, lr = 0.003
I0526 17:54:26.557972 13044 solver.cpp:237] Iteration 393000, loss = 1.26422
I0526 17:54:26.558145 13044 solver.cpp:253]     Train net output #0: loss = 1.26422 (* 1 = 1.26422 loss)
I0526 17:54:26.558161 13044 sgd_solver.cpp:106] Iteration 393000, lr = 0.003
I0526 17:54:38.672286 13044 solver.cpp:237] Iteration 393750, loss = 1.13985
I0526 17:54:38.672330 13044 solver.cpp:253]     Train net output #0: loss = 1.13985 (* 1 = 1.13985 loss)
I0526 17:54:38.672344 13044 sgd_solver.cpp:106] Iteration 393750, lr = 0.003
I0526 17:54:50.785434 13044 solver.cpp:237] Iteration 394500, loss = 1.32598
I0526 17:54:50.785470 13044 solver.cpp:253]     Train net output #0: loss = 1.32598 (* 1 = 1.32598 loss)
I0526 17:54:50.785482 13044 sgd_solver.cpp:106] Iteration 394500, lr = 0.003
I0526 17:55:23.805691 13044 solver.cpp:237] Iteration 395250, loss = 1.2154
I0526 17:55:23.805866 13044 solver.cpp:253]     Train net output #0: loss = 1.2154 (* 1 = 1.2154 loss)
I0526 17:55:23.805879 13044 sgd_solver.cpp:106] Iteration 395250, lr = 0.003
I0526 17:55:35.969545 13044 solver.cpp:237] Iteration 396000, loss = 1.46233
I0526 17:55:35.969590 13044 solver.cpp:253]     Train net output #0: loss = 1.46233 (* 1 = 1.46233 loss)
I0526 17:55:35.969604 13044 sgd_solver.cpp:106] Iteration 396000, lr = 0.003
I0526 17:55:48.113646 13044 solver.cpp:237] Iteration 396750, loss = 1.17875
I0526 17:55:48.113682 13044 solver.cpp:253]     Train net output #0: loss = 1.17875 (* 1 = 1.17875 loss)
I0526 17:55:48.113694 13044 sgd_solver.cpp:106] Iteration 396750, lr = 0.003
I0526 17:56:00.259269 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_397500.caffemodel
I0526 17:56:00.311548 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_397500.solverstate
I0526 17:56:00.344393 13044 solver.cpp:237] Iteration 397500, loss = 1.31086
I0526 17:56:00.344439 13044 solver.cpp:253]     Train net output #0: loss = 1.31086 (* 1 = 1.31086 loss)
I0526 17:56:00.344460 13044 sgd_solver.cpp:106] Iteration 397500, lr = 0.003
I0526 17:56:12.484995 13044 solver.cpp:237] Iteration 398250, loss = 1.00037
I0526 17:56:12.485033 13044 solver.cpp:253]     Train net output #0: loss = 1.00037 (* 1 = 1.00037 loss)
I0526 17:56:12.485049 13044 sgd_solver.cpp:106] Iteration 398250, lr = 0.003
I0526 17:56:24.578186 13044 solver.cpp:237] Iteration 399000, loss = 1.07867
I0526 17:56:24.578236 13044 solver.cpp:253]     Train net output #0: loss = 1.07867 (* 1 = 1.07867 loss)
I0526 17:56:24.578249 13044 sgd_solver.cpp:106] Iteration 399000, lr = 0.003
I0526 17:56:36.671489 13044 solver.cpp:237] Iteration 399750, loss = 1.19264
I0526 17:56:36.671650 13044 solver.cpp:253]     Train net output #0: loss = 1.19264 (* 1 = 1.19264 loss)
I0526 17:56:36.671664 13044 sgd_solver.cpp:106] Iteration 399750, lr = 0.003
I0526 17:57:09.664006 13044 solver.cpp:237] Iteration 400500, loss = 1.1877
I0526 17:57:09.664176 13044 solver.cpp:253]     Train net output #0: loss = 1.1877 (* 1 = 1.1877 loss)
I0526 17:57:09.664191 13044 sgd_solver.cpp:106] Iteration 400500, lr = 0.003
I0526 17:57:21.823782 13044 solver.cpp:237] Iteration 401250, loss = 1.17402
I0526 17:57:21.823818 13044 solver.cpp:253]     Train net output #0: loss = 1.17402 (* 1 = 1.17402 loss)
I0526 17:57:21.823832 13044 sgd_solver.cpp:106] Iteration 401250, lr = 0.003
I0526 17:57:33.976781 13044 solver.cpp:237] Iteration 402000, loss = 1.80381
I0526 17:57:33.976824 13044 solver.cpp:253]     Train net output #0: loss = 1.80381 (* 1 = 1.80381 loss)
I0526 17:57:33.976841 13044 sgd_solver.cpp:106] Iteration 402000, lr = 0.003
I0526 17:57:46.148322 13044 solver.cpp:237] Iteration 402750, loss = 1.0449
I0526 17:57:46.148483 13044 solver.cpp:253]     Train net output #0: loss = 1.0449 (* 1 = 1.0449 loss)
I0526 17:57:46.148499 13044 sgd_solver.cpp:106] Iteration 402750, lr = 0.003
I0526 17:57:58.277688 13044 solver.cpp:237] Iteration 403500, loss = 1.34425
I0526 17:57:58.277732 13044 solver.cpp:253]     Train net output #0: loss = 1.34425 (* 1 = 1.34425 loss)
I0526 17:57:58.277746 13044 sgd_solver.cpp:106] Iteration 403500, lr = 0.003
I0526 17:58:10.367544 13044 solver.cpp:237] Iteration 404250, loss = 0.713348
I0526 17:58:10.367583 13044 solver.cpp:253]     Train net output #0: loss = 0.71335 (* 1 = 0.71335 loss)
I0526 17:58:10.367596 13044 sgd_solver.cpp:106] Iteration 404250, lr = 0.003
I0526 17:58:22.425117 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_405000.caffemodel
I0526 17:58:22.474985 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_405000.solverstate
I0526 17:58:22.500466 13044 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 17:59:35.314653 13044 solver.cpp:409]     Test net output #0: accuracy = 0.900738
I0526 17:59:35.314826 13044 solver.cpp:409]     Test net output #1: loss = 0.315362 (* 1 = 0.315362 loss)
I0526 17:59:56.249871 13044 solver.cpp:237] Iteration 405000, loss = 1.12085
I0526 17:59:56.249922 13044 solver.cpp:253]     Train net output #0: loss = 1.12085 (* 1 = 1.12085 loss)
I0526 17:59:56.249940 13044 sgd_solver.cpp:106] Iteration 405000, lr = 0.003
I0526 18:00:08.435142 13044 solver.cpp:237] Iteration 405750, loss = 1.17247
I0526 18:00:08.435300 13044 solver.cpp:253]     Train net output #0: loss = 1.17247 (* 1 = 1.17247 loss)
I0526 18:00:08.435315 13044 sgd_solver.cpp:106] Iteration 405750, lr = 0.003
I0526 18:00:20.609289 13044 solver.cpp:237] Iteration 406500, loss = 1.26677
I0526 18:00:20.609324 13044 solver.cpp:253]     Train net output #0: loss = 1.26677 (* 1 = 1.26677 loss)
I0526 18:00:20.609340 13044 sgd_solver.cpp:106] Iteration 406500, lr = 0.003
I0526 18:00:32.783985 13044 solver.cpp:237] Iteration 407250, loss = 1.24306
I0526 18:00:32.784035 13044 solver.cpp:253]     Train net output #0: loss = 1.24306 (* 1 = 1.24306 loss)
I0526 18:00:32.784049 13044 sgd_solver.cpp:106] Iteration 407250, lr = 0.003
I0526 18:00:44.945304 13044 solver.cpp:237] Iteration 408000, loss = 1.21796
I0526 18:00:44.945457 13044 solver.cpp:253]     Train net output #0: loss = 1.21796 (* 1 = 1.21796 loss)
I0526 18:00:44.945473 13044 sgd_solver.cpp:106] Iteration 408000, lr = 0.003
I0526 18:00:57.088424 13044 solver.cpp:237] Iteration 408750, loss = 1.34396
I0526 18:00:57.088474 13044 solver.cpp:253]     Train net output #0: loss = 1.34396 (* 1 = 1.34396 loss)
I0526 18:00:57.088488 13044 sgd_solver.cpp:106] Iteration 408750, lr = 0.003
I0526 18:01:09.264150 13044 solver.cpp:237] Iteration 409500, loss = 1.50679
I0526 18:01:09.264188 13044 solver.cpp:253]     Train net output #0: loss = 1.50679 (* 1 = 1.50679 loss)
I0526 18:01:09.264201 13044 sgd_solver.cpp:106] Iteration 409500, lr = 0.003
I0526 18:01:42.316826 13044 solver.cpp:237] Iteration 410250, loss = 1.24088
I0526 18:01:42.316999 13044 solver.cpp:253]     Train net output #0: loss = 1.24088 (* 1 = 1.24088 loss)
I0526 18:01:42.317014 13044 sgd_solver.cpp:106] Iteration 410250, lr = 0.003
I0526 18:01:54.416306 13044 solver.cpp:237] Iteration 411000, loss = 0.931992
I0526 18:01:54.416352 13044 solver.cpp:253]     Train net output #0: loss = 0.931994 (* 1 = 0.931994 loss)
I0526 18:01:54.416366 13044 sgd_solver.cpp:106] Iteration 411000, lr = 0.003
I0526 18:02:06.552698 13044 solver.cpp:237] Iteration 411750, loss = 1.29139
I0526 18:02:06.552734 13044 solver.cpp:253]     Train net output #0: loss = 1.29139 (* 1 = 1.29139 loss)
I0526 18:02:06.552752 13044 sgd_solver.cpp:106] Iteration 411750, lr = 0.003
I0526 18:02:18.658424 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_412500.caffemodel
I0526 18:02:18.708600 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_412500.solverstate
I0526 18:02:18.740985 13044 solver.cpp:237] Iteration 412500, loss = 1.1073
I0526 18:02:18.741035 13044 solver.cpp:253]     Train net output #0: loss = 1.1073 (* 1 = 1.1073 loss)
I0526 18:02:18.741050 13044 sgd_solver.cpp:106] Iteration 412500, lr = 0.003
I0526 18:02:30.878828 13044 solver.cpp:237] Iteration 413250, loss = 0.619153
I0526 18:02:30.878865 13044 solver.cpp:253]     Train net output #0: loss = 0.619155 (* 1 = 0.619155 loss)
I0526 18:02:30.878877 13044 sgd_solver.cpp:106] Iteration 413250, lr = 0.003
I0526 18:02:43.026398 13044 solver.cpp:237] Iteration 414000, loss = 0.835617
I0526 18:02:43.026444 13044 solver.cpp:253]     Train net output #0: loss = 0.835619 (* 1 = 0.835619 loss)
I0526 18:02:43.026458 13044 sgd_solver.cpp:106] Iteration 414000, lr = 0.003
I0526 18:02:55.179869 13044 solver.cpp:237] Iteration 414750, loss = 1.18812
I0526 18:02:55.180027 13044 solver.cpp:253]     Train net output #0: loss = 1.18813 (* 1 = 1.18813 loss)
I0526 18:02:55.180042 13044 sgd_solver.cpp:106] Iteration 414750, lr = 0.003
I0526 18:03:28.223685 13044 solver.cpp:237] Iteration 415500, loss = 1.30905
I0526 18:03:28.223860 13044 solver.cpp:253]     Train net output #0: loss = 1.30905 (* 1 = 1.30905 loss)
I0526 18:03:28.223875 13044 sgd_solver.cpp:106] Iteration 415500, lr = 0.003
I0526 18:03:40.348234 13044 solver.cpp:237] Iteration 416250, loss = 1.52561
I0526 18:03:40.348270 13044 solver.cpp:253]     Train net output #0: loss = 1.52561 (* 1 = 1.52561 loss)
I0526 18:03:40.348286 13044 sgd_solver.cpp:106] Iteration 416250, lr = 0.003
I0526 18:03:52.461383 13044 solver.cpp:237] Iteration 417000, loss = 0.894696
I0526 18:03:52.461429 13044 solver.cpp:253]     Train net output #0: loss = 0.894697 (* 1 = 0.894697 loss)
I0526 18:03:52.461442 13044 sgd_solver.cpp:106] Iteration 417000, lr = 0.003
I0526 18:04:04.653707 13044 solver.cpp:237] Iteration 417750, loss = 1.3072
I0526 18:04:04.653857 13044 solver.cpp:253]     Train net output #0: loss = 1.3072 (* 1 = 1.3072 loss)
I0526 18:04:04.653872 13044 sgd_solver.cpp:106] Iteration 417750, lr = 0.003
I0526 18:04:16.823499 13044 solver.cpp:237] Iteration 418500, loss = 1.09316
I0526 18:04:16.823551 13044 solver.cpp:253]     Train net output #0: loss = 1.09316 (* 1 = 1.09316 loss)
I0526 18:04:16.823565 13044 sgd_solver.cpp:106] Iteration 418500, lr = 0.003
I0526 18:04:28.967934 13044 solver.cpp:237] Iteration 419250, loss = 1.21643
I0526 18:04:28.967970 13044 solver.cpp:253]     Train net output #0: loss = 1.21643 (* 1 = 1.21643 loss)
I0526 18:04:28.967984 13044 sgd_solver.cpp:106] Iteration 419250, lr = 0.003
I0526 18:04:41.442867 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_420000.caffemodel
I0526 18:04:41.492107 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_420000.solverstate
I0526 18:04:41.517973 13044 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 18:05:33.518415 13044 solver.cpp:409]     Test net output #0: accuracy = 0.898955
I0526 18:05:33.518586 13044 solver.cpp:409]     Test net output #1: loss = 0.33982 (* 1 = 0.33982 loss)
I0526 18:05:54.401186 13044 solver.cpp:237] Iteration 420000, loss = 1.51098
I0526 18:05:54.401235 13044 solver.cpp:253]     Train net output #0: loss = 1.51098 (* 1 = 1.51098 loss)
I0526 18:05:54.401253 13044 sgd_solver.cpp:106] Iteration 420000, lr = 0.003
I0526 18:06:06.639278 13044 solver.cpp:237] Iteration 420750, loss = 0.996656
I0526 18:06:06.639452 13044 solver.cpp:253]     Train net output #0: loss = 0.996658 (* 1 = 0.996658 loss)
I0526 18:06:06.639467 13044 sgd_solver.cpp:106] Iteration 420750, lr = 0.003
I0526 18:06:18.868199 13044 solver.cpp:237] Iteration 421500, loss = 1.15323
I0526 18:06:18.868249 13044 solver.cpp:253]     Train net output #0: loss = 1.15323 (* 1 = 1.15323 loss)
I0526 18:06:18.868263 13044 sgd_solver.cpp:106] Iteration 421500, lr = 0.003
I0526 18:06:31.061341 13044 solver.cpp:237] Iteration 422250, loss = 1.53441
I0526 18:06:31.061377 13044 solver.cpp:253]     Train net output #0: loss = 1.53441 (* 1 = 1.53441 loss)
I0526 18:06:31.061389 13044 sgd_solver.cpp:106] Iteration 422250, lr = 0.003
I0526 18:06:43.251157 13044 solver.cpp:237] Iteration 423000, loss = 1.25588
I0526 18:06:43.251327 13044 solver.cpp:253]     Train net output #0: loss = 1.25588 (* 1 = 1.25588 loss)
I0526 18:06:43.251340 13044 sgd_solver.cpp:106] Iteration 423000, lr = 0.003
I0526 18:06:55.431602 13044 solver.cpp:237] Iteration 423750, loss = 0.716137
I0526 18:06:55.431637 13044 solver.cpp:253]     Train net output #0: loss = 0.716138 (* 1 = 0.716138 loss)
I0526 18:06:55.431651 13044 sgd_solver.cpp:106] Iteration 423750, lr = 0.003
I0526 18:07:07.645983 13044 solver.cpp:237] Iteration 424500, loss = 0.813047
I0526 18:07:07.646029 13044 solver.cpp:253]     Train net output #0: loss = 0.813048 (* 1 = 0.813048 loss)
I0526 18:07:07.646044 13044 sgd_solver.cpp:106] Iteration 424500, lr = 0.003
I0526 18:07:40.777019 13044 solver.cpp:237] Iteration 425250, loss = 1.36569
I0526 18:07:40.777195 13044 solver.cpp:253]     Train net output #0: loss = 1.36569 (* 1 = 1.36569 loss)
I0526 18:07:40.777212 13044 sgd_solver.cpp:106] Iteration 425250, lr = 0.003
I0526 18:07:52.931202 13044 solver.cpp:237] Iteration 426000, loss = 1.11751
I0526 18:07:52.931238 13044 solver.cpp:253]     Train net output #0: loss = 1.11751 (* 1 = 1.11751 loss)
I0526 18:07:52.931252 13044 sgd_solver.cpp:106] Iteration 426000, lr = 0.003
I0526 18:08:05.078738 13044 solver.cpp:237] Iteration 426750, loss = 1.35432
I0526 18:08:05.078783 13044 solver.cpp:253]     Train net output #0: loss = 1.35433 (* 1 = 1.35433 loss)
I0526 18:08:05.078795 13044 sgd_solver.cpp:106] Iteration 426750, lr = 0.003
I0526 18:08:17.215461 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_427500.caffemodel
I0526 18:08:17.268487 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_427500.solverstate
I0526 18:08:17.301414 13044 solver.cpp:237] Iteration 427500, loss = 1.2652
I0526 18:08:17.301463 13044 solver.cpp:253]     Train net output #0: loss = 1.2652 (* 1 = 1.2652 loss)
I0526 18:08:17.301477 13044 sgd_solver.cpp:106] Iteration 427500, lr = 0.003
I0526 18:08:29.506968 13044 solver.cpp:237] Iteration 428250, loss = 0.693628
I0526 18:08:29.507015 13044 solver.cpp:253]     Train net output #0: loss = 0.693631 (* 1 = 0.693631 loss)
I0526 18:08:29.507030 13044 sgd_solver.cpp:106] Iteration 428250, lr = 0.003
I0526 18:08:41.752847 13044 solver.cpp:237] Iteration 429000, loss = 1.85799
I0526 18:08:41.752883 13044 solver.cpp:253]     Train net output #0: loss = 1.85799 (* 1 = 1.85799 loss)
I0526 18:08:41.752897 13044 sgd_solver.cpp:106] Iteration 429000, lr = 0.003
I0526 18:08:53.973587 13044 solver.cpp:237] Iteration 429750, loss = 0.964002
I0526 18:08:53.973762 13044 solver.cpp:253]     Train net output #0: loss = 0.964004 (* 1 = 0.964004 loss)
I0526 18:08:53.973778 13044 sgd_solver.cpp:106] Iteration 429750, lr = 0.003
I0526 18:09:27.092605 13044 solver.cpp:237] Iteration 430500, loss = 0.997237
I0526 18:09:27.092797 13044 solver.cpp:253]     Train net output #0: loss = 0.997239 (* 1 = 0.997239 loss)
I0526 18:09:27.092813 13044 sgd_solver.cpp:106] Iteration 430500, lr = 0.003
I0526 18:09:39.294400 13044 solver.cpp:237] Iteration 431250, loss = 0.804272
I0526 18:09:39.294447 13044 solver.cpp:253]     Train net output #0: loss = 0.804274 (* 1 = 0.804274 loss)
I0526 18:09:39.294461 13044 sgd_solver.cpp:106] Iteration 431250, lr = 0.003
I0526 18:09:51.497862 13044 solver.cpp:237] Iteration 432000, loss = 1.15214
I0526 18:09:51.497897 13044 solver.cpp:253]     Train net output #0: loss = 1.15214 (* 1 = 1.15214 loss)
I0526 18:09:51.497911 13044 sgd_solver.cpp:106] Iteration 432000, lr = 0.003
I0526 18:10:03.702119 13044 solver.cpp:237] Iteration 432750, loss = 1.14244
I0526 18:10:03.702299 13044 solver.cpp:253]     Train net output #0: loss = 1.14244 (* 1 = 1.14244 loss)
I0526 18:10:03.702313 13044 sgd_solver.cpp:106] Iteration 432750, lr = 0.003
I0526 18:10:15.938855 13044 solver.cpp:237] Iteration 433500, loss = 1.43289
I0526 18:10:15.938891 13044 solver.cpp:253]     Train net output #0: loss = 1.4329 (* 1 = 1.4329 loss)
I0526 18:10:15.938905 13044 sgd_solver.cpp:106] Iteration 433500, lr = 0.003
I0526 18:10:28.171010 13044 solver.cpp:237] Iteration 434250, loss = 1.46082
I0526 18:10:28.171051 13044 solver.cpp:253]     Train net output #0: loss = 1.46083 (* 1 = 1.46083 loss)
I0526 18:10:28.171067 13044 sgd_solver.cpp:106] Iteration 434250, lr = 0.003
I0526 18:10:40.351773 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_435000.caffemodel
I0526 18:10:40.403748 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_435000.solverstate
I0526 18:10:40.431572 13044 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 18:11:53.310192 13044 solver.cpp:409]     Test net output #0: accuracy = 0.899305
I0526 18:11:53.310366 13044 solver.cpp:409]     Test net output #1: loss = 0.325386 (* 1 = 0.325386 loss)
I0526 18:12:14.214253 13044 solver.cpp:237] Iteration 435000, loss = 1.29757
I0526 18:12:14.214305 13044 solver.cpp:253]     Train net output #0: loss = 1.29757 (* 1 = 1.29757 loss)
I0526 18:12:14.214323 13044 sgd_solver.cpp:106] Iteration 435000, lr = 0.003
I0526 18:12:26.347424 13044 solver.cpp:237] Iteration 435750, loss = 1.02687
I0526 18:12:26.347597 13044 solver.cpp:253]     Train net output #0: loss = 1.02688 (* 1 = 1.02688 loss)
I0526 18:12:26.347612 13044 sgd_solver.cpp:106] Iteration 435750, lr = 0.003
I0526 18:12:38.462560 13044 solver.cpp:237] Iteration 436500, loss = 1.18263
I0526 18:12:38.462602 13044 solver.cpp:253]     Train net output #0: loss = 1.18263 (* 1 = 1.18263 loss)
I0526 18:12:38.462620 13044 sgd_solver.cpp:106] Iteration 436500, lr = 0.003
I0526 18:12:50.569427 13044 solver.cpp:237] Iteration 437250, loss = 0.829881
I0526 18:12:50.569463 13044 solver.cpp:253]     Train net output #0: loss = 0.829883 (* 1 = 0.829883 loss)
I0526 18:12:50.569480 13044 sgd_solver.cpp:106] Iteration 437250, lr = 0.003
I0526 18:13:02.687584 13044 solver.cpp:237] Iteration 438000, loss = 1.36657
I0526 18:13:02.687741 13044 solver.cpp:253]     Train net output #0: loss = 1.36657 (* 1 = 1.36657 loss)
I0526 18:13:02.687755 13044 sgd_solver.cpp:106] Iteration 438000, lr = 0.003
I0526 18:13:14.768059 13044 solver.cpp:237] Iteration 438750, loss = 1.36619
I0526 18:13:14.768095 13044 solver.cpp:253]     Train net output #0: loss = 1.36619 (* 1 = 1.36619 loss)
I0526 18:13:14.768110 13044 sgd_solver.cpp:106] Iteration 438750, lr = 0.003
I0526 18:13:26.884606 13044 solver.cpp:237] Iteration 439500, loss = 1.25756
I0526 18:13:26.884652 13044 solver.cpp:253]     Train net output #0: loss = 1.25756 (* 1 = 1.25756 loss)
I0526 18:13:26.884668 13044 sgd_solver.cpp:106] Iteration 439500, lr = 0.003
I0526 18:13:59.904450 13044 solver.cpp:237] Iteration 440250, loss = 1.14415
I0526 18:13:59.904638 13044 solver.cpp:253]     Train net output #0: loss = 1.14415 (* 1 = 1.14415 loss)
I0526 18:13:59.904651 13044 sgd_solver.cpp:106] Iteration 440250, lr = 0.003
I0526 18:14:12.013171 13044 solver.cpp:237] Iteration 441000, loss = 1.22119
I0526 18:14:12.013206 13044 solver.cpp:253]     Train net output #0: loss = 1.22119 (* 1 = 1.22119 loss)
I0526 18:14:12.013221 13044 sgd_solver.cpp:106] Iteration 441000, lr = 0.003
I0526 18:14:24.124037 13044 solver.cpp:237] Iteration 441750, loss = 2.35848
I0526 18:14:24.124076 13044 solver.cpp:253]     Train net output #0: loss = 2.35849 (* 1 = 2.35849 loss)
I0526 18:14:24.124090 13044 sgd_solver.cpp:106] Iteration 441750, lr = 0.003
I0526 18:14:36.216240 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_442500.caffemodel
I0526 18:14:36.266243 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_442500.solverstate
I0526 18:14:36.296941 13044 solver.cpp:237] Iteration 442500, loss = 0.872925
I0526 18:14:36.296986 13044 solver.cpp:253]     Train net output #0: loss = 0.872927 (* 1 = 0.872927 loss)
I0526 18:14:36.297000 13044 sgd_solver.cpp:106] Iteration 442500, lr = 0.003
I0526 18:14:48.430037 13044 solver.cpp:237] Iteration 443250, loss = 1.04401
I0526 18:14:48.430078 13044 solver.cpp:253]     Train net output #0: loss = 1.04402 (* 1 = 1.04402 loss)
I0526 18:14:48.430091 13044 sgd_solver.cpp:106] Iteration 443250, lr = 0.003
I0526 18:15:00.595589 13044 solver.cpp:237] Iteration 444000, loss = 0.8467
I0526 18:15:00.595626 13044 solver.cpp:253]     Train net output #0: loss = 0.846701 (* 1 = 0.846701 loss)
I0526 18:15:00.595643 13044 sgd_solver.cpp:106] Iteration 444000, lr = 0.003
I0526 18:15:12.760929 13044 solver.cpp:237] Iteration 444750, loss = 1.08191
I0526 18:15:12.761101 13044 solver.cpp:253]     Train net output #0: loss = 1.08191 (* 1 = 1.08191 loss)
I0526 18:15:12.761117 13044 sgd_solver.cpp:106] Iteration 444750, lr = 0.003
I0526 18:15:45.811483 13044 solver.cpp:237] Iteration 445500, loss = 1.06118
I0526 18:15:45.811663 13044 solver.cpp:253]     Train net output #0: loss = 1.06118 (* 1 = 1.06118 loss)
I0526 18:15:45.811678 13044 sgd_solver.cpp:106] Iteration 445500, lr = 0.003
I0526 18:15:57.943336 13044 solver.cpp:237] Iteration 446250, loss = 1.13498
I0526 18:15:57.943382 13044 solver.cpp:253]     Train net output #0: loss = 1.13498 (* 1 = 1.13498 loss)
I0526 18:15:57.943397 13044 sgd_solver.cpp:106] Iteration 446250, lr = 0.003
I0526 18:16:10.074592 13044 solver.cpp:237] Iteration 447000, loss = 0.863521
I0526 18:16:10.074628 13044 solver.cpp:253]     Train net output #0: loss = 0.863523 (* 1 = 0.863523 loss)
I0526 18:16:10.074642 13044 sgd_solver.cpp:106] Iteration 447000, lr = 0.003
I0526 18:16:22.210789 13044 solver.cpp:237] Iteration 447750, loss = 1.26024
I0526 18:16:22.210968 13044 solver.cpp:253]     Train net output #0: loss = 1.26024 (* 1 = 1.26024 loss)
I0526 18:16:22.210983 13044 sgd_solver.cpp:106] Iteration 447750, lr = 0.003
I0526 18:16:34.345623 13044 solver.cpp:237] Iteration 448500, loss = 1.36469
I0526 18:16:34.345659 13044 solver.cpp:253]     Train net output #0: loss = 1.3647 (* 1 = 1.3647 loss)
I0526 18:16:34.345671 13044 sgd_solver.cpp:106] Iteration 448500, lr = 0.003
I0526 18:16:46.462800 13044 solver.cpp:237] Iteration 449250, loss = 1.49848
I0526 18:16:46.462843 13044 solver.cpp:253]     Train net output #0: loss = 1.49849 (* 1 = 1.49849 loss)
I0526 18:16:46.462857 13044 sgd_solver.cpp:106] Iteration 449250, lr = 0.003
I0526 18:16:58.610815 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_450000.caffemodel
I0526 18:16:58.660578 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_450000.solverstate
I0526 18:16:58.686080 13044 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 18:17:50.426352 13044 solver.cpp:409]     Test net output #0: accuracy = 0.902138
I0526 18:17:50.426527 13044 solver.cpp:409]     Test net output #1: loss = 0.306285 (* 1 = 0.306285 loss)
I0526 18:18:11.323081 13044 solver.cpp:237] Iteration 450000, loss = 1.44516
I0526 18:18:11.323133 13044 solver.cpp:253]     Train net output #0: loss = 1.44516 (* 1 = 1.44516 loss)
I0526 18:18:11.323148 13044 sgd_solver.cpp:106] Iteration 450000, lr = 0.003
I0526 18:18:23.517221 13044 solver.cpp:237] Iteration 450750, loss = 0.812631
I0526 18:18:23.517400 13044 solver.cpp:253]     Train net output #0: loss = 0.812632 (* 1 = 0.812632 loss)
I0526 18:18:23.517413 13044 sgd_solver.cpp:106] Iteration 450750, lr = 0.003
I0526 18:18:35.689926 13044 solver.cpp:237] Iteration 451500, loss = 0.840016
I0526 18:18:35.689963 13044 solver.cpp:253]     Train net output #0: loss = 0.840017 (* 1 = 0.840017 loss)
I0526 18:18:35.689976 13044 sgd_solver.cpp:106] Iteration 451500, lr = 0.003
I0526 18:18:47.890074 13044 solver.cpp:237] Iteration 452250, loss = 1.15942
I0526 18:18:47.890122 13044 solver.cpp:253]     Train net output #0: loss = 1.15942 (* 1 = 1.15942 loss)
I0526 18:18:47.890136 13044 sgd_solver.cpp:106] Iteration 452250, lr = 0.003
I0526 18:19:00.033746 13044 solver.cpp:237] Iteration 453000, loss = 1.2539
I0526 18:19:00.033906 13044 solver.cpp:253]     Train net output #0: loss = 1.2539 (* 1 = 1.2539 loss)
I0526 18:19:00.033922 13044 sgd_solver.cpp:106] Iteration 453000, lr = 0.003
I0526 18:19:12.172525 13044 solver.cpp:237] Iteration 453750, loss = 1.20988
I0526 18:19:12.172560 13044 solver.cpp:253]     Train net output #0: loss = 1.20988 (* 1 = 1.20988 loss)
I0526 18:19:12.172579 13044 sgd_solver.cpp:106] Iteration 453750, lr = 0.003
I0526 18:19:24.335420 13044 solver.cpp:237] Iteration 454500, loss = 1.41509
I0526 18:19:24.335466 13044 solver.cpp:253]     Train net output #0: loss = 1.41509 (* 1 = 1.41509 loss)
I0526 18:19:24.335479 13044 sgd_solver.cpp:106] Iteration 454500, lr = 0.003
I0526 18:19:57.420464 13044 solver.cpp:237] Iteration 455250, loss = 1.49117
I0526 18:19:57.420641 13044 solver.cpp:253]     Train net output #0: loss = 1.49117 (* 1 = 1.49117 loss)
I0526 18:19:57.420657 13044 sgd_solver.cpp:106] Iteration 455250, lr = 0.003
I0526 18:20:09.593318 13044 solver.cpp:237] Iteration 456000, loss = 0.939066
I0526 18:20:09.593363 13044 solver.cpp:253]     Train net output #0: loss = 0.939068 (* 1 = 0.939068 loss)
I0526 18:20:09.593379 13044 sgd_solver.cpp:106] Iteration 456000, lr = 0.003
I0526 18:20:21.788694 13044 solver.cpp:237] Iteration 456750, loss = 1.31151
I0526 18:20:21.788730 13044 solver.cpp:253]     Train net output #0: loss = 1.31151 (* 1 = 1.31151 loss)
I0526 18:20:21.788744 13044 sgd_solver.cpp:106] Iteration 456750, lr = 0.003
I0526 18:20:33.945431 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_457500.caffemodel
I0526 18:20:33.995070 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_457500.solverstate
I0526 18:20:34.026180 13044 solver.cpp:237] Iteration 457500, loss = 0.958108
I0526 18:20:34.026226 13044 solver.cpp:253]     Train net output #0: loss = 0.958109 (* 1 = 0.958109 loss)
I0526 18:20:34.026243 13044 sgd_solver.cpp:106] Iteration 457500, lr = 0.003
I0526 18:20:46.180876 13044 solver.cpp:237] Iteration 458250, loss = 1.25757
I0526 18:20:46.180913 13044 solver.cpp:253]     Train net output #0: loss = 1.25757 (* 1 = 1.25757 loss)
I0526 18:20:46.180929 13044 sgd_solver.cpp:106] Iteration 458250, lr = 0.003
I0526 18:20:58.324187 13044 solver.cpp:237] Iteration 459000, loss = 0.951223
I0526 18:20:58.324232 13044 solver.cpp:253]     Train net output #0: loss = 0.951224 (* 1 = 0.951224 loss)
I0526 18:20:58.324245 13044 sgd_solver.cpp:106] Iteration 459000, lr = 0.003
I0526 18:21:10.466815 13044 solver.cpp:237] Iteration 459750, loss = 0.804751
I0526 18:21:10.466990 13044 solver.cpp:253]     Train net output #0: loss = 0.804752 (* 1 = 0.804752 loss)
I0526 18:21:10.467005 13044 sgd_solver.cpp:106] Iteration 459750, lr = 0.003
I0526 18:21:43.560899 13044 solver.cpp:237] Iteration 460500, loss = 0.95231
I0526 18:21:43.561075 13044 solver.cpp:253]     Train net output #0: loss = 0.952311 (* 1 = 0.952311 loss)
I0526 18:21:43.561089 13044 sgd_solver.cpp:106] Iteration 460500, lr = 0.003
I0526 18:21:55.734200 13044 solver.cpp:237] Iteration 461250, loss = 1.51448
I0526 18:21:55.734236 13044 solver.cpp:253]     Train net output #0: loss = 1.51448 (* 1 = 1.51448 loss)
I0526 18:21:55.734252 13044 sgd_solver.cpp:106] Iteration 461250, lr = 0.003
I0526 18:22:07.916959 13044 solver.cpp:237] Iteration 462000, loss = 1.20058
I0526 18:22:07.917001 13044 solver.cpp:253]     Train net output #0: loss = 1.20058 (* 1 = 1.20058 loss)
I0526 18:22:07.917018 13044 sgd_solver.cpp:106] Iteration 462000, lr = 0.003
I0526 18:22:20.053731 13044 solver.cpp:237] Iteration 462750, loss = 0.98533
I0526 18:22:20.053890 13044 solver.cpp:253]     Train net output #0: loss = 0.985331 (* 1 = 0.985331 loss)
I0526 18:22:20.053905 13044 sgd_solver.cpp:106] Iteration 462750, lr = 0.003
I0526 18:22:32.202148 13044 solver.cpp:237] Iteration 463500, loss = 1.11534
I0526 18:22:32.202184 13044 solver.cpp:253]     Train net output #0: loss = 1.11534 (* 1 = 1.11534 loss)
I0526 18:22:32.202198 13044 sgd_solver.cpp:106] Iteration 463500, lr = 0.003
I0526 18:22:44.356972 13044 solver.cpp:237] Iteration 464250, loss = 0.813
I0526 18:22:44.357017 13044 solver.cpp:253]     Train net output #0: loss = 0.813002 (* 1 = 0.813002 loss)
I0526 18:22:44.357031 13044 sgd_solver.cpp:106] Iteration 464250, lr = 0.003
I0526 18:22:56.541774 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_465000.caffemodel
I0526 18:22:56.594512 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_465000.solverstate
I0526 18:22:56.621335 13044 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 18:24:09.516170 13044 solver.cpp:409]     Test net output #0: accuracy = 0.899353
I0526 18:24:09.516346 13044 solver.cpp:409]     Test net output #1: loss = 0.321524 (* 1 = 0.321524 loss)
I0526 18:24:30.399813 13044 solver.cpp:237] Iteration 465000, loss = 1.30573
I0526 18:24:30.399866 13044 solver.cpp:253]     Train net output #0: loss = 1.30574 (* 1 = 1.30574 loss)
I0526 18:24:30.399881 13044 sgd_solver.cpp:106] Iteration 465000, lr = 0.003
I0526 18:24:42.529592 13044 solver.cpp:237] Iteration 465750, loss = 0.887953
I0526 18:24:42.529762 13044 solver.cpp:253]     Train net output #0: loss = 0.887954 (* 1 = 0.887954 loss)
I0526 18:24:42.529777 13044 sgd_solver.cpp:106] Iteration 465750, lr = 0.003
I0526 18:24:54.664604 13044 solver.cpp:237] Iteration 466500, loss = 0.773639
I0526 18:24:54.664640 13044 solver.cpp:253]     Train net output #0: loss = 0.77364 (* 1 = 0.77364 loss)
I0526 18:24:54.664654 13044 sgd_solver.cpp:106] Iteration 466500, lr = 0.003
I0526 18:25:06.811853 13044 solver.cpp:237] Iteration 467250, loss = 1.16443
I0526 18:25:06.811897 13044 solver.cpp:253]     Train net output #0: loss = 1.16443 (* 1 = 1.16443 loss)
I0526 18:25:06.811910 13044 sgd_solver.cpp:106] Iteration 467250, lr = 0.003
I0526 18:25:18.966572 13044 solver.cpp:237] Iteration 468000, loss = 1.05983
I0526 18:25:18.966728 13044 solver.cpp:253]     Train net output #0: loss = 1.05983 (* 1 = 1.05983 loss)
I0526 18:25:18.966744 13044 sgd_solver.cpp:106] Iteration 468000, lr = 0.003
I0526 18:25:31.100559 13044 solver.cpp:237] Iteration 468750, loss = 1.05852
I0526 18:25:31.100605 13044 solver.cpp:253]     Train net output #0: loss = 1.05852 (* 1 = 1.05852 loss)
I0526 18:25:31.100618 13044 sgd_solver.cpp:106] Iteration 468750, lr = 0.003
I0526 18:25:43.183909 13044 solver.cpp:237] Iteration 469500, loss = 1.16231
I0526 18:25:43.183945 13044 solver.cpp:253]     Train net output #0: loss = 1.16232 (* 1 = 1.16232 loss)
I0526 18:25:43.183975 13044 sgd_solver.cpp:106] Iteration 469500, lr = 0.003
I0526 18:26:16.155958 13044 solver.cpp:237] Iteration 470250, loss = 1.27226
I0526 18:26:16.156153 13044 solver.cpp:253]     Train net output #0: loss = 1.27226 (* 1 = 1.27226 loss)
I0526 18:26:16.156168 13044 sgd_solver.cpp:106] Iteration 470250, lr = 0.003
I0526 18:26:28.268986 13044 solver.cpp:237] Iteration 471000, loss = 0.827358
I0526 18:26:28.269032 13044 solver.cpp:253]     Train net output #0: loss = 0.827359 (* 1 = 0.827359 loss)
I0526 18:26:28.269044 13044 sgd_solver.cpp:106] Iteration 471000, lr = 0.003
I0526 18:26:40.416723 13044 solver.cpp:237] Iteration 471750, loss = 0.752883
I0526 18:26:40.416760 13044 solver.cpp:253]     Train net output #0: loss = 0.752884 (* 1 = 0.752884 loss)
I0526 18:26:40.416777 13044 sgd_solver.cpp:106] Iteration 471750, lr = 0.003
I0526 18:26:52.542778 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_472500.caffemodel
I0526 18:26:52.593710 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_472500.solverstate
I0526 18:26:52.626293 13044 solver.cpp:237] Iteration 472500, loss = 1.05533
I0526 18:26:52.626339 13044 solver.cpp:253]     Train net output #0: loss = 1.05533 (* 1 = 1.05533 loss)
I0526 18:26:52.626361 13044 sgd_solver.cpp:106] Iteration 472500, lr = 0.003
I0526 18:27:04.711113 13044 solver.cpp:237] Iteration 473250, loss = 0.872838
I0526 18:27:04.711150 13044 solver.cpp:253]     Train net output #0: loss = 0.872839 (* 1 = 0.872839 loss)
I0526 18:27:04.711166 13044 sgd_solver.cpp:106] Iteration 473250, lr = 0.003
I0526 18:27:16.823122 13044 solver.cpp:237] Iteration 474000, loss = 0.869051
I0526 18:27:16.823170 13044 solver.cpp:253]     Train net output #0: loss = 0.869052 (* 1 = 0.869052 loss)
I0526 18:27:16.823184 13044 sgd_solver.cpp:106] Iteration 474000, lr = 0.003
I0526 18:27:28.928935 13044 solver.cpp:237] Iteration 474750, loss = 1.07465
I0526 18:27:28.929100 13044 solver.cpp:253]     Train net output #0: loss = 1.07465 (* 1 = 1.07465 loss)
I0526 18:27:28.929113 13044 sgd_solver.cpp:106] Iteration 474750, lr = 0.003
I0526 18:28:02.015136 13044 solver.cpp:237] Iteration 475500, loss = 1.47967
I0526 18:28:02.015316 13044 solver.cpp:253]     Train net output #0: loss = 1.47967 (* 1 = 1.47967 loss)
I0526 18:28:02.015331 13044 sgd_solver.cpp:106] Iteration 475500, lr = 0.003
I0526 18:28:14.229698 13044 solver.cpp:237] Iteration 476250, loss = 1.24057
I0526 18:28:14.229734 13044 solver.cpp:253]     Train net output #0: loss = 1.24057 (* 1 = 1.24057 loss)
I0526 18:28:14.229750 13044 sgd_solver.cpp:106] Iteration 476250, lr = 0.003
I0526 18:28:26.426072 13044 solver.cpp:237] Iteration 477000, loss = 1.23641
I0526 18:28:26.426113 13044 solver.cpp:253]     Train net output #0: loss = 1.23641 (* 1 = 1.23641 loss)
I0526 18:28:26.426127 13044 sgd_solver.cpp:106] Iteration 477000, lr = 0.003
I0526 18:28:38.592967 13044 solver.cpp:237] Iteration 477750, loss = 1.38134
I0526 18:28:38.593123 13044 solver.cpp:253]     Train net output #0: loss = 1.38134 (* 1 = 1.38134 loss)
I0526 18:28:38.593138 13044 sgd_solver.cpp:106] Iteration 477750, lr = 0.003
I0526 18:28:50.922610 13044 solver.cpp:237] Iteration 478500, loss = 1.13962
I0526 18:28:50.922652 13044 solver.cpp:253]     Train net output #0: loss = 1.13962 (* 1 = 1.13962 loss)
I0526 18:28:50.922665 13044 sgd_solver.cpp:106] Iteration 478500, lr = 0.003
I0526 18:29:03.096788 13044 solver.cpp:237] Iteration 479250, loss = 0.676661
I0526 18:29:03.096824 13044 solver.cpp:253]     Train net output #0: loss = 0.676661 (* 1 = 0.676661 loss)
I0526 18:29:03.096838 13044 sgd_solver.cpp:106] Iteration 479250, lr = 0.003
I0526 18:29:15.229964 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_480000.caffemodel
I0526 18:29:15.279201 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_480000.solverstate
I0526 18:29:15.304473 13044 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 18:30:07.304852 13044 solver.cpp:409]     Test net output #0: accuracy = 0.902916
I0526 18:30:07.305030 13044 solver.cpp:409]     Test net output #1: loss = 0.298805 (* 1 = 0.298805 loss)
I0526 18:30:28.150110 13044 solver.cpp:237] Iteration 480000, loss = 1.10354
I0526 18:30:28.150156 13044 solver.cpp:253]     Train net output #0: loss = 1.10354 (* 1 = 1.10354 loss)
I0526 18:30:28.150178 13044 sgd_solver.cpp:106] Iteration 480000, lr = 0.003
I0526 18:30:40.228539 13044 solver.cpp:237] Iteration 480750, loss = 0.765441
I0526 18:30:40.228706 13044 solver.cpp:253]     Train net output #0: loss = 0.765441 (* 1 = 0.765441 loss)
I0526 18:30:40.228721 13044 sgd_solver.cpp:106] Iteration 480750, lr = 0.003
I0526 18:30:52.346076 13044 solver.cpp:237] Iteration 481500, loss = 1.35924
I0526 18:30:52.346112 13044 solver.cpp:253]     Train net output #0: loss = 1.35924 (* 1 = 1.35924 loss)
I0526 18:30:52.346124 13044 sgd_solver.cpp:106] Iteration 481500, lr = 0.003
I0526 18:31:04.516892 13044 solver.cpp:237] Iteration 482250, loss = 1.10174
I0526 18:31:04.516938 13044 solver.cpp:253]     Train net output #0: loss = 1.10174 (* 1 = 1.10174 loss)
I0526 18:31:04.516952 13044 sgd_solver.cpp:106] Iteration 482250, lr = 0.003
I0526 18:31:16.668702 13044 solver.cpp:237] Iteration 483000, loss = 1.18778
I0526 18:31:16.668864 13044 solver.cpp:253]     Train net output #0: loss = 1.18778 (* 1 = 1.18778 loss)
I0526 18:31:16.668879 13044 sgd_solver.cpp:106] Iteration 483000, lr = 0.003
I0526 18:31:28.792670 13044 solver.cpp:237] Iteration 483750, loss = 1.02741
I0526 18:31:28.792714 13044 solver.cpp:253]     Train net output #0: loss = 1.02741 (* 1 = 1.02741 loss)
I0526 18:31:28.792727 13044 sgd_solver.cpp:106] Iteration 483750, lr = 0.003
I0526 18:31:40.924477 13044 solver.cpp:237] Iteration 484500, loss = 1.24015
I0526 18:31:40.924512 13044 solver.cpp:253]     Train net output #0: loss = 1.24015 (* 1 = 1.24015 loss)
I0526 18:31:40.924526 13044 sgd_solver.cpp:106] Iteration 484500, lr = 0.003
I0526 18:32:13.931104 13044 solver.cpp:237] Iteration 485250, loss = 1.19005
I0526 18:32:13.931289 13044 solver.cpp:253]     Train net output #0: loss = 1.19005 (* 1 = 1.19005 loss)
I0526 18:32:13.931304 13044 sgd_solver.cpp:106] Iteration 485250, lr = 0.003
I0526 18:32:26.053491 13044 solver.cpp:237] Iteration 486000, loss = 0.885365
I0526 18:32:26.053529 13044 solver.cpp:253]     Train net output #0: loss = 0.885365 (* 1 = 0.885365 loss)
I0526 18:32:26.053541 13044 sgd_solver.cpp:106] Iteration 486000, lr = 0.003
I0526 18:32:38.190879 13044 solver.cpp:237] Iteration 486750, loss = 1.00101
I0526 18:32:38.190928 13044 solver.cpp:253]     Train net output #0: loss = 1.00101 (* 1 = 1.00101 loss)
I0526 18:32:38.190942 13044 sgd_solver.cpp:106] Iteration 486750, lr = 0.003
I0526 18:32:50.331851 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_487500.caffemodel
I0526 18:32:50.381330 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_487500.solverstate
I0526 18:32:50.411489 13044 solver.cpp:237] Iteration 487500, loss = 1.30414
I0526 18:32:50.411536 13044 solver.cpp:253]     Train net output #0: loss = 1.30414 (* 1 = 1.30414 loss)
I0526 18:32:50.411555 13044 sgd_solver.cpp:106] Iteration 487500, lr = 0.003
I0526 18:33:02.540076 13044 solver.cpp:237] Iteration 488250, loss = 1.04688
I0526 18:33:02.540122 13044 solver.cpp:253]     Train net output #0: loss = 1.04688 (* 1 = 1.04688 loss)
I0526 18:33:02.540138 13044 sgd_solver.cpp:106] Iteration 488250, lr = 0.003
I0526 18:33:14.678526 13044 solver.cpp:237] Iteration 489000, loss = 1.39573
I0526 18:33:14.678561 13044 solver.cpp:253]     Train net output #0: loss = 1.39573 (* 1 = 1.39573 loss)
I0526 18:33:14.678575 13044 sgd_solver.cpp:106] Iteration 489000, lr = 0.003
I0526 18:33:26.806586 13044 solver.cpp:237] Iteration 489750, loss = 0.762581
I0526 18:33:26.806772 13044 solver.cpp:253]     Train net output #0: loss = 0.76258 (* 1 = 0.76258 loss)
I0526 18:33:26.806788 13044 sgd_solver.cpp:106] Iteration 489750, lr = 0.003
I0526 18:33:59.777736 13044 solver.cpp:237] Iteration 490500, loss = 1.07776
I0526 18:33:59.777920 13044 solver.cpp:253]     Train net output #0: loss = 1.07776 (* 1 = 1.07776 loss)
I0526 18:33:59.777935 13044 sgd_solver.cpp:106] Iteration 490500, lr = 0.003
I0526 18:34:11.912734 13044 solver.cpp:237] Iteration 491250, loss = 1.44814
I0526 18:34:11.912770 13044 solver.cpp:253]     Train net output #0: loss = 1.44814 (* 1 = 1.44814 loss)
I0526 18:34:11.912783 13044 sgd_solver.cpp:106] Iteration 491250, lr = 0.003
I0526 18:34:24.067270 13044 solver.cpp:237] Iteration 492000, loss = 1.60229
I0526 18:34:24.067315 13044 solver.cpp:253]     Train net output #0: loss = 1.60229 (* 1 = 1.60229 loss)
I0526 18:34:24.067329 13044 sgd_solver.cpp:106] Iteration 492000, lr = 0.003
I0526 18:34:36.208849 13044 solver.cpp:237] Iteration 492750, loss = 1.27937
I0526 18:34:36.209012 13044 solver.cpp:253]     Train net output #0: loss = 1.27937 (* 1 = 1.27937 loss)
I0526 18:34:36.209025 13044 sgd_solver.cpp:106] Iteration 492750, lr = 0.003
I0526 18:34:48.368607 13044 solver.cpp:237] Iteration 493500, loss = 1.17647
I0526 18:34:48.368655 13044 solver.cpp:253]     Train net output #0: loss = 1.17647 (* 1 = 1.17647 loss)
I0526 18:34:48.368669 13044 sgd_solver.cpp:106] Iteration 493500, lr = 0.003
I0526 18:35:00.539641 13044 solver.cpp:237] Iteration 494250, loss = 1.0601
I0526 18:35:00.539677 13044 solver.cpp:253]     Train net output #0: loss = 1.0601 (* 1 = 1.0601 loss)
I0526 18:35:00.539695 13044 sgd_solver.cpp:106] Iteration 494250, lr = 0.003
I0526 18:35:12.686611 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_495000.caffemodel
I0526 18:35:12.736227 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_495000.solverstate
I0526 18:35:12.762045 13044 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 18:36:25.469838 13044 solver.cpp:409]     Test net output #0: accuracy = 0.90276
I0526 18:36:25.470018 13044 solver.cpp:409]     Test net output #1: loss = 0.312131 (* 1 = 0.312131 loss)
I0526 18:36:46.308787 13044 solver.cpp:237] Iteration 495000, loss = 0.962196
I0526 18:36:46.308841 13044 solver.cpp:253]     Train net output #0: loss = 0.962196 (* 1 = 0.962196 loss)
I0526 18:36:46.308856 13044 sgd_solver.cpp:106] Iteration 495000, lr = 0.003
I0526 18:36:58.469480 13044 solver.cpp:237] Iteration 495750, loss = 0.922362
I0526 18:36:58.469648 13044 solver.cpp:253]     Train net output #0: loss = 0.922362 (* 1 = 0.922362 loss)
I0526 18:36:58.469663 13044 sgd_solver.cpp:106] Iteration 495750, lr = 0.003
I0526 18:37:10.639369 13044 solver.cpp:237] Iteration 496500, loss = 1.34805
I0526 18:37:10.639418 13044 solver.cpp:253]     Train net output #0: loss = 1.34805 (* 1 = 1.34805 loss)
I0526 18:37:10.639432 13044 sgd_solver.cpp:106] Iteration 496500, lr = 0.003
I0526 18:37:22.875463 13044 solver.cpp:237] Iteration 497250, loss = 1.15792
I0526 18:37:22.875499 13044 solver.cpp:253]     Train net output #0: loss = 1.15792 (* 1 = 1.15792 loss)
I0526 18:37:22.875519 13044 sgd_solver.cpp:106] Iteration 497250, lr = 0.003
I0526 18:37:35.088537 13044 solver.cpp:237] Iteration 498000, loss = 1.14688
I0526 18:37:35.088723 13044 solver.cpp:253]     Train net output #0: loss = 1.14688 (* 1 = 1.14688 loss)
I0526 18:37:35.088738 13044 sgd_solver.cpp:106] Iteration 498000, lr = 0.003
I0526 18:37:47.299856 13044 solver.cpp:237] Iteration 498750, loss = 1.20047
I0526 18:37:47.299891 13044 solver.cpp:253]     Train net output #0: loss = 1.20047 (* 1 = 1.20047 loss)
I0526 18:37:47.299906 13044 sgd_solver.cpp:106] Iteration 498750, lr = 0.003
I0526 18:37:59.529146 13044 solver.cpp:237] Iteration 499500, loss = 1.29875
I0526 18:37:59.529184 13044 solver.cpp:253]     Train net output #0: loss = 1.29875 (* 1 = 1.29875 loss)
I0526 18:37:59.529201 13044 sgd_solver.cpp:106] Iteration 499500, lr = 0.003
I0526 18:38:32.578927 13044 solver.cpp:237] Iteration 500250, loss = 1.26364
I0526 18:38:32.579107 13044 solver.cpp:253]     Train net output #0: loss = 1.26364 (* 1 = 1.26364 loss)
I0526 18:38:32.579120 13044 sgd_solver.cpp:106] Iteration 500250, lr = 0.003
I0526 18:38:44.776984 13044 solver.cpp:237] Iteration 501000, loss = 0.896764
I0526 18:38:44.777021 13044 solver.cpp:253]     Train net output #0: loss = 0.896763 (* 1 = 0.896763 loss)
I0526 18:38:44.777034 13044 sgd_solver.cpp:106] Iteration 501000, lr = 0.003
I0526 18:38:56.973438 13044 solver.cpp:237] Iteration 501750, loss = 0.876312
I0526 18:38:56.973484 13044 solver.cpp:253]     Train net output #0: loss = 0.876311 (* 1 = 0.876311 loss)
I0526 18:38:56.973496 13044 sgd_solver.cpp:106] Iteration 501750, lr = 0.003
I0526 18:39:09.147617 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_502500.caffemodel
I0526 18:39:09.199259 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_502500.solverstate
I0526 18:39:09.232014 13044 solver.cpp:237] Iteration 502500, loss = 1.49817
I0526 18:39:09.232064 13044 solver.cpp:253]     Train net output #0: loss = 1.49816 (* 1 = 1.49816 loss)
I0526 18:39:09.232081 13044 sgd_solver.cpp:106] Iteration 502500, lr = 0.003
I0526 18:39:21.416352 13044 solver.cpp:237] Iteration 503250, loss = 1.10321
I0526 18:39:21.416398 13044 solver.cpp:253]     Train net output #0: loss = 1.10321 (* 1 = 1.10321 loss)
I0526 18:39:21.416411 13044 sgd_solver.cpp:106] Iteration 503250, lr = 0.003
I0526 18:39:33.585258 13044 solver.cpp:237] Iteration 504000, loss = 1.55376
I0526 18:39:33.585294 13044 solver.cpp:253]     Train net output #0: loss = 1.55376 (* 1 = 1.55376 loss)
I0526 18:39:33.585307 13044 sgd_solver.cpp:106] Iteration 504000, lr = 0.003
I0526 18:39:45.755484 13044 solver.cpp:237] Iteration 504750, loss = 1.21318
I0526 18:39:45.755666 13044 solver.cpp:253]     Train net output #0: loss = 1.21318 (* 1 = 1.21318 loss)
I0526 18:39:45.755681 13044 sgd_solver.cpp:106] Iteration 504750, lr = 0.003
I0526 18:40:18.788679 13044 solver.cpp:237] Iteration 505500, loss = 1.50589
I0526 18:40:18.788864 13044 solver.cpp:253]     Train net output #0: loss = 1.50588 (* 1 = 1.50588 loss)
I0526 18:40:18.788880 13044 sgd_solver.cpp:106] Iteration 505500, lr = 0.003
I0526 18:40:30.905257 13044 solver.cpp:237] Iteration 506250, loss = 1.35894
I0526 18:40:30.905303 13044 solver.cpp:253]     Train net output #0: loss = 1.35894 (* 1 = 1.35894 loss)
I0526 18:40:30.905316 13044 sgd_solver.cpp:106] Iteration 506250, lr = 0.003
I0526 18:40:43.038662 13044 solver.cpp:237] Iteration 507000, loss = 1.53905
I0526 18:40:43.038698 13044 solver.cpp:253]     Train net output #0: loss = 1.53904 (* 1 = 1.53904 loss)
I0526 18:40:43.038712 13044 sgd_solver.cpp:106] Iteration 507000, lr = 0.003
I0526 18:40:55.219573 13044 solver.cpp:237] Iteration 507750, loss = 1.24617
I0526 18:40:55.219754 13044 solver.cpp:253]     Train net output #0: loss = 1.24617 (* 1 = 1.24617 loss)
I0526 18:40:55.219769 13044 sgd_solver.cpp:106] Iteration 507750, lr = 0.003
I0526 18:41:07.354579 13044 solver.cpp:237] Iteration 508500, loss = 1.05115
I0526 18:41:07.354614 13044 solver.cpp:253]     Train net output #0: loss = 1.05115 (* 1 = 1.05115 loss)
I0526 18:41:07.354627 13044 sgd_solver.cpp:106] Iteration 508500, lr = 0.003
I0526 18:41:19.525789 13044 solver.cpp:237] Iteration 509250, loss = 1.35094
I0526 18:41:19.525825 13044 solver.cpp:253]     Train net output #0: loss = 1.35094 (* 1 = 1.35094 loss)
I0526 18:41:19.525843 13044 sgd_solver.cpp:106] Iteration 509250, lr = 0.003
I0526 18:41:31.682718 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_510000.caffemodel
I0526 18:41:31.734225 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_510000.solverstate
I0526 18:41:31.761940 13044 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 18:42:23.430676 13044 solver.cpp:409]     Test net output #0: accuracy = 0.903964
I0526 18:42:23.430856 13044 solver.cpp:409]     Test net output #1: loss = 0.319645 (* 1 = 0.319645 loss)
I0526 18:42:44.299255 13044 solver.cpp:237] Iteration 510000, loss = 0.77153
I0526 18:42:44.299305 13044 solver.cpp:253]     Train net output #0: loss = 0.771529 (* 1 = 0.771529 loss)
I0526 18:42:44.299321 13044 sgd_solver.cpp:106] Iteration 510000, lr = 0.003
I0526 18:42:56.494105 13044 solver.cpp:237] Iteration 510750, loss = 1.08573
I0526 18:42:56.494274 13044 solver.cpp:253]     Train net output #0: loss = 1.08573 (* 1 = 1.08573 loss)
I0526 18:42:56.494288 13044 sgd_solver.cpp:106] Iteration 510750, lr = 0.003
I0526 18:43:08.659715 13044 solver.cpp:237] Iteration 511500, loss = 1.23658
I0526 18:43:08.659764 13044 solver.cpp:253]     Train net output #0: loss = 1.23658 (* 1 = 1.23658 loss)
I0526 18:43:08.659780 13044 sgd_solver.cpp:106] Iteration 511500, lr = 0.003
I0526 18:43:20.769438 13044 solver.cpp:237] Iteration 512250, loss = 1.55883
I0526 18:43:20.769474 13044 solver.cpp:253]     Train net output #0: loss = 1.55883 (* 1 = 1.55883 loss)
I0526 18:43:20.769490 13044 sgd_solver.cpp:106] Iteration 512250, lr = 0.003
I0526 18:43:32.881757 13044 solver.cpp:237] Iteration 513000, loss = 0.935659
I0526 18:43:32.881935 13044 solver.cpp:253]     Train net output #0: loss = 0.935659 (* 1 = 0.935659 loss)
I0526 18:43:32.881950 13044 sgd_solver.cpp:106] Iteration 513000, lr = 0.003
I0526 18:43:45.014813 13044 solver.cpp:237] Iteration 513750, loss = 1.51468
I0526 18:43:45.014849 13044 solver.cpp:253]     Train net output #0: loss = 1.51468 (* 1 = 1.51468 loss)
I0526 18:43:45.014863 13044 sgd_solver.cpp:106] Iteration 513750, lr = 0.003
I0526 18:43:57.179749 13044 solver.cpp:237] Iteration 514500, loss = 1.58318
I0526 18:43:57.179791 13044 solver.cpp:253]     Train net output #0: loss = 1.58318 (* 1 = 1.58318 loss)
I0526 18:43:57.179805 13044 sgd_solver.cpp:106] Iteration 514500, lr = 0.003
I0526 18:44:30.190845 13044 solver.cpp:237] Iteration 515250, loss = 1.01078
I0526 18:44:30.191030 13044 solver.cpp:253]     Train net output #0: loss = 1.01078 (* 1 = 1.01078 loss)
I0526 18:44:30.191045 13044 sgd_solver.cpp:106] Iteration 515250, lr = 0.003
I0526 18:44:42.346889 13044 solver.cpp:237] Iteration 516000, loss = 1.23068
I0526 18:44:42.346936 13044 solver.cpp:253]     Train net output #0: loss = 1.23068 (* 1 = 1.23068 loss)
I0526 18:44:42.346949 13044 sgd_solver.cpp:106] Iteration 516000, lr = 0.003
I0526 18:44:54.508965 13044 solver.cpp:237] Iteration 516750, loss = 1.37843
I0526 18:44:54.508999 13044 solver.cpp:253]     Train net output #0: loss = 1.37843 (* 1 = 1.37843 loss)
I0526 18:44:54.509013 13044 sgd_solver.cpp:106] Iteration 516750, lr = 0.003
I0526 18:45:06.643705 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_517500.caffemodel
I0526 18:45:06.693532 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_517500.solverstate
I0526 18:45:06.724112 13044 solver.cpp:237] Iteration 517500, loss = 0.840537
I0526 18:45:06.724158 13044 solver.cpp:253]     Train net output #0: loss = 0.840537 (* 1 = 0.840537 loss)
I0526 18:45:06.724174 13044 sgd_solver.cpp:106] Iteration 517500, lr = 0.003
I0526 18:45:18.857358 13044 solver.cpp:237] Iteration 518250, loss = 1.31008
I0526 18:45:18.857394 13044 solver.cpp:253]     Train net output #0: loss = 1.31008 (* 1 = 1.31008 loss)
I0526 18:45:18.857410 13044 sgd_solver.cpp:106] Iteration 518250, lr = 0.003
I0526 18:45:31.039702 13044 solver.cpp:237] Iteration 519000, loss = 0.911852
I0526 18:45:31.039749 13044 solver.cpp:253]     Train net output #0: loss = 0.911852 (* 1 = 0.911852 loss)
I0526 18:45:31.039763 13044 sgd_solver.cpp:106] Iteration 519000, lr = 0.003
I0526 18:45:43.225009 13044 solver.cpp:237] Iteration 519750, loss = 0.822904
I0526 18:45:43.225183 13044 solver.cpp:253]     Train net output #0: loss = 0.822904 (* 1 = 0.822904 loss)
I0526 18:45:43.225196 13044 sgd_solver.cpp:106] Iteration 519750, lr = 0.003
I0526 18:46:16.259317 13044 solver.cpp:237] Iteration 520500, loss = 0.889622
I0526 18:46:16.259505 13044 solver.cpp:253]     Train net output #0: loss = 0.889622 (* 1 = 0.889622 loss)
I0526 18:46:16.259526 13044 sgd_solver.cpp:106] Iteration 520500, lr = 0.003
I0526 18:46:28.447680 13044 solver.cpp:237] Iteration 521250, loss = 0.695986
I0526 18:46:28.447727 13044 solver.cpp:253]     Train net output #0: loss = 0.695986 (* 1 = 0.695986 loss)
I0526 18:46:28.447742 13044 sgd_solver.cpp:106] Iteration 521250, lr = 0.003
I0526 18:46:40.621289 13044 solver.cpp:237] Iteration 522000, loss = 1.24159
I0526 18:46:40.621323 13044 solver.cpp:253]     Train net output #0: loss = 1.24159 (* 1 = 1.24159 loss)
I0526 18:46:40.621336 13044 sgd_solver.cpp:106] Iteration 522000, lr = 0.003
I0526 18:46:52.752836 13044 solver.cpp:237] Iteration 522750, loss = 1.17602
I0526 18:46:52.753018 13044 solver.cpp:253]     Train net output #0: loss = 1.17602 (* 1 = 1.17602 loss)
I0526 18:46:52.753034 13044 sgd_solver.cpp:106] Iteration 522750, lr = 0.003
I0526 18:47:04.884814 13044 solver.cpp:237] Iteration 523500, loss = 1.48173
I0526 18:47:04.884850 13044 solver.cpp:253]     Train net output #0: loss = 1.48173 (* 1 = 1.48173 loss)
I0526 18:47:04.884863 13044 sgd_solver.cpp:106] Iteration 523500, lr = 0.003
I0526 18:47:17.066686 13044 solver.cpp:237] Iteration 524250, loss = 1.10269
I0526 18:47:17.066728 13044 solver.cpp:253]     Train net output #0: loss = 1.10269 (* 1 = 1.10269 loss)
I0526 18:47:17.066746 13044 sgd_solver.cpp:106] Iteration 524250, lr = 0.003
I0526 18:47:29.227108 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_525000.caffemodel
I0526 18:47:29.277876 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_525000.solverstate
I0526 18:47:29.303670 13044 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 18:48:42.169929 13044 solver.cpp:409]     Test net output #0: accuracy = 0.905192
I0526 18:48:42.170114 13044 solver.cpp:409]     Test net output #1: loss = 0.300872 (* 1 = 0.300872 loss)
I0526 18:49:03.036634 13044 solver.cpp:237] Iteration 525000, loss = 1.04255
I0526 18:49:03.036685 13044 solver.cpp:253]     Train net output #0: loss = 1.04255 (* 1 = 1.04255 loss)
I0526 18:49:03.036700 13044 sgd_solver.cpp:106] Iteration 525000, lr = 0.003
I0526 18:49:15.110926 13044 solver.cpp:237] Iteration 525750, loss = 1.24383
I0526 18:49:15.111109 13044 solver.cpp:253]     Train net output #0: loss = 1.24383 (* 1 = 1.24383 loss)
I0526 18:49:15.111122 13044 sgd_solver.cpp:106] Iteration 525750, lr = 0.003
I0526 18:49:27.254720 13044 solver.cpp:237] Iteration 526500, loss = 1.57758
I0526 18:49:27.254755 13044 solver.cpp:253]     Train net output #0: loss = 1.57758 (* 1 = 1.57758 loss)
I0526 18:49:27.254768 13044 sgd_solver.cpp:106] Iteration 526500, lr = 0.003
I0526 18:49:39.383828 13044 solver.cpp:237] Iteration 527250, loss = 1.14748
I0526 18:49:39.383869 13044 solver.cpp:253]     Train net output #0: loss = 1.14748 (* 1 = 1.14748 loss)
I0526 18:49:39.383887 13044 sgd_solver.cpp:106] Iteration 527250, lr = 0.003
I0526 18:49:51.508990 13044 solver.cpp:237] Iteration 528000, loss = 0.846506
I0526 18:49:51.509167 13044 solver.cpp:253]     Train net output #0: loss = 0.846506 (* 1 = 0.846506 loss)
I0526 18:49:51.509181 13044 sgd_solver.cpp:106] Iteration 528000, lr = 0.003
I0526 18:50:03.629904 13044 solver.cpp:237] Iteration 528750, loss = 1.14584
I0526 18:50:03.629948 13044 solver.cpp:253]     Train net output #0: loss = 1.14584 (* 1 = 1.14584 loss)
I0526 18:50:03.629962 13044 sgd_solver.cpp:106] Iteration 528750, lr = 0.003
I0526 18:50:15.764426 13044 solver.cpp:237] Iteration 529500, loss = 0.760922
I0526 18:50:15.764462 13044 solver.cpp:253]     Train net output #0: loss = 0.760922 (* 1 = 0.760922 loss)
I0526 18:50:15.764479 13044 sgd_solver.cpp:106] Iteration 529500, lr = 0.003
I0526 18:50:48.796686 13044 solver.cpp:237] Iteration 530250, loss = 1.23773
I0526 18:50:48.796874 13044 solver.cpp:253]     Train net output #0: loss = 1.23773 (* 1 = 1.23773 loss)
I0526 18:50:48.796890 13044 sgd_solver.cpp:106] Iteration 530250, lr = 0.003
I0526 18:51:00.891692 13044 solver.cpp:237] Iteration 531000, loss = 1.06071
I0526 18:51:00.891741 13044 solver.cpp:253]     Train net output #0: loss = 1.06071 (* 1 = 1.06071 loss)
I0526 18:51:00.891753 13044 sgd_solver.cpp:106] Iteration 531000, lr = 0.003
I0526 18:51:13.036123 13044 solver.cpp:237] Iteration 531750, loss = 0.955337
I0526 18:51:13.036160 13044 solver.cpp:253]     Train net output #0: loss = 0.955337 (* 1 = 0.955337 loss)
I0526 18:51:13.036173 13044 sgd_solver.cpp:106] Iteration 531750, lr = 0.003
I0526 18:51:25.158044 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_532500.caffemodel
I0526 18:51:25.207458 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_532500.solverstate
I0526 18:51:25.241148 13044 solver.cpp:237] Iteration 532500, loss = 0.956386
I0526 18:51:25.241199 13044 solver.cpp:253]     Train net output #0: loss = 0.956385 (* 1 = 0.956385 loss)
I0526 18:51:25.241214 13044 sgd_solver.cpp:106] Iteration 532500, lr = 0.003
I0526 18:51:37.369035 13044 solver.cpp:237] Iteration 533250, loss = 0.98597
I0526 18:51:37.369072 13044 solver.cpp:253]     Train net output #0: loss = 0.985969 (* 1 = 0.985969 loss)
I0526 18:51:37.369086 13044 sgd_solver.cpp:106] Iteration 533250, lr = 0.003
I0526 18:51:49.504505 13044 solver.cpp:237] Iteration 534000, loss = 1.18317
I0526 18:51:49.504552 13044 solver.cpp:253]     Train net output #0: loss = 1.18317 (* 1 = 1.18317 loss)
I0526 18:51:49.504565 13044 sgd_solver.cpp:106] Iteration 534000, lr = 0.003
I0526 18:52:01.637738 13044 solver.cpp:237] Iteration 534750, loss = 1.38338
I0526 18:52:01.637910 13044 solver.cpp:253]     Train net output #0: loss = 1.38338 (* 1 = 1.38338 loss)
I0526 18:52:01.637923 13044 sgd_solver.cpp:106] Iteration 534750, lr = 0.003
I0526 18:52:34.623447 13044 solver.cpp:237] Iteration 535500, loss = 1.41382
I0526 18:52:34.623636 13044 solver.cpp:253]     Train net output #0: loss = 1.41382 (* 1 = 1.41382 loss)
I0526 18:52:34.623651 13044 sgd_solver.cpp:106] Iteration 535500, lr = 0.003
I0526 18:52:46.766026 13044 solver.cpp:237] Iteration 536250, loss = 1.28376
I0526 18:52:46.766063 13044 solver.cpp:253]     Train net output #0: loss = 1.28376 (* 1 = 1.28376 loss)
I0526 18:52:46.766077 13044 sgd_solver.cpp:106] Iteration 536250, lr = 0.003
I0526 18:52:58.908676 13044 solver.cpp:237] Iteration 537000, loss = 1.15097
I0526 18:52:58.908721 13044 solver.cpp:253]     Train net output #0: loss = 1.15097 (* 1 = 1.15097 loss)
I0526 18:52:58.908740 13044 sgd_solver.cpp:106] Iteration 537000, lr = 0.003
I0526 18:53:11.055688 13044 solver.cpp:237] Iteration 537750, loss = 1.00473
I0526 18:53:11.055867 13044 solver.cpp:253]     Train net output #0: loss = 1.00473 (* 1 = 1.00473 loss)
I0526 18:53:11.055882 13044 sgd_solver.cpp:106] Iteration 537750, lr = 0.003
I0526 18:53:23.185075 13044 solver.cpp:237] Iteration 538500, loss = 0.867276
I0526 18:53:23.185119 13044 solver.cpp:253]     Train net output #0: loss = 0.867275 (* 1 = 0.867275 loss)
I0526 18:53:23.185132 13044 sgd_solver.cpp:106] Iteration 538500, lr = 0.003
I0526 18:53:35.324406 13044 solver.cpp:237] Iteration 539250, loss = 1.20157
I0526 18:53:35.324442 13044 solver.cpp:253]     Train net output #0: loss = 1.20157 (* 1 = 1.20157 loss)
I0526 18:53:35.324460 13044 sgd_solver.cpp:106] Iteration 539250, lr = 0.003
I0526 18:53:47.424768 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_540000.caffemodel
I0526 18:53:47.476040 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_540000.solverstate
I0526 18:53:47.502934 13044 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 18:54:39.483753 13044 solver.cpp:409]     Test net output #0: accuracy = 0.905278
I0526 18:54:39.483938 13044 solver.cpp:409]     Test net output #1: loss = 0.324695 (* 1 = 0.324695 loss)
I0526 18:55:00.357453 13044 solver.cpp:237] Iteration 540000, loss = 1.19698
I0526 18:55:00.357506 13044 solver.cpp:253]     Train net output #0: loss = 1.19698 (* 1 = 1.19698 loss)
I0526 18:55:00.357522 13044 sgd_solver.cpp:106] Iteration 540000, lr = 0.003
I0526 18:55:12.525121 13044 solver.cpp:237] Iteration 540750, loss = 1.00034
I0526 18:55:12.525315 13044 solver.cpp:253]     Train net output #0: loss = 1.00034 (* 1 = 1.00034 loss)
I0526 18:55:12.525328 13044 sgd_solver.cpp:106] Iteration 540750, lr = 0.003
I0526 18:55:24.727427 13044 solver.cpp:237] Iteration 541500, loss = 1.08416
I0526 18:55:24.727463 13044 solver.cpp:253]     Train net output #0: loss = 1.08416 (* 1 = 1.08416 loss)
I0526 18:55:24.727475 13044 sgd_solver.cpp:106] Iteration 541500, lr = 0.003
I0526 18:55:36.912325 13044 solver.cpp:237] Iteration 542250, loss = 1.08796
I0526 18:55:36.912375 13044 solver.cpp:253]     Train net output #0: loss = 1.08796 (* 1 = 1.08796 loss)
I0526 18:55:36.912389 13044 sgd_solver.cpp:106] Iteration 542250, lr = 0.003
I0526 18:55:49.109215 13044 solver.cpp:237] Iteration 543000, loss = 0.841128
I0526 18:55:49.109386 13044 solver.cpp:253]     Train net output #0: loss = 0.841128 (* 1 = 0.841128 loss)
I0526 18:55:49.109414 13044 sgd_solver.cpp:106] Iteration 543000, lr = 0.003
I0526 18:56:01.351311 13044 solver.cpp:237] Iteration 543750, loss = 0.90297
I0526 18:56:01.351359 13044 solver.cpp:253]     Train net output #0: loss = 0.90297 (* 1 = 0.90297 loss)
I0526 18:56:01.351373 13044 sgd_solver.cpp:106] Iteration 543750, lr = 0.003
I0526 18:56:13.584190 13044 solver.cpp:237] Iteration 544500, loss = 1.18177
I0526 18:56:13.584226 13044 solver.cpp:253]     Train net output #0: loss = 1.18177 (* 1 = 1.18177 loss)
I0526 18:56:13.584239 13044 sgd_solver.cpp:106] Iteration 544500, lr = 0.003
I0526 18:56:46.700018 13044 solver.cpp:237] Iteration 545250, loss = 1.16658
I0526 18:56:46.700206 13044 solver.cpp:253]     Train net output #0: loss = 1.16658 (* 1 = 1.16658 loss)
I0526 18:56:46.700222 13044 sgd_solver.cpp:106] Iteration 545250, lr = 0.003
I0526 18:56:58.886878 13044 solver.cpp:237] Iteration 546000, loss = 1.12181
I0526 18:56:58.886915 13044 solver.cpp:253]     Train net output #0: loss = 1.12181 (* 1 = 1.12181 loss)
I0526 18:56:58.886929 13044 sgd_solver.cpp:106] Iteration 546000, lr = 0.003
I0526 18:57:11.058223 13044 solver.cpp:237] Iteration 546750, loss = 0.893089
I0526 18:57:11.058274 13044 solver.cpp:253]     Train net output #0: loss = 0.893088 (* 1 = 0.893088 loss)
I0526 18:57:11.058287 13044 sgd_solver.cpp:106] Iteration 546750, lr = 0.003
I0526 18:57:23.196246 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_547500.caffemodel
I0526 18:57:23.247484 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_547500.solverstate
I0526 18:57:23.279778 13044 solver.cpp:237] Iteration 547500, loss = 1.05366
I0526 18:57:23.279824 13044 solver.cpp:253]     Train net output #0: loss = 1.05366 (* 1 = 1.05366 loss)
I0526 18:57:23.279844 13044 sgd_solver.cpp:106] Iteration 547500, lr = 0.003
I0526 18:57:35.437935 13044 solver.cpp:237] Iteration 548250, loss = 1.46461
I0526 18:57:35.437980 13044 solver.cpp:253]     Train net output #0: loss = 1.46461 (* 1 = 1.46461 loss)
I0526 18:57:35.437997 13044 sgd_solver.cpp:106] Iteration 548250, lr = 0.003
I0526 18:57:47.596285 13044 solver.cpp:237] Iteration 549000, loss = 0.931214
I0526 18:57:47.596323 13044 solver.cpp:253]     Train net output #0: loss = 0.931214 (* 1 = 0.931214 loss)
I0526 18:57:47.596335 13044 sgd_solver.cpp:106] Iteration 549000, lr = 0.003
I0526 18:57:59.767357 13044 solver.cpp:237] Iteration 549750, loss = 1.05843
I0526 18:57:59.767559 13044 solver.cpp:253]     Train net output #0: loss = 1.05843 (* 1 = 1.05843 loss)
I0526 18:57:59.767573 13044 sgd_solver.cpp:106] Iteration 549750, lr = 0.003
I0526 18:58:32.913405 13044 solver.cpp:237] Iteration 550500, loss = 1.30097
I0526 18:58:32.913597 13044 solver.cpp:253]     Train net output #0: loss = 1.30097 (* 1 = 1.30097 loss)
I0526 18:58:32.913612 13044 sgd_solver.cpp:106] Iteration 550500, lr = 0.003
I0526 18:58:45.120800 13044 solver.cpp:237] Iteration 551250, loss = 1.04528
I0526 18:58:45.120836 13044 solver.cpp:253]     Train net output #0: loss = 1.04528 (* 1 = 1.04528 loss)
I0526 18:58:45.120848 13044 sgd_solver.cpp:106] Iteration 551250, lr = 0.003
I0526 18:58:57.312741 13044 solver.cpp:237] Iteration 552000, loss = 1.05775
I0526 18:58:57.312788 13044 solver.cpp:253]     Train net output #0: loss = 1.05775 (* 1 = 1.05775 loss)
I0526 18:58:57.312803 13044 sgd_solver.cpp:106] Iteration 552000, lr = 0.003
I0526 18:59:09.537945 13044 solver.cpp:237] Iteration 552750, loss = 1.03738
I0526 18:59:09.538115 13044 solver.cpp:253]     Train net output #0: loss = 1.03738 (* 1 = 1.03738 loss)
I0526 18:59:09.538130 13044 sgd_solver.cpp:106] Iteration 552750, lr = 0.003
I0526 18:59:21.715283 13044 solver.cpp:237] Iteration 553500, loss = 1.2171
I0526 18:59:21.715327 13044 solver.cpp:253]     Train net output #0: loss = 1.2171 (* 1 = 1.2171 loss)
I0526 18:59:21.715347 13044 sgd_solver.cpp:106] Iteration 553500, lr = 0.003
I0526 18:59:33.961220 13044 solver.cpp:237] Iteration 554250, loss = 0.924435
I0526 18:59:33.961256 13044 solver.cpp:253]     Train net output #0: loss = 0.924435 (* 1 = 0.924435 loss)
I0526 18:59:33.961272 13044 sgd_solver.cpp:106] Iteration 554250, lr = 0.003
I0526 18:59:46.120887 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_555000.caffemodel
I0526 18:59:46.175832 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_555000.solverstate
I0526 18:59:46.206856 13044 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 19:00:59.122213 13044 solver.cpp:409]     Test net output #0: accuracy = 0.905338
I0526 19:00:59.122413 13044 solver.cpp:409]     Test net output #1: loss = 0.308818 (* 1 = 0.308818 loss)
I0526 19:01:20.004395 13044 solver.cpp:237] Iteration 555000, loss = 1.30197
I0526 19:01:20.004446 13044 solver.cpp:253]     Train net output #0: loss = 1.30197 (* 1 = 1.30197 loss)
I0526 19:01:20.004464 13044 sgd_solver.cpp:106] Iteration 555000, lr = 0.003
I0526 19:01:32.094372 13044 solver.cpp:237] Iteration 555750, loss = 0.945401
I0526 19:01:32.094549 13044 solver.cpp:253]     Train net output #0: loss = 0.9454 (* 1 = 0.9454 loss)
I0526 19:01:32.094563 13044 sgd_solver.cpp:106] Iteration 555750, lr = 0.003
I0526 19:01:44.178459 13044 solver.cpp:237] Iteration 556500, loss = 0.945195
I0526 19:01:44.178504 13044 solver.cpp:253]     Train net output #0: loss = 0.945194 (* 1 = 0.945194 loss)
I0526 19:01:44.178521 13044 sgd_solver.cpp:106] Iteration 556500, lr = 0.003
I0526 19:01:56.257189 13044 solver.cpp:237] Iteration 557250, loss = 1.03133
I0526 19:01:56.257225 13044 solver.cpp:253]     Train net output #0: loss = 1.03132 (* 1 = 1.03132 loss)
I0526 19:01:56.257239 13044 sgd_solver.cpp:106] Iteration 557250, lr = 0.003
I0526 19:02:08.345062 13044 solver.cpp:237] Iteration 558000, loss = 1.13722
I0526 19:02:08.345240 13044 solver.cpp:253]     Train net output #0: loss = 1.13722 (* 1 = 1.13722 loss)
I0526 19:02:08.345253 13044 sgd_solver.cpp:106] Iteration 558000, lr = 0.003
I0526 19:02:20.464332 13044 solver.cpp:237] Iteration 558750, loss = 1.36704
I0526 19:02:20.464368 13044 solver.cpp:253]     Train net output #0: loss = 1.36704 (* 1 = 1.36704 loss)
I0526 19:02:20.464385 13044 sgd_solver.cpp:106] Iteration 558750, lr = 0.003
I0526 19:02:32.564088 13044 solver.cpp:237] Iteration 559500, loss = 1.13476
I0526 19:02:32.564132 13044 solver.cpp:253]     Train net output #0: loss = 1.13476 (* 1 = 1.13476 loss)
I0526 19:02:32.564148 13044 sgd_solver.cpp:106] Iteration 559500, lr = 0.003
I0526 19:03:05.586434 13044 solver.cpp:237] Iteration 560250, loss = 1.43809
I0526 19:03:05.586627 13044 solver.cpp:253]     Train net output #0: loss = 1.43809 (* 1 = 1.43809 loss)
I0526 19:03:05.586642 13044 sgd_solver.cpp:106] Iteration 560250, lr = 0.003
I0526 19:03:17.751446 13044 solver.cpp:237] Iteration 561000, loss = 0.803852
I0526 19:03:17.751482 13044 solver.cpp:253]     Train net output #0: loss = 0.803851 (* 1 = 0.803851 loss)
I0526 19:03:17.751495 13044 sgd_solver.cpp:106] Iteration 561000, lr = 0.003
I0526 19:03:29.920778 13044 solver.cpp:237] Iteration 561750, loss = 1.10606
I0526 19:03:29.920822 13044 solver.cpp:253]     Train net output #0: loss = 1.10606 (* 1 = 1.10606 loss)
I0526 19:03:29.920840 13044 sgd_solver.cpp:106] Iteration 561750, lr = 0.003
I0526 19:03:42.054525 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_562500.caffemodel
I0526 19:03:42.104475 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_562500.solverstate
I0526 19:03:42.135440 13044 solver.cpp:237] Iteration 562500, loss = 1.29937
I0526 19:03:42.135485 13044 solver.cpp:253]     Train net output #0: loss = 1.29937 (* 1 = 1.29937 loss)
I0526 19:03:42.135499 13044 sgd_solver.cpp:106] Iteration 562500, lr = 0.003
I0526 19:03:54.322402 13044 solver.cpp:237] Iteration 563250, loss = 1.0751
I0526 19:03:54.322449 13044 solver.cpp:253]     Train net output #0: loss = 1.0751 (* 1 = 1.0751 loss)
I0526 19:03:54.322464 13044 sgd_solver.cpp:106] Iteration 563250, lr = 0.003
I0526 19:04:06.483816 13044 solver.cpp:237] Iteration 564000, loss = 1.27979
I0526 19:04:06.483852 13044 solver.cpp:253]     Train net output #0: loss = 1.27979 (* 1 = 1.27979 loss)
I0526 19:04:06.483870 13044 sgd_solver.cpp:106] Iteration 564000, lr = 0.003
I0526 19:04:18.610415 13044 solver.cpp:237] Iteration 564750, loss = 0.882998
I0526 19:04:18.610602 13044 solver.cpp:253]     Train net output #0: loss = 0.882998 (* 1 = 0.882998 loss)
I0526 19:04:18.610620 13044 sgd_solver.cpp:106] Iteration 564750, lr = 0.003
I0526 19:04:51.644718 13044 solver.cpp:237] Iteration 565500, loss = 1.11439
I0526 19:04:51.644920 13044 solver.cpp:253]     Train net output #0: loss = 1.11439 (* 1 = 1.11439 loss)
I0526 19:04:51.644937 13044 sgd_solver.cpp:106] Iteration 565500, lr = 0.003
I0526 19:05:03.765214 13044 solver.cpp:237] Iteration 566250, loss = 1.67801
I0526 19:05:03.765254 13044 solver.cpp:253]     Train net output #0: loss = 1.67801 (* 1 = 1.67801 loss)
I0526 19:05:03.765275 13044 sgd_solver.cpp:106] Iteration 566250, lr = 0.003
I0526 19:05:15.958899 13044 solver.cpp:237] Iteration 567000, loss = 1.21558
I0526 19:05:15.958936 13044 solver.cpp:253]     Train net output #0: loss = 1.21558 (* 1 = 1.21558 loss)
I0526 19:05:15.958950 13044 sgd_solver.cpp:106] Iteration 567000, lr = 0.003
I0526 19:05:28.141132 13044 solver.cpp:237] Iteration 567750, loss = 1.07738
I0526 19:05:28.141317 13044 solver.cpp:253]     Train net output #0: loss = 1.07738 (* 1 = 1.07738 loss)
I0526 19:05:28.141332 13044 sgd_solver.cpp:106] Iteration 567750, lr = 0.003
I0526 19:05:40.250077 13044 solver.cpp:237] Iteration 568500, loss = 0.811484
I0526 19:05:40.250113 13044 solver.cpp:253]     Train net output #0: loss = 0.811483 (* 1 = 0.811483 loss)
I0526 19:05:40.250130 13044 sgd_solver.cpp:106] Iteration 568500, lr = 0.003
I0526 19:05:52.361527 13044 solver.cpp:237] Iteration 569250, loss = 1.10684
I0526 19:05:52.361562 13044 solver.cpp:253]     Train net output #0: loss = 1.10684 (* 1 = 1.10684 loss)
I0526 19:05:52.361577 13044 sgd_solver.cpp:106] Iteration 569250, lr = 0.003
I0526 19:06:04.419126 13044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_570000.caffemodel
I0526 19:06:04.468924 13044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0030_2016-05-20T15.48.55.379925_iter_570000.solverstate
I0526 19:06:04.494436 13044 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 19:06:56.227408 13044 solver.cpp:409]     Test net output #0: accuracy = 0.901987
I0526 19:06:56.227602 13044 solver.cpp:409]     Test net output #1: loss = 0.304766 (* 1 = 0.304766 loss)
I0526 19:07:17.102489 13044 solver.cpp:237] Iteration 570000, loss = 0.985239
I0526 19:07:17.102542 13044 solver.cpp:253]     Train net output #0: loss = 0.985238 (* 1 = 0.985238 loss)
I0526 19:07:17.102557 13044 sgd_solver.cpp:106] Iteration 570000, lr = 0.003
I0526 19:07:29.245677 13044 solver.cpp:237] Iteration 570750, loss = 1.46046
I0526 19:07:29.245854 13044 solver.cpp:253]     Train net output #0: loss = 1.46046 (* 1 = 1.46046 loss)
I0526 19:07:29.245868 13044 sgd_solver.cpp:106] Iteration 570750, lr = 0.003
I0526 19:07:41.409936 13044 solver.cpp:237] Iteration 571500, loss = 0.924253
I0526 19:07:41.409986 13044 solver.cpp:253]     Train net output #0: loss = 0.924252 (* 1 = 0.924252 loss)
I0526 19:07:41.410002 13044 sgd_solver.cpp:106] Iteration 571500, lr = 0.003
I0526 19:07:53.584249 13044 solver.cpp:237] Iteration 572250, loss = 1.32817
I0526 19:07:53.584285 13044 solver.cpp:253]     Train net output #0: loss = 1.32817 (* 1 = 1.32817 loss)
I0526 19:07:53.584298 13044 sgd_solver.cpp:106] Iteration 572250, lr = 0.003
I0526 19:08:05.728184 13044 solver.cpp:237] Iteration 573000, loss = 1.04898
I0526 19:08:05.728365 13044 solver.cpp:253]     Train net output #0: loss = 1.04898 (* 1 = 1.04898 loss)
I0526 19:08:05.728379 13044 sgd_solver.cpp:106] Iteration 573000, lr = 0.003
I0526 19:08:17.849182 13044 solver.cpp:237] Iteration 573750, loss = 1.27326
I0526 19:08:17.849218 13044 solver.cpp:253]     Train net output #0: loss = 1.27326 (* 1 = 1.27326 loss)
I0526 19:08:17.849234 13044 sgd_solver.cpp:106] Iteration 573750, lr = 0.003
I0526 19:08:29.997661 13044 solver.cpp:237] Iteration 574500, loss = 0.607376
I0526 19:08:29.997705 13044 solver.cpp:253]     Train net output #0: loss = 0.607375 (* 1 = 0.607375 loss)
I0526 19:08:29.997721 13044 sgd_solver.cpp:106] Iteration 574500, lr = 0.003
I0526 19:09:03.034729 13044 solver.cpp:237] Iteration 575250, loss = 1.36292
I0526 19:09:03.034934 13044 solver.cpp:253]     Train net output #0: loss = 1.36292 (* 1 = 1.36292 loss)
I0526 19:09:03.034948 13044 sgd_solver.cpp:106] Iteration 575250, lr = 0.003
aprun: Apid 11269984: Caught signal Terminated, sending to application
*** Aborted at 1464304146 (unix time) try "date -d @1464304146" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11269984: Caught signal Terminated, sending to application
*** SIGTERM (@0x32f1) received by PID 13044 (TID 0x2aaac746f900) from PID 13041; stack trace: ***
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
=>> PBS: job killed: walltime 7229 exceeded limit 7200
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11269984: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11269984: Caught signal Terminated, sending to application
aprun: Apid 11269984: Caught signal Terminated, sending to application
aprun: Apid 11269984: Caught signal Terminated, sending to application
aprun: Apid 11269984: Caught signal Terminated, sending to application
aprun: Apid 11269984: Caught signal Terminated, sending to application
