2806691
I0521 13:38:24.554252 14148 caffe.cpp:184] Using GPUs 0
I0521 13:38:24.984577 14148 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0015
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036.prototxt"
I0521 13:38:24.986277 14148 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036.prototxt
I0521 13:38:25.004029 14148 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 13:38:25.004099 14148 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 13:38:25.004448 14148 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 13:38:25.004638 14148 layer_factory.hpp:77] Creating layer data_hdf5
I0521 13:38:25.004662 14148 net.cpp:106] Creating Layer data_hdf5
I0521 13:38:25.004676 14148 net.cpp:411] data_hdf5 -> data
I0521 13:38:25.004709 14148 net.cpp:411] data_hdf5 -> label
I0521 13:38:25.004741 14148 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 13:38:25.006024 14148 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 13:38:25.008235 14148 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 13:38:46.527127 14148 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 13:38:46.532280 14148 net.cpp:150] Setting up data_hdf5
I0521 13:38:46.532320 14148 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 13:38:46.532335 14148 net.cpp:157] Top shape: 10 (10)
I0521 13:38:46.532347 14148 net.cpp:165] Memory required for data: 254040
I0521 13:38:46.532361 14148 layer_factory.hpp:77] Creating layer conv1
I0521 13:38:46.532395 14148 net.cpp:106] Creating Layer conv1
I0521 13:38:46.532405 14148 net.cpp:454] conv1 <- data
I0521 13:38:46.532426 14148 net.cpp:411] conv1 -> conv1
I0521 13:38:47.340798 14148 net.cpp:150] Setting up conv1
I0521 13:38:47.340844 14148 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 13:38:47.340855 14148 net.cpp:165] Memory required for data: 3018840
I0521 13:38:47.340884 14148 layer_factory.hpp:77] Creating layer relu1
I0521 13:38:47.340905 14148 net.cpp:106] Creating Layer relu1
I0521 13:38:47.340916 14148 net.cpp:454] relu1 <- conv1
I0521 13:38:47.340929 14148 net.cpp:397] relu1 -> conv1 (in-place)
I0521 13:38:47.341455 14148 net.cpp:150] Setting up relu1
I0521 13:38:47.341471 14148 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 13:38:47.341481 14148 net.cpp:165] Memory required for data: 5783640
I0521 13:38:47.341490 14148 layer_factory.hpp:77] Creating layer pool1
I0521 13:38:47.341507 14148 net.cpp:106] Creating Layer pool1
I0521 13:38:47.341517 14148 net.cpp:454] pool1 <- conv1
I0521 13:38:47.341531 14148 net.cpp:411] pool1 -> pool1
I0521 13:38:47.341610 14148 net.cpp:150] Setting up pool1
I0521 13:38:47.341624 14148 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 13:38:47.341634 14148 net.cpp:165] Memory required for data: 7166040
I0521 13:38:47.341645 14148 layer_factory.hpp:77] Creating layer conv2
I0521 13:38:47.341666 14148 net.cpp:106] Creating Layer conv2
I0521 13:38:47.341677 14148 net.cpp:454] conv2 <- pool1
I0521 13:38:47.341691 14148 net.cpp:411] conv2 -> conv2
I0521 13:38:47.344390 14148 net.cpp:150] Setting up conv2
I0521 13:38:47.344419 14148 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 13:38:47.344429 14148 net.cpp:165] Memory required for data: 9153240
I0521 13:38:47.344446 14148 layer_factory.hpp:77] Creating layer relu2
I0521 13:38:47.344461 14148 net.cpp:106] Creating Layer relu2
I0521 13:38:47.344471 14148 net.cpp:454] relu2 <- conv2
I0521 13:38:47.344483 14148 net.cpp:397] relu2 -> conv2 (in-place)
I0521 13:38:47.344823 14148 net.cpp:150] Setting up relu2
I0521 13:38:47.344837 14148 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 13:38:47.344848 14148 net.cpp:165] Memory required for data: 11140440
I0521 13:38:47.344858 14148 layer_factory.hpp:77] Creating layer pool2
I0521 13:38:47.344871 14148 net.cpp:106] Creating Layer pool2
I0521 13:38:47.344880 14148 net.cpp:454] pool2 <- conv2
I0521 13:38:47.344893 14148 net.cpp:411] pool2 -> pool2
I0521 13:38:47.344974 14148 net.cpp:150] Setting up pool2
I0521 13:38:47.344987 14148 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 13:38:47.344996 14148 net.cpp:165] Memory required for data: 12134040
I0521 13:38:47.345005 14148 layer_factory.hpp:77] Creating layer conv3
I0521 13:38:47.345024 14148 net.cpp:106] Creating Layer conv3
I0521 13:38:47.345034 14148 net.cpp:454] conv3 <- pool2
I0521 13:38:47.345048 14148 net.cpp:411] conv3 -> conv3
I0521 13:38:47.347136 14148 net.cpp:150] Setting up conv3
I0521 13:38:47.347160 14148 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 13:38:47.347172 14148 net.cpp:165] Memory required for data: 13218200
I0521 13:38:47.347190 14148 layer_factory.hpp:77] Creating layer relu3
I0521 13:38:47.347206 14148 net.cpp:106] Creating Layer relu3
I0521 13:38:47.347216 14148 net.cpp:454] relu3 <- conv3
I0521 13:38:47.347229 14148 net.cpp:397] relu3 -> conv3 (in-place)
I0521 13:38:47.347690 14148 net.cpp:150] Setting up relu3
I0521 13:38:47.347707 14148 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 13:38:47.347718 14148 net.cpp:165] Memory required for data: 14302360
I0521 13:38:47.347728 14148 layer_factory.hpp:77] Creating layer pool3
I0521 13:38:47.347740 14148 net.cpp:106] Creating Layer pool3
I0521 13:38:47.347750 14148 net.cpp:454] pool3 <- conv3
I0521 13:38:47.347762 14148 net.cpp:411] pool3 -> pool3
I0521 13:38:47.347829 14148 net.cpp:150] Setting up pool3
I0521 13:38:47.347842 14148 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 13:38:47.347852 14148 net.cpp:165] Memory required for data: 14844440
I0521 13:38:47.347859 14148 layer_factory.hpp:77] Creating layer conv4
I0521 13:38:47.347877 14148 net.cpp:106] Creating Layer conv4
I0521 13:38:47.347887 14148 net.cpp:454] conv4 <- pool3
I0521 13:38:47.347900 14148 net.cpp:411] conv4 -> conv4
I0521 13:38:47.350623 14148 net.cpp:150] Setting up conv4
I0521 13:38:47.350646 14148 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 13:38:47.350656 14148 net.cpp:165] Memory required for data: 15207320
I0521 13:38:47.350672 14148 layer_factory.hpp:77] Creating layer relu4
I0521 13:38:47.350685 14148 net.cpp:106] Creating Layer relu4
I0521 13:38:47.350695 14148 net.cpp:454] relu4 <- conv4
I0521 13:38:47.350708 14148 net.cpp:397] relu4 -> conv4 (in-place)
I0521 13:38:47.351174 14148 net.cpp:150] Setting up relu4
I0521 13:38:47.351191 14148 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 13:38:47.351202 14148 net.cpp:165] Memory required for data: 15570200
I0521 13:38:47.351212 14148 layer_factory.hpp:77] Creating layer pool4
I0521 13:38:47.351224 14148 net.cpp:106] Creating Layer pool4
I0521 13:38:47.351234 14148 net.cpp:454] pool4 <- conv4
I0521 13:38:47.351248 14148 net.cpp:411] pool4 -> pool4
I0521 13:38:47.351315 14148 net.cpp:150] Setting up pool4
I0521 13:38:47.351327 14148 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 13:38:47.351337 14148 net.cpp:165] Memory required for data: 15751640
I0521 13:38:47.351347 14148 layer_factory.hpp:77] Creating layer ip1
I0521 13:38:47.351367 14148 net.cpp:106] Creating Layer ip1
I0521 13:38:47.351377 14148 net.cpp:454] ip1 <- pool4
I0521 13:38:47.351389 14148 net.cpp:411] ip1 -> ip1
I0521 13:38:47.366835 14148 net.cpp:150] Setting up ip1
I0521 13:38:47.366864 14148 net.cpp:157] Top shape: 10 196 (1960)
I0521 13:38:47.366875 14148 net.cpp:165] Memory required for data: 15759480
I0521 13:38:47.366899 14148 layer_factory.hpp:77] Creating layer relu5
I0521 13:38:47.366912 14148 net.cpp:106] Creating Layer relu5
I0521 13:38:47.366922 14148 net.cpp:454] relu5 <- ip1
I0521 13:38:47.366935 14148 net.cpp:397] relu5 -> ip1 (in-place)
I0521 13:38:47.367277 14148 net.cpp:150] Setting up relu5
I0521 13:38:47.367291 14148 net.cpp:157] Top shape: 10 196 (1960)
I0521 13:38:47.367300 14148 net.cpp:165] Memory required for data: 15767320
I0521 13:38:47.367311 14148 layer_factory.hpp:77] Creating layer drop1
I0521 13:38:47.367332 14148 net.cpp:106] Creating Layer drop1
I0521 13:38:47.367342 14148 net.cpp:454] drop1 <- ip1
I0521 13:38:47.367354 14148 net.cpp:397] drop1 -> ip1 (in-place)
I0521 13:38:47.367413 14148 net.cpp:150] Setting up drop1
I0521 13:38:47.367426 14148 net.cpp:157] Top shape: 10 196 (1960)
I0521 13:38:47.367436 14148 net.cpp:165] Memory required for data: 15775160
I0521 13:38:47.367446 14148 layer_factory.hpp:77] Creating layer ip2
I0521 13:38:47.367465 14148 net.cpp:106] Creating Layer ip2
I0521 13:38:47.367475 14148 net.cpp:454] ip2 <- ip1
I0521 13:38:47.367488 14148 net.cpp:411] ip2 -> ip2
I0521 13:38:47.367951 14148 net.cpp:150] Setting up ip2
I0521 13:38:47.367964 14148 net.cpp:157] Top shape: 10 98 (980)
I0521 13:38:47.367974 14148 net.cpp:165] Memory required for data: 15779080
I0521 13:38:47.367990 14148 layer_factory.hpp:77] Creating layer relu6
I0521 13:38:47.368003 14148 net.cpp:106] Creating Layer relu6
I0521 13:38:47.368012 14148 net.cpp:454] relu6 <- ip2
I0521 13:38:47.368024 14148 net.cpp:397] relu6 -> ip2 (in-place)
I0521 13:38:47.368556 14148 net.cpp:150] Setting up relu6
I0521 13:38:47.368572 14148 net.cpp:157] Top shape: 10 98 (980)
I0521 13:38:47.368582 14148 net.cpp:165] Memory required for data: 15783000
I0521 13:38:47.368592 14148 layer_factory.hpp:77] Creating layer drop2
I0521 13:38:47.368607 14148 net.cpp:106] Creating Layer drop2
I0521 13:38:47.368615 14148 net.cpp:454] drop2 <- ip2
I0521 13:38:47.368628 14148 net.cpp:397] drop2 -> ip2 (in-place)
I0521 13:38:47.368671 14148 net.cpp:150] Setting up drop2
I0521 13:38:47.368685 14148 net.cpp:157] Top shape: 10 98 (980)
I0521 13:38:47.368695 14148 net.cpp:165] Memory required for data: 15786920
I0521 13:38:47.368705 14148 layer_factory.hpp:77] Creating layer ip3
I0521 13:38:47.368717 14148 net.cpp:106] Creating Layer ip3
I0521 13:38:47.368727 14148 net.cpp:454] ip3 <- ip2
I0521 13:38:47.368741 14148 net.cpp:411] ip3 -> ip3
I0521 13:38:47.368948 14148 net.cpp:150] Setting up ip3
I0521 13:38:47.368963 14148 net.cpp:157] Top shape: 10 11 (110)
I0521 13:38:47.368973 14148 net.cpp:165] Memory required for data: 15787360
I0521 13:38:47.368988 14148 layer_factory.hpp:77] Creating layer drop3
I0521 13:38:47.369000 14148 net.cpp:106] Creating Layer drop3
I0521 13:38:47.369010 14148 net.cpp:454] drop3 <- ip3
I0521 13:38:47.369026 14148 net.cpp:397] drop3 -> ip3 (in-place)
I0521 13:38:47.369066 14148 net.cpp:150] Setting up drop3
I0521 13:38:47.369078 14148 net.cpp:157] Top shape: 10 11 (110)
I0521 13:38:47.369088 14148 net.cpp:165] Memory required for data: 15787800
I0521 13:38:47.369098 14148 layer_factory.hpp:77] Creating layer loss
I0521 13:38:47.369117 14148 net.cpp:106] Creating Layer loss
I0521 13:38:47.369127 14148 net.cpp:454] loss <- ip3
I0521 13:38:47.369138 14148 net.cpp:454] loss <- label
I0521 13:38:47.369149 14148 net.cpp:411] loss -> loss
I0521 13:38:47.369168 14148 layer_factory.hpp:77] Creating layer loss
I0521 13:38:47.369806 14148 net.cpp:150] Setting up loss
I0521 13:38:47.369827 14148 net.cpp:157] Top shape: (1)
I0521 13:38:47.369839 14148 net.cpp:160]     with loss weight 1
I0521 13:38:47.369885 14148 net.cpp:165] Memory required for data: 15787804
I0521 13:38:47.369896 14148 net.cpp:226] loss needs backward computation.
I0521 13:38:47.369907 14148 net.cpp:226] drop3 needs backward computation.
I0521 13:38:47.369915 14148 net.cpp:226] ip3 needs backward computation.
I0521 13:38:47.369925 14148 net.cpp:226] drop2 needs backward computation.
I0521 13:38:47.369935 14148 net.cpp:226] relu6 needs backward computation.
I0521 13:38:47.369945 14148 net.cpp:226] ip2 needs backward computation.
I0521 13:38:47.369956 14148 net.cpp:226] drop1 needs backward computation.
I0521 13:38:47.369964 14148 net.cpp:226] relu5 needs backward computation.
I0521 13:38:47.369973 14148 net.cpp:226] ip1 needs backward computation.
I0521 13:38:47.369983 14148 net.cpp:226] pool4 needs backward computation.
I0521 13:38:47.369993 14148 net.cpp:226] relu4 needs backward computation.
I0521 13:38:47.370003 14148 net.cpp:226] conv4 needs backward computation.
I0521 13:38:47.370014 14148 net.cpp:226] pool3 needs backward computation.
I0521 13:38:47.370024 14148 net.cpp:226] relu3 needs backward computation.
I0521 13:38:47.370033 14148 net.cpp:226] conv3 needs backward computation.
I0521 13:38:47.370051 14148 net.cpp:226] pool2 needs backward computation.
I0521 13:38:47.370062 14148 net.cpp:226] relu2 needs backward computation.
I0521 13:38:47.370072 14148 net.cpp:226] conv2 needs backward computation.
I0521 13:38:47.370084 14148 net.cpp:226] pool1 needs backward computation.
I0521 13:38:47.370093 14148 net.cpp:226] relu1 needs backward computation.
I0521 13:38:47.370103 14148 net.cpp:226] conv1 needs backward computation.
I0521 13:38:47.370115 14148 net.cpp:228] data_hdf5 does not need backward computation.
I0521 13:38:47.370124 14148 net.cpp:270] This network produces output loss
I0521 13:38:47.370148 14148 net.cpp:283] Network initialization done.
I0521 13:38:47.371778 14148 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036.prototxt
I0521 13:38:47.371850 14148 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 13:38:47.372202 14148 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 13:38:47.372392 14148 layer_factory.hpp:77] Creating layer data_hdf5
I0521 13:38:47.372408 14148 net.cpp:106] Creating Layer data_hdf5
I0521 13:38:47.372421 14148 net.cpp:411] data_hdf5 -> data
I0521 13:38:47.372437 14148 net.cpp:411] data_hdf5 -> label
I0521 13:38:47.372453 14148 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 13:38:47.373697 14148 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 13:39:08.683580 14148 net.cpp:150] Setting up data_hdf5
I0521 13:39:08.683750 14148 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 13:39:08.683764 14148 net.cpp:157] Top shape: 10 (10)
I0521 13:39:08.683775 14148 net.cpp:165] Memory required for data: 254040
I0521 13:39:08.683789 14148 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 13:39:08.683817 14148 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 13:39:08.683828 14148 net.cpp:454] label_data_hdf5_1_split <- label
I0521 13:39:08.683843 14148 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 13:39:08.683864 14148 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 13:39:08.683936 14148 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 13:39:08.683950 14148 net.cpp:157] Top shape: 10 (10)
I0521 13:39:08.683962 14148 net.cpp:157] Top shape: 10 (10)
I0521 13:39:08.683971 14148 net.cpp:165] Memory required for data: 254120
I0521 13:39:08.683981 14148 layer_factory.hpp:77] Creating layer conv1
I0521 13:39:08.684005 14148 net.cpp:106] Creating Layer conv1
I0521 13:39:08.684015 14148 net.cpp:454] conv1 <- data
I0521 13:39:08.684031 14148 net.cpp:411] conv1 -> conv1
I0521 13:39:08.686002 14148 net.cpp:150] Setting up conv1
I0521 13:39:08.686031 14148 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 13:39:08.686043 14148 net.cpp:165] Memory required for data: 3018920
I0521 13:39:08.686064 14148 layer_factory.hpp:77] Creating layer relu1
I0521 13:39:08.686079 14148 net.cpp:106] Creating Layer relu1
I0521 13:39:08.686089 14148 net.cpp:454] relu1 <- conv1
I0521 13:39:08.686100 14148 net.cpp:397] relu1 -> conv1 (in-place)
I0521 13:39:08.686606 14148 net.cpp:150] Setting up relu1
I0521 13:39:08.686622 14148 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 13:39:08.686633 14148 net.cpp:165] Memory required for data: 5783720
I0521 13:39:08.686643 14148 layer_factory.hpp:77] Creating layer pool1
I0521 13:39:08.686661 14148 net.cpp:106] Creating Layer pool1
I0521 13:39:08.686669 14148 net.cpp:454] pool1 <- conv1
I0521 13:39:08.686684 14148 net.cpp:411] pool1 -> pool1
I0521 13:39:08.686758 14148 net.cpp:150] Setting up pool1
I0521 13:39:08.686772 14148 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 13:39:08.686781 14148 net.cpp:165] Memory required for data: 7166120
I0521 13:39:08.686792 14148 layer_factory.hpp:77] Creating layer conv2
I0521 13:39:08.686810 14148 net.cpp:106] Creating Layer conv2
I0521 13:39:08.686820 14148 net.cpp:454] conv2 <- pool1
I0521 13:39:08.686836 14148 net.cpp:411] conv2 -> conv2
I0521 13:39:08.688748 14148 net.cpp:150] Setting up conv2
I0521 13:39:08.688771 14148 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 13:39:08.688783 14148 net.cpp:165] Memory required for data: 9153320
I0521 13:39:08.688802 14148 layer_factory.hpp:77] Creating layer relu2
I0521 13:39:08.688815 14148 net.cpp:106] Creating Layer relu2
I0521 13:39:08.688825 14148 net.cpp:454] relu2 <- conv2
I0521 13:39:08.688838 14148 net.cpp:397] relu2 -> conv2 (in-place)
I0521 13:39:08.689173 14148 net.cpp:150] Setting up relu2
I0521 13:39:08.689188 14148 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 13:39:08.689198 14148 net.cpp:165] Memory required for data: 11140520
I0521 13:39:08.689208 14148 layer_factory.hpp:77] Creating layer pool2
I0521 13:39:08.689221 14148 net.cpp:106] Creating Layer pool2
I0521 13:39:08.689230 14148 net.cpp:454] pool2 <- conv2
I0521 13:39:08.689244 14148 net.cpp:411] pool2 -> pool2
I0521 13:39:08.689316 14148 net.cpp:150] Setting up pool2
I0521 13:39:08.689328 14148 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 13:39:08.689338 14148 net.cpp:165] Memory required for data: 12134120
I0521 13:39:08.689348 14148 layer_factory.hpp:77] Creating layer conv3
I0521 13:39:08.689365 14148 net.cpp:106] Creating Layer conv3
I0521 13:39:08.689376 14148 net.cpp:454] conv3 <- pool2
I0521 13:39:08.689390 14148 net.cpp:411] conv3 -> conv3
I0521 13:39:08.691417 14148 net.cpp:150] Setting up conv3
I0521 13:39:08.691437 14148 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 13:39:08.691450 14148 net.cpp:165] Memory required for data: 13218280
I0521 13:39:08.691470 14148 layer_factory.hpp:77] Creating layer relu3
I0521 13:39:08.691496 14148 net.cpp:106] Creating Layer relu3
I0521 13:39:08.691507 14148 net.cpp:454] relu3 <- conv3
I0521 13:39:08.691520 14148 net.cpp:397] relu3 -> conv3 (in-place)
I0521 13:39:08.691992 14148 net.cpp:150] Setting up relu3
I0521 13:39:08.692006 14148 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 13:39:08.692018 14148 net.cpp:165] Memory required for data: 14302440
I0521 13:39:08.692026 14148 layer_factory.hpp:77] Creating layer pool3
I0521 13:39:08.692039 14148 net.cpp:106] Creating Layer pool3
I0521 13:39:08.692049 14148 net.cpp:454] pool3 <- conv3
I0521 13:39:08.692064 14148 net.cpp:411] pool3 -> pool3
I0521 13:39:08.692133 14148 net.cpp:150] Setting up pool3
I0521 13:39:08.692147 14148 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 13:39:08.692157 14148 net.cpp:165] Memory required for data: 14844520
I0521 13:39:08.692167 14148 layer_factory.hpp:77] Creating layer conv4
I0521 13:39:08.692185 14148 net.cpp:106] Creating Layer conv4
I0521 13:39:08.692195 14148 net.cpp:454] conv4 <- pool3
I0521 13:39:08.692210 14148 net.cpp:411] conv4 -> conv4
I0521 13:39:08.694275 14148 net.cpp:150] Setting up conv4
I0521 13:39:08.694298 14148 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 13:39:08.694308 14148 net.cpp:165] Memory required for data: 15207400
I0521 13:39:08.694325 14148 layer_factory.hpp:77] Creating layer relu4
I0521 13:39:08.694339 14148 net.cpp:106] Creating Layer relu4
I0521 13:39:08.694349 14148 net.cpp:454] relu4 <- conv4
I0521 13:39:08.694360 14148 net.cpp:397] relu4 -> conv4 (in-place)
I0521 13:39:08.694825 14148 net.cpp:150] Setting up relu4
I0521 13:39:08.694841 14148 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 13:39:08.694852 14148 net.cpp:165] Memory required for data: 15570280
I0521 13:39:08.694861 14148 layer_factory.hpp:77] Creating layer pool4
I0521 13:39:08.694875 14148 net.cpp:106] Creating Layer pool4
I0521 13:39:08.694885 14148 net.cpp:454] pool4 <- conv4
I0521 13:39:08.694898 14148 net.cpp:411] pool4 -> pool4
I0521 13:39:08.694969 14148 net.cpp:150] Setting up pool4
I0521 13:39:08.694983 14148 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 13:39:08.694991 14148 net.cpp:165] Memory required for data: 15751720
I0521 13:39:08.695001 14148 layer_factory.hpp:77] Creating layer ip1
I0521 13:39:08.695017 14148 net.cpp:106] Creating Layer ip1
I0521 13:39:08.695027 14148 net.cpp:454] ip1 <- pool4
I0521 13:39:08.695041 14148 net.cpp:411] ip1 -> ip1
I0521 13:39:08.710495 14148 net.cpp:150] Setting up ip1
I0521 13:39:08.710520 14148 net.cpp:157] Top shape: 10 196 (1960)
I0521 13:39:08.710530 14148 net.cpp:165] Memory required for data: 15759560
I0521 13:39:08.710551 14148 layer_factory.hpp:77] Creating layer relu5
I0521 13:39:08.710567 14148 net.cpp:106] Creating Layer relu5
I0521 13:39:08.710577 14148 net.cpp:454] relu5 <- ip1
I0521 13:39:08.710590 14148 net.cpp:397] relu5 -> ip1 (in-place)
I0521 13:39:08.710938 14148 net.cpp:150] Setting up relu5
I0521 13:39:08.710952 14148 net.cpp:157] Top shape: 10 196 (1960)
I0521 13:39:08.710961 14148 net.cpp:165] Memory required for data: 15767400
I0521 13:39:08.710973 14148 layer_factory.hpp:77] Creating layer drop1
I0521 13:39:08.710990 14148 net.cpp:106] Creating Layer drop1
I0521 13:39:08.711000 14148 net.cpp:454] drop1 <- ip1
I0521 13:39:08.711014 14148 net.cpp:397] drop1 -> ip1 (in-place)
I0521 13:39:08.711057 14148 net.cpp:150] Setting up drop1
I0521 13:39:08.711071 14148 net.cpp:157] Top shape: 10 196 (1960)
I0521 13:39:08.711081 14148 net.cpp:165] Memory required for data: 15775240
I0521 13:39:08.711089 14148 layer_factory.hpp:77] Creating layer ip2
I0521 13:39:08.711104 14148 net.cpp:106] Creating Layer ip2
I0521 13:39:08.711114 14148 net.cpp:454] ip2 <- ip1
I0521 13:39:08.711128 14148 net.cpp:411] ip2 -> ip2
I0521 13:39:08.711606 14148 net.cpp:150] Setting up ip2
I0521 13:39:08.711619 14148 net.cpp:157] Top shape: 10 98 (980)
I0521 13:39:08.711629 14148 net.cpp:165] Memory required for data: 15779160
I0521 13:39:08.711644 14148 layer_factory.hpp:77] Creating layer relu6
I0521 13:39:08.711670 14148 net.cpp:106] Creating Layer relu6
I0521 13:39:08.711680 14148 net.cpp:454] relu6 <- ip2
I0521 13:39:08.711694 14148 net.cpp:397] relu6 -> ip2 (in-place)
I0521 13:39:08.712224 14148 net.cpp:150] Setting up relu6
I0521 13:39:08.712247 14148 net.cpp:157] Top shape: 10 98 (980)
I0521 13:39:08.712256 14148 net.cpp:165] Memory required for data: 15783080
I0521 13:39:08.712267 14148 layer_factory.hpp:77] Creating layer drop2
I0521 13:39:08.712282 14148 net.cpp:106] Creating Layer drop2
I0521 13:39:08.712292 14148 net.cpp:454] drop2 <- ip2
I0521 13:39:08.712306 14148 net.cpp:397] drop2 -> ip2 (in-place)
I0521 13:39:08.712349 14148 net.cpp:150] Setting up drop2
I0521 13:39:08.712363 14148 net.cpp:157] Top shape: 10 98 (980)
I0521 13:39:08.712373 14148 net.cpp:165] Memory required for data: 15787000
I0521 13:39:08.712383 14148 layer_factory.hpp:77] Creating layer ip3
I0521 13:39:08.712396 14148 net.cpp:106] Creating Layer ip3
I0521 13:39:08.712406 14148 net.cpp:454] ip3 <- ip2
I0521 13:39:08.712420 14148 net.cpp:411] ip3 -> ip3
I0521 13:39:08.712647 14148 net.cpp:150] Setting up ip3
I0521 13:39:08.712661 14148 net.cpp:157] Top shape: 10 11 (110)
I0521 13:39:08.712671 14148 net.cpp:165] Memory required for data: 15787440
I0521 13:39:08.712687 14148 layer_factory.hpp:77] Creating layer drop3
I0521 13:39:08.712699 14148 net.cpp:106] Creating Layer drop3
I0521 13:39:08.712709 14148 net.cpp:454] drop3 <- ip3
I0521 13:39:08.712723 14148 net.cpp:397] drop3 -> ip3 (in-place)
I0521 13:39:08.712764 14148 net.cpp:150] Setting up drop3
I0521 13:39:08.712776 14148 net.cpp:157] Top shape: 10 11 (110)
I0521 13:39:08.712786 14148 net.cpp:165] Memory required for data: 15787880
I0521 13:39:08.712796 14148 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 13:39:08.712810 14148 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 13:39:08.712819 14148 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 13:39:08.712832 14148 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 13:39:08.712847 14148 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 13:39:08.712920 14148 net.cpp:150] Setting up ip3_drop3_0_split
I0521 13:39:08.712934 14148 net.cpp:157] Top shape: 10 11 (110)
I0521 13:39:08.712946 14148 net.cpp:157] Top shape: 10 11 (110)
I0521 13:39:08.712956 14148 net.cpp:165] Memory required for data: 15788760
I0521 13:39:08.712966 14148 layer_factory.hpp:77] Creating layer accuracy
I0521 13:39:08.712988 14148 net.cpp:106] Creating Layer accuracy
I0521 13:39:08.712997 14148 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 13:39:08.713009 14148 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 13:39:08.713022 14148 net.cpp:411] accuracy -> accuracy
I0521 13:39:08.713047 14148 net.cpp:150] Setting up accuracy
I0521 13:39:08.713059 14148 net.cpp:157] Top shape: (1)
I0521 13:39:08.713068 14148 net.cpp:165] Memory required for data: 15788764
I0521 13:39:08.713079 14148 layer_factory.hpp:77] Creating layer loss
I0521 13:39:08.713093 14148 net.cpp:106] Creating Layer loss
I0521 13:39:08.713102 14148 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 13:39:08.713114 14148 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 13:39:08.713126 14148 net.cpp:411] loss -> loss
I0521 13:39:08.713143 14148 layer_factory.hpp:77] Creating layer loss
I0521 13:39:08.713627 14148 net.cpp:150] Setting up loss
I0521 13:39:08.713641 14148 net.cpp:157] Top shape: (1)
I0521 13:39:08.713732 14148 net.cpp:160]     with loss weight 1
I0521 13:39:08.713752 14148 net.cpp:165] Memory required for data: 15788768
I0521 13:39:08.713763 14148 net.cpp:226] loss needs backward computation.
I0521 13:39:08.713774 14148 net.cpp:228] accuracy does not need backward computation.
I0521 13:39:08.713786 14148 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 13:39:08.713796 14148 net.cpp:226] drop3 needs backward computation.
I0521 13:39:08.713806 14148 net.cpp:226] ip3 needs backward computation.
I0521 13:39:08.713817 14148 net.cpp:226] drop2 needs backward computation.
I0521 13:39:08.713826 14148 net.cpp:226] relu6 needs backward computation.
I0521 13:39:08.713846 14148 net.cpp:226] ip2 needs backward computation.
I0521 13:39:08.713857 14148 net.cpp:226] drop1 needs backward computation.
I0521 13:39:08.713866 14148 net.cpp:226] relu5 needs backward computation.
I0521 13:39:08.713876 14148 net.cpp:226] ip1 needs backward computation.
I0521 13:39:08.713886 14148 net.cpp:226] pool4 needs backward computation.
I0521 13:39:08.713896 14148 net.cpp:226] relu4 needs backward computation.
I0521 13:39:08.713907 14148 net.cpp:226] conv4 needs backward computation.
I0521 13:39:08.713919 14148 net.cpp:226] pool3 needs backward computation.
I0521 13:39:08.713929 14148 net.cpp:226] relu3 needs backward computation.
I0521 13:39:08.713939 14148 net.cpp:226] conv3 needs backward computation.
I0521 13:39:08.713949 14148 net.cpp:226] pool2 needs backward computation.
I0521 13:39:08.713960 14148 net.cpp:226] relu2 needs backward computation.
I0521 13:39:08.713970 14148 net.cpp:226] conv2 needs backward computation.
I0521 13:39:08.713980 14148 net.cpp:226] pool1 needs backward computation.
I0521 13:39:08.713991 14148 net.cpp:226] relu1 needs backward computation.
I0521 13:39:08.714000 14148 net.cpp:226] conv1 needs backward computation.
I0521 13:39:08.714012 14148 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 13:39:08.714025 14148 net.cpp:228] data_hdf5 does not need backward computation.
I0521 13:39:08.714033 14148 net.cpp:270] This network produces output accuracy
I0521 13:39:08.714046 14148 net.cpp:270] This network produces output loss
I0521 13:39:08.714073 14148 net.cpp:283] Network initialization done.
I0521 13:39:08.714207 14148 solver.cpp:60] Solver scaffolding done.
I0521 13:39:08.715348 14148 caffe.cpp:212] Starting Optimization
I0521 13:39:08.715366 14148 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 13:39:08.715380 14148 solver.cpp:289] Learning Rate Policy: fixed
I0521 13:39:08.716447 14148 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 13:40:09.204090 14148 solver.cpp:409]     Test net output #0: accuracy = 0.0998264
I0521 13:40:09.204257 14148 solver.cpp:409]     Test net output #1: loss = 2.39739 (* 1 = 2.39739 loss)
I0521 13:40:09.222089 14148 solver.cpp:237] Iteration 0, loss = 2.39334
I0521 13:40:09.222126 14148 solver.cpp:253]     Train net output #0: loss = 2.39334 (* 1 = 2.39334 loss)
I0521 13:40:09.222143 14148 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0521 13:40:26.008806 14148 solver.cpp:237] Iteration 1500, loss = 2.17086
I0521 13:40:26.008853 14148 solver.cpp:253]     Train net output #0: loss = 2.17086 (* 1 = 2.17086 loss)
I0521 13:40:26.008869 14148 sgd_solver.cpp:106] Iteration 1500, lr = 0.0015
I0521 13:40:42.784584 14148 solver.cpp:237] Iteration 3000, loss = 2.10563
I0521 13:40:42.784731 14148 solver.cpp:253]     Train net output #0: loss = 2.10563 (* 1 = 2.10563 loss)
I0521 13:40:42.784747 14148 sgd_solver.cpp:106] Iteration 3000, lr = 0.0015
I0521 13:40:59.559125 14148 solver.cpp:237] Iteration 4500, loss = 2.02335
I0521 13:40:59.559170 14148 solver.cpp:253]     Train net output #0: loss = 2.02336 (* 1 = 2.02336 loss)
I0521 13:40:59.559185 14148 sgd_solver.cpp:106] Iteration 4500, lr = 0.0015
I0521 13:41:16.346997 14148 solver.cpp:237] Iteration 6000, loss = 1.35693
I0521 13:41:16.347148 14148 solver.cpp:253]     Train net output #0: loss = 1.35693 (* 1 = 1.35693 loss)
I0521 13:41:16.347162 14148 sgd_solver.cpp:106] Iteration 6000, lr = 0.0015
I0521 13:41:33.163841 14148 solver.cpp:237] Iteration 7500, loss = 1.12779
I0521 13:41:33.163877 14148 solver.cpp:253]     Train net output #0: loss = 1.12779 (* 1 = 1.12779 loss)
I0521 13:41:33.163893 14148 sgd_solver.cpp:106] Iteration 7500, lr = 0.0015
I0521 13:41:49.940794 14148 solver.cpp:237] Iteration 9000, loss = 2.06646
I0521 13:41:49.940932 14148 solver.cpp:253]     Train net output #0: loss = 2.06646 (* 1 = 2.06646 loss)
I0521 13:41:49.940946 14148 sgd_solver.cpp:106] Iteration 9000, lr = 0.0015
I0521 13:42:28.751577 14148 solver.cpp:237] Iteration 10500, loss = 1.96937
I0521 13:42:28.751739 14148 solver.cpp:253]     Train net output #0: loss = 1.96937 (* 1 = 1.96937 loss)
I0521 13:42:28.751754 14148 sgd_solver.cpp:106] Iteration 10500, lr = 0.0015
I0521 13:42:45.383666 14148 solver.cpp:237] Iteration 12000, loss = 0.888651
I0521 13:42:45.383702 14148 solver.cpp:253]     Train net output #0: loss = 0.88865 (* 1 = 0.88865 loss)
I0521 13:42:45.383718 14148 sgd_solver.cpp:106] Iteration 12000, lr = 0.0015
I0521 13:43:01.975723 14148 solver.cpp:237] Iteration 13500, loss = 1.53571
I0521 13:43:01.975888 14148 solver.cpp:253]     Train net output #0: loss = 1.53571 (* 1 = 1.53571 loss)
I0521 13:43:01.975903 14148 sgd_solver.cpp:106] Iteration 13500, lr = 0.0015
I0521 13:43:18.593876 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_15000.caffemodel
I0521 13:43:18.644071 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_15000.solverstate
I0521 13:43:18.672862 14148 solver.cpp:237] Iteration 15000, loss = 0.840316
I0521 13:43:18.672912 14148 solver.cpp:253]     Train net output #0: loss = 0.840316 (* 1 = 0.840316 loss)
I0521 13:43:18.672929 14148 sgd_solver.cpp:106] Iteration 15000, lr = 0.0015
I0521 13:43:35.287597 14148 solver.cpp:237] Iteration 16500, loss = 1.52445
I0521 13:43:35.287739 14148 solver.cpp:253]     Train net output #0: loss = 1.52445 (* 1 = 1.52445 loss)
I0521 13:43:35.287753 14148 sgd_solver.cpp:106] Iteration 16500, lr = 0.0015
I0521 13:43:51.916637 14148 solver.cpp:237] Iteration 18000, loss = 1.40875
I0521 13:43:51.916685 14148 solver.cpp:253]     Train net output #0: loss = 1.40874 (* 1 = 1.40874 loss)
I0521 13:43:51.916700 14148 sgd_solver.cpp:106] Iteration 18000, lr = 0.0015
I0521 13:44:08.568197 14148 solver.cpp:237] Iteration 19500, loss = 1.02751
I0521 13:44:08.568352 14148 solver.cpp:253]     Train net output #0: loss = 1.0275 (* 1 = 1.0275 loss)
I0521 13:44:08.568367 14148 sgd_solver.cpp:106] Iteration 19500, lr = 0.0015
I0521 13:44:47.284005 14148 solver.cpp:237] Iteration 21000, loss = 1.26215
I0521 13:44:47.284169 14148 solver.cpp:253]     Train net output #0: loss = 1.26215 (* 1 = 1.26215 loss)
I0521 13:44:47.284183 14148 sgd_solver.cpp:106] Iteration 21000, lr = 0.0015
I0521 13:45:03.906007 14148 solver.cpp:237] Iteration 22500, loss = 1.32549
I0521 13:45:03.906057 14148 solver.cpp:253]     Train net output #0: loss = 1.32549 (* 1 = 1.32549 loss)
I0521 13:45:03.906074 14148 sgd_solver.cpp:106] Iteration 22500, lr = 0.0015
I0521 13:45:20.532498 14148 solver.cpp:237] Iteration 24000, loss = 1.37306
I0521 13:45:20.532665 14148 solver.cpp:253]     Train net output #0: loss = 1.37306 (* 1 = 1.37306 loss)
I0521 13:45:20.532680 14148 sgd_solver.cpp:106] Iteration 24000, lr = 0.0015
I0521 13:45:37.160789 14148 solver.cpp:237] Iteration 25500, loss = 1.08045
I0521 13:45:37.160826 14148 solver.cpp:253]     Train net output #0: loss = 1.08045 (* 1 = 1.08045 loss)
I0521 13:45:37.160843 14148 sgd_solver.cpp:106] Iteration 25500, lr = 0.0015
I0521 13:45:53.785862 14148 solver.cpp:237] Iteration 27000, loss = 0.986019
I0521 13:45:53.786027 14148 solver.cpp:253]     Train net output #0: loss = 0.986018 (* 1 = 0.986018 loss)
I0521 13:45:53.786042 14148 sgd_solver.cpp:106] Iteration 27000, lr = 0.0015
I0521 13:46:10.405915 14148 solver.cpp:237] Iteration 28500, loss = 1.56842
I0521 13:46:10.405954 14148 solver.cpp:253]     Train net output #0: loss = 1.56842 (* 1 = 1.56842 loss)
I0521 13:46:10.405975 14148 sgd_solver.cpp:106] Iteration 28500, lr = 0.0015
I0521 13:46:26.970070 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_30000.caffemodel
I0521 13:46:27.015583 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_30000.solverstate
I0521 13:46:27.041996 14148 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 13:47:26.189160 14148 solver.cpp:409]     Test net output #0: accuracy = 0.841982
I0521 13:47:26.189323 14148 solver.cpp:409]     Test net output #1: loss = 0.552517 (* 1 = 0.552517 loss)
I0521 13:47:48.317234 14148 solver.cpp:237] Iteration 30000, loss = 1.27994
I0521 13:47:48.317289 14148 solver.cpp:253]     Train net output #0: loss = 1.27994 (* 1 = 1.27994 loss)
I0521 13:47:48.317306 14148 sgd_solver.cpp:106] Iteration 30000, lr = 0.0015
I0521 13:48:05.111861 14148 solver.cpp:237] Iteration 31500, loss = 0.97873
I0521 13:48:05.112023 14148 solver.cpp:253]     Train net output #0: loss = 0.97873 (* 1 = 0.97873 loss)
I0521 13:48:05.112037 14148 sgd_solver.cpp:106] Iteration 31500, lr = 0.0015
I0521 13:48:21.893875 14148 solver.cpp:237] Iteration 33000, loss = 1.70412
I0521 13:48:21.893929 14148 solver.cpp:253]     Train net output #0: loss = 1.70412 (* 1 = 1.70412 loss)
I0521 13:48:21.893944 14148 sgd_solver.cpp:106] Iteration 33000, lr = 0.0015
I0521 13:48:38.639705 14148 solver.cpp:237] Iteration 34500, loss = 1.48519
I0521 13:48:38.639844 14148 solver.cpp:253]     Train net output #0: loss = 1.48519 (* 1 = 1.48519 loss)
I0521 13:48:38.639858 14148 sgd_solver.cpp:106] Iteration 34500, lr = 0.0015
I0521 13:48:55.424146 14148 solver.cpp:237] Iteration 36000, loss = 1.35953
I0521 13:48:55.424198 14148 solver.cpp:253]     Train net output #0: loss = 1.35953 (* 1 = 1.35953 loss)
I0521 13:48:55.424213 14148 sgd_solver.cpp:106] Iteration 36000, lr = 0.0015
I0521 13:49:12.197690 14148 solver.cpp:237] Iteration 37500, loss = 1.48215
I0521 13:49:12.197845 14148 solver.cpp:253]     Train net output #0: loss = 1.48215 (* 1 = 1.48215 loss)
I0521 13:49:12.197860 14148 sgd_solver.cpp:106] Iteration 37500, lr = 0.0015
I0521 13:49:28.957782 14148 solver.cpp:237] Iteration 39000, loss = 0.510879
I0521 13:49:28.957818 14148 solver.cpp:253]     Train net output #0: loss = 0.510881 (* 1 = 0.510881 loss)
I0521 13:49:28.957834 14148 sgd_solver.cpp:106] Iteration 39000, lr = 0.0015
I0521 13:50:07.882436 14148 solver.cpp:237] Iteration 40500, loss = 2.01666
I0521 13:50:07.882599 14148 solver.cpp:253]     Train net output #0: loss = 2.01666 (* 1 = 2.01666 loss)
I0521 13:50:07.882614 14148 sgd_solver.cpp:106] Iteration 40500, lr = 0.0015
I0521 13:50:24.668742 14148 solver.cpp:237] Iteration 42000, loss = 1.44863
I0521 13:50:24.668793 14148 solver.cpp:253]     Train net output #0: loss = 1.44863 (* 1 = 1.44863 loss)
I0521 13:50:24.668809 14148 sgd_solver.cpp:106] Iteration 42000, lr = 0.0015
I0521 13:50:41.411005 14148 solver.cpp:237] Iteration 43500, loss = 1.4836
I0521 13:50:41.411157 14148 solver.cpp:253]     Train net output #0: loss = 1.48361 (* 1 = 1.48361 loss)
I0521 13:50:41.411171 14148 sgd_solver.cpp:106] Iteration 43500, lr = 0.0015
I0521 13:50:58.150769 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_45000.caffemodel
I0521 13:50:58.198819 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_45000.solverstate
I0521 13:50:58.230638 14148 solver.cpp:237] Iteration 45000, loss = 0.868941
I0521 13:50:58.230692 14148 solver.cpp:253]     Train net output #0: loss = 0.868943 (* 1 = 0.868943 loss)
I0521 13:50:58.230706 14148 sgd_solver.cpp:106] Iteration 45000, lr = 0.0015
I0521 13:51:15.014634 14148 solver.cpp:237] Iteration 46500, loss = 0.745539
I0521 13:51:15.014799 14148 solver.cpp:253]     Train net output #0: loss = 0.745541 (* 1 = 0.745541 loss)
I0521 13:51:15.014814 14148 sgd_solver.cpp:106] Iteration 46500, lr = 0.0015
I0521 13:51:31.796273 14148 solver.cpp:237] Iteration 48000, loss = 1.1322
I0521 13:51:31.796309 14148 solver.cpp:253]     Train net output #0: loss = 1.1322 (* 1 = 1.1322 loss)
I0521 13:51:31.796326 14148 sgd_solver.cpp:106] Iteration 48000, lr = 0.0015
I0521 13:51:48.568459 14148 solver.cpp:237] Iteration 49500, loss = 0.777496
I0521 13:51:48.568624 14148 solver.cpp:253]     Train net output #0: loss = 0.777499 (* 1 = 0.777499 loss)
I0521 13:51:48.568639 14148 sgd_solver.cpp:106] Iteration 49500, lr = 0.0015
I0521 13:52:27.494706 14148 solver.cpp:237] Iteration 51000, loss = 1.89114
I0521 13:52:27.494871 14148 solver.cpp:253]     Train net output #0: loss = 1.89114 (* 1 = 1.89114 loss)
I0521 13:52:27.494885 14148 sgd_solver.cpp:106] Iteration 51000, lr = 0.0015
I0521 13:52:44.240581 14148 solver.cpp:237] Iteration 52500, loss = 0.896751
I0521 13:52:44.240618 14148 solver.cpp:253]     Train net output #0: loss = 0.896754 (* 1 = 0.896754 loss)
I0521 13:52:44.240636 14148 sgd_solver.cpp:106] Iteration 52500, lr = 0.0015
I0521 13:53:00.926769 14148 solver.cpp:237] Iteration 54000, loss = 1.90523
I0521 13:53:00.926928 14148 solver.cpp:253]     Train net output #0: loss = 1.90523 (* 1 = 1.90523 loss)
I0521 13:53:00.926944 14148 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015
I0521 13:53:17.585661 14148 solver.cpp:237] Iteration 55500, loss = 0.92368
I0521 13:53:17.585711 14148 solver.cpp:253]     Train net output #0: loss = 0.923684 (* 1 = 0.923684 loss)
I0521 13:53:17.585727 14148 sgd_solver.cpp:106] Iteration 55500, lr = 0.0015
I0521 13:53:34.212054 14148 solver.cpp:237] Iteration 57000, loss = 2.51015
I0521 13:53:34.212194 14148 solver.cpp:253]     Train net output #0: loss = 2.51015 (* 1 = 2.51015 loss)
I0521 13:53:34.212208 14148 sgd_solver.cpp:106] Iteration 57000, lr = 0.0015
I0521 13:53:50.832114 14148 solver.cpp:237] Iteration 58500, loss = 0.96816
I0521 13:53:50.832168 14148 solver.cpp:253]     Train net output #0: loss = 0.968163 (* 1 = 0.968163 loss)
I0521 13:53:50.832182 14148 sgd_solver.cpp:106] Iteration 58500, lr = 0.0015
I0521 13:54:07.451972 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_60000.caffemodel
I0521 13:54:07.500660 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_60000.solverstate
I0521 13:54:07.529217 14148 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 13:55:27.625592 14148 solver.cpp:409]     Test net output #0: accuracy = 0.861175
I0521 13:55:27.625767 14148 solver.cpp:409]     Test net output #1: loss = 0.468358 (* 1 = 0.468358 loss)
I0521 13:55:49.783442 14148 solver.cpp:237] Iteration 60000, loss = 1.60346
I0521 13:55:49.783493 14148 solver.cpp:253]     Train net output #0: loss = 1.60346 (* 1 = 1.60346 loss)
I0521 13:55:49.783514 14148 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0521 13:56:06.758510 14148 solver.cpp:237] Iteration 61500, loss = 0.955424
I0521 13:56:06.758662 14148 solver.cpp:253]     Train net output #0: loss = 0.955428 (* 1 = 0.955428 loss)
I0521 13:56:06.758676 14148 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0521 13:56:23.738692 14148 solver.cpp:237] Iteration 63000, loss = 0.804285
I0521 13:56:23.738739 14148 solver.cpp:253]     Train net output #0: loss = 0.804289 (* 1 = 0.804289 loss)
I0521 13:56:23.738755 14148 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0521 13:56:40.694108 14148 solver.cpp:237] Iteration 64500, loss = 1.42941
I0521 13:56:40.694269 14148 solver.cpp:253]     Train net output #0: loss = 1.42941 (* 1 = 1.42941 loss)
I0521 13:56:40.694283 14148 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0521 13:56:57.637253 14148 solver.cpp:237] Iteration 66000, loss = 0.438093
I0521 13:56:57.637289 14148 solver.cpp:253]     Train net output #0: loss = 0.438097 (* 1 = 0.438097 loss)
I0521 13:56:57.637305 14148 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0521 13:57:14.625331 14148 solver.cpp:237] Iteration 67500, loss = 1.13365
I0521 13:57:14.625483 14148 solver.cpp:253]     Train net output #0: loss = 1.13365 (* 1 = 1.13365 loss)
I0521 13:57:14.625495 14148 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0521 13:57:31.601677 14148 solver.cpp:237] Iteration 69000, loss = 1.01346
I0521 13:57:31.601727 14148 solver.cpp:253]     Train net output #0: loss = 1.01346 (* 1 = 1.01346 loss)
I0521 13:57:31.601742 14148 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0521 13:58:10.700315 14148 solver.cpp:237] Iteration 70500, loss = 1.45902
I0521 13:58:10.700486 14148 solver.cpp:253]     Train net output #0: loss = 1.45902 (* 1 = 1.45902 loss)
I0521 13:58:10.700500 14148 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0521 13:58:27.674650 14148 solver.cpp:237] Iteration 72000, loss = 1.45713
I0521 13:58:27.674698 14148 solver.cpp:253]     Train net output #0: loss = 1.45714 (* 1 = 1.45714 loss)
I0521 13:58:27.674715 14148 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0521 13:58:44.486155 14148 solver.cpp:237] Iteration 73500, loss = 1.20014
I0521 13:58:44.486317 14148 solver.cpp:253]     Train net output #0: loss = 1.20014 (* 1 = 1.20014 loss)
I0521 13:58:44.486331 14148 sgd_solver.cpp:106] Iteration 73500, lr = 0.0015
I0521 13:59:01.081723 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_75000.caffemodel
I0521 13:59:01.129782 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_75000.solverstate
I0521 13:59:01.162822 14148 solver.cpp:237] Iteration 75000, loss = 1.54118
I0521 13:59:01.162874 14148 solver.cpp:253]     Train net output #0: loss = 1.54119 (* 1 = 1.54119 loss)
I0521 13:59:01.162890 14148 sgd_solver.cpp:106] Iteration 75000, lr = 0.0015
I0521 13:59:17.772841 14148 solver.cpp:237] Iteration 76500, loss = 1.8539
I0521 13:59:17.773002 14148 solver.cpp:253]     Train net output #0: loss = 1.8539 (* 1 = 1.8539 loss)
I0521 13:59:17.773015 14148 sgd_solver.cpp:106] Iteration 76500, lr = 0.0015
I0521 13:59:34.384804 14148 solver.cpp:237] Iteration 78000, loss = 2.12669
I0521 13:59:34.384846 14148 solver.cpp:253]     Train net output #0: loss = 2.1267 (* 1 = 2.1267 loss)
I0521 13:59:34.384863 14148 sgd_solver.cpp:106] Iteration 78000, lr = 0.0015
I0521 13:59:51.008690 14148 solver.cpp:237] Iteration 79500, loss = 1.10652
I0521 13:59:51.008841 14148 solver.cpp:253]     Train net output #0: loss = 1.10652 (* 1 = 1.10652 loss)
I0521 13:59:51.008854 14148 sgd_solver.cpp:106] Iteration 79500, lr = 0.0015
I0521 14:00:29.802031 14148 solver.cpp:237] Iteration 81000, loss = 1.25419
I0521 14:00:29.802211 14148 solver.cpp:253]     Train net output #0: loss = 1.25419 (* 1 = 1.25419 loss)
I0521 14:00:29.802224 14148 sgd_solver.cpp:106] Iteration 81000, lr = 0.0015
I0521 14:00:46.451581 14148 solver.cpp:237] Iteration 82500, loss = 1.59827
I0521 14:00:46.451627 14148 solver.cpp:253]     Train net output #0: loss = 1.59827 (* 1 = 1.59827 loss)
I0521 14:00:46.451645 14148 sgd_solver.cpp:106] Iteration 82500, lr = 0.0015
I0521 14:01:03.046181 14148 solver.cpp:237] Iteration 84000, loss = 1.06583
I0521 14:01:03.046325 14148 solver.cpp:253]     Train net output #0: loss = 1.06584 (* 1 = 1.06584 loss)
I0521 14:01:03.046339 14148 sgd_solver.cpp:106] Iteration 84000, lr = 0.0015
I0521 14:01:19.643556 14148 solver.cpp:237] Iteration 85500, loss = 1.30374
I0521 14:01:19.643605 14148 solver.cpp:253]     Train net output #0: loss = 1.30375 (* 1 = 1.30375 loss)
I0521 14:01:19.643620 14148 sgd_solver.cpp:106] Iteration 85500, lr = 0.0015
I0521 14:01:36.255033 14148 solver.cpp:237] Iteration 87000, loss = 1.66797
I0521 14:01:36.255195 14148 solver.cpp:253]     Train net output #0: loss = 1.66798 (* 1 = 1.66798 loss)
I0521 14:01:36.255209 14148 sgd_solver.cpp:106] Iteration 87000, lr = 0.0015
I0521 14:01:52.838057 14148 solver.cpp:237] Iteration 88500, loss = 1.1429
I0521 14:01:52.838094 14148 solver.cpp:253]     Train net output #0: loss = 1.14291 (* 1 = 1.14291 loss)
I0521 14:01:52.838109 14148 sgd_solver.cpp:106] Iteration 88500, lr = 0.0015
I0521 14:02:09.452827 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_90000.caffemodel
I0521 14:02:09.499346 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_90000.solverstate
I0521 14:02:09.525605 14148 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 14:03:08.678433 14148 solver.cpp:409]     Test net output #0: accuracy = 0.867604
I0521 14:03:08.678612 14148 solver.cpp:409]     Test net output #1: loss = 0.449725 (* 1 = 0.449725 loss)
I0521 14:03:30.804342 14148 solver.cpp:237] Iteration 90000, loss = 0.964018
I0521 14:03:30.804400 14148 solver.cpp:253]     Train net output #0: loss = 0.964021 (* 1 = 0.964021 loss)
I0521 14:03:30.804416 14148 sgd_solver.cpp:106] Iteration 90000, lr = 0.0015
I0521 14:03:47.853515 14148 solver.cpp:237] Iteration 91500, loss = 0.914731
I0521 14:03:47.853684 14148 solver.cpp:253]     Train net output #0: loss = 0.914735 (* 1 = 0.914735 loss)
I0521 14:03:47.853698 14148 sgd_solver.cpp:106] Iteration 91500, lr = 0.0015
I0521 14:04:04.883765 14148 solver.cpp:237] Iteration 93000, loss = 1.62675
I0521 14:04:04.883816 14148 solver.cpp:253]     Train net output #0: loss = 1.62676 (* 1 = 1.62676 loss)
I0521 14:04:04.883832 14148 sgd_solver.cpp:106] Iteration 93000, lr = 0.0015
I0521 14:04:21.926709 14148 solver.cpp:237] Iteration 94500, loss = 1.76896
I0521 14:04:21.926852 14148 solver.cpp:253]     Train net output #0: loss = 1.76896 (* 1 = 1.76896 loss)
I0521 14:04:21.926865 14148 sgd_solver.cpp:106] Iteration 94500, lr = 0.0015
I0521 14:04:38.974220 14148 solver.cpp:237] Iteration 96000, loss = 0.901009
I0521 14:04:38.974267 14148 solver.cpp:253]     Train net output #0: loss = 0.901012 (* 1 = 0.901012 loss)
I0521 14:04:38.974282 14148 sgd_solver.cpp:106] Iteration 96000, lr = 0.0015
I0521 14:04:56.015612 14148 solver.cpp:237] Iteration 97500, loss = 1.29058
I0521 14:04:56.015769 14148 solver.cpp:253]     Train net output #0: loss = 1.29058 (* 1 = 1.29058 loss)
I0521 14:04:56.015782 14148 sgd_solver.cpp:106] Iteration 97500, lr = 0.0015
I0521 14:05:13.030329 14148 solver.cpp:237] Iteration 99000, loss = 0.759929
I0521 14:05:13.030366 14148 solver.cpp:253]     Train net output #0: loss = 0.759932 (* 1 = 0.759932 loss)
I0521 14:05:13.030382 14148 sgd_solver.cpp:106] Iteration 99000, lr = 0.0015
I0521 14:05:52.208576 14148 solver.cpp:237] Iteration 100500, loss = 0.541978
I0521 14:05:52.208762 14148 solver.cpp:253]     Train net output #0: loss = 0.54198 (* 1 = 0.54198 loss)
I0521 14:05:52.208776 14148 sgd_solver.cpp:106] Iteration 100500, lr = 0.0015
I0521 14:06:09.232542 14148 solver.cpp:237] Iteration 102000, loss = 1.40832
I0521 14:06:09.232594 14148 solver.cpp:253]     Train net output #0: loss = 1.40832 (* 1 = 1.40832 loss)
I0521 14:06:09.232610 14148 sgd_solver.cpp:106] Iteration 102000, lr = 0.0015
I0521 14:06:26.227200 14148 solver.cpp:237] Iteration 103500, loss = 0.875709
I0521 14:06:26.227356 14148 solver.cpp:253]     Train net output #0: loss = 0.875711 (* 1 = 0.875711 loss)
I0521 14:06:26.227370 14148 sgd_solver.cpp:106] Iteration 103500, lr = 0.0015
I0521 14:06:43.281615 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_105000.caffemodel
I0521 14:06:43.327561 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_105000.solverstate
I0521 14:06:43.356358 14148 solver.cpp:237] Iteration 105000, loss = 1.53903
I0521 14:06:43.356408 14148 solver.cpp:253]     Train net output #0: loss = 1.53903 (* 1 = 1.53903 loss)
I0521 14:06:43.356423 14148 sgd_solver.cpp:106] Iteration 105000, lr = 0.0015
I0521 14:07:00.391836 14148 solver.cpp:237] Iteration 106500, loss = 1.20525
I0521 14:07:00.392001 14148 solver.cpp:253]     Train net output #0: loss = 1.20525 (* 1 = 1.20525 loss)
I0521 14:07:00.392015 14148 sgd_solver.cpp:106] Iteration 106500, lr = 0.0015
I0521 14:07:17.416734 14148 solver.cpp:237] Iteration 108000, loss = 0.798171
I0521 14:07:17.416771 14148 solver.cpp:253]     Train net output #0: loss = 0.798174 (* 1 = 0.798174 loss)
I0521 14:07:17.416790 14148 sgd_solver.cpp:106] Iteration 108000, lr = 0.0015
I0521 14:07:34.433549 14148 solver.cpp:237] Iteration 109500, loss = 1.25446
I0521 14:07:34.433699 14148 solver.cpp:253]     Train net output #0: loss = 1.25446 (* 1 = 1.25446 loss)
I0521 14:07:34.433713 14148 sgd_solver.cpp:106] Iteration 109500, lr = 0.0015
I0521 14:08:13.635996 14148 solver.cpp:237] Iteration 111000, loss = 2.40134
I0521 14:08:13.636168 14148 solver.cpp:253]     Train net output #0: loss = 2.40134 (* 1 = 2.40134 loss)
I0521 14:08:13.636183 14148 sgd_solver.cpp:106] Iteration 111000, lr = 0.0015
I0521 14:08:30.696151 14148 solver.cpp:237] Iteration 112500, loss = 2.95263
I0521 14:08:30.696204 14148 solver.cpp:253]     Train net output #0: loss = 2.95263 (* 1 = 2.95263 loss)
I0521 14:08:30.696219 14148 sgd_solver.cpp:106] Iteration 112500, lr = 0.0015
I0521 14:08:47.721499 14148 solver.cpp:237] Iteration 114000, loss = 1.63912
I0521 14:08:47.721663 14148 solver.cpp:253]     Train net output #0: loss = 1.63912 (* 1 = 1.63912 loss)
I0521 14:08:47.721678 14148 sgd_solver.cpp:106] Iteration 114000, lr = 0.0015
I0521 14:09:04.737164 14148 solver.cpp:237] Iteration 115500, loss = 1.35165
I0521 14:09:04.737216 14148 solver.cpp:253]     Train net output #0: loss = 1.35165 (* 1 = 1.35165 loss)
I0521 14:09:04.737231 14148 sgd_solver.cpp:106] Iteration 115500, lr = 0.0015
I0521 14:09:21.765511 14148 solver.cpp:237] Iteration 117000, loss = 1.77164
I0521 14:09:21.765655 14148 solver.cpp:253]     Train net output #0: loss = 1.77164 (* 1 = 1.77164 loss)
I0521 14:09:21.765671 14148 sgd_solver.cpp:106] Iteration 117000, lr = 0.0015
I0521 14:09:38.786064 14148 solver.cpp:237] Iteration 118500, loss = 1.38375
I0521 14:09:38.786110 14148 solver.cpp:253]     Train net output #0: loss = 1.38375 (* 1 = 1.38375 loss)
I0521 14:09:38.786126 14148 sgd_solver.cpp:106] Iteration 118500, lr = 0.0015
I0521 14:09:55.773973 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_120000.caffemodel
I0521 14:09:55.824239 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_120000.solverstate
I0521 14:09:55.849196 14148 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 14:11:16.270824 14148 solver.cpp:409]     Test net output #0: accuracy = 0.872556
I0521 14:11:16.270990 14148 solver.cpp:409]     Test net output #1: loss = 0.383088 (* 1 = 0.383088 loss)
I0521 14:11:38.456771 14148 solver.cpp:237] Iteration 120000, loss = 1.48462
I0521 14:11:38.456828 14148 solver.cpp:253]     Train net output #0: loss = 1.48463 (* 1 = 1.48463 loss)
I0521 14:11:38.456845 14148 sgd_solver.cpp:106] Iteration 120000, lr = 0.0015
I0521 14:11:55.326344 14148 solver.cpp:237] Iteration 121500, loss = 0.515067
I0521 14:11:55.326498 14148 solver.cpp:253]     Train net output #0: loss = 0.515069 (* 1 = 0.515069 loss)
I0521 14:11:55.326511 14148 sgd_solver.cpp:106] Iteration 121500, lr = 0.0015
I0521 14:12:12.233003 14148 solver.cpp:237] Iteration 123000, loss = 0.439041
I0521 14:12:12.233054 14148 solver.cpp:253]     Train net output #0: loss = 0.439043 (* 1 = 0.439043 loss)
I0521 14:12:12.233072 14148 sgd_solver.cpp:106] Iteration 123000, lr = 0.0015
I0521 14:12:29.097887 14148 solver.cpp:237] Iteration 124500, loss = 1.05394
I0521 14:12:29.098067 14148 solver.cpp:253]     Train net output #0: loss = 1.05394 (* 1 = 1.05394 loss)
I0521 14:12:29.098080 14148 sgd_solver.cpp:106] Iteration 124500, lr = 0.0015
I0521 14:12:45.950268 14148 solver.cpp:237] Iteration 126000, loss = 0.785232
I0521 14:12:45.950304 14148 solver.cpp:253]     Train net output #0: loss = 0.785234 (* 1 = 0.785234 loss)
I0521 14:12:45.950321 14148 sgd_solver.cpp:106] Iteration 126000, lr = 0.0015
I0521 14:13:02.735909 14148 solver.cpp:237] Iteration 127500, loss = 1.14215
I0521 14:13:02.736073 14148 solver.cpp:253]     Train net output #0: loss = 1.14215 (* 1 = 1.14215 loss)
I0521 14:13:02.736088 14148 sgd_solver.cpp:106] Iteration 127500, lr = 0.0015
I0521 14:13:19.372898 14148 solver.cpp:237] Iteration 129000, loss = 1.68592
I0521 14:13:19.372942 14148 solver.cpp:253]     Train net output #0: loss = 1.68593 (* 1 = 1.68593 loss)
I0521 14:13:19.372962 14148 sgd_solver.cpp:106] Iteration 129000, lr = 0.0015
I0521 14:13:58.125708 14148 solver.cpp:237] Iteration 130500, loss = 1.05729
I0521 14:13:58.125881 14148 solver.cpp:253]     Train net output #0: loss = 1.05729 (* 1 = 1.05729 loss)
I0521 14:13:58.125895 14148 sgd_solver.cpp:106] Iteration 130500, lr = 0.0015
I0521 14:14:14.744396 14148 solver.cpp:237] Iteration 132000, loss = 0.939209
I0521 14:14:14.744443 14148 solver.cpp:253]     Train net output #0: loss = 0.93921 (* 1 = 0.93921 loss)
I0521 14:14:14.744457 14148 sgd_solver.cpp:106] Iteration 132000, lr = 0.0015
I0521 14:14:31.351284 14148 solver.cpp:237] Iteration 133500, loss = 0.882817
I0521 14:14:31.351441 14148 solver.cpp:253]     Train net output #0: loss = 0.882819 (* 1 = 0.882819 loss)
I0521 14:14:31.351455 14148 sgd_solver.cpp:106] Iteration 133500, lr = 0.0015
I0521 14:14:47.956352 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_135000.caffemodel
I0521 14:14:48.004135 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_135000.solverstate
I0521 14:14:48.034621 14148 solver.cpp:237] Iteration 135000, loss = 1.68752
I0521 14:14:48.034672 14148 solver.cpp:253]     Train net output #0: loss = 1.68752 (* 1 = 1.68752 loss)
I0521 14:14:48.034687 14148 sgd_solver.cpp:106] Iteration 135000, lr = 0.0015
I0521 14:15:04.650516 14148 solver.cpp:237] Iteration 136500, loss = 1.29284
I0521 14:15:04.650683 14148 solver.cpp:253]     Train net output #0: loss = 1.29284 (* 1 = 1.29284 loss)
I0521 14:15:04.650697 14148 sgd_solver.cpp:106] Iteration 136500, lr = 0.0015
I0521 14:15:21.276031 14148 solver.cpp:237] Iteration 138000, loss = 1.80314
I0521 14:15:21.276070 14148 solver.cpp:253]     Train net output #0: loss = 1.80314 (* 1 = 1.80314 loss)
I0521 14:15:21.276092 14148 sgd_solver.cpp:106] Iteration 138000, lr = 0.0015
I0521 14:15:37.858773 14148 solver.cpp:237] Iteration 139500, loss = 1.6135
I0521 14:15:37.858929 14148 solver.cpp:253]     Train net output #0: loss = 1.6135 (* 1 = 1.6135 loss)
I0521 14:15:37.858943 14148 sgd_solver.cpp:106] Iteration 139500, lr = 0.0015
I0521 14:16:16.658077 14148 solver.cpp:237] Iteration 141000, loss = 0.688886
I0521 14:16:16.658253 14148 solver.cpp:253]     Train net output #0: loss = 0.688889 (* 1 = 0.688889 loss)
I0521 14:16:16.658267 14148 sgd_solver.cpp:106] Iteration 141000, lr = 0.0015
I0521 14:16:33.243392 14148 solver.cpp:237] Iteration 142500, loss = 1.65322
I0521 14:16:33.243429 14148 solver.cpp:253]     Train net output #0: loss = 1.65323 (* 1 = 1.65323 loss)
I0521 14:16:33.243446 14148 sgd_solver.cpp:106] Iteration 142500, lr = 0.0015
I0521 14:16:50.206601 14148 solver.cpp:237] Iteration 144000, loss = 1.38613
I0521 14:16:50.206776 14148 solver.cpp:253]     Train net output #0: loss = 1.38613 (* 1 = 1.38613 loss)
I0521 14:16:50.206790 14148 sgd_solver.cpp:106] Iteration 144000, lr = 0.0015
I0521 14:17:07.175911 14148 solver.cpp:237] Iteration 145500, loss = 0.758745
I0521 14:17:07.175962 14148 solver.cpp:253]     Train net output #0: loss = 0.758748 (* 1 = 0.758748 loss)
I0521 14:17:07.175978 14148 sgd_solver.cpp:106] Iteration 145500, lr = 0.0015
I0521 14:17:24.121649 14148 solver.cpp:237] Iteration 147000, loss = 1.5171
I0521 14:17:24.127826 14148 solver.cpp:253]     Train net output #0: loss = 1.5171 (* 1 = 1.5171 loss)
I0521 14:17:24.127843 14148 sgd_solver.cpp:106] Iteration 147000, lr = 0.0015
I0521 14:17:41.078095 14148 solver.cpp:237] Iteration 148500, loss = 0.968112
I0521 14:17:41.078135 14148 solver.cpp:253]     Train net output #0: loss = 0.968115 (* 1 = 0.968115 loss)
I0521 14:17:41.078150 14148 sgd_solver.cpp:106] Iteration 148500, lr = 0.0015
I0521 14:17:58.044911 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_150000.caffemodel
I0521 14:17:58.093235 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_150000.solverstate
I0521 14:17:58.120405 14148 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 14:18:57.494526 14148 solver.cpp:409]     Test net output #0: accuracy = 0.88158
I0521 14:18:57.494695 14148 solver.cpp:409]     Test net output #1: loss = 0.411439 (* 1 = 0.411439 loss)
I0521 14:19:18.377233 14148 solver.cpp:237] Iteration 150000, loss = 1.21406
I0521 14:19:18.377290 14148 solver.cpp:253]     Train net output #0: loss = 1.21407 (* 1 = 1.21407 loss)
I0521 14:19:18.377305 14148 sgd_solver.cpp:106] Iteration 150000, lr = 0.0015
I0521 14:19:35.006883 14148 solver.cpp:237] Iteration 151500, loss = 0.920493
I0521 14:19:35.007055 14148 solver.cpp:253]     Train net output #0: loss = 0.920497 (* 1 = 0.920497 loss)
I0521 14:19:35.007069 14148 sgd_solver.cpp:106] Iteration 151500, lr = 0.0015
I0521 14:19:51.629258 14148 solver.cpp:237] Iteration 153000, loss = 1.69521
I0521 14:19:51.629295 14148 solver.cpp:253]     Train net output #0: loss = 1.69521 (* 1 = 1.69521 loss)
I0521 14:19:51.629308 14148 sgd_solver.cpp:106] Iteration 153000, lr = 0.0015
I0521 14:20:08.238346 14148 solver.cpp:237] Iteration 154500, loss = 1.73895
I0521 14:20:08.238513 14148 solver.cpp:253]     Train net output #0: loss = 1.73895 (* 1 = 1.73895 loss)
I0521 14:20:08.238528 14148 sgd_solver.cpp:106] Iteration 154500, lr = 0.0015
I0521 14:20:24.829180 14148 solver.cpp:237] Iteration 156000, loss = 1.21454
I0521 14:20:24.829223 14148 solver.cpp:253]     Train net output #0: loss = 1.21454 (* 1 = 1.21454 loss)
I0521 14:20:24.829241 14148 sgd_solver.cpp:106] Iteration 156000, lr = 0.0015
I0521 14:20:41.461057 14148 solver.cpp:237] Iteration 157500, loss = 0.815171
I0521 14:20:41.461215 14148 solver.cpp:253]     Train net output #0: loss = 0.815173 (* 1 = 0.815173 loss)
I0521 14:20:41.461228 14148 sgd_solver.cpp:106] Iteration 157500, lr = 0.0015
I0521 14:20:58.100461 14148 solver.cpp:237] Iteration 159000, loss = 1.60966
I0521 14:20:58.100505 14148 solver.cpp:253]     Train net output #0: loss = 1.60966 (* 1 = 1.60966 loss)
I0521 14:20:58.100527 14148 sgd_solver.cpp:106] Iteration 159000, lr = 0.0015
I0521 14:21:35.633172 14148 solver.cpp:237] Iteration 160500, loss = 1.02608
I0521 14:21:35.633347 14148 solver.cpp:253]     Train net output #0: loss = 1.02608 (* 1 = 1.02608 loss)
I0521 14:21:35.633361 14148 sgd_solver.cpp:106] Iteration 160500, lr = 0.0015
I0521 14:21:52.267681 14148 solver.cpp:237] Iteration 162000, loss = 1.15103
I0521 14:21:52.267719 14148 solver.cpp:253]     Train net output #0: loss = 1.15103 (* 1 = 1.15103 loss)
I0521 14:21:52.267734 14148 sgd_solver.cpp:106] Iteration 162000, lr = 0.0015
I0521 14:22:08.907349 14148 solver.cpp:237] Iteration 163500, loss = 1.69747
I0521 14:22:08.907506 14148 solver.cpp:253]     Train net output #0: loss = 1.69747 (* 1 = 1.69747 loss)
I0521 14:22:08.907521 14148 sgd_solver.cpp:106] Iteration 163500, lr = 0.0015
I0521 14:22:25.523720 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_165000.caffemodel
I0521 14:22:25.579375 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_165000.solverstate
I0521 14:22:25.608325 14148 solver.cpp:237] Iteration 165000, loss = 0.584098
I0521 14:22:25.608376 14148 solver.cpp:253]     Train net output #0: loss = 0.584101 (* 1 = 0.584101 loss)
I0521 14:22:25.608391 14148 sgd_solver.cpp:106] Iteration 165000, lr = 0.0015
I0521 14:22:42.365679 14148 solver.cpp:237] Iteration 166500, loss = 1.16097
I0521 14:22:42.365830 14148 solver.cpp:253]     Train net output #0: loss = 1.16097 (* 1 = 1.16097 loss)
I0521 14:22:42.365844 14148 sgd_solver.cpp:106] Iteration 166500, lr = 0.0015
I0521 14:22:59.114528 14148 solver.cpp:237] Iteration 168000, loss = 1.23152
I0521 14:22:59.114581 14148 solver.cpp:253]     Train net output #0: loss = 1.23152 (* 1 = 1.23152 loss)
I0521 14:22:59.114595 14148 sgd_solver.cpp:106] Iteration 168000, lr = 0.0015
I0521 14:23:15.900964 14148 solver.cpp:237] Iteration 169500, loss = 0.486085
I0521 14:23:15.901124 14148 solver.cpp:253]     Train net output #0: loss = 0.486088 (* 1 = 0.486088 loss)
I0521 14:23:15.901139 14148 sgd_solver.cpp:106] Iteration 169500, lr = 0.0015
I0521 14:23:53.565398 14148 solver.cpp:237] Iteration 171000, loss = 1.2844
I0521 14:23:53.565574 14148 solver.cpp:253]     Train net output #0: loss = 1.2844 (* 1 = 1.2844 loss)
I0521 14:23:53.565588 14148 sgd_solver.cpp:106] Iteration 171000, lr = 0.0015
I0521 14:24:10.358098 14148 solver.cpp:237] Iteration 172500, loss = 0.828701
I0521 14:24:10.358150 14148 solver.cpp:253]     Train net output #0: loss = 0.828705 (* 1 = 0.828705 loss)
I0521 14:24:10.358165 14148 sgd_solver.cpp:106] Iteration 172500, lr = 0.0015
I0521 14:24:26.978235 14148 solver.cpp:237] Iteration 174000, loss = 0.935678
I0521 14:24:26.978382 14148 solver.cpp:253]     Train net output #0: loss = 0.935682 (* 1 = 0.935682 loss)
I0521 14:24:26.978396 14148 sgd_solver.cpp:106] Iteration 174000, lr = 0.0015
I0521 14:24:43.598320 14148 solver.cpp:237] Iteration 175500, loss = 0.733226
I0521 14:24:43.598369 14148 solver.cpp:253]     Train net output #0: loss = 0.733231 (* 1 = 0.733231 loss)
I0521 14:24:43.598383 14148 sgd_solver.cpp:106] Iteration 175500, lr = 0.0015
I0521 14:25:00.199561 14148 solver.cpp:237] Iteration 177000, loss = 0.673987
I0521 14:25:00.199723 14148 solver.cpp:253]     Train net output #0: loss = 0.673992 (* 1 = 0.673992 loss)
I0521 14:25:00.199738 14148 sgd_solver.cpp:106] Iteration 177000, lr = 0.0015
I0521 14:25:16.769366 14148 solver.cpp:237] Iteration 178500, loss = 1.51699
I0521 14:25:16.769402 14148 solver.cpp:253]     Train net output #0: loss = 1.51699 (* 1 = 1.51699 loss)
I0521 14:25:16.769417 14148 sgd_solver.cpp:106] Iteration 178500, lr = 0.0015
I0521 14:25:33.369606 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_180000.caffemodel
I0521 14:25:33.415328 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_180000.solverstate
I0521 14:25:33.440441 14148 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 14:26:53.845335 14148 solver.cpp:409]     Test net output #0: accuracy = 0.885921
I0521 14:26:53.845507 14148 solver.cpp:409]     Test net output #1: loss = 0.361932 (* 1 = 0.361932 loss)
I0521 14:27:14.695818 14148 solver.cpp:237] Iteration 180000, loss = 0.712755
I0521 14:27:14.695875 14148 solver.cpp:253]     Train net output #0: loss = 0.71276 (* 1 = 0.71276 loss)
I0521 14:27:14.695891 14148 sgd_solver.cpp:106] Iteration 180000, lr = 0.0015
I0521 14:27:31.571568 14148 solver.cpp:237] Iteration 181500, loss = 1.16606
I0521 14:27:31.571735 14148 solver.cpp:253]     Train net output #0: loss = 1.16607 (* 1 = 1.16607 loss)
I0521 14:27:31.571749 14148 sgd_solver.cpp:106] Iteration 181500, lr = 0.0015
I0521 14:27:48.401620 14148 solver.cpp:237] Iteration 183000, loss = 1.15836
I0521 14:27:48.401656 14148 solver.cpp:253]     Train net output #0: loss = 1.15836 (* 1 = 1.15836 loss)
I0521 14:27:48.401670 14148 sgd_solver.cpp:106] Iteration 183000, lr = 0.0015
I0521 14:28:05.198521 14148 solver.cpp:237] Iteration 184500, loss = 1.17642
I0521 14:28:05.198685 14148 solver.cpp:253]     Train net output #0: loss = 1.17642 (* 1 = 1.17642 loss)
I0521 14:28:05.198700 14148 sgd_solver.cpp:106] Iteration 184500, lr = 0.0015
I0521 14:28:22.071274 14148 solver.cpp:237] Iteration 186000, loss = 1.23331
I0521 14:28:22.071326 14148 solver.cpp:253]     Train net output #0: loss = 1.23331 (* 1 = 1.23331 loss)
I0521 14:28:22.071341 14148 sgd_solver.cpp:106] Iteration 186000, lr = 0.0015
I0521 14:28:38.942435 14148 solver.cpp:237] Iteration 187500, loss = 1.33652
I0521 14:28:38.942584 14148 solver.cpp:253]     Train net output #0: loss = 1.33652 (* 1 = 1.33652 loss)
I0521 14:28:38.942598 14148 sgd_solver.cpp:106] Iteration 187500, lr = 0.0015
I0521 14:28:55.833798 14148 solver.cpp:237] Iteration 189000, loss = 1.47219
I0521 14:28:55.833847 14148 solver.cpp:253]     Train net output #0: loss = 1.47219 (* 1 = 1.47219 loss)
I0521 14:28:55.833860 14148 sgd_solver.cpp:106] Iteration 189000, lr = 0.0015
I0521 14:29:33.480916 14148 solver.cpp:237] Iteration 190500, loss = 1.56635
I0521 14:29:33.481098 14148 solver.cpp:253]     Train net output #0: loss = 1.56636 (* 1 = 1.56636 loss)
I0521 14:29:33.481112 14148 sgd_solver.cpp:106] Iteration 190500, lr = 0.0015
I0521 14:29:50.345667 14148 solver.cpp:237] Iteration 192000, loss = 1.30638
I0521 14:29:50.345703 14148 solver.cpp:253]     Train net output #0: loss = 1.30638 (* 1 = 1.30638 loss)
I0521 14:29:50.345716 14148 sgd_solver.cpp:106] Iteration 192000, lr = 0.0015
I0521 14:30:07.194885 14148 solver.cpp:237] Iteration 193500, loss = 1.54418
I0521 14:30:07.195062 14148 solver.cpp:253]     Train net output #0: loss = 1.54418 (* 1 = 1.54418 loss)
I0521 14:30:07.195076 14148 sgd_solver.cpp:106] Iteration 193500, lr = 0.0015
I0521 14:30:24.035125 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_195000.caffemodel
I0521 14:30:24.081423 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_195000.solverstate
I0521 14:30:24.110067 14148 solver.cpp:237] Iteration 195000, loss = 0.60934
I0521 14:30:24.110112 14148 solver.cpp:253]     Train net output #0: loss = 0.609346 (* 1 = 0.609346 loss)
I0521 14:30:24.110134 14148 sgd_solver.cpp:106] Iteration 195000, lr = 0.0015
I0521 14:30:40.955561 14148 solver.cpp:237] Iteration 196500, loss = 1.89327
I0521 14:30:40.955724 14148 solver.cpp:253]     Train net output #0: loss = 1.89328 (* 1 = 1.89328 loss)
I0521 14:30:40.955739 14148 sgd_solver.cpp:106] Iteration 196500, lr = 0.0015
I0521 14:30:57.812335 14148 solver.cpp:237] Iteration 198000, loss = 1.35222
I0521 14:30:57.812387 14148 solver.cpp:253]     Train net output #0: loss = 1.35223 (* 1 = 1.35223 loss)
I0521 14:30:57.812402 14148 sgd_solver.cpp:106] Iteration 198000, lr = 0.0015
I0521 14:31:14.635656 14148 solver.cpp:237] Iteration 199500, loss = 0.874431
I0521 14:31:14.635825 14148 solver.cpp:253]     Train net output #0: loss = 0.874439 (* 1 = 0.874439 loss)
I0521 14:31:14.635839 14148 sgd_solver.cpp:106] Iteration 199500, lr = 0.0015
I0521 14:31:52.382539 14148 solver.cpp:237] Iteration 201000, loss = 1.83974
I0521 14:31:52.382716 14148 solver.cpp:253]     Train net output #0: loss = 1.83975 (* 1 = 1.83975 loss)
I0521 14:31:52.382730 14148 sgd_solver.cpp:106] Iteration 201000, lr = 0.0015
I0521 14:32:09.276806 14148 solver.cpp:237] Iteration 202500, loss = 0.450549
I0521 14:32:09.276860 14148 solver.cpp:253]     Train net output #0: loss = 0.450557 (* 1 = 0.450557 loss)
I0521 14:32:09.276875 14148 sgd_solver.cpp:106] Iteration 202500, lr = 0.0015
I0521 14:32:26.182288 14148 solver.cpp:237] Iteration 204000, loss = 1.32343
I0521 14:32:26.182454 14148 solver.cpp:253]     Train net output #0: loss = 1.32344 (* 1 = 1.32344 loss)
I0521 14:32:26.182468 14148 sgd_solver.cpp:106] Iteration 204000, lr = 0.0015
I0521 14:32:43.025189 14148 solver.cpp:237] Iteration 205500, loss = 1.02191
I0521 14:32:43.025225 14148 solver.cpp:253]     Train net output #0: loss = 1.02192 (* 1 = 1.02192 loss)
I0521 14:32:43.025239 14148 sgd_solver.cpp:106] Iteration 205500, lr = 0.0015
I0521 14:32:59.855566 14148 solver.cpp:237] Iteration 207000, loss = 1.55911
I0521 14:32:59.855723 14148 solver.cpp:253]     Train net output #0: loss = 1.55912 (* 1 = 1.55912 loss)
I0521 14:32:59.855737 14148 sgd_solver.cpp:106] Iteration 207000, lr = 0.0015
I0521 14:33:16.708860 14148 solver.cpp:237] Iteration 208500, loss = 0.906073
I0521 14:33:16.708899 14148 solver.cpp:253]     Train net output #0: loss = 0.906081 (* 1 = 0.906081 loss)
I0521 14:33:16.708914 14148 sgd_solver.cpp:106] Iteration 208500, lr = 0.0015
I0521 14:33:33.572540 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_210000.caffemodel
I0521 14:33:33.619276 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_210000.solverstate
I0521 14:33:33.644870 14148 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 14:34:32.938299 14148 solver.cpp:409]     Test net output #0: accuracy = 0.885294
I0521 14:34:32.938472 14148 solver.cpp:409]     Test net output #1: loss = 0.396091 (* 1 = 0.396091 loss)
I0521 14:34:53.795404 14148 solver.cpp:237] Iteration 210000, loss = 1.35229
I0521 14:34:53.795461 14148 solver.cpp:253]     Train net output #0: loss = 1.3523 (* 1 = 1.3523 loss)
I0521 14:34:53.795476 14148 sgd_solver.cpp:106] Iteration 210000, lr = 0.0015
I0521 14:35:10.416218 14148 solver.cpp:237] Iteration 211500, loss = 1.02476
I0521 14:35:10.416390 14148 solver.cpp:253]     Train net output #0: loss = 1.02477 (* 1 = 1.02477 loss)
I0521 14:35:10.416404 14148 sgd_solver.cpp:106] Iteration 211500, lr = 0.0015
I0521 14:35:27.032124 14148 solver.cpp:237] Iteration 213000, loss = 1.21022
I0521 14:35:27.032171 14148 solver.cpp:253]     Train net output #0: loss = 1.21023 (* 1 = 1.21023 loss)
I0521 14:35:27.032184 14148 sgd_solver.cpp:106] Iteration 213000, lr = 0.0015
I0521 14:35:43.653447 14148 solver.cpp:237] Iteration 214500, loss = 0.777936
I0521 14:35:43.653605 14148 solver.cpp:253]     Train net output #0: loss = 0.777944 (* 1 = 0.777944 loss)
I0521 14:35:43.653619 14148 sgd_solver.cpp:106] Iteration 214500, lr = 0.0015
I0521 14:36:00.265547 14148 solver.cpp:237] Iteration 216000, loss = 1.10264
I0521 14:36:00.265593 14148 solver.cpp:253]     Train net output #0: loss = 1.10264 (* 1 = 1.10264 loss)
I0521 14:36:00.265606 14148 sgd_solver.cpp:106] Iteration 216000, lr = 0.0015
I0521 14:36:16.885814 14148 solver.cpp:237] Iteration 217500, loss = 1.00502
I0521 14:36:16.885980 14148 solver.cpp:253]     Train net output #0: loss = 1.00502 (* 1 = 1.00502 loss)
I0521 14:36:16.885994 14148 sgd_solver.cpp:106] Iteration 217500, lr = 0.0015
I0521 14:36:33.477180 14148 solver.cpp:237] Iteration 219000, loss = 0.784999
I0521 14:36:33.477217 14148 solver.cpp:253]     Train net output #0: loss = 0.785008 (* 1 = 0.785008 loss)
I0521 14:36:33.477231 14148 sgd_solver.cpp:106] Iteration 219000, lr = 0.0015
I0521 14:37:10.923825 14148 solver.cpp:237] Iteration 220500, loss = 0.85654
I0521 14:37:10.924006 14148 solver.cpp:253]     Train net output #0: loss = 0.856548 (* 1 = 0.856548 loss)
I0521 14:37:10.924021 14148 sgd_solver.cpp:106] Iteration 220500, lr = 0.0015
I0521 14:37:27.550729 14148 solver.cpp:237] Iteration 222000, loss = 1.60323
I0521 14:37:27.550772 14148 solver.cpp:253]     Train net output #0: loss = 1.60324 (* 1 = 1.60324 loss)
I0521 14:37:27.550791 14148 sgd_solver.cpp:106] Iteration 222000, lr = 0.0015
I0521 14:37:44.169849 14148 solver.cpp:237] Iteration 223500, loss = 0.924499
I0521 14:37:44.170001 14148 solver.cpp:253]     Train net output #0: loss = 0.924507 (* 1 = 0.924507 loss)
I0521 14:37:44.170014 14148 sgd_solver.cpp:106] Iteration 223500, lr = 0.0015
I0521 14:38:01.019969 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_225000.caffemodel
I0521 14:38:01.069000 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_225000.solverstate
I0521 14:38:01.100499 14148 solver.cpp:237] Iteration 225000, loss = 1.27168
I0521 14:38:01.100560 14148 solver.cpp:253]     Train net output #0: loss = 1.27169 (* 1 = 1.27169 loss)
I0521 14:38:01.100575 14148 sgd_solver.cpp:106] Iteration 225000, lr = 0.0015
I0521 14:38:17.954808 14148 solver.cpp:237] Iteration 226500, loss = 0.975235
I0521 14:38:17.954982 14148 solver.cpp:253]     Train net output #0: loss = 0.975244 (* 1 = 0.975244 loss)
I0521 14:38:17.954995 14148 sgd_solver.cpp:106] Iteration 226500, lr = 0.0015
I0521 14:38:34.808274 14148 solver.cpp:237] Iteration 228000, loss = 0.964758
I0521 14:38:34.808310 14148 solver.cpp:253]     Train net output #0: loss = 0.964767 (* 1 = 0.964767 loss)
I0521 14:38:34.808325 14148 sgd_solver.cpp:106] Iteration 228000, lr = 0.0015
I0521 14:38:51.743505 14148 solver.cpp:237] Iteration 229500, loss = 0.55031
I0521 14:38:51.743669 14148 solver.cpp:253]     Train net output #0: loss = 0.550319 (* 1 = 0.550319 loss)
I0521 14:38:51.743682 14148 sgd_solver.cpp:106] Iteration 229500, lr = 0.0015
I0521 14:39:29.672629 14148 solver.cpp:237] Iteration 231000, loss = 1.45131
I0521 14:39:29.672806 14148 solver.cpp:253]     Train net output #0: loss = 1.45132 (* 1 = 1.45132 loss)
I0521 14:39:29.672819 14148 sgd_solver.cpp:106] Iteration 231000, lr = 0.0015
I0521 14:39:46.702522 14148 solver.cpp:237] Iteration 232500, loss = 1.06085
I0521 14:39:46.702558 14148 solver.cpp:253]     Train net output #0: loss = 1.06086 (* 1 = 1.06086 loss)
I0521 14:39:46.702571 14148 sgd_solver.cpp:106] Iteration 232500, lr = 0.0015
I0521 14:40:03.713078 14148 solver.cpp:237] Iteration 234000, loss = 0.946094
I0521 14:40:03.713238 14148 solver.cpp:253]     Train net output #0: loss = 0.946103 (* 1 = 0.946103 loss)
I0521 14:40:03.713251 14148 sgd_solver.cpp:106] Iteration 234000, lr = 0.0015
I0521 14:40:20.752228 14148 solver.cpp:237] Iteration 235500, loss = 1.00685
I0521 14:40:20.752274 14148 solver.cpp:253]     Train net output #0: loss = 1.00686 (* 1 = 1.00686 loss)
I0521 14:40:20.752291 14148 sgd_solver.cpp:106] Iteration 235500, lr = 0.0015
I0521 14:40:37.777386 14148 solver.cpp:237] Iteration 237000, loss = 0.257269
I0521 14:40:37.777549 14148 solver.cpp:253]     Train net output #0: loss = 0.257278 (* 1 = 0.257278 loss)
I0521 14:40:37.777564 14148 sgd_solver.cpp:106] Iteration 237000, lr = 0.0015
I0521 14:40:54.845006 14148 solver.cpp:237] Iteration 238500, loss = 0.803785
I0521 14:40:54.845052 14148 solver.cpp:253]     Train net output #0: loss = 0.803794 (* 1 = 0.803794 loss)
I0521 14:40:54.845067 14148 sgd_solver.cpp:106] Iteration 238500, lr = 0.0015
I0521 14:41:11.862447 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_240000.caffemodel
I0521 14:41:11.909198 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_240000.solverstate
I0521 14:41:11.934758 14148 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 14:42:32.482527 14148 solver.cpp:409]     Test net output #0: accuracy = 0.891655
I0521 14:42:32.482710 14148 solver.cpp:409]     Test net output #1: loss = 0.356198 (* 1 = 0.356198 loss)
I0521 14:42:53.357316 14148 solver.cpp:237] Iteration 240000, loss = 1.10898
I0521 14:42:53.357370 14148 solver.cpp:253]     Train net output #0: loss = 1.10899 (* 1 = 1.10899 loss)
I0521 14:42:53.357385 14148 sgd_solver.cpp:106] Iteration 240000, lr = 0.0015
I0521 14:43:10.009490 14148 solver.cpp:237] Iteration 241500, loss = 0.641142
I0521 14:43:10.009649 14148 solver.cpp:253]     Train net output #0: loss = 0.641152 (* 1 = 0.641152 loss)
I0521 14:43:10.009662 14148 sgd_solver.cpp:106] Iteration 241500, lr = 0.0015
I0521 14:43:26.726016 14148 solver.cpp:237] Iteration 243000, loss = 1.19878
I0521 14:43:26.726068 14148 solver.cpp:253]     Train net output #0: loss = 1.19879 (* 1 = 1.19879 loss)
I0521 14:43:26.726083 14148 sgd_solver.cpp:106] Iteration 243000, lr = 0.0015
I0521 14:43:43.560587 14148 solver.cpp:237] Iteration 244500, loss = 1.11142
I0521 14:43:43.560758 14148 solver.cpp:253]     Train net output #0: loss = 1.11143 (* 1 = 1.11143 loss)
I0521 14:43:43.560772 14148 sgd_solver.cpp:106] Iteration 244500, lr = 0.0015
I0521 14:44:00.401892 14148 solver.cpp:237] Iteration 246000, loss = 1.4014
I0521 14:44:00.401928 14148 solver.cpp:253]     Train net output #0: loss = 1.40141 (* 1 = 1.40141 loss)
I0521 14:44:00.401942 14148 sgd_solver.cpp:106] Iteration 246000, lr = 0.0015
I0521 14:44:17.244014 14148 solver.cpp:237] Iteration 247500, loss = 1.3793
I0521 14:44:17.244169 14148 solver.cpp:253]     Train net output #0: loss = 1.37931 (* 1 = 1.37931 loss)
I0521 14:44:17.244184 14148 sgd_solver.cpp:106] Iteration 247500, lr = 0.0015
I0521 14:44:34.074337 14148 solver.cpp:237] Iteration 249000, loss = 0.760177
I0521 14:44:34.074383 14148 solver.cpp:253]     Train net output #0: loss = 0.760187 (* 1 = 0.760187 loss)
I0521 14:44:34.074406 14148 sgd_solver.cpp:106] Iteration 249000, lr = 0.0015
I0521 14:45:11.699244 14148 solver.cpp:237] Iteration 250500, loss = 0.894359
I0521 14:45:11.699424 14148 solver.cpp:253]     Train net output #0: loss = 0.89437 (* 1 = 0.89437 loss)
I0521 14:45:11.699439 14148 sgd_solver.cpp:106] Iteration 250500, lr = 0.0015
I0521 14:45:28.480152 14148 solver.cpp:237] Iteration 252000, loss = 1.47947
I0521 14:45:28.480201 14148 solver.cpp:253]     Train net output #0: loss = 1.47948 (* 1 = 1.47948 loss)
I0521 14:45:28.480216 14148 sgd_solver.cpp:106] Iteration 252000, lr = 0.0015
I0521 14:45:45.237123 14148 solver.cpp:237] Iteration 253500, loss = 1.27322
I0521 14:45:45.237290 14148 solver.cpp:253]     Train net output #0: loss = 1.27323 (* 1 = 1.27323 loss)
I0521 14:45:45.237304 14148 sgd_solver.cpp:106] Iteration 253500, lr = 0.0015
I0521 14:46:02.026696 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_255000.caffemodel
I0521 14:46:02.072324 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_255000.solverstate
I0521 14:46:02.100971 14148 solver.cpp:237] Iteration 255000, loss = 1.19822
I0521 14:46:02.101019 14148 solver.cpp:253]     Train net output #0: loss = 1.19823 (* 1 = 1.19823 loss)
I0521 14:46:02.101035 14148 sgd_solver.cpp:106] Iteration 255000, lr = 0.0015
I0521 14:46:18.873978 14148 solver.cpp:237] Iteration 256500, loss = 0.993249
I0521 14:46:18.874166 14148 solver.cpp:253]     Train net output #0: loss = 0.99326 (* 1 = 0.99326 loss)
I0521 14:46:18.874182 14148 sgd_solver.cpp:106] Iteration 256500, lr = 0.0015
I0521 14:46:35.656235 14148 solver.cpp:237] Iteration 258000, loss = 0.642248
I0521 14:46:35.656282 14148 solver.cpp:253]     Train net output #0: loss = 0.642259 (* 1 = 0.642259 loss)
I0521 14:46:35.656298 14148 sgd_solver.cpp:106] Iteration 258000, lr = 0.0015
I0521 14:46:52.468941 14148 solver.cpp:237] Iteration 259500, loss = 0.907191
I0521 14:46:52.469094 14148 solver.cpp:253]     Train net output #0: loss = 0.907202 (* 1 = 0.907202 loss)
I0521 14:46:52.469108 14148 sgd_solver.cpp:106] Iteration 259500, lr = 0.0015
I0521 14:47:30.159615 14148 solver.cpp:237] Iteration 261000, loss = 1.13089
I0521 14:47:30.159796 14148 solver.cpp:253]     Train net output #0: loss = 1.13091 (* 1 = 1.13091 loss)
I0521 14:47:30.159811 14148 sgd_solver.cpp:106] Iteration 261000, lr = 0.0015
I0521 14:47:46.942332 14148 solver.cpp:237] Iteration 262500, loss = 1.19847
I0521 14:47:46.942368 14148 solver.cpp:253]     Train net output #0: loss = 1.19848 (* 1 = 1.19848 loss)
I0521 14:47:46.942384 14148 sgd_solver.cpp:106] Iteration 262500, lr = 0.0015
I0521 14:48:03.756775 14148 solver.cpp:237] Iteration 264000, loss = 1.46151
I0521 14:48:03.756937 14148 solver.cpp:253]     Train net output #0: loss = 1.46152 (* 1 = 1.46152 loss)
I0521 14:48:03.756952 14148 sgd_solver.cpp:106] Iteration 264000, lr = 0.0015
I0521 14:48:20.557778 14148 solver.cpp:237] Iteration 265500, loss = 1.2679
I0521 14:48:20.557824 14148 solver.cpp:253]     Train net output #0: loss = 1.26791 (* 1 = 1.26791 loss)
I0521 14:48:20.557837 14148 sgd_solver.cpp:106] Iteration 265500, lr = 0.0015
I0521 14:48:37.349954 14148 solver.cpp:237] Iteration 267000, loss = 1.1994
I0521 14:48:37.350103 14148 solver.cpp:253]     Train net output #0: loss = 1.19941 (* 1 = 1.19941 loss)
I0521 14:48:37.350116 14148 sgd_solver.cpp:106] Iteration 267000, lr = 0.0015
I0521 14:48:54.103453 14148 solver.cpp:237] Iteration 268500, loss = 1.48037
I0521 14:48:54.103497 14148 solver.cpp:253]     Train net output #0: loss = 1.48038 (* 1 = 1.48038 loss)
I0521 14:48:54.103510 14148 sgd_solver.cpp:106] Iteration 268500, lr = 0.0015
I0521 14:49:10.855080 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_270000.caffemodel
I0521 14:49:10.902066 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_270000.solverstate
I0521 14:49:10.927248 14148 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 14:50:10.379897 14148 solver.cpp:409]     Test net output #0: accuracy = 0.89083
I0521 14:50:10.380085 14148 solver.cpp:409]     Test net output #1: loss = 0.342712 (* 1 = 0.342712 loss)
I0521 14:50:31.291759 14148 solver.cpp:237] Iteration 270000, loss = 2.3306
I0521 14:50:31.291816 14148 solver.cpp:253]     Train net output #0: loss = 2.33061 (* 1 = 2.33061 loss)
I0521 14:50:31.291831 14148 sgd_solver.cpp:106] Iteration 270000, lr = 0.0015
I0521 14:50:47.861726 14148 solver.cpp:237] Iteration 271500, loss = 1.70881
I0521 14:50:47.861912 14148 solver.cpp:253]     Train net output #0: loss = 1.70882 (* 1 = 1.70882 loss)
I0521 14:50:47.861925 14148 sgd_solver.cpp:106] Iteration 271500, lr = 0.0015
I0521 14:51:04.459146 14148 solver.cpp:237] Iteration 273000, loss = 0.654944
I0521 14:51:04.459183 14148 solver.cpp:253]     Train net output #0: loss = 0.654955 (* 1 = 0.654955 loss)
I0521 14:51:04.459197 14148 sgd_solver.cpp:106] Iteration 273000, lr = 0.0015
I0521 14:51:21.096160 14148 solver.cpp:237] Iteration 274500, loss = 0.606543
I0521 14:51:21.096333 14148 solver.cpp:253]     Train net output #0: loss = 0.606555 (* 1 = 0.606555 loss)
I0521 14:51:21.096348 14148 sgd_solver.cpp:106] Iteration 274500, lr = 0.0015
I0521 14:51:37.731856 14148 solver.cpp:237] Iteration 276000, loss = 1.45031
I0521 14:51:37.731900 14148 solver.cpp:253]     Train net output #0: loss = 1.45032 (* 1 = 1.45032 loss)
I0521 14:51:37.731920 14148 sgd_solver.cpp:106] Iteration 276000, lr = 0.0015
I0521 14:51:54.368327 14148 solver.cpp:237] Iteration 277500, loss = 1.49644
I0521 14:51:54.368480 14148 solver.cpp:253]     Train net output #0: loss = 1.49645 (* 1 = 1.49645 loss)
I0521 14:51:54.368494 14148 sgd_solver.cpp:106] Iteration 277500, lr = 0.0015
I0521 14:52:10.970676 14148 solver.cpp:237] Iteration 279000, loss = 1.11768
I0521 14:52:10.970724 14148 solver.cpp:253]     Train net output #0: loss = 1.1177 (* 1 = 1.1177 loss)
I0521 14:52:10.970738 14148 sgd_solver.cpp:106] Iteration 279000, lr = 0.0015
I0521 14:52:48.473505 14148 solver.cpp:237] Iteration 280500, loss = 1.07507
I0521 14:52:48.473686 14148 solver.cpp:253]     Train net output #0: loss = 1.07509 (* 1 = 1.07509 loss)
I0521 14:52:48.473701 14148 sgd_solver.cpp:106] Iteration 280500, lr = 0.0015
I0521 14:53:05.091236 14148 solver.cpp:237] Iteration 282000, loss = 1.37478
I0521 14:53:05.091284 14148 solver.cpp:253]     Train net output #0: loss = 1.37479 (* 1 = 1.37479 loss)
I0521 14:53:05.091297 14148 sgd_solver.cpp:106] Iteration 282000, lr = 0.0015
I0521 14:53:21.723090 14148 solver.cpp:237] Iteration 283500, loss = 0.957708
I0521 14:53:21.723263 14148 solver.cpp:253]     Train net output #0: loss = 0.957723 (* 1 = 0.957723 loss)
I0521 14:53:21.723276 14148 sgd_solver.cpp:106] Iteration 283500, lr = 0.0015
I0521 14:53:38.345618 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_285000.caffemodel
I0521 14:53:38.393836 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_285000.solverstate
I0521 14:53:38.425261 14148 solver.cpp:237] Iteration 285000, loss = 2.34164
I0521 14:53:38.425313 14148 solver.cpp:253]     Train net output #0: loss = 2.34165 (* 1 = 2.34165 loss)
I0521 14:53:38.425329 14148 sgd_solver.cpp:106] Iteration 285000, lr = 0.0015
I0521 14:53:55.053961 14148 solver.cpp:237] Iteration 286500, loss = 1.33025
I0521 14:53:55.054136 14148 solver.cpp:253]     Train net output #0: loss = 1.33026 (* 1 = 1.33026 loss)
I0521 14:53:55.054150 14148 sgd_solver.cpp:106] Iteration 286500, lr = 0.0015
I0521 14:54:11.658542 14148 solver.cpp:237] Iteration 288000, loss = 2.32036
I0521 14:54:11.658596 14148 solver.cpp:253]     Train net output #0: loss = 2.32038 (* 1 = 2.32038 loss)
I0521 14:54:11.658609 14148 sgd_solver.cpp:106] Iteration 288000, lr = 0.0015
I0521 14:54:28.295804 14148 solver.cpp:237] Iteration 289500, loss = 0.645739
I0521 14:54:28.295963 14148 solver.cpp:253]     Train net output #0: loss = 0.645755 (* 1 = 0.645755 loss)
I0521 14:54:28.295975 14148 sgd_solver.cpp:106] Iteration 289500, lr = 0.0015
I0521 14:55:05.816728 14148 solver.cpp:237] Iteration 291000, loss = 1.59138
I0521 14:55:05.816910 14148 solver.cpp:253]     Train net output #0: loss = 1.5914 (* 1 = 1.5914 loss)
I0521 14:55:05.816925 14148 sgd_solver.cpp:106] Iteration 291000, lr = 0.0015
I0521 14:55:22.445614 14148 solver.cpp:237] Iteration 292500, loss = 1.12632
I0521 14:55:22.445660 14148 solver.cpp:253]     Train net output #0: loss = 1.12634 (* 1 = 1.12634 loss)
I0521 14:55:22.445677 14148 sgd_solver.cpp:106] Iteration 292500, lr = 0.0015
I0521 14:55:39.068961 14148 solver.cpp:237] Iteration 294000, loss = 1.01921
I0521 14:55:39.069128 14148 solver.cpp:253]     Train net output #0: loss = 1.01923 (* 1 = 1.01923 loss)
I0521 14:55:39.069140 14148 sgd_solver.cpp:106] Iteration 294000, lr = 0.0015
I0521 14:55:55.692713 14148 solver.cpp:237] Iteration 295500, loss = 1.03591
I0521 14:55:55.692754 14148 solver.cpp:253]     Train net output #0: loss = 1.03593 (* 1 = 1.03593 loss)
I0521 14:55:55.692769 14148 sgd_solver.cpp:106] Iteration 295500, lr = 0.0015
I0521 14:56:12.311054 14148 solver.cpp:237] Iteration 297000, loss = 1.50829
I0521 14:56:12.311231 14148 solver.cpp:253]     Train net output #0: loss = 1.5083 (* 1 = 1.5083 loss)
I0521 14:56:12.311245 14148 sgd_solver.cpp:106] Iteration 297000, lr = 0.0015
I0521 14:56:28.949944 14148 solver.cpp:237] Iteration 298500, loss = 0.980442
I0521 14:56:28.949981 14148 solver.cpp:253]     Train net output #0: loss = 0.980459 (* 1 = 0.980459 loss)
I0521 14:56:28.949995 14148 sgd_solver.cpp:106] Iteration 298500, lr = 0.0015
I0521 14:56:45.580072 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_300000.caffemodel
I0521 14:56:45.627614 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_300000.solverstate
I0521 14:56:45.655037 14148 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 14:58:05.979025 14148 solver.cpp:409]     Test net output #0: accuracy = 0.89459
I0521 14:58:05.979210 14148 solver.cpp:409]     Test net output #1: loss = 0.330082 (* 1 = 0.330082 loss)
I0521 14:58:26.863261 14148 solver.cpp:237] Iteration 300000, loss = 0.684639
I0521 14:58:26.863318 14148 solver.cpp:253]     Train net output #0: loss = 0.684656 (* 1 = 0.684656 loss)
I0521 14:58:26.863334 14148 sgd_solver.cpp:106] Iteration 300000, lr = 0.0015
I0521 14:58:43.919195 14148 solver.cpp:237] Iteration 301500, loss = 1.13795
I0521 14:58:43.919368 14148 solver.cpp:253]     Train net output #0: loss = 1.13797 (* 1 = 1.13797 loss)
I0521 14:58:43.919380 14148 sgd_solver.cpp:106] Iteration 301500, lr = 0.0015
I0521 14:59:00.987429 14148 solver.cpp:237] Iteration 303000, loss = 1.25356
I0521 14:59:00.987467 14148 solver.cpp:253]     Train net output #0: loss = 1.25357 (* 1 = 1.25357 loss)
I0521 14:59:00.987480 14148 sgd_solver.cpp:106] Iteration 303000, lr = 0.0015
I0521 14:59:18.007444 14148 solver.cpp:237] Iteration 304500, loss = 1.2541
I0521 14:59:18.007617 14148 solver.cpp:253]     Train net output #0: loss = 1.25411 (* 1 = 1.25411 loss)
I0521 14:59:18.007632 14148 sgd_solver.cpp:106] Iteration 304500, lr = 0.0015
I0521 14:59:35.051583 14148 solver.cpp:237] Iteration 306000, loss = 1.08674
I0521 14:59:35.051628 14148 solver.cpp:253]     Train net output #0: loss = 1.08676 (* 1 = 1.08676 loss)
I0521 14:59:35.051645 14148 sgd_solver.cpp:106] Iteration 306000, lr = 0.0015
I0521 14:59:52.060642 14148 solver.cpp:237] Iteration 307500, loss = 1.22433
I0521 14:59:52.060765 14148 solver.cpp:253]     Train net output #0: loss = 1.22434 (* 1 = 1.22434 loss)
I0521 14:59:52.060778 14148 sgd_solver.cpp:106] Iteration 307500, lr = 0.0015
I0521 15:00:09.098258 14148 solver.cpp:237] Iteration 309000, loss = 0.902276
I0521 15:00:09.098307 14148 solver.cpp:253]     Train net output #0: loss = 0.902293 (* 1 = 0.902293 loss)
I0521 15:00:09.098321 14148 sgd_solver.cpp:106] Iteration 309000, lr = 0.0015
I0521 15:00:47.011171 14148 solver.cpp:237] Iteration 310500, loss = 1.54136
I0521 15:00:47.011351 14148 solver.cpp:253]     Train net output #0: loss = 1.54137 (* 1 = 1.54137 loss)
I0521 15:00:47.011365 14148 sgd_solver.cpp:106] Iteration 310500, lr = 0.0015
I0521 15:01:04.020053 14148 solver.cpp:237] Iteration 312000, loss = 1.13565
I0521 15:01:04.020089 14148 solver.cpp:253]     Train net output #0: loss = 1.13566 (* 1 = 1.13566 loss)
I0521 15:01:04.020103 14148 sgd_solver.cpp:106] Iteration 312000, lr = 0.0015
I0521 15:01:21.026816 14148 solver.cpp:237] Iteration 313500, loss = 0.857776
I0521 15:01:21.026995 14148 solver.cpp:253]     Train net output #0: loss = 0.857794 (* 1 = 0.857794 loss)
I0521 15:01:21.027009 14148 sgd_solver.cpp:106] Iteration 313500, lr = 0.0015
I0521 15:01:38.093667 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_315000.caffemodel
I0521 15:01:38.140010 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_315000.solverstate
I0521 15:01:38.168705 14148 solver.cpp:237] Iteration 315000, loss = 0.384365
I0521 15:01:38.168750 14148 solver.cpp:253]     Train net output #0: loss = 0.384382 (* 1 = 0.384382 loss)
I0521 15:01:38.168762 14148 sgd_solver.cpp:106] Iteration 315000, lr = 0.0015
I0521 15:01:55.203811 14148 solver.cpp:237] Iteration 316500, loss = 0.644774
I0521 15:01:55.203975 14148 solver.cpp:253]     Train net output #0: loss = 0.644791 (* 1 = 0.644791 loss)
I0521 15:01:55.203989 14148 sgd_solver.cpp:106] Iteration 316500, lr = 0.0015
I0521 15:02:12.211876 14148 solver.cpp:237] Iteration 318000, loss = 1.68343
I0521 15:02:12.211928 14148 solver.cpp:253]     Train net output #0: loss = 1.68345 (* 1 = 1.68345 loss)
I0521 15:02:12.211942 14148 sgd_solver.cpp:106] Iteration 318000, lr = 0.0015
I0521 15:02:29.238875 14148 solver.cpp:237] Iteration 319500, loss = 0.949552
I0521 15:02:29.239048 14148 solver.cpp:253]     Train net output #0: loss = 0.949569 (* 1 = 0.949569 loss)
I0521 15:02:29.239063 14148 sgd_solver.cpp:106] Iteration 319500, lr = 0.0015
I0521 15:03:07.144583 14148 solver.cpp:237] Iteration 321000, loss = 0.826625
I0521 15:03:07.144765 14148 solver.cpp:253]     Train net output #0: loss = 0.826642 (* 1 = 0.826642 loss)
I0521 15:03:07.144780 14148 sgd_solver.cpp:106] Iteration 321000, lr = 0.0015
I0521 15:03:24.200850 14148 solver.cpp:237] Iteration 322500, loss = 1.11182
I0521 15:03:24.200901 14148 solver.cpp:253]     Train net output #0: loss = 1.11184 (* 1 = 1.11184 loss)
I0521 15:03:24.200916 14148 sgd_solver.cpp:106] Iteration 322500, lr = 0.0015
I0521 15:03:41.196583 14148 solver.cpp:237] Iteration 324000, loss = 0.674364
I0521 15:03:41.196756 14148 solver.cpp:253]     Train net output #0: loss = 0.674381 (* 1 = 0.674381 loss)
I0521 15:03:41.196770 14148 sgd_solver.cpp:106] Iteration 324000, lr = 0.0015
I0521 15:03:58.212869 14148 solver.cpp:237] Iteration 325500, loss = 0.923113
I0521 15:03:58.212901 14148 solver.cpp:253]     Train net output #0: loss = 0.92313 (* 1 = 0.92313 loss)
I0521 15:03:58.212915 14148 sgd_solver.cpp:106] Iteration 325500, lr = 0.0015
I0521 15:04:15.167148 14148 solver.cpp:237] Iteration 327000, loss = 1.16961
I0521 15:04:15.167317 14148 solver.cpp:253]     Train net output #0: loss = 1.16963 (* 1 = 1.16963 loss)
I0521 15:04:15.167331 14148 sgd_solver.cpp:106] Iteration 327000, lr = 0.0015
I0521 15:04:32.118734 14148 solver.cpp:237] Iteration 328500, loss = 1.4448
I0521 15:04:32.118782 14148 solver.cpp:253]     Train net output #0: loss = 1.44482 (* 1 = 1.44482 loss)
I0521 15:04:32.118795 14148 sgd_solver.cpp:106] Iteration 328500, lr = 0.0015
I0521 15:04:49.054800 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_330000.caffemodel
I0521 15:04:49.100739 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_330000.solverstate
I0521 15:04:49.125962 14148 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 15:05:48.277536 14148 solver.cpp:409]     Test net output #0: accuracy = 0.895383
I0521 15:05:48.277726 14148 solver.cpp:409]     Test net output #1: loss = 0.336676 (* 1 = 0.336676 loss)
I0521 15:06:09.142254 14148 solver.cpp:237] Iteration 330000, loss = 0.966464
I0521 15:06:09.142310 14148 solver.cpp:253]     Train net output #0: loss = 0.96648 (* 1 = 0.96648 loss)
I0521 15:06:09.142329 14148 sgd_solver.cpp:106] Iteration 330000, lr = 0.0015
I0521 15:06:25.922821 14148 solver.cpp:237] Iteration 331500, loss = 2.0013
I0521 15:06:25.922984 14148 solver.cpp:253]     Train net output #0: loss = 2.00131 (* 1 = 2.00131 loss)
I0521 15:06:25.922997 14148 sgd_solver.cpp:106] Iteration 331500, lr = 0.0015
I0521 15:06:42.576437 14148 solver.cpp:237] Iteration 333000, loss = 1.27826
I0521 15:06:42.576486 14148 solver.cpp:253]     Train net output #0: loss = 1.27828 (* 1 = 1.27828 loss)
I0521 15:06:42.576500 14148 sgd_solver.cpp:106] Iteration 333000, lr = 0.0015
I0521 15:06:59.166842 14148 solver.cpp:237] Iteration 334500, loss = 1.7291
I0521 15:06:59.167018 14148 solver.cpp:253]     Train net output #0: loss = 1.72912 (* 1 = 1.72912 loss)
I0521 15:06:59.167032 14148 sgd_solver.cpp:106] Iteration 334500, lr = 0.0015
I0521 15:07:15.785656 14148 solver.cpp:237] Iteration 336000, loss = 1.81862
I0521 15:07:15.785693 14148 solver.cpp:253]     Train net output #0: loss = 1.81864 (* 1 = 1.81864 loss)
I0521 15:07:15.785707 14148 sgd_solver.cpp:106] Iteration 336000, lr = 0.0015
I0521 15:07:32.425011 14148 solver.cpp:237] Iteration 337500, loss = 0.570475
I0521 15:07:32.425191 14148 solver.cpp:253]     Train net output #0: loss = 0.570491 (* 1 = 0.570491 loss)
I0521 15:07:32.425209 14148 sgd_solver.cpp:106] Iteration 337500, lr = 0.0015
I0521 15:07:49.068492 14148 solver.cpp:237] Iteration 339000, loss = 1.31742
I0521 15:07:49.068534 14148 solver.cpp:253]     Train net output #0: loss = 1.31744 (* 1 = 1.31744 loss)
I0521 15:07:49.068548 14148 sgd_solver.cpp:106] Iteration 339000, lr = 0.0015
I0521 15:08:26.583659 14148 solver.cpp:237] Iteration 340500, loss = 1.23568
I0521 15:08:26.583843 14148 solver.cpp:253]     Train net output #0: loss = 1.2357 (* 1 = 1.2357 loss)
I0521 15:08:26.583858 14148 sgd_solver.cpp:106] Iteration 340500, lr = 0.0015
I0521 15:08:43.224818 14148 solver.cpp:237] Iteration 342000, loss = 1.00305
I0521 15:08:43.224861 14148 solver.cpp:253]     Train net output #0: loss = 1.00307 (* 1 = 1.00307 loss)
I0521 15:08:43.224881 14148 sgd_solver.cpp:106] Iteration 342000, lr = 0.0015
I0521 15:08:59.817512 14148 solver.cpp:237] Iteration 343500, loss = 1.40084
I0521 15:08:59.817672 14148 solver.cpp:253]     Train net output #0: loss = 1.40085 (* 1 = 1.40085 loss)
I0521 15:08:59.817684 14148 sgd_solver.cpp:106] Iteration 343500, lr = 0.0015
I0521 15:09:16.441354 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_345000.caffemodel
I0521 15:09:16.486486 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_345000.solverstate
I0521 15:09:16.514984 14148 solver.cpp:237] Iteration 345000, loss = 1.21707
I0521 15:09:16.515034 14148 solver.cpp:253]     Train net output #0: loss = 1.21709 (* 1 = 1.21709 loss)
I0521 15:09:16.515048 14148 sgd_solver.cpp:106] Iteration 345000, lr = 0.0015
I0521 15:09:33.101997 14148 solver.cpp:237] Iteration 346500, loss = 1.19955
I0521 15:09:33.102172 14148 solver.cpp:253]     Train net output #0: loss = 1.19957 (* 1 = 1.19957 loss)
I0521 15:09:33.102186 14148 sgd_solver.cpp:106] Iteration 346500, lr = 0.0015
I0521 15:09:49.691463 14148 solver.cpp:237] Iteration 348000, loss = 0.921044
I0521 15:09:49.691501 14148 solver.cpp:253]     Train net output #0: loss = 0.921058 (* 1 = 0.921058 loss)
I0521 15:09:49.691515 14148 sgd_solver.cpp:106] Iteration 348000, lr = 0.0015
I0521 15:10:06.332273 14148 solver.cpp:237] Iteration 349500, loss = 0.611634
I0521 15:10:06.332453 14148 solver.cpp:253]     Train net output #0: loss = 0.611648 (* 1 = 0.611648 loss)
I0521 15:10:06.332468 14148 sgd_solver.cpp:106] Iteration 349500, lr = 0.0015
I0521 15:10:43.798686 14148 solver.cpp:237] Iteration 351000, loss = 1.25835
I0521 15:10:43.798872 14148 solver.cpp:253]     Train net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I0521 15:10:43.798887 14148 sgd_solver.cpp:106] Iteration 351000, lr = 0.0015
I0521 15:11:00.416309 14148 solver.cpp:237] Iteration 352500, loss = 0.645945
I0521 15:11:00.416359 14148 solver.cpp:253]     Train net output #0: loss = 0.645959 (* 1 = 0.645959 loss)
I0521 15:11:00.416373 14148 sgd_solver.cpp:106] Iteration 352500, lr = 0.0015
I0521 15:11:17.055619 14148 solver.cpp:237] Iteration 354000, loss = 1.13471
I0521 15:11:17.055793 14148 solver.cpp:253]     Train net output #0: loss = 1.13472 (* 1 = 1.13472 loss)
I0521 15:11:17.055806 14148 sgd_solver.cpp:106] Iteration 354000, lr = 0.0015
I0521 15:11:33.684188 14148 solver.cpp:237] Iteration 355500, loss = 1.3523
I0521 15:11:33.684224 14148 solver.cpp:253]     Train net output #0: loss = 1.35232 (* 1 = 1.35232 loss)
I0521 15:11:33.684238 14148 sgd_solver.cpp:106] Iteration 355500, lr = 0.0015
I0521 15:11:50.309108 14148 solver.cpp:237] Iteration 357000, loss = 0.971049
I0521 15:11:50.309283 14148 solver.cpp:253]     Train net output #0: loss = 0.971064 (* 1 = 0.971064 loss)
I0521 15:11:50.309298 14148 sgd_solver.cpp:106] Iteration 357000, lr = 0.0015
I0521 15:12:06.901792 14148 solver.cpp:237] Iteration 358500, loss = 0.626023
I0521 15:12:06.901845 14148 solver.cpp:253]     Train net output #0: loss = 0.626038 (* 1 = 0.626038 loss)
I0521 15:12:06.901859 14148 sgd_solver.cpp:106] Iteration 358500, lr = 0.0015
I0521 15:12:23.522670 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_360000.caffemodel
I0521 15:12:23.568269 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_360000.solverstate
I0521 15:12:23.593444 14148 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 15:13:44.127375 14148 solver.cpp:409]     Test net output #0: accuracy = 0.892937
I0521 15:13:44.127559 14148 solver.cpp:409]     Test net output #1: loss = 0.361505 (* 1 = 0.361505 loss)
I0521 15:14:05.008015 14148 solver.cpp:237] Iteration 360000, loss = 0.879615
I0521 15:14:05.008076 14148 solver.cpp:253]     Train net output #0: loss = 0.87963 (* 1 = 0.87963 loss)
I0521 15:14:05.008091 14148 sgd_solver.cpp:106] Iteration 360000, lr = 0.0015
I0521 15:14:22.163703 14148 solver.cpp:237] Iteration 361500, loss = 0.922194
I0521 15:14:22.163869 14148 solver.cpp:253]     Train net output #0: loss = 0.92221 (* 1 = 0.92221 loss)
I0521 15:14:22.163882 14148 sgd_solver.cpp:106] Iteration 361500, lr = 0.0015
I0521 15:14:39.332777 14148 solver.cpp:237] Iteration 363000, loss = 0.988794
I0521 15:14:39.332828 14148 solver.cpp:253]     Train net output #0: loss = 0.988809 (* 1 = 0.988809 loss)
I0521 15:14:39.332842 14148 sgd_solver.cpp:106] Iteration 363000, lr = 0.0015
I0521 15:14:56.508486 14148 solver.cpp:237] Iteration 364500, loss = 1.14175
I0521 15:14:56.508663 14148 solver.cpp:253]     Train net output #0: loss = 1.14177 (* 1 = 1.14177 loss)
I0521 15:14:56.508677 14148 sgd_solver.cpp:106] Iteration 364500, lr = 0.0015
I0521 15:15:13.732053 14148 solver.cpp:237] Iteration 366000, loss = 1.0678
I0521 15:15:13.732089 14148 solver.cpp:253]     Train net output #0: loss = 1.06782 (* 1 = 1.06782 loss)
I0521 15:15:13.732103 14148 sgd_solver.cpp:106] Iteration 366000, lr = 0.0015
I0521 15:15:30.921632 14148 solver.cpp:237] Iteration 367500, loss = 1.1304
I0521 15:15:30.921810 14148 solver.cpp:253]     Train net output #0: loss = 1.13041 (* 1 = 1.13041 loss)
I0521 15:15:30.921824 14148 sgd_solver.cpp:106] Iteration 367500, lr = 0.0015
I0521 15:15:47.974099 14148 solver.cpp:237] Iteration 369000, loss = 0.930472
I0521 15:15:47.974153 14148 solver.cpp:253]     Train net output #0: loss = 0.930488 (* 1 = 0.930488 loss)
I0521 15:15:47.974167 14148 sgd_solver.cpp:106] Iteration 369000, lr = 0.0015
I0521 15:16:25.474987 14148 solver.cpp:237] Iteration 370500, loss = 1.67651
I0521 15:16:25.475183 14148 solver.cpp:253]     Train net output #0: loss = 1.67653 (* 1 = 1.67653 loss)
I0521 15:16:25.475198 14148 sgd_solver.cpp:106] Iteration 370500, lr = 0.0015
I0521 15:16:42.081028 14148 solver.cpp:237] Iteration 372000, loss = 0.93149
I0521 15:16:42.081079 14148 solver.cpp:253]     Train net output #0: loss = 0.931506 (* 1 = 0.931506 loss)
I0521 15:16:42.081092 14148 sgd_solver.cpp:106] Iteration 372000, lr = 0.0015
I0521 15:16:58.670003 14148 solver.cpp:237] Iteration 373500, loss = 0.314119
I0521 15:16:58.670171 14148 solver.cpp:253]     Train net output #0: loss = 0.314136 (* 1 = 0.314136 loss)
I0521 15:16:58.670183 14148 sgd_solver.cpp:106] Iteration 373500, lr = 0.0015
I0521 15:17:15.280706 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_375000.caffemodel
I0521 15:17:15.329336 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_375000.solverstate
I0521 15:17:15.360940 14148 solver.cpp:237] Iteration 375000, loss = 1.01535
I0521 15:17:15.360993 14148 solver.cpp:253]     Train net output #0: loss = 1.01537 (* 1 = 1.01537 loss)
I0521 15:17:15.361009 14148 sgd_solver.cpp:106] Iteration 375000, lr = 0.0015
I0521 15:17:32.239753 14148 solver.cpp:237] Iteration 376500, loss = 1.32251
I0521 15:17:32.239944 14148 solver.cpp:253]     Train net output #0: loss = 1.32252 (* 1 = 1.32252 loss)
I0521 15:17:32.239959 14148 sgd_solver.cpp:106] Iteration 376500, lr = 0.0015
I0521 15:17:49.078234 14148 solver.cpp:237] Iteration 378000, loss = 0.818739
I0521 15:17:49.078271 14148 solver.cpp:253]     Train net output #0: loss = 0.818756 (* 1 = 0.818756 loss)
I0521 15:17:49.078285 14148 sgd_solver.cpp:106] Iteration 378000, lr = 0.0015
I0521 15:18:05.969254 14148 solver.cpp:237] Iteration 379500, loss = 1.03635
I0521 15:18:05.969411 14148 solver.cpp:253]     Train net output #0: loss = 1.03636 (* 1 = 1.03636 loss)
I0521 15:18:05.969425 14148 sgd_solver.cpp:106] Iteration 379500, lr = 0.0015
I0521 15:18:43.728760 14148 solver.cpp:237] Iteration 381000, loss = 0.955807
I0521 15:18:43.728945 14148 solver.cpp:253]     Train net output #0: loss = 0.955823 (* 1 = 0.955823 loss)
I0521 15:18:43.728958 14148 sgd_solver.cpp:106] Iteration 381000, lr = 0.0015
I0521 15:19:00.597767 14148 solver.cpp:237] Iteration 382500, loss = 1.33365
I0521 15:19:00.597805 14148 solver.cpp:253]     Train net output #0: loss = 1.33366 (* 1 = 1.33366 loss)
I0521 15:19:00.597818 14148 sgd_solver.cpp:106] Iteration 382500, lr = 0.0015
I0521 15:19:17.483126 14148 solver.cpp:237] Iteration 384000, loss = 1.03077
I0521 15:19:17.483299 14148 solver.cpp:253]     Train net output #0: loss = 1.03078 (* 1 = 1.03078 loss)
I0521 15:19:17.483314 14148 sgd_solver.cpp:106] Iteration 384000, lr = 0.0015
I0521 15:19:34.275277 14148 solver.cpp:237] Iteration 385500, loss = 1.11152
I0521 15:19:34.275323 14148 solver.cpp:253]     Train net output #0: loss = 1.11154 (* 1 = 1.11154 loss)
I0521 15:19:34.275339 14148 sgd_solver.cpp:106] Iteration 385500, lr = 0.0015
I0521 15:19:50.860672 14148 solver.cpp:237] Iteration 387000, loss = 1.50316
I0521 15:19:50.860832 14148 solver.cpp:253]     Train net output #0: loss = 1.50318 (* 1 = 1.50318 loss)
I0521 15:19:50.860846 14148 sgd_solver.cpp:106] Iteration 387000, lr = 0.0015
I0521 15:20:07.488533 14148 solver.cpp:237] Iteration 388500, loss = 0.824042
I0521 15:20:07.488586 14148 solver.cpp:253]     Train net output #0: loss = 0.824058 (* 1 = 0.824058 loss)
I0521 15:20:07.488600 14148 sgd_solver.cpp:106] Iteration 388500, lr = 0.0015
I0521 15:20:24.105164 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_390000.caffemodel
I0521 15:20:24.150745 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_390000.solverstate
I0521 15:20:24.175809 14148 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 15:21:23.769677 14148 solver.cpp:409]     Test net output #0: accuracy = 0.89766
I0521 15:21:23.769865 14148 solver.cpp:409]     Test net output #1: loss = 0.316262 (* 1 = 0.316262 loss)
I0521 15:21:44.645239 14148 solver.cpp:237] Iteration 390000, loss = 1.00767
I0521 15:21:44.645297 14148 solver.cpp:253]     Train net output #0: loss = 1.00768 (* 1 = 1.00768 loss)
I0521 15:21:44.645310 14148 sgd_solver.cpp:106] Iteration 390000, lr = 0.0015
I0521 15:22:01.659227 14148 solver.cpp:237] Iteration 391500, loss = 1.28228
I0521 15:22:01.659409 14148 solver.cpp:253]     Train net output #0: loss = 1.28229 (* 1 = 1.28229 loss)
I0521 15:22:01.659422 14148 sgd_solver.cpp:106] Iteration 391500, lr = 0.0015
I0521 15:22:18.687990 14148 solver.cpp:237] Iteration 393000, loss = 1.20036
I0521 15:22:18.688026 14148 solver.cpp:253]     Train net output #0: loss = 1.20037 (* 1 = 1.20037 loss)
I0521 15:22:18.688041 14148 sgd_solver.cpp:106] Iteration 393000, lr = 0.0015
I0521 15:22:35.737151 14148 solver.cpp:237] Iteration 394500, loss = 1.20077
I0521 15:22:35.737321 14148 solver.cpp:253]     Train net output #0: loss = 1.20078 (* 1 = 1.20078 loss)
I0521 15:22:35.737334 14148 sgd_solver.cpp:106] Iteration 394500, lr = 0.0015
I0521 15:22:52.778017 14148 solver.cpp:237] Iteration 396000, loss = 1.08507
I0521 15:22:52.778066 14148 solver.cpp:253]     Train net output #0: loss = 1.08509 (* 1 = 1.08509 loss)
I0521 15:22:52.778080 14148 sgd_solver.cpp:106] Iteration 396000, lr = 0.0015
I0521 15:23:09.807574 14148 solver.cpp:237] Iteration 397500, loss = 1.0831
I0521 15:23:09.807739 14148 solver.cpp:253]     Train net output #0: loss = 1.08311 (* 1 = 1.08311 loss)
I0521 15:23:09.807754 14148 sgd_solver.cpp:106] Iteration 397500, lr = 0.0015
I0521 15:23:26.955826 14148 solver.cpp:237] Iteration 399000, loss = 0.944338
I0521 15:23:26.955881 14148 solver.cpp:253]     Train net output #0: loss = 0.944352 (* 1 = 0.944352 loss)
I0521 15:23:26.955895 14148 sgd_solver.cpp:106] Iteration 399000, lr = 0.0015
I0521 15:24:05.092572 14148 solver.cpp:237] Iteration 400500, loss = 1.54135
I0521 15:24:05.092759 14148 solver.cpp:253]     Train net output #0: loss = 1.54136 (* 1 = 1.54136 loss)
I0521 15:24:05.092773 14148 sgd_solver.cpp:106] Iteration 400500, lr = 0.0015
I0521 15:24:22.274449 14148 solver.cpp:237] Iteration 402000, loss = 1.19057
I0521 15:24:22.274485 14148 solver.cpp:253]     Train net output #0: loss = 1.19058 (* 1 = 1.19058 loss)
I0521 15:24:22.274500 14148 sgd_solver.cpp:106] Iteration 402000, lr = 0.0015
I0521 15:24:39.480926 14148 solver.cpp:237] Iteration 403500, loss = 0.954711
I0521 15:24:39.481108 14148 solver.cpp:253]     Train net output #0: loss = 0.954725 (* 1 = 0.954725 loss)
I0521 15:24:39.481122 14148 sgd_solver.cpp:106] Iteration 403500, lr = 0.0015
I0521 15:24:56.665320 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_405000.caffemodel
I0521 15:24:56.802044 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_405000.solverstate
I0521 15:24:56.934725 14148 solver.cpp:237] Iteration 405000, loss = 1.09068
I0521 15:24:56.934773 14148 solver.cpp:253]     Train net output #0: loss = 1.0907 (* 1 = 1.0907 loss)
I0521 15:24:56.934788 14148 sgd_solver.cpp:106] Iteration 405000, lr = 0.0015
I0521 15:25:14.128803 14148 solver.cpp:237] Iteration 406500, loss = 0.654399
I0521 15:25:14.128980 14148 solver.cpp:253]     Train net output #0: loss = 0.654412 (* 1 = 0.654412 loss)
I0521 15:25:14.128994 14148 sgd_solver.cpp:106] Iteration 406500, lr = 0.0015
I0521 15:25:31.309224 14148 solver.cpp:237] Iteration 408000, loss = 1.32358
I0521 15:25:31.309274 14148 solver.cpp:253]     Train net output #0: loss = 1.32359 (* 1 = 1.32359 loss)
I0521 15:25:31.309288 14148 sgd_solver.cpp:106] Iteration 408000, lr = 0.0015
I0521 15:25:48.477891 14148 solver.cpp:237] Iteration 409500, loss = 1.29681
I0521 15:25:48.478073 14148 solver.cpp:253]     Train net output #0: loss = 1.29683 (* 1 = 1.29683 loss)
I0521 15:25:48.478088 14148 sgd_solver.cpp:106] Iteration 409500, lr = 0.0015
I0521 15:26:26.523108 14148 solver.cpp:237] Iteration 411000, loss = 1.49817
I0521 15:26:26.523296 14148 solver.cpp:253]     Train net output #0: loss = 1.49819 (* 1 = 1.49819 loss)
I0521 15:26:26.523310 14148 sgd_solver.cpp:106] Iteration 411000, lr = 0.0015
I0521 15:26:43.689501 14148 solver.cpp:237] Iteration 412500, loss = 1.60402
I0521 15:26:43.689548 14148 solver.cpp:253]     Train net output #0: loss = 1.60403 (* 1 = 1.60403 loss)
I0521 15:26:43.689563 14148 sgd_solver.cpp:106] Iteration 412500, lr = 0.0015
I0521 15:27:00.896838 14148 solver.cpp:237] Iteration 414000, loss = 1.93952
I0521 15:27:00.897018 14148 solver.cpp:253]     Train net output #0: loss = 1.93953 (* 1 = 1.93953 loss)
I0521 15:27:00.897032 14148 sgd_solver.cpp:106] Iteration 414000, lr = 0.0015
I0521 15:27:18.050094 14148 solver.cpp:237] Iteration 415500, loss = 1.30692
I0521 15:27:18.050130 14148 solver.cpp:253]     Train net output #0: loss = 1.30694 (* 1 = 1.30694 loss)
I0521 15:27:18.050144 14148 sgd_solver.cpp:106] Iteration 415500, lr = 0.0015
I0521 15:27:35.249431 14148 solver.cpp:237] Iteration 417000, loss = 1.24974
I0521 15:27:35.249606 14148 solver.cpp:253]     Train net output #0: loss = 1.24975 (* 1 = 1.24975 loss)
I0521 15:27:35.249619 14148 sgd_solver.cpp:106] Iteration 417000, lr = 0.0015
I0521 15:27:52.442605 14148 solver.cpp:237] Iteration 418500, loss = 0.803704
I0521 15:27:52.442657 14148 solver.cpp:253]     Train net output #0: loss = 0.803719 (* 1 = 0.803719 loss)
I0521 15:27:52.442672 14148 sgd_solver.cpp:106] Iteration 418500, lr = 0.0015
I0521 15:28:09.592242 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_420000.caffemodel
I0521 15:28:09.638948 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_420000.solverstate
I0521 15:28:09.664369 14148 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 15:29:29.805469 14148 solver.cpp:409]     Test net output #0: accuracy = 0.895084
I0521 15:29:29.805647 14148 solver.cpp:409]     Test net output #1: loss = 0.320362 (* 1 = 0.320362 loss)
I0521 15:29:50.617806 14148 solver.cpp:237] Iteration 420000, loss = 1.00436
I0521 15:29:50.617863 14148 solver.cpp:253]     Train net output #0: loss = 1.00437 (* 1 = 1.00437 loss)
I0521 15:29:50.617878 14148 sgd_solver.cpp:106] Iteration 420000, lr = 0.0015
I0521 15:30:07.560364 14148 solver.cpp:237] Iteration 421500, loss = 0.955513
I0521 15:30:07.560556 14148 solver.cpp:253]     Train net output #0: loss = 0.955528 (* 1 = 0.955528 loss)
I0521 15:30:07.560570 14148 sgd_solver.cpp:106] Iteration 421500, lr = 0.0015
I0521 15:30:24.522678 14148 solver.cpp:237] Iteration 423000, loss = 1.27337
I0521 15:30:24.522718 14148 solver.cpp:253]     Train net output #0: loss = 1.27338 (* 1 = 1.27338 loss)
I0521 15:30:24.522738 14148 sgd_solver.cpp:106] Iteration 423000, lr = 0.0015
I0521 15:30:41.501070 14148 solver.cpp:237] Iteration 424500, loss = 1.15497
I0521 15:30:41.501235 14148 solver.cpp:253]     Train net output #0: loss = 1.15499 (* 1 = 1.15499 loss)
I0521 15:30:41.501247 14148 sgd_solver.cpp:106] Iteration 424500, lr = 0.0015
I0521 15:30:58.441154 14148 solver.cpp:237] Iteration 426000, loss = 1.17324
I0521 15:30:58.441200 14148 solver.cpp:253]     Train net output #0: loss = 1.17326 (* 1 = 1.17326 loss)
I0521 15:30:58.441213 14148 sgd_solver.cpp:106] Iteration 426000, lr = 0.0015
I0521 15:31:15.458544 14148 solver.cpp:237] Iteration 427500, loss = 0.994442
I0521 15:31:15.458739 14148 solver.cpp:253]     Train net output #0: loss = 0.994457 (* 1 = 0.994457 loss)
I0521 15:31:15.458753 14148 sgd_solver.cpp:106] Iteration 427500, lr = 0.0015
I0521 15:31:32.636636 14148 solver.cpp:237] Iteration 429000, loss = 0.679687
I0521 15:31:32.636674 14148 solver.cpp:253]     Train net output #0: loss = 0.679702 (* 1 = 0.679702 loss)
I0521 15:31:32.636687 14148 sgd_solver.cpp:106] Iteration 429000, lr = 0.0015
I0521 15:32:10.661716 14148 solver.cpp:237] Iteration 430500, loss = 0.863646
I0521 15:32:10.661907 14148 solver.cpp:253]     Train net output #0: loss = 0.863662 (* 1 = 0.863662 loss)
I0521 15:32:10.661921 14148 sgd_solver.cpp:106] Iteration 430500, lr = 0.0015
I0521 15:32:27.827754 14148 solver.cpp:237] Iteration 432000, loss = 1.44303
I0521 15:32:27.827798 14148 solver.cpp:253]     Train net output #0: loss = 1.44305 (* 1 = 1.44305 loss)
I0521 15:32:27.827816 14148 sgd_solver.cpp:106] Iteration 432000, lr = 0.0015
I0521 15:32:45.021059 14148 solver.cpp:237] Iteration 433500, loss = 1.20318
I0521 15:32:45.021222 14148 solver.cpp:253]     Train net output #0: loss = 1.2032 (* 1 = 1.2032 loss)
I0521 15:32:45.021235 14148 sgd_solver.cpp:106] Iteration 433500, lr = 0.0015
I0521 15:33:02.168664 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_435000.caffemodel
I0521 15:33:02.216612 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_435000.solverstate
I0521 15:33:02.247251 14148 solver.cpp:237] Iteration 435000, loss = 2.48747
I0521 15:33:02.247300 14148 solver.cpp:253]     Train net output #0: loss = 2.48748 (* 1 = 2.48748 loss)
I0521 15:33:02.247319 14148 sgd_solver.cpp:106] Iteration 435000, lr = 0.0015
I0521 15:33:19.396227 14148 solver.cpp:237] Iteration 436500, loss = 0.622401
I0521 15:33:19.396414 14148 solver.cpp:253]     Train net output #0: loss = 0.622418 (* 1 = 0.622418 loss)
I0521 15:33:19.396428 14148 sgd_solver.cpp:106] Iteration 436500, lr = 0.0015
I0521 15:33:36.592113 14148 solver.cpp:237] Iteration 438000, loss = 1.35622
I0521 15:33:36.592147 14148 solver.cpp:253]     Train net output #0: loss = 1.35623 (* 1 = 1.35623 loss)
I0521 15:33:36.592164 14148 sgd_solver.cpp:106] Iteration 438000, lr = 0.0015
I0521 15:33:53.802412 14148 solver.cpp:237] Iteration 439500, loss = 1.67895
I0521 15:33:53.802594 14148 solver.cpp:253]     Train net output #0: loss = 1.67897 (* 1 = 1.67897 loss)
I0521 15:33:53.802608 14148 sgd_solver.cpp:106] Iteration 439500, lr = 0.0015
I0521 15:34:31.848323 14148 solver.cpp:237] Iteration 441000, loss = 0.628172
I0521 15:34:31.848522 14148 solver.cpp:253]     Train net output #0: loss = 0.628188 (* 1 = 0.628188 loss)
I0521 15:34:31.848539 14148 sgd_solver.cpp:106] Iteration 441000, lr = 0.0015
I0521 15:34:49.023943 14148 solver.cpp:237] Iteration 442500, loss = 1.27838
I0521 15:34:49.023978 14148 solver.cpp:253]     Train net output #0: loss = 1.27839 (* 1 = 1.27839 loss)
I0521 15:34:49.023993 14148 sgd_solver.cpp:106] Iteration 442500, lr = 0.0015
I0521 15:35:06.165498 14148 solver.cpp:237] Iteration 444000, loss = 1.29859
I0521 15:35:06.165678 14148 solver.cpp:253]     Train net output #0: loss = 1.29861 (* 1 = 1.29861 loss)
I0521 15:35:06.165690 14148 sgd_solver.cpp:106] Iteration 444000, lr = 0.0015
I0521 15:35:23.329644 14148 solver.cpp:237] Iteration 445500, loss = 1.27514
I0521 15:35:23.329694 14148 solver.cpp:253]     Train net output #0: loss = 1.27516 (* 1 = 1.27516 loss)
I0521 15:35:23.329707 14148 sgd_solver.cpp:106] Iteration 445500, lr = 0.0015
I0521 15:35:40.530526 14148 solver.cpp:237] Iteration 447000, loss = 1.54948
I0521 15:35:40.530704 14148 solver.cpp:253]     Train net output #0: loss = 1.54949 (* 1 = 1.54949 loss)
I0521 15:35:40.530719 14148 sgd_solver.cpp:106] Iteration 447000, lr = 0.0015
I0521 15:35:57.717784 14148 solver.cpp:237] Iteration 448500, loss = 0.563937
I0521 15:35:57.717830 14148 solver.cpp:253]     Train net output #0: loss = 0.563953 (* 1 = 0.563953 loss)
I0521 15:35:57.717844 14148 sgd_solver.cpp:106] Iteration 448500, lr = 0.0015
I0521 15:36:14.875615 14148 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_450000.caffemodel
I0521 15:36:14.924304 14148 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0015_2016-05-20T15.48.50.039036_iter_450000.solverstate
I0521 15:36:14.952036 14148 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 15:37:14.200750 14148 solver.cpp:409]     Test net output #0: accuracy = 0.898957
I0521 15:37:14.200938 14148 solver.cpp:409]     Test net output #1: loss = 0.317075 (* 1 = 0.317075 loss)
I0521 15:37:35.052556 14148 solver.cpp:237] Iteration 450000, loss = 1.17118
I0521 15:37:35.052613 14148 solver.cpp:253]     Train net output #0: loss = 1.1712 (* 1 = 1.1712 loss)
I0521 15:37:35.052628 14148 sgd_solver.cpp:106] Iteration 450000, lr = 0.0015
I0521 15:37:52.086242 14148 solver.cpp:237] Iteration 451500, loss = 0.912283
I0521 15:37:52.086444 14148 solver.cpp:253]     Train net output #0: loss = 0.912297 (* 1 = 0.912297 loss)
I0521 15:37:52.086458 14148 sgd_solver.cpp:106] Iteration 451500, lr = 0.0015
I0521 15:38:09.110610 14148 solver.cpp:237] Iteration 453000, loss = 1.23844
I0521 15:38:09.110646 14148 solver.cpp:253]     Train net output #0: loss = 1.23845 (* 1 = 1.23845 loss)
I0521 15:38:09.110661 14148 sgd_solver.cpp:106] Iteration 453000, lr = 0.0015
I0521 15:38:26.144263 14148 solver.cpp:237] Iteration 454500, loss = 1.51136
I0521 15:38:26.144443 14148 solver.cpp:253]     Train net output #0: loss = 1.51137 (* 1 = 1.51137 loss)
I0521 15:38:26.144457 14148 sgd_solver.cpp:106] Iteration 454500, lr = 0.0015
I0521 15:38:43.198879 14148 solver.cpp:237] Iteration 456000, loss = 0.878941
I0521 15:38:43.198918 14148 solver.cpp:253]     Train net output #0: loss = 0.878956 (* 1 = 0.878956 loss)
I0521 15:38:43.198937 14148 sgd_solver.cpp:106] Iteration 456000, lr = 0.0015
aprun: Apid 11238593: Caught signal Terminated, sending to application
*** Aborted at 1463859530 (unix time) try "date -d @1463859530" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x3741) received by PID 14148 (TID 0x2aaac746f900) from PID 14145; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7236 exceeded limit 7200
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11238593: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11238593: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11238593: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11238593: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11238593: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11238593: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
aprun: Apid 11238593: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03795] [c8-1c0s6n3] [Sat May 21 15:38:52 2016] PE RANK 0 exit signal Terminated
Application 11238593 exit codes: 143
Application 11238593 resources: utime ~6327s, stime ~899s, Rss ~5333524, inblocks ~10476658, outblocks ~474920
