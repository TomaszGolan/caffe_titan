2812691
I0526 19:09:39.074228 14297 caffe.cpp:184] Using GPUs 0
I0526 19:09:39.500685 14297 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.004
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271.prototxt"
I0526 19:09:39.502478 14297 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271.prototxt
I0526 19:09:39.524111 14297 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 19:09:39.524168 14297 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 19:09:39.524516 14297 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 19:09:39.524698 14297 layer_factory.hpp:77] Creating layer data_hdf5
I0526 19:09:39.524720 14297 net.cpp:106] Creating Layer data_hdf5
I0526 19:09:39.524735 14297 net.cpp:411] data_hdf5 -> data
I0526 19:09:39.524770 14297 net.cpp:411] data_hdf5 -> label
I0526 19:09:39.524801 14297 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 19:09:39.526367 14297 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 19:09:39.539144 14297 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 19:10:01.143173 14297 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 19:10:01.148352 14297 net.cpp:150] Setting up data_hdf5
I0526 19:10:01.148394 14297 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 19:10:01.148408 14297 net.cpp:157] Top shape: 20 (20)
I0526 19:10:01.148421 14297 net.cpp:165] Memory required for data: 508080
I0526 19:10:01.148433 14297 layer_factory.hpp:77] Creating layer conv1
I0526 19:10:01.148468 14297 net.cpp:106] Creating Layer conv1
I0526 19:10:01.148478 14297 net.cpp:454] conv1 <- data
I0526 19:10:01.148499 14297 net.cpp:411] conv1 -> conv1
I0526 19:10:02.308956 14297 net.cpp:150] Setting up conv1
I0526 19:10:02.309006 14297 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:10:02.309017 14297 net.cpp:165] Memory required for data: 6037680
I0526 19:10:02.309046 14297 layer_factory.hpp:77] Creating layer relu1
I0526 19:10:02.309068 14297 net.cpp:106] Creating Layer relu1
I0526 19:10:02.309079 14297 net.cpp:454] relu1 <- conv1
I0526 19:10:02.309093 14297 net.cpp:397] relu1 -> conv1 (in-place)
I0526 19:10:02.309610 14297 net.cpp:150] Setting up relu1
I0526 19:10:02.309628 14297 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:10:02.309638 14297 net.cpp:165] Memory required for data: 11567280
I0526 19:10:02.309648 14297 layer_factory.hpp:77] Creating layer pool1
I0526 19:10:02.309664 14297 net.cpp:106] Creating Layer pool1
I0526 19:10:02.309674 14297 net.cpp:454] pool1 <- conv1
I0526 19:10:02.309687 14297 net.cpp:411] pool1 -> pool1
I0526 19:10:02.309767 14297 net.cpp:150] Setting up pool1
I0526 19:10:02.309782 14297 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 19:10:02.309792 14297 net.cpp:165] Memory required for data: 14332080
I0526 19:10:02.309800 14297 layer_factory.hpp:77] Creating layer conv2
I0526 19:10:02.309823 14297 net.cpp:106] Creating Layer conv2
I0526 19:10:02.309834 14297 net.cpp:454] conv2 <- pool1
I0526 19:10:02.309845 14297 net.cpp:411] conv2 -> conv2
I0526 19:10:02.312543 14297 net.cpp:150] Setting up conv2
I0526 19:10:02.312569 14297 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:10:02.312582 14297 net.cpp:165] Memory required for data: 18306480
I0526 19:10:02.312600 14297 layer_factory.hpp:77] Creating layer relu2
I0526 19:10:02.312615 14297 net.cpp:106] Creating Layer relu2
I0526 19:10:02.312625 14297 net.cpp:454] relu2 <- conv2
I0526 19:10:02.312638 14297 net.cpp:397] relu2 -> conv2 (in-place)
I0526 19:10:02.312968 14297 net.cpp:150] Setting up relu2
I0526 19:10:02.312983 14297 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:10:02.312994 14297 net.cpp:165] Memory required for data: 22280880
I0526 19:10:02.313004 14297 layer_factory.hpp:77] Creating layer pool2
I0526 19:10:02.313015 14297 net.cpp:106] Creating Layer pool2
I0526 19:10:02.313025 14297 net.cpp:454] pool2 <- conv2
I0526 19:10:02.313038 14297 net.cpp:411] pool2 -> pool2
I0526 19:10:02.313119 14297 net.cpp:150] Setting up pool2
I0526 19:10:02.313133 14297 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 19:10:02.313143 14297 net.cpp:165] Memory required for data: 24268080
I0526 19:10:02.313151 14297 layer_factory.hpp:77] Creating layer conv3
I0526 19:10:02.313169 14297 net.cpp:106] Creating Layer conv3
I0526 19:10:02.313179 14297 net.cpp:454] conv3 <- pool2
I0526 19:10:02.313194 14297 net.cpp:411] conv3 -> conv3
I0526 19:10:02.315129 14297 net.cpp:150] Setting up conv3
I0526 19:10:02.315151 14297 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:10:02.315165 14297 net.cpp:165] Memory required for data: 26436400
I0526 19:10:02.315182 14297 layer_factory.hpp:77] Creating layer relu3
I0526 19:10:02.315199 14297 net.cpp:106] Creating Layer relu3
I0526 19:10:02.315209 14297 net.cpp:454] relu3 <- conv3
I0526 19:10:02.315222 14297 net.cpp:397] relu3 -> conv3 (in-place)
I0526 19:10:02.315690 14297 net.cpp:150] Setting up relu3
I0526 19:10:02.315706 14297 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:10:02.315716 14297 net.cpp:165] Memory required for data: 28604720
I0526 19:10:02.315726 14297 layer_factory.hpp:77] Creating layer pool3
I0526 19:10:02.315739 14297 net.cpp:106] Creating Layer pool3
I0526 19:10:02.315749 14297 net.cpp:454] pool3 <- conv3
I0526 19:10:02.315762 14297 net.cpp:411] pool3 -> pool3
I0526 19:10:02.315829 14297 net.cpp:150] Setting up pool3
I0526 19:10:02.315842 14297 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 19:10:02.315852 14297 net.cpp:165] Memory required for data: 29688880
I0526 19:10:02.315861 14297 layer_factory.hpp:77] Creating layer conv4
I0526 19:10:02.315878 14297 net.cpp:106] Creating Layer conv4
I0526 19:10:02.315889 14297 net.cpp:454] conv4 <- pool3
I0526 19:10:02.315903 14297 net.cpp:411] conv4 -> conv4
I0526 19:10:02.318624 14297 net.cpp:150] Setting up conv4
I0526 19:10:02.318652 14297 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:10:02.318663 14297 net.cpp:165] Memory required for data: 30414640
I0526 19:10:02.318678 14297 layer_factory.hpp:77] Creating layer relu4
I0526 19:10:02.318692 14297 net.cpp:106] Creating Layer relu4
I0526 19:10:02.318702 14297 net.cpp:454] relu4 <- conv4
I0526 19:10:02.318716 14297 net.cpp:397] relu4 -> conv4 (in-place)
I0526 19:10:02.319178 14297 net.cpp:150] Setting up relu4
I0526 19:10:02.319195 14297 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:10:02.319205 14297 net.cpp:165] Memory required for data: 31140400
I0526 19:10:02.319214 14297 layer_factory.hpp:77] Creating layer pool4
I0526 19:10:02.319227 14297 net.cpp:106] Creating Layer pool4
I0526 19:10:02.319237 14297 net.cpp:454] pool4 <- conv4
I0526 19:10:02.319250 14297 net.cpp:411] pool4 -> pool4
I0526 19:10:02.319319 14297 net.cpp:150] Setting up pool4
I0526 19:10:02.319332 14297 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 19:10:02.319342 14297 net.cpp:165] Memory required for data: 31503280
I0526 19:10:02.319352 14297 layer_factory.hpp:77] Creating layer ip1
I0526 19:10:02.319373 14297 net.cpp:106] Creating Layer ip1
I0526 19:10:02.319385 14297 net.cpp:454] ip1 <- pool4
I0526 19:10:02.319397 14297 net.cpp:411] ip1 -> ip1
I0526 19:10:02.334830 14297 net.cpp:150] Setting up ip1
I0526 19:10:02.334858 14297 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:10:02.334870 14297 net.cpp:165] Memory required for data: 31518960
I0526 19:10:02.334892 14297 layer_factory.hpp:77] Creating layer relu5
I0526 19:10:02.334908 14297 net.cpp:106] Creating Layer relu5
I0526 19:10:02.334918 14297 net.cpp:454] relu5 <- ip1
I0526 19:10:02.334931 14297 net.cpp:397] relu5 -> ip1 (in-place)
I0526 19:10:02.335273 14297 net.cpp:150] Setting up relu5
I0526 19:10:02.335286 14297 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:10:02.335296 14297 net.cpp:165] Memory required for data: 31534640
I0526 19:10:02.335306 14297 layer_factory.hpp:77] Creating layer drop1
I0526 19:10:02.335328 14297 net.cpp:106] Creating Layer drop1
I0526 19:10:02.335338 14297 net.cpp:454] drop1 <- ip1
I0526 19:10:02.335350 14297 net.cpp:397] drop1 -> ip1 (in-place)
I0526 19:10:02.335410 14297 net.cpp:150] Setting up drop1
I0526 19:10:02.335423 14297 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:10:02.335433 14297 net.cpp:165] Memory required for data: 31550320
I0526 19:10:02.335443 14297 layer_factory.hpp:77] Creating layer ip2
I0526 19:10:02.335463 14297 net.cpp:106] Creating Layer ip2
I0526 19:10:02.335472 14297 net.cpp:454] ip2 <- ip1
I0526 19:10:02.335486 14297 net.cpp:411] ip2 -> ip2
I0526 19:10:02.335948 14297 net.cpp:150] Setting up ip2
I0526 19:10:02.335961 14297 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:10:02.335971 14297 net.cpp:165] Memory required for data: 31558160
I0526 19:10:02.335986 14297 layer_factory.hpp:77] Creating layer relu6
I0526 19:10:02.335999 14297 net.cpp:106] Creating Layer relu6
I0526 19:10:02.336009 14297 net.cpp:454] relu6 <- ip2
I0526 19:10:02.336020 14297 net.cpp:397] relu6 -> ip2 (in-place)
I0526 19:10:02.336601 14297 net.cpp:150] Setting up relu6
I0526 19:10:02.336623 14297 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:10:02.336633 14297 net.cpp:165] Memory required for data: 31566000
I0526 19:10:02.336643 14297 layer_factory.hpp:77] Creating layer drop2
I0526 19:10:02.336658 14297 net.cpp:106] Creating Layer drop2
I0526 19:10:02.336668 14297 net.cpp:454] drop2 <- ip2
I0526 19:10:02.336681 14297 net.cpp:397] drop2 -> ip2 (in-place)
I0526 19:10:02.336724 14297 net.cpp:150] Setting up drop2
I0526 19:10:02.336737 14297 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:10:02.336747 14297 net.cpp:165] Memory required for data: 31573840
I0526 19:10:02.336757 14297 layer_factory.hpp:77] Creating layer ip3
I0526 19:10:02.336771 14297 net.cpp:106] Creating Layer ip3
I0526 19:10:02.336781 14297 net.cpp:454] ip3 <- ip2
I0526 19:10:02.336792 14297 net.cpp:411] ip3 -> ip3
I0526 19:10:02.337005 14297 net.cpp:150] Setting up ip3
I0526 19:10:02.337018 14297 net.cpp:157] Top shape: 20 11 (220)
I0526 19:10:02.337028 14297 net.cpp:165] Memory required for data: 31574720
I0526 19:10:02.337044 14297 layer_factory.hpp:77] Creating layer drop3
I0526 19:10:02.337056 14297 net.cpp:106] Creating Layer drop3
I0526 19:10:02.337065 14297 net.cpp:454] drop3 <- ip3
I0526 19:10:02.337077 14297 net.cpp:397] drop3 -> ip3 (in-place)
I0526 19:10:02.337117 14297 net.cpp:150] Setting up drop3
I0526 19:10:02.337131 14297 net.cpp:157] Top shape: 20 11 (220)
I0526 19:10:02.337139 14297 net.cpp:165] Memory required for data: 31575600
I0526 19:10:02.337149 14297 layer_factory.hpp:77] Creating layer loss
I0526 19:10:02.337169 14297 net.cpp:106] Creating Layer loss
I0526 19:10:02.337178 14297 net.cpp:454] loss <- ip3
I0526 19:10:02.337190 14297 net.cpp:454] loss <- label
I0526 19:10:02.337203 14297 net.cpp:411] loss -> loss
I0526 19:10:02.337220 14297 layer_factory.hpp:77] Creating layer loss
I0526 19:10:02.337858 14297 net.cpp:150] Setting up loss
I0526 19:10:02.337874 14297 net.cpp:157] Top shape: (1)
I0526 19:10:02.337883 14297 net.cpp:160]     with loss weight 1
I0526 19:10:02.337927 14297 net.cpp:165] Memory required for data: 31575604
I0526 19:10:02.337937 14297 net.cpp:226] loss needs backward computation.
I0526 19:10:02.337949 14297 net.cpp:226] drop3 needs backward computation.
I0526 19:10:02.337960 14297 net.cpp:226] ip3 needs backward computation.
I0526 19:10:02.337970 14297 net.cpp:226] drop2 needs backward computation.
I0526 19:10:02.337978 14297 net.cpp:226] relu6 needs backward computation.
I0526 19:10:02.337990 14297 net.cpp:226] ip2 needs backward computation.
I0526 19:10:02.337999 14297 net.cpp:226] drop1 needs backward computation.
I0526 19:10:02.338009 14297 net.cpp:226] relu5 needs backward computation.
I0526 19:10:02.338018 14297 net.cpp:226] ip1 needs backward computation.
I0526 19:10:02.338028 14297 net.cpp:226] pool4 needs backward computation.
I0526 19:10:02.338039 14297 net.cpp:226] relu4 needs backward computation.
I0526 19:10:02.338049 14297 net.cpp:226] conv4 needs backward computation.
I0526 19:10:02.338057 14297 net.cpp:226] pool3 needs backward computation.
I0526 19:10:02.338068 14297 net.cpp:226] relu3 needs backward computation.
I0526 19:10:02.338078 14297 net.cpp:226] conv3 needs backward computation.
I0526 19:10:02.338098 14297 net.cpp:226] pool2 needs backward computation.
I0526 19:10:02.338109 14297 net.cpp:226] relu2 needs backward computation.
I0526 19:10:02.338119 14297 net.cpp:226] conv2 needs backward computation.
I0526 19:10:02.338129 14297 net.cpp:226] pool1 needs backward computation.
I0526 19:10:02.338140 14297 net.cpp:226] relu1 needs backward computation.
I0526 19:10:02.338150 14297 net.cpp:226] conv1 needs backward computation.
I0526 19:10:02.338160 14297 net.cpp:228] data_hdf5 does not need backward computation.
I0526 19:10:02.338171 14297 net.cpp:270] This network produces output loss
I0526 19:10:02.338193 14297 net.cpp:283] Network initialization done.
I0526 19:10:02.340046 14297 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271.prototxt
I0526 19:10:02.340124 14297 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 19:10:02.340479 14297 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 19:10:02.340669 14297 layer_factory.hpp:77] Creating layer data_hdf5
I0526 19:10:02.340685 14297 net.cpp:106] Creating Layer data_hdf5
I0526 19:10:02.340698 14297 net.cpp:411] data_hdf5 -> data
I0526 19:10:02.340715 14297 net.cpp:411] data_hdf5 -> label
I0526 19:10:02.340730 14297 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 19:10:02.342294 14297 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 19:10:23.797137 14297 net.cpp:150] Setting up data_hdf5
I0526 19:10:23.797304 14297 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 19:10:23.797319 14297 net.cpp:157] Top shape: 20 (20)
I0526 19:10:23.797330 14297 net.cpp:165] Memory required for data: 508080
I0526 19:10:23.797343 14297 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 19:10:23.797374 14297 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 19:10:23.797384 14297 net.cpp:454] label_data_hdf5_1_split <- label
I0526 19:10:23.797399 14297 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 19:10:23.797420 14297 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 19:10:23.797494 14297 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 19:10:23.797508 14297 net.cpp:157] Top shape: 20 (20)
I0526 19:10:23.797519 14297 net.cpp:157] Top shape: 20 (20)
I0526 19:10:23.797529 14297 net.cpp:165] Memory required for data: 508240
I0526 19:10:23.797539 14297 layer_factory.hpp:77] Creating layer conv1
I0526 19:10:23.797561 14297 net.cpp:106] Creating Layer conv1
I0526 19:10:23.797572 14297 net.cpp:454] conv1 <- data
I0526 19:10:23.797586 14297 net.cpp:411] conv1 -> conv1
I0526 19:10:23.799510 14297 net.cpp:150] Setting up conv1
I0526 19:10:23.799535 14297 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:10:23.799546 14297 net.cpp:165] Memory required for data: 6037840
I0526 19:10:23.799567 14297 layer_factory.hpp:77] Creating layer relu1
I0526 19:10:23.799582 14297 net.cpp:106] Creating Layer relu1
I0526 19:10:23.799592 14297 net.cpp:454] relu1 <- conv1
I0526 19:10:23.799604 14297 net.cpp:397] relu1 -> conv1 (in-place)
I0526 19:10:23.800108 14297 net.cpp:150] Setting up relu1
I0526 19:10:23.800124 14297 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 19:10:23.800134 14297 net.cpp:165] Memory required for data: 11567440
I0526 19:10:23.800145 14297 layer_factory.hpp:77] Creating layer pool1
I0526 19:10:23.800161 14297 net.cpp:106] Creating Layer pool1
I0526 19:10:23.800171 14297 net.cpp:454] pool1 <- conv1
I0526 19:10:23.800184 14297 net.cpp:411] pool1 -> pool1
I0526 19:10:23.800259 14297 net.cpp:150] Setting up pool1
I0526 19:10:23.800273 14297 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 19:10:23.800282 14297 net.cpp:165] Memory required for data: 14332240
I0526 19:10:23.800293 14297 layer_factory.hpp:77] Creating layer conv2
I0526 19:10:23.800310 14297 net.cpp:106] Creating Layer conv2
I0526 19:10:23.800321 14297 net.cpp:454] conv2 <- pool1
I0526 19:10:23.800336 14297 net.cpp:411] conv2 -> conv2
I0526 19:10:23.802242 14297 net.cpp:150] Setting up conv2
I0526 19:10:23.802258 14297 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:10:23.802270 14297 net.cpp:165] Memory required for data: 18306640
I0526 19:10:23.802289 14297 layer_factory.hpp:77] Creating layer relu2
I0526 19:10:23.802302 14297 net.cpp:106] Creating Layer relu2
I0526 19:10:23.802311 14297 net.cpp:454] relu2 <- conv2
I0526 19:10:23.802325 14297 net.cpp:397] relu2 -> conv2 (in-place)
I0526 19:10:23.802659 14297 net.cpp:150] Setting up relu2
I0526 19:10:23.802672 14297 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 19:10:23.802682 14297 net.cpp:165] Memory required for data: 22281040
I0526 19:10:23.802692 14297 layer_factory.hpp:77] Creating layer pool2
I0526 19:10:23.802706 14297 net.cpp:106] Creating Layer pool2
I0526 19:10:23.802716 14297 net.cpp:454] pool2 <- conv2
I0526 19:10:23.802727 14297 net.cpp:411] pool2 -> pool2
I0526 19:10:23.802799 14297 net.cpp:150] Setting up pool2
I0526 19:10:23.802814 14297 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 19:10:23.802822 14297 net.cpp:165] Memory required for data: 24268240
I0526 19:10:23.802832 14297 layer_factory.hpp:77] Creating layer conv3
I0526 19:10:23.802850 14297 net.cpp:106] Creating Layer conv3
I0526 19:10:23.802860 14297 net.cpp:454] conv3 <- pool2
I0526 19:10:23.802875 14297 net.cpp:411] conv3 -> conv3
I0526 19:10:23.804844 14297 net.cpp:150] Setting up conv3
I0526 19:10:23.804867 14297 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:10:23.804879 14297 net.cpp:165] Memory required for data: 26436560
I0526 19:10:23.804898 14297 layer_factory.hpp:77] Creating layer relu3
I0526 19:10:23.804924 14297 net.cpp:106] Creating Layer relu3
I0526 19:10:23.804934 14297 net.cpp:454] relu3 <- conv3
I0526 19:10:23.804949 14297 net.cpp:397] relu3 -> conv3 (in-place)
I0526 19:10:23.805423 14297 net.cpp:150] Setting up relu3
I0526 19:10:23.805438 14297 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 19:10:23.805449 14297 net.cpp:165] Memory required for data: 28604880
I0526 19:10:23.805459 14297 layer_factory.hpp:77] Creating layer pool3
I0526 19:10:23.805472 14297 net.cpp:106] Creating Layer pool3
I0526 19:10:23.805482 14297 net.cpp:454] pool3 <- conv3
I0526 19:10:23.805495 14297 net.cpp:411] pool3 -> pool3
I0526 19:10:23.805567 14297 net.cpp:150] Setting up pool3
I0526 19:10:23.805580 14297 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 19:10:23.805590 14297 net.cpp:165] Memory required for data: 29689040
I0526 19:10:23.805598 14297 layer_factory.hpp:77] Creating layer conv4
I0526 19:10:23.805613 14297 net.cpp:106] Creating Layer conv4
I0526 19:10:23.805624 14297 net.cpp:454] conv4 <- pool3
I0526 19:10:23.805639 14297 net.cpp:411] conv4 -> conv4
I0526 19:10:23.807687 14297 net.cpp:150] Setting up conv4
I0526 19:10:23.807709 14297 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:10:23.807721 14297 net.cpp:165] Memory required for data: 30414800
I0526 19:10:23.807737 14297 layer_factory.hpp:77] Creating layer relu4
I0526 19:10:23.807750 14297 net.cpp:106] Creating Layer relu4
I0526 19:10:23.807760 14297 net.cpp:454] relu4 <- conv4
I0526 19:10:23.807775 14297 net.cpp:397] relu4 -> conv4 (in-place)
I0526 19:10:23.808251 14297 net.cpp:150] Setting up relu4
I0526 19:10:23.808267 14297 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 19:10:23.808277 14297 net.cpp:165] Memory required for data: 31140560
I0526 19:10:23.808289 14297 layer_factory.hpp:77] Creating layer pool4
I0526 19:10:23.808301 14297 net.cpp:106] Creating Layer pool4
I0526 19:10:23.808311 14297 net.cpp:454] pool4 <- conv4
I0526 19:10:23.808326 14297 net.cpp:411] pool4 -> pool4
I0526 19:10:23.808398 14297 net.cpp:150] Setting up pool4
I0526 19:10:23.808411 14297 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 19:10:23.808421 14297 net.cpp:165] Memory required for data: 31503440
I0526 19:10:23.808429 14297 layer_factory.hpp:77] Creating layer ip1
I0526 19:10:23.808444 14297 net.cpp:106] Creating Layer ip1
I0526 19:10:23.808455 14297 net.cpp:454] ip1 <- pool4
I0526 19:10:23.808470 14297 net.cpp:411] ip1 -> ip1
I0526 19:10:23.823801 14297 net.cpp:150] Setting up ip1
I0526 19:10:23.823830 14297 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:10:23.823842 14297 net.cpp:165] Memory required for data: 31519120
I0526 19:10:23.823863 14297 layer_factory.hpp:77] Creating layer relu5
I0526 19:10:23.823879 14297 net.cpp:106] Creating Layer relu5
I0526 19:10:23.823889 14297 net.cpp:454] relu5 <- ip1
I0526 19:10:23.823904 14297 net.cpp:397] relu5 -> ip1 (in-place)
I0526 19:10:23.824252 14297 net.cpp:150] Setting up relu5
I0526 19:10:23.824266 14297 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:10:23.824276 14297 net.cpp:165] Memory required for data: 31534800
I0526 19:10:23.824286 14297 layer_factory.hpp:77] Creating layer drop1
I0526 19:10:23.824306 14297 net.cpp:106] Creating Layer drop1
I0526 19:10:23.824316 14297 net.cpp:454] drop1 <- ip1
I0526 19:10:23.824328 14297 net.cpp:397] drop1 -> ip1 (in-place)
I0526 19:10:23.824374 14297 net.cpp:150] Setting up drop1
I0526 19:10:23.824388 14297 net.cpp:157] Top shape: 20 196 (3920)
I0526 19:10:23.824398 14297 net.cpp:165] Memory required for data: 31550480
I0526 19:10:23.824406 14297 layer_factory.hpp:77] Creating layer ip2
I0526 19:10:23.824420 14297 net.cpp:106] Creating Layer ip2
I0526 19:10:23.824430 14297 net.cpp:454] ip2 <- ip1
I0526 19:10:23.824443 14297 net.cpp:411] ip2 -> ip2
I0526 19:10:23.824924 14297 net.cpp:150] Setting up ip2
I0526 19:10:23.824939 14297 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:10:23.824949 14297 net.cpp:165] Memory required for data: 31558320
I0526 19:10:23.824965 14297 layer_factory.hpp:77] Creating layer relu6
I0526 19:10:23.824990 14297 net.cpp:106] Creating Layer relu6
I0526 19:10:23.825000 14297 net.cpp:454] relu6 <- ip2
I0526 19:10:23.825012 14297 net.cpp:397] relu6 -> ip2 (in-place)
I0526 19:10:23.825541 14297 net.cpp:150] Setting up relu6
I0526 19:10:23.825556 14297 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:10:23.825567 14297 net.cpp:165] Memory required for data: 31566160
I0526 19:10:23.825577 14297 layer_factory.hpp:77] Creating layer drop2
I0526 19:10:23.825590 14297 net.cpp:106] Creating Layer drop2
I0526 19:10:23.825601 14297 net.cpp:454] drop2 <- ip2
I0526 19:10:23.825614 14297 net.cpp:397] drop2 -> ip2 (in-place)
I0526 19:10:23.825659 14297 net.cpp:150] Setting up drop2
I0526 19:10:23.825671 14297 net.cpp:157] Top shape: 20 98 (1960)
I0526 19:10:23.825681 14297 net.cpp:165] Memory required for data: 31574000
I0526 19:10:23.825691 14297 layer_factory.hpp:77] Creating layer ip3
I0526 19:10:23.825706 14297 net.cpp:106] Creating Layer ip3
I0526 19:10:23.825716 14297 net.cpp:454] ip3 <- ip2
I0526 19:10:23.825731 14297 net.cpp:411] ip3 -> ip3
I0526 19:10:23.825951 14297 net.cpp:150] Setting up ip3
I0526 19:10:23.825965 14297 net.cpp:157] Top shape: 20 11 (220)
I0526 19:10:23.825974 14297 net.cpp:165] Memory required for data: 31574880
I0526 19:10:23.825990 14297 layer_factory.hpp:77] Creating layer drop3
I0526 19:10:23.826004 14297 net.cpp:106] Creating Layer drop3
I0526 19:10:23.826014 14297 net.cpp:454] drop3 <- ip3
I0526 19:10:23.826026 14297 net.cpp:397] drop3 -> ip3 (in-place)
I0526 19:10:23.826067 14297 net.cpp:150] Setting up drop3
I0526 19:10:23.826081 14297 net.cpp:157] Top shape: 20 11 (220)
I0526 19:10:23.826089 14297 net.cpp:165] Memory required for data: 31575760
I0526 19:10:23.826099 14297 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 19:10:23.826112 14297 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 19:10:23.826122 14297 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 19:10:23.826135 14297 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 19:10:23.826150 14297 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 19:10:23.826225 14297 net.cpp:150] Setting up ip3_drop3_0_split
I0526 19:10:23.826237 14297 net.cpp:157] Top shape: 20 11 (220)
I0526 19:10:23.826249 14297 net.cpp:157] Top shape: 20 11 (220)
I0526 19:10:23.826259 14297 net.cpp:165] Memory required for data: 31577520
I0526 19:10:23.826269 14297 layer_factory.hpp:77] Creating layer accuracy
I0526 19:10:23.826292 14297 net.cpp:106] Creating Layer accuracy
I0526 19:10:23.826302 14297 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 19:10:23.826311 14297 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 19:10:23.826325 14297 net.cpp:411] accuracy -> accuracy
I0526 19:10:23.826350 14297 net.cpp:150] Setting up accuracy
I0526 19:10:23.826364 14297 net.cpp:157] Top shape: (1)
I0526 19:10:23.826373 14297 net.cpp:165] Memory required for data: 31577524
I0526 19:10:23.826383 14297 layer_factory.hpp:77] Creating layer loss
I0526 19:10:23.826397 14297 net.cpp:106] Creating Layer loss
I0526 19:10:23.826407 14297 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 19:10:23.826418 14297 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 19:10:23.826431 14297 net.cpp:411] loss -> loss
I0526 19:10:23.826449 14297 layer_factory.hpp:77] Creating layer loss
I0526 19:10:23.826931 14297 net.cpp:150] Setting up loss
I0526 19:10:23.826946 14297 net.cpp:157] Top shape: (1)
I0526 19:10:23.826956 14297 net.cpp:160]     with loss weight 1
I0526 19:10:23.826973 14297 net.cpp:165] Memory required for data: 31577528
I0526 19:10:23.826983 14297 net.cpp:226] loss needs backward computation.
I0526 19:10:23.826994 14297 net.cpp:228] accuracy does not need backward computation.
I0526 19:10:23.827005 14297 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 19:10:23.827015 14297 net.cpp:226] drop3 needs backward computation.
I0526 19:10:23.827026 14297 net.cpp:226] ip3 needs backward computation.
I0526 19:10:23.827038 14297 net.cpp:226] drop2 needs backward computation.
I0526 19:10:23.827047 14297 net.cpp:226] relu6 needs backward computation.
I0526 19:10:23.827065 14297 net.cpp:226] ip2 needs backward computation.
I0526 19:10:23.827075 14297 net.cpp:226] drop1 needs backward computation.
I0526 19:10:23.827085 14297 net.cpp:226] relu5 needs backward computation.
I0526 19:10:23.827095 14297 net.cpp:226] ip1 needs backward computation.
I0526 19:10:23.827105 14297 net.cpp:226] pool4 needs backward computation.
I0526 19:10:23.827114 14297 net.cpp:226] relu4 needs backward computation.
I0526 19:10:23.827124 14297 net.cpp:226] conv4 needs backward computation.
I0526 19:10:23.827133 14297 net.cpp:226] pool3 needs backward computation.
I0526 19:10:23.827143 14297 net.cpp:226] relu3 needs backward computation.
I0526 19:10:23.827154 14297 net.cpp:226] conv3 needs backward computation.
I0526 19:10:23.827165 14297 net.cpp:226] pool2 needs backward computation.
I0526 19:10:23.827175 14297 net.cpp:226] relu2 needs backward computation.
I0526 19:10:23.827185 14297 net.cpp:226] conv2 needs backward computation.
I0526 19:10:23.827195 14297 net.cpp:226] pool1 needs backward computation.
I0526 19:10:23.827206 14297 net.cpp:226] relu1 needs backward computation.
I0526 19:10:23.827216 14297 net.cpp:226] conv1 needs backward computation.
I0526 19:10:23.827227 14297 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 19:10:23.827239 14297 net.cpp:228] data_hdf5 does not need backward computation.
I0526 19:10:23.827250 14297 net.cpp:270] This network produces output accuracy
I0526 19:10:23.827262 14297 net.cpp:270] This network produces output loss
I0526 19:10:23.827289 14297 net.cpp:283] Network initialization done.
I0526 19:10:23.827421 14297 solver.cpp:60] Solver scaffolding done.
I0526 19:10:23.828564 14297 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_285000.solverstate
I0526 19:10:24.055382 14297 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 19:10:24.060876 14297 caffe.cpp:212] Starting Optimization
I0526 19:10:24.060914 14297 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 19:10:24.060926 14297 solver.cpp:289] Learning Rate Policy: fixed
I0526 19:10:24.062285 14297 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 19:11:17.068286 14297 solver.cpp:409]     Test net output #0: accuracy = 0.898583
I0526 19:11:17.068456 14297 solver.cpp:409]     Test net output #1: loss = 0.316297 (* 1 = 0.316297 loss)
I0526 19:11:17.087455 14297 solver.cpp:237] Iteration 285000, loss = 1.02196
I0526 19:11:17.087491 14297 solver.cpp:253]     Train net output #0: loss = 1.02196 (* 1 = 1.02196 loss)
I0526 19:11:17.087509 14297 sgd_solver.cpp:106] Iteration 285000, lr = 0.004
I0526 19:11:29.230348 14297 solver.cpp:237] Iteration 285750, loss = 1.23538
I0526 19:11:29.230397 14297 solver.cpp:253]     Train net output #0: loss = 1.23538 (* 1 = 1.23538 loss)
I0526 19:11:29.230411 14297 sgd_solver.cpp:106] Iteration 285750, lr = 0.004
I0526 19:11:41.355175 14297 solver.cpp:237] Iteration 286500, loss = 1.1382
I0526 19:11:41.355211 14297 solver.cpp:253]     Train net output #0: loss = 1.1382 (* 1 = 1.1382 loss)
I0526 19:11:41.355223 14297 sgd_solver.cpp:106] Iteration 286500, lr = 0.004
I0526 19:11:53.527107 14297 solver.cpp:237] Iteration 287250, loss = 0.941658
I0526 19:11:53.527266 14297 solver.cpp:253]     Train net output #0: loss = 0.941657 (* 1 = 0.941657 loss)
I0526 19:11:53.527281 14297 sgd_solver.cpp:106] Iteration 287250, lr = 0.004
I0526 19:12:05.671533 14297 solver.cpp:237] Iteration 288000, loss = 1.07142
I0526 19:12:05.671569 14297 solver.cpp:253]     Train net output #0: loss = 1.07142 (* 1 = 1.07142 loss)
I0526 19:12:05.671583 14297 sgd_solver.cpp:106] Iteration 288000, lr = 0.004
I0526 19:12:17.814510 14297 solver.cpp:237] Iteration 288750, loss = 1.48084
I0526 19:12:17.814556 14297 solver.cpp:253]     Train net output #0: loss = 1.48084 (* 1 = 1.48084 loss)
I0526 19:12:17.814574 14297 sgd_solver.cpp:106] Iteration 288750, lr = 0.004
I0526 19:12:29.959588 14297 solver.cpp:237] Iteration 289500, loss = 1.1156
I0526 19:12:29.959723 14297 solver.cpp:253]     Train net output #0: loss = 1.1156 (* 1 = 1.1156 loss)
I0526 19:12:29.959738 14297 sgd_solver.cpp:106] Iteration 289500, lr = 0.004
I0526 19:13:04.317854 14297 solver.cpp:237] Iteration 290250, loss = 0.927523
I0526 19:13:04.318014 14297 solver.cpp:253]     Train net output #0: loss = 0.927522 (* 1 = 0.927522 loss)
I0526 19:13:04.318029 14297 sgd_solver.cpp:106] Iteration 290250, lr = 0.004
I0526 19:13:16.500597 14297 solver.cpp:237] Iteration 291000, loss = 1.10206
I0526 19:13:16.500633 14297 solver.cpp:253]     Train net output #0: loss = 1.10206 (* 1 = 1.10206 loss)
I0526 19:13:16.500646 14297 sgd_solver.cpp:106] Iteration 291000, lr = 0.004
I0526 19:13:28.648241 14297 solver.cpp:237] Iteration 291750, loss = 1.64613
I0526 19:13:28.648284 14297 solver.cpp:253]     Train net output #0: loss = 1.64613 (* 1 = 1.64613 loss)
I0526 19:13:28.648303 14297 sgd_solver.cpp:106] Iteration 291750, lr = 0.004
I0526 19:13:40.779868 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_292500.caffemodel
I0526 19:13:40.833217 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_292500.solverstate
I0526 19:13:40.865061 14297 solver.cpp:237] Iteration 292500, loss = 0.874208
I0526 19:13:40.865108 14297 solver.cpp:253]     Train net output #0: loss = 0.874207 (* 1 = 0.874207 loss)
I0526 19:13:40.865123 14297 sgd_solver.cpp:106] Iteration 292500, lr = 0.004
I0526 19:13:53.087481 14297 solver.cpp:237] Iteration 293250, loss = 1.237
I0526 19:13:53.087517 14297 solver.cpp:253]     Train net output #0: loss = 1.237 (* 1 = 1.237 loss)
I0526 19:13:53.087532 14297 sgd_solver.cpp:106] Iteration 293250, lr = 0.004
I0526 19:14:05.272073 14297 solver.cpp:237] Iteration 294000, loss = 1.1021
I0526 19:14:05.272126 14297 solver.cpp:253]     Train net output #0: loss = 1.1021 (* 1 = 1.1021 loss)
I0526 19:14:05.272140 14297 sgd_solver.cpp:106] Iteration 294000, lr = 0.004
I0526 19:14:17.410744 14297 solver.cpp:237] Iteration 294750, loss = 1.31864
I0526 19:14:17.410887 14297 solver.cpp:253]     Train net output #0: loss = 1.31864 (* 1 = 1.31864 loss)
I0526 19:14:17.410900 14297 sgd_solver.cpp:106] Iteration 294750, lr = 0.004
I0526 19:14:51.763674 14297 solver.cpp:237] Iteration 295500, loss = 1.12726
I0526 19:14:51.763849 14297 solver.cpp:253]     Train net output #0: loss = 1.12726 (* 1 = 1.12726 loss)
I0526 19:14:51.763864 14297 sgd_solver.cpp:106] Iteration 295500, lr = 0.004
I0526 19:15:03.942000 14297 solver.cpp:237] Iteration 296250, loss = 0.955876
I0526 19:15:03.942039 14297 solver.cpp:253]     Train net output #0: loss = 0.955877 (* 1 = 0.955877 loss)
I0526 19:15:03.942051 14297 sgd_solver.cpp:106] Iteration 296250, lr = 0.004
I0526 19:15:16.107657 14297 solver.cpp:237] Iteration 297000, loss = 0.876498
I0526 19:15:16.107702 14297 solver.cpp:253]     Train net output #0: loss = 0.876498 (* 1 = 0.876498 loss)
I0526 19:15:16.107715 14297 sgd_solver.cpp:106] Iteration 297000, lr = 0.004
I0526 19:15:28.283531 14297 solver.cpp:237] Iteration 297750, loss = 0.930214
I0526 19:15:28.283668 14297 solver.cpp:253]     Train net output #0: loss = 0.930214 (* 1 = 0.930214 loss)
I0526 19:15:28.283682 14297 sgd_solver.cpp:106] Iteration 297750, lr = 0.004
I0526 19:15:40.439678 14297 solver.cpp:237] Iteration 298500, loss = 1.65207
I0526 19:15:40.439724 14297 solver.cpp:253]     Train net output #0: loss = 1.65207 (* 1 = 1.65207 loss)
I0526 19:15:40.439740 14297 sgd_solver.cpp:106] Iteration 298500, lr = 0.004
I0526 19:15:52.597846 14297 solver.cpp:237] Iteration 299250, loss = 1.55127
I0526 19:15:52.597882 14297 solver.cpp:253]     Train net output #0: loss = 1.55127 (* 1 = 1.55127 loss)
I0526 19:15:52.597899 14297 sgd_solver.cpp:106] Iteration 299250, lr = 0.004
I0526 19:16:04.748183 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_300000.caffemodel
I0526 19:16:04.798661 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_300000.solverstate
I0526 19:16:04.825212 14297 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 19:16:56.836661 14297 solver.cpp:409]     Test net output #0: accuracy = 0.898396
I0526 19:16:56.836818 14297 solver.cpp:409]     Test net output #1: loss = 0.316814 (* 1 = 0.316814 loss)
I0526 19:17:19.078687 14297 solver.cpp:237] Iteration 300000, loss = 1.20885
I0526 19:17:19.078742 14297 solver.cpp:253]     Train net output #0: loss = 1.20885 (* 1 = 1.20885 loss)
I0526 19:17:19.078758 14297 sgd_solver.cpp:106] Iteration 300000, lr = 0.004
I0526 19:17:31.168223 14297 solver.cpp:237] Iteration 300750, loss = 1.62778
I0526 19:17:31.168370 14297 solver.cpp:253]     Train net output #0: loss = 1.62778 (* 1 = 1.62778 loss)
I0526 19:17:31.168383 14297 sgd_solver.cpp:106] Iteration 300750, lr = 0.004
I0526 19:17:43.259892 14297 solver.cpp:237] Iteration 301500, loss = 1.03095
I0526 19:17:43.259943 14297 solver.cpp:253]     Train net output #0: loss = 1.03095 (* 1 = 1.03095 loss)
I0526 19:17:43.259955 14297 sgd_solver.cpp:106] Iteration 301500, lr = 0.004
I0526 19:17:55.355944 14297 solver.cpp:237] Iteration 302250, loss = 0.933671
I0526 19:17:55.355983 14297 solver.cpp:253]     Train net output #0: loss = 0.933671 (* 1 = 0.933671 loss)
I0526 19:17:55.355995 14297 sgd_solver.cpp:106] Iteration 302250, lr = 0.004
I0526 19:18:07.463529 14297 solver.cpp:237] Iteration 303000, loss = 1.29293
I0526 19:18:07.463678 14297 solver.cpp:253]     Train net output #0: loss = 1.29293 (* 1 = 1.29293 loss)
I0526 19:18:07.463692 14297 sgd_solver.cpp:106] Iteration 303000, lr = 0.004
I0526 19:18:19.592835 14297 solver.cpp:237] Iteration 303750, loss = 1.29665
I0526 19:18:19.592871 14297 solver.cpp:253]     Train net output #0: loss = 1.29665 (* 1 = 1.29665 loss)
I0526 19:18:19.592885 14297 sgd_solver.cpp:106] Iteration 303750, lr = 0.004
I0526 19:18:31.759961 14297 solver.cpp:237] Iteration 304500, loss = 1.11384
I0526 19:18:31.760006 14297 solver.cpp:253]     Train net output #0: loss = 1.11384 (* 1 = 1.11384 loss)
I0526 19:18:31.760022 14297 sgd_solver.cpp:106] Iteration 304500, lr = 0.004
I0526 19:19:06.126168 14297 solver.cpp:237] Iteration 305250, loss = 1.21919
I0526 19:19:06.126343 14297 solver.cpp:253]     Train net output #0: loss = 1.21919 (* 1 = 1.21919 loss)
I0526 19:19:06.126358 14297 sgd_solver.cpp:106] Iteration 305250, lr = 0.004
I0526 19:19:18.305698 14297 solver.cpp:237] Iteration 306000, loss = 1.48655
I0526 19:19:18.305734 14297 solver.cpp:253]     Train net output #0: loss = 1.48655 (* 1 = 1.48655 loss)
I0526 19:19:18.305750 14297 sgd_solver.cpp:106] Iteration 306000, lr = 0.004
I0526 19:19:30.475911 14297 solver.cpp:237] Iteration 306750, loss = 1.35985
I0526 19:19:30.475953 14297 solver.cpp:253]     Train net output #0: loss = 1.35985 (* 1 = 1.35985 loss)
I0526 19:19:30.475967 14297 sgd_solver.cpp:106] Iteration 306750, lr = 0.004
I0526 19:19:42.588218 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_307500.caffemodel
I0526 19:19:42.639613 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_307500.solverstate
I0526 19:19:42.672267 14297 solver.cpp:237] Iteration 307500, loss = 0.766693
I0526 19:19:42.672319 14297 solver.cpp:253]     Train net output #0: loss = 0.766694 (* 1 = 0.766694 loss)
I0526 19:19:42.672335 14297 sgd_solver.cpp:106] Iteration 307500, lr = 0.004
I0526 19:19:54.787261 14297 solver.cpp:237] Iteration 308250, loss = 0.895569
I0526 19:19:54.787309 14297 solver.cpp:253]     Train net output #0: loss = 0.89557 (* 1 = 0.89557 loss)
I0526 19:19:54.787323 14297 sgd_solver.cpp:106] Iteration 308250, lr = 0.004
I0526 19:20:06.914110 14297 solver.cpp:237] Iteration 309000, loss = 1.00517
I0526 19:20:06.914147 14297 solver.cpp:253]     Train net output #0: loss = 1.00517 (* 1 = 1.00517 loss)
I0526 19:20:06.914160 14297 sgd_solver.cpp:106] Iteration 309000, lr = 0.004
I0526 19:20:19.039870 14297 solver.cpp:237] Iteration 309750, loss = 1.31162
I0526 19:20:19.040040 14297 solver.cpp:253]     Train net output #0: loss = 1.31162 (* 1 = 1.31162 loss)
I0526 19:20:19.040055 14297 sgd_solver.cpp:106] Iteration 309750, lr = 0.004
I0526 19:20:53.320102 14297 solver.cpp:237] Iteration 310500, loss = 1.18132
I0526 19:20:53.320268 14297 solver.cpp:253]     Train net output #0: loss = 1.18132 (* 1 = 1.18132 loss)
I0526 19:20:53.320284 14297 sgd_solver.cpp:106] Iteration 310500, lr = 0.004
I0526 19:21:05.437119 14297 solver.cpp:237] Iteration 311250, loss = 0.888378
I0526 19:21:05.437163 14297 solver.cpp:253]     Train net output #0: loss = 0.888379 (* 1 = 0.888379 loss)
I0526 19:21:05.437180 14297 sgd_solver.cpp:106] Iteration 311250, lr = 0.004
I0526 19:21:17.549229 14297 solver.cpp:237] Iteration 312000, loss = 0.990279
I0526 19:21:17.549266 14297 solver.cpp:253]     Train net output #0: loss = 0.99028 (* 1 = 0.99028 loss)
I0526 19:21:17.549279 14297 sgd_solver.cpp:106] Iteration 312000, lr = 0.004
I0526 19:21:29.707531 14297 solver.cpp:237] Iteration 312750, loss = 1.1885
I0526 19:21:29.707684 14297 solver.cpp:253]     Train net output #0: loss = 1.1885 (* 1 = 1.1885 loss)
I0526 19:21:29.707700 14297 sgd_solver.cpp:106] Iteration 312750, lr = 0.004
I0526 19:21:41.850800 14297 solver.cpp:237] Iteration 313500, loss = 1.05003
I0526 19:21:41.850836 14297 solver.cpp:253]     Train net output #0: loss = 1.05003 (* 1 = 1.05003 loss)
I0526 19:21:41.850849 14297 sgd_solver.cpp:106] Iteration 313500, lr = 0.004
I0526 19:21:54.013967 14297 solver.cpp:237] Iteration 314250, loss = 0.663987
I0526 19:21:54.014015 14297 solver.cpp:253]     Train net output #0: loss = 0.663988 (* 1 = 0.663988 loss)
I0526 19:21:54.014029 14297 sgd_solver.cpp:106] Iteration 314250, lr = 0.004
I0526 19:22:06.184586 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_315000.caffemodel
I0526 19:22:06.236486 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_315000.solverstate
I0526 19:22:06.264523 14297 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 19:23:19.075706 14297 solver.cpp:409]     Test net output #0: accuracy = 0.899531
I0526 19:23:19.075875 14297 solver.cpp:409]     Test net output #1: loss = 0.338801 (* 1 = 0.338801 loss)
I0526 19:23:41.353857 14297 solver.cpp:237] Iteration 315000, loss = 1.25754
I0526 19:23:41.353910 14297 solver.cpp:253]     Train net output #0: loss = 1.25754 (* 1 = 1.25754 loss)
I0526 19:23:41.353925 14297 sgd_solver.cpp:106] Iteration 315000, lr = 0.004
I0526 19:23:53.499682 14297 solver.cpp:237] Iteration 315750, loss = 1.08845
I0526 19:23:53.499845 14297 solver.cpp:253]     Train net output #0: loss = 1.08845 (* 1 = 1.08845 loss)
I0526 19:23:53.499858 14297 sgd_solver.cpp:106] Iteration 315750, lr = 0.004
I0526 19:24:05.671982 14297 solver.cpp:237] Iteration 316500, loss = 0.933422
I0526 19:24:05.672019 14297 solver.cpp:253]     Train net output #0: loss = 0.933422 (* 1 = 0.933422 loss)
I0526 19:24:05.672031 14297 sgd_solver.cpp:106] Iteration 316500, lr = 0.004
I0526 19:24:17.847688 14297 solver.cpp:237] Iteration 317250, loss = 1.44567
I0526 19:24:17.847724 14297 solver.cpp:253]     Train net output #0: loss = 1.44567 (* 1 = 1.44567 loss)
I0526 19:24:17.847738 14297 sgd_solver.cpp:106] Iteration 317250, lr = 0.004
I0526 19:24:30.065865 14297 solver.cpp:237] Iteration 318000, loss = 1.2524
I0526 19:24:30.066020 14297 solver.cpp:253]     Train net output #0: loss = 1.2524 (* 1 = 1.2524 loss)
I0526 19:24:30.066035 14297 sgd_solver.cpp:106] Iteration 318000, lr = 0.004
I0526 19:24:42.270349 14297 solver.cpp:237] Iteration 318750, loss = 0.927218
I0526 19:24:42.270385 14297 solver.cpp:253]     Train net output #0: loss = 0.927218 (* 1 = 0.927218 loss)
I0526 19:24:42.270398 14297 sgd_solver.cpp:106] Iteration 318750, lr = 0.004
I0526 19:24:54.467093 14297 solver.cpp:237] Iteration 319500, loss = 1.13468
I0526 19:24:54.467142 14297 solver.cpp:253]     Train net output #0: loss = 1.13468 (* 1 = 1.13468 loss)
I0526 19:24:54.467156 14297 sgd_solver.cpp:106] Iteration 319500, lr = 0.004
I0526 19:25:28.875402 14297 solver.cpp:237] Iteration 320250, loss = 1.46574
I0526 19:25:28.875569 14297 solver.cpp:253]     Train net output #0: loss = 1.46574 (* 1 = 1.46574 loss)
I0526 19:25:28.875583 14297 sgd_solver.cpp:106] Iteration 320250, lr = 0.004
I0526 19:25:41.058394 14297 solver.cpp:237] Iteration 321000, loss = 1.03401
I0526 19:25:41.058441 14297 solver.cpp:253]     Train net output #0: loss = 1.03401 (* 1 = 1.03401 loss)
I0526 19:25:41.058454 14297 sgd_solver.cpp:106] Iteration 321000, lr = 0.004
I0526 19:25:53.208166 14297 solver.cpp:237] Iteration 321750, loss = 1.24188
I0526 19:25:53.208201 14297 solver.cpp:253]     Train net output #0: loss = 1.24188 (* 1 = 1.24188 loss)
I0526 19:25:53.208219 14297 sgd_solver.cpp:106] Iteration 321750, lr = 0.004
I0526 19:26:05.340904 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_322500.caffemodel
I0526 19:26:05.393120 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_322500.solverstate
I0526 19:26:05.426458 14297 solver.cpp:237] Iteration 322500, loss = 1.76524
I0526 19:26:05.426506 14297 solver.cpp:253]     Train net output #0: loss = 1.76525 (* 1 = 1.76525 loss)
I0526 19:26:05.426523 14297 sgd_solver.cpp:106] Iteration 322500, lr = 0.004
I0526 19:26:17.617599 14297 solver.cpp:237] Iteration 323250, loss = 1.49474
I0526 19:26:17.617635 14297 solver.cpp:253]     Train net output #0: loss = 1.49474 (* 1 = 1.49474 loss)
I0526 19:26:17.617648 14297 sgd_solver.cpp:106] Iteration 323250, lr = 0.004
I0526 19:26:29.827353 14297 solver.cpp:237] Iteration 324000, loss = 0.664188
I0526 19:26:29.827404 14297 solver.cpp:253]     Train net output #0: loss = 0.664189 (* 1 = 0.664189 loss)
I0526 19:26:29.827419 14297 sgd_solver.cpp:106] Iteration 324000, lr = 0.004
I0526 19:26:42.036873 14297 solver.cpp:237] Iteration 324750, loss = 1.08112
I0526 19:26:42.037027 14297 solver.cpp:253]     Train net output #0: loss = 1.08112 (* 1 = 1.08112 loss)
I0526 19:26:42.037042 14297 sgd_solver.cpp:106] Iteration 324750, lr = 0.004
I0526 19:27:16.466073 14297 solver.cpp:237] Iteration 325500, loss = 0.826441
I0526 19:27:16.466234 14297 solver.cpp:253]     Train net output #0: loss = 0.826441 (* 1 = 0.826441 loss)
I0526 19:27:16.466250 14297 sgd_solver.cpp:106] Iteration 325500, lr = 0.004
I0526 19:27:28.624805 14297 solver.cpp:237] Iteration 326250, loss = 1.25817
I0526 19:27:28.624841 14297 solver.cpp:253]     Train net output #0: loss = 1.25817 (* 1 = 1.25817 loss)
I0526 19:27:28.624855 14297 sgd_solver.cpp:106] Iteration 326250, lr = 0.004
I0526 19:27:40.823312 14297 solver.cpp:237] Iteration 327000, loss = 1.27429
I0526 19:27:40.823357 14297 solver.cpp:253]     Train net output #0: loss = 1.27429 (* 1 = 1.27429 loss)
I0526 19:27:40.823374 14297 sgd_solver.cpp:106] Iteration 327000, lr = 0.004
I0526 19:27:53.061461 14297 solver.cpp:237] Iteration 327750, loss = 1.24357
I0526 19:27:53.061601 14297 solver.cpp:253]     Train net output #0: loss = 1.24357 (* 1 = 1.24357 loss)
I0526 19:27:53.061616 14297 sgd_solver.cpp:106] Iteration 327750, lr = 0.004
I0526 19:28:05.305932 14297 solver.cpp:237] Iteration 328500, loss = 1.1737
I0526 19:28:05.305981 14297 solver.cpp:253]     Train net output #0: loss = 1.1737 (* 1 = 1.1737 loss)
I0526 19:28:05.305996 14297 sgd_solver.cpp:106] Iteration 328500, lr = 0.004
I0526 19:28:17.503882 14297 solver.cpp:237] Iteration 329250, loss = 1.2403
I0526 19:28:17.503919 14297 solver.cpp:253]     Train net output #0: loss = 1.2403 (* 1 = 1.2403 loss)
I0526 19:28:17.503937 14297 sgd_solver.cpp:106] Iteration 329250, lr = 0.004
I0526 19:28:29.681203 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_330000.caffemodel
I0526 19:28:29.730537 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_330000.solverstate
I0526 19:28:29.756026 14297 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 19:29:21.437695 14297 solver.cpp:409]     Test net output #0: accuracy = 0.901212
I0526 19:29:21.437855 14297 solver.cpp:409]     Test net output #1: loss = 0.31973 (* 1 = 0.31973 loss)
I0526 19:29:43.659157 14297 solver.cpp:237] Iteration 330000, loss = 0.837942
I0526 19:29:43.659209 14297 solver.cpp:253]     Train net output #0: loss = 0.837942 (* 1 = 0.837942 loss)
I0526 19:29:43.659224 14297 sgd_solver.cpp:106] Iteration 330000, lr = 0.004
I0526 19:29:55.778520 14297 solver.cpp:237] Iteration 330750, loss = 0.91257
I0526 19:29:55.778664 14297 solver.cpp:253]     Train net output #0: loss = 0.91257 (* 1 = 0.91257 loss)
I0526 19:29:55.778678 14297 sgd_solver.cpp:106] Iteration 330750, lr = 0.004
I0526 19:30:07.888974 14297 solver.cpp:237] Iteration 331500, loss = 0.94515
I0526 19:30:07.889011 14297 solver.cpp:253]     Train net output #0: loss = 0.94515 (* 1 = 0.94515 loss)
I0526 19:30:07.889027 14297 sgd_solver.cpp:106] Iteration 331500, lr = 0.004
I0526 19:30:20.007107 14297 solver.cpp:237] Iteration 332250, loss = 1.19275
I0526 19:30:20.007153 14297 solver.cpp:253]     Train net output #0: loss = 1.19275 (* 1 = 1.19275 loss)
I0526 19:30:20.007169 14297 sgd_solver.cpp:106] Iteration 332250, lr = 0.004
I0526 19:30:32.118757 14297 solver.cpp:237] Iteration 333000, loss = 0.889543
I0526 19:30:32.118897 14297 solver.cpp:253]     Train net output #0: loss = 0.889542 (* 1 = 0.889542 loss)
I0526 19:30:32.118912 14297 sgd_solver.cpp:106] Iteration 333000, lr = 0.004
I0526 19:30:44.241937 14297 solver.cpp:237] Iteration 333750, loss = 1.52813
I0526 19:30:44.241987 14297 solver.cpp:253]     Train net output #0: loss = 1.52813 (* 1 = 1.52813 loss)
I0526 19:30:44.242000 14297 sgd_solver.cpp:106] Iteration 333750, lr = 0.004
I0526 19:30:56.365970 14297 solver.cpp:237] Iteration 334500, loss = 1.29031
I0526 19:30:56.366006 14297 solver.cpp:253]     Train net output #0: loss = 1.29031 (* 1 = 1.29031 loss)
I0526 19:30:56.366019 14297 sgd_solver.cpp:106] Iteration 334500, lr = 0.004
I0526 19:31:30.721412 14297 solver.cpp:237] Iteration 335250, loss = 0.626285
I0526 19:31:30.721580 14297 solver.cpp:253]     Train net output #0: loss = 0.626285 (* 1 = 0.626285 loss)
I0526 19:31:30.721595 14297 sgd_solver.cpp:106] Iteration 335250, lr = 0.004
I0526 19:31:42.902669 14297 solver.cpp:237] Iteration 336000, loss = 0.861333
I0526 19:31:42.902705 14297 solver.cpp:253]     Train net output #0: loss = 0.861333 (* 1 = 0.861333 loss)
I0526 19:31:42.902719 14297 sgd_solver.cpp:106] Iteration 336000, lr = 0.004
I0526 19:31:54.987578 14297 solver.cpp:237] Iteration 336750, loss = 1.13802
I0526 19:31:54.987640 14297 solver.cpp:253]     Train net output #0: loss = 1.13802 (* 1 = 1.13802 loss)
I0526 19:31:54.987654 14297 sgd_solver.cpp:106] Iteration 336750, lr = 0.004
I0526 19:32:07.057380 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_337500.caffemodel
I0526 19:32:07.106868 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_337500.solverstate
I0526 19:32:07.137264 14297 solver.cpp:237] Iteration 337500, loss = 1.43503
I0526 19:32:07.137307 14297 solver.cpp:253]     Train net output #0: loss = 1.43503 (* 1 = 1.43503 loss)
I0526 19:32:07.137322 14297 sgd_solver.cpp:106] Iteration 337500, lr = 0.004
I0526 19:32:19.253172 14297 solver.cpp:237] Iteration 338250, loss = 1.05491
I0526 19:32:19.253219 14297 solver.cpp:253]     Train net output #0: loss = 1.05491 (* 1 = 1.05491 loss)
I0526 19:32:19.253233 14297 sgd_solver.cpp:106] Iteration 338250, lr = 0.004
I0526 19:32:31.405028 14297 solver.cpp:237] Iteration 339000, loss = 0.99805
I0526 19:32:31.405066 14297 solver.cpp:253]     Train net output #0: loss = 0.99805 (* 1 = 0.99805 loss)
I0526 19:32:31.405079 14297 sgd_solver.cpp:106] Iteration 339000, lr = 0.004
I0526 19:32:43.540894 14297 solver.cpp:237] Iteration 339750, loss = 0.864279
I0526 19:32:43.541054 14297 solver.cpp:253]     Train net output #0: loss = 0.864279 (* 1 = 0.864279 loss)
I0526 19:32:43.541071 14297 sgd_solver.cpp:106] Iteration 339750, lr = 0.004
I0526 19:33:17.931896 14297 solver.cpp:237] Iteration 340500, loss = 1.2211
I0526 19:33:17.932067 14297 solver.cpp:253]     Train net output #0: loss = 1.2211 (* 1 = 1.2211 loss)
I0526 19:33:17.932082 14297 sgd_solver.cpp:106] Iteration 340500, lr = 0.004
I0526 19:33:30.047437 14297 solver.cpp:237] Iteration 341250, loss = 1.46643
I0526 19:33:30.047483 14297 solver.cpp:253]     Train net output #0: loss = 1.46643 (* 1 = 1.46643 loss)
I0526 19:33:30.047497 14297 sgd_solver.cpp:106] Iteration 341250, lr = 0.004
I0526 19:33:42.197865 14297 solver.cpp:237] Iteration 342000, loss = 1.28569
I0526 19:33:42.197901 14297 solver.cpp:253]     Train net output #0: loss = 1.28569 (* 1 = 1.28569 loss)
I0526 19:33:42.197913 14297 sgd_solver.cpp:106] Iteration 342000, lr = 0.004
I0526 19:33:54.357189 14297 solver.cpp:237] Iteration 342750, loss = 1.33142
I0526 19:33:54.357345 14297 solver.cpp:253]     Train net output #0: loss = 1.33142 (* 1 = 1.33142 loss)
I0526 19:33:54.357359 14297 sgd_solver.cpp:106] Iteration 342750, lr = 0.004
I0526 19:34:06.514276 14297 solver.cpp:237] Iteration 343500, loss = 1.22278
I0526 19:34:06.514312 14297 solver.cpp:253]     Train net output #0: loss = 1.22278 (* 1 = 1.22278 loss)
I0526 19:34:06.514324 14297 sgd_solver.cpp:106] Iteration 343500, lr = 0.004
I0526 19:34:18.717013 14297 solver.cpp:237] Iteration 344250, loss = 1.12523
I0526 19:34:18.717063 14297 solver.cpp:253]     Train net output #0: loss = 1.12523 (* 1 = 1.12523 loss)
I0526 19:34:18.717077 14297 sgd_solver.cpp:106] Iteration 344250, lr = 0.004
I0526 19:34:30.882454 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_345000.caffemodel
I0526 19:34:30.931953 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_345000.solverstate
I0526 19:34:30.958065 14297 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 19:35:43.691768 14297 solver.cpp:409]     Test net output #0: accuracy = 0.898913
I0526 19:35:43.691936 14297 solver.cpp:409]     Test net output #1: loss = 0.331667 (* 1 = 0.331667 loss)
I0526 19:36:05.873982 14297 solver.cpp:237] Iteration 345000, loss = 1.34321
I0526 19:36:05.874035 14297 solver.cpp:253]     Train net output #0: loss = 1.34321 (* 1 = 1.34321 loss)
I0526 19:36:05.874053 14297 sgd_solver.cpp:106] Iteration 345000, lr = 0.004
I0526 19:36:18.044155 14297 solver.cpp:237] Iteration 345750, loss = 1.3031
I0526 19:36:18.044311 14297 solver.cpp:253]     Train net output #0: loss = 1.3031 (* 1 = 1.3031 loss)
I0526 19:36:18.044323 14297 sgd_solver.cpp:106] Iteration 345750, lr = 0.004
I0526 19:36:30.246395 14297 solver.cpp:237] Iteration 346500, loss = 0.891438
I0526 19:36:30.246443 14297 solver.cpp:253]     Train net output #0: loss = 0.891438 (* 1 = 0.891438 loss)
I0526 19:36:30.246456 14297 sgd_solver.cpp:106] Iteration 346500, lr = 0.004
I0526 19:36:42.399900 14297 solver.cpp:237] Iteration 347250, loss = 0.985947
I0526 19:36:42.399937 14297 solver.cpp:253]     Train net output #0: loss = 0.985946 (* 1 = 0.985946 loss)
I0526 19:36:42.399950 14297 sgd_solver.cpp:106] Iteration 347250, lr = 0.004
I0526 19:36:54.560751 14297 solver.cpp:237] Iteration 348000, loss = 0.718545
I0526 19:36:54.560914 14297 solver.cpp:253]     Train net output #0: loss = 0.718545 (* 1 = 0.718545 loss)
I0526 19:36:54.560930 14297 sgd_solver.cpp:106] Iteration 348000, lr = 0.004
I0526 19:37:06.795186 14297 solver.cpp:237] Iteration 348750, loss = 1.20862
I0526 19:37:06.795220 14297 solver.cpp:253]     Train net output #0: loss = 1.20862 (* 1 = 1.20862 loss)
I0526 19:37:06.795235 14297 sgd_solver.cpp:106] Iteration 348750, lr = 0.004
I0526 19:37:19.024852 14297 solver.cpp:237] Iteration 349500, loss = 1.13015
I0526 19:37:19.024899 14297 solver.cpp:253]     Train net output #0: loss = 1.13015 (* 1 = 1.13015 loss)
I0526 19:37:19.024914 14297 sgd_solver.cpp:106] Iteration 349500, lr = 0.004
I0526 19:37:53.484807 14297 solver.cpp:237] Iteration 350250, loss = 1.01924
I0526 19:37:53.484977 14297 solver.cpp:253]     Train net output #0: loss = 1.01924 (* 1 = 1.01924 loss)
I0526 19:37:53.484990 14297 sgd_solver.cpp:106] Iteration 350250, lr = 0.004
I0526 19:38:05.708369 14297 solver.cpp:237] Iteration 351000, loss = 1.37816
I0526 19:38:05.708415 14297 solver.cpp:253]     Train net output #0: loss = 1.37816 (* 1 = 1.37816 loss)
I0526 19:38:05.708428 14297 sgd_solver.cpp:106] Iteration 351000, lr = 0.004
I0526 19:38:17.929131 14297 solver.cpp:237] Iteration 351750, loss = 1.0001
I0526 19:38:17.929165 14297 solver.cpp:253]     Train net output #0: loss = 1.0001 (* 1 = 1.0001 loss)
I0526 19:38:17.929178 14297 sgd_solver.cpp:106] Iteration 351750, lr = 0.004
I0526 19:38:30.132553 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_352500.caffemodel
I0526 19:38:30.184201 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_352500.solverstate
I0526 19:38:30.216670 14297 solver.cpp:237] Iteration 352500, loss = 1.57512
I0526 19:38:30.216719 14297 solver.cpp:253]     Train net output #0: loss = 1.57512 (* 1 = 1.57512 loss)
I0526 19:38:30.216733 14297 sgd_solver.cpp:106] Iteration 352500, lr = 0.004
I0526 19:38:42.422091 14297 solver.cpp:237] Iteration 353250, loss = 1.05229
I0526 19:38:42.422127 14297 solver.cpp:253]     Train net output #0: loss = 1.05229 (* 1 = 1.05229 loss)
I0526 19:38:42.422140 14297 sgd_solver.cpp:106] Iteration 353250, lr = 0.004
I0526 19:38:54.591434 14297 solver.cpp:237] Iteration 354000, loss = 1.84858
I0526 19:38:54.591473 14297 solver.cpp:253]     Train net output #0: loss = 1.84858 (* 1 = 1.84858 loss)
I0526 19:38:54.591495 14297 sgd_solver.cpp:106] Iteration 354000, lr = 0.004
I0526 19:39:06.807579 14297 solver.cpp:237] Iteration 354750, loss = 0.941253
I0526 19:39:06.807740 14297 solver.cpp:253]     Train net output #0: loss = 0.941253 (* 1 = 0.941253 loss)
I0526 19:39:06.807754 14297 sgd_solver.cpp:106] Iteration 354750, lr = 0.004
I0526 19:39:41.260468 14297 solver.cpp:237] Iteration 355500, loss = 0.829185
I0526 19:39:41.260637 14297 solver.cpp:253]     Train net output #0: loss = 0.829186 (* 1 = 0.829186 loss)
I0526 19:39:41.260651 14297 sgd_solver.cpp:106] Iteration 355500, lr = 0.004
I0526 19:39:53.443892 14297 solver.cpp:237] Iteration 356250, loss = 1.02735
I0526 19:39:53.443940 14297 solver.cpp:253]     Train net output #0: loss = 1.02735 (* 1 = 1.02735 loss)
I0526 19:39:53.443956 14297 sgd_solver.cpp:106] Iteration 356250, lr = 0.004
I0526 19:40:05.610888 14297 solver.cpp:237] Iteration 357000, loss = 1.00707
I0526 19:40:05.610924 14297 solver.cpp:253]     Train net output #0: loss = 1.00707 (* 1 = 1.00707 loss)
I0526 19:40:05.610937 14297 sgd_solver.cpp:106] Iteration 357000, lr = 0.004
I0526 19:40:17.782099 14297 solver.cpp:237] Iteration 357750, loss = 0.864361
I0526 19:40:17.782263 14297 solver.cpp:253]     Train net output #0: loss = 0.864362 (* 1 = 0.864362 loss)
I0526 19:40:17.782277 14297 sgd_solver.cpp:106] Iteration 357750, lr = 0.004
I0526 19:40:29.976959 14297 solver.cpp:237] Iteration 358500, loss = 1.77317
I0526 19:40:29.976995 14297 solver.cpp:253]     Train net output #0: loss = 1.77317 (* 1 = 1.77317 loss)
I0526 19:40:29.977010 14297 sgd_solver.cpp:106] Iteration 358500, lr = 0.004
I0526 19:40:42.189223 14297 solver.cpp:237] Iteration 359250, loss = 1.33202
I0526 19:40:42.189270 14297 solver.cpp:253]     Train net output #0: loss = 1.33202 (* 1 = 1.33202 loss)
I0526 19:40:42.189282 14297 sgd_solver.cpp:106] Iteration 359250, lr = 0.004
I0526 19:40:54.353200 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_360000.caffemodel
I0526 19:40:54.405261 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_360000.solverstate
I0526 19:40:54.433601 14297 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 19:41:46.496933 14297 solver.cpp:409]     Test net output #0: accuracy = 0.898197
I0526 19:41:46.497109 14297 solver.cpp:409]     Test net output #1: loss = 0.323186 (* 1 = 0.323186 loss)
I0526 19:42:07.391031 14297 solver.cpp:237] Iteration 360000, loss = 0.923034
I0526 19:42:07.391088 14297 solver.cpp:253]     Train net output #0: loss = 0.923035 (* 1 = 0.923035 loss)
I0526 19:42:07.391101 14297 sgd_solver.cpp:106] Iteration 360000, lr = 0.004
I0526 19:42:19.479825 14297 solver.cpp:237] Iteration 360750, loss = 1.1266
I0526 19:42:19.479995 14297 solver.cpp:253]     Train net output #0: loss = 1.1266 (* 1 = 1.1266 loss)
I0526 19:42:19.480008 14297 sgd_solver.cpp:106] Iteration 360750, lr = 0.004
I0526 19:42:31.649847 14297 solver.cpp:237] Iteration 361500, loss = 1.00246
I0526 19:42:31.649883 14297 solver.cpp:253]     Train net output #0: loss = 1.00246 (* 1 = 1.00246 loss)
I0526 19:42:31.649896 14297 sgd_solver.cpp:106] Iteration 361500, lr = 0.004
I0526 19:42:43.846721 14297 solver.cpp:237] Iteration 362250, loss = 0.928893
I0526 19:42:43.846771 14297 solver.cpp:253]     Train net output #0: loss = 0.928894 (* 1 = 0.928894 loss)
I0526 19:42:43.846786 14297 sgd_solver.cpp:106] Iteration 362250, lr = 0.004
I0526 19:42:56.028002 14297 solver.cpp:237] Iteration 363000, loss = 0.84242
I0526 19:42:56.028168 14297 solver.cpp:253]     Train net output #0: loss = 0.842421 (* 1 = 0.842421 loss)
I0526 19:42:56.028183 14297 sgd_solver.cpp:106] Iteration 363000, lr = 0.004
I0526 19:43:08.203709 14297 solver.cpp:237] Iteration 363750, loss = 0.841502
I0526 19:43:08.203755 14297 solver.cpp:253]     Train net output #0: loss = 0.841503 (* 1 = 0.841503 loss)
I0526 19:43:08.203768 14297 sgd_solver.cpp:106] Iteration 363750, lr = 0.004
I0526 19:43:20.422065 14297 solver.cpp:237] Iteration 364500, loss = 1.33505
I0526 19:43:20.422101 14297 solver.cpp:253]     Train net output #0: loss = 1.33505 (* 1 = 1.33505 loss)
I0526 19:43:20.422117 14297 sgd_solver.cpp:106] Iteration 364500, lr = 0.004
I0526 19:43:53.469632 14297 solver.cpp:237] Iteration 365250, loss = 0.9215
I0526 19:43:53.469789 14297 solver.cpp:253]     Train net output #0: loss = 0.921501 (* 1 = 0.921501 loss)
I0526 19:43:53.469805 14297 sgd_solver.cpp:106] Iteration 365250, lr = 0.004
I0526 19:44:05.635150 14297 solver.cpp:237] Iteration 366000, loss = 1.47151
I0526 19:44:05.635186 14297 solver.cpp:253]     Train net output #0: loss = 1.47151 (* 1 = 1.47151 loss)
I0526 19:44:05.635200 14297 sgd_solver.cpp:106] Iteration 366000, lr = 0.004
I0526 19:44:17.803133 14297 solver.cpp:237] Iteration 366750, loss = 2.02305
I0526 19:44:17.803169 14297 solver.cpp:253]     Train net output #0: loss = 2.02305 (* 1 = 2.02305 loss)
I0526 19:44:17.803182 14297 sgd_solver.cpp:106] Iteration 366750, lr = 0.004
I0526 19:44:29.942309 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_367500.caffemodel
I0526 19:44:29.991260 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_367500.solverstate
I0526 19:44:30.021461 14297 solver.cpp:237] Iteration 367500, loss = 0.928387
I0526 19:44:30.021508 14297 solver.cpp:253]     Train net output #0: loss = 0.928387 (* 1 = 0.928387 loss)
I0526 19:44:30.021522 14297 sgd_solver.cpp:106] Iteration 367500, lr = 0.004
I0526 19:44:42.140447 14297 solver.cpp:237] Iteration 368250, loss = 1.44799
I0526 19:44:42.140485 14297 solver.cpp:253]     Train net output #0: loss = 1.44799 (* 1 = 1.44799 loss)
I0526 19:44:42.140501 14297 sgd_solver.cpp:106] Iteration 368250, lr = 0.004
I0526 19:44:54.270651 14297 solver.cpp:237] Iteration 369000, loss = 0.94563
I0526 19:44:54.270694 14297 solver.cpp:253]     Train net output #0: loss = 0.94563 (* 1 = 0.94563 loss)
I0526 19:44:54.270709 14297 sgd_solver.cpp:106] Iteration 369000, lr = 0.004
I0526 19:45:06.387114 14297 solver.cpp:237] Iteration 369750, loss = 0.598148
I0526 19:45:06.387264 14297 solver.cpp:253]     Train net output #0: loss = 0.598148 (* 1 = 0.598148 loss)
I0526 19:45:06.387279 14297 sgd_solver.cpp:106] Iteration 369750, lr = 0.004
I0526 19:45:39.349915 14297 solver.cpp:237] Iteration 370500, loss = 1.13348
I0526 19:45:39.350081 14297 solver.cpp:253]     Train net output #0: loss = 1.13349 (* 1 = 1.13349 loss)
I0526 19:45:39.350097 14297 sgd_solver.cpp:106] Iteration 370500, lr = 0.004
I0526 19:45:51.437206 14297 solver.cpp:237] Iteration 371250, loss = 0.862403
I0526 19:45:51.437243 14297 solver.cpp:253]     Train net output #0: loss = 0.862404 (* 1 = 0.862404 loss)
I0526 19:45:51.437258 14297 sgd_solver.cpp:106] Iteration 371250, lr = 0.004
I0526 19:46:03.585044 14297 solver.cpp:237] Iteration 372000, loss = 1.06674
I0526 19:46:03.585090 14297 solver.cpp:253]     Train net output #0: loss = 1.06674 (* 1 = 1.06674 loss)
I0526 19:46:03.585108 14297 sgd_solver.cpp:106] Iteration 372000, lr = 0.004
I0526 19:46:15.677865 14297 solver.cpp:237] Iteration 372750, loss = 1.12985
I0526 19:46:15.678025 14297 solver.cpp:253]     Train net output #0: loss = 1.12985 (* 1 = 1.12985 loss)
I0526 19:46:15.678040 14297 sgd_solver.cpp:106] Iteration 372750, lr = 0.004
I0526 19:46:27.752354 14297 solver.cpp:237] Iteration 373500, loss = 1.02664
I0526 19:46:27.752398 14297 solver.cpp:253]     Train net output #0: loss = 1.02665 (* 1 = 1.02665 loss)
I0526 19:46:27.752411 14297 sgd_solver.cpp:106] Iteration 373500, lr = 0.004
I0526 19:46:39.829962 14297 solver.cpp:237] Iteration 374250, loss = 1.09548
I0526 19:46:39.829998 14297 solver.cpp:253]     Train net output #0: loss = 1.09548 (* 1 = 1.09548 loss)
I0526 19:46:39.830011 14297 sgd_solver.cpp:106] Iteration 374250, lr = 0.004
I0526 19:46:51.931056 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_375000.caffemodel
I0526 19:46:51.980648 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_375000.solverstate
I0526 19:46:52.006117 14297 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 19:48:04.759423 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903579
I0526 19:48:04.759598 14297 solver.cpp:409]     Test net output #1: loss = 0.312741 (* 1 = 0.312741 loss)
I0526 19:48:25.627617 14297 solver.cpp:237] Iteration 375000, loss = 1.38079
I0526 19:48:25.627671 14297 solver.cpp:253]     Train net output #0: loss = 1.38079 (* 1 = 1.38079 loss)
I0526 19:48:25.627686 14297 sgd_solver.cpp:106] Iteration 375000, lr = 0.004
I0526 19:48:37.769434 14297 solver.cpp:237] Iteration 375750, loss = 1.23294
I0526 19:48:37.769601 14297 solver.cpp:253]     Train net output #0: loss = 1.23294 (* 1 = 1.23294 loss)
I0526 19:48:37.769616 14297 sgd_solver.cpp:106] Iteration 375750, lr = 0.004
I0526 19:48:49.935528 14297 solver.cpp:237] Iteration 376500, loss = 0.861643
I0526 19:48:49.935565 14297 solver.cpp:253]     Train net output #0: loss = 0.861644 (* 1 = 0.861644 loss)
I0526 19:48:49.935580 14297 sgd_solver.cpp:106] Iteration 376500, lr = 0.004
I0526 19:49:02.101150 14297 solver.cpp:237] Iteration 377250, loss = 1.47487
I0526 19:49:02.101196 14297 solver.cpp:253]     Train net output #0: loss = 1.47487 (* 1 = 1.47487 loss)
I0526 19:49:02.101209 14297 sgd_solver.cpp:106] Iteration 377250, lr = 0.004
I0526 19:49:14.227749 14297 solver.cpp:237] Iteration 378000, loss = 0.899635
I0526 19:49:14.227897 14297 solver.cpp:253]     Train net output #0: loss = 0.899637 (* 1 = 0.899637 loss)
I0526 19:49:14.227911 14297 sgd_solver.cpp:106] Iteration 378000, lr = 0.004
I0526 19:49:26.354564 14297 solver.cpp:237] Iteration 378750, loss = 1.00591
I0526 19:49:26.354614 14297 solver.cpp:253]     Train net output #0: loss = 1.00592 (* 1 = 1.00592 loss)
I0526 19:49:26.354629 14297 sgd_solver.cpp:106] Iteration 378750, lr = 0.004
I0526 19:49:38.526880 14297 solver.cpp:237] Iteration 379500, loss = 0.838586
I0526 19:49:38.526916 14297 solver.cpp:253]     Train net output #0: loss = 0.838587 (* 1 = 0.838587 loss)
I0526 19:49:38.526931 14297 sgd_solver.cpp:106] Iteration 379500, lr = 0.004
I0526 19:50:11.574599 14297 solver.cpp:237] Iteration 380250, loss = 1.16809
I0526 19:50:11.574769 14297 solver.cpp:253]     Train net output #0: loss = 1.16809 (* 1 = 1.16809 loss)
I0526 19:50:11.574784 14297 sgd_solver.cpp:106] Iteration 380250, lr = 0.004
I0526 19:50:23.742413 14297 solver.cpp:237] Iteration 381000, loss = 0.794491
I0526 19:50:23.742449 14297 solver.cpp:253]     Train net output #0: loss = 0.794492 (* 1 = 0.794492 loss)
I0526 19:50:23.742465 14297 sgd_solver.cpp:106] Iteration 381000, lr = 0.004
I0526 19:50:35.928079 14297 solver.cpp:237] Iteration 381750, loss = 1.52571
I0526 19:50:35.928130 14297 solver.cpp:253]     Train net output #0: loss = 1.52571 (* 1 = 1.52571 loss)
I0526 19:50:35.928143 14297 sgd_solver.cpp:106] Iteration 381750, lr = 0.004
I0526 19:50:48.082800 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_382500.caffemodel
I0526 19:50:48.132663 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_382500.solverstate
I0526 19:50:48.166246 14297 solver.cpp:237] Iteration 382500, loss = 0.946266
I0526 19:50:48.166295 14297 solver.cpp:253]     Train net output #0: loss = 0.946267 (* 1 = 0.946267 loss)
I0526 19:50:48.166309 14297 sgd_solver.cpp:106] Iteration 382500, lr = 0.004
I0526 19:51:00.334715 14297 solver.cpp:237] Iteration 383250, loss = 1.16016
I0526 19:51:00.334767 14297 solver.cpp:253]     Train net output #0: loss = 1.16016 (* 1 = 1.16016 loss)
I0526 19:51:00.334781 14297 sgd_solver.cpp:106] Iteration 383250, lr = 0.004
I0526 19:51:12.494031 14297 solver.cpp:237] Iteration 384000, loss = 0.941793
I0526 19:51:12.494069 14297 solver.cpp:253]     Train net output #0: loss = 0.941795 (* 1 = 0.941795 loss)
I0526 19:51:12.494083 14297 sgd_solver.cpp:106] Iteration 384000, lr = 0.004
I0526 19:51:24.673159 14297 solver.cpp:237] Iteration 384750, loss = 0.805905
I0526 19:51:24.673322 14297 solver.cpp:253]     Train net output #0: loss = 0.805907 (* 1 = 0.805907 loss)
I0526 19:51:24.673336 14297 sgd_solver.cpp:106] Iteration 384750, lr = 0.004
I0526 19:51:57.779690 14297 solver.cpp:237] Iteration 385500, loss = 0.858521
I0526 19:51:57.779868 14297 solver.cpp:253]     Train net output #0: loss = 0.858523 (* 1 = 0.858523 loss)
I0526 19:51:57.779886 14297 sgd_solver.cpp:106] Iteration 385500, lr = 0.004
I0526 19:52:09.924931 14297 solver.cpp:237] Iteration 386250, loss = 1.289
I0526 19:52:09.924967 14297 solver.cpp:253]     Train net output #0: loss = 1.28901 (* 1 = 1.28901 loss)
I0526 19:52:09.924980 14297 sgd_solver.cpp:106] Iteration 386250, lr = 0.004
I0526 19:52:22.077342 14297 solver.cpp:237] Iteration 387000, loss = 0.989426
I0526 19:52:22.077389 14297 solver.cpp:253]     Train net output #0: loss = 0.989428 (* 1 = 0.989428 loss)
I0526 19:52:22.077404 14297 sgd_solver.cpp:106] Iteration 387000, lr = 0.004
I0526 19:52:34.251061 14297 solver.cpp:237] Iteration 387750, loss = 0.740438
I0526 19:52:34.251212 14297 solver.cpp:253]     Train net output #0: loss = 0.74044 (* 1 = 0.74044 loss)
I0526 19:52:34.251227 14297 sgd_solver.cpp:106] Iteration 387750, lr = 0.004
I0526 19:52:46.424950 14297 solver.cpp:237] Iteration 388500, loss = 1.14532
I0526 19:52:46.425000 14297 solver.cpp:253]     Train net output #0: loss = 1.14532 (* 1 = 1.14532 loss)
I0526 19:52:46.425014 14297 sgd_solver.cpp:106] Iteration 388500, lr = 0.004
I0526 19:52:58.586859 14297 solver.cpp:237] Iteration 389250, loss = 1.04971
I0526 19:52:58.586895 14297 solver.cpp:253]     Train net output #0: loss = 1.04972 (* 1 = 1.04972 loss)
I0526 19:52:58.586910 14297 sgd_solver.cpp:106] Iteration 389250, lr = 0.004
I0526 19:53:10.717330 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_390000.caffemodel
I0526 19:53:10.768409 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_390000.solverstate
I0526 19:53:10.796387 14297 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 19:54:02.513840 14297 solver.cpp:409]     Test net output #0: accuracy = 0.90002
I0526 19:54:02.514011 14297 solver.cpp:409]     Test net output #1: loss = 0.334065 (* 1 = 0.334065 loss)
I0526 19:54:23.473096 14297 solver.cpp:237] Iteration 390000, loss = 1.24366
I0526 19:54:23.473147 14297 solver.cpp:253]     Train net output #0: loss = 1.24367 (* 1 = 1.24367 loss)
I0526 19:54:23.473165 14297 sgd_solver.cpp:106] Iteration 390000, lr = 0.004
I0526 19:54:35.646630 14297 solver.cpp:237] Iteration 390750, loss = 1.12282
I0526 19:54:35.646785 14297 solver.cpp:253]     Train net output #0: loss = 1.12282 (* 1 = 1.12282 loss)
I0526 19:54:35.646798 14297 sgd_solver.cpp:106] Iteration 390750, lr = 0.004
I0526 19:54:47.841006 14297 solver.cpp:237] Iteration 391500, loss = 0.900853
I0526 19:54:47.841053 14297 solver.cpp:253]     Train net output #0: loss = 0.900855 (* 1 = 0.900855 loss)
I0526 19:54:47.841066 14297 sgd_solver.cpp:106] Iteration 391500, lr = 0.004
I0526 19:54:59.941684 14297 solver.cpp:237] Iteration 392250, loss = 0.8542
I0526 19:54:59.941721 14297 solver.cpp:253]     Train net output #0: loss = 0.854203 (* 1 = 0.854203 loss)
I0526 19:54:59.941735 14297 sgd_solver.cpp:106] Iteration 392250, lr = 0.004
I0526 19:55:12.041494 14297 solver.cpp:237] Iteration 393000, loss = 0.814926
I0526 19:55:12.041669 14297 solver.cpp:253]     Train net output #0: loss = 0.814928 (* 1 = 0.814928 loss)
I0526 19:55:12.041687 14297 sgd_solver.cpp:106] Iteration 393000, lr = 0.004
I0526 19:55:24.133611 14297 solver.cpp:237] Iteration 393750, loss = 1.31909
I0526 19:55:24.133647 14297 solver.cpp:253]     Train net output #0: loss = 1.3191 (* 1 = 1.3191 loss)
I0526 19:55:24.133661 14297 sgd_solver.cpp:106] Iteration 393750, lr = 0.004
I0526 19:55:36.234496 14297 solver.cpp:237] Iteration 394500, loss = 1.05302
I0526 19:55:36.234544 14297 solver.cpp:253]     Train net output #0: loss = 1.05302 (* 1 = 1.05302 loss)
I0526 19:55:36.234557 14297 sgd_solver.cpp:106] Iteration 394500, lr = 0.004
I0526 19:56:09.357288 14297 solver.cpp:237] Iteration 395250, loss = 1.35282
I0526 19:56:09.357465 14297 solver.cpp:253]     Train net output #0: loss = 1.35282 (* 1 = 1.35282 loss)
I0526 19:56:09.357481 14297 sgd_solver.cpp:106] Iteration 395250, lr = 0.004
I0526 19:56:21.552462 14297 solver.cpp:237] Iteration 396000, loss = 1.54715
I0526 19:56:21.552498 14297 solver.cpp:253]     Train net output #0: loss = 1.54715 (* 1 = 1.54715 loss)
I0526 19:56:21.552512 14297 sgd_solver.cpp:106] Iteration 396000, lr = 0.004
I0526 19:56:33.673229 14297 solver.cpp:237] Iteration 396750, loss = 1.0675
I0526 19:56:33.673279 14297 solver.cpp:253]     Train net output #0: loss = 1.0675 (* 1 = 1.0675 loss)
I0526 19:56:33.673292 14297 sgd_solver.cpp:106] Iteration 396750, lr = 0.004
I0526 19:56:45.774592 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_397500.caffemodel
I0526 19:56:45.827047 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_397500.solverstate
I0526 19:56:45.860118 14297 solver.cpp:237] Iteration 397500, loss = 1.7655
I0526 19:56:45.860168 14297 solver.cpp:253]     Train net output #0: loss = 1.76551 (* 1 = 1.76551 loss)
I0526 19:56:45.860183 14297 sgd_solver.cpp:106] Iteration 397500, lr = 0.004
I0526 19:56:58.001302 14297 solver.cpp:237] Iteration 398250, loss = 0.687535
I0526 19:56:58.001353 14297 solver.cpp:253]     Train net output #0: loss = 0.687538 (* 1 = 0.687538 loss)
I0526 19:56:58.001366 14297 sgd_solver.cpp:106] Iteration 398250, lr = 0.004
I0526 19:57:10.131359 14297 solver.cpp:237] Iteration 399000, loss = 0.995064
I0526 19:57:10.131397 14297 solver.cpp:253]     Train net output #0: loss = 0.995067 (* 1 = 0.995067 loss)
I0526 19:57:10.131412 14297 sgd_solver.cpp:106] Iteration 399000, lr = 0.004
I0526 19:57:22.203747 14297 solver.cpp:237] Iteration 399750, loss = 0.997877
I0526 19:57:22.203918 14297 solver.cpp:253]     Train net output #0: loss = 0.99788 (* 1 = 0.99788 loss)
I0526 19:57:22.203933 14297 sgd_solver.cpp:106] Iteration 399750, lr = 0.004
I0526 19:57:55.193233 14297 solver.cpp:237] Iteration 400500, loss = 1.06759
I0526 19:57:55.193403 14297 solver.cpp:253]     Train net output #0: loss = 1.0676 (* 1 = 1.0676 loss)
I0526 19:57:55.193418 14297 sgd_solver.cpp:106] Iteration 400500, lr = 0.004
I0526 19:58:07.274199 14297 solver.cpp:237] Iteration 401250, loss = 0.958192
I0526 19:58:07.274247 14297 solver.cpp:253]     Train net output #0: loss = 0.958195 (* 1 = 0.958195 loss)
I0526 19:58:07.274262 14297 sgd_solver.cpp:106] Iteration 401250, lr = 0.004
I0526 19:58:19.349675 14297 solver.cpp:237] Iteration 402000, loss = 1.3547
I0526 19:58:19.349711 14297 solver.cpp:253]     Train net output #0: loss = 1.3547 (* 1 = 1.3547 loss)
I0526 19:58:19.349725 14297 sgd_solver.cpp:106] Iteration 402000, lr = 0.004
I0526 19:58:31.428119 14297 solver.cpp:237] Iteration 402750, loss = 1.21074
I0526 19:58:31.428295 14297 solver.cpp:253]     Train net output #0: loss = 1.21074 (* 1 = 1.21074 loss)
I0526 19:58:31.428309 14297 sgd_solver.cpp:106] Iteration 402750, lr = 0.004
I0526 19:58:43.483501 14297 solver.cpp:237] Iteration 403500, loss = 1.52411
I0526 19:58:43.483537 14297 solver.cpp:253]     Train net output #0: loss = 1.52411 (* 1 = 1.52411 loss)
I0526 19:58:43.483551 14297 sgd_solver.cpp:106] Iteration 403500, lr = 0.004
I0526 19:58:55.560364 14297 solver.cpp:237] Iteration 404250, loss = 0.860015
I0526 19:58:55.560415 14297 solver.cpp:253]     Train net output #0: loss = 0.860018 (* 1 = 0.860018 loss)
I0526 19:58:55.560430 14297 sgd_solver.cpp:106] Iteration 404250, lr = 0.004
I0526 19:59:07.618496 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_405000.caffemodel
I0526 19:59:07.667889 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_405000.solverstate
I0526 19:59:07.693490 14297 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 20:00:20.526758 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903558
I0526 20:00:20.526932 14297 solver.cpp:409]     Test net output #1: loss = 0.320435 (* 1 = 0.320435 loss)
I0526 20:00:41.429129 14297 solver.cpp:237] Iteration 405000, loss = 0.741012
I0526 20:00:41.429180 14297 solver.cpp:253]     Train net output #0: loss = 0.741015 (* 1 = 0.741015 loss)
I0526 20:00:41.429198 14297 sgd_solver.cpp:106] Iteration 405000, lr = 0.004
I0526 20:00:53.634919 14297 solver.cpp:237] Iteration 405750, loss = 1.10882
I0526 20:00:53.635077 14297 solver.cpp:253]     Train net output #0: loss = 1.10882 (* 1 = 1.10882 loss)
I0526 20:00:53.635090 14297 sgd_solver.cpp:106] Iteration 405750, lr = 0.004
I0526 20:01:05.837442 14297 solver.cpp:237] Iteration 406500, loss = 1.12212
I0526 20:01:05.837489 14297 solver.cpp:253]     Train net output #0: loss = 1.12213 (* 1 = 1.12213 loss)
I0526 20:01:05.837503 14297 sgd_solver.cpp:106] Iteration 406500, lr = 0.004
I0526 20:01:18.032873 14297 solver.cpp:237] Iteration 407250, loss = 0.98865
I0526 20:01:18.032910 14297 solver.cpp:253]     Train net output #0: loss = 0.988653 (* 1 = 0.988653 loss)
I0526 20:01:18.032924 14297 sgd_solver.cpp:106] Iteration 407250, lr = 0.004
I0526 20:01:30.248575 14297 solver.cpp:237] Iteration 408000, loss = 1.05518
I0526 20:01:30.248756 14297 solver.cpp:253]     Train net output #0: loss = 1.05518 (* 1 = 1.05518 loss)
I0526 20:01:30.248772 14297 sgd_solver.cpp:106] Iteration 408000, lr = 0.004
I0526 20:01:42.495756 14297 solver.cpp:237] Iteration 408750, loss = 1.36577
I0526 20:01:42.495792 14297 solver.cpp:253]     Train net output #0: loss = 1.36577 (* 1 = 1.36577 loss)
I0526 20:01:42.495807 14297 sgd_solver.cpp:106] Iteration 408750, lr = 0.004
I0526 20:01:54.686805 14297 solver.cpp:237] Iteration 409500, loss = 1.00988
I0526 20:01:54.686852 14297 solver.cpp:253]     Train net output #0: loss = 1.00988 (* 1 = 1.00988 loss)
I0526 20:01:54.686866 14297 sgd_solver.cpp:106] Iteration 409500, lr = 0.004
I0526 20:02:27.738503 14297 solver.cpp:237] Iteration 410250, loss = 0.996658
I0526 20:02:27.738682 14297 solver.cpp:253]     Train net output #0: loss = 0.996662 (* 1 = 0.996662 loss)
I0526 20:02:27.738697 14297 sgd_solver.cpp:106] Iteration 410250, lr = 0.004
I0526 20:02:39.893965 14297 solver.cpp:237] Iteration 411000, loss = 0.734639
I0526 20:02:39.894017 14297 solver.cpp:253]     Train net output #0: loss = 0.734643 (* 1 = 0.734643 loss)
I0526 20:02:39.894032 14297 sgd_solver.cpp:106] Iteration 411000, lr = 0.004
I0526 20:02:52.104893 14297 solver.cpp:237] Iteration 411750, loss = 1.5635
I0526 20:02:52.104930 14297 solver.cpp:253]     Train net output #0: loss = 1.5635 (* 1 = 1.5635 loss)
I0526 20:02:52.104944 14297 sgd_solver.cpp:106] Iteration 411750, lr = 0.004
I0526 20:03:04.259414 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_412500.caffemodel
I0526 20:03:04.308718 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_412500.solverstate
I0526 20:03:04.339493 14297 solver.cpp:237] Iteration 412500, loss = 1.38702
I0526 20:03:04.339536 14297 solver.cpp:253]     Train net output #0: loss = 1.38703 (* 1 = 1.38703 loss)
I0526 20:03:04.339555 14297 sgd_solver.cpp:106] Iteration 412500, lr = 0.004
I0526 20:03:16.533687 14297 solver.cpp:237] Iteration 413250, loss = 1.27115
I0526 20:03:16.533723 14297 solver.cpp:253]     Train net output #0: loss = 1.27115 (* 1 = 1.27115 loss)
I0526 20:03:16.533737 14297 sgd_solver.cpp:106] Iteration 413250, lr = 0.004
I0526 20:03:28.761123 14297 solver.cpp:237] Iteration 414000, loss = 1.19445
I0526 20:03:28.761170 14297 solver.cpp:253]     Train net output #0: loss = 1.19446 (* 1 = 1.19446 loss)
I0526 20:03:28.761185 14297 sgd_solver.cpp:106] Iteration 414000, lr = 0.004
I0526 20:03:40.982729 14297 solver.cpp:237] Iteration 414750, loss = 0.898949
I0526 20:03:40.982892 14297 solver.cpp:253]     Train net output #0: loss = 0.898953 (* 1 = 0.898953 loss)
I0526 20:03:40.982905 14297 sgd_solver.cpp:106] Iteration 414750, lr = 0.004
I0526 20:04:14.086576 14297 solver.cpp:237] Iteration 415500, loss = 1.26227
I0526 20:04:14.086750 14297 solver.cpp:253]     Train net output #0: loss = 1.26228 (* 1 = 1.26228 loss)
I0526 20:04:14.086766 14297 sgd_solver.cpp:106] Iteration 415500, lr = 0.004
I0526 20:04:26.299026 14297 solver.cpp:237] Iteration 416250, loss = 1.56162
I0526 20:04:26.299072 14297 solver.cpp:253]     Train net output #0: loss = 1.56162 (* 1 = 1.56162 loss)
I0526 20:04:26.299087 14297 sgd_solver.cpp:106] Iteration 416250, lr = 0.004
I0526 20:04:38.506623 14297 solver.cpp:237] Iteration 417000, loss = 1.03375
I0526 20:04:38.506659 14297 solver.cpp:253]     Train net output #0: loss = 1.03376 (* 1 = 1.03376 loss)
I0526 20:04:38.506674 14297 sgd_solver.cpp:106] Iteration 417000, lr = 0.004
I0526 20:04:50.666328 14297 solver.cpp:237] Iteration 417750, loss = 1.03909
I0526 20:04:50.666498 14297 solver.cpp:253]     Train net output #0: loss = 1.0391 (* 1 = 1.0391 loss)
I0526 20:04:50.666513 14297 sgd_solver.cpp:106] Iteration 417750, lr = 0.004
I0526 20:05:02.755870 14297 solver.cpp:237] Iteration 418500, loss = 1.23762
I0526 20:05:02.755906 14297 solver.cpp:253]     Train net output #0: loss = 1.23763 (* 1 = 1.23763 loss)
I0526 20:05:02.755921 14297 sgd_solver.cpp:106] Iteration 418500, lr = 0.004
I0526 20:05:14.895850 14297 solver.cpp:237] Iteration 419250, loss = 1.6078
I0526 20:05:14.895900 14297 solver.cpp:253]     Train net output #0: loss = 1.6078 (* 1 = 1.6078 loss)
I0526 20:05:14.895915 14297 sgd_solver.cpp:106] Iteration 419250, lr = 0.004
I0526 20:05:27.014626 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_420000.caffemodel
I0526 20:05:27.064021 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_420000.solverstate
I0526 20:05:27.089359 14297 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 20:06:19.112273 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903392
I0526 20:06:19.112443 14297 solver.cpp:409]     Test net output #1: loss = 0.301378 (* 1 = 0.301378 loss)
I0526 20:06:40.065712 14297 solver.cpp:237] Iteration 420000, loss = 1.03945
I0526 20:06:40.065767 14297 solver.cpp:253]     Train net output #0: loss = 1.03945 (* 1 = 1.03945 loss)
I0526 20:06:40.065783 14297 sgd_solver.cpp:106] Iteration 420000, lr = 0.004
I0526 20:06:52.238895 14297 solver.cpp:237] Iteration 420750, loss = 1.28943
I0526 20:06:52.239081 14297 solver.cpp:253]     Train net output #0: loss = 1.28943 (* 1 = 1.28943 loss)
I0526 20:06:52.239099 14297 sgd_solver.cpp:106] Iteration 420750, lr = 0.004
I0526 20:07:04.447365 14297 solver.cpp:237] Iteration 421500, loss = 0.863278
I0526 20:07:04.447402 14297 solver.cpp:253]     Train net output #0: loss = 0.863283 (* 1 = 0.863283 loss)
I0526 20:07:04.447417 14297 sgd_solver.cpp:106] Iteration 421500, lr = 0.004
I0526 20:07:16.651803 14297 solver.cpp:237] Iteration 422250, loss = 1.23089
I0526 20:07:16.651849 14297 solver.cpp:253]     Train net output #0: loss = 1.2309 (* 1 = 1.2309 loss)
I0526 20:07:16.651862 14297 sgd_solver.cpp:106] Iteration 422250, lr = 0.004
I0526 20:07:28.858711 14297 solver.cpp:237] Iteration 423000, loss = 0.973825
I0526 20:07:28.858866 14297 solver.cpp:253]     Train net output #0: loss = 0.97383 (* 1 = 0.97383 loss)
I0526 20:07:28.858881 14297 sgd_solver.cpp:106] Iteration 423000, lr = 0.004
I0526 20:07:41.051868 14297 solver.cpp:237] Iteration 423750, loss = 1.4561
I0526 20:07:41.051911 14297 solver.cpp:253]     Train net output #0: loss = 1.45611 (* 1 = 1.45611 loss)
I0526 20:07:41.051925 14297 sgd_solver.cpp:106] Iteration 423750, lr = 0.004
I0526 20:07:53.212023 14297 solver.cpp:237] Iteration 424500, loss = 1.13513
I0526 20:07:53.212059 14297 solver.cpp:253]     Train net output #0: loss = 1.13513 (* 1 = 1.13513 loss)
I0526 20:07:53.212074 14297 sgd_solver.cpp:106] Iteration 424500, lr = 0.004
I0526 20:08:26.296442 14297 solver.cpp:237] Iteration 425250, loss = 1.3078
I0526 20:08:26.296623 14297 solver.cpp:253]     Train net output #0: loss = 1.30781 (* 1 = 1.30781 loss)
I0526 20:08:26.296640 14297 sgd_solver.cpp:106] Iteration 425250, lr = 0.004
I0526 20:08:38.537582 14297 solver.cpp:237] Iteration 426000, loss = 0.998677
I0526 20:08:38.537634 14297 solver.cpp:253]     Train net output #0: loss = 0.998682 (* 1 = 0.998682 loss)
I0526 20:08:38.537649 14297 sgd_solver.cpp:106] Iteration 426000, lr = 0.004
I0526 20:08:50.742916 14297 solver.cpp:237] Iteration 426750, loss = 0.681959
I0526 20:08:50.742954 14297 solver.cpp:253]     Train net output #0: loss = 0.681963 (* 1 = 0.681963 loss)
I0526 20:08:50.742969 14297 sgd_solver.cpp:106] Iteration 426750, lr = 0.004
I0526 20:09:02.891062 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_427500.caffemodel
I0526 20:09:02.944151 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_427500.solverstate
I0526 20:09:02.976763 14297 solver.cpp:237] Iteration 427500, loss = 1.87464
I0526 20:09:02.976814 14297 solver.cpp:253]     Train net output #0: loss = 1.87464 (* 1 = 1.87464 loss)
I0526 20:09:02.976829 14297 sgd_solver.cpp:106] Iteration 427500, lr = 0.004
I0526 20:09:15.176973 14297 solver.cpp:237] Iteration 428250, loss = 0.860066
I0526 20:09:15.177012 14297 solver.cpp:253]     Train net output #0: loss = 0.860071 (* 1 = 0.860071 loss)
I0526 20:09:15.177026 14297 sgd_solver.cpp:106] Iteration 428250, lr = 0.004
I0526 20:09:27.359966 14297 solver.cpp:237] Iteration 429000, loss = 2.62751
I0526 20:09:27.360013 14297 solver.cpp:253]     Train net output #0: loss = 2.62752 (* 1 = 2.62752 loss)
I0526 20:09:27.360028 14297 sgd_solver.cpp:106] Iteration 429000, lr = 0.004
I0526 20:09:39.530717 14297 solver.cpp:237] Iteration 429750, loss = 0.5464
I0526 20:09:39.530876 14297 solver.cpp:253]     Train net output #0: loss = 0.546405 (* 1 = 0.546405 loss)
I0526 20:09:39.530891 14297 sgd_solver.cpp:106] Iteration 429750, lr = 0.004
I0526 20:10:12.646661 14297 solver.cpp:237] Iteration 430500, loss = 0.982448
I0526 20:10:12.646843 14297 solver.cpp:253]     Train net output #0: loss = 0.982453 (* 1 = 0.982453 loss)
I0526 20:10:12.646858 14297 sgd_solver.cpp:106] Iteration 430500, lr = 0.004
I0526 20:10:24.840884 14297 solver.cpp:237] Iteration 431250, loss = 1.33616
I0526 20:10:24.840919 14297 solver.cpp:253]     Train net output #0: loss = 1.33617 (* 1 = 1.33617 loss)
I0526 20:10:24.840934 14297 sgd_solver.cpp:106] Iteration 431250, lr = 0.004
I0526 20:10:37.051112 14297 solver.cpp:237] Iteration 432000, loss = 1.01416
I0526 20:10:37.051161 14297 solver.cpp:253]     Train net output #0: loss = 1.01417 (* 1 = 1.01417 loss)
I0526 20:10:37.051174 14297 sgd_solver.cpp:106] Iteration 432000, lr = 0.004
I0526 20:10:49.250983 14297 solver.cpp:237] Iteration 432750, loss = 1.607
I0526 20:10:49.251140 14297 solver.cpp:253]     Train net output #0: loss = 1.607 (* 1 = 1.607 loss)
I0526 20:10:49.251153 14297 sgd_solver.cpp:106] Iteration 432750, lr = 0.004
I0526 20:11:01.470185 14297 solver.cpp:237] Iteration 433500, loss = 1.43347
I0526 20:11:01.470237 14297 solver.cpp:253]     Train net output #0: loss = 1.43348 (* 1 = 1.43348 loss)
I0526 20:11:01.470250 14297 sgd_solver.cpp:106] Iteration 433500, lr = 0.004
I0526 20:11:13.671473 14297 solver.cpp:237] Iteration 434250, loss = 1.34612
I0526 20:11:13.671509 14297 solver.cpp:253]     Train net output #0: loss = 1.34613 (* 1 = 1.34613 loss)
I0526 20:11:13.671524 14297 sgd_solver.cpp:106] Iteration 434250, lr = 0.004
I0526 20:11:25.835847 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_435000.caffemodel
I0526 20:11:25.895562 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_435000.solverstate
I0526 20:11:25.923341 14297 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 20:12:38.802999 14297 solver.cpp:409]     Test net output #0: accuracy = 0.902539
I0526 20:12:38.803169 14297 solver.cpp:409]     Test net output #1: loss = 0.311417 (* 1 = 0.311417 loss)
I0526 20:12:59.707072 14297 solver.cpp:237] Iteration 435000, loss = 1.03678
I0526 20:12:59.707124 14297 solver.cpp:253]     Train net output #0: loss = 1.03679 (* 1 = 1.03679 loss)
I0526 20:12:59.707139 14297 sgd_solver.cpp:106] Iteration 435000, lr = 0.004
I0526 20:13:11.759883 14297 solver.cpp:237] Iteration 435750, loss = 1.1918
I0526 20:13:11.760056 14297 solver.cpp:253]     Train net output #0: loss = 1.19181 (* 1 = 1.19181 loss)
I0526 20:13:11.760069 14297 sgd_solver.cpp:106] Iteration 435750, lr = 0.004
I0526 20:13:23.858795 14297 solver.cpp:237] Iteration 436500, loss = 1.2226
I0526 20:13:23.858831 14297 solver.cpp:253]     Train net output #0: loss = 1.2226 (* 1 = 1.2226 loss)
I0526 20:13:23.858844 14297 sgd_solver.cpp:106] Iteration 436500, lr = 0.004
I0526 20:13:35.967633 14297 solver.cpp:237] Iteration 437250, loss = 1.05921
I0526 20:13:35.967679 14297 solver.cpp:253]     Train net output #0: loss = 1.05922 (* 1 = 1.05922 loss)
I0526 20:13:35.967694 14297 sgd_solver.cpp:106] Iteration 437250, lr = 0.004
I0526 20:13:48.112215 14297 solver.cpp:237] Iteration 438000, loss = 1.00443
I0526 20:13:48.112370 14297 solver.cpp:253]     Train net output #0: loss = 1.00443 (* 1 = 1.00443 loss)
I0526 20:13:48.112385 14297 sgd_solver.cpp:106] Iteration 438000, lr = 0.004
I0526 20:14:00.247100 14297 solver.cpp:237] Iteration 438750, loss = 1.2824
I0526 20:14:00.247144 14297 solver.cpp:253]     Train net output #0: loss = 1.28241 (* 1 = 1.28241 loss)
I0526 20:14:00.247159 14297 sgd_solver.cpp:106] Iteration 438750, lr = 0.004
I0526 20:14:12.374166 14297 solver.cpp:237] Iteration 439500, loss = 1.27009
I0526 20:14:12.374202 14297 solver.cpp:253]     Train net output #0: loss = 1.2701 (* 1 = 1.2701 loss)
I0526 20:14:12.374217 14297 sgd_solver.cpp:106] Iteration 439500, lr = 0.004
I0526 20:14:45.428700 14297 solver.cpp:237] Iteration 440250, loss = 1.24655
I0526 20:14:45.428886 14297 solver.cpp:253]     Train net output #0: loss = 1.24655 (* 1 = 1.24655 loss)
I0526 20:14:45.428901 14297 sgd_solver.cpp:106] Iteration 440250, lr = 0.004
I0526 20:14:57.564450 14297 solver.cpp:237] Iteration 441000, loss = 1.40936
I0526 20:14:57.564486 14297 solver.cpp:253]     Train net output #0: loss = 1.40937 (* 1 = 1.40937 loss)
I0526 20:14:57.564499 14297 sgd_solver.cpp:106] Iteration 441000, lr = 0.004
I0526 20:15:09.697224 14297 solver.cpp:237] Iteration 441750, loss = 1.916
I0526 20:15:09.697259 14297 solver.cpp:253]     Train net output #0: loss = 1.916 (* 1 = 1.916 loss)
I0526 20:15:09.697271 14297 sgd_solver.cpp:106] Iteration 441750, lr = 0.004
I0526 20:15:21.814856 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_442500.caffemodel
I0526 20:15:21.864925 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_442500.solverstate
I0526 20:15:21.895563 14297 solver.cpp:237] Iteration 442500, loss = 1.34174
I0526 20:15:21.895609 14297 solver.cpp:253]     Train net output #0: loss = 1.34175 (* 1 = 1.34175 loss)
I0526 20:15:21.895624 14297 sgd_solver.cpp:106] Iteration 442500, lr = 0.004
I0526 20:15:33.992903 14297 solver.cpp:237] Iteration 443250, loss = 0.965224
I0526 20:15:33.992949 14297 solver.cpp:253]     Train net output #0: loss = 0.965229 (* 1 = 0.965229 loss)
I0526 20:15:33.992962 14297 sgd_solver.cpp:106] Iteration 443250, lr = 0.004
I0526 20:15:46.088565 14297 solver.cpp:237] Iteration 444000, loss = 0.900101
I0526 20:15:46.088601 14297 solver.cpp:253]     Train net output #0: loss = 0.900106 (* 1 = 0.900106 loss)
I0526 20:15:46.088616 14297 sgd_solver.cpp:106] Iteration 444000, lr = 0.004
I0526 20:15:58.196573 14297 solver.cpp:237] Iteration 444750, loss = 0.902785
I0526 20:15:58.196732 14297 solver.cpp:253]     Train net output #0: loss = 0.90279 (* 1 = 0.90279 loss)
I0526 20:15:58.196746 14297 sgd_solver.cpp:106] Iteration 444750, lr = 0.004
I0526 20:16:31.221132 14297 solver.cpp:237] Iteration 445500, loss = 1.01309
I0526 20:16:31.221308 14297 solver.cpp:253]     Train net output #0: loss = 1.01309 (* 1 = 1.01309 loss)
I0526 20:16:31.221323 14297 sgd_solver.cpp:106] Iteration 445500, lr = 0.004
I0526 20:16:43.348125 14297 solver.cpp:237] Iteration 446250, loss = 1.09036
I0526 20:16:43.348161 14297 solver.cpp:253]     Train net output #0: loss = 1.09037 (* 1 = 1.09037 loss)
I0526 20:16:43.348176 14297 sgd_solver.cpp:106] Iteration 446250, lr = 0.004
I0526 20:16:55.464201 14297 solver.cpp:237] Iteration 447000, loss = 0.874057
I0526 20:16:55.464249 14297 solver.cpp:253]     Train net output #0: loss = 0.874061 (* 1 = 0.874061 loss)
I0526 20:16:55.464263 14297 sgd_solver.cpp:106] Iteration 447000, lr = 0.004
I0526 20:17:07.618340 14297 solver.cpp:237] Iteration 447750, loss = 0.954955
I0526 20:17:07.618499 14297 solver.cpp:253]     Train net output #0: loss = 0.95496 (* 1 = 0.95496 loss)
I0526 20:17:07.618513 14297 sgd_solver.cpp:106] Iteration 447750, lr = 0.004
I0526 20:17:19.763665 14297 solver.cpp:237] Iteration 448500, loss = 1.29357
I0526 20:17:19.763715 14297 solver.cpp:253]     Train net output #0: loss = 1.29357 (* 1 = 1.29357 loss)
I0526 20:17:19.763730 14297 sgd_solver.cpp:106] Iteration 448500, lr = 0.004
I0526 20:17:31.851316 14297 solver.cpp:237] Iteration 449250, loss = 1.19363
I0526 20:17:31.851352 14297 solver.cpp:253]     Train net output #0: loss = 1.19364 (* 1 = 1.19364 loss)
I0526 20:17:31.851366 14297 sgd_solver.cpp:106] Iteration 449250, lr = 0.004
I0526 20:17:43.926122 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_450000.caffemodel
I0526 20:17:43.975606 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_450000.solverstate
I0526 20:17:44.000799 14297 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 20:18:35.686444 14297 solver.cpp:409]     Test net output #0: accuracy = 0.904284
I0526 20:18:35.686620 14297 solver.cpp:409]     Test net output #1: loss = 0.306746 (* 1 = 0.306746 loss)
I0526 20:18:56.616257 14297 solver.cpp:237] Iteration 450000, loss = 1.13107
I0526 20:18:56.616308 14297 solver.cpp:253]     Train net output #0: loss = 1.13107 (* 1 = 1.13107 loss)
I0526 20:18:56.616463 14297 sgd_solver.cpp:106] Iteration 450000, lr = 0.004
I0526 20:19:08.773314 14297 solver.cpp:237] Iteration 450750, loss = 1.26898
I0526 20:19:08.773481 14297 solver.cpp:253]     Train net output #0: loss = 1.26898 (* 1 = 1.26898 loss)
I0526 20:19:08.773494 14297 sgd_solver.cpp:106] Iteration 450750, lr = 0.004
I0526 20:19:20.944125 14297 solver.cpp:237] Iteration 451500, loss = 0.692914
I0526 20:19:20.944172 14297 solver.cpp:253]     Train net output #0: loss = 0.692919 (* 1 = 0.692919 loss)
I0526 20:19:20.944186 14297 sgd_solver.cpp:106] Iteration 451500, lr = 0.004
I0526 20:19:33.143023 14297 solver.cpp:237] Iteration 452250, loss = 1.4295
I0526 20:19:33.143059 14297 solver.cpp:253]     Train net output #0: loss = 1.4295 (* 1 = 1.4295 loss)
I0526 20:19:33.143072 14297 sgd_solver.cpp:106] Iteration 452250, lr = 0.004
I0526 20:19:45.348460 14297 solver.cpp:237] Iteration 453000, loss = 0.855223
I0526 20:19:45.348635 14297 solver.cpp:253]     Train net output #0: loss = 0.855228 (* 1 = 0.855228 loss)
I0526 20:19:45.348649 14297 sgd_solver.cpp:106] Iteration 453000, lr = 0.004
I0526 20:19:57.573899 14297 solver.cpp:237] Iteration 453750, loss = 1.64426
I0526 20:19:57.573935 14297 solver.cpp:253]     Train net output #0: loss = 1.64427 (* 1 = 1.64427 loss)
I0526 20:19:57.573950 14297 sgd_solver.cpp:106] Iteration 453750, lr = 0.004
I0526 20:20:09.798267 14297 solver.cpp:237] Iteration 454500, loss = 1.24281
I0526 20:20:09.798310 14297 solver.cpp:253]     Train net output #0: loss = 1.24281 (* 1 = 1.24281 loss)
I0526 20:20:09.798323 14297 sgd_solver.cpp:106] Iteration 454500, lr = 0.004
I0526 20:20:42.977282 14297 solver.cpp:237] Iteration 455250, loss = 1.00806
I0526 20:20:42.977460 14297 solver.cpp:253]     Train net output #0: loss = 1.00806 (* 1 = 1.00806 loss)
I0526 20:20:42.977476 14297 sgd_solver.cpp:106] Iteration 455250, lr = 0.004
I0526 20:20:55.205036 14297 solver.cpp:237] Iteration 456000, loss = 1.15457
I0526 20:20:55.205071 14297 solver.cpp:253]     Train net output #0: loss = 1.15458 (* 1 = 1.15458 loss)
I0526 20:20:55.205087 14297 sgd_solver.cpp:106] Iteration 456000, lr = 0.004
I0526 20:21:07.375949 14297 solver.cpp:237] Iteration 456750, loss = 1.63202
I0526 20:21:07.375995 14297 solver.cpp:253]     Train net output #0: loss = 1.63203 (* 1 = 1.63203 loss)
I0526 20:21:07.376009 14297 sgd_solver.cpp:106] Iteration 456750, lr = 0.004
I0526 20:21:19.541810 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_457500.caffemodel
I0526 20:21:19.597393 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_457500.solverstate
I0526 20:21:19.628408 14297 solver.cpp:237] Iteration 457500, loss = 1.40278
I0526 20:21:19.628453 14297 solver.cpp:253]     Train net output #0: loss = 1.40278 (* 1 = 1.40278 loss)
I0526 20:21:19.628469 14297 sgd_solver.cpp:106] Iteration 457500, lr = 0.004
I0526 20:21:31.788486 14297 solver.cpp:237] Iteration 458250, loss = 1.25552
I0526 20:21:31.788535 14297 solver.cpp:253]     Train net output #0: loss = 1.25552 (* 1 = 1.25552 loss)
I0526 20:21:31.788549 14297 sgd_solver.cpp:106] Iteration 458250, lr = 0.004
I0526 20:21:43.952491 14297 solver.cpp:237] Iteration 459000, loss = 1.03066
I0526 20:21:43.952527 14297 solver.cpp:253]     Train net output #0: loss = 1.03067 (* 1 = 1.03067 loss)
I0526 20:21:43.952543 14297 sgd_solver.cpp:106] Iteration 459000, lr = 0.004
I0526 20:21:56.139117 14297 solver.cpp:237] Iteration 459750, loss = 1.19628
I0526 20:21:56.139308 14297 solver.cpp:253]     Train net output #0: loss = 1.19629 (* 1 = 1.19629 loss)
I0526 20:21:56.139322 14297 sgd_solver.cpp:106] Iteration 459750, lr = 0.004
I0526 20:22:29.229745 14297 solver.cpp:237] Iteration 460500, loss = 0.955374
I0526 20:22:29.229930 14297 solver.cpp:253]     Train net output #0: loss = 0.955378 (* 1 = 0.955378 loss)
I0526 20:22:29.229945 14297 sgd_solver.cpp:106] Iteration 460500, lr = 0.004
I0526 20:22:41.432744 14297 solver.cpp:237] Iteration 461250, loss = 1.18595
I0526 20:22:41.432790 14297 solver.cpp:253]     Train net output #0: loss = 1.18596 (* 1 = 1.18596 loss)
I0526 20:22:41.432804 14297 sgd_solver.cpp:106] Iteration 461250, lr = 0.004
I0526 20:22:53.628957 14297 solver.cpp:237] Iteration 462000, loss = 0.919337
I0526 20:22:53.628994 14297 solver.cpp:253]     Train net output #0: loss = 0.919342 (* 1 = 0.919342 loss)
I0526 20:22:53.629009 14297 sgd_solver.cpp:106] Iteration 462000, lr = 0.004
I0526 20:23:05.825897 14297 solver.cpp:237] Iteration 462750, loss = 1.02668
I0526 20:23:05.826067 14297 solver.cpp:253]     Train net output #0: loss = 1.02668 (* 1 = 1.02668 loss)
I0526 20:23:05.826082 14297 sgd_solver.cpp:106] Iteration 462750, lr = 0.004
I0526 20:23:18.018120 14297 solver.cpp:237] Iteration 463500, loss = 1.11971
I0526 20:23:18.018156 14297 solver.cpp:253]     Train net output #0: loss = 1.11972 (* 1 = 1.11972 loss)
I0526 20:23:18.018169 14297 sgd_solver.cpp:106] Iteration 463500, lr = 0.004
I0526 20:23:30.200572 14297 solver.cpp:237] Iteration 464250, loss = 0.799266
I0526 20:23:30.200621 14297 solver.cpp:253]     Train net output #0: loss = 0.79927 (* 1 = 0.79927 loss)
I0526 20:23:30.200636 14297 sgd_solver.cpp:106] Iteration 464250, lr = 0.004
I0526 20:23:42.403635 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_465000.caffemodel
I0526 20:23:42.456317 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_465000.solverstate
I0526 20:23:42.483535 14297 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 20:24:55.377960 14297 solver.cpp:409]     Test net output #0: accuracy = 0.900637
I0526 20:24:55.378118 14297 solver.cpp:409]     Test net output #1: loss = 0.333352 (* 1 = 0.333352 loss)
I0526 20:25:16.291353 14297 solver.cpp:237] Iteration 465000, loss = 0.856019
I0526 20:25:16.291407 14297 solver.cpp:253]     Train net output #0: loss = 0.856023 (* 1 = 0.856023 loss)
I0526 20:25:16.291424 14297 sgd_solver.cpp:106] Iteration 465000, lr = 0.004
I0526 20:25:28.355792 14297 solver.cpp:237] Iteration 465750, loss = 1.33463
I0526 20:25:28.355969 14297 solver.cpp:253]     Train net output #0: loss = 1.33464 (* 1 = 1.33464 loss)
I0526 20:25:28.355985 14297 sgd_solver.cpp:106] Iteration 465750, lr = 0.004
I0526 20:25:40.454659 14297 solver.cpp:237] Iteration 466500, loss = 1.06328
I0526 20:25:40.454707 14297 solver.cpp:253]     Train net output #0: loss = 1.06328 (* 1 = 1.06328 loss)
I0526 20:25:40.454721 14297 sgd_solver.cpp:106] Iteration 466500, lr = 0.004
I0526 20:25:52.582311 14297 solver.cpp:237] Iteration 467250, loss = 1.19456
I0526 20:25:52.582348 14297 solver.cpp:253]     Train net output #0: loss = 1.19457 (* 1 = 1.19457 loss)
I0526 20:25:52.582362 14297 sgd_solver.cpp:106] Iteration 467250, lr = 0.004
I0526 20:26:04.733722 14297 solver.cpp:237] Iteration 468000, loss = 1.48777
I0526 20:26:04.733896 14297 solver.cpp:253]     Train net output #0: loss = 1.48778 (* 1 = 1.48778 loss)
I0526 20:26:04.733911 14297 sgd_solver.cpp:106] Iteration 468000, lr = 0.004
I0526 20:26:16.893788 14297 solver.cpp:237] Iteration 468750, loss = 1.06202
I0526 20:26:16.893824 14297 solver.cpp:253]     Train net output #0: loss = 1.06203 (* 1 = 1.06203 loss)
I0526 20:26:16.893838 14297 sgd_solver.cpp:106] Iteration 468750, lr = 0.004
I0526 20:26:29.024440 14297 solver.cpp:237] Iteration 469500, loss = 1.27492
I0526 20:26:29.024484 14297 solver.cpp:253]     Train net output #0: loss = 1.27493 (* 1 = 1.27493 loss)
I0526 20:26:29.024498 14297 sgd_solver.cpp:106] Iteration 469500, lr = 0.004
I0526 20:27:02.107936 14297 solver.cpp:237] Iteration 470250, loss = 1.09564
I0526 20:27:02.108137 14297 solver.cpp:253]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0526 20:27:02.108155 14297 sgd_solver.cpp:106] Iteration 470250, lr = 0.004
I0526 20:27:14.258774 14297 solver.cpp:237] Iteration 471000, loss = 1.43289
I0526 20:27:14.258822 14297 solver.cpp:253]     Train net output #0: loss = 1.43289 (* 1 = 1.43289 loss)
I0526 20:27:14.258837 14297 sgd_solver.cpp:106] Iteration 471000, lr = 0.004
I0526 20:27:26.387138 14297 solver.cpp:237] Iteration 471750, loss = 1.17445
I0526 20:27:26.387174 14297 solver.cpp:253]     Train net output #0: loss = 1.17445 (* 1 = 1.17445 loss)
I0526 20:27:26.387190 14297 sgd_solver.cpp:106] Iteration 471750, lr = 0.004
I0526 20:27:38.490988 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_472500.caffemodel
I0526 20:27:38.542563 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_472500.solverstate
I0526 20:27:38.575448 14297 solver.cpp:237] Iteration 472500, loss = 1.09115
I0526 20:27:38.575500 14297 solver.cpp:253]     Train net output #0: loss = 1.09115 (* 1 = 1.09115 loss)
I0526 20:27:38.575513 14297 sgd_solver.cpp:106] Iteration 472500, lr = 0.004
I0526 20:27:50.619067 14297 solver.cpp:237] Iteration 473250, loss = 0.693347
I0526 20:27:50.619104 14297 solver.cpp:253]     Train net output #0: loss = 0.693352 (* 1 = 0.693352 loss)
I0526 20:27:50.619118 14297 sgd_solver.cpp:106] Iteration 473250, lr = 0.004
I0526 20:28:02.664191 14297 solver.cpp:237] Iteration 474000, loss = 0.891234
I0526 20:28:02.664228 14297 solver.cpp:253]     Train net output #0: loss = 0.891238 (* 1 = 0.891238 loss)
I0526 20:28:02.664242 14297 sgd_solver.cpp:106] Iteration 474000, lr = 0.004
I0526 20:28:14.751057 14297 solver.cpp:237] Iteration 474750, loss = 1.18727
I0526 20:28:14.751235 14297 solver.cpp:253]     Train net output #0: loss = 1.18728 (* 1 = 1.18728 loss)
I0526 20:28:14.751248 14297 sgd_solver.cpp:106] Iteration 474750, lr = 0.004
I0526 20:28:47.708976 14297 solver.cpp:237] Iteration 475500, loss = 1.07293
I0526 20:28:47.709159 14297 solver.cpp:253]     Train net output #0: loss = 1.07293 (* 1 = 1.07293 loss)
I0526 20:28:47.709174 14297 sgd_solver.cpp:106] Iteration 475500, lr = 0.004
I0526 20:28:59.802224 14297 solver.cpp:237] Iteration 476250, loss = 0.887689
I0526 20:28:59.802273 14297 solver.cpp:253]     Train net output #0: loss = 0.887693 (* 1 = 0.887693 loss)
I0526 20:28:59.802287 14297 sgd_solver.cpp:106] Iteration 476250, lr = 0.004
I0526 20:29:11.914890 14297 solver.cpp:237] Iteration 477000, loss = 1.62894
I0526 20:29:11.914926 14297 solver.cpp:253]     Train net output #0: loss = 1.62894 (* 1 = 1.62894 loss)
I0526 20:29:11.914939 14297 sgd_solver.cpp:106] Iteration 477000, lr = 0.004
I0526 20:29:24.046222 14297 solver.cpp:237] Iteration 477750, loss = 1.02136
I0526 20:29:24.046396 14297 solver.cpp:253]     Train net output #0: loss = 1.02136 (* 1 = 1.02136 loss)
I0526 20:29:24.046411 14297 sgd_solver.cpp:106] Iteration 477750, lr = 0.004
I0526 20:29:36.108646 14297 solver.cpp:237] Iteration 478500, loss = 1.28054
I0526 20:29:36.108682 14297 solver.cpp:253]     Train net output #0: loss = 1.28054 (* 1 = 1.28054 loss)
I0526 20:29:36.108697 14297 sgd_solver.cpp:106] Iteration 478500, lr = 0.004
I0526 20:29:48.192333 14297 solver.cpp:237] Iteration 479250, loss = 0.861841
I0526 20:29:48.192383 14297 solver.cpp:253]     Train net output #0: loss = 0.861845 (* 1 = 0.861845 loss)
I0526 20:29:48.192397 14297 sgd_solver.cpp:106] Iteration 479250, lr = 0.004
I0526 20:30:00.348284 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_480000.caffemodel
I0526 20:30:00.397691 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_480000.solverstate
I0526 20:30:00.423112 14297 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 20:30:52.469566 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903219
I0526 20:30:52.469750 14297 solver.cpp:409]     Test net output #1: loss = 0.315791 (* 1 = 0.315791 loss)
I0526 20:31:13.357578 14297 solver.cpp:237] Iteration 480000, loss = 0.880498
I0526 20:31:13.357633 14297 solver.cpp:253]     Train net output #0: loss = 0.880503 (* 1 = 0.880503 loss)
I0526 20:31:13.357648 14297 sgd_solver.cpp:106] Iteration 480000, lr = 0.004
I0526 20:31:25.506592 14297 solver.cpp:237] Iteration 480750, loss = 0.87308
I0526 20:31:25.506772 14297 solver.cpp:253]     Train net output #0: loss = 0.873084 (* 1 = 0.873084 loss)
I0526 20:31:25.506786 14297 sgd_solver.cpp:106] Iteration 480750, lr = 0.004
I0526 20:31:37.666412 14297 solver.cpp:237] Iteration 481500, loss = 1.05644
I0526 20:31:37.666448 14297 solver.cpp:253]     Train net output #0: loss = 1.05644 (* 1 = 1.05644 loss)
I0526 20:31:37.666462 14297 sgd_solver.cpp:106] Iteration 481500, lr = 0.004
I0526 20:31:49.771103 14297 solver.cpp:237] Iteration 482250, loss = 1.27748
I0526 20:31:49.771154 14297 solver.cpp:253]     Train net output #0: loss = 1.27748 (* 1 = 1.27748 loss)
I0526 20:31:49.771168 14297 sgd_solver.cpp:106] Iteration 482250, lr = 0.004
I0526 20:32:01.911949 14297 solver.cpp:237] Iteration 483000, loss = 1.15509
I0526 20:32:01.912116 14297 solver.cpp:253]     Train net output #0: loss = 1.15509 (* 1 = 1.15509 loss)
I0526 20:32:01.912130 14297 sgd_solver.cpp:106] Iteration 483000, lr = 0.004
I0526 20:32:14.055528 14297 solver.cpp:237] Iteration 483750, loss = 0.936869
I0526 20:32:14.055578 14297 solver.cpp:253]     Train net output #0: loss = 0.936874 (* 1 = 0.936874 loss)
I0526 20:32:14.055593 14297 sgd_solver.cpp:106] Iteration 483750, lr = 0.004
I0526 20:32:26.210645 14297 solver.cpp:237] Iteration 484500, loss = 1.23277
I0526 20:32:26.210681 14297 solver.cpp:253]     Train net output #0: loss = 1.23278 (* 1 = 1.23278 loss)
I0526 20:32:26.210695 14297 sgd_solver.cpp:106] Iteration 484500, lr = 0.004
I0526 20:32:59.245298 14297 solver.cpp:237] Iteration 485250, loss = 1.35763
I0526 20:32:59.245487 14297 solver.cpp:253]     Train net output #0: loss = 1.35764 (* 1 = 1.35764 loss)
I0526 20:32:59.245503 14297 sgd_solver.cpp:106] Iteration 485250, lr = 0.004
I0526 20:33:11.389289 14297 solver.cpp:237] Iteration 486000, loss = 1.14687
I0526 20:33:11.389339 14297 solver.cpp:253]     Train net output #0: loss = 1.14688 (* 1 = 1.14688 loss)
I0526 20:33:11.389353 14297 sgd_solver.cpp:106] Iteration 486000, lr = 0.004
I0526 20:33:23.502671 14297 solver.cpp:237] Iteration 486750, loss = 1.04208
I0526 20:33:23.502707 14297 solver.cpp:253]     Train net output #0: loss = 1.04208 (* 1 = 1.04208 loss)
I0526 20:33:23.502720 14297 sgd_solver.cpp:106] Iteration 486750, lr = 0.004
I0526 20:33:35.589838 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_487500.caffemodel
I0526 20:33:35.639444 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_487500.solverstate
I0526 20:33:35.670171 14297 solver.cpp:237] Iteration 487500, loss = 1.42308
I0526 20:33:35.670212 14297 solver.cpp:253]     Train net output #0: loss = 1.42308 (* 1 = 1.42308 loss)
I0526 20:33:35.670225 14297 sgd_solver.cpp:106] Iteration 487500, lr = 0.004
I0526 20:33:47.747748 14297 solver.cpp:237] Iteration 488250, loss = 0.763513
I0526 20:33:47.747784 14297 solver.cpp:253]     Train net output #0: loss = 0.763517 (* 1 = 0.763517 loss)
I0526 20:33:47.747798 14297 sgd_solver.cpp:106] Iteration 488250, lr = 0.004
I0526 20:33:59.878285 14297 solver.cpp:237] Iteration 489000, loss = 1.32881
I0526 20:33:59.878331 14297 solver.cpp:253]     Train net output #0: loss = 1.32882 (* 1 = 1.32882 loss)
I0526 20:33:59.878346 14297 sgd_solver.cpp:106] Iteration 489000, lr = 0.004
I0526 20:34:11.989904 14297 solver.cpp:237] Iteration 489750, loss = 0.715112
I0526 20:34:11.990082 14297 solver.cpp:253]     Train net output #0: loss = 0.715117 (* 1 = 0.715117 loss)
I0526 20:34:11.990097 14297 sgd_solver.cpp:106] Iteration 489750, lr = 0.004
I0526 20:34:45.026264 14297 solver.cpp:237] Iteration 490500, loss = 0.972596
I0526 20:34:45.026451 14297 solver.cpp:253]     Train net output #0: loss = 0.9726 (* 1 = 0.9726 loss)
I0526 20:34:45.026466 14297 sgd_solver.cpp:106] Iteration 490500, lr = 0.004
I0526 20:34:57.201681 14297 solver.cpp:237] Iteration 491250, loss = 1.81255
I0526 20:34:57.201719 14297 solver.cpp:253]     Train net output #0: loss = 1.81255 (* 1 = 1.81255 loss)
I0526 20:34:57.201732 14297 sgd_solver.cpp:106] Iteration 491250, lr = 0.004
I0526 20:35:09.370973 14297 solver.cpp:237] Iteration 492000, loss = 0.989975
I0526 20:35:09.371022 14297 solver.cpp:253]     Train net output #0: loss = 0.989979 (* 1 = 0.989979 loss)
I0526 20:35:09.371036 14297 sgd_solver.cpp:106] Iteration 492000, lr = 0.004
I0526 20:35:21.473376 14297 solver.cpp:237] Iteration 492750, loss = 1.49749
I0526 20:35:21.473551 14297 solver.cpp:253]     Train net output #0: loss = 1.49749 (* 1 = 1.49749 loss)
I0526 20:35:21.473567 14297 sgd_solver.cpp:106] Iteration 492750, lr = 0.004
I0526 20:35:33.592521 14297 solver.cpp:237] Iteration 493500, loss = 1.14949
I0526 20:35:33.592566 14297 solver.cpp:253]     Train net output #0: loss = 1.1495 (* 1 = 1.1495 loss)
I0526 20:35:33.592582 14297 sgd_solver.cpp:106] Iteration 493500, lr = 0.004
I0526 20:35:45.692836 14297 solver.cpp:237] Iteration 494250, loss = 1.24577
I0526 20:35:45.692872 14297 solver.cpp:253]     Train net output #0: loss = 1.24577 (* 1 = 1.24577 loss)
I0526 20:35:45.692885 14297 sgd_solver.cpp:106] Iteration 494250, lr = 0.004
I0526 20:35:57.780997 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_495000.caffemodel
I0526 20:35:57.830338 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_495000.solverstate
I0526 20:35:57.856287 14297 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 20:37:10.924741 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903125
I0526 20:37:10.924924 14297 solver.cpp:409]     Test net output #1: loss = 0.307418 (* 1 = 0.307418 loss)
I0526 20:37:32.020596 14297 solver.cpp:237] Iteration 495000, loss = 1.68761
I0526 20:37:32.020648 14297 solver.cpp:253]     Train net output #0: loss = 1.68762 (* 1 = 1.68762 loss)
I0526 20:37:32.020663 14297 sgd_solver.cpp:106] Iteration 495000, lr = 0.004
I0526 20:37:44.175644 14297 solver.cpp:237] Iteration 495750, loss = 0.809562
I0526 20:37:44.175823 14297 solver.cpp:253]     Train net output #0: loss = 0.809566 (* 1 = 0.809566 loss)
I0526 20:37:44.175837 14297 sgd_solver.cpp:106] Iteration 495750, lr = 0.004
I0526 20:37:56.299991 14297 solver.cpp:237] Iteration 496500, loss = 1.09754
I0526 20:37:56.300029 14297 solver.cpp:253]     Train net output #0: loss = 1.09754 (* 1 = 1.09754 loss)
I0526 20:37:56.300042 14297 sgd_solver.cpp:106] Iteration 496500, lr = 0.004
I0526 20:38:08.451992 14297 solver.cpp:237] Iteration 497250, loss = 1.23902
I0526 20:38:08.452041 14297 solver.cpp:253]     Train net output #0: loss = 1.23902 (* 1 = 1.23902 loss)
I0526 20:38:08.452054 14297 sgd_solver.cpp:106] Iteration 497250, lr = 0.004
I0526 20:38:20.619560 14297 solver.cpp:237] Iteration 498000, loss = 1.00415
I0526 20:38:20.619740 14297 solver.cpp:253]     Train net output #0: loss = 1.00416 (* 1 = 1.00416 loss)
I0526 20:38:20.619753 14297 sgd_solver.cpp:106] Iteration 498000, lr = 0.004
I0526 20:38:32.747320 14297 solver.cpp:237] Iteration 498750, loss = 1.36767
I0526 20:38:32.747370 14297 solver.cpp:253]     Train net output #0: loss = 1.36767 (* 1 = 1.36767 loss)
I0526 20:38:32.747385 14297 sgd_solver.cpp:106] Iteration 498750, lr = 0.004
I0526 20:38:44.883147 14297 solver.cpp:237] Iteration 499500, loss = 1.06355
I0526 20:38:44.883182 14297 solver.cpp:253]     Train net output #0: loss = 1.06355 (* 1 = 1.06355 loss)
I0526 20:38:44.883195 14297 sgd_solver.cpp:106] Iteration 499500, lr = 0.004
I0526 20:39:17.961522 14297 solver.cpp:237] Iteration 500250, loss = 0.824937
I0526 20:39:17.961711 14297 solver.cpp:253]     Train net output #0: loss = 0.824942 (* 1 = 0.824942 loss)
I0526 20:39:17.961726 14297 sgd_solver.cpp:106] Iteration 500250, lr = 0.004
I0526 20:39:30.101387 14297 solver.cpp:237] Iteration 501000, loss = 1.41716
I0526 20:39:30.101431 14297 solver.cpp:253]     Train net output #0: loss = 1.41716 (* 1 = 1.41716 loss)
I0526 20:39:30.101445 14297 sgd_solver.cpp:106] Iteration 501000, lr = 0.004
I0526 20:39:42.265899 14297 solver.cpp:237] Iteration 501750, loss = 1.00727
I0526 20:39:42.265935 14297 solver.cpp:253]     Train net output #0: loss = 1.00728 (* 1 = 1.00728 loss)
I0526 20:39:42.265949 14297 sgd_solver.cpp:106] Iteration 501750, lr = 0.004
I0526 20:39:54.433311 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_502500.caffemodel
I0526 20:39:54.485261 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_502500.solverstate
I0526 20:39:54.517707 14297 solver.cpp:237] Iteration 502500, loss = 1.55099
I0526 20:39:54.517757 14297 solver.cpp:253]     Train net output #0: loss = 1.55099 (* 1 = 1.55099 loss)
I0526 20:39:54.517773 14297 sgd_solver.cpp:106] Iteration 502500, lr = 0.004
I0526 20:40:06.681906 14297 solver.cpp:237] Iteration 503250, loss = 1.20269
I0526 20:40:06.681941 14297 solver.cpp:253]     Train net output #0: loss = 1.20269 (* 1 = 1.20269 loss)
I0526 20:40:06.681956 14297 sgd_solver.cpp:106] Iteration 503250, lr = 0.004
I0526 20:40:18.845782 14297 solver.cpp:237] Iteration 504000, loss = 2.15837
I0526 20:40:18.845835 14297 solver.cpp:253]     Train net output #0: loss = 2.15837 (* 1 = 2.15837 loss)
I0526 20:40:18.845849 14297 sgd_solver.cpp:106] Iteration 504000, lr = 0.004
I0526 20:40:31.039959 14297 solver.cpp:237] Iteration 504750, loss = 1.03645
I0526 20:40:31.040148 14297 solver.cpp:253]     Train net output #0: loss = 1.03645 (* 1 = 1.03645 loss)
I0526 20:40:31.040163 14297 sgd_solver.cpp:106] Iteration 504750, lr = 0.004
I0526 20:41:04.126145 14297 solver.cpp:237] Iteration 505500, loss = 1.05103
I0526 20:41:04.126329 14297 solver.cpp:253]     Train net output #0: loss = 1.05104 (* 1 = 1.05104 loss)
I0526 20:41:04.126346 14297 sgd_solver.cpp:106] Iteration 505500, lr = 0.004
I0526 20:41:16.275519 14297 solver.cpp:237] Iteration 506250, loss = 0.765398
I0526 20:41:16.275555 14297 solver.cpp:253]     Train net output #0: loss = 0.765402 (* 1 = 0.765402 loss)
I0526 20:41:16.275569 14297 sgd_solver.cpp:106] Iteration 506250, lr = 0.004
I0526 20:41:28.453068 14297 solver.cpp:237] Iteration 507000, loss = 0.949585
I0526 20:41:28.453115 14297 solver.cpp:253]     Train net output #0: loss = 0.949589 (* 1 = 0.949589 loss)
I0526 20:41:28.453130 14297 sgd_solver.cpp:106] Iteration 507000, lr = 0.004
I0526 20:41:40.633776 14297 solver.cpp:237] Iteration 507750, loss = 1.07862
I0526 20:41:40.633950 14297 solver.cpp:253]     Train net output #0: loss = 1.07862 (* 1 = 1.07862 loss)
I0526 20:41:40.633966 14297 sgd_solver.cpp:106] Iteration 507750, lr = 0.004
I0526 20:41:52.812872 14297 solver.cpp:237] Iteration 508500, loss = 1.89653
I0526 20:41:52.812919 14297 solver.cpp:253]     Train net output #0: loss = 1.89653 (* 1 = 1.89653 loss)
I0526 20:41:52.812933 14297 sgd_solver.cpp:106] Iteration 508500, lr = 0.004
I0526 20:42:04.951689 14297 solver.cpp:237] Iteration 509250, loss = 1.16385
I0526 20:42:04.951725 14297 solver.cpp:253]     Train net output #0: loss = 1.16385 (* 1 = 1.16385 loss)
I0526 20:42:04.951740 14297 sgd_solver.cpp:106] Iteration 509250, lr = 0.004
I0526 20:42:17.057903 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_510000.caffemodel
I0526 20:42:17.110566 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_510000.solverstate
I0526 20:42:17.138591 14297 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 20:43:08.723408 14297 solver.cpp:409]     Test net output #0: accuracy = 0.902645
I0526 20:43:08.723593 14297 solver.cpp:409]     Test net output #1: loss = 0.295427 (* 1 = 0.295427 loss)
I0526 20:43:29.604079 14297 solver.cpp:237] Iteration 510000, loss = 0.875541
I0526 20:43:29.604138 14297 solver.cpp:253]     Train net output #0: loss = 0.875545 (* 1 = 0.875545 loss)
I0526 20:43:29.604154 14297 sgd_solver.cpp:106] Iteration 510000, lr = 0.004
I0526 20:43:41.768309 14297 solver.cpp:237] Iteration 510750, loss = 1.01333
I0526 20:43:41.768482 14297 solver.cpp:253]     Train net output #0: loss = 1.01333 (* 1 = 1.01333 loss)
I0526 20:43:41.768496 14297 sgd_solver.cpp:106] Iteration 510750, lr = 0.004
I0526 20:43:53.932548 14297 solver.cpp:237] Iteration 511500, loss = 0.778788
I0526 20:43:53.932601 14297 solver.cpp:253]     Train net output #0: loss = 0.778793 (* 1 = 0.778793 loss)
I0526 20:43:53.932615 14297 sgd_solver.cpp:106] Iteration 511500, lr = 0.004
I0526 20:44:06.087512 14297 solver.cpp:237] Iteration 512250, loss = 1.33098
I0526 20:44:06.087548 14297 solver.cpp:253]     Train net output #0: loss = 1.33098 (* 1 = 1.33098 loss)
I0526 20:44:06.087563 14297 sgd_solver.cpp:106] Iteration 512250, lr = 0.004
I0526 20:44:18.233479 14297 solver.cpp:237] Iteration 513000, loss = 1.12627
I0526 20:44:18.233644 14297 solver.cpp:253]     Train net output #0: loss = 1.12628 (* 1 = 1.12628 loss)
I0526 20:44:18.233661 14297 sgd_solver.cpp:106] Iteration 513000, lr = 0.004
I0526 20:44:30.368360 14297 solver.cpp:237] Iteration 513750, loss = 1.31759
I0526 20:44:30.368404 14297 solver.cpp:253]     Train net output #0: loss = 1.3176 (* 1 = 1.3176 loss)
I0526 20:44:30.368418 14297 sgd_solver.cpp:106] Iteration 513750, lr = 0.004
I0526 20:44:42.508632 14297 solver.cpp:237] Iteration 514500, loss = 0.966445
I0526 20:44:42.508669 14297 solver.cpp:253]     Train net output #0: loss = 0.96645 (* 1 = 0.96645 loss)
I0526 20:44:42.508683 14297 sgd_solver.cpp:106] Iteration 514500, lr = 0.004
I0526 20:45:15.518807 14297 solver.cpp:237] Iteration 515250, loss = 1.26721
I0526 20:45:15.519006 14297 solver.cpp:253]     Train net output #0: loss = 1.26722 (* 1 = 1.26722 loss)
I0526 20:45:15.519021 14297 sgd_solver.cpp:106] Iteration 515250, lr = 0.004
I0526 20:45:27.655130 14297 solver.cpp:237] Iteration 516000, loss = 1.21796
I0526 20:45:27.655166 14297 solver.cpp:253]     Train net output #0: loss = 1.21796 (* 1 = 1.21796 loss)
I0526 20:45:27.655180 14297 sgd_solver.cpp:106] Iteration 516000, lr = 0.004
I0526 20:45:39.830615 14297 solver.cpp:237] Iteration 516750, loss = 1.99662
I0526 20:45:39.830665 14297 solver.cpp:253]     Train net output #0: loss = 1.99663 (* 1 = 1.99663 loss)
I0526 20:45:39.830678 14297 sgd_solver.cpp:106] Iteration 516750, lr = 0.004
I0526 20:45:51.992578 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_517500.caffemodel
I0526 20:45:52.042145 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_517500.solverstate
I0526 20:45:52.072603 14297 solver.cpp:237] Iteration 517500, loss = 1.07226
I0526 20:45:52.072648 14297 solver.cpp:253]     Train net output #0: loss = 1.07227 (* 1 = 1.07227 loss)
I0526 20:45:52.072664 14297 sgd_solver.cpp:106] Iteration 517500, lr = 0.004
I0526 20:46:04.233089 14297 solver.cpp:237] Iteration 518250, loss = 1.57465
I0526 20:46:04.233140 14297 solver.cpp:253]     Train net output #0: loss = 1.57466 (* 1 = 1.57466 loss)
I0526 20:46:04.233155 14297 sgd_solver.cpp:106] Iteration 518250, lr = 0.004
I0526 20:46:16.374583 14297 solver.cpp:237] Iteration 519000, loss = 0.906659
I0526 20:46:16.374620 14297 solver.cpp:253]     Train net output #0: loss = 0.906664 (* 1 = 0.906664 loss)
I0526 20:46:16.374634 14297 sgd_solver.cpp:106] Iteration 519000, lr = 0.004
I0526 20:46:28.465875 14297 solver.cpp:237] Iteration 519750, loss = 0.959514
I0526 20:46:28.466063 14297 solver.cpp:253]     Train net output #0: loss = 0.959519 (* 1 = 0.959519 loss)
I0526 20:46:28.466079 14297 sgd_solver.cpp:106] Iteration 519750, lr = 0.004
I0526 20:47:01.497131 14297 solver.cpp:237] Iteration 520500, loss = 1.22794
I0526 20:47:01.497320 14297 solver.cpp:253]     Train net output #0: loss = 1.22794 (* 1 = 1.22794 loss)
I0526 20:47:01.497334 14297 sgd_solver.cpp:106] Iteration 520500, lr = 0.004
I0526 20:47:13.607708 14297 solver.cpp:237] Iteration 521250, loss = 1.07433
I0526 20:47:13.607753 14297 solver.cpp:253]     Train net output #0: loss = 1.07434 (* 1 = 1.07434 loss)
I0526 20:47:13.607769 14297 sgd_solver.cpp:106] Iteration 521250, lr = 0.004
I0526 20:47:25.750699 14297 solver.cpp:237] Iteration 522000, loss = 0.766879
I0526 20:47:25.750735 14297 solver.cpp:253]     Train net output #0: loss = 0.766884 (* 1 = 0.766884 loss)
I0526 20:47:25.750749 14297 sgd_solver.cpp:106] Iteration 522000, lr = 0.004
I0526 20:47:37.904165 14297 solver.cpp:237] Iteration 522750, loss = 1.15246
I0526 20:47:37.904330 14297 solver.cpp:253]     Train net output #0: loss = 1.15247 (* 1 = 1.15247 loss)
I0526 20:47:37.904342 14297 sgd_solver.cpp:106] Iteration 522750, lr = 0.004
I0526 20:47:50.034579 14297 solver.cpp:237] Iteration 523500, loss = 1.0898
I0526 20:47:50.034618 14297 solver.cpp:253]     Train net output #0: loss = 1.0898 (* 1 = 1.0898 loss)
I0526 20:47:50.034631 14297 sgd_solver.cpp:106] Iteration 523500, lr = 0.004
I0526 20:48:02.187008 14297 solver.cpp:237] Iteration 524250, loss = 0.965275
I0526 20:48:02.187046 14297 solver.cpp:253]     Train net output #0: loss = 0.96528 (* 1 = 0.96528 loss)
I0526 20:48:02.187059 14297 sgd_solver.cpp:106] Iteration 524250, lr = 0.004
I0526 20:48:14.290740 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_525000.caffemodel
I0526 20:48:14.340142 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_525000.solverstate
I0526 20:48:14.365660 14297 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 20:49:27.251587 14297 solver.cpp:409]     Test net output #0: accuracy = 0.902678
I0526 20:49:27.251777 14297 solver.cpp:409]     Test net output #1: loss = 0.308133 (* 1 = 0.308133 loss)
I0526 20:49:48.149286 14297 solver.cpp:237] Iteration 525000, loss = 0.983862
I0526 20:49:48.149341 14297 solver.cpp:253]     Train net output #0: loss = 0.983867 (* 1 = 0.983867 loss)
I0526 20:49:48.149358 14297 sgd_solver.cpp:106] Iteration 525000, lr = 0.004
I0526 20:50:00.377009 14297 solver.cpp:237] Iteration 525750, loss = 1.38718
I0526 20:50:00.377182 14297 solver.cpp:253]     Train net output #0: loss = 1.38718 (* 1 = 1.38718 loss)
I0526 20:50:00.377197 14297 sgd_solver.cpp:106] Iteration 525750, lr = 0.004
I0526 20:50:12.580850 14297 solver.cpp:237] Iteration 526500, loss = 1.02542
I0526 20:50:12.580898 14297 solver.cpp:253]     Train net output #0: loss = 1.02543 (* 1 = 1.02543 loss)
I0526 20:50:12.580911 14297 sgd_solver.cpp:106] Iteration 526500, lr = 0.004
I0526 20:50:24.767786 14297 solver.cpp:237] Iteration 527250, loss = 1.45435
I0526 20:50:24.767822 14297 solver.cpp:253]     Train net output #0: loss = 1.45435 (* 1 = 1.45435 loss)
I0526 20:50:24.767835 14297 sgd_solver.cpp:106] Iteration 527250, lr = 0.004
I0526 20:50:36.999053 14297 solver.cpp:237] Iteration 528000, loss = 1.36323
I0526 20:50:36.999244 14297 solver.cpp:253]     Train net output #0: loss = 1.36323 (* 1 = 1.36323 loss)
I0526 20:50:36.999258 14297 sgd_solver.cpp:106] Iteration 528000, lr = 0.004
I0526 20:50:49.218924 14297 solver.cpp:237] Iteration 528750, loss = 1.21408
I0526 20:50:49.218961 14297 solver.cpp:253]     Train net output #0: loss = 1.21408 (* 1 = 1.21408 loss)
I0526 20:50:49.218974 14297 sgd_solver.cpp:106] Iteration 528750, lr = 0.004
I0526 20:51:01.461649 14297 solver.cpp:237] Iteration 529500, loss = 0.844999
I0526 20:51:01.461696 14297 solver.cpp:253]     Train net output #0: loss = 0.845004 (* 1 = 0.845004 loss)
I0526 20:51:01.461710 14297 sgd_solver.cpp:106] Iteration 529500, lr = 0.004
I0526 20:51:34.565520 14297 solver.cpp:237] Iteration 530250, loss = 1.3599
I0526 20:51:34.565709 14297 solver.cpp:253]     Train net output #0: loss = 1.3599 (* 1 = 1.3599 loss)
I0526 20:51:34.565724 14297 sgd_solver.cpp:106] Iteration 530250, lr = 0.004
I0526 20:51:46.751767 14297 solver.cpp:237] Iteration 531000, loss = 0.950398
I0526 20:51:46.751806 14297 solver.cpp:253]     Train net output #0: loss = 0.950403 (* 1 = 0.950403 loss)
I0526 20:51:46.751819 14297 sgd_solver.cpp:106] Iteration 531000, lr = 0.004
I0526 20:51:58.941004 14297 solver.cpp:237] Iteration 531750, loss = 1.03249
I0526 20:51:58.941050 14297 solver.cpp:253]     Train net output #0: loss = 1.03249 (* 1 = 1.03249 loss)
I0526 20:51:58.941063 14297 sgd_solver.cpp:106] Iteration 531750, lr = 0.004
I0526 20:52:11.106395 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_532500.caffemodel
I0526 20:52:11.155982 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_532500.solverstate
I0526 20:52:11.189479 14297 solver.cpp:237] Iteration 532500, loss = 1.40074
I0526 20:52:11.189530 14297 solver.cpp:253]     Train net output #0: loss = 1.40074 (* 1 = 1.40074 loss)
I0526 20:52:11.189545 14297 sgd_solver.cpp:106] Iteration 532500, lr = 0.004
I0526 20:52:23.364374 14297 solver.cpp:237] Iteration 533250, loss = 1.02333
I0526 20:52:23.364423 14297 solver.cpp:253]     Train net output #0: loss = 1.02334 (* 1 = 1.02334 loss)
I0526 20:52:23.364437 14297 sgd_solver.cpp:106] Iteration 533250, lr = 0.004
I0526 20:52:35.550107 14297 solver.cpp:237] Iteration 534000, loss = 0.944147
I0526 20:52:35.550143 14297 solver.cpp:253]     Train net output #0: loss = 0.944152 (* 1 = 0.944152 loss)
I0526 20:52:35.550158 14297 sgd_solver.cpp:106] Iteration 534000, lr = 0.004
I0526 20:52:47.715200 14297 solver.cpp:237] Iteration 534750, loss = 1.30336
I0526 20:52:47.715389 14297 solver.cpp:253]     Train net output #0: loss = 1.30336 (* 1 = 1.30336 loss)
I0526 20:52:47.715404 14297 sgd_solver.cpp:106] Iteration 534750, lr = 0.004
I0526 20:53:20.777573 14297 solver.cpp:237] Iteration 535500, loss = 1.20025
I0526 20:53:20.777767 14297 solver.cpp:253]     Train net output #0: loss = 1.20025 (* 1 = 1.20025 loss)
I0526 20:53:20.777784 14297 sgd_solver.cpp:106] Iteration 535500, lr = 0.004
I0526 20:53:32.931238 14297 solver.cpp:237] Iteration 536250, loss = 1.27312
I0526 20:53:32.931287 14297 solver.cpp:253]     Train net output #0: loss = 1.27313 (* 1 = 1.27313 loss)
I0526 20:53:32.931301 14297 sgd_solver.cpp:106] Iteration 536250, lr = 0.004
I0526 20:53:45.139698 14297 solver.cpp:237] Iteration 537000, loss = 0.866924
I0526 20:53:45.139734 14297 solver.cpp:253]     Train net output #0: loss = 0.866929 (* 1 = 0.866929 loss)
I0526 20:53:45.139750 14297 sgd_solver.cpp:106] Iteration 537000, lr = 0.004
I0526 20:53:57.364699 14297 solver.cpp:237] Iteration 537750, loss = 1.28014
I0526 20:53:57.364892 14297 solver.cpp:253]     Train net output #0: loss = 1.28015 (* 1 = 1.28015 loss)
I0526 20:53:57.364907 14297 sgd_solver.cpp:106] Iteration 537750, lr = 0.004
I0526 20:54:09.625478 14297 solver.cpp:237] Iteration 538500, loss = 0.863542
I0526 20:54:09.625515 14297 solver.cpp:253]     Train net output #0: loss = 0.863547 (* 1 = 0.863547 loss)
I0526 20:54:09.625530 14297 sgd_solver.cpp:106] Iteration 538500, lr = 0.004
I0526 20:54:21.874689 14297 solver.cpp:237] Iteration 539250, loss = 0.831577
I0526 20:54:21.874737 14297 solver.cpp:253]     Train net output #0: loss = 0.831583 (* 1 = 0.831583 loss)
I0526 20:54:21.874750 14297 sgd_solver.cpp:106] Iteration 539250, lr = 0.004
I0526 20:54:34.125360 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_540000.caffemodel
I0526 20:54:34.176924 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_540000.solverstate
I0526 20:54:34.203912 14297 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 20:55:26.179807 14297 solver.cpp:409]     Test net output #0: accuracy = 0.899972
I0526 20:55:26.179998 14297 solver.cpp:409]     Test net output #1: loss = 0.313277 (* 1 = 0.313277 loss)
I0526 20:55:47.091285 14297 solver.cpp:237] Iteration 540000, loss = 0.905658
I0526 20:55:47.091338 14297 solver.cpp:253]     Train net output #0: loss = 0.905664 (* 1 = 0.905664 loss)
I0526 20:55:47.091354 14297 sgd_solver.cpp:106] Iteration 540000, lr = 0.004
I0526 20:55:59.233790 14297 solver.cpp:237] Iteration 540750, loss = 0.86111
I0526 20:55:59.233975 14297 solver.cpp:253]     Train net output #0: loss = 0.861116 (* 1 = 0.861116 loss)
I0526 20:55:59.233989 14297 sgd_solver.cpp:106] Iteration 540750, lr = 0.004
I0526 20:56:11.384099 14297 solver.cpp:237] Iteration 541500, loss = 0.988396
I0526 20:56:11.384135 14297 solver.cpp:253]     Train net output #0: loss = 0.988402 (* 1 = 0.988402 loss)
I0526 20:56:11.384150 14297 sgd_solver.cpp:106] Iteration 541500, lr = 0.004
I0526 20:56:23.512197 14297 solver.cpp:237] Iteration 542250, loss = 1.13197
I0526 20:56:23.512240 14297 solver.cpp:253]     Train net output #0: loss = 1.13198 (* 1 = 1.13198 loss)
I0526 20:56:23.512259 14297 sgd_solver.cpp:106] Iteration 542250, lr = 0.004
I0526 20:56:35.690774 14297 solver.cpp:237] Iteration 543000, loss = 1.40362
I0526 20:56:35.690940 14297 solver.cpp:253]     Train net output #0: loss = 1.40362 (* 1 = 1.40362 loss)
I0526 20:56:35.690954 14297 sgd_solver.cpp:106] Iteration 543000, lr = 0.004
I0526 20:56:47.875852 14297 solver.cpp:237] Iteration 543750, loss = 1.15887
I0526 20:56:47.875888 14297 solver.cpp:253]     Train net output #0: loss = 1.15888 (* 1 = 1.15888 loss)
I0526 20:56:47.875902 14297 sgd_solver.cpp:106] Iteration 543750, lr = 0.004
I0526 20:57:00.049075 14297 solver.cpp:237] Iteration 544500, loss = 1.35609
I0526 20:57:00.049116 14297 solver.cpp:253]     Train net output #0: loss = 1.3561 (* 1 = 1.3561 loss)
I0526 20:57:00.049130 14297 sgd_solver.cpp:106] Iteration 544500, lr = 0.004
I0526 20:57:33.043577 14297 solver.cpp:237] Iteration 545250, loss = 1.62619
I0526 20:57:33.043769 14297 solver.cpp:253]     Train net output #0: loss = 1.62619 (* 1 = 1.62619 loss)
I0526 20:57:33.043783 14297 sgd_solver.cpp:106] Iteration 545250, lr = 0.004
I0526 20:57:45.088958 14297 solver.cpp:237] Iteration 546000, loss = 0.882671
I0526 20:57:45.089004 14297 solver.cpp:253]     Train net output #0: loss = 0.882677 (* 1 = 0.882677 loss)
I0526 20:57:45.089018 14297 sgd_solver.cpp:106] Iteration 546000, lr = 0.004
I0526 20:57:57.132939 14297 solver.cpp:237] Iteration 546750, loss = 1.30617
I0526 20:57:57.132975 14297 solver.cpp:253]     Train net output #0: loss = 1.30617 (* 1 = 1.30617 loss)
I0526 20:57:57.132990 14297 sgd_solver.cpp:106] Iteration 546750, lr = 0.004
I0526 20:58:09.167795 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_547500.caffemodel
I0526 20:58:09.219990 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_547500.solverstate
I0526 20:58:09.253103 14297 solver.cpp:237] Iteration 547500, loss = 1.65849
I0526 20:58:09.253152 14297 solver.cpp:253]     Train net output #0: loss = 1.6585 (* 1 = 1.6585 loss)
I0526 20:58:09.253166 14297 sgd_solver.cpp:106] Iteration 547500, lr = 0.004
I0526 20:58:21.299096 14297 solver.cpp:237] Iteration 548250, loss = 1.11132
I0526 20:58:21.299132 14297 solver.cpp:253]     Train net output #0: loss = 1.11132 (* 1 = 1.11132 loss)
I0526 20:58:21.299146 14297 sgd_solver.cpp:106] Iteration 548250, lr = 0.004
I0526 20:58:33.395045 14297 solver.cpp:237] Iteration 549000, loss = 0.921548
I0526 20:58:33.395097 14297 solver.cpp:253]     Train net output #0: loss = 0.921555 (* 1 = 0.921555 loss)
I0526 20:58:33.395110 14297 sgd_solver.cpp:106] Iteration 549000, lr = 0.004
I0526 20:58:45.603137 14297 solver.cpp:237] Iteration 549750, loss = 0.89604
I0526 20:58:45.603327 14297 solver.cpp:253]     Train net output #0: loss = 0.896046 (* 1 = 0.896046 loss)
I0526 20:58:45.603340 14297 sgd_solver.cpp:106] Iteration 549750, lr = 0.004
I0526 20:59:18.680809 14297 solver.cpp:237] Iteration 550500, loss = 1.08988
I0526 20:59:18.680989 14297 solver.cpp:253]     Train net output #0: loss = 1.08988 (* 1 = 1.08988 loss)
I0526 20:59:18.681005 14297 sgd_solver.cpp:106] Iteration 550500, lr = 0.004
I0526 20:59:30.841454 14297 solver.cpp:237] Iteration 551250, loss = 1.27017
I0526 20:59:30.841490 14297 solver.cpp:253]     Train net output #0: loss = 1.27017 (* 1 = 1.27017 loss)
I0526 20:59:30.841505 14297 sgd_solver.cpp:106] Iteration 551250, lr = 0.004
I0526 20:59:42.988265 14297 solver.cpp:237] Iteration 552000, loss = 1.24008
I0526 20:59:42.988301 14297 solver.cpp:253]     Train net output #0: loss = 1.24008 (* 1 = 1.24008 loss)
I0526 20:59:42.988315 14297 sgd_solver.cpp:106] Iteration 552000, lr = 0.004
I0526 20:59:55.144773 14297 solver.cpp:237] Iteration 552750, loss = 0.641203
I0526 20:59:55.144960 14297 solver.cpp:253]     Train net output #0: loss = 0.641209 (* 1 = 0.641209 loss)
I0526 20:59:55.144976 14297 sgd_solver.cpp:106] Iteration 552750, lr = 0.004
I0526 21:00:07.293750 14297 solver.cpp:237] Iteration 553500, loss = 1.18596
I0526 21:00:07.293787 14297 solver.cpp:253]     Train net output #0: loss = 1.18597 (* 1 = 1.18597 loss)
I0526 21:00:07.293799 14297 sgd_solver.cpp:106] Iteration 553500, lr = 0.004
I0526 21:00:19.445116 14297 solver.cpp:237] Iteration 554250, loss = 0.784124
I0526 21:00:19.445165 14297 solver.cpp:253]     Train net output #0: loss = 0.78413 (* 1 = 0.78413 loss)
I0526 21:00:19.445179 14297 sgd_solver.cpp:106] Iteration 554250, lr = 0.004
I0526 21:00:31.585685 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_555000.caffemodel
I0526 21:00:31.641558 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_555000.solverstate
I0526 21:00:31.673362 14297 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 21:01:44.491405 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903703
I0526 21:01:44.491607 14297 solver.cpp:409]     Test net output #1: loss = 0.312735 (* 1 = 0.312735 loss)
I0526 21:02:05.386878 14297 solver.cpp:237] Iteration 555000, loss = 1.01907
I0526 21:02:05.386930 14297 solver.cpp:253]     Train net output #0: loss = 1.01907 (* 1 = 1.01907 loss)
I0526 21:02:05.386945 14297 sgd_solver.cpp:106] Iteration 555000, lr = 0.004
I0526 21:02:17.554888 14297 solver.cpp:237] Iteration 555750, loss = 1.11805
I0526 21:02:17.555078 14297 solver.cpp:253]     Train net output #0: loss = 1.11805 (* 1 = 1.11805 loss)
I0526 21:02:17.555093 14297 sgd_solver.cpp:106] Iteration 555750, lr = 0.004
I0526 21:02:29.760993 14297 solver.cpp:237] Iteration 556500, loss = 1.54118
I0526 21:02:29.761023 14297 solver.cpp:253]     Train net output #0: loss = 1.54119 (* 1 = 1.54119 loss)
I0526 21:02:29.761037 14297 sgd_solver.cpp:106] Iteration 556500, lr = 0.004
I0526 21:02:41.962287 14297 solver.cpp:237] Iteration 557250, loss = 1.1578
I0526 21:02:41.962332 14297 solver.cpp:253]     Train net output #0: loss = 1.15781 (* 1 = 1.15781 loss)
I0526 21:02:41.962345 14297 sgd_solver.cpp:106] Iteration 557250, lr = 0.004
I0526 21:02:54.137933 14297 solver.cpp:237] Iteration 558000, loss = 1.20285
I0526 21:02:54.138103 14297 solver.cpp:253]     Train net output #0: loss = 1.20285 (* 1 = 1.20285 loss)
I0526 21:02:54.138118 14297 sgd_solver.cpp:106] Iteration 558000, lr = 0.004
I0526 21:03:06.297103 14297 solver.cpp:237] Iteration 558750, loss = 1.59339
I0526 21:03:06.297148 14297 solver.cpp:253]     Train net output #0: loss = 1.59339 (* 1 = 1.59339 loss)
I0526 21:03:06.297163 14297 sgd_solver.cpp:106] Iteration 558750, lr = 0.004
I0526 21:03:18.468040 14297 solver.cpp:237] Iteration 559500, loss = 1.4438
I0526 21:03:18.468075 14297 solver.cpp:253]     Train net output #0: loss = 1.4438 (* 1 = 1.4438 loss)
I0526 21:03:18.468096 14297 sgd_solver.cpp:106] Iteration 559500, lr = 0.004
I0526 21:03:51.625578 14297 solver.cpp:237] Iteration 560250, loss = 1.16373
I0526 21:03:51.625772 14297 solver.cpp:253]     Train net output #0: loss = 1.16374 (* 1 = 1.16374 loss)
I0526 21:03:51.625787 14297 sgd_solver.cpp:106] Iteration 560250, lr = 0.004
I0526 21:04:03.800215 14297 solver.cpp:237] Iteration 561000, loss = 0.860821
I0526 21:04:03.800263 14297 solver.cpp:253]     Train net output #0: loss = 0.860828 (* 1 = 0.860828 loss)
I0526 21:04:03.800277 14297 sgd_solver.cpp:106] Iteration 561000, lr = 0.004
I0526 21:04:15.946281 14297 solver.cpp:237] Iteration 561750, loss = 1.23769
I0526 21:04:15.946317 14297 solver.cpp:253]     Train net output #0: loss = 1.2377 (* 1 = 1.2377 loss)
I0526 21:04:15.946331 14297 sgd_solver.cpp:106] Iteration 561750, lr = 0.004
I0526 21:04:28.118433 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_562500.caffemodel
I0526 21:04:28.167995 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_562500.solverstate
I0526 21:04:28.198851 14297 solver.cpp:237] Iteration 562500, loss = 1.13147
I0526 21:04:28.198896 14297 solver.cpp:253]     Train net output #0: loss = 1.13147 (* 1 = 1.13147 loss)
I0526 21:04:28.198914 14297 sgd_solver.cpp:106] Iteration 562500, lr = 0.004
I0526 21:04:40.351879 14297 solver.cpp:237] Iteration 563250, loss = 1.15563
I0526 21:04:40.351917 14297 solver.cpp:253]     Train net output #0: loss = 1.15563 (* 1 = 1.15563 loss)
I0526 21:04:40.351930 14297 sgd_solver.cpp:106] Iteration 563250, lr = 0.004
I0526 21:04:52.508277 14297 solver.cpp:237] Iteration 564000, loss = 0.922974
I0526 21:04:52.508323 14297 solver.cpp:253]     Train net output #0: loss = 0.92298 (* 1 = 0.92298 loss)
I0526 21:04:52.508338 14297 sgd_solver.cpp:106] Iteration 564000, lr = 0.004
I0526 21:05:04.659229 14297 solver.cpp:237] Iteration 564750, loss = 1.16427
I0526 21:05:04.659407 14297 solver.cpp:253]     Train net output #0: loss = 1.16427 (* 1 = 1.16427 loss)
I0526 21:05:04.659420 14297 sgd_solver.cpp:106] Iteration 564750, lr = 0.004
I0526 21:05:37.744968 14297 solver.cpp:237] Iteration 565500, loss = 1.35068
I0526 21:05:37.745172 14297 solver.cpp:253]     Train net output #0: loss = 1.35068 (* 1 = 1.35068 loss)
I0526 21:05:37.745187 14297 sgd_solver.cpp:106] Iteration 565500, lr = 0.004
I0526 21:05:49.952029 14297 solver.cpp:237] Iteration 566250, loss = 1.31031
I0526 21:05:49.952065 14297 solver.cpp:253]     Train net output #0: loss = 1.31032 (* 1 = 1.31032 loss)
I0526 21:05:49.952080 14297 sgd_solver.cpp:106] Iteration 566250, lr = 0.004
I0526 21:06:02.115948 14297 solver.cpp:237] Iteration 567000, loss = 1.72742
I0526 21:06:02.115998 14297 solver.cpp:253]     Train net output #0: loss = 1.72742 (* 1 = 1.72742 loss)
I0526 21:06:02.116013 14297 sgd_solver.cpp:106] Iteration 567000, lr = 0.004
I0526 21:06:14.293766 14297 solver.cpp:237] Iteration 567750, loss = 1.31332
I0526 21:06:14.293942 14297 solver.cpp:253]     Train net output #0: loss = 1.31332 (* 1 = 1.31332 loss)
I0526 21:06:14.293956 14297 sgd_solver.cpp:106] Iteration 567750, lr = 0.004
I0526 21:06:26.486130 14297 solver.cpp:237] Iteration 568500, loss = 1.45341
I0526 21:06:26.486176 14297 solver.cpp:253]     Train net output #0: loss = 1.45341 (* 1 = 1.45341 loss)
I0526 21:06:26.486189 14297 sgd_solver.cpp:106] Iteration 568500, lr = 0.004
I0526 21:06:38.676064 14297 solver.cpp:237] Iteration 569250, loss = 1.00324
I0526 21:06:38.676106 14297 solver.cpp:253]     Train net output #0: loss = 1.00324 (* 1 = 1.00324 loss)
I0526 21:06:38.676122 14297 sgd_solver.cpp:106] Iteration 569250, lr = 0.004
I0526 21:06:50.875543 14297 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_570000.caffemodel
I0526 21:06:50.925757 14297 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_570000.solverstate
I0526 21:06:50.951845 14297 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 21:07:42.621294 14297 solver.cpp:409]     Test net output #0: accuracy = 0.903944
I0526 21:07:42.621495 14297 solver.cpp:409]     Test net output #1: loss = 0.304616 (* 1 = 0.304616 loss)
I0526 21:08:03.492977 14297 solver.cpp:237] Iteration 570000, loss = 1.45764
I0526 21:08:03.493031 14297 solver.cpp:253]     Train net output #0: loss = 1.45765 (* 1 = 1.45765 loss)
I0526 21:08:03.493048 14297 sgd_solver.cpp:106] Iteration 570000, lr = 0.004
I0526 21:08:15.730069 14297 solver.cpp:237] Iteration 570750, loss = 0.862014
I0526 21:08:15.730252 14297 solver.cpp:253]     Train net output #0: loss = 0.862019 (* 1 = 0.862019 loss)
I0526 21:08:15.730267 14297 sgd_solver.cpp:106] Iteration 570750, lr = 0.004
I0526 21:08:27.945055 14297 solver.cpp:237] Iteration 571500, loss = 0.41253
I0526 21:08:27.945091 14297 solver.cpp:253]     Train net output #0: loss = 0.412535 (* 1 = 0.412535 loss)
I0526 21:08:27.945106 14297 sgd_solver.cpp:106] Iteration 571500, lr = 0.004
I0526 21:08:40.101213 14297 solver.cpp:237] Iteration 572250, loss = 0.444418
I0526 21:08:40.101260 14297 solver.cpp:253]     Train net output #0: loss = 0.444424 (* 1 = 0.444424 loss)
I0526 21:08:40.101274 14297 sgd_solver.cpp:106] Iteration 572250, lr = 0.004
I0526 21:08:52.303819 14297 solver.cpp:237] Iteration 573000, loss = 0.74265
I0526 21:08:52.303993 14297 solver.cpp:253]     Train net output #0: loss = 0.742655 (* 1 = 0.742655 loss)
I0526 21:08:52.304010 14297 sgd_solver.cpp:106] Iteration 573000, lr = 0.004
I0526 21:09:04.454622 14297 solver.cpp:237] Iteration 573750, loss = 1.18737
I0526 21:09:04.454664 14297 solver.cpp:253]     Train net output #0: loss = 1.18738 (* 1 = 1.18738 loss)
I0526 21:09:04.454679 14297 sgd_solver.cpp:106] Iteration 573750, lr = 0.004
I0526 21:09:16.577718 14297 solver.cpp:237] Iteration 574500, loss = 0.979285
I0526 21:09:16.577755 14297 solver.cpp:253]     Train net output #0: loss = 0.97929 (* 1 = 0.97929 loss)
I0526 21:09:16.577769 14297 sgd_solver.cpp:106] Iteration 574500, lr = 0.004
I0526 21:09:49.615522 14297 solver.cpp:237] Iteration 575250, loss = 1.1026
I0526 21:09:49.615731 14297 solver.cpp:253]     Train net output #0: loss = 1.1026 (* 1 = 1.1026 loss)
I0526 21:09:49.615747 14297 sgd_solver.cpp:106] Iteration 575250, lr = 0.004
aprun: Apid 11270428: Caught signal Terminated, sending to application
*** Aborted at 1464311397 (unix time) try "date -d @1464311397" if you are using GNU date ***
aprun: Apid 11270428: Caught signal Terminated, sending to application
PC: @     0x2aaab9276670 (unknown)
aprun: Apid 11270428: Caught signal Terminated, sending to application
*** SIGTERM (@0x37d6) received by PID 14297 (TID 0x2aaac746f900) from PID 14294; stack trace: ***
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab9276670 (unknown)
    @     0x2aaab930eb7d (unknown)
=>> PBS: job killed: walltime 7230 exceeded limit 7200
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab928a408 (unknown)
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11270428: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11270428: Caught signal Terminated, sending to application
aprun: Apid 11270428: Caught signal Terminated, sending to application
aprun: Apid 11270428: Caught signal Terminated, sending to application
aprun: Apid 11270428: Caught signal Terminated, sending to application
aprun: Apid 11270428: Caught signal Terminated, sending to application
aprun: Apid 11270428: Caught signal Terminated, sending to application
