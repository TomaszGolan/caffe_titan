2811174
I0525 23:29:17.676479 26495 caffe.cpp:184] Using GPUs 0
I0525 23:29:18.096581 26495 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0025
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607.prototxt"
I0525 23:29:18.100018 26495 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607.prototxt
I0525 23:29:18.117683 26495 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 23:29:18.117740 26495 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 23:29:18.118088 26495 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 23:29:18.118268 26495 layer_factory.hpp:77] Creating layer data_hdf5
I0525 23:29:18.118293 26495 net.cpp:106] Creating Layer data_hdf5
I0525 23:29:18.118306 26495 net.cpp:411] data_hdf5 -> data
I0525 23:29:18.118340 26495 net.cpp:411] data_hdf5 -> label
I0525 23:29:18.118373 26495 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 23:29:18.119563 26495 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 23:29:18.121919 26495 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 23:29:39.676532 26495 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 23:29:39.681892 26495 net.cpp:150] Setting up data_hdf5
I0525 23:29:39.681936 26495 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0525 23:29:39.681951 26495 net.cpp:157] Top shape: 10 (10)
I0525 23:29:39.681962 26495 net.cpp:165] Memory required for data: 254040
I0525 23:29:39.681975 26495 layer_factory.hpp:77] Creating layer conv1
I0525 23:29:39.682008 26495 net.cpp:106] Creating Layer conv1
I0525 23:29:39.682020 26495 net.cpp:454] conv1 <- data
I0525 23:29:39.682044 26495 net.cpp:411] conv1 -> conv1
I0525 23:29:40.044317 26495 net.cpp:150] Setting up conv1
I0525 23:29:40.044363 26495 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0525 23:29:40.044374 26495 net.cpp:165] Memory required for data: 3018840
I0525 23:29:40.044406 26495 layer_factory.hpp:77] Creating layer relu1
I0525 23:29:40.044427 26495 net.cpp:106] Creating Layer relu1
I0525 23:29:40.044438 26495 net.cpp:454] relu1 <- conv1
I0525 23:29:40.044452 26495 net.cpp:397] relu1 -> conv1 (in-place)
I0525 23:29:40.044975 26495 net.cpp:150] Setting up relu1
I0525 23:29:40.044992 26495 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0525 23:29:40.045002 26495 net.cpp:165] Memory required for data: 5783640
I0525 23:29:40.045012 26495 layer_factory.hpp:77] Creating layer pool1
I0525 23:29:40.045029 26495 net.cpp:106] Creating Layer pool1
I0525 23:29:40.045049 26495 net.cpp:454] pool1 <- conv1
I0525 23:29:40.045060 26495 net.cpp:411] pool1 -> pool1
I0525 23:29:40.045140 26495 net.cpp:150] Setting up pool1
I0525 23:29:40.045155 26495 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0525 23:29:40.045164 26495 net.cpp:165] Memory required for data: 7166040
I0525 23:29:40.045174 26495 layer_factory.hpp:77] Creating layer conv2
I0525 23:29:40.045195 26495 net.cpp:106] Creating Layer conv2
I0525 23:29:40.045207 26495 net.cpp:454] conv2 <- pool1
I0525 23:29:40.045219 26495 net.cpp:411] conv2 -> conv2
I0525 23:29:40.047916 26495 net.cpp:150] Setting up conv2
I0525 23:29:40.047945 26495 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0525 23:29:40.047955 26495 net.cpp:165] Memory required for data: 9153240
I0525 23:29:40.047974 26495 layer_factory.hpp:77] Creating layer relu2
I0525 23:29:40.047989 26495 net.cpp:106] Creating Layer relu2
I0525 23:29:40.047999 26495 net.cpp:454] relu2 <- conv2
I0525 23:29:40.048012 26495 net.cpp:397] relu2 -> conv2 (in-place)
I0525 23:29:40.048344 26495 net.cpp:150] Setting up relu2
I0525 23:29:40.048359 26495 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0525 23:29:40.048369 26495 net.cpp:165] Memory required for data: 11140440
I0525 23:29:40.048380 26495 layer_factory.hpp:77] Creating layer pool2
I0525 23:29:40.048393 26495 net.cpp:106] Creating Layer pool2
I0525 23:29:40.048403 26495 net.cpp:454] pool2 <- conv2
I0525 23:29:40.048415 26495 net.cpp:411] pool2 -> pool2
I0525 23:29:40.048497 26495 net.cpp:150] Setting up pool2
I0525 23:29:40.048511 26495 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0525 23:29:40.048521 26495 net.cpp:165] Memory required for data: 12134040
I0525 23:29:40.048528 26495 layer_factory.hpp:77] Creating layer conv3
I0525 23:29:40.048547 26495 net.cpp:106] Creating Layer conv3
I0525 23:29:40.048557 26495 net.cpp:454] conv3 <- pool2
I0525 23:29:40.048570 26495 net.cpp:411] conv3 -> conv3
I0525 23:29:40.050683 26495 net.cpp:150] Setting up conv3
I0525 23:29:40.050707 26495 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0525 23:29:40.050717 26495 net.cpp:165] Memory required for data: 13218200
I0525 23:29:40.050736 26495 layer_factory.hpp:77] Creating layer relu3
I0525 23:29:40.050752 26495 net.cpp:106] Creating Layer relu3
I0525 23:29:40.050762 26495 net.cpp:454] relu3 <- conv3
I0525 23:29:40.050776 26495 net.cpp:397] relu3 -> conv3 (in-place)
I0525 23:29:40.051236 26495 net.cpp:150] Setting up relu3
I0525 23:29:40.051254 26495 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0525 23:29:40.051265 26495 net.cpp:165] Memory required for data: 14302360
I0525 23:29:40.051275 26495 layer_factory.hpp:77] Creating layer pool3
I0525 23:29:40.051288 26495 net.cpp:106] Creating Layer pool3
I0525 23:29:40.051298 26495 net.cpp:454] pool3 <- conv3
I0525 23:29:40.051311 26495 net.cpp:411] pool3 -> pool3
I0525 23:29:40.051378 26495 net.cpp:150] Setting up pool3
I0525 23:29:40.051393 26495 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0525 23:29:40.051401 26495 net.cpp:165] Memory required for data: 14844440
I0525 23:29:40.051411 26495 layer_factory.hpp:77] Creating layer conv4
I0525 23:29:40.051429 26495 net.cpp:106] Creating Layer conv4
I0525 23:29:40.051440 26495 net.cpp:454] conv4 <- pool3
I0525 23:29:40.051452 26495 net.cpp:411] conv4 -> conv4
I0525 23:29:40.054185 26495 net.cpp:150] Setting up conv4
I0525 23:29:40.054214 26495 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0525 23:29:40.054224 26495 net.cpp:165] Memory required for data: 15207320
I0525 23:29:40.054240 26495 layer_factory.hpp:77] Creating layer relu4
I0525 23:29:40.054255 26495 net.cpp:106] Creating Layer relu4
I0525 23:29:40.054265 26495 net.cpp:454] relu4 <- conv4
I0525 23:29:40.054277 26495 net.cpp:397] relu4 -> conv4 (in-place)
I0525 23:29:40.054746 26495 net.cpp:150] Setting up relu4
I0525 23:29:40.054764 26495 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0525 23:29:40.054774 26495 net.cpp:165] Memory required for data: 15570200
I0525 23:29:40.054785 26495 layer_factory.hpp:77] Creating layer pool4
I0525 23:29:40.054797 26495 net.cpp:106] Creating Layer pool4
I0525 23:29:40.054807 26495 net.cpp:454] pool4 <- conv4
I0525 23:29:40.054821 26495 net.cpp:411] pool4 -> pool4
I0525 23:29:40.054889 26495 net.cpp:150] Setting up pool4
I0525 23:29:40.054903 26495 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0525 23:29:40.054913 26495 net.cpp:165] Memory required for data: 15751640
I0525 23:29:40.054920 26495 layer_factory.hpp:77] Creating layer ip1
I0525 23:29:40.054939 26495 net.cpp:106] Creating Layer ip1
I0525 23:29:40.054949 26495 net.cpp:454] ip1 <- pool4
I0525 23:29:40.054963 26495 net.cpp:411] ip1 -> ip1
I0525 23:29:40.070442 26495 net.cpp:150] Setting up ip1
I0525 23:29:40.070472 26495 net.cpp:157] Top shape: 10 196 (1960)
I0525 23:29:40.070483 26495 net.cpp:165] Memory required for data: 15759480
I0525 23:29:40.070504 26495 layer_factory.hpp:77] Creating layer relu5
I0525 23:29:40.070519 26495 net.cpp:106] Creating Layer relu5
I0525 23:29:40.070529 26495 net.cpp:454] relu5 <- ip1
I0525 23:29:40.070543 26495 net.cpp:397] relu5 -> ip1 (in-place)
I0525 23:29:40.070889 26495 net.cpp:150] Setting up relu5
I0525 23:29:40.070904 26495 net.cpp:157] Top shape: 10 196 (1960)
I0525 23:29:40.070914 26495 net.cpp:165] Memory required for data: 15767320
I0525 23:29:40.070922 26495 layer_factory.hpp:77] Creating layer drop1
I0525 23:29:40.070945 26495 net.cpp:106] Creating Layer drop1
I0525 23:29:40.070955 26495 net.cpp:454] drop1 <- ip1
I0525 23:29:40.070967 26495 net.cpp:397] drop1 -> ip1 (in-place)
I0525 23:29:40.071027 26495 net.cpp:150] Setting up drop1
I0525 23:29:40.071040 26495 net.cpp:157] Top shape: 10 196 (1960)
I0525 23:29:40.071049 26495 net.cpp:165] Memory required for data: 15775160
I0525 23:29:40.071059 26495 layer_factory.hpp:77] Creating layer ip2
I0525 23:29:40.071077 26495 net.cpp:106] Creating Layer ip2
I0525 23:29:40.071089 26495 net.cpp:454] ip2 <- ip1
I0525 23:29:40.071101 26495 net.cpp:411] ip2 -> ip2
I0525 23:29:40.071568 26495 net.cpp:150] Setting up ip2
I0525 23:29:40.071581 26495 net.cpp:157] Top shape: 10 98 (980)
I0525 23:29:40.071591 26495 net.cpp:165] Memory required for data: 15779080
I0525 23:29:40.071606 26495 layer_factory.hpp:77] Creating layer relu6
I0525 23:29:40.071620 26495 net.cpp:106] Creating Layer relu6
I0525 23:29:40.071630 26495 net.cpp:454] relu6 <- ip2
I0525 23:29:40.071641 26495 net.cpp:397] relu6 -> ip2 (in-place)
I0525 23:29:40.072162 26495 net.cpp:150] Setting up relu6
I0525 23:29:40.072178 26495 net.cpp:157] Top shape: 10 98 (980)
I0525 23:29:40.072188 26495 net.cpp:165] Memory required for data: 15783000
I0525 23:29:40.072198 26495 layer_factory.hpp:77] Creating layer drop2
I0525 23:29:40.072211 26495 net.cpp:106] Creating Layer drop2
I0525 23:29:40.072221 26495 net.cpp:454] drop2 <- ip2
I0525 23:29:40.072234 26495 net.cpp:397] drop2 -> ip2 (in-place)
I0525 23:29:40.072276 26495 net.cpp:150] Setting up drop2
I0525 23:29:40.072289 26495 net.cpp:157] Top shape: 10 98 (980)
I0525 23:29:40.072300 26495 net.cpp:165] Memory required for data: 15786920
I0525 23:29:40.072309 26495 layer_factory.hpp:77] Creating layer ip3
I0525 23:29:40.072324 26495 net.cpp:106] Creating Layer ip3
I0525 23:29:40.072332 26495 net.cpp:454] ip3 <- ip2
I0525 23:29:40.072345 26495 net.cpp:411] ip3 -> ip3
I0525 23:29:40.072556 26495 net.cpp:150] Setting up ip3
I0525 23:29:40.072568 26495 net.cpp:157] Top shape: 10 11 (110)
I0525 23:29:40.072578 26495 net.cpp:165] Memory required for data: 15787360
I0525 23:29:40.072593 26495 layer_factory.hpp:77] Creating layer drop3
I0525 23:29:40.072605 26495 net.cpp:106] Creating Layer drop3
I0525 23:29:40.072615 26495 net.cpp:454] drop3 <- ip3
I0525 23:29:40.072628 26495 net.cpp:397] drop3 -> ip3 (in-place)
I0525 23:29:40.072667 26495 net.cpp:150] Setting up drop3
I0525 23:29:40.072680 26495 net.cpp:157] Top shape: 10 11 (110)
I0525 23:29:40.072690 26495 net.cpp:165] Memory required for data: 15787800
I0525 23:29:40.072700 26495 layer_factory.hpp:77] Creating layer loss
I0525 23:29:40.072720 26495 net.cpp:106] Creating Layer loss
I0525 23:29:40.072729 26495 net.cpp:454] loss <- ip3
I0525 23:29:40.072741 26495 net.cpp:454] loss <- label
I0525 23:29:40.072753 26495 net.cpp:411] loss -> loss
I0525 23:29:40.072772 26495 layer_factory.hpp:77] Creating layer loss
I0525 23:29:40.073420 26495 net.cpp:150] Setting up loss
I0525 23:29:40.073441 26495 net.cpp:157] Top shape: (1)
I0525 23:29:40.073454 26495 net.cpp:160]     with loss weight 1
I0525 23:29:40.073496 26495 net.cpp:165] Memory required for data: 15787804
I0525 23:29:40.073508 26495 net.cpp:226] loss needs backward computation.
I0525 23:29:40.073518 26495 net.cpp:226] drop3 needs backward computation.
I0525 23:29:40.073528 26495 net.cpp:226] ip3 needs backward computation.
I0525 23:29:40.073539 26495 net.cpp:226] drop2 needs backward computation.
I0525 23:29:40.073547 26495 net.cpp:226] relu6 needs backward computation.
I0525 23:29:40.073557 26495 net.cpp:226] ip2 needs backward computation.
I0525 23:29:40.073567 26495 net.cpp:226] drop1 needs backward computation.
I0525 23:29:40.073577 26495 net.cpp:226] relu5 needs backward computation.
I0525 23:29:40.073586 26495 net.cpp:226] ip1 needs backward computation.
I0525 23:29:40.073597 26495 net.cpp:226] pool4 needs backward computation.
I0525 23:29:40.073607 26495 net.cpp:226] relu4 needs backward computation.
I0525 23:29:40.073617 26495 net.cpp:226] conv4 needs backward computation.
I0525 23:29:40.073627 26495 net.cpp:226] pool3 needs backward computation.
I0525 23:29:40.073637 26495 net.cpp:226] relu3 needs backward computation.
I0525 23:29:40.073645 26495 net.cpp:226] conv3 needs backward computation.
I0525 23:29:40.073665 26495 net.cpp:226] pool2 needs backward computation.
I0525 23:29:40.073676 26495 net.cpp:226] relu2 needs backward computation.
I0525 23:29:40.073688 26495 net.cpp:226] conv2 needs backward computation.
I0525 23:29:40.073698 26495 net.cpp:226] pool1 needs backward computation.
I0525 23:29:40.073709 26495 net.cpp:226] relu1 needs backward computation.
I0525 23:29:40.073719 26495 net.cpp:226] conv1 needs backward computation.
I0525 23:29:40.073729 26495 net.cpp:228] data_hdf5 does not need backward computation.
I0525 23:29:40.073740 26495 net.cpp:270] This network produces output loss
I0525 23:29:40.073763 26495 net.cpp:283] Network initialization done.
I0525 23:29:40.075448 26495 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607.prototxt
I0525 23:29:40.075518 26495 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 23:29:40.075872 26495 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 23:29:40.076063 26495 layer_factory.hpp:77] Creating layer data_hdf5
I0525 23:29:40.076078 26495 net.cpp:106] Creating Layer data_hdf5
I0525 23:29:40.076092 26495 net.cpp:411] data_hdf5 -> data
I0525 23:29:40.076108 26495 net.cpp:411] data_hdf5 -> label
I0525 23:29:40.076124 26495 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 23:29:40.077494 26495 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 23:30:01.447733 26495 net.cpp:150] Setting up data_hdf5
I0525 23:30:01.447898 26495 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0525 23:30:01.447913 26495 net.cpp:157] Top shape: 10 (10)
I0525 23:30:01.447924 26495 net.cpp:165] Memory required for data: 254040
I0525 23:30:01.447937 26495 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 23:30:01.447967 26495 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 23:30:01.447976 26495 net.cpp:454] label_data_hdf5_1_split <- label
I0525 23:30:01.447991 26495 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 23:30:01.448012 26495 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 23:30:01.448086 26495 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 23:30:01.448099 26495 net.cpp:157] Top shape: 10 (10)
I0525 23:30:01.448112 26495 net.cpp:157] Top shape: 10 (10)
I0525 23:30:01.448122 26495 net.cpp:165] Memory required for data: 254120
I0525 23:30:01.448132 26495 layer_factory.hpp:77] Creating layer conv1
I0525 23:30:01.448151 26495 net.cpp:106] Creating Layer conv1
I0525 23:30:01.448163 26495 net.cpp:454] conv1 <- data
I0525 23:30:01.448178 26495 net.cpp:411] conv1 -> conv1
I0525 23:30:01.450145 26495 net.cpp:150] Setting up conv1
I0525 23:30:01.450170 26495 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0525 23:30:01.450181 26495 net.cpp:165] Memory required for data: 3018920
I0525 23:30:01.450202 26495 layer_factory.hpp:77] Creating layer relu1
I0525 23:30:01.450217 26495 net.cpp:106] Creating Layer relu1
I0525 23:30:01.450227 26495 net.cpp:454] relu1 <- conv1
I0525 23:30:01.450240 26495 net.cpp:397] relu1 -> conv1 (in-place)
I0525 23:30:01.450747 26495 net.cpp:150] Setting up relu1
I0525 23:30:01.450763 26495 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0525 23:30:01.450774 26495 net.cpp:165] Memory required for data: 5783720
I0525 23:30:01.450784 26495 layer_factory.hpp:77] Creating layer pool1
I0525 23:30:01.450799 26495 net.cpp:106] Creating Layer pool1
I0525 23:30:01.450809 26495 net.cpp:454] pool1 <- conv1
I0525 23:30:01.450822 26495 net.cpp:411] pool1 -> pool1
I0525 23:30:01.450896 26495 net.cpp:150] Setting up pool1
I0525 23:30:01.450911 26495 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0525 23:30:01.450919 26495 net.cpp:165] Memory required for data: 7166120
I0525 23:30:01.450929 26495 layer_factory.hpp:77] Creating layer conv2
I0525 23:30:01.450947 26495 net.cpp:106] Creating Layer conv2
I0525 23:30:01.450958 26495 net.cpp:454] conv2 <- pool1
I0525 23:30:01.450971 26495 net.cpp:411] conv2 -> conv2
I0525 23:30:01.452886 26495 net.cpp:150] Setting up conv2
I0525 23:30:01.452909 26495 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0525 23:30:01.452921 26495 net.cpp:165] Memory required for data: 9153320
I0525 23:30:01.452939 26495 layer_factory.hpp:77] Creating layer relu2
I0525 23:30:01.452953 26495 net.cpp:106] Creating Layer relu2
I0525 23:30:01.452963 26495 net.cpp:454] relu2 <- conv2
I0525 23:30:01.452976 26495 net.cpp:397] relu2 -> conv2 (in-place)
I0525 23:30:01.453320 26495 net.cpp:150] Setting up relu2
I0525 23:30:01.453336 26495 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0525 23:30:01.453346 26495 net.cpp:165] Memory required for data: 11140520
I0525 23:30:01.453356 26495 layer_factory.hpp:77] Creating layer pool2
I0525 23:30:01.453368 26495 net.cpp:106] Creating Layer pool2
I0525 23:30:01.453378 26495 net.cpp:454] pool2 <- conv2
I0525 23:30:01.453392 26495 net.cpp:411] pool2 -> pool2
I0525 23:30:01.453464 26495 net.cpp:150] Setting up pool2
I0525 23:30:01.453479 26495 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0525 23:30:01.453487 26495 net.cpp:165] Memory required for data: 12134120
I0525 23:30:01.453497 26495 layer_factory.hpp:77] Creating layer conv3
I0525 23:30:01.453516 26495 net.cpp:106] Creating Layer conv3
I0525 23:30:01.453526 26495 net.cpp:454] conv3 <- pool2
I0525 23:30:01.453539 26495 net.cpp:411] conv3 -> conv3
I0525 23:30:01.455538 26495 net.cpp:150] Setting up conv3
I0525 23:30:01.455561 26495 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0525 23:30:01.455574 26495 net.cpp:165] Memory required for data: 13218280
I0525 23:30:01.455592 26495 layer_factory.hpp:77] Creating layer relu3
I0525 23:30:01.455618 26495 net.cpp:106] Creating Layer relu3
I0525 23:30:01.455628 26495 net.cpp:454] relu3 <- conv3
I0525 23:30:01.455642 26495 net.cpp:397] relu3 -> conv3 (in-place)
I0525 23:30:01.456113 26495 net.cpp:150] Setting up relu3
I0525 23:30:01.456135 26495 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0525 23:30:01.456146 26495 net.cpp:165] Memory required for data: 14302440
I0525 23:30:01.456153 26495 layer_factory.hpp:77] Creating layer pool3
I0525 23:30:01.456166 26495 net.cpp:106] Creating Layer pool3
I0525 23:30:01.456176 26495 net.cpp:454] pool3 <- conv3
I0525 23:30:01.456188 26495 net.cpp:411] pool3 -> pool3
I0525 23:30:01.456259 26495 net.cpp:150] Setting up pool3
I0525 23:30:01.456272 26495 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0525 23:30:01.456282 26495 net.cpp:165] Memory required for data: 14844520
I0525 23:30:01.456292 26495 layer_factory.hpp:77] Creating layer conv4
I0525 23:30:01.456310 26495 net.cpp:106] Creating Layer conv4
I0525 23:30:01.456320 26495 net.cpp:454] conv4 <- pool3
I0525 23:30:01.456333 26495 net.cpp:411] conv4 -> conv4
I0525 23:30:01.458396 26495 net.cpp:150] Setting up conv4
I0525 23:30:01.458418 26495 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0525 23:30:01.458431 26495 net.cpp:165] Memory required for data: 15207400
I0525 23:30:01.458446 26495 layer_factory.hpp:77] Creating layer relu4
I0525 23:30:01.458461 26495 net.cpp:106] Creating Layer relu4
I0525 23:30:01.458470 26495 net.cpp:454] relu4 <- conv4
I0525 23:30:01.458483 26495 net.cpp:397] relu4 -> conv4 (in-place)
I0525 23:30:01.458950 26495 net.cpp:150] Setting up relu4
I0525 23:30:01.458966 26495 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0525 23:30:01.458976 26495 net.cpp:165] Memory required for data: 15570280
I0525 23:30:01.458986 26495 layer_factory.hpp:77] Creating layer pool4
I0525 23:30:01.459000 26495 net.cpp:106] Creating Layer pool4
I0525 23:30:01.459010 26495 net.cpp:454] pool4 <- conv4
I0525 23:30:01.459023 26495 net.cpp:411] pool4 -> pool4
I0525 23:30:01.459096 26495 net.cpp:150] Setting up pool4
I0525 23:30:01.459110 26495 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0525 23:30:01.459120 26495 net.cpp:165] Memory required for data: 15751720
I0525 23:30:01.459130 26495 layer_factory.hpp:77] Creating layer ip1
I0525 23:30:01.459146 26495 net.cpp:106] Creating Layer ip1
I0525 23:30:01.459156 26495 net.cpp:454] ip1 <- pool4
I0525 23:30:01.459170 26495 net.cpp:411] ip1 -> ip1
I0525 23:30:01.474588 26495 net.cpp:150] Setting up ip1
I0525 23:30:01.474617 26495 net.cpp:157] Top shape: 10 196 (1960)
I0525 23:30:01.474628 26495 net.cpp:165] Memory required for data: 15759560
I0525 23:30:01.474650 26495 layer_factory.hpp:77] Creating layer relu5
I0525 23:30:01.474666 26495 net.cpp:106] Creating Layer relu5
I0525 23:30:01.474676 26495 net.cpp:454] relu5 <- ip1
I0525 23:30:01.474691 26495 net.cpp:397] relu5 -> ip1 (in-place)
I0525 23:30:01.475040 26495 net.cpp:150] Setting up relu5
I0525 23:30:01.475054 26495 net.cpp:157] Top shape: 10 196 (1960)
I0525 23:30:01.475064 26495 net.cpp:165] Memory required for data: 15767400
I0525 23:30:01.475075 26495 layer_factory.hpp:77] Creating layer drop1
I0525 23:30:01.475093 26495 net.cpp:106] Creating Layer drop1
I0525 23:30:01.475102 26495 net.cpp:454] drop1 <- ip1
I0525 23:30:01.475116 26495 net.cpp:397] drop1 -> ip1 (in-place)
I0525 23:30:01.475162 26495 net.cpp:150] Setting up drop1
I0525 23:30:01.475174 26495 net.cpp:157] Top shape: 10 196 (1960)
I0525 23:30:01.475184 26495 net.cpp:165] Memory required for data: 15775240
I0525 23:30:01.475193 26495 layer_factory.hpp:77] Creating layer ip2
I0525 23:30:01.475208 26495 net.cpp:106] Creating Layer ip2
I0525 23:30:01.475219 26495 net.cpp:454] ip2 <- ip1
I0525 23:30:01.475231 26495 net.cpp:411] ip2 -> ip2
I0525 23:30:01.475716 26495 net.cpp:150] Setting up ip2
I0525 23:30:01.475730 26495 net.cpp:157] Top shape: 10 98 (980)
I0525 23:30:01.475739 26495 net.cpp:165] Memory required for data: 15779160
I0525 23:30:01.475755 26495 layer_factory.hpp:77] Creating layer relu6
I0525 23:30:01.475780 26495 net.cpp:106] Creating Layer relu6
I0525 23:30:01.475791 26495 net.cpp:454] relu6 <- ip2
I0525 23:30:01.475803 26495 net.cpp:397] relu6 -> ip2 (in-place)
I0525 23:30:01.476346 26495 net.cpp:150] Setting up relu6
I0525 23:30:01.476362 26495 net.cpp:157] Top shape: 10 98 (980)
I0525 23:30:01.476372 26495 net.cpp:165] Memory required for data: 15783080
I0525 23:30:01.476382 26495 layer_factory.hpp:77] Creating layer drop2
I0525 23:30:01.476397 26495 net.cpp:106] Creating Layer drop2
I0525 23:30:01.476407 26495 net.cpp:454] drop2 <- ip2
I0525 23:30:01.476419 26495 net.cpp:397] drop2 -> ip2 (in-place)
I0525 23:30:01.476464 26495 net.cpp:150] Setting up drop2
I0525 23:30:01.476476 26495 net.cpp:157] Top shape: 10 98 (980)
I0525 23:30:01.476486 26495 net.cpp:165] Memory required for data: 15787000
I0525 23:30:01.476493 26495 layer_factory.hpp:77] Creating layer ip3
I0525 23:30:01.476508 26495 net.cpp:106] Creating Layer ip3
I0525 23:30:01.476518 26495 net.cpp:454] ip3 <- ip2
I0525 23:30:01.476532 26495 net.cpp:411] ip3 -> ip3
I0525 23:30:01.476753 26495 net.cpp:150] Setting up ip3
I0525 23:30:01.476766 26495 net.cpp:157] Top shape: 10 11 (110)
I0525 23:30:01.476776 26495 net.cpp:165] Memory required for data: 15787440
I0525 23:30:01.476793 26495 layer_factory.hpp:77] Creating layer drop3
I0525 23:30:01.476805 26495 net.cpp:106] Creating Layer drop3
I0525 23:30:01.476815 26495 net.cpp:454] drop3 <- ip3
I0525 23:30:01.476827 26495 net.cpp:397] drop3 -> ip3 (in-place)
I0525 23:30:01.476869 26495 net.cpp:150] Setting up drop3
I0525 23:30:01.476881 26495 net.cpp:157] Top shape: 10 11 (110)
I0525 23:30:01.476891 26495 net.cpp:165] Memory required for data: 15787880
I0525 23:30:01.476902 26495 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 23:30:01.476914 26495 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 23:30:01.476924 26495 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 23:30:01.476938 26495 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 23:30:01.476953 26495 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 23:30:01.477025 26495 net.cpp:150] Setting up ip3_drop3_0_split
I0525 23:30:01.477047 26495 net.cpp:157] Top shape: 10 11 (110)
I0525 23:30:01.477061 26495 net.cpp:157] Top shape: 10 11 (110)
I0525 23:30:01.477071 26495 net.cpp:165] Memory required for data: 15788760
I0525 23:30:01.477080 26495 layer_factory.hpp:77] Creating layer accuracy
I0525 23:30:01.477102 26495 net.cpp:106] Creating Layer accuracy
I0525 23:30:01.477113 26495 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 23:30:01.477123 26495 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 23:30:01.477138 26495 net.cpp:411] accuracy -> accuracy
I0525 23:30:01.477161 26495 net.cpp:150] Setting up accuracy
I0525 23:30:01.477174 26495 net.cpp:157] Top shape: (1)
I0525 23:30:01.477183 26495 net.cpp:165] Memory required for data: 15788764
I0525 23:30:01.477193 26495 layer_factory.hpp:77] Creating layer loss
I0525 23:30:01.477207 26495 net.cpp:106] Creating Layer loss
I0525 23:30:01.477218 26495 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 23:30:01.477228 26495 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 23:30:01.477242 26495 net.cpp:411] loss -> loss
I0525 23:30:01.477259 26495 layer_factory.hpp:77] Creating layer loss
I0525 23:30:01.477740 26495 net.cpp:150] Setting up loss
I0525 23:30:01.477753 26495 net.cpp:157] Top shape: (1)
I0525 23:30:01.477763 26495 net.cpp:160]     with loss weight 1
I0525 23:30:01.477782 26495 net.cpp:165] Memory required for data: 15788768
I0525 23:30:01.477792 26495 net.cpp:226] loss needs backward computation.
I0525 23:30:01.477803 26495 net.cpp:228] accuracy does not need backward computation.
I0525 23:30:01.477814 26495 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 23:30:01.477824 26495 net.cpp:226] drop3 needs backward computation.
I0525 23:30:01.477833 26495 net.cpp:226] ip3 needs backward computation.
I0525 23:30:01.477844 26495 net.cpp:226] drop2 needs backward computation.
I0525 23:30:01.477854 26495 net.cpp:226] relu6 needs backward computation.
I0525 23:30:01.477872 26495 net.cpp:226] ip2 needs backward computation.
I0525 23:30:01.477882 26495 net.cpp:226] drop1 needs backward computation.
I0525 23:30:01.477892 26495 net.cpp:226] relu5 needs backward computation.
I0525 23:30:01.477901 26495 net.cpp:226] ip1 needs backward computation.
I0525 23:30:01.477911 26495 net.cpp:226] pool4 needs backward computation.
I0525 23:30:01.477921 26495 net.cpp:226] relu4 needs backward computation.
I0525 23:30:01.477932 26495 net.cpp:226] conv4 needs backward computation.
I0525 23:30:01.477943 26495 net.cpp:226] pool3 needs backward computation.
I0525 23:30:01.477954 26495 net.cpp:226] relu3 needs backward computation.
I0525 23:30:01.477965 26495 net.cpp:226] conv3 needs backward computation.
I0525 23:30:01.477975 26495 net.cpp:226] pool2 needs backward computation.
I0525 23:30:01.477985 26495 net.cpp:226] relu2 needs backward computation.
I0525 23:30:01.477995 26495 net.cpp:226] conv2 needs backward computation.
I0525 23:30:01.478005 26495 net.cpp:226] pool1 needs backward computation.
I0525 23:30:01.478016 26495 net.cpp:226] relu1 needs backward computation.
I0525 23:30:01.478026 26495 net.cpp:226] conv1 needs backward computation.
I0525 23:30:01.478039 26495 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 23:30:01.478049 26495 net.cpp:228] data_hdf5 does not need backward computation.
I0525 23:30:01.478060 26495 net.cpp:270] This network produces output accuracy
I0525 23:30:01.478071 26495 net.cpp:270] This network produces output loss
I0525 23:30:01.478099 26495 net.cpp:283] Network initialization done.
I0525 23:30:01.478234 26495 solver.cpp:60] Solver scaffolding done.
I0525 23:30:01.479369 26495 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_450000.solverstate
I0525 23:30:01.742183 26495 sgd_solver.cpp:318] SGDSolver: restoring history
I0525 23:30:01.747736 26495 caffe.cpp:212] Starting Optimization
I0525 23:30:01.747776 26495 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 23:30:01.747787 26495 solver.cpp:289] Learning Rate Policy: fixed
I0525 23:30:01.749003 26495 solver.cpp:341] Iteration 450000, Testing net (#0)
I0525 23:31:02.356603 26495 solver.cpp:409]     Test net output #0: accuracy = 0.892808
I0525 23:31:02.356758 26495 solver.cpp:409]     Test net output #1: loss = 0.356307 (* 1 = 0.356307 loss)
I0525 23:31:02.374526 26495 solver.cpp:237] Iteration 450000, loss = 1.06624
I0525 23:31:02.374562 26495 solver.cpp:253]     Train net output #0: loss = 1.06624 (* 1 = 1.06624 loss)
I0525 23:31:02.374580 26495 sgd_solver.cpp:106] Iteration 450000, lr = 0.0025
I0525 23:31:19.146952 26495 solver.cpp:237] Iteration 451500, loss = 1.16755
I0525 23:31:19.147001 26495 solver.cpp:253]     Train net output #0: loss = 1.16755 (* 1 = 1.16755 loss)
I0525 23:31:19.147016 26495 sgd_solver.cpp:106] Iteration 451500, lr = 0.0025
I0525 23:31:35.910295 26495 solver.cpp:237] Iteration 453000, loss = 1.35732
I0525 23:31:35.910460 26495 solver.cpp:253]     Train net output #0: loss = 1.35732 (* 1 = 1.35732 loss)
I0525 23:31:35.910475 26495 sgd_solver.cpp:106] Iteration 453000, lr = 0.0025
I0525 23:31:52.687801 26495 solver.cpp:237] Iteration 454500, loss = 1.06144
I0525 23:31:52.687837 26495 solver.cpp:253]     Train net output #0: loss = 1.06143 (* 1 = 1.06143 loss)
I0525 23:31:52.687851 26495 sgd_solver.cpp:106] Iteration 454500, lr = 0.0025
I0525 23:32:09.484401 26495 solver.cpp:237] Iteration 456000, loss = 0.782696
I0525 23:32:09.484552 26495 solver.cpp:253]     Train net output #0: loss = 0.782694 (* 1 = 0.782694 loss)
I0525 23:32:09.484567 26495 sgd_solver.cpp:106] Iteration 456000, lr = 0.0025
I0525 23:32:26.261912 26495 solver.cpp:237] Iteration 457500, loss = 0.727508
I0525 23:32:26.261960 26495 solver.cpp:253]     Train net output #0: loss = 0.727508 (* 1 = 0.727508 loss)
I0525 23:32:26.261973 26495 sgd_solver.cpp:106] Iteration 457500, lr = 0.0025
I0525 23:32:43.032871 26495 solver.cpp:237] Iteration 459000, loss = 1.16188
I0525 23:32:43.033025 26495 solver.cpp:253]     Train net output #0: loss = 1.16188 (* 1 = 1.16188 loss)
I0525 23:32:43.033046 26495 sgd_solver.cpp:106] Iteration 459000, lr = 0.0025
I0525 23:33:22.078063 26495 solver.cpp:237] Iteration 460500, loss = 0.63906
I0525 23:33:22.078222 26495 solver.cpp:253]     Train net output #0: loss = 0.639059 (* 1 = 0.639059 loss)
I0525 23:33:22.078238 26495 sgd_solver.cpp:106] Iteration 460500, lr = 0.0025
I0525 23:33:38.876998 26495 solver.cpp:237] Iteration 462000, loss = 1.84912
I0525 23:33:38.877053 26495 solver.cpp:253]     Train net output #0: loss = 1.84912 (* 1 = 1.84912 loss)
I0525 23:33:38.877066 26495 sgd_solver.cpp:106] Iteration 462000, lr = 0.0025
I0525 23:33:55.771859 26495 solver.cpp:237] Iteration 463500, loss = 1.17057
I0525 23:33:55.771997 26495 solver.cpp:253]     Train net output #0: loss = 1.17057 (* 1 = 1.17057 loss)
I0525 23:33:55.772011 26495 sgd_solver.cpp:106] Iteration 463500, lr = 0.0025
I0525 23:34:12.629694 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_465000.caffemodel
I0525 23:34:12.676525 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_465000.solverstate
I0525 23:34:12.706495 26495 solver.cpp:237] Iteration 465000, loss = 0.517886
I0525 23:34:12.706549 26495 solver.cpp:253]     Train net output #0: loss = 0.517884 (* 1 = 0.517884 loss)
I0525 23:34:12.706564 26495 sgd_solver.cpp:106] Iteration 465000, lr = 0.0025
I0525 23:34:29.643153 26495 solver.cpp:237] Iteration 466500, loss = 0.9893
I0525 23:34:29.643311 26495 solver.cpp:253]     Train net output #0: loss = 0.989298 (* 1 = 0.989298 loss)
I0525 23:34:29.643326 26495 sgd_solver.cpp:106] Iteration 466500, lr = 0.0025
I0525 23:34:46.495358 26495 solver.cpp:237] Iteration 468000, loss = 0.953132
I0525 23:34:46.495395 26495 solver.cpp:253]     Train net output #0: loss = 0.953129 (* 1 = 0.953129 loss)
I0525 23:34:46.495409 26495 sgd_solver.cpp:106] Iteration 468000, lr = 0.0025
I0525 23:35:03.113790 26495 solver.cpp:237] Iteration 469500, loss = 1.56359
I0525 23:35:03.113940 26495 solver.cpp:253]     Train net output #0: loss = 1.56359 (* 1 = 1.56359 loss)
I0525 23:35:03.113955 26495 sgd_solver.cpp:106] Iteration 469500, lr = 0.0025
I0525 23:35:41.882375 26495 solver.cpp:237] Iteration 471000, loss = 0.635276
I0525 23:35:41.882550 26495 solver.cpp:253]     Train net output #0: loss = 0.635273 (* 1 = 0.635273 loss)
I0525 23:35:41.882565 26495 sgd_solver.cpp:106] Iteration 471000, lr = 0.0025
I0525 23:35:58.473908 26495 solver.cpp:237] Iteration 472500, loss = 0.600802
I0525 23:35:58.473945 26495 solver.cpp:253]     Train net output #0: loss = 0.600798 (* 1 = 0.600798 loss)
I0525 23:35:58.473959 26495 sgd_solver.cpp:106] Iteration 472500, lr = 0.0025
I0525 23:36:15.092790 26495 solver.cpp:237] Iteration 474000, loss = 0.690697
I0525 23:36:15.092949 26495 solver.cpp:253]     Train net output #0: loss = 0.690693 (* 1 = 0.690693 loss)
I0525 23:36:15.092964 26495 sgd_solver.cpp:106] Iteration 474000, lr = 0.0025
I0525 23:36:31.700599 26495 solver.cpp:237] Iteration 475500, loss = 0.934377
I0525 23:36:31.700649 26495 solver.cpp:253]     Train net output #0: loss = 0.934374 (* 1 = 0.934374 loss)
I0525 23:36:31.700662 26495 sgd_solver.cpp:106] Iteration 475500, lr = 0.0025
I0525 23:36:48.318080 26495 solver.cpp:237] Iteration 477000, loss = 0.622553
I0525 23:36:48.318219 26495 solver.cpp:253]     Train net output #0: loss = 0.62255 (* 1 = 0.62255 loss)
I0525 23:36:48.318233 26495 sgd_solver.cpp:106] Iteration 477000, lr = 0.0025
I0525 23:37:04.925822 26495 solver.cpp:237] Iteration 478500, loss = 1.23738
I0525 23:37:04.925873 26495 solver.cpp:253]     Train net output #0: loss = 1.23738 (* 1 = 1.23738 loss)
I0525 23:37:04.925887 26495 sgd_solver.cpp:106] Iteration 478500, lr = 0.0025
I0525 23:37:21.530544 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_480000.caffemodel
I0525 23:37:21.577699 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_480000.solverstate
I0525 23:37:21.604122 26495 solver.cpp:341] Iteration 480000, Testing net (#0)
I0525 23:38:21.052829 26495 solver.cpp:409]     Test net output #0: accuracy = 0.897972
I0525 23:38:21.052983 26495 solver.cpp:409]     Test net output #1: loss = 0.3339 (* 1 = 0.3339 loss)
I0525 23:38:43.197943 26495 solver.cpp:237] Iteration 480000, loss = 1.3797
I0525 23:38:43.197998 26495 solver.cpp:253]     Train net output #0: loss = 1.37969 (* 1 = 1.37969 loss)
I0525 23:38:43.198012 26495 sgd_solver.cpp:106] Iteration 480000, lr = 0.0025
I0525 23:39:00.236423 26495 solver.cpp:237] Iteration 481500, loss = 1.2341
I0525 23:39:00.236582 26495 solver.cpp:253]     Train net output #0: loss = 1.2341 (* 1 = 1.2341 loss)
I0525 23:39:00.236595 26495 sgd_solver.cpp:106] Iteration 481500, lr = 0.0025
I0525 23:39:17.280328 26495 solver.cpp:237] Iteration 483000, loss = 1.14092
I0525 23:39:17.280364 26495 solver.cpp:253]     Train net output #0: loss = 1.14091 (* 1 = 1.14091 loss)
I0525 23:39:17.280378 26495 sgd_solver.cpp:106] Iteration 483000, lr = 0.0025
I0525 23:39:34.332432 26495 solver.cpp:237] Iteration 484500, loss = 1.65045
I0525 23:39:34.332579 26495 solver.cpp:253]     Train net output #0: loss = 1.65044 (* 1 = 1.65044 loss)
I0525 23:39:34.332593 26495 sgd_solver.cpp:106] Iteration 484500, lr = 0.0025
I0525 23:39:51.386260 26495 solver.cpp:237] Iteration 486000, loss = 0.858173
I0525 23:39:51.386308 26495 solver.cpp:253]     Train net output #0: loss = 0.858167 (* 1 = 0.858167 loss)
I0525 23:39:51.386324 26495 sgd_solver.cpp:106] Iteration 486000, lr = 0.0025
I0525 23:40:08.466083 26495 solver.cpp:237] Iteration 487500, loss = 1.5474
I0525 23:40:08.466229 26495 solver.cpp:253]     Train net output #0: loss = 1.5474 (* 1 = 1.5474 loss)
I0525 23:40:08.466243 26495 sgd_solver.cpp:106] Iteration 487500, lr = 0.0025
I0525 23:40:25.491945 26495 solver.cpp:237] Iteration 489000, loss = 0.863633
I0525 23:40:25.491991 26495 solver.cpp:253]     Train net output #0: loss = 0.863625 (* 1 = 0.863625 loss)
I0525 23:40:25.492004 26495 sgd_solver.cpp:106] Iteration 489000, lr = 0.0025
I0525 23:41:04.742565 26495 solver.cpp:237] Iteration 490500, loss = 1.14308
I0525 23:41:04.742734 26495 solver.cpp:253]     Train net output #0: loss = 1.14307 (* 1 = 1.14307 loss)
I0525 23:41:04.742748 26495 sgd_solver.cpp:106] Iteration 490500, lr = 0.0025
I0525 23:41:21.800915 26495 solver.cpp:237] Iteration 492000, loss = 1.07979
I0525 23:41:21.800951 26495 solver.cpp:253]     Train net output #0: loss = 1.07978 (* 1 = 1.07978 loss)
I0525 23:41:21.800968 26495 sgd_solver.cpp:106] Iteration 492000, lr = 0.0025
I0525 23:41:38.850846 26495 solver.cpp:237] Iteration 493500, loss = 1.45366
I0525 23:41:38.850998 26495 solver.cpp:253]     Train net output #0: loss = 1.45366 (* 1 = 1.45366 loss)
I0525 23:41:38.851012 26495 sgd_solver.cpp:106] Iteration 493500, lr = 0.0025
I0525 23:41:55.890055 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_495000.caffemodel
I0525 23:41:55.938236 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_495000.solverstate
I0525 23:41:55.969291 26495 solver.cpp:237] Iteration 495000, loss = 0.634387
I0525 23:41:55.969343 26495 solver.cpp:253]     Train net output #0: loss = 0.634378 (* 1 = 0.634378 loss)
I0525 23:41:55.969358 26495 sgd_solver.cpp:106] Iteration 495000, lr = 0.0025
I0525 23:42:13.028164 26495 solver.cpp:237] Iteration 496500, loss = 0.585431
I0525 23:42:13.028308 26495 solver.cpp:253]     Train net output #0: loss = 0.585423 (* 1 = 0.585423 loss)
I0525 23:42:13.028324 26495 sgd_solver.cpp:106] Iteration 496500, lr = 0.0025
I0525 23:42:30.082307 26495 solver.cpp:237] Iteration 498000, loss = 0.897935
I0525 23:42:30.082358 26495 solver.cpp:253]     Train net output #0: loss = 0.897927 (* 1 = 0.897927 loss)
I0525 23:42:30.082375 26495 sgd_solver.cpp:106] Iteration 498000, lr = 0.0025
I0525 23:42:47.157593 26495 solver.cpp:237] Iteration 499500, loss = 1.5515
I0525 23:42:47.157747 26495 solver.cpp:253]     Train net output #0: loss = 1.55149 (* 1 = 1.55149 loss)
I0525 23:42:47.157762 26495 sgd_solver.cpp:106] Iteration 499500, lr = 0.0025
I0525 23:43:26.383656 26495 solver.cpp:237] Iteration 501000, loss = 0.862978
I0525 23:43:26.383819 26495 solver.cpp:253]     Train net output #0: loss = 0.862971 (* 1 = 0.862971 loss)
I0525 23:43:26.383833 26495 sgd_solver.cpp:106] Iteration 501000, lr = 0.0025
I0525 23:43:43.442059 26495 solver.cpp:237] Iteration 502500, loss = 1.00689
I0525 23:43:43.442106 26495 solver.cpp:253]     Train net output #0: loss = 1.00688 (* 1 = 1.00688 loss)
I0525 23:43:43.442118 26495 sgd_solver.cpp:106] Iteration 502500, lr = 0.0025
I0525 23:44:00.498946 26495 solver.cpp:237] Iteration 504000, loss = 1.08794
I0525 23:44:00.499097 26495 solver.cpp:253]     Train net output #0: loss = 1.08793 (* 1 = 1.08793 loss)
I0525 23:44:00.499111 26495 sgd_solver.cpp:106] Iteration 504000, lr = 0.0025
I0525 23:44:17.549917 26495 solver.cpp:237] Iteration 505500, loss = 0.883461
I0525 23:44:17.549954 26495 solver.cpp:253]     Train net output #0: loss = 0.883453 (* 1 = 0.883453 loss)
I0525 23:44:17.549970 26495 sgd_solver.cpp:106] Iteration 505500, lr = 0.0025
I0525 23:44:34.614055 26495 solver.cpp:237] Iteration 507000, loss = 0.670661
I0525 23:44:34.614207 26495 solver.cpp:253]     Train net output #0: loss = 0.670652 (* 1 = 0.670652 loss)
I0525 23:44:34.614222 26495 sgd_solver.cpp:106] Iteration 507000, lr = 0.0025
I0525 23:44:51.639508 26495 solver.cpp:237] Iteration 508500, loss = 1.37725
I0525 23:44:51.639552 26495 solver.cpp:253]     Train net output #0: loss = 1.37724 (* 1 = 1.37724 loss)
I0525 23:44:51.639569 26495 sgd_solver.cpp:106] Iteration 508500, lr = 0.0025
I0525 23:45:08.707790 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_510000.caffemodel
I0525 23:45:08.756088 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_510000.solverstate
I0525 23:45:08.783403 26495 solver.cpp:341] Iteration 510000, Testing net (#0)
I0525 23:46:29.082763 26495 solver.cpp:409]     Test net output #0: accuracy = 0.894298
I0525 23:46:29.082926 26495 solver.cpp:409]     Test net output #1: loss = 0.334444 (* 1 = 0.334444 loss)
I0525 23:46:51.269829 26495 solver.cpp:237] Iteration 510000, loss = 0.609113
I0525 23:46:51.269886 26495 solver.cpp:253]     Train net output #0: loss = 0.609105 (* 1 = 0.609105 loss)
I0525 23:46:51.269901 26495 sgd_solver.cpp:106] Iteration 510000, lr = 0.0025
I0525 23:47:08.224786 26495 solver.cpp:237] Iteration 511500, loss = 0.717321
I0525 23:47:08.224948 26495 solver.cpp:253]     Train net output #0: loss = 0.717311 (* 1 = 0.717311 loss)
I0525 23:47:08.224962 26495 sgd_solver.cpp:106] Iteration 511500, lr = 0.0025
I0525 23:47:25.135670 26495 solver.cpp:237] Iteration 513000, loss = 1.03244
I0525 23:47:25.135717 26495 solver.cpp:253]     Train net output #0: loss = 1.03243 (* 1 = 1.03243 loss)
I0525 23:47:25.135731 26495 sgd_solver.cpp:106] Iteration 513000, lr = 0.0025
I0525 23:47:41.923493 26495 solver.cpp:237] Iteration 514500, loss = 1.30491
I0525 23:47:41.923645 26495 solver.cpp:253]     Train net output #0: loss = 1.3049 (* 1 = 1.3049 loss)
I0525 23:47:41.923660 26495 sgd_solver.cpp:106] Iteration 514500, lr = 0.0025
I0525 23:47:58.690698 26495 solver.cpp:237] Iteration 516000, loss = 1.07274
I0525 23:47:58.690743 26495 solver.cpp:253]     Train net output #0: loss = 1.07273 (* 1 = 1.07273 loss)
I0525 23:47:58.690757 26495 sgd_solver.cpp:106] Iteration 516000, lr = 0.0025
I0525 23:48:15.469280 26495 solver.cpp:237] Iteration 517500, loss = 1.25383
I0525 23:48:15.469434 26495 solver.cpp:253]     Train net output #0: loss = 1.25382 (* 1 = 1.25382 loss)
I0525 23:48:15.469449 26495 sgd_solver.cpp:106] Iteration 517500, lr = 0.0025
I0525 23:48:32.240916 26495 solver.cpp:237] Iteration 519000, loss = 1.56274
I0525 23:48:32.240952 26495 solver.cpp:253]     Train net output #0: loss = 1.56273 (* 1 = 1.56273 loss)
I0525 23:48:32.240964 26495 sgd_solver.cpp:106] Iteration 519000, lr = 0.0025
I0525 23:49:11.039397 26495 solver.cpp:237] Iteration 520500, loss = 1.62338
I0525 23:49:11.039569 26495 solver.cpp:253]     Train net output #0: loss = 1.62337 (* 1 = 1.62337 loss)
I0525 23:49:11.039584 26495 sgd_solver.cpp:106] Iteration 520500, lr = 0.0025
I0525 23:49:27.653172 26495 solver.cpp:237] Iteration 522000, loss = 1.17918
I0525 23:49:27.653218 26495 solver.cpp:253]     Train net output #0: loss = 1.17917 (* 1 = 1.17917 loss)
I0525 23:49:27.653230 26495 sgd_solver.cpp:106] Iteration 522000, lr = 0.0025
I0525 23:49:44.268915 26495 solver.cpp:237] Iteration 523500, loss = 0.509867
I0525 23:49:44.269064 26495 solver.cpp:253]     Train net output #0: loss = 0.509857 (* 1 = 0.509857 loss)
I0525 23:49:44.269079 26495 sgd_solver.cpp:106] Iteration 523500, lr = 0.0025
I0525 23:50:00.914083 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_525000.caffemodel
I0525 23:50:00.962101 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_525000.solverstate
I0525 23:50:00.992790 26495 solver.cpp:237] Iteration 525000, loss = 1.3289
I0525 23:50:00.992841 26495 solver.cpp:253]     Train net output #0: loss = 1.32889 (* 1 = 1.32889 loss)
I0525 23:50:00.992854 26495 sgd_solver.cpp:106] Iteration 525000, lr = 0.0025
I0525 23:50:17.617928 26495 solver.cpp:237] Iteration 526500, loss = 1.56725
I0525 23:50:17.618085 26495 solver.cpp:253]     Train net output #0: loss = 1.56724 (* 1 = 1.56724 loss)
I0525 23:50:17.618099 26495 sgd_solver.cpp:106] Iteration 526500, lr = 0.0025
I0525 23:50:34.254914 26495 solver.cpp:237] Iteration 528000, loss = 1.23181
I0525 23:50:34.254951 26495 solver.cpp:253]     Train net output #0: loss = 1.23179 (* 1 = 1.23179 loss)
I0525 23:50:34.254964 26495 sgd_solver.cpp:106] Iteration 528000, lr = 0.0025
I0525 23:50:50.869066 26495 solver.cpp:237] Iteration 529500, loss = 0.964042
I0525 23:50:50.869235 26495 solver.cpp:253]     Train net output #0: loss = 0.964031 (* 1 = 0.964031 loss)
I0525 23:50:50.869251 26495 sgd_solver.cpp:106] Iteration 529500, lr = 0.0025
I0525 23:51:29.631454 26495 solver.cpp:237] Iteration 531000, loss = 0.862758
I0525 23:51:29.631623 26495 solver.cpp:253]     Train net output #0: loss = 0.862747 (* 1 = 0.862747 loss)
I0525 23:51:29.631638 26495 sgd_solver.cpp:106] Iteration 531000, lr = 0.0025
I0525 23:51:46.246738 26495 solver.cpp:237] Iteration 532500, loss = 0.483707
I0525 23:51:46.246775 26495 solver.cpp:253]     Train net output #0: loss = 0.483696 (* 1 = 0.483696 loss)
I0525 23:51:46.246788 26495 sgd_solver.cpp:106] Iteration 532500, lr = 0.0025
I0525 23:52:02.887454 26495 solver.cpp:237] Iteration 534000, loss = 1.43429
I0525 23:52:02.887611 26495 solver.cpp:253]     Train net output #0: loss = 1.43428 (* 1 = 1.43428 loss)
I0525 23:52:02.887626 26495 sgd_solver.cpp:106] Iteration 534000, lr = 0.0025
I0525 23:52:19.515867 26495 solver.cpp:237] Iteration 535500, loss = 0.865024
I0525 23:52:19.515913 26495 solver.cpp:253]     Train net output #0: loss = 0.865015 (* 1 = 0.865015 loss)
I0525 23:52:19.515926 26495 sgd_solver.cpp:106] Iteration 535500, lr = 0.0025
I0525 23:52:36.159690 26495 solver.cpp:237] Iteration 537000, loss = 1.62648
I0525 23:52:36.159832 26495 solver.cpp:253]     Train net output #0: loss = 1.62647 (* 1 = 1.62647 loss)
I0525 23:52:36.159847 26495 sgd_solver.cpp:106] Iteration 537000, lr = 0.0025
I0525 23:52:52.769168 26495 solver.cpp:237] Iteration 538500, loss = 1.34722
I0525 23:52:52.769210 26495 solver.cpp:253]     Train net output #0: loss = 1.34721 (* 1 = 1.34721 loss)
I0525 23:52:52.769228 26495 sgd_solver.cpp:106] Iteration 538500, lr = 0.0025
I0525 23:53:09.402755 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_540000.caffemodel
I0525 23:53:09.448700 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_540000.solverstate
I0525 23:53:09.474076 26495 solver.cpp:341] Iteration 540000, Testing net (#0)
I0525 23:54:08.670392 26495 solver.cpp:409]     Test net output #0: accuracy = 0.895664
I0525 23:54:08.670559 26495 solver.cpp:409]     Test net output #1: loss = 0.345083 (* 1 = 0.345083 loss)
I0525 23:54:30.843482 26495 solver.cpp:237] Iteration 540000, loss = 1.27234
I0525 23:54:30.843534 26495 solver.cpp:253]     Train net output #0: loss = 1.27233 (* 1 = 1.27233 loss)
I0525 23:54:30.843549 26495 sgd_solver.cpp:106] Iteration 540000, lr = 0.0025
I0525 23:54:47.864866 26495 solver.cpp:237] Iteration 541500, loss = 0.818489
I0525 23:54:47.865030 26495 solver.cpp:253]     Train net output #0: loss = 0.81848 (* 1 = 0.81848 loss)
I0525 23:54:47.865049 26495 sgd_solver.cpp:106] Iteration 541500, lr = 0.0025
I0525 23:55:04.929173 26495 solver.cpp:237] Iteration 543000, loss = 1.20488
I0525 23:55:04.929216 26495 solver.cpp:253]     Train net output #0: loss = 1.20488 (* 1 = 1.20488 loss)
I0525 23:55:04.929230 26495 sgd_solver.cpp:106] Iteration 543000, lr = 0.0025
I0525 23:55:21.985312 26495 solver.cpp:237] Iteration 544500, loss = 2.1478
I0525 23:55:21.985469 26495 solver.cpp:253]     Train net output #0: loss = 2.1478 (* 1 = 2.1478 loss)
I0525 23:55:21.985486 26495 sgd_solver.cpp:106] Iteration 544500, lr = 0.0025
I0525 23:55:39.027794 26495 solver.cpp:237] Iteration 546000, loss = 1.41339
I0525 23:55:39.027844 26495 solver.cpp:253]     Train net output #0: loss = 1.41338 (* 1 = 1.41338 loss)
I0525 23:55:39.027858 26495 sgd_solver.cpp:106] Iteration 546000, lr = 0.0025
I0525 23:55:56.092183 26495 solver.cpp:237] Iteration 547500, loss = 1.02928
I0525 23:55:56.092339 26495 solver.cpp:253]     Train net output #0: loss = 1.02927 (* 1 = 1.02927 loss)
I0525 23:55:56.092353 26495 sgd_solver.cpp:106] Iteration 547500, lr = 0.0025
I0525 23:56:13.162130 26495 solver.cpp:237] Iteration 549000, loss = 1.41959
I0525 23:56:13.162178 26495 solver.cpp:253]     Train net output #0: loss = 1.41958 (* 1 = 1.41958 loss)
I0525 23:56:13.162190 26495 sgd_solver.cpp:106] Iteration 549000, lr = 0.0025
I0525 23:56:52.429298 26495 solver.cpp:237] Iteration 550500, loss = 1.65666
I0525 23:56:52.429468 26495 solver.cpp:253]     Train net output #0: loss = 1.65665 (* 1 = 1.65665 loss)
I0525 23:56:52.429482 26495 sgd_solver.cpp:106] Iteration 550500, lr = 0.0025
I0525 23:57:09.490942 26495 solver.cpp:237] Iteration 552000, loss = 0.911975
I0525 23:57:09.490993 26495 solver.cpp:253]     Train net output #0: loss = 0.911966 (* 1 = 0.911966 loss)
I0525 23:57:09.491008 26495 sgd_solver.cpp:106] Iteration 552000, lr = 0.0025
I0525 23:57:26.553282 26495 solver.cpp:237] Iteration 553500, loss = 0.85497
I0525 23:57:26.553444 26495 solver.cpp:253]     Train net output #0: loss = 0.854962 (* 1 = 0.854962 loss)
I0525 23:57:26.553462 26495 sgd_solver.cpp:106] Iteration 553500, lr = 0.0025
I0525 23:57:43.590243 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_555000.caffemodel
I0525 23:57:43.636617 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_555000.solverstate
I0525 23:57:43.665655 26495 solver.cpp:237] Iteration 555000, loss = 1.50122
I0525 23:57:43.665699 26495 solver.cpp:253]     Train net output #0: loss = 1.50121 (* 1 = 1.50121 loss)
I0525 23:57:43.665717 26495 sgd_solver.cpp:106] Iteration 555000, lr = 0.0025
I0525 23:58:00.727401 26495 solver.cpp:237] Iteration 556500, loss = 1.42255
I0525 23:58:00.727550 26495 solver.cpp:253]     Train net output #0: loss = 1.42254 (* 1 = 1.42254 loss)
I0525 23:58:00.727563 26495 sgd_solver.cpp:106] Iteration 556500, lr = 0.0025
I0525 23:58:17.783205 26495 solver.cpp:237] Iteration 558000, loss = 1.41405
I0525 23:58:17.783254 26495 solver.cpp:253]     Train net output #0: loss = 1.41404 (* 1 = 1.41404 loss)
I0525 23:58:17.783267 26495 sgd_solver.cpp:106] Iteration 558000, lr = 0.0025
I0525 23:58:34.848423 26495 solver.cpp:237] Iteration 559500, loss = 0.626126
I0525 23:58:34.848580 26495 solver.cpp:253]     Train net output #0: loss = 0.626118 (* 1 = 0.626118 loss)
I0525 23:58:34.848595 26495 sgd_solver.cpp:106] Iteration 559500, lr = 0.0025
I0525 23:59:14.057857 26495 solver.cpp:237] Iteration 561000, loss = 1.49521
I0525 23:59:14.058022 26495 solver.cpp:253]     Train net output #0: loss = 1.4952 (* 1 = 1.4952 loss)
I0525 23:59:14.058037 26495 sgd_solver.cpp:106] Iteration 561000, lr = 0.0025
I0525 23:59:31.138295 26495 solver.cpp:237] Iteration 562500, loss = 2.87215
I0525 23:59:31.138345 26495 solver.cpp:253]     Train net output #0: loss = 2.87214 (* 1 = 2.87214 loss)
I0525 23:59:31.138357 26495 sgd_solver.cpp:106] Iteration 562500, lr = 0.0025
I0525 23:59:48.191607 26495 solver.cpp:237] Iteration 564000, loss = 1.75132
I0525 23:59:48.191754 26495 solver.cpp:253]     Train net output #0: loss = 1.75132 (* 1 = 1.75132 loss)
I0525 23:59:48.191769 26495 sgd_solver.cpp:106] Iteration 564000, lr = 0.0025
I0526 00:00:05.255198 26495 solver.cpp:237] Iteration 565500, loss = 1.21828
I0526 00:00:05.255245 26495 solver.cpp:253]     Train net output #0: loss = 1.21828 (* 1 = 1.21828 loss)
I0526 00:00:05.255259 26495 sgd_solver.cpp:106] Iteration 565500, lr = 0.0025
I0526 00:00:22.309887 26495 solver.cpp:237] Iteration 567000, loss = 0.840546
I0526 00:00:22.310048 26495 solver.cpp:253]     Train net output #0: loss = 0.840537 (* 1 = 0.840537 loss)
I0526 00:00:22.310065 26495 sgd_solver.cpp:106] Iteration 567000, lr = 0.0025
I0526 00:00:39.385910 26495 solver.cpp:237] Iteration 568500, loss = 1.7202
I0526 00:00:39.385960 26495 solver.cpp:253]     Train net output #0: loss = 1.72019 (* 1 = 1.72019 loss)
I0526 00:00:39.385974 26495 sgd_solver.cpp:106] Iteration 568500, lr = 0.0025
I0526 00:00:56.241943 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_570000.caffemodel
I0526 00:00:56.287381 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_570000.solverstate
I0526 00:00:56.312777 26495 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 00:02:16.513669 26495 solver.cpp:409]     Test net output #0: accuracy = 0.893995
I0526 00:02:16.513834 26495 solver.cpp:409]     Test net output #1: loss = 0.336068 (* 1 = 0.336068 loss)
I0526 00:02:38.676271 26495 solver.cpp:237] Iteration 570000, loss = 1.66108
I0526 00:02:38.676324 26495 solver.cpp:253]     Train net output #0: loss = 1.66107 (* 1 = 1.66107 loss)
I0526 00:02:38.676342 26495 sgd_solver.cpp:106] Iteration 570000, lr = 0.0025
I0526 00:02:55.647752 26495 solver.cpp:237] Iteration 571500, loss = 1.27234
I0526 00:02:55.647923 26495 solver.cpp:253]     Train net output #0: loss = 1.27233 (* 1 = 1.27233 loss)
I0526 00:02:55.647938 26495 sgd_solver.cpp:106] Iteration 571500, lr = 0.0025
I0526 00:03:12.621119 26495 solver.cpp:237] Iteration 573000, loss = 1.24985
I0526 00:03:12.621160 26495 solver.cpp:253]     Train net output #0: loss = 1.24984 (* 1 = 1.24984 loss)
I0526 00:03:12.621176 26495 sgd_solver.cpp:106] Iteration 573000, lr = 0.0025
I0526 00:03:29.577836 26495 solver.cpp:237] Iteration 574500, loss = 1.08571
I0526 00:03:29.577977 26495 solver.cpp:253]     Train net output #0: loss = 1.0857 (* 1 = 1.0857 loss)
I0526 00:03:29.577991 26495 sgd_solver.cpp:106] Iteration 574500, lr = 0.0025
I0526 00:03:46.566956 26495 solver.cpp:237] Iteration 576000, loss = 1.40435
I0526 00:03:46.567000 26495 solver.cpp:253]     Train net output #0: loss = 1.40434 (* 1 = 1.40434 loss)
I0526 00:03:46.567014 26495 sgd_solver.cpp:106] Iteration 576000, lr = 0.0025
I0526 00:04:03.535220 26495 solver.cpp:237] Iteration 577500, loss = 1.18505
I0526 00:04:03.535378 26495 solver.cpp:253]     Train net output #0: loss = 1.18504 (* 1 = 1.18504 loss)
I0526 00:04:03.535392 26495 sgd_solver.cpp:106] Iteration 577500, lr = 0.0025
I0526 00:04:20.473721 26495 solver.cpp:237] Iteration 579000, loss = 0.928897
I0526 00:04:20.473757 26495 solver.cpp:253]     Train net output #0: loss = 0.928887 (* 1 = 0.928887 loss)
I0526 00:04:20.473772 26495 sgd_solver.cpp:106] Iteration 579000, lr = 0.0025
I0526 00:04:59.693092 26495 solver.cpp:237] Iteration 580500, loss = 0.887323
I0526 00:04:59.693259 26495 solver.cpp:253]     Train net output #0: loss = 0.887312 (* 1 = 0.887312 loss)
I0526 00:04:59.693275 26495 sgd_solver.cpp:106] Iteration 580500, lr = 0.0025
I0526 00:05:16.655832 26495 solver.cpp:237] Iteration 582000, loss = 0.426301
I0526 00:05:16.655879 26495 solver.cpp:253]     Train net output #0: loss = 0.42629 (* 1 = 0.42629 loss)
I0526 00:05:16.655892 26495 sgd_solver.cpp:106] Iteration 582000, lr = 0.0025
I0526 00:05:33.618340 26495 solver.cpp:237] Iteration 583500, loss = 1.12058
I0526 00:05:33.618484 26495 solver.cpp:253]     Train net output #0: loss = 1.12057 (* 1 = 1.12057 loss)
I0526 00:05:33.618499 26495 sgd_solver.cpp:106] Iteration 583500, lr = 0.0025
I0526 00:05:50.570008 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_585000.caffemodel
I0526 00:05:50.617667 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_585000.solverstate
I0526 00:05:50.648654 26495 solver.cpp:237] Iteration 585000, loss = 1.37993
I0526 00:05:50.648705 26495 solver.cpp:253]     Train net output #0: loss = 1.37992 (* 1 = 1.37992 loss)
I0526 00:05:50.648720 26495 sgd_solver.cpp:106] Iteration 585000, lr = 0.0025
I0526 00:06:07.604189 26495 solver.cpp:237] Iteration 586500, loss = 0.811545
I0526 00:06:07.604365 26495 solver.cpp:253]     Train net output #0: loss = 0.811534 (* 1 = 0.811534 loss)
I0526 00:06:07.604379 26495 sgd_solver.cpp:106] Iteration 586500, lr = 0.0025
I0526 00:06:24.596580 26495 solver.cpp:237] Iteration 588000, loss = 1.80295
I0526 00:06:24.596617 26495 solver.cpp:253]     Train net output #0: loss = 1.80294 (* 1 = 1.80294 loss)
I0526 00:06:24.596632 26495 sgd_solver.cpp:106] Iteration 588000, lr = 0.0025
I0526 00:06:41.551554 26495 solver.cpp:237] Iteration 589500, loss = 1.6186
I0526 00:06:41.551708 26495 solver.cpp:253]     Train net output #0: loss = 1.61859 (* 1 = 1.61859 loss)
I0526 00:06:41.551724 26495 sgd_solver.cpp:106] Iteration 589500, lr = 0.0025
I0526 00:07:20.718375 26495 solver.cpp:237] Iteration 591000, loss = 0.745013
I0526 00:07:20.718545 26495 solver.cpp:253]     Train net output #0: loss = 0.745002 (* 1 = 0.745002 loss)
I0526 00:07:20.718560 26495 sgd_solver.cpp:106] Iteration 591000, lr = 0.0025
I0526 00:07:37.684367 26495 solver.cpp:237] Iteration 592500, loss = 2.18401
I0526 00:07:37.684403 26495 solver.cpp:253]     Train net output #0: loss = 2.184 (* 1 = 2.184 loss)
I0526 00:07:37.684417 26495 sgd_solver.cpp:106] Iteration 592500, lr = 0.0025
I0526 00:07:54.645210 26495 solver.cpp:237] Iteration 594000, loss = 1.71181
I0526 00:07:54.645372 26495 solver.cpp:253]     Train net output #0: loss = 1.7118 (* 1 = 1.7118 loss)
I0526 00:07:54.645388 26495 sgd_solver.cpp:106] Iteration 594000, lr = 0.0025
I0526 00:08:11.628470 26495 solver.cpp:237] Iteration 595500, loss = 1.20455
I0526 00:08:11.628521 26495 solver.cpp:253]     Train net output #0: loss = 1.20454 (* 1 = 1.20454 loss)
I0526 00:08:11.628535 26495 sgd_solver.cpp:106] Iteration 595500, lr = 0.0025
I0526 00:08:28.611156 26495 solver.cpp:237] Iteration 597000, loss = 1.28324
I0526 00:08:28.611305 26495 solver.cpp:253]     Train net output #0: loss = 1.28323 (* 1 = 1.28323 loss)
I0526 00:08:28.611320 26495 sgd_solver.cpp:106] Iteration 597000, lr = 0.0025
I0526 00:08:45.596340 26495 solver.cpp:237] Iteration 598500, loss = 1.37501
I0526 00:08:45.596386 26495 solver.cpp:253]     Train net output #0: loss = 1.375 (* 1 = 1.375 loss)
I0526 00:08:45.596401 26495 sgd_solver.cpp:106] Iteration 598500, lr = 0.0025
I0526 00:09:02.544515 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_600000.caffemodel
I0526 00:09:02.592491 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_600000.solverstate
I0526 00:09:02.619881 26495 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 00:10:02.058362 26495 solver.cpp:409]     Test net output #0: accuracy = 0.895072
I0526 00:10:02.058526 26495 solver.cpp:409]     Test net output #1: loss = 0.326895 (* 1 = 0.326895 loss)
I0526 00:10:23.000900 26495 solver.cpp:237] Iteration 600000, loss = 1.55041
I0526 00:10:23.000953 26495 solver.cpp:253]     Train net output #0: loss = 1.5504 (* 1 = 1.5504 loss)
I0526 00:10:23.000968 26495 sgd_solver.cpp:106] Iteration 600000, lr = 0.0025
I0526 00:10:39.635354 26495 solver.cpp:237] Iteration 601500, loss = 0.990401
I0526 00:10:39.635521 26495 solver.cpp:253]     Train net output #0: loss = 0.99039 (* 1 = 0.99039 loss)
I0526 00:10:39.635536 26495 sgd_solver.cpp:106] Iteration 601500, lr = 0.0025
I0526 00:10:56.264459 26495 solver.cpp:237] Iteration 603000, loss = 1.08978
I0526 00:10:56.264497 26495 solver.cpp:253]     Train net output #0: loss = 1.08977 (* 1 = 1.08977 loss)
I0526 00:10:56.264509 26495 sgd_solver.cpp:106] Iteration 603000, lr = 0.0025
I0526 00:11:12.882136 26495 solver.cpp:237] Iteration 604500, loss = 0.953552
I0526 00:11:12.882309 26495 solver.cpp:253]     Train net output #0: loss = 0.95354 (* 1 = 0.95354 loss)
I0526 00:11:12.882324 26495 sgd_solver.cpp:106] Iteration 604500, lr = 0.0025
I0526 00:11:29.513840 26495 solver.cpp:237] Iteration 606000, loss = 0.27966
I0526 00:11:29.513888 26495 solver.cpp:253]     Train net output #0: loss = 0.279648 (* 1 = 0.279648 loss)
I0526 00:11:29.513903 26495 sgd_solver.cpp:106] Iteration 606000, lr = 0.0025
I0526 00:11:46.140612 26495 solver.cpp:237] Iteration 607500, loss = 1.11928
I0526 00:11:46.140761 26495 solver.cpp:253]     Train net output #0: loss = 1.11927 (* 1 = 1.11927 loss)
I0526 00:11:46.140775 26495 sgd_solver.cpp:106] Iteration 607500, lr = 0.0025
I0526 00:12:02.808426 26495 solver.cpp:237] Iteration 609000, loss = 0.524579
I0526 00:12:02.808471 26495 solver.cpp:253]     Train net output #0: loss = 0.524568 (* 1 = 0.524568 loss)
I0526 00:12:02.808485 26495 sgd_solver.cpp:106] Iteration 609000, lr = 0.0025
I0526 00:12:40.381847 26495 solver.cpp:237] Iteration 610500, loss = 0.608649
I0526 00:12:40.382015 26495 solver.cpp:253]     Train net output #0: loss = 0.608638 (* 1 = 0.608638 loss)
I0526 00:12:40.382032 26495 sgd_solver.cpp:106] Iteration 610500, lr = 0.0025
I0526 00:12:57.036630 26495 solver.cpp:237] Iteration 612000, loss = 1.17589
I0526 00:12:57.036679 26495 solver.cpp:253]     Train net output #0: loss = 1.17588 (* 1 = 1.17588 loss)
I0526 00:12:57.036695 26495 sgd_solver.cpp:106] Iteration 612000, lr = 0.0025
I0526 00:13:13.785733 26495 solver.cpp:237] Iteration 613500, loss = 1.26593
I0526 00:13:13.785892 26495 solver.cpp:253]     Train net output #0: loss = 1.26592 (* 1 = 1.26592 loss)
I0526 00:13:13.785907 26495 sgd_solver.cpp:106] Iteration 613500, lr = 0.0025
I0526 00:13:30.687824 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_615000.caffemodel
I0526 00:13:30.734258 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_615000.solverstate
I0526 00:13:30.763203 26495 solver.cpp:237] Iteration 615000, loss = 0.974655
I0526 00:13:30.763245 26495 solver.cpp:253]     Train net output #0: loss = 0.974646 (* 1 = 0.974646 loss)
I0526 00:13:30.763259 26495 sgd_solver.cpp:106] Iteration 615000, lr = 0.0025
I0526 00:13:47.666162 26495 solver.cpp:237] Iteration 616500, loss = 0.407285
I0526 00:13:47.666338 26495 solver.cpp:253]     Train net output #0: loss = 0.407276 (* 1 = 0.407276 loss)
I0526 00:13:47.666355 26495 sgd_solver.cpp:106] Iteration 616500, lr = 0.0025
I0526 00:14:04.507652 26495 solver.cpp:237] Iteration 618000, loss = 1.54863
I0526 00:14:04.507699 26495 solver.cpp:253]     Train net output #0: loss = 1.54862 (* 1 = 1.54862 loss)
I0526 00:14:04.507714 26495 sgd_solver.cpp:106] Iteration 618000, lr = 0.0025
I0526 00:14:21.415125 26495 solver.cpp:237] Iteration 619500, loss = 1.18371
I0526 00:14:21.415274 26495 solver.cpp:253]     Train net output #0: loss = 1.1837 (* 1 = 1.1837 loss)
I0526 00:14:21.415289 26495 sgd_solver.cpp:106] Iteration 619500, lr = 0.0025
I0526 00:14:59.172582 26495 solver.cpp:237] Iteration 621000, loss = 1.15986
I0526 00:14:59.172749 26495 solver.cpp:253]     Train net output #0: loss = 1.15985 (* 1 = 1.15985 loss)
I0526 00:14:59.172762 26495 sgd_solver.cpp:106] Iteration 621000, lr = 0.0025
I0526 00:15:16.009405 26495 solver.cpp:237] Iteration 622500, loss = 0.664944
I0526 00:15:16.009450 26495 solver.cpp:253]     Train net output #0: loss = 0.664934 (* 1 = 0.664934 loss)
I0526 00:15:16.009464 26495 sgd_solver.cpp:106] Iteration 622500, lr = 0.0025
I0526 00:15:32.835870 26495 solver.cpp:237] Iteration 624000, loss = 0.895887
I0526 00:15:32.836019 26495 solver.cpp:253]     Train net output #0: loss = 0.895877 (* 1 = 0.895877 loss)
I0526 00:15:32.836032 26495 sgd_solver.cpp:106] Iteration 624000, lr = 0.0025
I0526 00:15:49.762084 26495 solver.cpp:237] Iteration 625500, loss = 1.01817
I0526 00:15:49.762131 26495 solver.cpp:253]     Train net output #0: loss = 1.01817 (* 1 = 1.01817 loss)
I0526 00:15:49.762145 26495 sgd_solver.cpp:106] Iteration 625500, lr = 0.0025
I0526 00:16:06.640445 26495 solver.cpp:237] Iteration 627000, loss = 1.33518
I0526 00:16:06.640619 26495 solver.cpp:253]     Train net output #0: loss = 1.33517 (* 1 = 1.33517 loss)
I0526 00:16:06.640633 26495 sgd_solver.cpp:106] Iteration 627000, lr = 0.0025
I0526 00:16:23.505003 26495 solver.cpp:237] Iteration 628500, loss = 1.59081
I0526 00:16:23.505046 26495 solver.cpp:253]     Train net output #0: loss = 1.5908 (* 1 = 1.5908 loss)
I0526 00:16:23.505061 26495 sgd_solver.cpp:106] Iteration 628500, lr = 0.0025
I0526 00:16:40.393086 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_630000.caffemodel
I0526 00:16:40.439090 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_630000.solverstate
I0526 00:16:40.464850 26495 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 00:18:00.615142 26495 solver.cpp:409]     Test net output #0: accuracy = 0.900852
I0526 00:18:00.615310 26495 solver.cpp:409]     Test net output #1: loss = 0.311598 (* 1 = 0.311598 loss)
I0526 00:18:21.470470 26495 solver.cpp:237] Iteration 630000, loss = 1.14487
I0526 00:18:21.470523 26495 solver.cpp:253]     Train net output #0: loss = 1.14486 (* 1 = 1.14486 loss)
I0526 00:18:21.470537 26495 sgd_solver.cpp:106] Iteration 630000, lr = 0.0025
I0526 00:18:38.441359 26495 solver.cpp:237] Iteration 631500, loss = 1.47323
I0526 00:18:38.441526 26495 solver.cpp:253]     Train net output #0: loss = 1.47323 (* 1 = 1.47323 loss)
I0526 00:18:38.441541 26495 sgd_solver.cpp:106] Iteration 631500, lr = 0.0025
I0526 00:18:55.395699 26495 solver.cpp:237] Iteration 633000, loss = 1.37615
I0526 00:18:55.395735 26495 solver.cpp:253]     Train net output #0: loss = 1.37614 (* 1 = 1.37614 loss)
I0526 00:18:55.395748 26495 sgd_solver.cpp:106] Iteration 633000, lr = 0.0025
I0526 00:19:12.362154 26495 solver.cpp:237] Iteration 634500, loss = 1.76455
I0526 00:19:12.362325 26495 solver.cpp:253]     Train net output #0: loss = 1.76454 (* 1 = 1.76454 loss)
I0526 00:19:12.362341 26495 sgd_solver.cpp:106] Iteration 634500, lr = 0.0025
I0526 00:19:29.312428 26495 solver.cpp:237] Iteration 636000, loss = 1.22294
I0526 00:19:29.312474 26495 solver.cpp:253]     Train net output #0: loss = 1.22293 (* 1 = 1.22293 loss)
I0526 00:19:29.312489 26495 sgd_solver.cpp:106] Iteration 636000, lr = 0.0025
I0526 00:19:46.282498 26495 solver.cpp:237] Iteration 637500, loss = 0.983911
I0526 00:19:46.282649 26495 solver.cpp:253]     Train net output #0: loss = 0.983903 (* 1 = 0.983903 loss)
I0526 00:19:46.282665 26495 sgd_solver.cpp:106] Iteration 637500, lr = 0.0025
I0526 00:20:03.228050 26495 solver.cpp:237] Iteration 639000, loss = 0.822069
I0526 00:20:03.228097 26495 solver.cpp:253]     Train net output #0: loss = 0.822061 (* 1 = 0.822061 loss)
I0526 00:20:03.228111 26495 sgd_solver.cpp:106] Iteration 639000, lr = 0.0025
I0526 00:20:41.092571 26495 solver.cpp:237] Iteration 640500, loss = 1.17158
I0526 00:20:41.092741 26495 solver.cpp:253]     Train net output #0: loss = 1.17157 (* 1 = 1.17157 loss)
I0526 00:20:41.092756 26495 sgd_solver.cpp:106] Iteration 640500, lr = 0.0025
I0526 00:20:58.049536 26495 solver.cpp:237] Iteration 642000, loss = 0.793631
I0526 00:20:58.049573 26495 solver.cpp:253]     Train net output #0: loss = 0.793624 (* 1 = 0.793624 loss)
I0526 00:20:58.049587 26495 sgd_solver.cpp:106] Iteration 642000, lr = 0.0025
I0526 00:21:15.017027 26495 solver.cpp:237] Iteration 643500, loss = 1.41136
I0526 00:21:15.017195 26495 solver.cpp:253]     Train net output #0: loss = 1.41135 (* 1 = 1.41135 loss)
I0526 00:21:15.017210 26495 sgd_solver.cpp:106] Iteration 643500, lr = 0.0025
I0526 00:21:31.963129 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_645000.caffemodel
I0526 00:21:32.009537 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_645000.solverstate
I0526 00:21:32.040292 26495 solver.cpp:237] Iteration 645000, loss = 1.09402
I0526 00:21:32.040341 26495 solver.cpp:253]     Train net output #0: loss = 1.09401 (* 1 = 1.09401 loss)
I0526 00:21:32.040355 26495 sgd_solver.cpp:106] Iteration 645000, lr = 0.0025
I0526 00:21:49.116153 26495 solver.cpp:237] Iteration 646500, loss = 2.61116
I0526 00:21:49.116317 26495 solver.cpp:253]     Train net output #0: loss = 2.61115 (* 1 = 2.61115 loss)
I0526 00:21:49.116330 26495 sgd_solver.cpp:106] Iteration 646500, lr = 0.0025
I0526 00:22:06.164165 26495 solver.cpp:237] Iteration 648000, loss = 0.582555
I0526 00:22:06.164214 26495 solver.cpp:253]     Train net output #0: loss = 0.582548 (* 1 = 0.582548 loss)
I0526 00:22:06.164230 26495 sgd_solver.cpp:106] Iteration 648000, lr = 0.0025
I0526 00:22:23.209697 26495 solver.cpp:237] Iteration 649500, loss = 0.666807
I0526 00:22:23.209861 26495 solver.cpp:253]     Train net output #0: loss = 0.6668 (* 1 = 0.6668 loss)
I0526 00:22:23.209875 26495 sgd_solver.cpp:106] Iteration 649500, lr = 0.0025
I0526 00:23:01.160790 26495 solver.cpp:237] Iteration 651000, loss = 0.971549
I0526 00:23:01.160960 26495 solver.cpp:253]     Train net output #0: loss = 0.971542 (* 1 = 0.971542 loss)
I0526 00:23:01.160975 26495 sgd_solver.cpp:106] Iteration 651000, lr = 0.0025
I0526 00:23:18.210819 26495 solver.cpp:237] Iteration 652500, loss = 0.579699
I0526 00:23:18.210862 26495 solver.cpp:253]     Train net output #0: loss = 0.579692 (* 1 = 0.579692 loss)
I0526 00:23:18.210875 26495 sgd_solver.cpp:106] Iteration 652500, lr = 0.0025
I0526 00:23:35.276160 26495 solver.cpp:237] Iteration 654000, loss = 1.20668
I0526 00:23:35.276317 26495 solver.cpp:253]     Train net output #0: loss = 1.20668 (* 1 = 1.20668 loss)
I0526 00:23:35.276331 26495 sgd_solver.cpp:106] Iteration 654000, lr = 0.0025
I0526 00:23:52.357681 26495 solver.cpp:237] Iteration 655500, loss = 0.585382
I0526 00:23:52.357718 26495 solver.cpp:253]     Train net output #0: loss = 0.585374 (* 1 = 0.585374 loss)
I0526 00:23:52.357733 26495 sgd_solver.cpp:106] Iteration 655500, lr = 0.0025
I0526 00:24:09.416110 26495 solver.cpp:237] Iteration 657000, loss = 1.25526
I0526 00:24:09.416271 26495 solver.cpp:253]     Train net output #0: loss = 1.25525 (* 1 = 1.25525 loss)
I0526 00:24:09.416285 26495 sgd_solver.cpp:106] Iteration 657000, lr = 0.0025
I0526 00:24:26.475282 26495 solver.cpp:237] Iteration 658500, loss = 1.10009
I0526 00:24:26.475332 26495 solver.cpp:253]     Train net output #0: loss = 1.10008 (* 1 = 1.10008 loss)
I0526 00:24:26.475347 26495 sgd_solver.cpp:106] Iteration 658500, lr = 0.0025
I0526 00:24:43.523844 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_660000.caffemodel
I0526 00:24:43.571578 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_660000.solverstate
I0526 00:24:43.598089 26495 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 00:25:42.339766 26495 solver.cpp:409]     Test net output #0: accuracy = 0.898727
I0526 00:25:42.339943 26495 solver.cpp:409]     Test net output #1: loss = 0.329221 (* 1 = 0.329221 loss)
I0526 00:26:03.218153 26495 solver.cpp:237] Iteration 660000, loss = 0.863888
I0526 00:26:03.218209 26495 solver.cpp:253]     Train net output #0: loss = 0.863881 (* 1 = 0.863881 loss)
I0526 00:26:03.218225 26495 sgd_solver.cpp:106] Iteration 660000, lr = 0.0025
I0526 00:26:19.990178 26495 solver.cpp:237] Iteration 661500, loss = 1.26892
I0526 00:26:19.990350 26495 solver.cpp:253]     Train net output #0: loss = 1.26892 (* 1 = 1.26892 loss)
I0526 00:26:19.990365 26495 sgd_solver.cpp:106] Iteration 661500, lr = 0.0025
I0526 00:26:36.796049 26495 solver.cpp:237] Iteration 663000, loss = 1.36382
I0526 00:26:36.796097 26495 solver.cpp:253]     Train net output #0: loss = 1.36381 (* 1 = 1.36381 loss)
I0526 00:26:36.796109 26495 sgd_solver.cpp:106] Iteration 663000, lr = 0.0025
I0526 00:26:53.561350 26495 solver.cpp:237] Iteration 664500, loss = 1.34901
I0526 00:26:53.561496 26495 solver.cpp:253]     Train net output #0: loss = 1.349 (* 1 = 1.349 loss)
I0526 00:26:53.561509 26495 sgd_solver.cpp:106] Iteration 664500, lr = 0.0025
I0526 00:27:10.347618 26495 solver.cpp:237] Iteration 666000, loss = 0.811335
I0526 00:27:10.347654 26495 solver.cpp:253]     Train net output #0: loss = 0.811329 (* 1 = 0.811329 loss)
I0526 00:27:10.347668 26495 sgd_solver.cpp:106] Iteration 666000, lr = 0.0025
I0526 00:27:27.134660 26495 solver.cpp:237] Iteration 667500, loss = 1.25727
I0526 00:27:27.134834 26495 solver.cpp:253]     Train net output #0: loss = 1.25726 (* 1 = 1.25726 loss)
I0526 00:27:27.134847 26495 sgd_solver.cpp:106] Iteration 667500, lr = 0.0025
I0526 00:27:43.891600 26495 solver.cpp:237] Iteration 669000, loss = 1.02445
I0526 00:27:43.891645 26495 solver.cpp:253]     Train net output #0: loss = 1.02445 (* 1 = 1.02445 loss)
I0526 00:27:43.891659 26495 sgd_solver.cpp:106] Iteration 669000, lr = 0.0025
I0526 00:28:21.507017 26495 solver.cpp:237] Iteration 670500, loss = 2.09446
I0526 00:28:21.507191 26495 solver.cpp:253]     Train net output #0: loss = 2.09445 (* 1 = 2.09445 loss)
I0526 00:28:21.507207 26495 sgd_solver.cpp:106] Iteration 670500, lr = 0.0025
I0526 00:28:38.301856 26495 solver.cpp:237] Iteration 672000, loss = 0.834126
I0526 00:28:38.301897 26495 solver.cpp:253]     Train net output #0: loss = 0.834121 (* 1 = 0.834121 loss)
I0526 00:28:38.301914 26495 sgd_solver.cpp:106] Iteration 672000, lr = 0.0025
I0526 00:28:55.072474 26495 solver.cpp:237] Iteration 673500, loss = 0.872962
I0526 00:28:55.072634 26495 solver.cpp:253]     Train net output #0: loss = 0.872957 (* 1 = 0.872957 loss)
I0526 00:28:55.072649 26495 sgd_solver.cpp:106] Iteration 673500, lr = 0.0025
I0526 00:29:11.855806 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_675000.caffemodel
I0526 00:29:11.903578 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_675000.solverstate
I0526 00:29:11.934371 26495 solver.cpp:237] Iteration 675000, loss = 0.818944
I0526 00:29:11.934422 26495 solver.cpp:253]     Train net output #0: loss = 0.818938 (* 1 = 0.818938 loss)
I0526 00:29:11.934435 26495 sgd_solver.cpp:106] Iteration 675000, lr = 0.0025
I0526 00:29:28.713160 26495 solver.cpp:237] Iteration 676500, loss = 0.830265
I0526 00:29:28.713328 26495 solver.cpp:253]     Train net output #0: loss = 0.830259 (* 1 = 0.830259 loss)
I0526 00:29:28.713342 26495 sgd_solver.cpp:106] Iteration 676500, lr = 0.0025
I0526 00:29:45.496668 26495 solver.cpp:237] Iteration 678000, loss = 1.34356
I0526 00:29:45.496704 26495 solver.cpp:253]     Train net output #0: loss = 1.34356 (* 1 = 1.34356 loss)
I0526 00:29:45.496718 26495 sgd_solver.cpp:106] Iteration 678000, lr = 0.0025
I0526 00:30:02.273809 26495 solver.cpp:237] Iteration 679500, loss = 1.12059
I0526 00:30:02.273977 26495 solver.cpp:253]     Train net output #0: loss = 1.12059 (* 1 = 1.12059 loss)
I0526 00:30:02.273991 26495 sgd_solver.cpp:106] Iteration 679500, lr = 0.0025
I0526 00:30:39.954536 26495 solver.cpp:237] Iteration 681000, loss = 0.725359
I0526 00:30:39.954711 26495 solver.cpp:253]     Train net output #0: loss = 0.725352 (* 1 = 0.725352 loss)
I0526 00:30:39.954726 26495 sgd_solver.cpp:106] Iteration 681000, lr = 0.0025
I0526 00:30:56.743257 26495 solver.cpp:237] Iteration 682500, loss = 1.23521
I0526 00:30:56.743294 26495 solver.cpp:253]     Train net output #0: loss = 1.2352 (* 1 = 1.2352 loss)
I0526 00:30:56.743307 26495 sgd_solver.cpp:106] Iteration 682500, lr = 0.0025
I0526 00:31:13.505486 26495 solver.cpp:237] Iteration 684000, loss = 1.39184
I0526 00:31:13.505662 26495 solver.cpp:253]     Train net output #0: loss = 1.39183 (* 1 = 1.39183 loss)
I0526 00:31:13.505677 26495 sgd_solver.cpp:106] Iteration 684000, lr = 0.0025
I0526 00:31:30.295835 26495 solver.cpp:237] Iteration 685500, loss = 0.840167
I0526 00:31:30.295884 26495 solver.cpp:253]     Train net output #0: loss = 0.840161 (* 1 = 0.840161 loss)
I0526 00:31:30.295898 26495 sgd_solver.cpp:106] Iteration 685500, lr = 0.0025
I0526 00:31:47.068192 26495 solver.cpp:237] Iteration 687000, loss = 1.04921
I0526 00:31:47.068344 26495 solver.cpp:253]     Train net output #0: loss = 1.04921 (* 1 = 1.04921 loss)
I0526 00:31:47.068358 26495 sgd_solver.cpp:106] Iteration 687000, lr = 0.0025
I0526 00:32:03.748572 26495 solver.cpp:237] Iteration 688500, loss = 0.693256
I0526 00:32:03.748620 26495 solver.cpp:253]     Train net output #0: loss = 0.69325 (* 1 = 0.69325 loss)
I0526 00:32:03.748633 26495 sgd_solver.cpp:106] Iteration 688500, lr = 0.0025
I0526 00:32:20.345805 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_690000.caffemodel
I0526 00:32:20.391392 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_690000.solverstate
I0526 00:32:20.416728 26495 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 00:33:40.878394 26495 solver.cpp:409]     Test net output #0: accuracy = 0.901278
I0526 00:33:40.878563 26495 solver.cpp:409]     Test net output #1: loss = 0.313579 (* 1 = 0.313579 loss)
I0526 00:34:01.764951 26495 solver.cpp:237] Iteration 690000, loss = 1.42747
I0526 00:34:01.765003 26495 solver.cpp:253]     Train net output #0: loss = 1.42747 (* 1 = 1.42747 loss)
I0526 00:34:01.765022 26495 sgd_solver.cpp:106] Iteration 690000, lr = 0.0025
I0526 00:34:18.843147 26495 solver.cpp:237] Iteration 691500, loss = 0.923039
I0526 00:34:18.843317 26495 solver.cpp:253]     Train net output #0: loss = 0.923034 (* 1 = 0.923034 loss)
I0526 00:34:18.843333 26495 sgd_solver.cpp:106] Iteration 691500, lr = 0.0025
I0526 00:34:35.922396 26495 solver.cpp:237] Iteration 693000, loss = 1.68079
I0526 00:34:35.922441 26495 solver.cpp:253]     Train net output #0: loss = 1.68078 (* 1 = 1.68078 loss)
I0526 00:34:35.922454 26495 sgd_solver.cpp:106] Iteration 693000, lr = 0.0025
I0526 00:34:52.975179 26495 solver.cpp:237] Iteration 694500, loss = 1.11544
I0526 00:34:52.975344 26495 solver.cpp:253]     Train net output #0: loss = 1.11544 (* 1 = 1.11544 loss)
I0526 00:34:52.975358 26495 sgd_solver.cpp:106] Iteration 694500, lr = 0.0025
I0526 00:35:10.056198 26495 solver.cpp:237] Iteration 696000, loss = 1.01983
I0526 00:35:10.056234 26495 solver.cpp:253]     Train net output #0: loss = 1.01982 (* 1 = 1.01982 loss)
I0526 00:35:10.056247 26495 sgd_solver.cpp:106] Iteration 696000, lr = 0.0025
I0526 00:35:26.773371 26495 solver.cpp:237] Iteration 697500, loss = 1.64691
I0526 00:35:26.773540 26495 solver.cpp:253]     Train net output #0: loss = 1.64691 (* 1 = 1.64691 loss)
I0526 00:35:26.773555 26495 sgd_solver.cpp:106] Iteration 697500, lr = 0.0025
I0526 00:35:43.420047 26495 solver.cpp:237] Iteration 699000, loss = 1.19562
I0526 00:35:43.420089 26495 solver.cpp:253]     Train net output #0: loss = 1.19562 (* 1 = 1.19562 loss)
I0526 00:35:43.420105 26495 sgd_solver.cpp:106] Iteration 699000, lr = 0.0025
I0526 00:36:20.917963 26495 solver.cpp:237] Iteration 700500, loss = 0.721436
I0526 00:36:20.918134 26495 solver.cpp:253]     Train net output #0: loss = 0.721429 (* 1 = 0.721429 loss)
I0526 00:36:20.918150 26495 sgd_solver.cpp:106] Iteration 700500, lr = 0.0025
I0526 00:36:37.565124 26495 solver.cpp:237] Iteration 702000, loss = 0.686468
I0526 00:36:37.565171 26495 solver.cpp:253]     Train net output #0: loss = 0.686462 (* 1 = 0.686462 loss)
I0526 00:36:37.565186 26495 sgd_solver.cpp:106] Iteration 702000, lr = 0.0025
I0526 00:36:54.202258 26495 solver.cpp:237] Iteration 703500, loss = 0.71215
I0526 00:36:54.202424 26495 solver.cpp:253]     Train net output #0: loss = 0.712144 (* 1 = 0.712144 loss)
I0526 00:36:54.202438 26495 sgd_solver.cpp:106] Iteration 703500, lr = 0.0025
I0526 00:37:10.835476 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_705000.caffemodel
I0526 00:37:10.881662 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_705000.solverstate
I0526 00:37:10.910722 26495 solver.cpp:237] Iteration 705000, loss = 1.21905
I0526 00:37:10.910766 26495 solver.cpp:253]     Train net output #0: loss = 1.21904 (* 1 = 1.21904 loss)
I0526 00:37:10.910780 26495 sgd_solver.cpp:106] Iteration 705000, lr = 0.0025
I0526 00:37:27.570947 26495 solver.cpp:237] Iteration 706500, loss = 0.723757
I0526 00:37:27.571118 26495 solver.cpp:253]     Train net output #0: loss = 0.723751 (* 1 = 0.723751 loss)
I0526 00:37:27.571135 26495 sgd_solver.cpp:106] Iteration 706500, lr = 0.0025
I0526 00:37:44.572034 26495 solver.cpp:237] Iteration 708000, loss = 1.36038
I0526 00:37:44.572073 26495 solver.cpp:253]     Train net output #0: loss = 1.36037 (* 1 = 1.36037 loss)
I0526 00:37:44.572091 26495 sgd_solver.cpp:106] Iteration 708000, lr = 0.0025
I0526 00:38:01.796600 26495 solver.cpp:237] Iteration 709500, loss = 1.18539
I0526 00:38:01.796751 26495 solver.cpp:253]     Train net output #0: loss = 1.18538 (* 1 = 1.18538 loss)
I0526 00:38:01.796766 26495 sgd_solver.cpp:106] Iteration 709500, lr = 0.0025
I0526 00:38:39.901401 26495 solver.cpp:237] Iteration 711000, loss = 2.02708
I0526 00:38:39.901571 26495 solver.cpp:253]     Train net output #0: loss = 2.02708 (* 1 = 2.02708 loss)
I0526 00:38:39.901584 26495 sgd_solver.cpp:106] Iteration 711000, lr = 0.0025
I0526 00:38:57.123445 26495 solver.cpp:237] Iteration 712500, loss = 2.46372
I0526 00:38:57.123481 26495 solver.cpp:253]     Train net output #0: loss = 2.46372 (* 1 = 2.46372 loss)
I0526 00:38:57.123497 26495 sgd_solver.cpp:106] Iteration 712500, lr = 0.0025
I0526 00:39:14.371520 26495 solver.cpp:237] Iteration 714000, loss = 1.38003
I0526 00:39:14.371685 26495 solver.cpp:253]     Train net output #0: loss = 1.38002 (* 1 = 1.38002 loss)
I0526 00:39:14.371698 26495 sgd_solver.cpp:106] Iteration 714000, lr = 0.0025
I0526 00:39:31.560338 26495 solver.cpp:237] Iteration 715500, loss = 0.77705
I0526 00:39:31.560387 26495 solver.cpp:253]     Train net output #0: loss = 0.777046 (* 1 = 0.777046 loss)
I0526 00:39:31.560402 26495 sgd_solver.cpp:106] Iteration 715500, lr = 0.0025
I0526 00:39:48.787899 26495 solver.cpp:237] Iteration 717000, loss = 1.2168
I0526 00:39:48.788054 26495 solver.cpp:253]     Train net output #0: loss = 1.21679 (* 1 = 1.21679 loss)
I0526 00:39:48.788067 26495 sgd_solver.cpp:106] Iteration 717000, lr = 0.0025
I0526 00:40:05.952365 26495 solver.cpp:237] Iteration 718500, loss = 1.1786
I0526 00:40:05.952401 26495 solver.cpp:253]     Train net output #0: loss = 1.1786 (* 1 = 1.1786 loss)
I0526 00:40:05.952415 26495 sgd_solver.cpp:106] Iteration 718500, lr = 0.0025
I0526 00:40:23.141482 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_720000.caffemodel
I0526 00:40:23.187392 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_720000.solverstate
I0526 00:40:23.212965 26495 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 00:41:22.602494 26495 solver.cpp:409]     Test net output #0: accuracy = 0.894158
I0526 00:41:22.602677 26495 solver.cpp:409]     Test net output #1: loss = 0.34008 (* 1 = 0.34008 loss)
I0526 00:41:43.484210 26495 solver.cpp:237] Iteration 720000, loss = 1.71853
I0526 00:41:43.484263 26495 solver.cpp:253]     Train net output #0: loss = 1.71852 (* 1 = 1.71852 loss)
I0526 00:41:43.484277 26495 sgd_solver.cpp:106] Iteration 720000, lr = 0.0025
I0526 00:42:00.125578 26495 solver.cpp:237] Iteration 721500, loss = 0.871459
I0526 00:42:00.125754 26495 solver.cpp:253]     Train net output #0: loss = 0.871455 (* 1 = 0.871455 loss)
I0526 00:42:00.125769 26495 sgd_solver.cpp:106] Iteration 721500, lr = 0.0025
I0526 00:42:16.749747 26495 solver.cpp:237] Iteration 723000, loss = 1.01275
I0526 00:42:16.749784 26495 solver.cpp:253]     Train net output #0: loss = 1.01275 (* 1 = 1.01275 loss)
I0526 00:42:16.749801 26495 sgd_solver.cpp:106] Iteration 723000, lr = 0.0025
I0526 00:42:33.381705 26495 solver.cpp:237] Iteration 724500, loss = 0.735629
I0526 00:42:33.381872 26495 solver.cpp:253]     Train net output #0: loss = 0.735626 (* 1 = 0.735626 loss)
I0526 00:42:33.381886 26495 sgd_solver.cpp:106] Iteration 724500, lr = 0.0025
I0526 00:42:50.024359 26495 solver.cpp:237] Iteration 726000, loss = 1.09252
I0526 00:42:50.024404 26495 solver.cpp:253]     Train net output #0: loss = 1.09252 (* 1 = 1.09252 loss)
I0526 00:42:50.024417 26495 sgd_solver.cpp:106] Iteration 726000, lr = 0.0025
I0526 00:43:06.639705 26495 solver.cpp:237] Iteration 727500, loss = 1.0918
I0526 00:43:06.639858 26495 solver.cpp:253]     Train net output #0: loss = 1.0918 (* 1 = 1.0918 loss)
I0526 00:43:06.639871 26495 sgd_solver.cpp:106] Iteration 727500, lr = 0.0025
I0526 00:43:23.277542 26495 solver.cpp:237] Iteration 729000, loss = 0.757949
I0526 00:43:23.277590 26495 solver.cpp:253]     Train net output #0: loss = 0.757946 (* 1 = 0.757946 loss)
I0526 00:43:23.277606 26495 sgd_solver.cpp:106] Iteration 729000, lr = 0.0025
I0526 00:44:00.745333 26495 solver.cpp:237] Iteration 730500, loss = 1.43538
I0526 00:44:00.745522 26495 solver.cpp:253]     Train net output #0: loss = 1.43538 (* 1 = 1.43538 loss)
I0526 00:44:00.745537 26495 sgd_solver.cpp:106] Iteration 730500, lr = 0.0025
I0526 00:44:17.369352 26495 solver.cpp:237] Iteration 732000, loss = 0.712496
I0526 00:44:17.369388 26495 solver.cpp:253]     Train net output #0: loss = 0.712493 (* 1 = 0.712493 loss)
I0526 00:44:17.369405 26495 sgd_solver.cpp:106] Iteration 732000, lr = 0.0025
I0526 00:44:33.994019 26495 solver.cpp:237] Iteration 733500, loss = 0.97002
I0526 00:44:33.994179 26495 solver.cpp:253]     Train net output #0: loss = 0.970016 (* 1 = 0.970016 loss)
I0526 00:44:33.994192 26495 sgd_solver.cpp:106] Iteration 733500, lr = 0.0025
I0526 00:44:50.634924 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_735000.caffemodel
I0526 00:44:50.683552 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_735000.solverstate
I0526 00:44:50.714000 26495 solver.cpp:237] Iteration 735000, loss = 1.74477
I0526 00:44:50.714051 26495 solver.cpp:253]     Train net output #0: loss = 1.74477 (* 1 = 1.74477 loss)
I0526 00:44:50.714066 26495 sgd_solver.cpp:106] Iteration 735000, lr = 0.0025
I0526 00:45:07.332412 26495 solver.cpp:237] Iteration 736500, loss = 0.974985
I0526 00:45:07.332586 26495 solver.cpp:253]     Train net output #0: loss = 0.97498 (* 1 = 0.97498 loss)
I0526 00:45:07.332599 26495 sgd_solver.cpp:106] Iteration 736500, lr = 0.0025
I0526 00:45:23.983846 26495 solver.cpp:237] Iteration 738000, loss = 2.18085
I0526 00:45:23.983891 26495 solver.cpp:253]     Train net output #0: loss = 2.18085 (* 1 = 2.18085 loss)
I0526 00:45:23.983906 26495 sgd_solver.cpp:106] Iteration 738000, lr = 0.0025
I0526 00:45:40.630801 26495 solver.cpp:237] Iteration 739500, loss = 1.76836
I0526 00:45:40.630986 26495 solver.cpp:253]     Train net output #0: loss = 1.76836 (* 1 = 1.76836 loss)
I0526 00:45:40.631000 26495 sgd_solver.cpp:106] Iteration 739500, lr = 0.0025
I0526 00:46:18.137032 26495 solver.cpp:237] Iteration 741000, loss = 0.972606
I0526 00:46:18.137218 26495 solver.cpp:253]     Train net output #0: loss = 0.9726 (* 1 = 0.9726 loss)
I0526 00:46:18.137233 26495 sgd_solver.cpp:106] Iteration 741000, lr = 0.0025
I0526 00:46:34.771757 26495 solver.cpp:237] Iteration 742500, loss = 1.88231
I0526 00:46:34.771800 26495 solver.cpp:253]     Train net output #0: loss = 1.8823 (* 1 = 1.8823 loss)
I0526 00:46:34.771817 26495 sgd_solver.cpp:106] Iteration 742500, lr = 0.0025
I0526 00:46:51.421092 26495 solver.cpp:237] Iteration 744000, loss = 0.949681
I0526 00:46:51.421250 26495 solver.cpp:253]     Train net output #0: loss = 0.949675 (* 1 = 0.949675 loss)
I0526 00:46:51.421264 26495 sgd_solver.cpp:106] Iteration 744000, lr = 0.0025
I0526 00:47:08.046576 26495 solver.cpp:237] Iteration 745500, loss = 1.21172
I0526 00:47:08.046623 26495 solver.cpp:253]     Train net output #0: loss = 1.21171 (* 1 = 1.21171 loss)
I0526 00:47:08.046638 26495 sgd_solver.cpp:106] Iteration 745500, lr = 0.0025
I0526 00:47:24.660508 26495 solver.cpp:237] Iteration 747000, loss = 1.66357
I0526 00:47:24.660673 26495 solver.cpp:253]     Train net output #0: loss = 1.66357 (* 1 = 1.66357 loss)
I0526 00:47:24.660688 26495 sgd_solver.cpp:106] Iteration 747000, lr = 0.0025
I0526 00:47:41.273294 26495 solver.cpp:237] Iteration 748500, loss = 1.16766
I0526 00:47:41.273329 26495 solver.cpp:253]     Train net output #0: loss = 1.16765 (* 1 = 1.16765 loss)
I0526 00:47:41.273344 26495 sgd_solver.cpp:106] Iteration 748500, lr = 0.0025
I0526 00:47:57.883481 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_750000.caffemodel
I0526 00:47:57.932123 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_750000.solverstate
I0526 00:47:57.959688 26495 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 00:49:18.142019 26495 solver.cpp:409]     Test net output #0: accuracy = 0.899651
I0526 00:49:18.142204 26495 solver.cpp:409]     Test net output #1: loss = 0.322303 (* 1 = 0.322303 loss)
I0526 00:49:39.066154 26495 solver.cpp:237] Iteration 750000, loss = 0.882204
I0526 00:49:39.066207 26495 solver.cpp:253]     Train net output #0: loss = 0.882199 (* 1 = 0.882199 loss)
I0526 00:49:39.066222 26495 sgd_solver.cpp:106] Iteration 750000, lr = 0.0025
I0526 00:49:56.025902 26495 solver.cpp:237] Iteration 751500, loss = 0.855403
I0526 00:49:56.026079 26495 solver.cpp:253]     Train net output #0: loss = 0.855398 (* 1 = 0.855398 loss)
I0526 00:49:56.026095 26495 sgd_solver.cpp:106] Iteration 751500, lr = 0.0025
I0526 00:50:12.973567 26495 solver.cpp:237] Iteration 753000, loss = 1.22364
I0526 00:50:12.973603 26495 solver.cpp:253]     Train net output #0: loss = 1.22364 (* 1 = 1.22364 loss)
I0526 00:50:12.973616 26495 sgd_solver.cpp:106] Iteration 753000, lr = 0.0025
I0526 00:50:29.957893 26495 solver.cpp:237] Iteration 754500, loss = 0.557433
I0526 00:50:29.958066 26495 solver.cpp:253]     Train net output #0: loss = 0.557428 (* 1 = 0.557428 loss)
I0526 00:50:29.958081 26495 sgd_solver.cpp:106] Iteration 754500, lr = 0.0025
I0526 00:50:46.919643 26495 solver.cpp:237] Iteration 756000, loss = 1.05513
I0526 00:50:46.919690 26495 solver.cpp:253]     Train net output #0: loss = 1.05513 (* 1 = 1.05513 loss)
I0526 00:50:46.919705 26495 sgd_solver.cpp:106] Iteration 756000, lr = 0.0025
I0526 00:51:03.903699 26495 solver.cpp:237] Iteration 757500, loss = 0.924764
I0526 00:51:03.903868 26495 solver.cpp:253]     Train net output #0: loss = 0.924759 (* 1 = 0.924759 loss)
I0526 00:51:03.903882 26495 sgd_solver.cpp:106] Iteration 757500, lr = 0.0025
I0526 00:51:20.861068 26495 solver.cpp:237] Iteration 759000, loss = 1.60398
I0526 00:51:20.861104 26495 solver.cpp:253]     Train net output #0: loss = 1.60397 (* 1 = 1.60397 loss)
I0526 00:51:20.861119 26495 sgd_solver.cpp:106] Iteration 759000, lr = 0.0025
I0526 00:51:58.695677 26495 solver.cpp:237] Iteration 760500, loss = 0.677286
I0526 00:51:58.695861 26495 solver.cpp:253]     Train net output #0: loss = 0.677281 (* 1 = 0.677281 loss)
I0526 00:51:58.695876 26495 sgd_solver.cpp:106] Iteration 760500, lr = 0.0025
I0526 00:52:15.774143 26495 solver.cpp:237] Iteration 762000, loss = 0.97196
I0526 00:52:15.774180 26495 solver.cpp:253]     Train net output #0: loss = 0.971955 (* 1 = 0.971955 loss)
I0526 00:52:15.774194 26495 sgd_solver.cpp:106] Iteration 762000, lr = 0.0025
I0526 00:52:32.851917 26495 solver.cpp:237] Iteration 763500, loss = 0.966596
I0526 00:52:32.852087 26495 solver.cpp:253]     Train net output #0: loss = 0.966591 (* 1 = 0.966591 loss)
I0526 00:52:32.852100 26495 sgd_solver.cpp:106] Iteration 763500, lr = 0.0025
I0526 00:52:49.887820 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_765000.caffemodel
I0526 00:52:49.933691 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_765000.solverstate
I0526 00:52:49.962561 26495 solver.cpp:237] Iteration 765000, loss = 1.25006
I0526 00:52:49.962606 26495 solver.cpp:253]     Train net output #0: loss = 1.25006 (* 1 = 1.25006 loss)
I0526 00:52:49.962620 26495 sgd_solver.cpp:106] Iteration 765000, lr = 0.0025
I0526 00:53:07.042357 26495 solver.cpp:237] Iteration 766500, loss = 0.833123
I0526 00:53:07.042526 26495 solver.cpp:253]     Train net output #0: loss = 0.833117 (* 1 = 0.833117 loss)
I0526 00:53:07.042541 26495 sgd_solver.cpp:106] Iteration 766500, lr = 0.0025
I0526 00:53:24.124526 26495 solver.cpp:237] Iteration 768000, loss = 1.47759
I0526 00:53:24.124577 26495 solver.cpp:253]     Train net output #0: loss = 1.47759 (* 1 = 1.47759 loss)
I0526 00:53:24.124589 26495 sgd_solver.cpp:106] Iteration 768000, lr = 0.0025
I0526 00:53:41.177158 26495 solver.cpp:237] Iteration 769500, loss = 1.21346
I0526 00:53:41.177330 26495 solver.cpp:253]     Train net output #0: loss = 1.21345 (* 1 = 1.21345 loss)
I0526 00:53:41.177343 26495 sgd_solver.cpp:106] Iteration 769500, lr = 0.0025
I0526 00:54:19.118747 26495 solver.cpp:237] Iteration 771000, loss = 0.800322
I0526 00:54:19.118927 26495 solver.cpp:253]     Train net output #0: loss = 0.800316 (* 1 = 0.800316 loss)
I0526 00:54:19.118943 26495 sgd_solver.cpp:106] Iteration 771000, lr = 0.0025
I0526 00:54:36.151576 26495 solver.cpp:237] Iteration 772500, loss = 0.809278
I0526 00:54:36.151626 26495 solver.cpp:253]     Train net output #0: loss = 0.809272 (* 1 = 0.809272 loss)
I0526 00:54:36.151639 26495 sgd_solver.cpp:106] Iteration 772500, lr = 0.0025
I0526 00:54:53.221592 26495 solver.cpp:237] Iteration 774000, loss = 1.05622
I0526 00:54:53.221765 26495 solver.cpp:253]     Train net output #0: loss = 1.05622 (* 1 = 1.05622 loss)
I0526 00:54:53.221779 26495 sgd_solver.cpp:106] Iteration 774000, lr = 0.0025
I0526 00:55:10.283370 26495 solver.cpp:237] Iteration 775500, loss = 1.19087
I0526 00:55:10.283406 26495 solver.cpp:253]     Train net output #0: loss = 1.19087 (* 1 = 1.19087 loss)
I0526 00:55:10.283419 26495 sgd_solver.cpp:106] Iteration 775500, lr = 0.0025
I0526 00:55:27.353696 26495 solver.cpp:237] Iteration 777000, loss = 1.26243
I0526 00:55:27.353866 26495 solver.cpp:253]     Train net output #0: loss = 1.26242 (* 1 = 1.26242 loss)
I0526 00:55:27.353883 26495 sgd_solver.cpp:106] Iteration 777000, lr = 0.0025
I0526 00:55:44.413648 26495 solver.cpp:237] Iteration 778500, loss = 1.53625
I0526 00:55:44.413688 26495 solver.cpp:253]     Train net output #0: loss = 1.53625 (* 1 = 1.53625 loss)
I0526 00:55:44.413705 26495 sgd_solver.cpp:106] Iteration 778500, lr = 0.0025
I0526 00:56:01.449841 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_780000.caffemodel
I0526 00:56:01.506858 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_780000.solverstate
I0526 00:56:01.532270 26495 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 00:57:00.815502 26495 solver.cpp:409]     Test net output #0: accuracy = 0.90071
I0526 00:57:00.815678 26495 solver.cpp:409]     Test net output #1: loss = 0.313145 (* 1 = 0.313145 loss)
I0526 00:57:21.701408 26495 solver.cpp:237] Iteration 780000, loss = 1.33742
I0526 00:57:21.701462 26495 solver.cpp:253]     Train net output #0: loss = 1.33742 (* 1 = 1.33742 loss)
I0526 00:57:21.701477 26495 sgd_solver.cpp:106] Iteration 780000, lr = 0.0025
I0526 00:57:38.598353 26495 solver.cpp:237] Iteration 781500, loss = 0.737564
I0526 00:57:38.598531 26495 solver.cpp:253]     Train net output #0: loss = 0.737559 (* 1 = 0.737559 loss)
I0526 00:57:38.598544 26495 sgd_solver.cpp:106] Iteration 781500, lr = 0.0025
I0526 00:57:55.203795 26495 solver.cpp:237] Iteration 783000, loss = 0.428741
I0526 00:57:55.203843 26495 solver.cpp:253]     Train net output #0: loss = 0.428737 (* 1 = 0.428737 loss)
I0526 00:57:55.203858 26495 sgd_solver.cpp:106] Iteration 783000, lr = 0.0025
I0526 00:58:11.843080 26495 solver.cpp:237] Iteration 784500, loss = 1.58846
I0526 00:58:11.843251 26495 solver.cpp:253]     Train net output #0: loss = 1.58846 (* 1 = 1.58846 loss)
I0526 00:58:11.843266 26495 sgd_solver.cpp:106] Iteration 784500, lr = 0.0025
I0526 00:58:28.482833 26495 solver.cpp:237] Iteration 786000, loss = 0.971141
I0526 00:58:28.482869 26495 solver.cpp:253]     Train net output #0: loss = 0.971137 (* 1 = 0.971137 loss)
I0526 00:58:28.482883 26495 sgd_solver.cpp:106] Iteration 786000, lr = 0.0025
I0526 00:58:45.162482 26495 solver.cpp:237] Iteration 787500, loss = 1.01368
I0526 00:58:45.162652 26495 solver.cpp:253]     Train net output #0: loss = 1.01368 (* 1 = 1.01368 loss)
I0526 00:58:45.162667 26495 sgd_solver.cpp:106] Iteration 787500, lr = 0.0025
I0526 00:59:01.811250 26495 solver.cpp:237] Iteration 789000, loss = 1.45853
I0526 00:59:01.811293 26495 solver.cpp:253]     Train net output #0: loss = 1.45853 (* 1 = 1.45853 loss)
I0526 00:59:01.811311 26495 sgd_solver.cpp:106] Iteration 789000, lr = 0.0025
I0526 00:59:39.312700 26495 solver.cpp:237] Iteration 790500, loss = 1.61961
I0526 00:59:39.312876 26495 solver.cpp:253]     Train net output #0: loss = 1.6196 (* 1 = 1.6196 loss)
I0526 00:59:39.312891 26495 sgd_solver.cpp:106] Iteration 790500, lr = 0.0025
I0526 00:59:55.938339 26495 solver.cpp:237] Iteration 792000, loss = 1.20172
I0526 00:59:55.938385 26495 solver.cpp:253]     Train net output #0: loss = 1.20171 (* 1 = 1.20171 loss)
I0526 00:59:55.938402 26495 sgd_solver.cpp:106] Iteration 792000, lr = 0.0025
I0526 01:00:12.548282 26495 solver.cpp:237] Iteration 793500, loss = 1.44809
I0526 01:00:12.548440 26495 solver.cpp:253]     Train net output #0: loss = 1.44809 (* 1 = 1.44809 loss)
I0526 01:00:12.548454 26495 sgd_solver.cpp:106] Iteration 793500, lr = 0.0025
I0526 01:00:29.560968 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_795000.caffemodel
I0526 01:00:29.607512 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_795000.solverstate
I0526 01:00:29.636871 26495 solver.cpp:237] Iteration 795000, loss = 1.03323
I0526 01:00:29.636916 26495 solver.cpp:253]     Train net output #0: loss = 1.03322 (* 1 = 1.03322 loss)
I0526 01:00:29.636931 26495 sgd_solver.cpp:106] Iteration 795000, lr = 0.0025
I0526 01:00:46.701371 26495 solver.cpp:237] Iteration 796500, loss = 0.931017
I0526 01:00:46.701557 26495 solver.cpp:253]     Train net output #0: loss = 0.931013 (* 1 = 0.931013 loss)
I0526 01:00:46.701573 26495 sgd_solver.cpp:106] Iteration 796500, lr = 0.0025
I0526 01:01:03.749651 26495 solver.cpp:237] Iteration 798000, loss = 0.494813
I0526 01:01:03.749696 26495 solver.cpp:253]     Train net output #0: loss = 0.494809 (* 1 = 0.494809 loss)
I0526 01:01:03.749709 26495 sgd_solver.cpp:106] Iteration 798000, lr = 0.0025
I0526 01:01:20.827047 26495 solver.cpp:237] Iteration 799500, loss = 0.92242
I0526 01:01:20.827216 26495 solver.cpp:253]     Train net output #0: loss = 0.922417 (* 1 = 0.922417 loss)
I0526 01:01:20.827231 26495 sgd_solver.cpp:106] Iteration 799500, lr = 0.0025
I0526 01:01:58.778375 26495 solver.cpp:237] Iteration 801000, loss = 0.825494
I0526 01:01:58.778556 26495 solver.cpp:253]     Train net output #0: loss = 0.82549 (* 1 = 0.82549 loss)
I0526 01:01:58.778571 26495 sgd_solver.cpp:106] Iteration 801000, lr = 0.0025
I0526 01:02:15.856767 26495 solver.cpp:237] Iteration 802500, loss = 0.46897
I0526 01:02:15.856804 26495 solver.cpp:253]     Train net output #0: loss = 0.468967 (* 1 = 0.468967 loss)
I0526 01:02:15.856820 26495 sgd_solver.cpp:106] Iteration 802500, lr = 0.0025
I0526 01:02:32.886950 26495 solver.cpp:237] Iteration 804000, loss = 1.32965
I0526 01:02:32.887121 26495 solver.cpp:253]     Train net output #0: loss = 1.32965 (* 1 = 1.32965 loss)
I0526 01:02:32.887135 26495 sgd_solver.cpp:106] Iteration 804000, lr = 0.0025
I0526 01:02:49.927836 26495 solver.cpp:237] Iteration 805500, loss = 1.38283
I0526 01:02:49.927883 26495 solver.cpp:253]     Train net output #0: loss = 1.38282 (* 1 = 1.38282 loss)
I0526 01:02:49.927897 26495 sgd_solver.cpp:106] Iteration 805500, lr = 0.0025
I0526 01:03:06.981833 26495 solver.cpp:237] Iteration 807000, loss = 1.05181
I0526 01:03:06.981993 26495 solver.cpp:253]     Train net output #0: loss = 1.05181 (* 1 = 1.05181 loss)
I0526 01:03:06.982007 26495 sgd_solver.cpp:106] Iteration 807000, lr = 0.0025
I0526 01:03:23.970218 26495 solver.cpp:237] Iteration 808500, loss = 0.777116
I0526 01:03:23.970268 26495 solver.cpp:253]     Train net output #0: loss = 0.777114 (* 1 = 0.777114 loss)
I0526 01:03:23.970283 26495 sgd_solver.cpp:106] Iteration 808500, lr = 0.0025
I0526 01:03:40.948709 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_810000.caffemodel
I0526 01:03:41.001590 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_810000.solverstate
I0526 01:03:41.028074 26495 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 01:05:01.299974 26495 solver.cpp:409]     Test net output #0: accuracy = 0.896972
I0526 01:05:01.300153 26495 solver.cpp:409]     Test net output #1: loss = 0.324028 (* 1 = 0.324028 loss)
I0526 01:05:22.159231 26495 solver.cpp:237] Iteration 810000, loss = 1.25669
I0526 01:05:22.159286 26495 solver.cpp:253]     Train net output #0: loss = 1.25669 (* 1 = 1.25669 loss)
I0526 01:05:22.159301 26495 sgd_solver.cpp:106] Iteration 810000, lr = 0.0025
I0526 01:05:38.802073 26495 solver.cpp:237] Iteration 811500, loss = 1.00887
I0526 01:05:38.802242 26495 solver.cpp:253]     Train net output #0: loss = 1.00887 (* 1 = 1.00887 loss)
I0526 01:05:38.802255 26495 sgd_solver.cpp:106] Iteration 811500, lr = 0.0025
I0526 01:05:55.451766 26495 solver.cpp:237] Iteration 813000, loss = 1.24433
I0526 01:05:55.451802 26495 solver.cpp:253]     Train net output #0: loss = 1.24433 (* 1 = 1.24433 loss)
I0526 01:05:55.451819 26495 sgd_solver.cpp:106] Iteration 813000, lr = 0.0025
I0526 01:06:12.095991 26495 solver.cpp:237] Iteration 814500, loss = 1.54652
I0526 01:06:12.096159 26495 solver.cpp:253]     Train net output #0: loss = 1.54651 (* 1 = 1.54651 loss)
I0526 01:06:12.096174 26495 sgd_solver.cpp:106] Iteration 814500, lr = 0.0025
I0526 01:06:28.713088 26495 solver.cpp:237] Iteration 816000, loss = 0.819302
I0526 01:06:28.713135 26495 solver.cpp:253]     Train net output #0: loss = 0.8193 (* 1 = 0.8193 loss)
I0526 01:06:28.713150 26495 sgd_solver.cpp:106] Iteration 816000, lr = 0.0025
I0526 01:06:45.377629 26495 solver.cpp:237] Iteration 817500, loss = 1.16377
I0526 01:06:45.377797 26495 solver.cpp:253]     Train net output #0: loss = 1.16377 (* 1 = 1.16377 loss)
I0526 01:06:45.377813 26495 sgd_solver.cpp:106] Iteration 817500, lr = 0.0025
I0526 01:07:02.033521 26495 solver.cpp:237] Iteration 819000, loss = 1.3473
I0526 01:07:02.033570 26495 solver.cpp:253]     Train net output #0: loss = 1.3473 (* 1 = 1.3473 loss)
I0526 01:07:02.033586 26495 sgd_solver.cpp:106] Iteration 819000, lr = 0.0025
I0526 01:07:39.567646 26495 solver.cpp:237] Iteration 820500, loss = 1.49403
I0526 01:07:39.567827 26495 solver.cpp:253]     Train net output #0: loss = 1.49403 (* 1 = 1.49403 loss)
I0526 01:07:39.567843 26495 sgd_solver.cpp:106] Iteration 820500, lr = 0.0025
I0526 01:07:56.225673 26495 solver.cpp:237] Iteration 822000, loss = 0.954538
I0526 01:07:56.225720 26495 solver.cpp:253]     Train net output #0: loss = 0.954537 (* 1 = 0.954537 loss)
I0526 01:07:56.225734 26495 sgd_solver.cpp:106] Iteration 822000, lr = 0.0025
I0526 01:08:12.861507 26495 solver.cpp:237] Iteration 823500, loss = 1.49276
I0526 01:08:12.861680 26495 solver.cpp:253]     Train net output #0: loss = 1.49276 (* 1 = 1.49276 loss)
I0526 01:08:12.861693 26495 sgd_solver.cpp:106] Iteration 823500, lr = 0.0025
I0526 01:08:29.502291 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_825000.caffemodel
I0526 01:08:29.550127 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_825000.solverstate
I0526 01:08:29.581086 26495 solver.cpp:237] Iteration 825000, loss = 1.36518
I0526 01:08:29.581135 26495 solver.cpp:253]     Train net output #0: loss = 1.36518 (* 1 = 1.36518 loss)
I0526 01:08:29.581151 26495 sgd_solver.cpp:106] Iteration 825000, lr = 0.0025
I0526 01:08:46.211683 26495 solver.cpp:237] Iteration 826500, loss = 1.65412
I0526 01:08:46.211858 26495 solver.cpp:253]     Train net output #0: loss = 1.65412 (* 1 = 1.65412 loss)
I0526 01:08:46.211874 26495 sgd_solver.cpp:106] Iteration 826500, lr = 0.0025
I0526 01:09:02.877185 26495 solver.cpp:237] Iteration 828000, loss = 0.936545
I0526 01:09:02.877233 26495 solver.cpp:253]     Train net output #0: loss = 0.936543 (* 1 = 0.936543 loss)
I0526 01:09:02.877249 26495 sgd_solver.cpp:106] Iteration 828000, lr = 0.0025
I0526 01:09:19.534350 26495 solver.cpp:237] Iteration 829500, loss = 0.968791
I0526 01:09:19.534512 26495 solver.cpp:253]     Train net output #0: loss = 0.96879 (* 1 = 0.96879 loss)
I0526 01:09:19.534528 26495 sgd_solver.cpp:106] Iteration 829500, lr = 0.0025
I0526 01:09:57.088469 26495 solver.cpp:237] Iteration 831000, loss = 0.610373
I0526 01:09:57.088650 26495 solver.cpp:253]     Train net output #0: loss = 0.610372 (* 1 = 0.610372 loss)
I0526 01:09:57.088666 26495 sgd_solver.cpp:106] Iteration 831000, lr = 0.0025
I0526 01:10:13.728519 26495 solver.cpp:237] Iteration 832500, loss = 1.08059
I0526 01:10:13.728565 26495 solver.cpp:253]     Train net output #0: loss = 1.08059 (* 1 = 1.08059 loss)
I0526 01:10:13.728579 26495 sgd_solver.cpp:106] Iteration 832500, lr = 0.0025
I0526 01:10:30.359001 26495 solver.cpp:237] Iteration 834000, loss = 1.16692
I0526 01:10:30.359163 26495 solver.cpp:253]     Train net output #0: loss = 1.16692 (* 1 = 1.16692 loss)
I0526 01:10:30.359177 26495 sgd_solver.cpp:106] Iteration 834000, lr = 0.0025
I0526 01:10:46.989301 26495 solver.cpp:237] Iteration 835500, loss = 0.982783
I0526 01:10:46.989351 26495 solver.cpp:253]     Train net output #0: loss = 0.982781 (* 1 = 0.982781 loss)
I0526 01:10:46.989365 26495 sgd_solver.cpp:106] Iteration 835500, lr = 0.0025
I0526 01:11:03.628656 26495 solver.cpp:237] Iteration 837000, loss = 1.72124
I0526 01:11:03.628837 26495 solver.cpp:253]     Train net output #0: loss = 1.72123 (* 1 = 1.72123 loss)
I0526 01:11:03.628852 26495 sgd_solver.cpp:106] Iteration 837000, lr = 0.0025
I0526 01:11:20.262219 26495 solver.cpp:237] Iteration 838500, loss = 1.53935
I0526 01:11:20.262255 26495 solver.cpp:253]     Train net output #0: loss = 1.53935 (* 1 = 1.53935 loss)
I0526 01:11:20.262269 26495 sgd_solver.cpp:106] Iteration 838500, lr = 0.0025
I0526 01:11:36.879871 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_840000.caffemodel
I0526 01:11:36.925917 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_840000.solverstate
I0526 01:11:36.951642 26495 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 01:12:36.396869 26495 solver.cpp:409]     Test net output #0: accuracy = 0.896784
I0526 01:12:36.397064 26495 solver.cpp:409]     Test net output #1: loss = 0.330004 (* 1 = 0.330004 loss)
I0526 01:12:57.286888 26495 solver.cpp:237] Iteration 840000, loss = 1.0804
I0526 01:12:57.286942 26495 solver.cpp:253]     Train net output #0: loss = 1.0804 (* 1 = 1.0804 loss)
I0526 01:12:57.286955 26495 sgd_solver.cpp:106] Iteration 840000, lr = 0.0025
I0526 01:13:14.072435 26495 solver.cpp:237] Iteration 841500, loss = 0.770065
I0526 01:13:14.072613 26495 solver.cpp:253]     Train net output #0: loss = 0.770064 (* 1 = 0.770064 loss)
I0526 01:13:14.072628 26495 sgd_solver.cpp:106] Iteration 841500, lr = 0.0025
I0526 01:13:30.860965 26495 solver.cpp:237] Iteration 843000, loss = 1.16104
I0526 01:13:30.861001 26495 solver.cpp:253]     Train net output #0: loss = 1.16104 (* 1 = 1.16104 loss)
I0526 01:13:30.861014 26495 sgd_solver.cpp:106] Iteration 843000, lr = 0.0025
I0526 01:13:47.609684 26495 solver.cpp:237] Iteration 844500, loss = 0.932845
I0526 01:13:47.609858 26495 solver.cpp:253]     Train net output #0: loss = 0.932844 (* 1 = 0.932844 loss)
I0526 01:13:47.609874 26495 sgd_solver.cpp:106] Iteration 844500, lr = 0.0025
I0526 01:14:04.378638 26495 solver.cpp:237] Iteration 846000, loss = 0.611429
I0526 01:14:04.378684 26495 solver.cpp:253]     Train net output #0: loss = 0.611427 (* 1 = 0.611427 loss)
I0526 01:14:04.378697 26495 sgd_solver.cpp:106] Iteration 846000, lr = 0.0025
I0526 01:14:21.138341 26495 solver.cpp:237] Iteration 847500, loss = 1.19287
I0526 01:14:21.138502 26495 solver.cpp:253]     Train net output #0: loss = 1.19287 (* 1 = 1.19287 loss)
I0526 01:14:21.138516 26495 sgd_solver.cpp:106] Iteration 847500, lr = 0.0025
I0526 01:14:37.917695 26495 solver.cpp:237] Iteration 849000, loss = 1.05505
I0526 01:14:37.917743 26495 solver.cpp:253]     Train net output #0: loss = 1.05505 (* 1 = 1.05505 loss)
I0526 01:14:37.917757 26495 sgd_solver.cpp:106] Iteration 849000, lr = 0.0025
I0526 01:15:15.591651 26495 solver.cpp:237] Iteration 850500, loss = 1.30655
I0526 01:15:15.591832 26495 solver.cpp:253]     Train net output #0: loss = 1.30655 (* 1 = 1.30655 loss)
I0526 01:15:15.591847 26495 sgd_solver.cpp:106] Iteration 850500, lr = 0.0025
I0526 01:15:32.362637 26495 solver.cpp:237] Iteration 852000, loss = 0.40743
I0526 01:15:32.362674 26495 solver.cpp:253]     Train net output #0: loss = 0.407429 (* 1 = 0.407429 loss)
I0526 01:15:32.362689 26495 sgd_solver.cpp:106] Iteration 852000, lr = 0.0025
I0526 01:15:49.184411 26495 solver.cpp:237] Iteration 853500, loss = 0.692283
I0526 01:15:49.184582 26495 solver.cpp:253]     Train net output #0: loss = 0.692281 (* 1 = 0.692281 loss)
I0526 01:15:49.184597 26495 sgd_solver.cpp:106] Iteration 853500, lr = 0.0025
I0526 01:16:05.943033 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_855000.caffemodel
I0526 01:16:05.996954 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_855000.solverstate
I0526 01:16:06.026065 26495 solver.cpp:237] Iteration 855000, loss = 1.63624
I0526 01:16:06.026105 26495 solver.cpp:253]     Train net output #0: loss = 1.63624 (* 1 = 1.63624 loss)
I0526 01:16:06.026129 26495 sgd_solver.cpp:106] Iteration 855000, lr = 0.0025
I0526 01:16:22.660373 26495 solver.cpp:237] Iteration 856500, loss = 0.886979
I0526 01:16:22.660550 26495 solver.cpp:253]     Train net output #0: loss = 0.886977 (* 1 = 0.886977 loss)
I0526 01:16:22.660567 26495 sgd_solver.cpp:106] Iteration 856500, lr = 0.0025
I0526 01:16:39.291342 26495 solver.cpp:237] Iteration 858000, loss = 0.854981
I0526 01:16:39.291391 26495 solver.cpp:253]     Train net output #0: loss = 0.85498 (* 1 = 0.85498 loss)
I0526 01:16:39.291405 26495 sgd_solver.cpp:106] Iteration 858000, lr = 0.0025
I0526 01:16:55.950585 26495 solver.cpp:237] Iteration 859500, loss = 1.22813
I0526 01:16:55.950763 26495 solver.cpp:253]     Train net output #0: loss = 1.22813 (* 1 = 1.22813 loss)
I0526 01:16:55.950778 26495 sgd_solver.cpp:106] Iteration 859500, lr = 0.0025
I0526 01:17:33.648564 26495 solver.cpp:237] Iteration 861000, loss = 0.957977
I0526 01:17:33.648749 26495 solver.cpp:253]     Train net output #0: loss = 0.957974 (* 1 = 0.957974 loss)
I0526 01:17:33.648766 26495 sgd_solver.cpp:106] Iteration 861000, lr = 0.0025
I0526 01:17:50.514443 26495 solver.cpp:237] Iteration 862500, loss = 3.12252
I0526 01:17:50.514492 26495 solver.cpp:253]     Train net output #0: loss = 3.12251 (* 1 = 3.12251 loss)
I0526 01:17:50.514505 26495 sgd_solver.cpp:106] Iteration 862500, lr = 0.0025
I0526 01:18:07.376302 26495 solver.cpp:237] Iteration 864000, loss = 1.51258
I0526 01:18:07.376477 26495 solver.cpp:253]     Train net output #0: loss = 1.51257 (* 1 = 1.51257 loss)
I0526 01:18:07.376490 26495 sgd_solver.cpp:106] Iteration 864000, lr = 0.0025
I0526 01:18:24.267833 26495 solver.cpp:237] Iteration 865500, loss = 1.07028
I0526 01:18:24.267881 26495 solver.cpp:253]     Train net output #0: loss = 1.07028 (* 1 = 1.07028 loss)
I0526 01:18:24.267895 26495 sgd_solver.cpp:106] Iteration 865500, lr = 0.0025
I0526 01:18:41.149169 26495 solver.cpp:237] Iteration 867000, loss = 0.980893
I0526 01:18:41.149355 26495 solver.cpp:253]     Train net output #0: loss = 0.980889 (* 1 = 0.980889 loss)
I0526 01:18:41.149371 26495 sgd_solver.cpp:106] Iteration 867000, lr = 0.0025
I0526 01:18:58.048600 26495 solver.cpp:237] Iteration 868500, loss = 1.03402
I0526 01:18:58.048637 26495 solver.cpp:253]     Train net output #0: loss = 1.03401 (* 1 = 1.03401 loss)
I0526 01:18:58.048650 26495 sgd_solver.cpp:106] Iteration 868500, lr = 0.0025
I0526 01:19:14.905844 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_870000.caffemodel
I0526 01:19:14.952476 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_870000.solverstate
I0526 01:19:14.977955 26495 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 01:20:35.222774 26495 solver.cpp:409]     Test net output #0: accuracy = 0.898536
I0526 01:20:35.222957 26495 solver.cpp:409]     Test net output #1: loss = 0.31504 (* 1 = 0.31504 loss)
I0526 01:20:56.099030 26495 solver.cpp:237] Iteration 870000, loss = 1.76678
I0526 01:20:56.099084 26495 solver.cpp:253]     Train net output #0: loss = 1.76678 (* 1 = 1.76678 loss)
I0526 01:20:56.099098 26495 sgd_solver.cpp:106] Iteration 870000, lr = 0.0025
I0526 01:21:13.081936 26495 solver.cpp:237] Iteration 871500, loss = 1.05197
I0526 01:21:13.082118 26495 solver.cpp:253]     Train net output #0: loss = 1.05196 (* 1 = 1.05196 loss)
I0526 01:21:13.082132 26495 sgd_solver.cpp:106] Iteration 871500, lr = 0.0025
I0526 01:21:30.039590 26495 solver.cpp:237] Iteration 873000, loss = 0.944827
I0526 01:21:30.039633 26495 solver.cpp:253]     Train net output #0: loss = 0.944824 (* 1 = 0.944824 loss)
I0526 01:21:30.039649 26495 sgd_solver.cpp:106] Iteration 873000, lr = 0.0025
I0526 01:21:46.987910 26495 solver.cpp:237] Iteration 874500, loss = 0.972411
I0526 01:21:46.988095 26495 solver.cpp:253]     Train net output #0: loss = 0.972408 (* 1 = 0.972408 loss)
I0526 01:21:46.988111 26495 sgd_solver.cpp:106] Iteration 874500, lr = 0.0025
I0526 01:22:03.939785 26495 solver.cpp:237] Iteration 876000, loss = 1.06144
I0526 01:22:03.939834 26495 solver.cpp:253]     Train net output #0: loss = 1.06143 (* 1 = 1.06143 loss)
I0526 01:22:03.939848 26495 sgd_solver.cpp:106] Iteration 876000, lr = 0.0025
I0526 01:22:20.901058 26495 solver.cpp:237] Iteration 877500, loss = 1.04178
I0526 01:22:20.901240 26495 solver.cpp:253]     Train net output #0: loss = 1.04177 (* 1 = 1.04177 loss)
I0526 01:22:20.901254 26495 sgd_solver.cpp:106] Iteration 877500, lr = 0.0025
I0526 01:22:37.870797 26495 solver.cpp:237] Iteration 879000, loss = 0.70727
I0526 01:22:37.870834 26495 solver.cpp:253]     Train net output #0: loss = 0.707265 (* 1 = 0.707265 loss)
I0526 01:22:37.870848 26495 sgd_solver.cpp:106] Iteration 879000, lr = 0.0025
I0526 01:23:15.696871 26495 solver.cpp:237] Iteration 880500, loss = 0.939054
I0526 01:23:15.697064 26495 solver.cpp:253]     Train net output #0: loss = 0.93905 (* 1 = 0.93905 loss)
I0526 01:23:15.697079 26495 sgd_solver.cpp:106] Iteration 880500, lr = 0.0025
I0526 01:23:32.669041 26495 solver.cpp:237] Iteration 882000, loss = 0.422285
I0526 01:23:32.669077 26495 solver.cpp:253]     Train net output #0: loss = 0.422282 (* 1 = 0.422282 loss)
I0526 01:23:32.669091 26495 sgd_solver.cpp:106] Iteration 882000, lr = 0.0025
I0526 01:23:49.659134 26495 solver.cpp:237] Iteration 883500, loss = 1.18375
I0526 01:23:49.659307 26495 solver.cpp:253]     Train net output #0: loss = 1.18374 (* 1 = 1.18374 loss)
I0526 01:23:49.659320 26495 sgd_solver.cpp:106] Iteration 883500, lr = 0.0025
I0526 01:24:06.615279 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_885000.caffemodel
I0526 01:24:06.663549 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_885000.solverstate
I0526 01:24:06.694442 26495 solver.cpp:237] Iteration 885000, loss = 2.06184
I0526 01:24:06.694489 26495 solver.cpp:253]     Train net output #0: loss = 2.06183 (* 1 = 2.06183 loss)
I0526 01:24:06.694506 26495 sgd_solver.cpp:106] Iteration 885000, lr = 0.0025
I0526 01:24:23.670370 26495 solver.cpp:237] Iteration 886500, loss = 0.842843
I0526 01:24:23.670562 26495 solver.cpp:253]     Train net output #0: loss = 0.842839 (* 1 = 0.842839 loss)
I0526 01:24:23.670578 26495 sgd_solver.cpp:106] Iteration 886500, lr = 0.0025
I0526 01:24:40.617655 26495 solver.cpp:237] Iteration 888000, loss = 2.01736
I0526 01:24:40.617691 26495 solver.cpp:253]     Train net output #0: loss = 2.01735 (* 1 = 2.01735 loss)
I0526 01:24:40.617705 26495 sgd_solver.cpp:106] Iteration 888000, lr = 0.0025
I0526 01:24:57.556534 26495 solver.cpp:237] Iteration 889500, loss = 1.3048
I0526 01:24:57.556711 26495 solver.cpp:253]     Train net output #0: loss = 1.3048 (* 1 = 1.3048 loss)
I0526 01:24:57.556725 26495 sgd_solver.cpp:106] Iteration 889500, lr = 0.0025
I0526 01:25:35.398722 26495 solver.cpp:237] Iteration 891000, loss = 1.18073
I0526 01:25:35.398907 26495 solver.cpp:253]     Train net output #0: loss = 1.18073 (* 1 = 1.18073 loss)
I0526 01:25:35.398922 26495 sgd_solver.cpp:106] Iteration 891000, lr = 0.0025
I0526 01:25:52.367991 26495 solver.cpp:237] Iteration 892500, loss = 1.57553
I0526 01:25:52.368038 26495 solver.cpp:253]     Train net output #0: loss = 1.57553 (* 1 = 1.57553 loss)
I0526 01:25:52.368052 26495 sgd_solver.cpp:106] Iteration 892500, lr = 0.0025
I0526 01:26:09.329336 26495 solver.cpp:237] Iteration 894000, loss = 1.1723
I0526 01:26:09.329524 26495 solver.cpp:253]     Train net output #0: loss = 1.1723 (* 1 = 1.1723 loss)
I0526 01:26:09.329538 26495 sgd_solver.cpp:106] Iteration 894000, lr = 0.0025
I0526 01:26:26.293772 26495 solver.cpp:237] Iteration 895500, loss = 1.49762
I0526 01:26:26.293808 26495 solver.cpp:253]     Train net output #0: loss = 1.49762 (* 1 = 1.49762 loss)
I0526 01:26:26.293822 26495 sgd_solver.cpp:106] Iteration 895500, lr = 0.0025
I0526 01:26:43.257686 26495 solver.cpp:237] Iteration 897000, loss = 1.44165
I0526 01:26:43.257863 26495 solver.cpp:253]     Train net output #0: loss = 1.44165 (* 1 = 1.44165 loss)
I0526 01:26:43.257876 26495 sgd_solver.cpp:106] Iteration 897000, lr = 0.0025
I0526 01:27:00.206362 26495 solver.cpp:237] Iteration 898500, loss = 1.41338
I0526 01:27:00.206403 26495 solver.cpp:253]     Train net output #0: loss = 1.41338 (* 1 = 1.41338 loss)
I0526 01:27:00.206424 26495 sgd_solver.cpp:106] Iteration 898500, lr = 0.0025
I0526 01:27:17.171861 26495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_900000.caffemodel
I0526 01:27:17.220037 26495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_900000.solverstate
I0526 01:27:17.247757 26495 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 01:28:16.393697 26495 solver.cpp:409]     Test net output #0: accuracy = 0.898451
I0526 01:28:16.393879 26495 solver.cpp:409]     Test net output #1: loss = 0.333129 (* 1 = 0.333129 loss)
I0526 01:28:37.269337 26495 solver.cpp:237] Iteration 900000, loss = 0.425574
I0526 01:28:37.269390 26495 solver.cpp:253]     Train net output #0: loss = 0.425571 (* 1 = 0.425571 loss)
I0526 01:28:37.269405 26495 sgd_solver.cpp:106] Iteration 900000, lr = 0.0025
I0526 01:28:53.921707 26495 solver.cpp:237] Iteration 901500, loss = 0.88387
I0526 01:28:53.921878 26495 solver.cpp:253]     Train net output #0: loss = 0.883868 (* 1 = 0.883868 loss)
I0526 01:28:53.921893 26495 sgd_solver.cpp:106] Iteration 901500, lr = 0.0025
aprun: Apid 11266253: Caught signal Terminated, sending to application
*** Aborted at 1464240550 (unix time) try "date -d @1464240550" if you are using GNU date ***
aprun: Apid 11266253: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11266253: Caught signal Terminated, sending to application
*** SIGTERM (@0x677c) received by PID 26495 (TID 0x2aaac746f900) from PID 26492; stack trace: ***
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
=>> PBS: job killed: walltime 7201 exceeded limit 7200
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11266253: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11266253: Caught signal Terminated, sending to application
aprun: Apid 11266253: Caught signal Terminated, sending to application
aprun: Apid 11266253: Caught signal Terminated, sending to application
aprun: Apid 11266253: Caught signal Terminated, sending to application
aprun: Apid 11266253: Caught signal Terminated, sending to application
aprun: Apid 11266253: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03789] [c8-1c0s6n1] [Thu May 26 01:29:12 2016] PE RANK 0 exit signal Terminated
Application 11266253 exit codes: 143
Application 11266253 resources: utime ~6301s, stime ~892s, Rss ~5329884, inblocks ~10491400, outblocks ~474919
