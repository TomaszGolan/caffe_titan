2808933
I0523 18:01:12.367835 15542 caffe.cpp:184] Using GPUs 0
I0523 18:01:12.794040 15542 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.0035
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507.prototxt"
I0523 18:01:12.795891 15542 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507.prototxt
I0523 18:01:12.813349 15542 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 18:01:12.813408 15542 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 18:01:12.813755 15542 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 18:01:12.813936 15542 layer_factory.hpp:77] Creating layer data_hdf5
I0523 18:01:12.813959 15542 net.cpp:106] Creating Layer data_hdf5
I0523 18:01:12.813974 15542 net.cpp:411] data_hdf5 -> data
I0523 18:01:12.814007 15542 net.cpp:411] data_hdf5 -> label
I0523 18:01:12.814039 15542 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 18:01:12.825806 15542 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 18:01:12.850054 15542 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 18:01:34.394004 15542 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 18:01:34.399235 15542 net.cpp:150] Setting up data_hdf5
I0523 18:01:34.399278 15542 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 18:01:34.399293 15542 net.cpp:157] Top shape: 60 (60)
I0523 18:01:34.399303 15542 net.cpp:165] Memory required for data: 1524240
I0523 18:01:34.399317 15542 layer_factory.hpp:77] Creating layer conv1
I0523 18:01:34.399351 15542 net.cpp:106] Creating Layer conv1
I0523 18:01:34.399363 15542 net.cpp:454] conv1 <- data
I0523 18:01:34.399385 15542 net.cpp:411] conv1 -> conv1
I0523 18:01:37.841770 15542 net.cpp:150] Setting up conv1
I0523 18:01:37.841814 15542 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 18:01:37.841827 15542 net.cpp:165] Memory required for data: 18113040
I0523 18:01:37.841858 15542 layer_factory.hpp:77] Creating layer relu1
I0523 18:01:37.841879 15542 net.cpp:106] Creating Layer relu1
I0523 18:01:37.841889 15542 net.cpp:454] relu1 <- conv1
I0523 18:01:37.841903 15542 net.cpp:397] relu1 -> conv1 (in-place)
I0523 18:01:37.842418 15542 net.cpp:150] Setting up relu1
I0523 18:01:37.842434 15542 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 18:01:37.842444 15542 net.cpp:165] Memory required for data: 34701840
I0523 18:01:37.842454 15542 layer_factory.hpp:77] Creating layer pool1
I0523 18:01:37.842473 15542 net.cpp:106] Creating Layer pool1
I0523 18:01:37.842481 15542 net.cpp:454] pool1 <- conv1
I0523 18:01:37.842494 15542 net.cpp:411] pool1 -> pool1
I0523 18:01:37.842574 15542 net.cpp:150] Setting up pool1
I0523 18:01:37.842589 15542 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 18:01:37.842598 15542 net.cpp:165] Memory required for data: 42996240
I0523 18:01:37.842609 15542 layer_factory.hpp:77] Creating layer conv2
I0523 18:01:37.842633 15542 net.cpp:106] Creating Layer conv2
I0523 18:01:37.842643 15542 net.cpp:454] conv2 <- pool1
I0523 18:01:37.842656 15542 net.cpp:411] conv2 -> conv2
I0523 18:01:37.845407 15542 net.cpp:150] Setting up conv2
I0523 18:01:37.845434 15542 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 18:01:37.845445 15542 net.cpp:165] Memory required for data: 54919440
I0523 18:01:37.845464 15542 layer_factory.hpp:77] Creating layer relu2
I0523 18:01:37.845479 15542 net.cpp:106] Creating Layer relu2
I0523 18:01:37.845489 15542 net.cpp:454] relu2 <- conv2
I0523 18:01:37.845501 15542 net.cpp:397] relu2 -> conv2 (in-place)
I0523 18:01:37.845834 15542 net.cpp:150] Setting up relu2
I0523 18:01:37.845849 15542 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 18:01:37.845859 15542 net.cpp:165] Memory required for data: 66842640
I0523 18:01:37.845868 15542 layer_factory.hpp:77] Creating layer pool2
I0523 18:01:37.845881 15542 net.cpp:106] Creating Layer pool2
I0523 18:01:37.845891 15542 net.cpp:454] pool2 <- conv2
I0523 18:01:37.845903 15542 net.cpp:411] pool2 -> pool2
I0523 18:01:37.845983 15542 net.cpp:150] Setting up pool2
I0523 18:01:37.845996 15542 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 18:01:37.846006 15542 net.cpp:165] Memory required for data: 72804240
I0523 18:01:37.846016 15542 layer_factory.hpp:77] Creating layer conv3
I0523 18:01:37.846036 15542 net.cpp:106] Creating Layer conv3
I0523 18:01:37.846047 15542 net.cpp:454] conv3 <- pool2
I0523 18:01:37.846061 15542 net.cpp:411] conv3 -> conv3
I0523 18:01:37.848001 15542 net.cpp:150] Setting up conv3
I0523 18:01:37.848023 15542 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 18:01:37.848036 15542 net.cpp:165] Memory required for data: 79309200
I0523 18:01:37.848053 15542 layer_factory.hpp:77] Creating layer relu3
I0523 18:01:37.848069 15542 net.cpp:106] Creating Layer relu3
I0523 18:01:37.848079 15542 net.cpp:454] relu3 <- conv3
I0523 18:01:37.848091 15542 net.cpp:397] relu3 -> conv3 (in-place)
I0523 18:01:37.848562 15542 net.cpp:150] Setting up relu3
I0523 18:01:37.848578 15542 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 18:01:37.848589 15542 net.cpp:165] Memory required for data: 85814160
I0523 18:01:37.848599 15542 layer_factory.hpp:77] Creating layer pool3
I0523 18:01:37.848613 15542 net.cpp:106] Creating Layer pool3
I0523 18:01:37.848623 15542 net.cpp:454] pool3 <- conv3
I0523 18:01:37.848634 15542 net.cpp:411] pool3 -> pool3
I0523 18:01:37.848701 15542 net.cpp:150] Setting up pool3
I0523 18:01:37.848714 15542 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 18:01:37.848724 15542 net.cpp:165] Memory required for data: 89066640
I0523 18:01:37.848734 15542 layer_factory.hpp:77] Creating layer conv4
I0523 18:01:37.848752 15542 net.cpp:106] Creating Layer conv4
I0523 18:01:37.848763 15542 net.cpp:454] conv4 <- pool3
I0523 18:01:37.848776 15542 net.cpp:411] conv4 -> conv4
I0523 18:01:37.851569 15542 net.cpp:150] Setting up conv4
I0523 18:01:37.851598 15542 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 18:01:37.851608 15542 net.cpp:165] Memory required for data: 91243920
I0523 18:01:37.851624 15542 layer_factory.hpp:77] Creating layer relu4
I0523 18:01:37.851639 15542 net.cpp:106] Creating Layer relu4
I0523 18:01:37.851649 15542 net.cpp:454] relu4 <- conv4
I0523 18:01:37.851661 15542 net.cpp:397] relu4 -> conv4 (in-place)
I0523 18:01:37.852134 15542 net.cpp:150] Setting up relu4
I0523 18:01:37.852150 15542 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 18:01:37.852161 15542 net.cpp:165] Memory required for data: 93421200
I0523 18:01:37.852172 15542 layer_factory.hpp:77] Creating layer pool4
I0523 18:01:37.852185 15542 net.cpp:106] Creating Layer pool4
I0523 18:01:37.852195 15542 net.cpp:454] pool4 <- conv4
I0523 18:01:37.852207 15542 net.cpp:411] pool4 -> pool4
I0523 18:01:37.852275 15542 net.cpp:150] Setting up pool4
I0523 18:01:37.852289 15542 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 18:01:37.852300 15542 net.cpp:165] Memory required for data: 94509840
I0523 18:01:37.852309 15542 layer_factory.hpp:77] Creating layer ip1
I0523 18:01:37.852329 15542 net.cpp:106] Creating Layer ip1
I0523 18:01:37.852339 15542 net.cpp:454] ip1 <- pool4
I0523 18:01:37.852351 15542 net.cpp:411] ip1 -> ip1
I0523 18:01:37.867782 15542 net.cpp:150] Setting up ip1
I0523 18:01:37.867810 15542 net.cpp:157] Top shape: 60 196 (11760)
I0523 18:01:37.867822 15542 net.cpp:165] Memory required for data: 94556880
I0523 18:01:37.867846 15542 layer_factory.hpp:77] Creating layer relu5
I0523 18:01:37.867861 15542 net.cpp:106] Creating Layer relu5
I0523 18:01:37.867871 15542 net.cpp:454] relu5 <- ip1
I0523 18:01:37.867884 15542 net.cpp:397] relu5 -> ip1 (in-place)
I0523 18:01:37.868226 15542 net.cpp:150] Setting up relu5
I0523 18:01:37.868239 15542 net.cpp:157] Top shape: 60 196 (11760)
I0523 18:01:37.868249 15542 net.cpp:165] Memory required for data: 94603920
I0523 18:01:37.868260 15542 layer_factory.hpp:77] Creating layer drop1
I0523 18:01:37.868283 15542 net.cpp:106] Creating Layer drop1
I0523 18:01:37.868293 15542 net.cpp:454] drop1 <- ip1
I0523 18:01:37.868304 15542 net.cpp:397] drop1 -> ip1 (in-place)
I0523 18:01:37.868363 15542 net.cpp:150] Setting up drop1
I0523 18:01:37.868376 15542 net.cpp:157] Top shape: 60 196 (11760)
I0523 18:01:37.868386 15542 net.cpp:165] Memory required for data: 94650960
I0523 18:01:37.868396 15542 layer_factory.hpp:77] Creating layer ip2
I0523 18:01:37.868415 15542 net.cpp:106] Creating Layer ip2
I0523 18:01:37.868425 15542 net.cpp:454] ip2 <- ip1
I0523 18:01:37.868438 15542 net.cpp:411] ip2 -> ip2
I0523 18:01:37.868901 15542 net.cpp:150] Setting up ip2
I0523 18:01:37.868914 15542 net.cpp:157] Top shape: 60 98 (5880)
I0523 18:01:37.868923 15542 net.cpp:165] Memory required for data: 94674480
I0523 18:01:37.868938 15542 layer_factory.hpp:77] Creating layer relu6
I0523 18:01:37.868952 15542 net.cpp:106] Creating Layer relu6
I0523 18:01:37.868960 15542 net.cpp:454] relu6 <- ip2
I0523 18:01:37.868973 15542 net.cpp:397] relu6 -> ip2 (in-place)
I0523 18:01:37.869503 15542 net.cpp:150] Setting up relu6
I0523 18:01:37.869519 15542 net.cpp:157] Top shape: 60 98 (5880)
I0523 18:01:37.869530 15542 net.cpp:165] Memory required for data: 94698000
I0523 18:01:37.869540 15542 layer_factory.hpp:77] Creating layer drop2
I0523 18:01:37.869554 15542 net.cpp:106] Creating Layer drop2
I0523 18:01:37.869563 15542 net.cpp:454] drop2 <- ip2
I0523 18:01:37.869576 15542 net.cpp:397] drop2 -> ip2 (in-place)
I0523 18:01:37.869619 15542 net.cpp:150] Setting up drop2
I0523 18:01:37.869632 15542 net.cpp:157] Top shape: 60 98 (5880)
I0523 18:01:37.869642 15542 net.cpp:165] Memory required for data: 94721520
I0523 18:01:37.869652 15542 layer_factory.hpp:77] Creating layer ip3
I0523 18:01:37.869666 15542 net.cpp:106] Creating Layer ip3
I0523 18:01:37.869676 15542 net.cpp:454] ip3 <- ip2
I0523 18:01:37.869689 15542 net.cpp:411] ip3 -> ip3
I0523 18:01:37.869899 15542 net.cpp:150] Setting up ip3
I0523 18:01:37.869911 15542 net.cpp:157] Top shape: 60 11 (660)
I0523 18:01:37.869921 15542 net.cpp:165] Memory required for data: 94724160
I0523 18:01:37.869936 15542 layer_factory.hpp:77] Creating layer drop3
I0523 18:01:37.869949 15542 net.cpp:106] Creating Layer drop3
I0523 18:01:37.869959 15542 net.cpp:454] drop3 <- ip3
I0523 18:01:37.869971 15542 net.cpp:397] drop3 -> ip3 (in-place)
I0523 18:01:37.870010 15542 net.cpp:150] Setting up drop3
I0523 18:01:37.870023 15542 net.cpp:157] Top shape: 60 11 (660)
I0523 18:01:37.870034 15542 net.cpp:165] Memory required for data: 94726800
I0523 18:01:37.870044 15542 layer_factory.hpp:77] Creating layer loss
I0523 18:01:37.870064 15542 net.cpp:106] Creating Layer loss
I0523 18:01:37.870074 15542 net.cpp:454] loss <- ip3
I0523 18:01:37.870085 15542 net.cpp:454] loss <- label
I0523 18:01:37.870097 15542 net.cpp:411] loss -> loss
I0523 18:01:37.870115 15542 layer_factory.hpp:77] Creating layer loss
I0523 18:01:37.870754 15542 net.cpp:150] Setting up loss
I0523 18:01:37.870775 15542 net.cpp:157] Top shape: (1)
I0523 18:01:37.870785 15542 net.cpp:160]     with loss weight 1
I0523 18:01:37.870828 15542 net.cpp:165] Memory required for data: 94726804
I0523 18:01:37.870838 15542 net.cpp:226] loss needs backward computation.
I0523 18:01:37.870851 15542 net.cpp:226] drop3 needs backward computation.
I0523 18:01:37.870860 15542 net.cpp:226] ip3 needs backward computation.
I0523 18:01:37.870870 15542 net.cpp:226] drop2 needs backward computation.
I0523 18:01:37.870880 15542 net.cpp:226] relu6 needs backward computation.
I0523 18:01:37.870889 15542 net.cpp:226] ip2 needs backward computation.
I0523 18:01:37.870900 15542 net.cpp:226] drop1 needs backward computation.
I0523 18:01:37.870909 15542 net.cpp:226] relu5 needs backward computation.
I0523 18:01:37.870919 15542 net.cpp:226] ip1 needs backward computation.
I0523 18:01:37.870929 15542 net.cpp:226] pool4 needs backward computation.
I0523 18:01:37.870939 15542 net.cpp:226] relu4 needs backward computation.
I0523 18:01:37.870949 15542 net.cpp:226] conv4 needs backward computation.
I0523 18:01:37.870959 15542 net.cpp:226] pool3 needs backward computation.
I0523 18:01:37.870970 15542 net.cpp:226] relu3 needs backward computation.
I0523 18:01:37.870980 15542 net.cpp:226] conv3 needs backward computation.
I0523 18:01:37.871000 15542 net.cpp:226] pool2 needs backward computation.
I0523 18:01:37.871011 15542 net.cpp:226] relu2 needs backward computation.
I0523 18:01:37.871021 15542 net.cpp:226] conv2 needs backward computation.
I0523 18:01:37.871031 15542 net.cpp:226] pool1 needs backward computation.
I0523 18:01:37.871040 15542 net.cpp:226] relu1 needs backward computation.
I0523 18:01:37.871050 15542 net.cpp:226] conv1 needs backward computation.
I0523 18:01:37.871062 15542 net.cpp:228] data_hdf5 does not need backward computation.
I0523 18:01:37.871070 15542 net.cpp:270] This network produces output loss
I0523 18:01:37.871094 15542 net.cpp:283] Network initialization done.
I0523 18:01:37.872861 15542 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507.prototxt
I0523 18:01:37.872932 15542 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 18:01:37.873299 15542 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 18:01:37.873491 15542 layer_factory.hpp:77] Creating layer data_hdf5
I0523 18:01:37.873505 15542 net.cpp:106] Creating Layer data_hdf5
I0523 18:01:37.873517 15542 net.cpp:411] data_hdf5 -> data
I0523 18:01:37.873534 15542 net.cpp:411] data_hdf5 -> label
I0523 18:01:37.873549 15542 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 18:01:37.888885 15542 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 18:01:59.253453 15542 net.cpp:150] Setting up data_hdf5
I0523 18:01:59.253618 15542 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 18:01:59.253633 15542 net.cpp:157] Top shape: 60 (60)
I0523 18:01:59.253645 15542 net.cpp:165] Memory required for data: 1524240
I0523 18:01:59.253659 15542 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 18:01:59.253687 15542 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 18:01:59.253697 15542 net.cpp:454] label_data_hdf5_1_split <- label
I0523 18:01:59.253712 15542 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 18:01:59.253733 15542 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 18:01:59.253806 15542 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 18:01:59.253820 15542 net.cpp:157] Top shape: 60 (60)
I0523 18:01:59.253831 15542 net.cpp:157] Top shape: 60 (60)
I0523 18:01:59.253841 15542 net.cpp:165] Memory required for data: 1524720
I0523 18:01:59.253850 15542 layer_factory.hpp:77] Creating layer conv1
I0523 18:01:59.253873 15542 net.cpp:106] Creating Layer conv1
I0523 18:01:59.253885 15542 net.cpp:454] conv1 <- data
I0523 18:01:59.253897 15542 net.cpp:411] conv1 -> conv1
I0523 18:01:59.255844 15542 net.cpp:150] Setting up conv1
I0523 18:01:59.255868 15542 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 18:01:59.255880 15542 net.cpp:165] Memory required for data: 18113520
I0523 18:01:59.255902 15542 layer_factory.hpp:77] Creating layer relu1
I0523 18:01:59.255915 15542 net.cpp:106] Creating Layer relu1
I0523 18:01:59.255925 15542 net.cpp:454] relu1 <- conv1
I0523 18:01:59.255939 15542 net.cpp:397] relu1 -> conv1 (in-place)
I0523 18:01:59.256438 15542 net.cpp:150] Setting up relu1
I0523 18:01:59.256454 15542 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 18:01:59.256464 15542 net.cpp:165] Memory required for data: 34702320
I0523 18:01:59.256474 15542 layer_factory.hpp:77] Creating layer pool1
I0523 18:01:59.256491 15542 net.cpp:106] Creating Layer pool1
I0523 18:01:59.256500 15542 net.cpp:454] pool1 <- conv1
I0523 18:01:59.256513 15542 net.cpp:411] pool1 -> pool1
I0523 18:01:59.256587 15542 net.cpp:150] Setting up pool1
I0523 18:01:59.256602 15542 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 18:01:59.256610 15542 net.cpp:165] Memory required for data: 42996720
I0523 18:01:59.256618 15542 layer_factory.hpp:77] Creating layer conv2
I0523 18:01:59.256636 15542 net.cpp:106] Creating Layer conv2
I0523 18:01:59.256647 15542 net.cpp:454] conv2 <- pool1
I0523 18:01:59.256661 15542 net.cpp:411] conv2 -> conv2
I0523 18:01:59.258580 15542 net.cpp:150] Setting up conv2
I0523 18:01:59.258602 15542 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 18:01:59.258612 15542 net.cpp:165] Memory required for data: 54919920
I0523 18:01:59.258631 15542 layer_factory.hpp:77] Creating layer relu2
I0523 18:01:59.258644 15542 net.cpp:106] Creating Layer relu2
I0523 18:01:59.258654 15542 net.cpp:454] relu2 <- conv2
I0523 18:01:59.258667 15542 net.cpp:397] relu2 -> conv2 (in-place)
I0523 18:01:59.258998 15542 net.cpp:150] Setting up relu2
I0523 18:01:59.259012 15542 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 18:01:59.259022 15542 net.cpp:165] Memory required for data: 66843120
I0523 18:01:59.259032 15542 layer_factory.hpp:77] Creating layer pool2
I0523 18:01:59.259045 15542 net.cpp:106] Creating Layer pool2
I0523 18:01:59.259055 15542 net.cpp:454] pool2 <- conv2
I0523 18:01:59.259068 15542 net.cpp:411] pool2 -> pool2
I0523 18:01:59.259137 15542 net.cpp:150] Setting up pool2
I0523 18:01:59.259150 15542 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 18:01:59.259160 15542 net.cpp:165] Memory required for data: 72804720
I0523 18:01:59.259171 15542 layer_factory.hpp:77] Creating layer conv3
I0523 18:01:59.259189 15542 net.cpp:106] Creating Layer conv3
I0523 18:01:59.259199 15542 net.cpp:454] conv3 <- pool2
I0523 18:01:59.259213 15542 net.cpp:411] conv3 -> conv3
I0523 18:01:59.261193 15542 net.cpp:150] Setting up conv3
I0523 18:01:59.261215 15542 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 18:01:59.261227 15542 net.cpp:165] Memory required for data: 79309680
I0523 18:01:59.261260 15542 layer_factory.hpp:77] Creating layer relu3
I0523 18:01:59.261273 15542 net.cpp:106] Creating Layer relu3
I0523 18:01:59.261283 15542 net.cpp:454] relu3 <- conv3
I0523 18:01:59.261296 15542 net.cpp:397] relu3 -> conv3 (in-place)
I0523 18:01:59.261775 15542 net.cpp:150] Setting up relu3
I0523 18:01:59.261791 15542 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 18:01:59.261802 15542 net.cpp:165] Memory required for data: 85814640
I0523 18:01:59.261812 15542 layer_factory.hpp:77] Creating layer pool3
I0523 18:01:59.261826 15542 net.cpp:106] Creating Layer pool3
I0523 18:01:59.261836 15542 net.cpp:454] pool3 <- conv3
I0523 18:01:59.261848 15542 net.cpp:411] pool3 -> pool3
I0523 18:01:59.261919 15542 net.cpp:150] Setting up pool3
I0523 18:01:59.261932 15542 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 18:01:59.261942 15542 net.cpp:165] Memory required for data: 89067120
I0523 18:01:59.261951 15542 layer_factory.hpp:77] Creating layer conv4
I0523 18:01:59.261970 15542 net.cpp:106] Creating Layer conv4
I0523 18:01:59.261979 15542 net.cpp:454] conv4 <- pool3
I0523 18:01:59.261993 15542 net.cpp:411] conv4 -> conv4
I0523 18:01:59.264045 15542 net.cpp:150] Setting up conv4
I0523 18:01:59.264067 15542 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 18:01:59.264080 15542 net.cpp:165] Memory required for data: 91244400
I0523 18:01:59.264094 15542 layer_factory.hpp:77] Creating layer relu4
I0523 18:01:59.264107 15542 net.cpp:106] Creating Layer relu4
I0523 18:01:59.264117 15542 net.cpp:454] relu4 <- conv4
I0523 18:01:59.264130 15542 net.cpp:397] relu4 -> conv4 (in-place)
I0523 18:01:59.264600 15542 net.cpp:150] Setting up relu4
I0523 18:01:59.264616 15542 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 18:01:59.264626 15542 net.cpp:165] Memory required for data: 93421680
I0523 18:01:59.264636 15542 layer_factory.hpp:77] Creating layer pool4
I0523 18:01:59.264649 15542 net.cpp:106] Creating Layer pool4
I0523 18:01:59.264659 15542 net.cpp:454] pool4 <- conv4
I0523 18:01:59.264672 15542 net.cpp:411] pool4 -> pool4
I0523 18:01:59.264744 15542 net.cpp:150] Setting up pool4
I0523 18:01:59.264756 15542 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 18:01:59.264766 15542 net.cpp:165] Memory required for data: 94510320
I0523 18:01:59.264776 15542 layer_factory.hpp:77] Creating layer ip1
I0523 18:01:59.264791 15542 net.cpp:106] Creating Layer ip1
I0523 18:01:59.264801 15542 net.cpp:454] ip1 <- pool4
I0523 18:01:59.264814 15542 net.cpp:411] ip1 -> ip1
I0523 18:01:59.280321 15542 net.cpp:150] Setting up ip1
I0523 18:01:59.280349 15542 net.cpp:157] Top shape: 60 196 (11760)
I0523 18:01:59.280360 15542 net.cpp:165] Memory required for data: 94557360
I0523 18:01:59.280382 15542 layer_factory.hpp:77] Creating layer relu5
I0523 18:01:59.280397 15542 net.cpp:106] Creating Layer relu5
I0523 18:01:59.280407 15542 net.cpp:454] relu5 <- ip1
I0523 18:01:59.280421 15542 net.cpp:397] relu5 -> ip1 (in-place)
I0523 18:01:59.280766 15542 net.cpp:150] Setting up relu5
I0523 18:01:59.280781 15542 net.cpp:157] Top shape: 60 196 (11760)
I0523 18:01:59.280791 15542 net.cpp:165] Memory required for data: 94604400
I0523 18:01:59.280802 15542 layer_factory.hpp:77] Creating layer drop1
I0523 18:01:59.280819 15542 net.cpp:106] Creating Layer drop1
I0523 18:01:59.280829 15542 net.cpp:454] drop1 <- ip1
I0523 18:01:59.280843 15542 net.cpp:397] drop1 -> ip1 (in-place)
I0523 18:01:59.280887 15542 net.cpp:150] Setting up drop1
I0523 18:01:59.280900 15542 net.cpp:157] Top shape: 60 196 (11760)
I0523 18:01:59.280908 15542 net.cpp:165] Memory required for data: 94651440
I0523 18:01:59.280920 15542 layer_factory.hpp:77] Creating layer ip2
I0523 18:01:59.280935 15542 net.cpp:106] Creating Layer ip2
I0523 18:01:59.280944 15542 net.cpp:454] ip2 <- ip1
I0523 18:01:59.280957 15542 net.cpp:411] ip2 -> ip2
I0523 18:01:59.281442 15542 net.cpp:150] Setting up ip2
I0523 18:01:59.281455 15542 net.cpp:157] Top shape: 60 98 (5880)
I0523 18:01:59.281466 15542 net.cpp:165] Memory required for data: 94674960
I0523 18:01:59.281481 15542 layer_factory.hpp:77] Creating layer relu6
I0523 18:01:59.281507 15542 net.cpp:106] Creating Layer relu6
I0523 18:01:59.281517 15542 net.cpp:454] relu6 <- ip2
I0523 18:01:59.281529 15542 net.cpp:397] relu6 -> ip2 (in-place)
I0523 18:01:59.282063 15542 net.cpp:150] Setting up relu6
I0523 18:01:59.282078 15542 net.cpp:157] Top shape: 60 98 (5880)
I0523 18:01:59.282088 15542 net.cpp:165] Memory required for data: 94698480
I0523 18:01:59.282100 15542 layer_factory.hpp:77] Creating layer drop2
I0523 18:01:59.282114 15542 net.cpp:106] Creating Layer drop2
I0523 18:01:59.282124 15542 net.cpp:454] drop2 <- ip2
I0523 18:01:59.282136 15542 net.cpp:397] drop2 -> ip2 (in-place)
I0523 18:01:59.282181 15542 net.cpp:150] Setting up drop2
I0523 18:01:59.282193 15542 net.cpp:157] Top shape: 60 98 (5880)
I0523 18:01:59.282203 15542 net.cpp:165] Memory required for data: 94722000
I0523 18:01:59.282213 15542 layer_factory.hpp:77] Creating layer ip3
I0523 18:01:59.282228 15542 net.cpp:106] Creating Layer ip3
I0523 18:01:59.282238 15542 net.cpp:454] ip3 <- ip2
I0523 18:01:59.282251 15542 net.cpp:411] ip3 -> ip3
I0523 18:01:59.282471 15542 net.cpp:150] Setting up ip3
I0523 18:01:59.282485 15542 net.cpp:157] Top shape: 60 11 (660)
I0523 18:01:59.282495 15542 net.cpp:165] Memory required for data: 94724640
I0523 18:01:59.282510 15542 layer_factory.hpp:77] Creating layer drop3
I0523 18:01:59.282522 15542 net.cpp:106] Creating Layer drop3
I0523 18:01:59.282532 15542 net.cpp:454] drop3 <- ip3
I0523 18:01:59.282544 15542 net.cpp:397] drop3 -> ip3 (in-place)
I0523 18:01:59.282587 15542 net.cpp:150] Setting up drop3
I0523 18:01:59.282598 15542 net.cpp:157] Top shape: 60 11 (660)
I0523 18:01:59.282609 15542 net.cpp:165] Memory required for data: 94727280
I0523 18:01:59.282618 15542 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 18:01:59.282631 15542 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 18:01:59.282641 15542 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 18:01:59.282655 15542 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 18:01:59.282668 15542 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 18:01:59.282742 15542 net.cpp:150] Setting up ip3_drop3_0_split
I0523 18:01:59.282754 15542 net.cpp:157] Top shape: 60 11 (660)
I0523 18:01:59.282768 15542 net.cpp:157] Top shape: 60 11 (660)
I0523 18:01:59.282778 15542 net.cpp:165] Memory required for data: 94732560
I0523 18:01:59.282784 15542 layer_factory.hpp:77] Creating layer accuracy
I0523 18:01:59.282806 15542 net.cpp:106] Creating Layer accuracy
I0523 18:01:59.282816 15542 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 18:01:59.282827 15542 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 18:01:59.282841 15542 net.cpp:411] accuracy -> accuracy
I0523 18:01:59.282865 15542 net.cpp:150] Setting up accuracy
I0523 18:01:59.282877 15542 net.cpp:157] Top shape: (1)
I0523 18:01:59.282887 15542 net.cpp:165] Memory required for data: 94732564
I0523 18:01:59.282897 15542 layer_factory.hpp:77] Creating layer loss
I0523 18:01:59.282910 15542 net.cpp:106] Creating Layer loss
I0523 18:01:59.282922 15542 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 18:01:59.282935 15542 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 18:01:59.282949 15542 net.cpp:411] loss -> loss
I0523 18:01:59.282966 15542 layer_factory.hpp:77] Creating layer loss
I0523 18:01:59.283452 15542 net.cpp:150] Setting up loss
I0523 18:01:59.283465 15542 net.cpp:157] Top shape: (1)
I0523 18:01:59.283475 15542 net.cpp:160]     with loss weight 1
I0523 18:01:59.283493 15542 net.cpp:165] Memory required for data: 94732568
I0523 18:01:59.283504 15542 net.cpp:226] loss needs backward computation.
I0523 18:01:59.283515 15542 net.cpp:228] accuracy does not need backward computation.
I0523 18:01:59.283526 15542 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 18:01:59.283536 15542 net.cpp:226] drop3 needs backward computation.
I0523 18:01:59.283546 15542 net.cpp:226] ip3 needs backward computation.
I0523 18:01:59.283556 15542 net.cpp:226] drop2 needs backward computation.
I0523 18:01:59.283567 15542 net.cpp:226] relu6 needs backward computation.
I0523 18:01:59.283584 15542 net.cpp:226] ip2 needs backward computation.
I0523 18:01:59.283594 15542 net.cpp:226] drop1 needs backward computation.
I0523 18:01:59.283604 15542 net.cpp:226] relu5 needs backward computation.
I0523 18:01:59.283613 15542 net.cpp:226] ip1 needs backward computation.
I0523 18:01:59.283623 15542 net.cpp:226] pool4 needs backward computation.
I0523 18:01:59.283633 15542 net.cpp:226] relu4 needs backward computation.
I0523 18:01:59.283643 15542 net.cpp:226] conv4 needs backward computation.
I0523 18:01:59.283653 15542 net.cpp:226] pool3 needs backward computation.
I0523 18:01:59.283663 15542 net.cpp:226] relu3 needs backward computation.
I0523 18:01:59.283673 15542 net.cpp:226] conv3 needs backward computation.
I0523 18:01:59.283682 15542 net.cpp:226] pool2 needs backward computation.
I0523 18:01:59.283692 15542 net.cpp:226] relu2 needs backward computation.
I0523 18:01:59.283702 15542 net.cpp:226] conv2 needs backward computation.
I0523 18:01:59.283713 15542 net.cpp:226] pool1 needs backward computation.
I0523 18:01:59.283723 15542 net.cpp:226] relu1 needs backward computation.
I0523 18:01:59.283732 15542 net.cpp:226] conv1 needs backward computation.
I0523 18:01:59.283743 15542 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 18:01:59.283756 15542 net.cpp:228] data_hdf5 does not need backward computation.
I0523 18:01:59.283764 15542 net.cpp:270] This network produces output accuracy
I0523 18:01:59.283776 15542 net.cpp:270] This network produces output loss
I0523 18:01:59.283803 15542 net.cpp:283] Network initialization done.
I0523 18:01:59.283936 15542 solver.cpp:60] Solver scaffolding done.
I0523 18:01:59.285078 15542 caffe.cpp:212] Starting Optimization
I0523 18:01:59.285096 15542 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 18:01:59.285110 15542 solver.cpp:289] Learning Rate Policy: fixed
I0523 18:01:59.286331 15542 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 18:02:47.571722 15542 solver.cpp:409]     Test net output #0: accuracy = 0.0599272
I0523 18:02:47.571899 15542 solver.cpp:409]     Test net output #1: loss = 2.39815 (* 1 = 2.39815 loss)
I0523 18:02:47.597797 15542 solver.cpp:237] Iteration 0, loss = 2.40663
I0523 18:02:47.597834 15542 solver.cpp:253]     Train net output #0: loss = 2.40663 (* 1 = 2.40663 loss)
I0523 18:02:47.597852 15542 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0523 18:02:56.688385 15542 solver.cpp:237] Iteration 250, loss = 2.04403
I0523 18:02:56.688421 15542 solver.cpp:253]     Train net output #0: loss = 2.04403 (* 1 = 2.04403 loss)
I0523 18:02:56.688438 15542 sgd_solver.cpp:106] Iteration 250, lr = 0.0035
I0523 18:03:05.776794 15542 solver.cpp:237] Iteration 500, loss = 1.94466
I0523 18:03:05.776840 15542 solver.cpp:253]     Train net output #0: loss = 1.94466 (* 1 = 1.94466 loss)
I0523 18:03:05.776854 15542 sgd_solver.cpp:106] Iteration 500, lr = 0.0035
I0523 18:03:14.859190 15542 solver.cpp:237] Iteration 750, loss = 2.14897
I0523 18:03:14.859225 15542 solver.cpp:253]     Train net output #0: loss = 2.14897 (* 1 = 2.14897 loss)
I0523 18:03:14.859242 15542 sgd_solver.cpp:106] Iteration 750, lr = 0.0035
I0523 18:03:23.953028 15542 solver.cpp:237] Iteration 1000, loss = 1.78385
I0523 18:03:23.953181 15542 solver.cpp:253]     Train net output #0: loss = 1.78385 (* 1 = 1.78385 loss)
I0523 18:03:23.953197 15542 sgd_solver.cpp:106] Iteration 1000, lr = 0.0035
I0523 18:03:33.051600 15542 solver.cpp:237] Iteration 1250, loss = 1.71399
I0523 18:03:33.051645 15542 solver.cpp:253]     Train net output #0: loss = 1.71399 (* 1 = 1.71399 loss)
I0523 18:03:33.051662 15542 sgd_solver.cpp:106] Iteration 1250, lr = 0.0035
I0523 18:03:42.150837 15542 solver.cpp:237] Iteration 1500, loss = 1.78065
I0523 18:03:42.150873 15542 solver.cpp:253]     Train net output #0: loss = 1.78065 (* 1 = 1.78065 loss)
I0523 18:03:42.150887 15542 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0523 18:04:13.479444 15542 solver.cpp:237] Iteration 1750, loss = 1.67548
I0523 18:04:13.479607 15542 solver.cpp:253]     Train net output #0: loss = 1.67548 (* 1 = 1.67548 loss)
I0523 18:04:13.479624 15542 sgd_solver.cpp:106] Iteration 1750, lr = 0.0035
I0523 18:04:22.583091 15542 solver.cpp:237] Iteration 2000, loss = 1.7021
I0523 18:04:22.583134 15542 solver.cpp:253]     Train net output #0: loss = 1.7021 (* 1 = 1.7021 loss)
I0523 18:04:22.583153 15542 sgd_solver.cpp:106] Iteration 2000, lr = 0.0035
I0523 18:04:31.679725 15542 solver.cpp:237] Iteration 2250, loss = 1.84937
I0523 18:04:31.679761 15542 solver.cpp:253]     Train net output #0: loss = 1.84937 (* 1 = 1.84937 loss)
I0523 18:04:31.679775 15542 sgd_solver.cpp:106] Iteration 2250, lr = 0.0035
I0523 18:04:40.749666 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_2500.caffemodel
I0523 18:04:40.816076 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_2500.solverstate
I0523 18:04:40.852633 15542 solver.cpp:237] Iteration 2500, loss = 1.6008
I0523 18:04:40.852679 15542 solver.cpp:253]     Train net output #0: loss = 1.6008 (* 1 = 1.6008 loss)
I0523 18:04:40.852694 15542 sgd_solver.cpp:106] Iteration 2500, lr = 0.0035
I0523 18:04:49.949096 15542 solver.cpp:237] Iteration 2750, loss = 1.52
I0523 18:04:49.949237 15542 solver.cpp:253]     Train net output #0: loss = 1.52 (* 1 = 1.52 loss)
I0523 18:04:49.949251 15542 sgd_solver.cpp:106] Iteration 2750, lr = 0.0035
I0523 18:04:59.044894 15542 solver.cpp:237] Iteration 3000, loss = 1.44125
I0523 18:04:59.044929 15542 solver.cpp:253]     Train net output #0: loss = 1.44125 (* 1 = 1.44125 loss)
I0523 18:04:59.044945 15542 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0523 18:05:08.147814 15542 solver.cpp:237] Iteration 3250, loss = 1.41002
I0523 18:05:08.147856 15542 solver.cpp:253]     Train net output #0: loss = 1.41002 (* 1 = 1.41002 loss)
I0523 18:05:08.147874 15542 sgd_solver.cpp:106] Iteration 3250, lr = 0.0035
I0523 18:05:39.415155 15542 solver.cpp:237] Iteration 3500, loss = 1.54626
I0523 18:05:39.415314 15542 solver.cpp:253]     Train net output #0: loss = 1.54626 (* 1 = 1.54626 loss)
I0523 18:05:39.415329 15542 sgd_solver.cpp:106] Iteration 3500, lr = 0.0035
I0523 18:05:48.511935 15542 solver.cpp:237] Iteration 3750, loss = 1.35254
I0523 18:05:48.511970 15542 solver.cpp:253]     Train net output #0: loss = 1.35254 (* 1 = 1.35254 loss)
I0523 18:05:48.511984 15542 sgd_solver.cpp:106] Iteration 3750, lr = 0.0035
I0523 18:05:57.627267 15542 solver.cpp:237] Iteration 4000, loss = 1.51771
I0523 18:05:57.627312 15542 solver.cpp:253]     Train net output #0: loss = 1.51771 (* 1 = 1.51771 loss)
I0523 18:05:57.627329 15542 sgd_solver.cpp:106] Iteration 4000, lr = 0.0035
I0523 18:06:06.732321 15542 solver.cpp:237] Iteration 4250, loss = 1.19301
I0523 18:06:06.732357 15542 solver.cpp:253]     Train net output #0: loss = 1.19301 (* 1 = 1.19301 loss)
I0523 18:06:06.732372 15542 sgd_solver.cpp:106] Iteration 4250, lr = 0.0035
I0523 18:06:15.832801 15542 solver.cpp:237] Iteration 4500, loss = 1.43444
I0523 18:06:15.832950 15542 solver.cpp:253]     Train net output #0: loss = 1.43444 (* 1 = 1.43444 loss)
I0523 18:06:15.832964 15542 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0523 18:06:24.924396 15542 solver.cpp:237] Iteration 4750, loss = 1.49704
I0523 18:06:24.924435 15542 solver.cpp:253]     Train net output #0: loss = 1.49704 (* 1 = 1.49704 loss)
I0523 18:06:24.924449 15542 sgd_solver.cpp:106] Iteration 4750, lr = 0.0035
I0523 18:06:33.999934 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_5000.caffemodel
I0523 18:06:34.063400 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_5000.solverstate
I0523 18:06:34.088551 15542 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 18:07:21.427958 15542 solver.cpp:409]     Test net output #0: accuracy = 0.801037
I0523 18:07:21.428117 15542 solver.cpp:409]     Test net output #1: loss = 0.677415 (* 1 = 0.677415 loss)
I0523 18:07:43.619611 15542 solver.cpp:237] Iteration 5000, loss = 1.35706
I0523 18:07:43.619665 15542 solver.cpp:253]     Train net output #0: loss = 1.35706 (* 1 = 1.35706 loss)
I0523 18:07:43.619680 15542 sgd_solver.cpp:106] Iteration 5000, lr = 0.0035
I0523 18:07:52.698302 15542 solver.cpp:237] Iteration 5250, loss = 1.18168
I0523 18:07:52.698444 15542 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0523 18:07:52.698458 15542 sgd_solver.cpp:106] Iteration 5250, lr = 0.0035
I0523 18:08:01.780179 15542 solver.cpp:237] Iteration 5500, loss = 1.44458
I0523 18:08:01.780221 15542 solver.cpp:253]     Train net output #0: loss = 1.44458 (* 1 = 1.44458 loss)
I0523 18:08:01.780239 15542 sgd_solver.cpp:106] Iteration 5500, lr = 0.0035
I0523 18:08:10.856181 15542 solver.cpp:237] Iteration 5750, loss = 1.32194
I0523 18:08:10.856217 15542 solver.cpp:253]     Train net output #0: loss = 1.32194 (* 1 = 1.32194 loss)
I0523 18:08:10.856230 15542 sgd_solver.cpp:106] Iteration 5750, lr = 0.0035
I0523 18:08:19.929728 15542 solver.cpp:237] Iteration 6000, loss = 1.44625
I0523 18:08:19.929762 15542 solver.cpp:253]     Train net output #0: loss = 1.44625 (* 1 = 1.44625 loss)
I0523 18:08:19.929776 15542 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0523 18:08:28.999079 15542 solver.cpp:237] Iteration 6250, loss = 1.61917
I0523 18:08:28.999222 15542 solver.cpp:253]     Train net output #0: loss = 1.61917 (* 1 = 1.61917 loss)
I0523 18:08:28.999235 15542 sgd_solver.cpp:106] Iteration 6250, lr = 0.0035
I0523 18:08:38.082244 15542 solver.cpp:237] Iteration 6500, loss = 1.37912
I0523 18:08:38.082279 15542 solver.cpp:253]     Train net output #0: loss = 1.37912 (* 1 = 1.37912 loss)
I0523 18:08:38.082293 15542 sgd_solver.cpp:106] Iteration 6500, lr = 0.0035
I0523 18:09:09.362735 15542 solver.cpp:237] Iteration 6750, loss = 1.26008
I0523 18:09:09.362893 15542 solver.cpp:253]     Train net output #0: loss = 1.26008 (* 1 = 1.26008 loss)
I0523 18:09:09.362910 15542 sgd_solver.cpp:106] Iteration 6750, lr = 0.0035
I0523 18:09:18.438279 15542 solver.cpp:237] Iteration 7000, loss = 1.38941
I0523 18:09:18.438318 15542 solver.cpp:253]     Train net output #0: loss = 1.38941 (* 1 = 1.38941 loss)
I0523 18:09:18.438336 15542 sgd_solver.cpp:106] Iteration 7000, lr = 0.0035
I0523 18:09:27.518270 15542 solver.cpp:237] Iteration 7250, loss = 1.25045
I0523 18:09:27.518306 15542 solver.cpp:253]     Train net output #0: loss = 1.25045 (* 1 = 1.25045 loss)
I0523 18:09:27.518319 15542 sgd_solver.cpp:106] Iteration 7250, lr = 0.0035
I0523 18:09:36.555611 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_7500.caffemodel
I0523 18:09:36.621434 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_7500.solverstate
I0523 18:09:36.660097 15542 solver.cpp:237] Iteration 7500, loss = 1.17903
I0523 18:09:36.660147 15542 solver.cpp:253]     Train net output #0: loss = 1.17903 (* 1 = 1.17903 loss)
I0523 18:09:36.660161 15542 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0523 18:09:45.743455 15542 solver.cpp:237] Iteration 7750, loss = 1.23515
I0523 18:09:45.743618 15542 solver.cpp:253]     Train net output #0: loss = 1.23515 (* 1 = 1.23515 loss)
I0523 18:09:45.743633 15542 sgd_solver.cpp:106] Iteration 7750, lr = 0.0035
I0523 18:09:54.814278 15542 solver.cpp:237] Iteration 8000, loss = 1.34036
I0523 18:09:54.814313 15542 solver.cpp:253]     Train net output #0: loss = 1.34036 (* 1 = 1.34036 loss)
I0523 18:09:54.814329 15542 sgd_solver.cpp:106] Iteration 8000, lr = 0.0035
I0523 18:10:03.888283 15542 solver.cpp:237] Iteration 8250, loss = 1.30539
I0523 18:10:03.888319 15542 solver.cpp:253]     Train net output #0: loss = 1.30539 (* 1 = 1.30539 loss)
I0523 18:10:03.888335 15542 sgd_solver.cpp:106] Iteration 8250, lr = 0.0035
I0523 18:10:35.178665 15542 solver.cpp:237] Iteration 8500, loss = 1.52793
I0523 18:10:35.178827 15542 solver.cpp:253]     Train net output #0: loss = 1.52793 (* 1 = 1.52793 loss)
I0523 18:10:35.178843 15542 sgd_solver.cpp:106] Iteration 8500, lr = 0.0035
I0523 18:10:44.263649 15542 solver.cpp:237] Iteration 8750, loss = 1.45173
I0523 18:10:44.263684 15542 solver.cpp:253]     Train net output #0: loss = 1.45173 (* 1 = 1.45173 loss)
I0523 18:10:44.263703 15542 sgd_solver.cpp:106] Iteration 8750, lr = 0.0035
I0523 18:10:53.347483 15542 solver.cpp:237] Iteration 9000, loss = 1.52385
I0523 18:10:53.347518 15542 solver.cpp:253]     Train net output #0: loss = 1.52385 (* 1 = 1.52385 loss)
I0523 18:10:53.347535 15542 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0523 18:11:02.421195 15542 solver.cpp:237] Iteration 9250, loss = 1.32717
I0523 18:11:02.421241 15542 solver.cpp:253]     Train net output #0: loss = 1.32717 (* 1 = 1.32717 loss)
I0523 18:11:02.421258 15542 sgd_solver.cpp:106] Iteration 9250, lr = 0.0035
I0523 18:11:11.503392 15542 solver.cpp:237] Iteration 9500, loss = 1.29707
I0523 18:11:11.503547 15542 solver.cpp:253]     Train net output #0: loss = 1.29707 (* 1 = 1.29707 loss)
I0523 18:11:11.503561 15542 sgd_solver.cpp:106] Iteration 9500, lr = 0.0035
I0523 18:11:20.581461 15542 solver.cpp:237] Iteration 9750, loss = 1.18091
I0523 18:11:20.581503 15542 solver.cpp:253]     Train net output #0: loss = 1.18091 (* 1 = 1.18091 loss)
I0523 18:11:20.581521 15542 sgd_solver.cpp:106] Iteration 9750, lr = 0.0035
I0523 18:11:29.620282 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_10000.caffemodel
I0523 18:11:29.685546 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_10000.solverstate
I0523 18:11:29.713241 15542 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 18:12:37.811740 15542 solver.cpp:409]     Test net output #0: accuracy = 0.838996
I0523 18:12:37.811900 15542 solver.cpp:409]     Test net output #1: loss = 0.53313 (* 1 = 0.53313 loss)
I0523 18:13:00.095396 15542 solver.cpp:237] Iteration 10000, loss = 1.4696
I0523 18:13:00.095450 15542 solver.cpp:253]     Train net output #0: loss = 1.4696 (* 1 = 1.4696 loss)
I0523 18:13:00.095465 15542 sgd_solver.cpp:106] Iteration 10000, lr = 0.0035
I0523 18:13:09.211877 15542 solver.cpp:237] Iteration 10250, loss = 1.47397
I0523 18:13:09.212031 15542 solver.cpp:253]     Train net output #0: loss = 1.47397 (* 1 = 1.47397 loss)
I0523 18:13:09.212045 15542 sgd_solver.cpp:106] Iteration 10250, lr = 0.0035
I0523 18:13:18.331099 15542 solver.cpp:237] Iteration 10500, loss = 1.22688
I0523 18:13:18.331132 15542 solver.cpp:253]     Train net output #0: loss = 1.22688 (* 1 = 1.22688 loss)
I0523 18:13:18.331151 15542 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0523 18:13:27.446614 15542 solver.cpp:237] Iteration 10750, loss = 1.22811
I0523 18:13:27.446658 15542 solver.cpp:253]     Train net output #0: loss = 1.22811 (* 1 = 1.22811 loss)
I0523 18:13:27.446671 15542 sgd_solver.cpp:106] Iteration 10750, lr = 0.0035
I0523 18:13:36.565186 15542 solver.cpp:237] Iteration 11000, loss = 1.3757
I0523 18:13:36.565220 15542 solver.cpp:253]     Train net output #0: loss = 1.3757 (* 1 = 1.3757 loss)
I0523 18:13:36.565237 15542 sgd_solver.cpp:106] Iteration 11000, lr = 0.0035
I0523 18:13:45.692008 15542 solver.cpp:237] Iteration 11250, loss = 1.17365
I0523 18:13:45.692149 15542 solver.cpp:253]     Train net output #0: loss = 1.17365 (* 1 = 1.17365 loss)
I0523 18:13:45.692163 15542 sgd_solver.cpp:106] Iteration 11250, lr = 0.0035
I0523 18:13:54.807342 15542 solver.cpp:237] Iteration 11500, loss = 1.14747
I0523 18:13:54.807387 15542 solver.cpp:253]     Train net output #0: loss = 1.14747 (* 1 = 1.14747 loss)
I0523 18:13:54.807404 15542 sgd_solver.cpp:106] Iteration 11500, lr = 0.0035
I0523 18:14:26.153525 15542 solver.cpp:237] Iteration 11750, loss = 1.42179
I0523 18:14:26.153687 15542 solver.cpp:253]     Train net output #0: loss = 1.42179 (* 1 = 1.42179 loss)
I0523 18:14:26.153702 15542 sgd_solver.cpp:106] Iteration 11750, lr = 0.0035
I0523 18:14:35.263838 15542 solver.cpp:237] Iteration 12000, loss = 1.148
I0523 18:14:35.263871 15542 solver.cpp:253]     Train net output #0: loss = 1.148 (* 1 = 1.148 loss)
I0523 18:14:35.263890 15542 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0523 18:14:44.367070 15542 solver.cpp:237] Iteration 12250, loss = 1.17734
I0523 18:14:44.367115 15542 solver.cpp:253]     Train net output #0: loss = 1.17734 (* 1 = 1.17734 loss)
I0523 18:14:44.367131 15542 sgd_solver.cpp:106] Iteration 12250, lr = 0.0035
I0523 18:14:53.446120 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_12500.caffemodel
I0523 18:14:53.510933 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_12500.solverstate
I0523 18:14:53.549180 15542 solver.cpp:237] Iteration 12500, loss = 1.22502
I0523 18:14:53.549228 15542 solver.cpp:253]     Train net output #0: loss = 1.22502 (* 1 = 1.22502 loss)
I0523 18:14:53.549245 15542 sgd_solver.cpp:106] Iteration 12500, lr = 0.0035
I0523 18:15:02.665479 15542 solver.cpp:237] Iteration 12750, loss = 1.1152
I0523 18:15:02.665623 15542 solver.cpp:253]     Train net output #0: loss = 1.1152 (* 1 = 1.1152 loss)
I0523 18:15:02.665637 15542 sgd_solver.cpp:106] Iteration 12750, lr = 0.0035
I0523 18:15:11.772688 15542 solver.cpp:237] Iteration 13000, loss = 1.5227
I0523 18:15:11.772727 15542 solver.cpp:253]     Train net output #0: loss = 1.5227 (* 1 = 1.5227 loss)
I0523 18:15:11.772747 15542 sgd_solver.cpp:106] Iteration 13000, lr = 0.0035
I0523 18:15:20.899277 15542 solver.cpp:237] Iteration 13250, loss = 1.50337
I0523 18:15:20.899312 15542 solver.cpp:253]     Train net output #0: loss = 1.50337 (* 1 = 1.50337 loss)
I0523 18:15:20.899327 15542 sgd_solver.cpp:106] Iteration 13250, lr = 0.0035
I0523 18:15:52.223990 15542 solver.cpp:237] Iteration 13500, loss = 1.21508
I0523 18:15:52.224169 15542 solver.cpp:253]     Train net output #0: loss = 1.21508 (* 1 = 1.21508 loss)
I0523 18:15:52.224186 15542 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0523 18:16:01.339826 15542 solver.cpp:237] Iteration 13750, loss = 1.47358
I0523 18:16:01.339867 15542 solver.cpp:253]     Train net output #0: loss = 1.47358 (* 1 = 1.47358 loss)
I0523 18:16:01.339885 15542 sgd_solver.cpp:106] Iteration 13750, lr = 0.0035
I0523 18:16:10.457042 15542 solver.cpp:237] Iteration 14000, loss = 1.18684
I0523 18:16:10.457083 15542 solver.cpp:253]     Train net output #0: loss = 1.18684 (* 1 = 1.18684 loss)
I0523 18:16:10.457099 15542 sgd_solver.cpp:106] Iteration 14000, lr = 0.0035
I0523 18:16:19.572113 15542 solver.cpp:237] Iteration 14250, loss = 1.27075
I0523 18:16:19.572147 15542 solver.cpp:253]     Train net output #0: loss = 1.27075 (* 1 = 1.27075 loss)
I0523 18:16:19.572163 15542 sgd_solver.cpp:106] Iteration 14250, lr = 0.0035
I0523 18:16:28.680755 15542 solver.cpp:237] Iteration 14500, loss = 1.18085
I0523 18:16:28.680907 15542 solver.cpp:253]     Train net output #0: loss = 1.18085 (* 1 = 1.18085 loss)
I0523 18:16:28.680922 15542 sgd_solver.cpp:106] Iteration 14500, lr = 0.0035
I0523 18:16:37.791066 15542 solver.cpp:237] Iteration 14750, loss = 1.09719
I0523 18:16:37.791100 15542 solver.cpp:253]     Train net output #0: loss = 1.09719 (* 1 = 1.09719 loss)
I0523 18:16:37.791117 15542 sgd_solver.cpp:106] Iteration 14750, lr = 0.0035
I0523 18:16:46.869541 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_15000.caffemodel
I0523 18:16:46.933763 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_15000.solverstate
I0523 18:16:46.959362 15542 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 18:17:33.908452 15542 solver.cpp:409]     Test net output #0: accuracy = 0.853815
I0523 18:17:33.908612 15542 solver.cpp:409]     Test net output #1: loss = 0.497893 (* 1 = 0.497893 loss)
I0523 18:17:56.073578 15542 solver.cpp:237] Iteration 15000, loss = 1.12109
I0523 18:17:56.073632 15542 solver.cpp:253]     Train net output #0: loss = 1.12109 (* 1 = 1.12109 loss)
I0523 18:17:56.073647 15542 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0523 18:18:05.109715 15542 solver.cpp:237] Iteration 15250, loss = 1.30244
I0523 18:18:05.109889 15542 solver.cpp:253]     Train net output #0: loss = 1.30244 (* 1 = 1.30244 loss)
I0523 18:18:05.109902 15542 sgd_solver.cpp:106] Iteration 15250, lr = 0.0035
I0523 18:18:14.143693 15542 solver.cpp:237] Iteration 15500, loss = 1.41564
I0523 18:18:14.143728 15542 solver.cpp:253]     Train net output #0: loss = 1.41564 (* 1 = 1.41564 loss)
I0523 18:18:14.143744 15542 sgd_solver.cpp:106] Iteration 15500, lr = 0.0035
I0523 18:18:23.179774 15542 solver.cpp:237] Iteration 15750, loss = 1.3788
I0523 18:18:23.179808 15542 solver.cpp:253]     Train net output #0: loss = 1.3788 (* 1 = 1.3788 loss)
I0523 18:18:23.179824 15542 sgd_solver.cpp:106] Iteration 15750, lr = 0.0035
I0523 18:18:32.211045 15542 solver.cpp:237] Iteration 16000, loss = 1.33554
I0523 18:18:32.211088 15542 solver.cpp:253]     Train net output #0: loss = 1.33554 (* 1 = 1.33554 loss)
I0523 18:18:32.211104 15542 sgd_solver.cpp:106] Iteration 16000, lr = 0.0035
I0523 18:18:41.244732 15542 solver.cpp:237] Iteration 16250, loss = 1.31207
I0523 18:18:41.244874 15542 solver.cpp:253]     Train net output #0: loss = 1.31207 (* 1 = 1.31207 loss)
I0523 18:18:41.244887 15542 sgd_solver.cpp:106] Iteration 16250, lr = 0.0035
I0523 18:18:50.276549 15542 solver.cpp:237] Iteration 16500, loss = 1.20235
I0523 18:18:50.276594 15542 solver.cpp:253]     Train net output #0: loss = 1.20235 (* 1 = 1.20235 loss)
I0523 18:18:50.276610 15542 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0523 18:19:21.586856 15542 solver.cpp:237] Iteration 16750, loss = 1.38686
I0523 18:19:21.587031 15542 solver.cpp:253]     Train net output #0: loss = 1.38686 (* 1 = 1.38686 loss)
I0523 18:19:21.587047 15542 sgd_solver.cpp:106] Iteration 16750, lr = 0.0035
I0523 18:19:30.623111 15542 solver.cpp:237] Iteration 17000, loss = 1.32542
I0523 18:19:30.623147 15542 solver.cpp:253]     Train net output #0: loss = 1.32542 (* 1 = 1.32542 loss)
I0523 18:19:30.623160 15542 sgd_solver.cpp:106] Iteration 17000, lr = 0.0035
I0523 18:19:39.659523 15542 solver.cpp:237] Iteration 17250, loss = 1.22072
I0523 18:19:39.659557 15542 solver.cpp:253]     Train net output #0: loss = 1.22072 (* 1 = 1.22072 loss)
I0523 18:19:39.659574 15542 sgd_solver.cpp:106] Iteration 17250, lr = 0.0035
I0523 18:19:48.659704 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_17500.caffemodel
I0523 18:19:48.722744 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_17500.solverstate
I0523 18:19:48.760463 15542 solver.cpp:237] Iteration 17500, loss = 1.24066
I0523 18:19:48.760505 15542 solver.cpp:253]     Train net output #0: loss = 1.24066 (* 1 = 1.24066 loss)
I0523 18:19:48.760522 15542 sgd_solver.cpp:106] Iteration 17500, lr = 0.0035
I0523 18:19:57.794968 15542 solver.cpp:237] Iteration 17750, loss = 1.17452
I0523 18:19:57.795117 15542 solver.cpp:253]     Train net output #0: loss = 1.17452 (* 1 = 1.17452 loss)
I0523 18:19:57.795130 15542 sgd_solver.cpp:106] Iteration 17750, lr = 0.0035
I0523 18:20:06.825920 15542 solver.cpp:237] Iteration 18000, loss = 1.18921
I0523 18:20:06.825963 15542 solver.cpp:253]     Train net output #0: loss = 1.18921 (* 1 = 1.18921 loss)
I0523 18:20:06.825978 15542 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0523 18:20:15.858153 15542 solver.cpp:237] Iteration 18250, loss = 1.25614
I0523 18:20:15.858189 15542 solver.cpp:253]     Train net output #0: loss = 1.25614 (* 1 = 1.25614 loss)
I0523 18:20:15.858203 15542 sgd_solver.cpp:106] Iteration 18250, lr = 0.0035
I0523 18:20:47.049144 15542 solver.cpp:237] Iteration 18500, loss = 0.93723
I0523 18:20:47.049314 15542 solver.cpp:253]     Train net output #0: loss = 0.93723 (* 1 = 0.93723 loss)
I0523 18:20:47.049329 15542 sgd_solver.cpp:106] Iteration 18500, lr = 0.0035
I0523 18:20:56.083613 15542 solver.cpp:237] Iteration 18750, loss = 1.19187
I0523 18:20:56.083655 15542 solver.cpp:253]     Train net output #0: loss = 1.19187 (* 1 = 1.19187 loss)
I0523 18:20:56.083673 15542 sgd_solver.cpp:106] Iteration 18750, lr = 0.0035
I0523 18:21:05.115625 15542 solver.cpp:237] Iteration 19000, loss = 1.50373
I0523 18:21:05.115661 15542 solver.cpp:253]     Train net output #0: loss = 1.50373 (* 1 = 1.50373 loss)
I0523 18:21:05.115677 15542 sgd_solver.cpp:106] Iteration 19000, lr = 0.0035
I0523 18:21:14.152459 15542 solver.cpp:237] Iteration 19250, loss = 1.30318
I0523 18:21:14.152494 15542 solver.cpp:253]     Train net output #0: loss = 1.30318 (* 1 = 1.30318 loss)
I0523 18:21:14.152508 15542 sgd_solver.cpp:106] Iteration 19250, lr = 0.0035
I0523 18:21:23.190318 15542 solver.cpp:237] Iteration 19500, loss = 1.26922
I0523 18:21:23.190476 15542 solver.cpp:253]     Train net output #0: loss = 1.26922 (* 1 = 1.26922 loss)
I0523 18:21:23.190490 15542 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0523 18:21:32.223208 15542 solver.cpp:237] Iteration 19750, loss = 1.07264
I0523 18:21:32.223242 15542 solver.cpp:253]     Train net output #0: loss = 1.07264 (* 1 = 1.07264 loss)
I0523 18:21:32.223260 15542 sgd_solver.cpp:106] Iteration 19750, lr = 0.0035
I0523 18:21:41.223023 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_20000.caffemodel
I0523 18:21:41.285773 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_20000.solverstate
I0523 18:21:41.312131 15542 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 18:22:49.458676 15542 solver.cpp:409]     Test net output #0: accuracy = 0.866535
I0523 18:22:49.458852 15542 solver.cpp:409]     Test net output #1: loss = 0.417141 (* 1 = 0.417141 loss)
I0523 18:23:11.661011 15542 solver.cpp:237] Iteration 20000, loss = 1.20705
I0523 18:23:11.661065 15542 solver.cpp:253]     Train net output #0: loss = 1.20705 (* 1 = 1.20705 loss)
I0523 18:23:11.661082 15542 sgd_solver.cpp:106] Iteration 20000, lr = 0.0035
I0523 18:23:20.699991 15542 solver.cpp:237] Iteration 20250, loss = 1.23223
I0523 18:23:20.700146 15542 solver.cpp:253]     Train net output #0: loss = 1.23223 (* 1 = 1.23223 loss)
I0523 18:23:20.700160 15542 sgd_solver.cpp:106] Iteration 20250, lr = 0.0035
I0523 18:23:29.759464 15542 solver.cpp:237] Iteration 20500, loss = 1.02247
I0523 18:23:29.759506 15542 solver.cpp:253]     Train net output #0: loss = 1.02247 (* 1 = 1.02247 loss)
I0523 18:23:29.759521 15542 sgd_solver.cpp:106] Iteration 20500, lr = 0.0035
I0523 18:23:38.814030 15542 solver.cpp:237] Iteration 20750, loss = 1.08714
I0523 18:23:38.814065 15542 solver.cpp:253]     Train net output #0: loss = 1.08714 (* 1 = 1.08714 loss)
I0523 18:23:38.814079 15542 sgd_solver.cpp:106] Iteration 20750, lr = 0.0035
I0523 18:23:47.860247 15542 solver.cpp:237] Iteration 21000, loss = 1.33348
I0523 18:23:47.860283 15542 solver.cpp:253]     Train net output #0: loss = 1.33348 (* 1 = 1.33348 loss)
I0523 18:23:47.860298 15542 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0523 18:23:56.910336 15542 solver.cpp:237] Iteration 21250, loss = 1.39007
I0523 18:23:56.910492 15542 solver.cpp:253]     Train net output #0: loss = 1.39007 (* 1 = 1.39007 loss)
I0523 18:23:56.910506 15542 sgd_solver.cpp:106] Iteration 21250, lr = 0.0035
I0523 18:24:05.977766 15542 solver.cpp:237] Iteration 21500, loss = 1.14028
I0523 18:24:05.977799 15542 solver.cpp:253]     Train net output #0: loss = 1.14028 (* 1 = 1.14028 loss)
I0523 18:24:05.977814 15542 sgd_solver.cpp:106] Iteration 21500, lr = 0.0035
I0523 18:24:37.185400 15542 solver.cpp:237] Iteration 21750, loss = 1.17683
I0523 18:24:37.185567 15542 solver.cpp:253]     Train net output #0: loss = 1.17683 (* 1 = 1.17683 loss)
I0523 18:24:37.185581 15542 sgd_solver.cpp:106] Iteration 21750, lr = 0.0035
I0523 18:24:46.243103 15542 solver.cpp:237] Iteration 22000, loss = 1.37307
I0523 18:24:46.243142 15542 solver.cpp:253]     Train net output #0: loss = 1.37307 (* 1 = 1.37307 loss)
I0523 18:24:46.243160 15542 sgd_solver.cpp:106] Iteration 22000, lr = 0.0035
I0523 18:24:55.296922 15542 solver.cpp:237] Iteration 22250, loss = 1.47281
I0523 18:24:55.296957 15542 solver.cpp:253]     Train net output #0: loss = 1.47281 (* 1 = 1.47281 loss)
I0523 18:24:55.296975 15542 sgd_solver.cpp:106] Iteration 22250, lr = 0.0035
I0523 18:25:04.307479 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_22500.caffemodel
I0523 18:25:04.373440 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_22500.solverstate
I0523 18:25:04.413827 15542 solver.cpp:237] Iteration 22500, loss = 1.55215
I0523 18:25:04.413877 15542 solver.cpp:253]     Train net output #0: loss = 1.55215 (* 1 = 1.55215 loss)
I0523 18:25:04.413894 15542 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0523 18:25:13.476523 15542 solver.cpp:237] Iteration 22750, loss = 1.0781
I0523 18:25:13.476681 15542 solver.cpp:253]     Train net output #0: loss = 1.0781 (* 1 = 1.0781 loss)
I0523 18:25:13.476694 15542 sgd_solver.cpp:106] Iteration 22750, lr = 0.0035
I0523 18:25:22.534334 15542 solver.cpp:237] Iteration 23000, loss = 1.30809
I0523 18:25:22.534368 15542 solver.cpp:253]     Train net output #0: loss = 1.30809 (* 1 = 1.30809 loss)
I0523 18:25:22.534384 15542 sgd_solver.cpp:106] Iteration 23000, lr = 0.0035
I0523 18:25:31.598081 15542 solver.cpp:237] Iteration 23250, loss = 0.98098
I0523 18:25:31.598134 15542 solver.cpp:253]     Train net output #0: loss = 0.98098 (* 1 = 0.98098 loss)
I0523 18:25:31.598148 15542 sgd_solver.cpp:106] Iteration 23250, lr = 0.0035
I0523 18:26:02.863998 15542 solver.cpp:237] Iteration 23500, loss = 1.43676
I0523 18:26:02.864179 15542 solver.cpp:253]     Train net output #0: loss = 1.43676 (* 1 = 1.43676 loss)
I0523 18:26:02.864197 15542 sgd_solver.cpp:106] Iteration 23500, lr = 0.0035
I0523 18:26:11.924564 15542 solver.cpp:237] Iteration 23750, loss = 1.46943
I0523 18:26:11.924599 15542 solver.cpp:253]     Train net output #0: loss = 1.46943 (* 1 = 1.46943 loss)
I0523 18:26:11.924614 15542 sgd_solver.cpp:106] Iteration 23750, lr = 0.0035
I0523 18:26:20.991120 15542 solver.cpp:237] Iteration 24000, loss = 1.40637
I0523 18:26:20.991166 15542 solver.cpp:253]     Train net output #0: loss = 1.40637 (* 1 = 1.40637 loss)
I0523 18:26:20.991180 15542 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0523 18:26:30.045177 15542 solver.cpp:237] Iteration 24250, loss = 1.18759
I0523 18:26:30.045213 15542 solver.cpp:253]     Train net output #0: loss = 1.18759 (* 1 = 1.18759 loss)
I0523 18:26:30.045229 15542 sgd_solver.cpp:106] Iteration 24250, lr = 0.0035
I0523 18:26:39.113523 15542 solver.cpp:237] Iteration 24500, loss = 1.19384
I0523 18:26:39.113670 15542 solver.cpp:253]     Train net output #0: loss = 1.19384 (* 1 = 1.19384 loss)
I0523 18:26:39.113683 15542 sgd_solver.cpp:106] Iteration 24500, lr = 0.0035
I0523 18:26:48.172792 15542 solver.cpp:237] Iteration 24750, loss = 1.44886
I0523 18:26:48.172834 15542 solver.cpp:253]     Train net output #0: loss = 1.44886 (* 1 = 1.44886 loss)
I0523 18:26:48.172852 15542 sgd_solver.cpp:106] Iteration 24750, lr = 0.0035
I0523 18:26:57.179224 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_25000.caffemodel
I0523 18:26:57.245939 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_25000.solverstate
I0523 18:26:57.274332 15542 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 18:27:44.607226 15542 solver.cpp:409]     Test net output #0: accuracy = 0.8728
I0523 18:27:44.607388 15542 solver.cpp:409]     Test net output #1: loss = 0.397066 (* 1 = 0.397066 loss)
I0523 18:28:05.485332 15542 solver.cpp:237] Iteration 25000, loss = 1.22652
I0523 18:28:05.485383 15542 solver.cpp:253]     Train net output #0: loss = 1.22652 (* 1 = 1.22652 loss)
I0523 18:28:05.485397 15542 sgd_solver.cpp:106] Iteration 25000, lr = 0.0035
I0523 18:28:14.506875 15542 solver.cpp:237] Iteration 25250, loss = 1.009
I0523 18:28:14.506909 15542 solver.cpp:253]     Train net output #0: loss = 1.009 (* 1 = 1.009 loss)
I0523 18:28:14.506927 15542 sgd_solver.cpp:106] Iteration 25250, lr = 0.0035
I0523 18:28:23.520594 15542 solver.cpp:237] Iteration 25500, loss = 1.2746
I0523 18:28:23.520756 15542 solver.cpp:253]     Train net output #0: loss = 1.2746 (* 1 = 1.2746 loss)
I0523 18:28:23.520771 15542 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0523 18:28:32.538486 15542 solver.cpp:237] Iteration 25750, loss = 1.23816
I0523 18:28:32.538525 15542 solver.cpp:253]     Train net output #0: loss = 1.23816 (* 1 = 1.23816 loss)
I0523 18:28:32.538547 15542 sgd_solver.cpp:106] Iteration 25750, lr = 0.0035
I0523 18:28:41.555933 15542 solver.cpp:237] Iteration 26000, loss = 1.10582
I0523 18:28:41.555968 15542 solver.cpp:253]     Train net output #0: loss = 1.10582 (* 1 = 1.10582 loss)
I0523 18:28:41.555981 15542 sgd_solver.cpp:106] Iteration 26000, lr = 0.0035
I0523 18:28:50.572414 15542 solver.cpp:237] Iteration 26250, loss = 1.07741
I0523 18:28:50.572458 15542 solver.cpp:253]     Train net output #0: loss = 1.07741 (* 1 = 1.07741 loss)
I0523 18:28:50.572474 15542 sgd_solver.cpp:106] Iteration 26250, lr = 0.0035
I0523 18:28:59.596046 15542 solver.cpp:237] Iteration 26500, loss = 1.09183
I0523 18:28:59.596213 15542 solver.cpp:253]     Train net output #0: loss = 1.09183 (* 1 = 1.09183 loss)
I0523 18:28:59.596227 15542 sgd_solver.cpp:106] Iteration 26500, lr = 0.0035
I0523 18:29:29.490452 15542 solver.cpp:237] Iteration 26750, loss = 1.32719
I0523 18:29:29.490501 15542 solver.cpp:253]     Train net output #0: loss = 1.32719 (* 1 = 1.32719 loss)
I0523 18:29:29.490516 15542 sgd_solver.cpp:106] Iteration 26750, lr = 0.0035
I0523 18:29:38.517032 15542 solver.cpp:237] Iteration 27000, loss = 0.929814
I0523 18:29:38.517201 15542 solver.cpp:253]     Train net output #0: loss = 0.929814 (* 1 = 0.929814 loss)
I0523 18:29:38.517215 15542 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0523 18:29:47.529316 15542 solver.cpp:237] Iteration 27250, loss = 1.8573
I0523 18:29:47.529361 15542 solver.cpp:253]     Train net output #0: loss = 1.8573 (* 1 = 1.8573 loss)
I0523 18:29:47.529378 15542 sgd_solver.cpp:106] Iteration 27250, lr = 0.0035
I0523 18:29:56.515707 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_27500.caffemodel
I0523 18:29:56.578649 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_27500.solverstate
I0523 18:29:56.616235 15542 solver.cpp:237] Iteration 27500, loss = 0.829247
I0523 18:29:56.616281 15542 solver.cpp:253]     Train net output #0: loss = 0.829247 (* 1 = 0.829247 loss)
I0523 18:29:56.616294 15542 sgd_solver.cpp:106] Iteration 27500, lr = 0.0035
I0523 18:30:05.641913 15542 solver.cpp:237] Iteration 27750, loss = 1.22208
I0523 18:30:05.641955 15542 solver.cpp:253]     Train net output #0: loss = 1.22208 (* 1 = 1.22208 loss)
I0523 18:30:05.641975 15542 sgd_solver.cpp:106] Iteration 27750, lr = 0.0035
I0523 18:30:14.664041 15542 solver.cpp:237] Iteration 28000, loss = 1.2789
I0523 18:30:14.664201 15542 solver.cpp:253]     Train net output #0: loss = 1.2789 (* 1 = 1.2789 loss)
I0523 18:30:14.664216 15542 sgd_solver.cpp:106] Iteration 28000, lr = 0.0035
I0523 18:30:23.684909 15542 solver.cpp:237] Iteration 28250, loss = 1.17236
I0523 18:30:23.684943 15542 solver.cpp:253]     Train net output #0: loss = 1.17236 (* 1 = 1.17236 loss)
I0523 18:30:23.684958 15542 sgd_solver.cpp:106] Iteration 28250, lr = 0.0035
I0523 18:30:53.624646 15542 solver.cpp:237] Iteration 28500, loss = 1.0247
I0523 18:30:53.624817 15542 solver.cpp:253]     Train net output #0: loss = 1.0247 (* 1 = 1.0247 loss)
I0523 18:30:53.624833 15542 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0523 18:31:02.630570 15542 solver.cpp:237] Iteration 28750, loss = 1.10943
I0523 18:31:02.630617 15542 solver.cpp:253]     Train net output #0: loss = 1.10943 (* 1 = 1.10943 loss)
I0523 18:31:02.630633 15542 sgd_solver.cpp:106] Iteration 28750, lr = 0.0035
I0523 18:31:11.648262 15542 solver.cpp:237] Iteration 29000, loss = 1.40917
I0523 18:31:11.648298 15542 solver.cpp:253]     Train net output #0: loss = 1.40917 (* 1 = 1.40917 loss)
I0523 18:31:11.648313 15542 sgd_solver.cpp:106] Iteration 29000, lr = 0.0035
I0523 18:31:20.664753 15542 solver.cpp:237] Iteration 29250, loss = 1.29212
I0523 18:31:20.664801 15542 solver.cpp:253]     Train net output #0: loss = 1.29212 (* 1 = 1.29212 loss)
I0523 18:31:20.664818 15542 sgd_solver.cpp:106] Iteration 29250, lr = 0.0035
I0523 18:31:29.685506 15542 solver.cpp:237] Iteration 29500, loss = 1.19879
I0523 18:31:29.685655 15542 solver.cpp:253]     Train net output #0: loss = 1.19879 (* 1 = 1.19879 loss)
I0523 18:31:29.685669 15542 sgd_solver.cpp:106] Iteration 29500, lr = 0.0035
I0523 18:31:38.700739 15542 solver.cpp:237] Iteration 29750, loss = 1.58143
I0523 18:31:38.700773 15542 solver.cpp:253]     Train net output #0: loss = 1.58143 (* 1 = 1.58143 loss)
I0523 18:31:38.700788 15542 sgd_solver.cpp:106] Iteration 29750, lr = 0.0035
I0523 18:31:47.689193 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_30000.caffemodel
I0523 18:31:47.752414 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_30000.solverstate
I0523 18:31:47.779105 15542 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 18:32:55.968668 15542 solver.cpp:409]     Test net output #0: accuracy = 0.871713
I0523 18:32:55.968847 15542 solver.cpp:409]     Test net output #1: loss = 0.40101 (* 1 = 0.40101 loss)
I0523 18:33:16.931493 15542 solver.cpp:237] Iteration 30000, loss = 1.3121
I0523 18:33:16.931545 15542 solver.cpp:253]     Train net output #0: loss = 1.3121 (* 1 = 1.3121 loss)
I0523 18:33:16.931562 15542 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0523 18:33:26.019225 15542 solver.cpp:237] Iteration 30250, loss = 1.11458
I0523 18:33:26.019392 15542 solver.cpp:253]     Train net output #0: loss = 1.11458 (* 1 = 1.11458 loss)
I0523 18:33:26.019404 15542 sgd_solver.cpp:106] Iteration 30250, lr = 0.0035
I0523 18:33:35.122230 15542 solver.cpp:237] Iteration 30500, loss = 1.30825
I0523 18:33:35.122264 15542 solver.cpp:253]     Train net output #0: loss = 1.30825 (* 1 = 1.30825 loss)
I0523 18:33:35.122279 15542 sgd_solver.cpp:106] Iteration 30500, lr = 0.0035
I0523 18:33:44.219035 15542 solver.cpp:237] Iteration 30750, loss = 1.44137
I0523 18:33:44.219071 15542 solver.cpp:253]     Train net output #0: loss = 1.44137 (* 1 = 1.44137 loss)
I0523 18:33:44.219085 15542 sgd_solver.cpp:106] Iteration 30750, lr = 0.0035
I0523 18:33:53.311588 15542 solver.cpp:237] Iteration 31000, loss = 1.292
I0523 18:33:53.311633 15542 solver.cpp:253]     Train net output #0: loss = 1.292 (* 1 = 1.292 loss)
I0523 18:33:53.311650 15542 sgd_solver.cpp:106] Iteration 31000, lr = 0.0035
I0523 18:34:02.409432 15542 solver.cpp:237] Iteration 31250, loss = 1.44784
I0523 18:34:02.409582 15542 solver.cpp:253]     Train net output #0: loss = 1.44784 (* 1 = 1.44784 loss)
I0523 18:34:02.409596 15542 sgd_solver.cpp:106] Iteration 31250, lr = 0.0035
I0523 18:34:11.515527 15542 solver.cpp:237] Iteration 31500, loss = 1.17763
I0523 18:34:11.515561 15542 solver.cpp:253]     Train net output #0: loss = 1.17763 (* 1 = 1.17763 loss)
I0523 18:34:11.515575 15542 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0523 18:34:41.543054 15542 solver.cpp:237] Iteration 31750, loss = 1.23949
I0523 18:34:41.543223 15542 solver.cpp:253]     Train net output #0: loss = 1.23949 (* 1 = 1.23949 loss)
I0523 18:34:41.543237 15542 sgd_solver.cpp:106] Iteration 31750, lr = 0.0035
I0523 18:34:50.641933 15542 solver.cpp:237] Iteration 32000, loss = 1.09652
I0523 18:34:50.641968 15542 solver.cpp:253]     Train net output #0: loss = 1.09652 (* 1 = 1.09652 loss)
I0523 18:34:50.641984 15542 sgd_solver.cpp:106] Iteration 32000, lr = 0.0035
I0523 18:34:59.730504 15542 solver.cpp:237] Iteration 32250, loss = 1.06724
I0523 18:34:59.730540 15542 solver.cpp:253]     Train net output #0: loss = 1.06724 (* 1 = 1.06724 loss)
I0523 18:34:59.730553 15542 sgd_solver.cpp:106] Iteration 32250, lr = 0.0035
I0523 18:35:08.796793 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_32500.caffemodel
I0523 18:35:08.859522 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_32500.solverstate
I0523 18:35:08.897058 15542 solver.cpp:237] Iteration 32500, loss = 1.26053
I0523 18:35:08.897097 15542 solver.cpp:253]     Train net output #0: loss = 1.26053 (* 1 = 1.26053 loss)
I0523 18:35:08.897121 15542 sgd_solver.cpp:106] Iteration 32500, lr = 0.0035
I0523 18:35:17.990836 15542 solver.cpp:237] Iteration 32750, loss = 1.31385
I0523 18:35:17.991006 15542 solver.cpp:253]     Train net output #0: loss = 1.31385 (* 1 = 1.31385 loss)
I0523 18:35:17.991021 15542 sgd_solver.cpp:106] Iteration 32750, lr = 0.0035
I0523 18:35:27.098553 15542 solver.cpp:237] Iteration 33000, loss = 1.3703
I0523 18:35:27.098588 15542 solver.cpp:253]     Train net output #0: loss = 1.3703 (* 1 = 1.3703 loss)
I0523 18:35:27.098606 15542 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0523 18:35:36.201886 15542 solver.cpp:237] Iteration 33250, loss = 1.32791
I0523 18:35:36.201932 15542 solver.cpp:253]     Train net output #0: loss = 1.32791 (* 1 = 1.32791 loss)
I0523 18:35:36.201949 15542 sgd_solver.cpp:106] Iteration 33250, lr = 0.0035
I0523 18:36:06.222993 15542 solver.cpp:237] Iteration 33500, loss = 1.16114
I0523 18:36:06.223165 15542 solver.cpp:253]     Train net output #0: loss = 1.16114 (* 1 = 1.16114 loss)
I0523 18:36:06.223181 15542 sgd_solver.cpp:106] Iteration 33500, lr = 0.0035
I0523 18:36:15.328727 15542 solver.cpp:237] Iteration 33750, loss = 1.14593
I0523 18:36:15.328763 15542 solver.cpp:253]     Train net output #0: loss = 1.14593 (* 1 = 1.14593 loss)
I0523 18:36:15.328776 15542 sgd_solver.cpp:106] Iteration 33750, lr = 0.0035
I0523 18:36:24.428547 15542 solver.cpp:237] Iteration 34000, loss = 1.37573
I0523 18:36:24.428594 15542 solver.cpp:253]     Train net output #0: loss = 1.37573 (* 1 = 1.37573 loss)
I0523 18:36:24.428608 15542 sgd_solver.cpp:106] Iteration 34000, lr = 0.0035
I0523 18:36:33.539765 15542 solver.cpp:237] Iteration 34250, loss = 0.926439
I0523 18:36:33.539801 15542 solver.cpp:253]     Train net output #0: loss = 0.926439 (* 1 = 0.926439 loss)
I0523 18:36:33.539814 15542 sgd_solver.cpp:106] Iteration 34250, lr = 0.0035
I0523 18:36:42.639010 15542 solver.cpp:237] Iteration 34500, loss = 1.16942
I0523 18:36:42.639160 15542 solver.cpp:253]     Train net output #0: loss = 1.16942 (* 1 = 1.16942 loss)
I0523 18:36:42.639176 15542 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0523 18:36:51.745702 15542 solver.cpp:237] Iteration 34750, loss = 0.998782
I0523 18:36:51.745745 15542 solver.cpp:253]     Train net output #0: loss = 0.998782 (* 1 = 0.998782 loss)
I0523 18:36:51.745764 15542 sgd_solver.cpp:106] Iteration 34750, lr = 0.0035
I0523 18:37:00.822511 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_35000.caffemodel
I0523 18:37:00.886435 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_35000.solverstate
I0523 18:37:00.912956 15542 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 18:37:47.923727 15542 solver.cpp:409]     Test net output #0: accuracy = 0.871627
I0523 18:37:47.923895 15542 solver.cpp:409]     Test net output #1: loss = 0.425158 (* 1 = 0.425158 loss)
I0523 18:38:08.835229 15542 solver.cpp:237] Iteration 35000, loss = 1.4237
I0523 18:38:08.835283 15542 solver.cpp:253]     Train net output #0: loss = 1.4237 (* 1 = 1.4237 loss)
I0523 18:38:08.835297 15542 sgd_solver.cpp:106] Iteration 35000, lr = 0.0035
I0523 18:38:17.905798 15542 solver.cpp:237] Iteration 35250, loss = 1.36699
I0523 18:38:17.905834 15542 solver.cpp:253]     Train net output #0: loss = 1.36699 (* 1 = 1.36699 loss)
I0523 18:38:17.905851 15542 sgd_solver.cpp:106] Iteration 35250, lr = 0.0035
I0523 18:38:26.982246 15542 solver.cpp:237] Iteration 35500, loss = 1.2759
I0523 18:38:26.982409 15542 solver.cpp:253]     Train net output #0: loss = 1.2759 (* 1 = 1.2759 loss)
I0523 18:38:26.982421 15542 sgd_solver.cpp:106] Iteration 35500, lr = 0.0035
I0523 18:38:36.056531 15542 solver.cpp:237] Iteration 35750, loss = 1.20893
I0523 18:38:36.056567 15542 solver.cpp:253]     Train net output #0: loss = 1.20893 (* 1 = 1.20893 loss)
I0523 18:38:36.056583 15542 sgd_solver.cpp:106] Iteration 35750, lr = 0.0035
I0523 18:38:45.130142 15542 solver.cpp:237] Iteration 36000, loss = 1.12703
I0523 18:38:45.130177 15542 solver.cpp:253]     Train net output #0: loss = 1.12703 (* 1 = 1.12703 loss)
I0523 18:38:45.130192 15542 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0523 18:38:54.212370 15542 solver.cpp:237] Iteration 36250, loss = 1.20011
I0523 18:38:54.212407 15542 solver.cpp:253]     Train net output #0: loss = 1.20011 (* 1 = 1.20011 loss)
I0523 18:38:54.212430 15542 sgd_solver.cpp:106] Iteration 36250, lr = 0.0035
I0523 18:39:03.286695 15542 solver.cpp:237] Iteration 36500, loss = 1.1695
I0523 18:39:03.286866 15542 solver.cpp:253]     Train net output #0: loss = 1.1695 (* 1 = 1.1695 loss)
I0523 18:39:03.286880 15542 sgd_solver.cpp:106] Iteration 36500, lr = 0.0035
I0523 18:39:33.290259 15542 solver.cpp:237] Iteration 36750, loss = 1.07612
I0523 18:39:33.290433 15542 solver.cpp:253]     Train net output #0: loss = 1.07612 (* 1 = 1.07612 loss)
I0523 18:39:33.290449 15542 sgd_solver.cpp:106] Iteration 36750, lr = 0.0035
I0523 18:39:42.370301 15542 solver.cpp:237] Iteration 37000, loss = 1.01397
I0523 18:39:42.370349 15542 solver.cpp:253]     Train net output #0: loss = 1.01397 (* 1 = 1.01397 loss)
I0523 18:39:42.370363 15542 sgd_solver.cpp:106] Iteration 37000, lr = 0.0035
I0523 18:39:51.448097 15542 solver.cpp:237] Iteration 37250, loss = 1.58765
I0523 18:39:51.448133 15542 solver.cpp:253]     Train net output #0: loss = 1.58765 (* 1 = 1.58765 loss)
I0523 18:39:51.448148 15542 sgd_solver.cpp:106] Iteration 37250, lr = 0.0035
I0523 18:40:00.486577 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_37500.caffemodel
I0523 18:40:00.552007 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_37500.solverstate
I0523 18:40:00.591576 15542 solver.cpp:237] Iteration 37500, loss = 1.39417
I0523 18:40:00.591625 15542 solver.cpp:253]     Train net output #0: loss = 1.39417 (* 1 = 1.39417 loss)
I0523 18:40:00.591640 15542 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0523 18:40:09.665640 15542 solver.cpp:237] Iteration 37750, loss = 1.31514
I0523 18:40:09.665803 15542 solver.cpp:253]     Train net output #0: loss = 1.31514 (* 1 = 1.31514 loss)
I0523 18:40:09.665817 15542 sgd_solver.cpp:106] Iteration 37750, lr = 0.0035
I0523 18:40:18.737416 15542 solver.cpp:237] Iteration 38000, loss = 1.24164
I0523 18:40:18.737450 15542 solver.cpp:253]     Train net output #0: loss = 1.24164 (* 1 = 1.24164 loss)
I0523 18:40:18.737469 15542 sgd_solver.cpp:106] Iteration 38000, lr = 0.0035
I0523 18:40:27.812178 15542 solver.cpp:237] Iteration 38250, loss = 1.2636
I0523 18:40:27.812214 15542 solver.cpp:253]     Train net output #0: loss = 1.2636 (* 1 = 1.2636 loss)
I0523 18:40:27.812230 15542 sgd_solver.cpp:106] Iteration 38250, lr = 0.0035
I0523 18:40:57.800844 15542 solver.cpp:237] Iteration 38500, loss = 0.970029
I0523 18:40:57.801020 15542 solver.cpp:253]     Train net output #0: loss = 0.970029 (* 1 = 0.970029 loss)
I0523 18:40:57.801034 15542 sgd_solver.cpp:106] Iteration 38500, lr = 0.0035
I0523 18:41:06.886397 15542 solver.cpp:237] Iteration 38750, loss = 1.35149
I0523 18:41:06.886432 15542 solver.cpp:253]     Train net output #0: loss = 1.35149 (* 1 = 1.35149 loss)
I0523 18:41:06.886446 15542 sgd_solver.cpp:106] Iteration 38750, lr = 0.0035
I0523 18:41:15.961987 15542 solver.cpp:237] Iteration 39000, loss = 1.14147
I0523 18:41:15.962021 15542 solver.cpp:253]     Train net output #0: loss = 1.14147 (* 1 = 1.14147 loss)
I0523 18:41:15.962038 15542 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0523 18:41:25.037046 15542 solver.cpp:237] Iteration 39250, loss = 1.28676
I0523 18:41:25.037096 15542 solver.cpp:253]     Train net output #0: loss = 1.28676 (* 1 = 1.28676 loss)
I0523 18:41:25.037109 15542 sgd_solver.cpp:106] Iteration 39250, lr = 0.0035
I0523 18:41:34.111469 15542 solver.cpp:237] Iteration 39500, loss = 1.05877
I0523 18:41:34.111634 15542 solver.cpp:253]     Train net output #0: loss = 1.05877 (* 1 = 1.05877 loss)
I0523 18:41:34.111649 15542 sgd_solver.cpp:106] Iteration 39500, lr = 0.0035
I0523 18:41:43.181643 15542 solver.cpp:237] Iteration 39750, loss = 0.995475
I0523 18:41:43.181679 15542 solver.cpp:253]     Train net output #0: loss = 0.995475 (* 1 = 0.995475 loss)
I0523 18:41:43.181696 15542 sgd_solver.cpp:106] Iteration 39750, lr = 0.0035
I0523 18:41:52.219058 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_40000.caffemodel
I0523 18:41:52.281793 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_40000.solverstate
I0523 18:41:52.308359 15542 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 18:43:00.535650 15542 solver.cpp:409]     Test net output #0: accuracy = 0.878806
I0523 18:43:00.535833 15542 solver.cpp:409]     Test net output #1: loss = 0.372514 (* 1 = 0.372514 loss)
I0523 18:43:21.454514 15542 solver.cpp:237] Iteration 40000, loss = 1.27292
I0523 18:43:21.454565 15542 solver.cpp:253]     Train net output #0: loss = 1.27292 (* 1 = 1.27292 loss)
I0523 18:43:21.454579 15542 sgd_solver.cpp:106] Iteration 40000, lr = 0.0035
I0523 18:43:30.573663 15542 solver.cpp:237] Iteration 40250, loss = 1.21685
I0523 18:43:30.573833 15542 solver.cpp:253]     Train net output #0: loss = 1.21685 (* 1 = 1.21685 loss)
I0523 18:43:30.573848 15542 sgd_solver.cpp:106] Iteration 40250, lr = 0.0035
I0523 18:43:39.679918 15542 solver.cpp:237] Iteration 40500, loss = 1.27332
I0523 18:43:39.679951 15542 solver.cpp:253]     Train net output #0: loss = 1.27332 (* 1 = 1.27332 loss)
I0523 18:43:39.679965 15542 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0523 18:43:48.795822 15542 solver.cpp:237] Iteration 40750, loss = 1.12204
I0523 18:43:48.795858 15542 solver.cpp:253]     Train net output #0: loss = 1.12204 (* 1 = 1.12204 loss)
I0523 18:43:48.795876 15542 sgd_solver.cpp:106] Iteration 40750, lr = 0.0035
I0523 18:43:57.907891 15542 solver.cpp:237] Iteration 41000, loss = 1.11561
I0523 18:43:57.907938 15542 solver.cpp:253]     Train net output #0: loss = 1.11561 (* 1 = 1.11561 loss)
I0523 18:43:57.907953 15542 sgd_solver.cpp:106] Iteration 41000, lr = 0.0035
I0523 18:44:07.030351 15542 solver.cpp:237] Iteration 41250, loss = 1.46443
I0523 18:44:07.030501 15542 solver.cpp:253]     Train net output #0: loss = 1.46443 (* 1 = 1.46443 loss)
I0523 18:44:07.030514 15542 sgd_solver.cpp:106] Iteration 41250, lr = 0.0035
I0523 18:44:16.146813 15542 solver.cpp:237] Iteration 41500, loss = 1.0064
I0523 18:44:16.146854 15542 solver.cpp:253]     Train net output #0: loss = 1.0064 (* 1 = 1.0064 loss)
I0523 18:44:16.146872 15542 sgd_solver.cpp:106] Iteration 41500, lr = 0.0035
I0523 18:44:46.165773 15542 solver.cpp:237] Iteration 41750, loss = 1.01636
I0523 18:44:46.165942 15542 solver.cpp:253]     Train net output #0: loss = 1.01636 (* 1 = 1.01636 loss)
I0523 18:44:46.165956 15542 sgd_solver.cpp:106] Iteration 41750, lr = 0.0035
I0523 18:44:55.286314 15542 solver.cpp:237] Iteration 42000, loss = 1.13103
I0523 18:44:55.286347 15542 solver.cpp:253]     Train net output #0: loss = 1.13103 (* 1 = 1.13103 loss)
I0523 18:44:55.286365 15542 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0523 18:45:04.402499 15542 solver.cpp:237] Iteration 42250, loss = 1.09755
I0523 18:45:04.402535 15542 solver.cpp:253]     Train net output #0: loss = 1.09755 (* 1 = 1.09755 loss)
I0523 18:45:04.402549 15542 sgd_solver.cpp:106] Iteration 42250, lr = 0.0035
I0523 18:45:13.489591 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_42500.caffemodel
I0523 18:45:13.552830 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_42500.solverstate
I0523 18:45:13.590584 15542 solver.cpp:237] Iteration 42500, loss = 1.25133
I0523 18:45:13.590627 15542 solver.cpp:253]     Train net output #0: loss = 1.25133 (* 1 = 1.25133 loss)
I0523 18:45:13.590641 15542 sgd_solver.cpp:106] Iteration 42500, lr = 0.0035
I0523 18:45:22.713732 15542 solver.cpp:237] Iteration 42750, loss = 0.994024
I0523 18:45:22.713899 15542 solver.cpp:253]     Train net output #0: loss = 0.994024 (* 1 = 0.994024 loss)
I0523 18:45:22.713915 15542 sgd_solver.cpp:106] Iteration 42750, lr = 0.0035
I0523 18:45:31.831976 15542 solver.cpp:237] Iteration 43000, loss = 1.13547
I0523 18:45:31.832017 15542 solver.cpp:253]     Train net output #0: loss = 1.13547 (* 1 = 1.13547 loss)
I0523 18:45:31.832037 15542 sgd_solver.cpp:106] Iteration 43000, lr = 0.0035
I0523 18:45:40.960126 15542 solver.cpp:237] Iteration 43250, loss = 0.89805
I0523 18:45:40.960162 15542 solver.cpp:253]     Train net output #0: loss = 0.89805 (* 1 = 0.89805 loss)
I0523 18:45:40.960177 15542 sgd_solver.cpp:106] Iteration 43250, lr = 0.0035
I0523 18:46:10.974267 15542 solver.cpp:237] Iteration 43500, loss = 0.962007
I0523 18:46:10.974445 15542 solver.cpp:253]     Train net output #0: loss = 0.962007 (* 1 = 0.962007 loss)
I0523 18:46:10.974462 15542 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0523 18:46:20.084539 15542 solver.cpp:237] Iteration 43750, loss = 1.34272
I0523 18:46:20.084585 15542 solver.cpp:253]     Train net output #0: loss = 1.34272 (* 1 = 1.34272 loss)
I0523 18:46:20.084599 15542 sgd_solver.cpp:106] Iteration 43750, lr = 0.0035
I0523 18:46:29.193790 15542 solver.cpp:237] Iteration 44000, loss = 1.37874
I0523 18:46:29.193826 15542 solver.cpp:253]     Train net output #0: loss = 1.37874 (* 1 = 1.37874 loss)
I0523 18:46:29.193842 15542 sgd_solver.cpp:106] Iteration 44000, lr = 0.0035
I0523 18:46:38.312268 15542 solver.cpp:237] Iteration 44250, loss = 1.306
I0523 18:46:38.312302 15542 solver.cpp:253]     Train net output #0: loss = 1.306 (* 1 = 1.306 loss)
I0523 18:46:38.312319 15542 sgd_solver.cpp:106] Iteration 44250, lr = 0.0035
I0523 18:46:47.440336 15542 solver.cpp:237] Iteration 44500, loss = 0.998035
I0523 18:46:47.440500 15542 solver.cpp:253]     Train net output #0: loss = 0.998035 (* 1 = 0.998035 loss)
I0523 18:46:47.440515 15542 sgd_solver.cpp:106] Iteration 44500, lr = 0.0035
I0523 18:46:56.552189 15542 solver.cpp:237] Iteration 44750, loss = 1.10055
I0523 18:46:56.552223 15542 solver.cpp:253]     Train net output #0: loss = 1.10055 (* 1 = 1.10055 loss)
I0523 18:46:56.552242 15542 sgd_solver.cpp:106] Iteration 44750, lr = 0.0035
I0523 18:47:05.634099 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_45000.caffemodel
I0523 18:47:05.697926 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_45000.solverstate
I0523 18:47:05.724385 15542 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 18:47:53.036523 15542 solver.cpp:409]     Test net output #0: accuracy = 0.883441
I0523 18:47:53.036707 15542 solver.cpp:409]     Test net output #1: loss = 0.395233 (* 1 = 0.395233 loss)
I0523 18:48:13.935230 15542 solver.cpp:237] Iteration 45000, loss = 1.03491
I0523 18:48:13.935282 15542 solver.cpp:253]     Train net output #0: loss = 1.03491 (* 1 = 1.03491 loss)
I0523 18:48:13.935297 15542 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0523 18:48:22.972486 15542 solver.cpp:237] Iteration 45250, loss = 1.2672
I0523 18:48:22.972522 15542 solver.cpp:253]     Train net output #0: loss = 1.2672 (* 1 = 1.2672 loss)
I0523 18:48:22.972537 15542 sgd_solver.cpp:106] Iteration 45250, lr = 0.0035
I0523 18:48:32.008775 15542 solver.cpp:237] Iteration 45500, loss = 1.14058
I0523 18:48:32.008942 15542 solver.cpp:253]     Train net output #0: loss = 1.14058 (* 1 = 1.14058 loss)
I0523 18:48:32.008956 15542 sgd_solver.cpp:106] Iteration 45500, lr = 0.0035
I0523 18:48:41.039865 15542 solver.cpp:237] Iteration 45750, loss = 1.00934
I0523 18:48:41.039899 15542 solver.cpp:253]     Train net output #0: loss = 1.00934 (* 1 = 1.00934 loss)
I0523 18:48:41.039917 15542 sgd_solver.cpp:106] Iteration 45750, lr = 0.0035
I0523 18:48:50.075613 15542 solver.cpp:237] Iteration 46000, loss = 1.2832
I0523 18:48:50.075661 15542 solver.cpp:253]     Train net output #0: loss = 1.2832 (* 1 = 1.2832 loss)
I0523 18:48:50.075676 15542 sgd_solver.cpp:106] Iteration 46000, lr = 0.0035
I0523 18:48:59.106488 15542 solver.cpp:237] Iteration 46250, loss = 1.17002
I0523 18:48:59.106524 15542 solver.cpp:253]     Train net output #0: loss = 1.17002 (* 1 = 1.17002 loss)
I0523 18:48:59.106541 15542 sgd_solver.cpp:106] Iteration 46250, lr = 0.0035
I0523 18:49:08.137449 15542 solver.cpp:237] Iteration 46500, loss = 1.11244
I0523 18:49:08.137614 15542 solver.cpp:253]     Train net output #0: loss = 1.11244 (* 1 = 1.11244 loss)
I0523 18:49:08.137627 15542 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0523 18:49:38.105298 15542 solver.cpp:237] Iteration 46750, loss = 1.23042
I0523 18:49:38.105348 15542 solver.cpp:253]     Train net output #0: loss = 1.23042 (* 1 = 1.23042 loss)
I0523 18:49:38.105365 15542 sgd_solver.cpp:106] Iteration 46750, lr = 0.0035
I0523 18:49:47.144156 15542 solver.cpp:237] Iteration 47000, loss = 1.10144
I0523 18:49:47.144325 15542 solver.cpp:253]     Train net output #0: loss = 1.10144 (* 1 = 1.10144 loss)
I0523 18:49:47.144338 15542 sgd_solver.cpp:106] Iteration 47000, lr = 0.0035
I0523 18:49:56.176928 15542 solver.cpp:237] Iteration 47250, loss = 1.31014
I0523 18:49:56.176961 15542 solver.cpp:253]     Train net output #0: loss = 1.31014 (* 1 = 1.31014 loss)
I0523 18:49:56.176980 15542 sgd_solver.cpp:106] Iteration 47250, lr = 0.0035
I0523 18:50:05.178858 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_47500.caffemodel
I0523 18:50:05.245615 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_47500.solverstate
I0523 18:50:05.285145 15542 solver.cpp:237] Iteration 47500, loss = 1.1648
I0523 18:50:05.285194 15542 solver.cpp:253]     Train net output #0: loss = 1.1648 (* 1 = 1.1648 loss)
I0523 18:50:05.285208 15542 sgd_solver.cpp:106] Iteration 47500, lr = 0.0035
I0523 18:50:14.325986 15542 solver.cpp:237] Iteration 47750, loss = 1.1019
I0523 18:50:14.326020 15542 solver.cpp:253]     Train net output #0: loss = 1.1019 (* 1 = 1.1019 loss)
I0523 18:50:14.326037 15542 sgd_solver.cpp:106] Iteration 47750, lr = 0.0035
I0523 18:50:23.361253 15542 solver.cpp:237] Iteration 48000, loss = 1.37196
I0523 18:50:23.361412 15542 solver.cpp:253]     Train net output #0: loss = 1.37196 (* 1 = 1.37196 loss)
I0523 18:50:23.361424 15542 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0523 18:50:32.392612 15542 solver.cpp:237] Iteration 48250, loss = 1.3168
I0523 18:50:32.392650 15542 solver.cpp:253]     Train net output #0: loss = 1.3168 (* 1 = 1.3168 loss)
I0523 18:50:32.392671 15542 sgd_solver.cpp:106] Iteration 48250, lr = 0.0035
I0523 18:51:02.322898 15542 solver.cpp:237] Iteration 48500, loss = 1.14489
I0523 18:51:02.323079 15542 solver.cpp:253]     Train net output #0: loss = 1.14489 (* 1 = 1.14489 loss)
I0523 18:51:02.323093 15542 sgd_solver.cpp:106] Iteration 48500, lr = 0.0035
I0523 18:51:11.354969 15542 solver.cpp:237] Iteration 48750, loss = 1.24522
I0523 18:51:11.355002 15542 solver.cpp:253]     Train net output #0: loss = 1.24522 (* 1 = 1.24522 loss)
I0523 18:51:11.355021 15542 sgd_solver.cpp:106] Iteration 48750, lr = 0.0035
I0523 18:51:20.387058 15542 solver.cpp:237] Iteration 49000, loss = 1.30535
I0523 18:51:20.387100 15542 solver.cpp:253]     Train net output #0: loss = 1.30535 (* 1 = 1.30535 loss)
I0523 18:51:20.387120 15542 sgd_solver.cpp:106] Iteration 49000, lr = 0.0035
I0523 18:51:29.421382 15542 solver.cpp:237] Iteration 49250, loss = 1.35903
I0523 18:51:29.421412 15542 solver.cpp:253]     Train net output #0: loss = 1.35903 (* 1 = 1.35903 loss)
I0523 18:51:29.421427 15542 sgd_solver.cpp:106] Iteration 49250, lr = 0.0035
I0523 18:51:38.458757 15542 solver.cpp:237] Iteration 49500, loss = 1.28789
I0523 18:51:38.458933 15542 solver.cpp:253]     Train net output #0: loss = 1.28789 (* 1 = 1.28789 loss)
I0523 18:51:38.458948 15542 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0523 18:51:47.500159 15542 solver.cpp:237] Iteration 49750, loss = 1.43548
I0523 18:51:47.500203 15542 solver.cpp:253]     Train net output #0: loss = 1.43548 (* 1 = 1.43548 loss)
I0523 18:51:47.500217 15542 sgd_solver.cpp:106] Iteration 49750, lr = 0.0035
I0523 18:51:56.506053 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_50000.caffemodel
I0523 18:51:56.571532 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_50000.solverstate
I0523 18:51:56.599985 15542 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 18:53:04.849831 15542 solver.cpp:409]     Test net output #0: accuracy = 0.885446
I0523 18:53:04.850009 15542 solver.cpp:409]     Test net output #1: loss = 0.373004 (* 1 = 0.373004 loss)
I0523 18:53:25.758033 15542 solver.cpp:237] Iteration 50000, loss = 1.18588
I0523 18:53:25.758085 15542 solver.cpp:253]     Train net output #0: loss = 1.18588 (* 1 = 1.18588 loss)
I0523 18:53:25.758100 15542 sgd_solver.cpp:106] Iteration 50000, lr = 0.0035
I0523 18:53:34.819399 15542 solver.cpp:237] Iteration 50250, loss = 0.994116
I0523 18:53:34.819434 15542 solver.cpp:253]     Train net output #0: loss = 0.994116 (* 1 = 0.994116 loss)
I0523 18:53:34.819453 15542 sgd_solver.cpp:106] Iteration 50250, lr = 0.0035
I0523 18:53:43.876986 15542 solver.cpp:237] Iteration 50500, loss = 1.24713
I0523 18:53:43.877152 15542 solver.cpp:253]     Train net output #0: loss = 1.24713 (* 1 = 1.24713 loss)
I0523 18:53:43.877168 15542 sgd_solver.cpp:106] Iteration 50500, lr = 0.0035
I0523 18:53:52.925027 15542 solver.cpp:237] Iteration 50750, loss = 1.27659
I0523 18:53:52.925071 15542 solver.cpp:253]     Train net output #0: loss = 1.27659 (* 1 = 1.27659 loss)
I0523 18:53:52.925092 15542 sgd_solver.cpp:106] Iteration 50750, lr = 0.0035
I0523 18:54:01.983096 15542 solver.cpp:237] Iteration 51000, loss = 1.32346
I0523 18:54:01.983131 15542 solver.cpp:253]     Train net output #0: loss = 1.32346 (* 1 = 1.32346 loss)
I0523 18:54:01.983145 15542 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0523 18:54:11.050793 15542 solver.cpp:237] Iteration 51250, loss = 1.23361
I0523 18:54:11.050828 15542 solver.cpp:253]     Train net output #0: loss = 1.23361 (* 1 = 1.23361 loss)
I0523 18:54:11.050843 15542 sgd_solver.cpp:106] Iteration 51250, lr = 0.0035
I0523 18:54:20.106032 15542 solver.cpp:237] Iteration 51500, loss = 1.4083
I0523 18:54:20.106207 15542 solver.cpp:253]     Train net output #0: loss = 1.4083 (* 1 = 1.4083 loss)
I0523 18:54:20.106221 15542 sgd_solver.cpp:106] Iteration 51500, lr = 0.0035
I0523 18:54:50.046870 15542 solver.cpp:237] Iteration 51750, loss = 1.10404
I0523 18:54:50.046921 15542 solver.cpp:253]     Train net output #0: loss = 1.10404 (* 1 = 1.10404 loss)
I0523 18:54:50.046937 15542 sgd_solver.cpp:106] Iteration 51750, lr = 0.0035
I0523 18:54:59.108583 15542 solver.cpp:237] Iteration 52000, loss = 1.18602
I0523 18:54:59.108742 15542 solver.cpp:253]     Train net output #0: loss = 1.18602 (* 1 = 1.18602 loss)
I0523 18:54:59.108755 15542 sgd_solver.cpp:106] Iteration 52000, lr = 0.0035
I0523 18:55:08.169628 15542 solver.cpp:237] Iteration 52250, loss = 1.44195
I0523 18:55:08.169677 15542 solver.cpp:253]     Train net output #0: loss = 1.44195 (* 1 = 1.44195 loss)
I0523 18:55:08.169690 15542 sgd_solver.cpp:106] Iteration 52250, lr = 0.0035
I0523 18:55:17.194442 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_52500.caffemodel
I0523 18:55:17.259243 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_52500.solverstate
I0523 18:55:17.297085 15542 solver.cpp:237] Iteration 52500, loss = 0.974207
I0523 18:55:17.297127 15542 solver.cpp:253]     Train net output #0: loss = 0.974207 (* 1 = 0.974207 loss)
I0523 18:55:17.297144 15542 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0523 18:55:26.361929 15542 solver.cpp:237] Iteration 52750, loss = 1.23758
I0523 18:55:26.361964 15542 solver.cpp:253]     Train net output #0: loss = 1.23758 (* 1 = 1.23758 loss)
I0523 18:55:26.361981 15542 sgd_solver.cpp:106] Iteration 52750, lr = 0.0035
I0523 18:55:35.409339 15542 solver.cpp:237] Iteration 53000, loss = 0.943734
I0523 18:55:35.409520 15542 solver.cpp:253]     Train net output #0: loss = 0.943734 (* 1 = 0.943734 loss)
I0523 18:55:35.409534 15542 sgd_solver.cpp:106] Iteration 53000, lr = 0.0035
I0523 18:55:44.444936 15542 solver.cpp:237] Iteration 53250, loss = 1.23732
I0523 18:55:44.444969 15542 solver.cpp:253]     Train net output #0: loss = 1.23732 (* 1 = 1.23732 loss)
I0523 18:55:44.444983 15542 sgd_solver.cpp:106] Iteration 53250, lr = 0.0035
I0523 18:56:14.401053 15542 solver.cpp:237] Iteration 53500, loss = 1.11911
I0523 18:56:14.401232 15542 solver.cpp:253]     Train net output #0: loss = 1.11911 (* 1 = 1.11911 loss)
I0523 18:56:14.401245 15542 sgd_solver.cpp:106] Iteration 53500, lr = 0.0035
I0523 18:56:23.456277 15542 solver.cpp:237] Iteration 53750, loss = 1.01675
I0523 18:56:23.456321 15542 solver.cpp:253]     Train net output #0: loss = 1.01675 (* 1 = 1.01675 loss)
I0523 18:56:23.456336 15542 sgd_solver.cpp:106] Iteration 53750, lr = 0.0035
I0523 18:56:32.518510 15542 solver.cpp:237] Iteration 54000, loss = 1.40696
I0523 18:56:32.518545 15542 solver.cpp:253]     Train net output #0: loss = 1.40696 (* 1 = 1.40696 loss)
I0523 18:56:32.518563 15542 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0523 18:56:41.560271 15542 solver.cpp:237] Iteration 54250, loss = 1.29944
I0523 18:56:41.560305 15542 solver.cpp:253]     Train net output #0: loss = 1.29944 (* 1 = 1.29944 loss)
I0523 18:56:41.560318 15542 sgd_solver.cpp:106] Iteration 54250, lr = 0.0035
I0523 18:56:50.607558 15542 solver.cpp:237] Iteration 54500, loss = 1.19997
I0523 18:56:50.607723 15542 solver.cpp:253]     Train net output #0: loss = 1.19997 (* 1 = 1.19997 loss)
I0523 18:56:50.607738 15542 sgd_solver.cpp:106] Iteration 54500, lr = 0.0035
I0523 18:56:59.666378 15542 solver.cpp:237] Iteration 54750, loss = 1.22197
I0523 18:56:59.666411 15542 solver.cpp:253]     Train net output #0: loss = 1.22197 (* 1 = 1.22197 loss)
I0523 18:56:59.666429 15542 sgd_solver.cpp:106] Iteration 54750, lr = 0.0035
I0523 18:57:08.693752 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_55000.caffemodel
I0523 18:57:08.757256 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_55000.solverstate
I0523 18:57:08.783743 15542 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 18:57:55.752065 15542 solver.cpp:409]     Test net output #0: accuracy = 0.883599
I0523 18:57:55.752243 15542 solver.cpp:409]     Test net output #1: loss = 0.35551 (* 1 = 0.35551 loss)
I0523 18:58:16.619959 15542 solver.cpp:237] Iteration 55000, loss = 0.983977
I0523 18:58:16.620012 15542 solver.cpp:253]     Train net output #0: loss = 0.983977 (* 1 = 0.983977 loss)
I0523 18:58:16.620030 15542 sgd_solver.cpp:106] Iteration 55000, lr = 0.0035
I0523 18:58:25.645998 15542 solver.cpp:237] Iteration 55250, loss = 1.31651
I0523 18:58:25.646039 15542 solver.cpp:253]     Train net output #0: loss = 1.31651 (* 1 = 1.31651 loss)
I0523 18:58:25.646056 15542 sgd_solver.cpp:106] Iteration 55250, lr = 0.0035
I0523 18:58:34.666556 15542 solver.cpp:237] Iteration 55500, loss = 1.13468
I0523 18:58:34.666725 15542 solver.cpp:253]     Train net output #0: loss = 1.13468 (* 1 = 1.13468 loss)
I0523 18:58:34.666738 15542 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0523 18:58:43.685611 15542 solver.cpp:237] Iteration 55750, loss = 1.28939
I0523 18:58:43.685647 15542 solver.cpp:253]     Train net output #0: loss = 1.28939 (* 1 = 1.28939 loss)
I0523 18:58:43.685660 15542 sgd_solver.cpp:106] Iteration 55750, lr = 0.0035
I0523 18:58:52.706259 15542 solver.cpp:237] Iteration 56000, loss = 0.878552
I0523 18:58:52.706300 15542 solver.cpp:253]     Train net output #0: loss = 0.878552 (* 1 = 0.878552 loss)
I0523 18:58:52.706320 15542 sgd_solver.cpp:106] Iteration 56000, lr = 0.0035
I0523 18:59:01.722151 15542 solver.cpp:237] Iteration 56250, loss = 1.26623
I0523 18:59:01.722187 15542 solver.cpp:253]     Train net output #0: loss = 1.26623 (* 1 = 1.26623 loss)
I0523 18:59:01.722203 15542 sgd_solver.cpp:106] Iteration 56250, lr = 0.0035
I0523 18:59:10.738227 15542 solver.cpp:237] Iteration 56500, loss = 1.31976
I0523 18:59:10.738387 15542 solver.cpp:253]     Train net output #0: loss = 1.31976 (* 1 = 1.31976 loss)
I0523 18:59:10.738404 15542 sgd_solver.cpp:106] Iteration 56500, lr = 0.0035
I0523 18:59:40.705934 15542 solver.cpp:237] Iteration 56750, loss = 1.47352
I0523 18:59:40.705983 15542 solver.cpp:253]     Train net output #0: loss = 1.47352 (* 1 = 1.47352 loss)
I0523 18:59:40.705998 15542 sgd_solver.cpp:106] Iteration 56750, lr = 0.0035
I0523 18:59:49.726083 15542 solver.cpp:237] Iteration 57000, loss = 0.8869
I0523 18:59:49.726244 15542 solver.cpp:253]     Train net output #0: loss = 0.8869 (* 1 = 0.8869 loss)
I0523 18:59:49.726259 15542 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0523 18:59:58.745921 15542 solver.cpp:237] Iteration 57250, loss = 1.14194
I0523 18:59:58.745954 15542 solver.cpp:253]     Train net output #0: loss = 1.14194 (* 1 = 1.14194 loss)
I0523 18:59:58.745970 15542 sgd_solver.cpp:106] Iteration 57250, lr = 0.0035
I0523 19:00:07.722596 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_57500.caffemodel
I0523 19:00:07.786368 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_57500.solverstate
I0523 19:00:07.824143 15542 solver.cpp:237] Iteration 57500, loss = 1.05674
I0523 19:00:07.824185 15542 solver.cpp:253]     Train net output #0: loss = 1.05674 (* 1 = 1.05674 loss)
I0523 19:00:07.824203 15542 sgd_solver.cpp:106] Iteration 57500, lr = 0.0035
I0523 19:00:16.843735 15542 solver.cpp:237] Iteration 57750, loss = 1.22421
I0523 19:00:16.843770 15542 solver.cpp:253]     Train net output #0: loss = 1.22421 (* 1 = 1.22421 loss)
I0523 19:00:16.843786 15542 sgd_solver.cpp:106] Iteration 57750, lr = 0.0035
I0523 19:00:25.857059 15542 solver.cpp:237] Iteration 58000, loss = 1.16536
I0523 19:00:25.857221 15542 solver.cpp:253]     Train net output #0: loss = 1.16536 (* 1 = 1.16536 loss)
I0523 19:00:25.857234 15542 sgd_solver.cpp:106] Iteration 58000, lr = 0.0035
I0523 19:00:34.874181 15542 solver.cpp:237] Iteration 58250, loss = 1.34766
I0523 19:00:34.874228 15542 solver.cpp:253]     Train net output #0: loss = 1.34766 (* 1 = 1.34766 loss)
I0523 19:00:34.874244 15542 sgd_solver.cpp:106] Iteration 58250, lr = 0.0035
I0523 19:01:04.837481 15542 solver.cpp:237] Iteration 58500, loss = 1.05512
I0523 19:01:04.837661 15542 solver.cpp:253]     Train net output #0: loss = 1.05512 (* 1 = 1.05512 loss)
I0523 19:01:04.837674 15542 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0523 19:01:13.857925 15542 solver.cpp:237] Iteration 58750, loss = 1.07434
I0523 19:01:13.857960 15542 solver.cpp:253]     Train net output #0: loss = 1.07434 (* 1 = 1.07434 loss)
I0523 19:01:13.857977 15542 sgd_solver.cpp:106] Iteration 58750, lr = 0.0035
I0523 19:01:22.876796 15542 solver.cpp:237] Iteration 59000, loss = 1.01254
I0523 19:01:22.876842 15542 solver.cpp:253]     Train net output #0: loss = 1.01254 (* 1 = 1.01254 loss)
I0523 19:01:22.876859 15542 sgd_solver.cpp:106] Iteration 59000, lr = 0.0035
I0523 19:01:31.891753 15542 solver.cpp:237] Iteration 59250, loss = 1.17612
I0523 19:01:31.891788 15542 solver.cpp:253]     Train net output #0: loss = 1.17612 (* 1 = 1.17612 loss)
I0523 19:01:31.891804 15542 sgd_solver.cpp:106] Iteration 59250, lr = 0.0035
I0523 19:01:40.908325 15542 solver.cpp:237] Iteration 59500, loss = 1.36407
I0523 19:01:40.908495 15542 solver.cpp:253]     Train net output #0: loss = 1.36407 (* 1 = 1.36407 loss)
I0523 19:01:40.908509 15542 sgd_solver.cpp:106] Iteration 59500, lr = 0.0035
I0523 19:01:49.930918 15542 solver.cpp:237] Iteration 59750, loss = 1.0568
I0523 19:01:49.930968 15542 solver.cpp:253]     Train net output #0: loss = 1.0568 (* 1 = 1.0568 loss)
I0523 19:01:49.930980 15542 sgd_solver.cpp:106] Iteration 59750, lr = 0.0035
I0523 19:01:58.912374 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_60000.caffemodel
I0523 19:01:58.975394 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_60000.solverstate
I0523 19:01:59.001600 15542 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 19:03:07.255970 15542 solver.cpp:409]     Test net output #0: accuracy = 0.888238
I0523 19:03:07.256148 15542 solver.cpp:409]     Test net output #1: loss = 0.369498 (* 1 = 0.369498 loss)
I0523 19:03:28.164976 15542 solver.cpp:237] Iteration 60000, loss = 0.958136
I0523 19:03:28.165031 15542 solver.cpp:253]     Train net output #0: loss = 0.958136 (* 1 = 0.958136 loss)
I0523 19:03:28.165046 15542 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0523 19:03:37.270189 15542 solver.cpp:237] Iteration 60250, loss = 1.20933
I0523 19:03:37.270357 15542 solver.cpp:253]     Train net output #0: loss = 1.20933 (* 1 = 1.20933 loss)
I0523 19:03:37.270371 15542 sgd_solver.cpp:106] Iteration 60250, lr = 0.0035
I0523 19:03:46.366475 15542 solver.cpp:237] Iteration 60500, loss = 1.39325
I0523 19:03:46.366509 15542 solver.cpp:253]     Train net output #0: loss = 1.39325 (* 1 = 1.39325 loss)
I0523 19:03:46.366524 15542 sgd_solver.cpp:106] Iteration 60500, lr = 0.0035
I0523 19:03:55.465170 15542 solver.cpp:237] Iteration 60750, loss = 1.14042
I0523 19:03:55.465204 15542 solver.cpp:253]     Train net output #0: loss = 1.14042 (* 1 = 1.14042 loss)
I0523 19:03:55.465227 15542 sgd_solver.cpp:106] Iteration 60750, lr = 0.0035
I0523 19:04:04.572712 15542 solver.cpp:237] Iteration 61000, loss = 0.95142
I0523 19:04:04.572748 15542 solver.cpp:253]     Train net output #0: loss = 0.95142 (* 1 = 0.95142 loss)
I0523 19:04:04.572765 15542 sgd_solver.cpp:106] Iteration 61000, lr = 0.0035
I0523 19:04:13.678892 15542 solver.cpp:237] Iteration 61250, loss = 1.36339
I0523 19:04:13.679050 15542 solver.cpp:253]     Train net output #0: loss = 1.36339 (* 1 = 1.36339 loss)
I0523 19:04:13.679064 15542 sgd_solver.cpp:106] Iteration 61250, lr = 0.0035
I0523 19:04:22.776367 15542 solver.cpp:237] Iteration 61500, loss = 1.42293
I0523 19:04:22.776406 15542 solver.cpp:253]     Train net output #0: loss = 1.42293 (* 1 = 1.42293 loss)
I0523 19:04:22.776423 15542 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0523 19:04:52.778165 15542 solver.cpp:237] Iteration 61750, loss = 1.37534
I0523 19:04:52.778357 15542 solver.cpp:253]     Train net output #0: loss = 1.37534 (* 1 = 1.37534 loss)
I0523 19:04:52.778373 15542 sgd_solver.cpp:106] Iteration 61750, lr = 0.0035
I0523 19:05:01.872514 15542 solver.cpp:237] Iteration 62000, loss = 1.24274
I0523 19:05:01.872548 15542 solver.cpp:253]     Train net output #0: loss = 1.24274 (* 1 = 1.24274 loss)
I0523 19:05:01.872563 15542 sgd_solver.cpp:106] Iteration 62000, lr = 0.0035
I0523 19:05:10.970049 15542 solver.cpp:237] Iteration 62250, loss = 0.956328
I0523 19:05:10.970098 15542 solver.cpp:253]     Train net output #0: loss = 0.956328 (* 1 = 0.956328 loss)
I0523 19:05:10.970114 15542 sgd_solver.cpp:106] Iteration 62250, lr = 0.0035
I0523 19:05:20.035723 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_62500.caffemodel
I0523 19:05:20.100473 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_62500.solverstate
I0523 19:05:20.140203 15542 solver.cpp:237] Iteration 62500, loss = 1.2957
I0523 19:05:20.140254 15542 solver.cpp:253]     Train net output #0: loss = 1.2957 (* 1 = 1.2957 loss)
I0523 19:05:20.140269 15542 sgd_solver.cpp:106] Iteration 62500, lr = 0.0035
I0523 19:05:29.245713 15542 solver.cpp:237] Iteration 62750, loss = 1.27586
I0523 19:05:29.245890 15542 solver.cpp:253]     Train net output #0: loss = 1.27586 (* 1 = 1.27586 loss)
I0523 19:05:29.245904 15542 sgd_solver.cpp:106] Iteration 62750, lr = 0.0035
I0523 19:05:38.339273 15542 solver.cpp:237] Iteration 63000, loss = 1.09588
I0523 19:05:38.339311 15542 solver.cpp:253]     Train net output #0: loss = 1.09588 (* 1 = 1.09588 loss)
I0523 19:05:38.339330 15542 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0523 19:05:47.440460 15542 solver.cpp:237] Iteration 63250, loss = 1.07556
I0523 19:05:47.440496 15542 solver.cpp:253]     Train net output #0: loss = 1.07556 (* 1 = 1.07556 loss)
I0523 19:05:47.440510 15542 sgd_solver.cpp:106] Iteration 63250, lr = 0.0035
I0523 19:06:17.465865 15542 solver.cpp:237] Iteration 63500, loss = 1.14417
I0523 19:06:17.466049 15542 solver.cpp:253]     Train net output #0: loss = 1.14417 (* 1 = 1.14417 loss)
I0523 19:06:17.466065 15542 sgd_solver.cpp:106] Iteration 63500, lr = 0.0035
I0523 19:06:26.560822 15542 solver.cpp:237] Iteration 63750, loss = 1.09717
I0523 19:06:26.560863 15542 solver.cpp:253]     Train net output #0: loss = 1.09717 (* 1 = 1.09717 loss)
I0523 19:06:26.560880 15542 sgd_solver.cpp:106] Iteration 63750, lr = 0.0035
I0523 19:06:35.657707 15542 solver.cpp:237] Iteration 64000, loss = 1.1007
I0523 19:06:35.657742 15542 solver.cpp:253]     Train net output #0: loss = 1.1007 (* 1 = 1.1007 loss)
I0523 19:06:35.657759 15542 sgd_solver.cpp:106] Iteration 64000, lr = 0.0035
I0523 19:06:44.763989 15542 solver.cpp:237] Iteration 64250, loss = 1.38822
I0523 19:06:44.764024 15542 solver.cpp:253]     Train net output #0: loss = 1.38822 (* 1 = 1.38822 loss)
I0523 19:06:44.764039 15542 sgd_solver.cpp:106] Iteration 64250, lr = 0.0035
I0523 19:06:53.858266 15542 solver.cpp:237] Iteration 64500, loss = 1.19046
I0523 19:06:53.858433 15542 solver.cpp:253]     Train net output #0: loss = 1.19046 (* 1 = 1.19046 loss)
I0523 19:06:53.858446 15542 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0523 19:07:02.957788 15542 solver.cpp:237] Iteration 64750, loss = 0.976853
I0523 19:07:02.957824 15542 solver.cpp:253]     Train net output #0: loss = 0.976853 (* 1 = 0.976853 loss)
I0523 19:07:02.957839 15542 sgd_solver.cpp:106] Iteration 64750, lr = 0.0035
I0523 19:07:12.026429 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_65000.caffemodel
I0523 19:07:12.089411 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_65000.solverstate
I0523 19:07:12.115622 15542 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 19:07:59.471868 15542 solver.cpp:409]     Test net output #0: accuracy = 0.886126
I0523 19:07:59.472060 15542 solver.cpp:409]     Test net output #1: loss = 0.354467 (* 1 = 0.354467 loss)
I0523 19:08:20.399960 15542 solver.cpp:237] Iteration 65000, loss = 0.871517
I0523 19:08:20.400013 15542 solver.cpp:253]     Train net output #0: loss = 0.871517 (* 1 = 0.871517 loss)
I0523 19:08:20.400028 15542 sgd_solver.cpp:106] Iteration 65000, lr = 0.0035
I0523 19:08:29.470099 15542 solver.cpp:237] Iteration 65250, loss = 1.11921
I0523 19:08:29.470135 15542 solver.cpp:253]     Train net output #0: loss = 1.11921 (* 1 = 1.11921 loss)
I0523 19:08:29.470157 15542 sgd_solver.cpp:106] Iteration 65250, lr = 0.0035
I0523 19:08:38.546159 15542 solver.cpp:237] Iteration 65500, loss = 1.22343
I0523 19:08:38.546324 15542 solver.cpp:253]     Train net output #0: loss = 1.22343 (* 1 = 1.22343 loss)
I0523 19:08:38.546337 15542 sgd_solver.cpp:106] Iteration 65500, lr = 0.0035
I0523 19:08:47.623805 15542 solver.cpp:237] Iteration 65750, loss = 1.18472
I0523 19:08:47.623839 15542 solver.cpp:253]     Train net output #0: loss = 1.18472 (* 1 = 1.18472 loss)
I0523 19:08:47.623857 15542 sgd_solver.cpp:106] Iteration 65750, lr = 0.0035
I0523 19:08:56.698079 15542 solver.cpp:237] Iteration 66000, loss = 1.19348
I0523 19:08:56.698122 15542 solver.cpp:253]     Train net output #0: loss = 1.19348 (* 1 = 1.19348 loss)
I0523 19:08:56.698138 15542 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0523 19:09:05.776134 15542 solver.cpp:237] Iteration 66250, loss = 1.1086
I0523 19:09:05.776168 15542 solver.cpp:253]     Train net output #0: loss = 1.1086 (* 1 = 1.1086 loss)
I0523 19:09:05.776182 15542 sgd_solver.cpp:106] Iteration 66250, lr = 0.0035
I0523 19:09:14.848528 15542 solver.cpp:237] Iteration 66500, loss = 0.905923
I0523 19:09:14.848690 15542 solver.cpp:253]     Train net output #0: loss = 0.905923 (* 1 = 0.905923 loss)
I0523 19:09:14.848704 15542 sgd_solver.cpp:106] Iteration 66500, lr = 0.0035
I0523 19:09:44.884829 15542 solver.cpp:237] Iteration 66750, loss = 0.990292
I0523 19:09:44.885015 15542 solver.cpp:253]     Train net output #0: loss = 0.990292 (* 1 = 0.990292 loss)
I0523 19:09:44.885031 15542 sgd_solver.cpp:106] Iteration 66750, lr = 0.0035
I0523 19:09:53.958914 15542 solver.cpp:237] Iteration 67000, loss = 0.982643
I0523 19:09:53.958950 15542 solver.cpp:253]     Train net output #0: loss = 0.982643 (* 1 = 0.982643 loss)
I0523 19:09:53.958968 15542 sgd_solver.cpp:106] Iteration 67000, lr = 0.0035
I0523 19:10:03.038563 15542 solver.cpp:237] Iteration 67250, loss = 1.31326
I0523 19:10:03.038599 15542 solver.cpp:253]     Train net output #0: loss = 1.31326 (* 1 = 1.31326 loss)
I0523 19:10:03.038616 15542 sgd_solver.cpp:106] Iteration 67250, lr = 0.0035
I0523 19:10:12.079062 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_67500.caffemodel
I0523 19:10:12.142706 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_67500.solverstate
I0523 19:10:12.180490 15542 solver.cpp:237] Iteration 67500, loss = 1.17578
I0523 19:10:12.180536 15542 solver.cpp:253]     Train net output #0: loss = 1.17578 (* 1 = 1.17578 loss)
I0523 19:10:12.180552 15542 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0523 19:10:21.264291 15542 solver.cpp:237] Iteration 67750, loss = 1.34441
I0523 19:10:21.264456 15542 solver.cpp:253]     Train net output #0: loss = 1.34441 (* 1 = 1.34441 loss)
I0523 19:10:21.264469 15542 sgd_solver.cpp:106] Iteration 67750, lr = 0.0035
I0523 19:10:30.341502 15542 solver.cpp:237] Iteration 68000, loss = 1.13022
I0523 19:10:30.341547 15542 solver.cpp:253]     Train net output #0: loss = 1.13022 (* 1 = 1.13022 loss)
I0523 19:10:30.341563 15542 sgd_solver.cpp:106] Iteration 68000, lr = 0.0035
I0523 19:10:39.417708 15542 solver.cpp:237] Iteration 68250, loss = 1.30778
I0523 19:10:39.417744 15542 solver.cpp:253]     Train net output #0: loss = 1.30778 (* 1 = 1.30778 loss)
I0523 19:10:39.417760 15542 sgd_solver.cpp:106] Iteration 68250, lr = 0.0035
I0523 19:11:09.382262 15542 solver.cpp:237] Iteration 68500, loss = 0.916638
I0523 19:11:09.382459 15542 solver.cpp:253]     Train net output #0: loss = 0.916638 (* 1 = 0.916638 loss)
I0523 19:11:09.382475 15542 sgd_solver.cpp:106] Iteration 68500, lr = 0.0035
I0523 19:11:18.454354 15542 solver.cpp:237] Iteration 68750, loss = 1.34547
I0523 19:11:18.454388 15542 solver.cpp:253]     Train net output #0: loss = 1.34547 (* 1 = 1.34547 loss)
I0523 19:11:18.454406 15542 sgd_solver.cpp:106] Iteration 68750, lr = 0.0035
I0523 19:11:27.529295 15542 solver.cpp:237] Iteration 69000, loss = 1.21967
I0523 19:11:27.529335 15542 solver.cpp:253]     Train net output #0: loss = 1.21967 (* 1 = 1.21967 loss)
I0523 19:11:27.529352 15542 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0523 19:11:36.611130 15542 solver.cpp:237] Iteration 69250, loss = 1.36718
I0523 19:11:36.611163 15542 solver.cpp:253]     Train net output #0: loss = 1.36718 (* 1 = 1.36718 loss)
I0523 19:11:36.611182 15542 sgd_solver.cpp:106] Iteration 69250, lr = 0.0035
I0523 19:11:45.690218 15542 solver.cpp:237] Iteration 69500, loss = 1.1418
I0523 19:11:45.690389 15542 solver.cpp:253]     Train net output #0: loss = 1.1418 (* 1 = 1.1418 loss)
I0523 19:11:45.690403 15542 sgd_solver.cpp:106] Iteration 69500, lr = 0.0035
I0523 19:11:54.758939 15542 solver.cpp:237] Iteration 69750, loss = 1.28635
I0523 19:11:54.758968 15542 solver.cpp:253]     Train net output #0: loss = 1.28635 (* 1 = 1.28635 loss)
I0523 19:11:54.758983 15542 sgd_solver.cpp:106] Iteration 69750, lr = 0.0035
I0523 19:12:03.793254 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_70000.caffemodel
I0523 19:12:03.856212 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_70000.solverstate
I0523 19:12:03.882958 15542 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 19:13:12.112462 15542 solver.cpp:409]     Test net output #0: accuracy = 0.891419
I0523 19:13:12.112646 15542 solver.cpp:409]     Test net output #1: loss = 0.336968 (* 1 = 0.336968 loss)
I0523 19:13:33.016753 15542 solver.cpp:237] Iteration 70000, loss = 1.1515
I0523 19:13:33.016806 15542 solver.cpp:253]     Train net output #0: loss = 1.1515 (* 1 = 1.1515 loss)
I0523 19:13:33.016821 15542 sgd_solver.cpp:106] Iteration 70000, lr = 0.0035
I0523 19:13:42.127239 15542 solver.cpp:237] Iteration 70250, loss = 1.2458
I0523 19:13:42.127410 15542 solver.cpp:253]     Train net output #0: loss = 1.2458 (* 1 = 1.2458 loss)
I0523 19:13:42.127424 15542 sgd_solver.cpp:106] Iteration 70250, lr = 0.0035
I0523 19:13:51.243398 15542 solver.cpp:237] Iteration 70500, loss = 1.06196
I0523 19:13:51.243443 15542 solver.cpp:253]     Train net output #0: loss = 1.06196 (* 1 = 1.06196 loss)
I0523 19:13:51.243461 15542 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0523 19:14:00.358464 15542 solver.cpp:237] Iteration 70750, loss = 0.778093
I0523 19:14:00.358500 15542 solver.cpp:253]     Train net output #0: loss = 0.778093 (* 1 = 0.778093 loss)
I0523 19:14:00.358515 15542 sgd_solver.cpp:106] Iteration 70750, lr = 0.0035
I0523 19:14:09.486532 15542 solver.cpp:237] Iteration 71000, loss = 1.04666
I0523 19:14:09.486567 15542 solver.cpp:253]     Train net output #0: loss = 1.04666 (* 1 = 1.04666 loss)
I0523 19:14:09.486584 15542 sgd_solver.cpp:106] Iteration 71000, lr = 0.0035
I0523 19:14:18.607146 15542 solver.cpp:237] Iteration 71250, loss = 0.940671
I0523 19:14:18.607324 15542 solver.cpp:253]     Train net output #0: loss = 0.940671 (* 1 = 0.940671 loss)
I0523 19:14:18.607338 15542 sgd_solver.cpp:106] Iteration 71250, lr = 0.0035
I0523 19:14:27.714833 15542 solver.cpp:237] Iteration 71500, loss = 0.976321
I0523 19:14:27.714867 15542 solver.cpp:253]     Train net output #0: loss = 0.976321 (* 1 = 0.976321 loss)
I0523 19:14:27.714884 15542 sgd_solver.cpp:106] Iteration 71500, lr = 0.0035
I0523 19:14:57.739428 15542 solver.cpp:237] Iteration 71750, loss = 1.16649
I0523 19:14:57.739624 15542 solver.cpp:253]     Train net output #0: loss = 1.16649 (* 1 = 1.16649 loss)
I0523 19:14:57.739639 15542 sgd_solver.cpp:106] Iteration 71750, lr = 0.0035
I0523 19:15:06.860303 15542 solver.cpp:237] Iteration 72000, loss = 1.08724
I0523 19:15:06.860352 15542 solver.cpp:253]     Train net output #0: loss = 1.08724 (* 1 = 1.08724 loss)
I0523 19:15:06.860368 15542 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0523 19:15:15.980569 15542 solver.cpp:237] Iteration 72250, loss = 1.10578
I0523 19:15:15.980604 15542 solver.cpp:253]     Train net output #0: loss = 1.10578 (* 1 = 1.10578 loss)
I0523 19:15:15.980621 15542 sgd_solver.cpp:106] Iteration 72250, lr = 0.0035
I0523 19:15:25.063737 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_72500.caffemodel
I0523 19:15:25.129037 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_72500.solverstate
I0523 19:15:25.168625 15542 solver.cpp:237] Iteration 72500, loss = 1.21109
I0523 19:15:25.168675 15542 solver.cpp:253]     Train net output #0: loss = 1.21109 (* 1 = 1.21109 loss)
I0523 19:15:25.168689 15542 sgd_solver.cpp:106] Iteration 72500, lr = 0.0035
I0523 19:15:34.288710 15542 solver.cpp:237] Iteration 72750, loss = 1.30098
I0523 19:15:34.288899 15542 solver.cpp:253]     Train net output #0: loss = 1.30098 (* 1 = 1.30098 loss)
I0523 19:15:34.288914 15542 sgd_solver.cpp:106] Iteration 72750, lr = 0.0035
I0523 19:15:43.405704 15542 solver.cpp:237] Iteration 73000, loss = 1.51805
I0523 19:15:43.405737 15542 solver.cpp:253]     Train net output #0: loss = 1.51805 (* 1 = 1.51805 loss)
I0523 19:15:43.405755 15542 sgd_solver.cpp:106] Iteration 73000, lr = 0.0035
I0523 19:15:52.530251 15542 solver.cpp:237] Iteration 73250, loss = 1.24147
I0523 19:15:52.530285 15542 solver.cpp:253]     Train net output #0: loss = 1.24147 (* 1 = 1.24147 loss)
I0523 19:15:52.530302 15542 sgd_solver.cpp:106] Iteration 73250, lr = 0.0035
I0523 19:16:22.548985 15542 solver.cpp:237] Iteration 73500, loss = 1.02295
I0523 19:16:22.549173 15542 solver.cpp:253]     Train net output #0: loss = 1.02295 (* 1 = 1.02295 loss)
I0523 19:16:22.549187 15542 sgd_solver.cpp:106] Iteration 73500, lr = 0.0035
I0523 19:16:31.671802 15542 solver.cpp:237] Iteration 73750, loss = 1.27629
I0523 19:16:31.671835 15542 solver.cpp:253]     Train net output #0: loss = 1.27629 (* 1 = 1.27629 loss)
I0523 19:16:31.671854 15542 sgd_solver.cpp:106] Iteration 73750, lr = 0.0035
I0523 19:16:40.784636 15542 solver.cpp:237] Iteration 74000, loss = 0.968629
I0523 19:16:40.784672 15542 solver.cpp:253]     Train net output #0: loss = 0.968629 (* 1 = 0.968629 loss)
I0523 19:16:40.784687 15542 sgd_solver.cpp:106] Iteration 74000, lr = 0.0035
I0523 19:16:49.906043 15542 solver.cpp:237] Iteration 74250, loss = 1.3545
I0523 19:16:49.906090 15542 solver.cpp:253]     Train net output #0: loss = 1.3545 (* 1 = 1.3545 loss)
I0523 19:16:49.906106 15542 sgd_solver.cpp:106] Iteration 74250, lr = 0.0035
I0523 19:16:59.017578 15542 solver.cpp:237] Iteration 74500, loss = 0.930824
I0523 19:16:59.017745 15542 solver.cpp:253]     Train net output #0: loss = 0.930824 (* 1 = 0.930824 loss)
I0523 19:16:59.017760 15542 sgd_solver.cpp:106] Iteration 74500, lr = 0.0035
I0523 19:17:08.133872 15542 solver.cpp:237] Iteration 74750, loss = 1.1284
I0523 19:17:08.133908 15542 solver.cpp:253]     Train net output #0: loss = 1.1284 (* 1 = 1.1284 loss)
I0523 19:17:08.133924 15542 sgd_solver.cpp:106] Iteration 74750, lr = 0.0035
I0523 19:17:17.213235 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_75000.caffemodel
I0523 19:17:17.278769 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_75000.solverstate
I0523 19:17:17.307304 15542 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 19:18:04.296903 15542 solver.cpp:409]     Test net output #0: accuracy = 0.889359
I0523 19:18:04.297104 15542 solver.cpp:409]     Test net output #1: loss = 0.378501 (* 1 = 0.378501 loss)
I0523 19:18:25.178093 15542 solver.cpp:237] Iteration 75000, loss = 1.32462
I0523 19:18:25.178145 15542 solver.cpp:253]     Train net output #0: loss = 1.32462 (* 1 = 1.32462 loss)
I0523 19:18:25.178163 15542 sgd_solver.cpp:106] Iteration 75000, lr = 0.0035
I0523 19:18:34.218569 15542 solver.cpp:237] Iteration 75250, loss = 0.81571
I0523 19:18:34.218605 15542 solver.cpp:253]     Train net output #0: loss = 0.81571 (* 1 = 0.81571 loss)
I0523 19:18:34.218623 15542 sgd_solver.cpp:106] Iteration 75250, lr = 0.0035
I0523 19:18:43.253355 15542 solver.cpp:237] Iteration 75500, loss = 1.08975
I0523 19:18:43.253523 15542 solver.cpp:253]     Train net output #0: loss = 1.08975 (* 1 = 1.08975 loss)
I0523 19:18:43.253537 15542 sgd_solver.cpp:106] Iteration 75500, lr = 0.0035
I0523 19:18:52.292505 15542 solver.cpp:237] Iteration 75750, loss = 1.00054
I0523 19:18:52.292543 15542 solver.cpp:253]     Train net output #0: loss = 1.00054 (* 1 = 1.00054 loss)
I0523 19:18:52.292563 15542 sgd_solver.cpp:106] Iteration 75750, lr = 0.0035
I0523 19:19:01.326788 15542 solver.cpp:237] Iteration 76000, loss = 1.20989
I0523 19:19:01.326824 15542 solver.cpp:253]     Train net output #0: loss = 1.20989 (* 1 = 1.20989 loss)
I0523 19:19:01.326840 15542 sgd_solver.cpp:106] Iteration 76000, lr = 0.0035
I0523 19:19:10.361654 15542 solver.cpp:237] Iteration 76250, loss = 1.41265
I0523 19:19:10.361688 15542 solver.cpp:253]     Train net output #0: loss = 1.41265 (* 1 = 1.41265 loss)
I0523 19:19:10.361706 15542 sgd_solver.cpp:106] Iteration 76250, lr = 0.0035
I0523 19:19:19.398090 15542 solver.cpp:237] Iteration 76500, loss = 1.30801
I0523 19:19:19.398267 15542 solver.cpp:253]     Train net output #0: loss = 1.30801 (* 1 = 1.30801 loss)
I0523 19:19:19.398282 15542 sgd_solver.cpp:106] Iteration 76500, lr = 0.0035
I0523 19:19:49.316030 15542 solver.cpp:237] Iteration 76750, loss = 1.16083
I0523 19:19:49.316079 15542 solver.cpp:253]     Train net output #0: loss = 1.16083 (* 1 = 1.16083 loss)
I0523 19:19:49.316098 15542 sgd_solver.cpp:106] Iteration 76750, lr = 0.0035
I0523 19:19:58.351366 15542 solver.cpp:237] Iteration 77000, loss = 1.08965
I0523 19:19:58.351534 15542 solver.cpp:253]     Train net output #0: loss = 1.08965 (* 1 = 1.08965 loss)
I0523 19:19:58.351547 15542 sgd_solver.cpp:106] Iteration 77000, lr = 0.0035
I0523 19:20:07.384721 15542 solver.cpp:237] Iteration 77250, loss = 1.0685
I0523 19:20:07.384763 15542 solver.cpp:253]     Train net output #0: loss = 1.0685 (* 1 = 1.0685 loss)
I0523 19:20:07.384781 15542 sgd_solver.cpp:106] Iteration 77250, lr = 0.0035
I0523 19:20:16.385223 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_77500.caffemodel
I0523 19:20:16.448731 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_77500.solverstate
I0523 19:20:16.486449 15542 solver.cpp:237] Iteration 77500, loss = 1.01365
I0523 19:20:16.486493 15542 solver.cpp:253]     Train net output #0: loss = 1.01365 (* 1 = 1.01365 loss)
I0523 19:20:16.486507 15542 sgd_solver.cpp:106] Iteration 77500, lr = 0.0035
I0523 19:20:25.520243 15542 solver.cpp:237] Iteration 77750, loss = 1.08461
I0523 19:20:25.520278 15542 solver.cpp:253]     Train net output #0: loss = 1.08461 (* 1 = 1.08461 loss)
I0523 19:20:25.520292 15542 sgd_solver.cpp:106] Iteration 77750, lr = 0.0035
I0523 19:20:34.555910 15542 solver.cpp:237] Iteration 78000, loss = 1.2006
I0523 19:20:34.556100 15542 solver.cpp:253]     Train net output #0: loss = 1.2006 (* 1 = 1.2006 loss)
I0523 19:20:34.556114 15542 sgd_solver.cpp:106] Iteration 78000, lr = 0.0035
I0523 19:20:43.584969 15542 solver.cpp:237] Iteration 78250, loss = 1.09174
I0523 19:20:43.585005 15542 solver.cpp:253]     Train net output #0: loss = 1.09174 (* 1 = 1.09174 loss)
I0523 19:20:43.585021 15542 sgd_solver.cpp:106] Iteration 78250, lr = 0.0035
I0523 19:21:13.468567 15542 solver.cpp:237] Iteration 78500, loss = 1.18361
I0523 19:21:13.468751 15542 solver.cpp:253]     Train net output #0: loss = 1.18361 (* 1 = 1.18361 loss)
I0523 19:21:13.468766 15542 sgd_solver.cpp:106] Iteration 78500, lr = 0.0035
I0523 19:21:22.510174 15542 solver.cpp:237] Iteration 78750, loss = 1.06927
I0523 19:21:22.510222 15542 solver.cpp:253]     Train net output #0: loss = 1.06927 (* 1 = 1.06927 loss)
I0523 19:21:22.510238 15542 sgd_solver.cpp:106] Iteration 78750, lr = 0.0035
I0523 19:21:31.549309 15542 solver.cpp:237] Iteration 79000, loss = 1.18282
I0523 19:21:31.549345 15542 solver.cpp:253]     Train net output #0: loss = 1.18282 (* 1 = 1.18282 loss)
I0523 19:21:31.549358 15542 sgd_solver.cpp:106] Iteration 79000, lr = 0.0035
I0523 19:21:40.585881 15542 solver.cpp:237] Iteration 79250, loss = 1.28516
I0523 19:21:40.585916 15542 solver.cpp:253]     Train net output #0: loss = 1.28516 (* 1 = 1.28516 loss)
I0523 19:21:40.585932 15542 sgd_solver.cpp:106] Iteration 79250, lr = 0.0035
I0523 19:21:49.620764 15542 solver.cpp:237] Iteration 79500, loss = 1.40696
I0523 19:21:49.620944 15542 solver.cpp:253]     Train net output #0: loss = 1.40696 (* 1 = 1.40696 loss)
I0523 19:21:49.620959 15542 sgd_solver.cpp:106] Iteration 79500, lr = 0.0035
I0523 19:21:58.660769 15542 solver.cpp:237] Iteration 79750, loss = 1.25764
I0523 19:21:58.660804 15542 solver.cpp:253]     Train net output #0: loss = 1.25764 (* 1 = 1.25764 loss)
I0523 19:21:58.660821 15542 sgd_solver.cpp:106] Iteration 79750, lr = 0.0035
I0523 19:22:07.656244 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_80000.caffemodel
I0523 19:22:07.718307 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_80000.solverstate
I0523 19:22:07.744921 15542 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 19:23:15.927258 15542 solver.cpp:409]     Test net output #0: accuracy = 0.893219
I0523 19:23:15.927446 15542 solver.cpp:409]     Test net output #1: loss = 0.338772 (* 1 = 0.338772 loss)
I0523 19:23:36.813846 15542 solver.cpp:237] Iteration 80000, loss = 1.03934
I0523 19:23:36.813899 15542 solver.cpp:253]     Train net output #0: loss = 1.03934 (* 1 = 1.03934 loss)
I0523 19:23:36.813913 15542 sgd_solver.cpp:106] Iteration 80000, lr = 0.0035
I0523 19:23:45.865597 15542 solver.cpp:237] Iteration 80250, loss = 1.17721
I0523 19:23:45.865633 15542 solver.cpp:253]     Train net output #0: loss = 1.17721 (* 1 = 1.17721 loss)
I0523 19:23:45.865646 15542 sgd_solver.cpp:106] Iteration 80250, lr = 0.0035
I0523 19:23:54.920389 15542 solver.cpp:237] Iteration 80500, loss = 1.1496
I0523 19:23:54.920572 15542 solver.cpp:253]     Train net output #0: loss = 1.1496 (* 1 = 1.1496 loss)
I0523 19:23:54.920585 15542 sgd_solver.cpp:106] Iteration 80500, lr = 0.0035
I0523 19:24:03.981564 15542 solver.cpp:237] Iteration 80750, loss = 1.0958
I0523 19:24:03.981597 15542 solver.cpp:253]     Train net output #0: loss = 1.0958 (* 1 = 1.0958 loss)
I0523 19:24:03.981614 15542 sgd_solver.cpp:106] Iteration 80750, lr = 0.0035
I0523 19:24:13.037142 15542 solver.cpp:237] Iteration 81000, loss = 1.12436
I0523 19:24:13.037178 15542 solver.cpp:253]     Train net output #0: loss = 1.12436 (* 1 = 1.12436 loss)
I0523 19:24:13.037194 15542 sgd_solver.cpp:106] Iteration 81000, lr = 0.0035
I0523 19:24:22.087707 15542 solver.cpp:237] Iteration 81250, loss = 1.36178
I0523 19:24:22.087750 15542 solver.cpp:253]     Train net output #0: loss = 1.36178 (* 1 = 1.36178 loss)
I0523 19:24:22.087769 15542 sgd_solver.cpp:106] Iteration 81250, lr = 0.0035
I0523 19:24:31.134918 15542 solver.cpp:237] Iteration 81500, loss = 1.28999
I0523 19:24:31.135094 15542 solver.cpp:253]     Train net output #0: loss = 1.28999 (* 1 = 1.28999 loss)
I0523 19:24:31.135110 15542 sgd_solver.cpp:106] Iteration 81500, lr = 0.0035
I0523 19:25:01.074100 15542 solver.cpp:237] Iteration 81750, loss = 1.35198
I0523 19:25:01.074151 15542 solver.cpp:253]     Train net output #0: loss = 1.35198 (* 1 = 1.35198 loss)
I0523 19:25:01.074168 15542 sgd_solver.cpp:106] Iteration 81750, lr = 0.0035
I0523 19:25:10.133493 15542 solver.cpp:237] Iteration 82000, loss = 1.14258
I0523 19:25:10.133684 15542 solver.cpp:253]     Train net output #0: loss = 1.14258 (* 1 = 1.14258 loss)
I0523 19:25:10.133698 15542 sgd_solver.cpp:106] Iteration 82000, lr = 0.0035
I0523 19:25:19.182674 15542 solver.cpp:237] Iteration 82250, loss = 1.43945
I0523 19:25:19.182708 15542 solver.cpp:253]     Train net output #0: loss = 1.43945 (* 1 = 1.43945 loss)
I0523 19:25:19.182725 15542 sgd_solver.cpp:106] Iteration 82250, lr = 0.0035
I0523 19:25:28.195415 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_82500.caffemodel
I0523 19:25:28.258477 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_82500.solverstate
I0523 19:25:28.295954 15542 solver.cpp:237] Iteration 82500, loss = 0.880098
I0523 19:25:28.296000 15542 solver.cpp:253]     Train net output #0: loss = 0.880098 (* 1 = 0.880098 loss)
I0523 19:25:28.296015 15542 sgd_solver.cpp:106] Iteration 82500, lr = 0.0035
I0523 19:25:37.343013 15542 solver.cpp:237] Iteration 82750, loss = 1.02858
I0523 19:25:37.343056 15542 solver.cpp:253]     Train net output #0: loss = 1.02858 (* 1 = 1.02858 loss)
I0523 19:25:37.343073 15542 sgd_solver.cpp:106] Iteration 82750, lr = 0.0035
I0523 19:25:46.411926 15542 solver.cpp:237] Iteration 83000, loss = 1.06884
I0523 19:25:46.412096 15542 solver.cpp:253]     Train net output #0: loss = 1.06884 (* 1 = 1.06884 loss)
I0523 19:25:46.412109 15542 sgd_solver.cpp:106] Iteration 83000, lr = 0.0035
I0523 19:25:55.481794 15542 solver.cpp:237] Iteration 83250, loss = 1.12051
I0523 19:25:55.481840 15542 solver.cpp:253]     Train net output #0: loss = 1.12051 (* 1 = 1.12051 loss)
I0523 19:25:55.481853 15542 sgd_solver.cpp:106] Iteration 83250, lr = 0.0035
I0523 19:26:25.379708 15542 solver.cpp:237] Iteration 83500, loss = 1.11982
I0523 19:26:25.379896 15542 solver.cpp:253]     Train net output #0: loss = 1.11982 (* 1 = 1.11982 loss)
I0523 19:26:25.379911 15542 sgd_solver.cpp:106] Iteration 83500, lr = 0.0035
I0523 19:26:34.437198 15542 solver.cpp:237] Iteration 83750, loss = 1.12539
I0523 19:26:34.437232 15542 solver.cpp:253]     Train net output #0: loss = 1.12539 (* 1 = 1.12539 loss)
I0523 19:26:34.437249 15542 sgd_solver.cpp:106] Iteration 83750, lr = 0.0035
I0523 19:26:43.490612 15542 solver.cpp:237] Iteration 84000, loss = 1.16508
I0523 19:26:43.490648 15542 solver.cpp:253]     Train net output #0: loss = 1.16508 (* 1 = 1.16508 loss)
I0523 19:26:43.490666 15542 sgd_solver.cpp:106] Iteration 84000, lr = 0.0035
I0523 19:26:52.536075 15542 solver.cpp:237] Iteration 84250, loss = 0.952039
I0523 19:26:52.536115 15542 solver.cpp:253]     Train net output #0: loss = 0.952039 (* 1 = 0.952039 loss)
I0523 19:26:52.536134 15542 sgd_solver.cpp:106] Iteration 84250, lr = 0.0035
I0523 19:27:01.591403 15542 solver.cpp:237] Iteration 84500, loss = 1.12682
I0523 19:27:01.591574 15542 solver.cpp:253]     Train net output #0: loss = 1.12682 (* 1 = 1.12682 loss)
I0523 19:27:01.591588 15542 sgd_solver.cpp:106] Iteration 84500, lr = 0.0035
I0523 19:27:10.656482 15542 solver.cpp:237] Iteration 84750, loss = 0.993139
I0523 19:27:10.656527 15542 solver.cpp:253]     Train net output #0: loss = 0.993139 (* 1 = 0.993139 loss)
I0523 19:27:10.656548 15542 sgd_solver.cpp:106] Iteration 84750, lr = 0.0035
I0523 19:27:19.687207 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_85000.caffemodel
I0523 19:27:19.750849 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_85000.solverstate
I0523 19:27:19.777344 15542 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 19:28:07.125865 15542 solver.cpp:409]     Test net output #0: accuracy = 0.891546
I0523 19:28:07.126057 15542 solver.cpp:409]     Test net output #1: loss = 0.360093 (* 1 = 0.360093 loss)
I0523 19:28:28.014435 15542 solver.cpp:237] Iteration 85000, loss = 1.21887
I0523 19:28:28.014487 15542 solver.cpp:253]     Train net output #0: loss = 1.21887 (* 1 = 1.21887 loss)
I0523 19:28:28.014504 15542 sgd_solver.cpp:106] Iteration 85000, lr = 0.0035
I0523 19:28:37.034556 15542 solver.cpp:237] Iteration 85250, loss = 0.939677
I0523 19:28:37.034592 15542 solver.cpp:253]     Train net output #0: loss = 0.939677 (* 1 = 0.939677 loss)
I0523 19:28:37.034610 15542 sgd_solver.cpp:106] Iteration 85250, lr = 0.0035
I0523 19:28:46.063706 15542 solver.cpp:237] Iteration 85500, loss = 1.12235
I0523 19:28:46.063881 15542 solver.cpp:253]     Train net output #0: loss = 1.12235 (* 1 = 1.12235 loss)
I0523 19:28:46.063895 15542 sgd_solver.cpp:106] Iteration 85500, lr = 0.0035
I0523 19:28:55.078155 15542 solver.cpp:237] Iteration 85750, loss = 1.12169
I0523 19:28:55.078198 15542 solver.cpp:253]     Train net output #0: loss = 1.12169 (* 1 = 1.12169 loss)
I0523 19:28:55.078213 15542 sgd_solver.cpp:106] Iteration 85750, lr = 0.0035
I0523 19:29:04.097295 15542 solver.cpp:237] Iteration 86000, loss = 1.07377
I0523 19:29:04.097329 15542 solver.cpp:253]     Train net output #0: loss = 1.07377 (* 1 = 1.07377 loss)
I0523 19:29:04.097347 15542 sgd_solver.cpp:106] Iteration 86000, lr = 0.0035
I0523 19:29:13.103885 15542 solver.cpp:237] Iteration 86250, loss = 1.17724
I0523 19:29:13.103920 15542 solver.cpp:253]     Train net output #0: loss = 1.17724 (* 1 = 1.17724 loss)
I0523 19:29:13.103936 15542 sgd_solver.cpp:106] Iteration 86250, lr = 0.0035
I0523 19:29:22.121397 15542 solver.cpp:237] Iteration 86500, loss = 1.17603
I0523 19:29:22.121582 15542 solver.cpp:253]     Train net output #0: loss = 1.17603 (* 1 = 1.17603 loss)
I0523 19:29:22.121597 15542 sgd_solver.cpp:106] Iteration 86500, lr = 0.0035
I0523 19:29:52.016403 15542 solver.cpp:237] Iteration 86750, loss = 1.2746
I0523 19:29:52.016454 15542 solver.cpp:253]     Train net output #0: loss = 1.2746 (* 1 = 1.2746 loss)
I0523 19:29:52.016469 15542 sgd_solver.cpp:106] Iteration 86750, lr = 0.0035
I0523 19:30:01.030328 15542 solver.cpp:237] Iteration 87000, loss = 1.18559
I0523 19:30:01.030503 15542 solver.cpp:253]     Train net output #0: loss = 1.18559 (* 1 = 1.18559 loss)
I0523 19:30:01.030515 15542 sgd_solver.cpp:106] Iteration 87000, lr = 0.0035
I0523 19:30:10.046854 15542 solver.cpp:237] Iteration 87250, loss = 1.32915
I0523 19:30:10.046895 15542 solver.cpp:253]     Train net output #0: loss = 1.32915 (* 1 = 1.32915 loss)
I0523 19:30:10.046914 15542 sgd_solver.cpp:106] Iteration 87250, lr = 0.0035
I0523 19:30:19.030660 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_87500.caffemodel
I0523 19:30:19.095252 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_87500.solverstate
I0523 19:30:19.134884 15542 solver.cpp:237] Iteration 87500, loss = 1.14784
I0523 19:30:19.134937 15542 solver.cpp:253]     Train net output #0: loss = 1.14784 (* 1 = 1.14784 loss)
I0523 19:30:19.134950 15542 sgd_solver.cpp:106] Iteration 87500, lr = 0.0035
I0523 19:30:28.148171 15542 solver.cpp:237] Iteration 87750, loss = 1.16167
I0523 19:30:28.148205 15542 solver.cpp:253]     Train net output #0: loss = 1.16167 (* 1 = 1.16167 loss)
I0523 19:30:28.148222 15542 sgd_solver.cpp:106] Iteration 87750, lr = 0.0035
I0523 19:30:37.168119 15542 solver.cpp:237] Iteration 88000, loss = 1.43125
I0523 19:30:37.168316 15542 solver.cpp:253]     Train net output #0: loss = 1.43125 (* 1 = 1.43125 loss)
I0523 19:30:37.168331 15542 sgd_solver.cpp:106] Iteration 88000, lr = 0.0035
I0523 19:30:46.183104 15542 solver.cpp:237] Iteration 88250, loss = 1.10064
I0523 19:30:46.183137 15542 solver.cpp:253]     Train net output #0: loss = 1.10064 (* 1 = 1.10064 loss)
I0523 19:30:46.183156 15542 sgd_solver.cpp:106] Iteration 88250, lr = 0.0035
I0523 19:31:16.077339 15542 solver.cpp:237] Iteration 88500, loss = 1.26736
I0523 19:31:16.077529 15542 solver.cpp:253]     Train net output #0: loss = 1.26736 (* 1 = 1.26736 loss)
I0523 19:31:16.077545 15542 sgd_solver.cpp:106] Iteration 88500, lr = 0.0035
I0523 19:31:25.090957 15542 solver.cpp:237] Iteration 88750, loss = 1.00252
I0523 19:31:25.090999 15542 solver.cpp:253]     Train net output #0: loss = 1.00252 (* 1 = 1.00252 loss)
I0523 19:31:25.091017 15542 sgd_solver.cpp:106] Iteration 88750, lr = 0.0035
I0523 19:31:34.117849 15542 solver.cpp:237] Iteration 89000, loss = 1.14586
I0523 19:31:34.117884 15542 solver.cpp:253]     Train net output #0: loss = 1.14586 (* 1 = 1.14586 loss)
I0523 19:31:34.117902 15542 sgd_solver.cpp:106] Iteration 89000, lr = 0.0035
I0523 19:31:43.132060 15542 solver.cpp:237] Iteration 89250, loss = 1.39728
I0523 19:31:43.132094 15542 solver.cpp:253]     Train net output #0: loss = 1.39728 (* 1 = 1.39728 loss)
I0523 19:31:43.132110 15542 sgd_solver.cpp:106] Iteration 89250, lr = 0.0035
I0523 19:31:52.152509 15542 solver.cpp:237] Iteration 89500, loss = 1.22162
I0523 19:31:52.152690 15542 solver.cpp:253]     Train net output #0: loss = 1.22162 (* 1 = 1.22162 loss)
I0523 19:31:52.152704 15542 sgd_solver.cpp:106] Iteration 89500, lr = 0.0035
I0523 19:32:01.166996 15542 solver.cpp:237] Iteration 89750, loss = 1.05022
I0523 19:32:01.167032 15542 solver.cpp:253]     Train net output #0: loss = 1.05022 (* 1 = 1.05022 loss)
I0523 19:32:01.167048 15542 sgd_solver.cpp:106] Iteration 89750, lr = 0.0035
I0523 19:32:10.149749 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_90000.caffemodel
I0523 19:32:10.215663 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_90000.solverstate
I0523 19:32:10.244050 15542 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 19:33:18.438558 15542 solver.cpp:409]     Test net output #0: accuracy = 0.89354
I0523 19:33:18.438746 15542 solver.cpp:409]     Test net output #1: loss = 0.338326 (* 1 = 0.338326 loss)
I0523 19:33:39.330811 15542 solver.cpp:237] Iteration 90000, loss = 0.973034
I0523 19:33:39.330863 15542 solver.cpp:253]     Train net output #0: loss = 0.973034 (* 1 = 0.973034 loss)
I0523 19:33:39.330878 15542 sgd_solver.cpp:106] Iteration 90000, lr = 0.0035
I0523 19:33:48.426518 15542 solver.cpp:237] Iteration 90250, loss = 1.01464
I0523 19:33:48.426553 15542 solver.cpp:253]     Train net output #0: loss = 1.01464 (* 1 = 1.01464 loss)
I0523 19:33:48.426568 15542 sgd_solver.cpp:106] Iteration 90250, lr = 0.0035
I0523 19:33:57.527575 15542 solver.cpp:237] Iteration 90500, loss = 1.39933
I0523 19:33:57.527761 15542 solver.cpp:253]     Train net output #0: loss = 1.39933 (* 1 = 1.39933 loss)
I0523 19:33:57.527776 15542 sgd_solver.cpp:106] Iteration 90500, lr = 0.0035
I0523 19:34:06.629010 15542 solver.cpp:237] Iteration 90750, loss = 1.12981
I0523 19:34:06.629045 15542 solver.cpp:253]     Train net output #0: loss = 1.12981 (* 1 = 1.12981 loss)
I0523 19:34:06.629070 15542 sgd_solver.cpp:106] Iteration 90750, lr = 0.0035
I0523 19:34:15.731798 15542 solver.cpp:237] Iteration 91000, loss = 1.40868
I0523 19:34:15.731842 15542 solver.cpp:253]     Train net output #0: loss = 1.40868 (* 1 = 1.40868 loss)
I0523 19:34:15.731856 15542 sgd_solver.cpp:106] Iteration 91000, lr = 0.0035
I0523 19:34:24.822067 15542 solver.cpp:237] Iteration 91250, loss = 1.04062
I0523 19:34:24.822103 15542 solver.cpp:253]     Train net output #0: loss = 1.04062 (* 1 = 1.04062 loss)
I0523 19:34:24.822119 15542 sgd_solver.cpp:106] Iteration 91250, lr = 0.0035
I0523 19:34:33.922035 15542 solver.cpp:237] Iteration 91500, loss = 1.18659
I0523 19:34:33.922215 15542 solver.cpp:253]     Train net output #0: loss = 1.18659 (* 1 = 1.18659 loss)
I0523 19:34:33.922230 15542 sgd_solver.cpp:106] Iteration 91500, lr = 0.0035
I0523 19:35:03.879338 15542 solver.cpp:237] Iteration 91750, loss = 1.13048
I0523 19:35:03.879390 15542 solver.cpp:253]     Train net output #0: loss = 1.13048 (* 1 = 1.13048 loss)
I0523 19:35:03.879406 15542 sgd_solver.cpp:106] Iteration 91750, lr = 0.0035
I0523 19:35:12.973983 15542 solver.cpp:237] Iteration 92000, loss = 1.16219
I0523 19:35:12.974164 15542 solver.cpp:253]     Train net output #0: loss = 1.16219 (* 1 = 1.16219 loss)
I0523 19:35:12.974177 15542 sgd_solver.cpp:106] Iteration 92000, lr = 0.0035
I0523 19:35:22.069034 15542 solver.cpp:237] Iteration 92250, loss = 1.1658
I0523 19:35:22.069074 15542 solver.cpp:253]     Train net output #0: loss = 1.1658 (* 1 = 1.1658 loss)
I0523 19:35:22.069092 15542 sgd_solver.cpp:106] Iteration 92250, lr = 0.0035
I0523 19:35:31.120447 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_92500.caffemodel
I0523 19:35:31.183787 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_92500.solverstate
I0523 19:35:31.221451 15542 solver.cpp:237] Iteration 92500, loss = 1.01513
I0523 19:35:31.221489 15542 solver.cpp:253]     Train net output #0: loss = 1.01513 (* 1 = 1.01513 loss)
I0523 19:35:31.221508 15542 sgd_solver.cpp:106] Iteration 92500, lr = 0.0035
I0523 19:35:40.324785 15542 solver.cpp:237] Iteration 92750, loss = 1.06218
I0523 19:35:40.324820 15542 solver.cpp:253]     Train net output #0: loss = 1.06218 (* 1 = 1.06218 loss)
I0523 19:35:40.324834 15542 sgd_solver.cpp:106] Iteration 92750, lr = 0.0035
I0523 19:35:49.428908 15542 solver.cpp:237] Iteration 93000, loss = 1.20468
I0523 19:35:49.429086 15542 solver.cpp:253]     Train net output #0: loss = 1.20468 (* 1 = 1.20468 loss)
I0523 19:35:49.429100 15542 sgd_solver.cpp:106] Iteration 93000, lr = 0.0035
I0523 19:35:58.530102 15542 solver.cpp:237] Iteration 93250, loss = 1.02691
I0523 19:35:58.530143 15542 solver.cpp:253]     Train net output #0: loss = 1.02691 (* 1 = 1.02691 loss)
I0523 19:35:58.530164 15542 sgd_solver.cpp:106] Iteration 93250, lr = 0.0035
I0523 19:36:28.534217 15542 solver.cpp:237] Iteration 93500, loss = 1.02799
I0523 19:36:28.534422 15542 solver.cpp:253]     Train net output #0: loss = 1.02799 (* 1 = 1.02799 loss)
I0523 19:36:28.534436 15542 sgd_solver.cpp:106] Iteration 93500, lr = 0.0035
I0523 19:36:37.644457 15542 solver.cpp:237] Iteration 93750, loss = 1.18127
I0523 19:36:37.644492 15542 solver.cpp:253]     Train net output #0: loss = 1.18127 (* 1 = 1.18127 loss)
I0523 19:36:37.644510 15542 sgd_solver.cpp:106] Iteration 93750, lr = 0.0035
I0523 19:36:46.747078 15542 solver.cpp:237] Iteration 94000, loss = 1.3122
I0523 19:36:46.747122 15542 solver.cpp:253]     Train net output #0: loss = 1.3122 (* 1 = 1.3122 loss)
I0523 19:36:46.747136 15542 sgd_solver.cpp:106] Iteration 94000, lr = 0.0035
I0523 19:36:55.855497 15542 solver.cpp:237] Iteration 94250, loss = 1.50692
I0523 19:36:55.855532 15542 solver.cpp:253]     Train net output #0: loss = 1.50692 (* 1 = 1.50692 loss)
I0523 19:36:55.855548 15542 sgd_solver.cpp:106] Iteration 94250, lr = 0.0035
I0523 19:37:04.952260 15542 solver.cpp:237] Iteration 94500, loss = 1.01565
I0523 19:37:04.952441 15542 solver.cpp:253]     Train net output #0: loss = 1.01565 (* 1 = 1.01565 loss)
I0523 19:37:04.952455 15542 sgd_solver.cpp:106] Iteration 94500, lr = 0.0035
I0523 19:37:14.059427 15542 solver.cpp:237] Iteration 94750, loss = 1.32836
I0523 19:37:14.059473 15542 solver.cpp:253]     Train net output #0: loss = 1.32836 (* 1 = 1.32836 loss)
I0523 19:37:14.059489 15542 sgd_solver.cpp:106] Iteration 94750, lr = 0.0035
I0523 19:37:23.120641 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_95000.caffemodel
I0523 19:37:23.183182 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_95000.solverstate
I0523 19:37:23.209422 15542 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 19:38:10.198343 15542 solver.cpp:409]     Test net output #0: accuracy = 0.894499
I0523 19:38:10.198534 15542 solver.cpp:409]     Test net output #1: loss = 0.325075 (* 1 = 0.325075 loss)
I0523 19:38:31.083941 15542 solver.cpp:237] Iteration 95000, loss = 1.15718
I0523 19:38:31.083992 15542 solver.cpp:253]     Train net output #0: loss = 1.15718 (* 1 = 1.15718 loss)
I0523 19:38:31.084007 15542 sgd_solver.cpp:106] Iteration 95000, lr = 0.0035
I0523 19:38:40.160169 15542 solver.cpp:237] Iteration 95250, loss = 1.06421
I0523 19:38:40.160203 15542 solver.cpp:253]     Train net output #0: loss = 1.06421 (* 1 = 1.06421 loss)
I0523 19:38:40.160223 15542 sgd_solver.cpp:106] Iteration 95250, lr = 0.0035
I0523 19:38:49.239451 15542 solver.cpp:237] Iteration 95500, loss = 1.072
I0523 19:38:49.239626 15542 solver.cpp:253]     Train net output #0: loss = 1.072 (* 1 = 1.072 loss)
I0523 19:38:49.239640 15542 sgd_solver.cpp:106] Iteration 95500, lr = 0.0035
I0523 19:38:58.317430 15542 solver.cpp:237] Iteration 95750, loss = 1.05826
I0523 19:38:58.317463 15542 solver.cpp:253]     Train net output #0: loss = 1.05826 (* 1 = 1.05826 loss)
I0523 19:38:58.317486 15542 sgd_solver.cpp:106] Iteration 95750, lr = 0.0035
I0523 19:39:07.393610 15542 solver.cpp:237] Iteration 96000, loss = 1.2879
I0523 19:39:07.393645 15542 solver.cpp:253]     Train net output #0: loss = 1.2879 (* 1 = 1.2879 loss)
I0523 19:39:07.393661 15542 sgd_solver.cpp:106] Iteration 96000, lr = 0.0035
I0523 19:39:16.474215 15542 solver.cpp:237] Iteration 96250, loss = 1.25265
I0523 19:39:16.474263 15542 solver.cpp:253]     Train net output #0: loss = 1.25265 (* 1 = 1.25265 loss)
I0523 19:39:16.474277 15542 sgd_solver.cpp:106] Iteration 96250, lr = 0.0035
I0523 19:39:25.548043 15542 solver.cpp:237] Iteration 96500, loss = 1.16926
I0523 19:39:25.548215 15542 solver.cpp:253]     Train net output #0: loss = 1.16926 (* 1 = 1.16926 loss)
I0523 19:39:25.548230 15542 sgd_solver.cpp:106] Iteration 96500, lr = 0.0035
I0523 19:39:55.497875 15542 solver.cpp:237] Iteration 96750, loss = 1.16119
I0523 19:39:55.497925 15542 solver.cpp:253]     Train net output #0: loss = 1.16119 (* 1 = 1.16119 loss)
I0523 19:39:55.497943 15542 sgd_solver.cpp:106] Iteration 96750, lr = 0.0035
I0523 19:40:04.572228 15542 solver.cpp:237] Iteration 97000, loss = 0.989171
I0523 19:40:04.572408 15542 solver.cpp:253]     Train net output #0: loss = 0.989171 (* 1 = 0.989171 loss)
I0523 19:40:04.572422 15542 sgd_solver.cpp:106] Iteration 97000, lr = 0.0035
I0523 19:40:13.644451 15542 solver.cpp:237] Iteration 97250, loss = 1.18765
I0523 19:40:13.644495 15542 solver.cpp:253]     Train net output #0: loss = 1.18765 (* 1 = 1.18765 loss)
I0523 19:40:13.644513 15542 sgd_solver.cpp:106] Iteration 97250, lr = 0.0035
I0523 19:40:22.682186 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_97500.caffemodel
I0523 19:40:22.746078 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_97500.solverstate
I0523 19:40:22.783624 15542 solver.cpp:237] Iteration 97500, loss = 1.47429
I0523 19:40:22.783669 15542 solver.cpp:253]     Train net output #0: loss = 1.47429 (* 1 = 1.47429 loss)
I0523 19:40:22.783684 15542 sgd_solver.cpp:106] Iteration 97500, lr = 0.0035
I0523 19:40:31.857177 15542 solver.cpp:237] Iteration 97750, loss = 1.25473
I0523 19:40:31.857225 15542 solver.cpp:253]     Train net output #0: loss = 1.25473 (* 1 = 1.25473 loss)
I0523 19:40:31.857239 15542 sgd_solver.cpp:106] Iteration 97750, lr = 0.0035
I0523 19:40:40.933235 15542 solver.cpp:237] Iteration 98000, loss = 1.02685
I0523 19:40:40.933423 15542 solver.cpp:253]     Train net output #0: loss = 1.02685 (* 1 = 1.02685 loss)
I0523 19:40:40.933436 15542 sgd_solver.cpp:106] Iteration 98000, lr = 0.0035
I0523 19:40:50.009846 15542 solver.cpp:237] Iteration 98250, loss = 1.09979
I0523 19:40:50.009881 15542 solver.cpp:253]     Train net output #0: loss = 1.09979 (* 1 = 1.09979 loss)
I0523 19:40:50.009898 15542 sgd_solver.cpp:106] Iteration 98250, lr = 0.0035
I0523 19:41:19.967087 15542 solver.cpp:237] Iteration 98500, loss = 1.11978
I0523 19:41:19.967295 15542 solver.cpp:253]     Train net output #0: loss = 1.11978 (* 1 = 1.11978 loss)
I0523 19:41:19.967311 15542 sgd_solver.cpp:106] Iteration 98500, lr = 0.0035
I0523 19:41:29.047045 15542 solver.cpp:237] Iteration 98750, loss = 1.27622
I0523 19:41:29.047085 15542 solver.cpp:253]     Train net output #0: loss = 1.27622 (* 1 = 1.27622 loss)
I0523 19:41:29.047104 15542 sgd_solver.cpp:106] Iteration 98750, lr = 0.0035
I0523 19:41:38.119009 15542 solver.cpp:237] Iteration 99000, loss = 1.30085
I0523 19:41:38.119043 15542 solver.cpp:253]     Train net output #0: loss = 1.30085 (* 1 = 1.30085 loss)
I0523 19:41:38.119060 15542 sgd_solver.cpp:106] Iteration 99000, lr = 0.0035
I0523 19:41:47.198825 15542 solver.cpp:237] Iteration 99250, loss = 1.44638
I0523 19:41:47.198873 15542 solver.cpp:253]     Train net output #0: loss = 1.44638 (* 1 = 1.44638 loss)
I0523 19:41:47.198889 15542 sgd_solver.cpp:106] Iteration 99250, lr = 0.0035
I0523 19:41:56.280345 15542 solver.cpp:237] Iteration 99500, loss = 1.01049
I0523 19:41:56.280520 15542 solver.cpp:253]     Train net output #0: loss = 1.01049 (* 1 = 1.01049 loss)
I0523 19:41:56.280534 15542 sgd_solver.cpp:106] Iteration 99500, lr = 0.0035
I0523 19:42:05.355619 15542 solver.cpp:237] Iteration 99750, loss = 1.1157
I0523 19:42:05.355654 15542 solver.cpp:253]     Train net output #0: loss = 1.1157 (* 1 = 1.1157 loss)
I0523 19:42:05.355670 15542 sgd_solver.cpp:106] Iteration 99750, lr = 0.0035
I0523 19:42:14.394115 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_100000.caffemodel
I0523 19:42:14.458655 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_100000.solverstate
I0523 19:42:14.485736 15542 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 19:43:22.673399 15542 solver.cpp:409]     Test net output #0: accuracy = 0.894972
I0523 19:43:22.673593 15542 solver.cpp:409]     Test net output #1: loss = 0.342951 (* 1 = 0.342951 loss)
I0523 19:43:43.544096 15542 solver.cpp:237] Iteration 100000, loss = 1.36362
I0523 19:43:43.544149 15542 solver.cpp:253]     Train net output #0: loss = 1.36362 (* 1 = 1.36362 loss)
I0523 19:43:43.544167 15542 sgd_solver.cpp:106] Iteration 100000, lr = 0.0035
I0523 19:43:52.662039 15542 solver.cpp:237] Iteration 100250, loss = 0.950533
I0523 19:43:52.662082 15542 solver.cpp:253]     Train net output #0: loss = 0.950533 (* 1 = 0.950533 loss)
I0523 19:43:52.662099 15542 sgd_solver.cpp:106] Iteration 100250, lr = 0.0035
I0523 19:44:01.783223 15542 solver.cpp:237] Iteration 100500, loss = 1.58511
I0523 19:44:01.783413 15542 solver.cpp:253]     Train net output #0: loss = 1.58511 (* 1 = 1.58511 loss)
I0523 19:44:01.783427 15542 sgd_solver.cpp:106] Iteration 100500, lr = 0.0035
I0523 19:44:10.897126 15542 solver.cpp:237] Iteration 100750, loss = 1.25819
I0523 19:44:10.897161 15542 solver.cpp:253]     Train net output #0: loss = 1.25819 (* 1 = 1.25819 loss)
I0523 19:44:10.897178 15542 sgd_solver.cpp:106] Iteration 100750, lr = 0.0035
I0523 19:44:20.026042 15542 solver.cpp:237] Iteration 101000, loss = 1.08548
I0523 19:44:20.026085 15542 solver.cpp:253]     Train net output #0: loss = 1.08548 (* 1 = 1.08548 loss)
I0523 19:44:20.026103 15542 sgd_solver.cpp:106] Iteration 101000, lr = 0.0035
I0523 19:44:29.157416 15542 solver.cpp:237] Iteration 101250, loss = 1.19977
I0523 19:44:29.157450 15542 solver.cpp:253]     Train net output #0: loss = 1.19977 (* 1 = 1.19977 loss)
I0523 19:44:29.157467 15542 sgd_solver.cpp:106] Iteration 101250, lr = 0.0035
I0523 19:44:38.278079 15542 solver.cpp:237] Iteration 101500, loss = 1.38059
I0523 19:44:38.278256 15542 solver.cpp:253]     Train net output #0: loss = 1.38059 (* 1 = 1.38059 loss)
I0523 19:44:38.278270 15542 sgd_solver.cpp:106] Iteration 101500, lr = 0.0035
I0523 19:45:08.266337 15542 solver.cpp:237] Iteration 101750, loss = 1.34839
I0523 19:45:08.266387 15542 solver.cpp:253]     Train net output #0: loss = 1.34839 (* 1 = 1.34839 loss)
I0523 19:45:08.266405 15542 sgd_solver.cpp:106] Iteration 101750, lr = 0.0035
I0523 19:45:17.387259 15542 solver.cpp:237] Iteration 102000, loss = 1.131
I0523 19:45:17.387439 15542 solver.cpp:253]     Train net output #0: loss = 1.131 (* 1 = 1.131 loss)
I0523 19:45:17.387451 15542 sgd_solver.cpp:106] Iteration 102000, lr = 0.0035
I0523 19:45:26.502908 15542 solver.cpp:237] Iteration 102250, loss = 1.11336
I0523 19:45:26.502943 15542 solver.cpp:253]     Train net output #0: loss = 1.11336 (* 1 = 1.11336 loss)
I0523 19:45:26.502959 15542 sgd_solver.cpp:106] Iteration 102250, lr = 0.0035
I0523 19:45:35.582684 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_102500.caffemodel
I0523 19:45:35.645212 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_102500.solverstate
I0523 19:45:35.682154 15542 solver.cpp:237] Iteration 102500, loss = 1.05552
I0523 19:45:35.682195 15542 solver.cpp:253]     Train net output #0: loss = 1.05552 (* 1 = 1.05552 loss)
I0523 19:45:35.682214 15542 sgd_solver.cpp:106] Iteration 102500, lr = 0.0035
I0523 19:45:44.799593 15542 solver.cpp:237] Iteration 102750, loss = 1.20038
I0523 19:45:44.799629 15542 solver.cpp:253]     Train net output #0: loss = 1.20038 (* 1 = 1.20038 loss)
I0523 19:45:44.799643 15542 sgd_solver.cpp:106] Iteration 102750, lr = 0.0035
I0523 19:45:53.914068 15542 solver.cpp:237] Iteration 103000, loss = 1.01553
I0523 19:45:53.914257 15542 solver.cpp:253]     Train net output #0: loss = 1.01553 (* 1 = 1.01553 loss)
I0523 19:45:53.914269 15542 sgd_solver.cpp:106] Iteration 103000, lr = 0.0035
I0523 19:46:03.026113 15542 solver.cpp:237] Iteration 103250, loss = 1.02445
I0523 19:46:03.026152 15542 solver.cpp:253]     Train net output #0: loss = 1.02445 (* 1 = 1.02445 loss)
I0523 19:46:03.026170 15542 sgd_solver.cpp:106] Iteration 103250, lr = 0.0035
I0523 19:46:33.009160 15542 solver.cpp:237] Iteration 103500, loss = 1.09857
I0523 19:46:33.009356 15542 solver.cpp:253]     Train net output #0: loss = 1.09857 (* 1 = 1.09857 loss)
I0523 19:46:33.009371 15542 sgd_solver.cpp:106] Iteration 103500, lr = 0.0035
I0523 19:46:42.130101 15542 solver.cpp:237] Iteration 103750, loss = 0.954498
I0523 19:46:42.130136 15542 solver.cpp:253]     Train net output #0: loss = 0.954498 (* 1 = 0.954498 loss)
I0523 19:46:42.130151 15542 sgd_solver.cpp:106] Iteration 103750, lr = 0.0035
I0523 19:46:51.255190 15542 solver.cpp:237] Iteration 104000, loss = 1.27002
I0523 19:46:51.255239 15542 solver.cpp:253]     Train net output #0: loss = 1.27002 (* 1 = 1.27002 loss)
I0523 19:46:51.255254 15542 sgd_solver.cpp:106] Iteration 104000, lr = 0.0035
I0523 19:47:00.370005 15542 solver.cpp:237] Iteration 104250, loss = 1.09676
I0523 19:47:00.370040 15542 solver.cpp:253]     Train net output #0: loss = 1.09676 (* 1 = 1.09676 loss)
I0523 19:47:00.370055 15542 sgd_solver.cpp:106] Iteration 104250, lr = 0.0035
I0523 19:47:09.487197 15542 solver.cpp:237] Iteration 104500, loss = 1.13991
I0523 19:47:09.487385 15542 solver.cpp:253]     Train net output #0: loss = 1.13991 (* 1 = 1.13991 loss)
I0523 19:47:09.487397 15542 sgd_solver.cpp:106] Iteration 104500, lr = 0.0035
I0523 19:47:18.606016 15542 solver.cpp:237] Iteration 104750, loss = 0.986082
I0523 19:47:18.606055 15542 solver.cpp:253]     Train net output #0: loss = 0.986082 (* 1 = 0.986082 loss)
I0523 19:47:18.606076 15542 sgd_solver.cpp:106] Iteration 104750, lr = 0.0035
I0523 19:47:27.680294 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_105000.caffemodel
I0523 19:47:27.744721 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_105000.solverstate
I0523 19:47:27.770928 15542 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 19:48:15.068564 15542 solver.cpp:409]     Test net output #0: accuracy = 0.89606
I0523 19:48:15.068761 15542 solver.cpp:409]     Test net output #1: loss = 0.330568 (* 1 = 0.330568 loss)
I0523 19:48:35.969207 15542 solver.cpp:237] Iteration 105000, loss = 0.866824
I0523 19:48:35.969259 15542 solver.cpp:253]     Train net output #0: loss = 0.866824 (* 1 = 0.866824 loss)
I0523 19:48:35.969275 15542 sgd_solver.cpp:106] Iteration 105000, lr = 0.0035
I0523 19:48:45.006784 15542 solver.cpp:237] Iteration 105250, loss = 1.07647
I0523 19:48:45.006819 15542 solver.cpp:253]     Train net output #0: loss = 1.07647 (* 1 = 1.07647 loss)
I0523 19:48:45.006834 15542 sgd_solver.cpp:106] Iteration 105250, lr = 0.0035
I0523 19:48:54.045485 15542 solver.cpp:237] Iteration 105500, loss = 1.52521
I0523 19:48:54.045677 15542 solver.cpp:253]     Train net output #0: loss = 1.52521 (* 1 = 1.52521 loss)
I0523 19:48:54.045692 15542 sgd_solver.cpp:106] Iteration 105500, lr = 0.0035
I0523 19:49:03.084384 15542 solver.cpp:237] Iteration 105750, loss = 1.35102
I0523 19:49:03.084419 15542 solver.cpp:253]     Train net output #0: loss = 1.35102 (* 1 = 1.35102 loss)
I0523 19:49:03.084437 15542 sgd_solver.cpp:106] Iteration 105750, lr = 0.0035
I0523 19:49:12.118170 15542 solver.cpp:237] Iteration 106000, loss = 0.945141
I0523 19:49:12.118206 15542 solver.cpp:253]     Train net output #0: loss = 0.945141 (* 1 = 0.945141 loss)
I0523 19:49:12.118221 15542 sgd_solver.cpp:106] Iteration 106000, lr = 0.0035
I0523 19:49:21.152343 15542 solver.cpp:237] Iteration 106250, loss = 1.14829
I0523 19:49:21.152385 15542 solver.cpp:253]     Train net output #0: loss = 1.14829 (* 1 = 1.14829 loss)
I0523 19:49:21.152402 15542 sgd_solver.cpp:106] Iteration 106250, lr = 0.0035
I0523 19:49:30.196359 15542 solver.cpp:237] Iteration 106500, loss = 0.962599
I0523 19:49:30.196535 15542 solver.cpp:253]     Train net output #0: loss = 0.962599 (* 1 = 0.962599 loss)
I0523 19:49:30.196550 15542 sgd_solver.cpp:106] Iteration 106500, lr = 0.0035
I0523 19:50:00.117678 15542 solver.cpp:237] Iteration 106750, loss = 1.17205
I0523 19:50:00.117727 15542 solver.cpp:253]     Train net output #0: loss = 1.17205 (* 1 = 1.17205 loss)
I0523 19:50:00.117744 15542 sgd_solver.cpp:106] Iteration 106750, lr = 0.0035
I0523 19:50:09.148701 15542 solver.cpp:237] Iteration 107000, loss = 0.925469
I0523 19:50:09.148895 15542 solver.cpp:253]     Train net output #0: loss = 0.925469 (* 1 = 0.925469 loss)
I0523 19:50:09.148910 15542 sgd_solver.cpp:106] Iteration 107000, lr = 0.0035
I0523 19:50:18.194174 15542 solver.cpp:237] Iteration 107250, loss = 1.09027
I0523 19:50:18.194208 15542 solver.cpp:253]     Train net output #0: loss = 1.09027 (* 1 = 1.09027 loss)
I0523 19:50:18.194226 15542 sgd_solver.cpp:106] Iteration 107250, lr = 0.0035
I0523 19:50:27.189849 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_107500.caffemodel
I0523 19:50:27.252826 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_107500.solverstate
I0523 19:50:27.289387 15542 solver.cpp:237] Iteration 107500, loss = 1.21373
I0523 19:50:27.289433 15542 solver.cpp:253]     Train net output #0: loss = 1.21373 (* 1 = 1.21373 loss)
I0523 19:50:27.289448 15542 sgd_solver.cpp:106] Iteration 107500, lr = 0.0035
I0523 19:50:36.326912 15542 solver.cpp:237] Iteration 107750, loss = 1.04239
I0523 19:50:36.326953 15542 solver.cpp:253]     Train net output #0: loss = 1.04239 (* 1 = 1.04239 loss)
I0523 19:50:36.326973 15542 sgd_solver.cpp:106] Iteration 107750, lr = 0.0035
I0523 19:50:45.364145 15542 solver.cpp:237] Iteration 108000, loss = 1.12571
I0523 19:50:45.364336 15542 solver.cpp:253]     Train net output #0: loss = 1.12571 (* 1 = 1.12571 loss)
I0523 19:50:45.364351 15542 sgd_solver.cpp:106] Iteration 108000, lr = 0.0035
I0523 19:50:54.399137 15542 solver.cpp:237] Iteration 108250, loss = 1.10657
I0523 19:50:54.399170 15542 solver.cpp:253]     Train net output #0: loss = 1.10657 (* 1 = 1.10657 loss)
I0523 19:50:54.399186 15542 sgd_solver.cpp:106] Iteration 108250, lr = 0.0035
I0523 19:51:24.295297 15542 solver.cpp:237] Iteration 108500, loss = 1.12859
I0523 19:51:24.295496 15542 solver.cpp:253]     Train net output #0: loss = 1.12859 (* 1 = 1.12859 loss)
I0523 19:51:24.295511 15542 sgd_solver.cpp:106] Iteration 108500, lr = 0.0035
I0523 19:51:33.327982 15542 solver.cpp:237] Iteration 108750, loss = 1.1557
I0523 19:51:33.328016 15542 solver.cpp:253]     Train net output #0: loss = 1.1557 (* 1 = 1.1557 loss)
I0523 19:51:33.328032 15542 sgd_solver.cpp:106] Iteration 108750, lr = 0.0035
I0523 19:51:42.367782 15542 solver.cpp:237] Iteration 109000, loss = 1.28603
I0523 19:51:42.367816 15542 solver.cpp:253]     Train net output #0: loss = 1.28603 (* 1 = 1.28603 loss)
I0523 19:51:42.367833 15542 sgd_solver.cpp:106] Iteration 109000, lr = 0.0035
I0523 19:51:51.409548 15542 solver.cpp:237] Iteration 109250, loss = 0.954337
I0523 19:51:51.409597 15542 solver.cpp:253]     Train net output #0: loss = 0.954337 (* 1 = 0.954337 loss)
I0523 19:51:51.409611 15542 sgd_solver.cpp:106] Iteration 109250, lr = 0.0035
I0523 19:52:00.444195 15542 solver.cpp:237] Iteration 109500, loss = 1.2895
I0523 19:52:00.444371 15542 solver.cpp:253]     Train net output #0: loss = 1.2895 (* 1 = 1.2895 loss)
I0523 19:52:00.444386 15542 sgd_solver.cpp:106] Iteration 109500, lr = 0.0035
I0523 19:52:09.480248 15542 solver.cpp:237] Iteration 109750, loss = 0.884228
I0523 19:52:09.480283 15542 solver.cpp:253]     Train net output #0: loss = 0.884229 (* 1 = 0.884229 loss)
I0523 19:52:09.480299 15542 sgd_solver.cpp:106] Iteration 109750, lr = 0.0035
I0523 19:52:18.479750 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_110000.caffemodel
I0523 19:52:18.548828 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_110000.solverstate
I0523 19:52:18.575243 15542 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 19:53:26.716100 15542 solver.cpp:409]     Test net output #0: accuracy = 0.895791
I0523 19:53:26.716295 15542 solver.cpp:409]     Test net output #1: loss = 0.353399 (* 1 = 0.353399 loss)
I0523 19:53:47.614449 15542 solver.cpp:237] Iteration 110000, loss = 1.0082
I0523 19:53:47.614498 15542 solver.cpp:253]     Train net output #0: loss = 1.0082 (* 1 = 1.0082 loss)
I0523 19:53:47.614513 15542 sgd_solver.cpp:106] Iteration 110000, lr = 0.0035
I0523 19:53:56.666637 15542 solver.cpp:237] Iteration 110250, loss = 1.29152
I0523 19:53:56.666683 15542 solver.cpp:253]     Train net output #0: loss = 1.29152 (* 1 = 1.29152 loss)
I0523 19:53:56.666702 15542 sgd_solver.cpp:106] Iteration 110250, lr = 0.0035
I0523 19:54:05.708317 15542 solver.cpp:237] Iteration 110500, loss = 1.22786
I0523 19:54:05.708509 15542 solver.cpp:253]     Train net output #0: loss = 1.22786 (* 1 = 1.22786 loss)
I0523 19:54:05.708523 15542 sgd_solver.cpp:106] Iteration 110500, lr = 0.0035
I0523 19:54:14.757735 15542 solver.cpp:237] Iteration 110750, loss = 1.04833
I0523 19:54:14.757769 15542 solver.cpp:253]     Train net output #0: loss = 1.04833 (* 1 = 1.04833 loss)
I0523 19:54:14.757783 15542 sgd_solver.cpp:106] Iteration 110750, lr = 0.0035
I0523 19:54:23.823863 15542 solver.cpp:237] Iteration 111000, loss = 1.06408
I0523 19:54:23.823901 15542 solver.cpp:253]     Train net output #0: loss = 1.06408 (* 1 = 1.06408 loss)
I0523 19:54:23.823921 15542 sgd_solver.cpp:106] Iteration 111000, lr = 0.0035
I0523 19:54:32.897675 15542 solver.cpp:237] Iteration 111250, loss = 1.1692
I0523 19:54:32.897711 15542 solver.cpp:253]     Train net output #0: loss = 1.1692 (* 1 = 1.1692 loss)
I0523 19:54:32.897724 15542 sgd_solver.cpp:106] Iteration 111250, lr = 0.0035
I0523 19:54:41.947111 15542 solver.cpp:237] Iteration 111500, loss = 1.28093
I0523 19:54:41.947299 15542 solver.cpp:253]     Train net output #0: loss = 1.28093 (* 1 = 1.28093 loss)
I0523 19:54:41.947312 15542 sgd_solver.cpp:106] Iteration 111500, lr = 0.0035
I0523 19:55:11.855995 15542 solver.cpp:237] Iteration 111750, loss = 1.15112
I0523 19:55:11.856043 15542 solver.cpp:253]     Train net output #0: loss = 1.15112 (* 1 = 1.15112 loss)
I0523 19:55:11.856060 15542 sgd_solver.cpp:106] Iteration 111750, lr = 0.0035
I0523 19:55:20.919999 15542 solver.cpp:237] Iteration 112000, loss = 1.01614
I0523 19:55:20.920186 15542 solver.cpp:253]     Train net output #0: loss = 1.01614 (* 1 = 1.01614 loss)
I0523 19:55:20.920199 15542 sgd_solver.cpp:106] Iteration 112000, lr = 0.0035
I0523 19:55:29.976547 15542 solver.cpp:237] Iteration 112250, loss = 1.12282
I0523 19:55:29.976580 15542 solver.cpp:253]     Train net output #0: loss = 1.12282 (* 1 = 1.12282 loss)
I0523 19:55:29.976598 15542 sgd_solver.cpp:106] Iteration 112250, lr = 0.0035
I0523 19:55:38.993927 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_112500.caffemodel
I0523 19:55:39.059098 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_112500.solverstate
I0523 19:55:39.097506 15542 solver.cpp:237] Iteration 112500, loss = 1.00423
I0523 19:55:39.097555 15542 solver.cpp:253]     Train net output #0: loss = 1.00423 (* 1 = 1.00423 loss)
I0523 19:55:39.097569 15542 sgd_solver.cpp:106] Iteration 112500, lr = 0.0035
I0523 19:55:48.146416 15542 solver.cpp:237] Iteration 112750, loss = 1.00485
I0523 19:55:48.146451 15542 solver.cpp:253]     Train net output #0: loss = 1.00485 (* 1 = 1.00485 loss)
I0523 19:55:48.146467 15542 sgd_solver.cpp:106] Iteration 112750, lr = 0.0035
I0523 19:55:57.210503 15542 solver.cpp:237] Iteration 113000, loss = 1.30282
I0523 19:55:57.210696 15542 solver.cpp:253]     Train net output #0: loss = 1.30282 (* 1 = 1.30282 loss)
I0523 19:55:57.210711 15542 sgd_solver.cpp:106] Iteration 113000, lr = 0.0035
I0523 19:56:06.259347 15542 solver.cpp:237] Iteration 113250, loss = 1.2122
I0523 19:56:06.259382 15542 solver.cpp:253]     Train net output #0: loss = 1.2122 (* 1 = 1.2122 loss)
I0523 19:56:06.259398 15542 sgd_solver.cpp:106] Iteration 113250, lr = 0.0035
I0523 19:56:36.214601 15542 solver.cpp:237] Iteration 113500, loss = 1.06946
I0523 19:56:36.214814 15542 solver.cpp:253]     Train net output #0: loss = 1.06946 (* 1 = 1.06946 loss)
I0523 19:56:36.214828 15542 sgd_solver.cpp:106] Iteration 113500, lr = 0.0035
I0523 19:56:45.282827 15542 solver.cpp:237] Iteration 113750, loss = 1.0156
I0523 19:56:45.282873 15542 solver.cpp:253]     Train net output #0: loss = 1.0156 (* 1 = 1.0156 loss)
I0523 19:56:45.282889 15542 sgd_solver.cpp:106] Iteration 113750, lr = 0.0035
I0523 19:56:54.348636 15542 solver.cpp:237] Iteration 114000, loss = 1.28178
I0523 19:56:54.348672 15542 solver.cpp:253]     Train net output #0: loss = 1.28178 (* 1 = 1.28178 loss)
I0523 19:56:54.348688 15542 sgd_solver.cpp:106] Iteration 114000, lr = 0.0035
I0523 19:57:03.404963 15542 solver.cpp:237] Iteration 114250, loss = 1.18588
I0523 19:57:03.404997 15542 solver.cpp:253]     Train net output #0: loss = 1.18588 (* 1 = 1.18588 loss)
I0523 19:57:03.405014 15542 sgd_solver.cpp:106] Iteration 114250, lr = 0.0035
I0523 19:57:12.449218 15542 solver.cpp:237] Iteration 114500, loss = 1.30385
I0523 19:57:12.449404 15542 solver.cpp:253]     Train net output #0: loss = 1.30385 (* 1 = 1.30385 loss)
I0523 19:57:12.449419 15542 sgd_solver.cpp:106] Iteration 114500, lr = 0.0035
I0523 19:57:21.502825 15542 solver.cpp:237] Iteration 114750, loss = 0.919916
I0523 19:57:21.502859 15542 solver.cpp:253]     Train net output #0: loss = 0.919916 (* 1 = 0.919916 loss)
I0523 19:57:21.502876 15542 sgd_solver.cpp:106] Iteration 114750, lr = 0.0035
I0523 19:57:30.535007 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_115000.caffemodel
I0523 19:57:30.597762 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_115000.solverstate
I0523 19:57:30.622913 15542 solver.cpp:341] Iteration 115000, Testing net (#0)
I0523 19:58:17.591565 15542 solver.cpp:409]     Test net output #0: accuracy = 0.897192
I0523 19:58:17.591766 15542 solver.cpp:409]     Test net output #1: loss = 0.319887 (* 1 = 0.319887 loss)
I0523 19:58:38.448802 15542 solver.cpp:237] Iteration 115000, loss = 0.856876
I0523 19:58:38.448856 15542 solver.cpp:253]     Train net output #0: loss = 0.856876 (* 1 = 0.856876 loss)
I0523 19:58:38.448871 15542 sgd_solver.cpp:106] Iteration 115000, lr = 0.0035
I0523 19:58:47.467252 15542 solver.cpp:237] Iteration 115250, loss = 1.04816
I0523 19:58:47.467288 15542 solver.cpp:253]     Train net output #0: loss = 1.04816 (* 1 = 1.04816 loss)
I0523 19:58:47.467301 15542 sgd_solver.cpp:106] Iteration 115250, lr = 0.0035
I0523 19:58:56.488585 15542 solver.cpp:237] Iteration 115500, loss = 1.39361
I0523 19:58:56.488773 15542 solver.cpp:253]     Train net output #0: loss = 1.39361 (* 1 = 1.39361 loss)
I0523 19:58:56.488787 15542 sgd_solver.cpp:106] Iteration 115500, lr = 0.0035
I0523 19:59:05.510541 15542 solver.cpp:237] Iteration 115750, loss = 1.17382
I0523 19:59:05.510576 15542 solver.cpp:253]     Train net output #0: loss = 1.17382 (* 1 = 1.17382 loss)
I0523 19:59:05.510591 15542 sgd_solver.cpp:106] Iteration 115750, lr = 0.0035
I0523 19:59:14.530380 15542 solver.cpp:237] Iteration 116000, loss = 1.31963
I0523 19:59:14.530413 15542 solver.cpp:253]     Train net output #0: loss = 1.31963 (* 1 = 1.31963 loss)
I0523 19:59:14.530432 15542 sgd_solver.cpp:106] Iteration 116000, lr = 0.0035
I0523 19:59:23.545451 15542 solver.cpp:237] Iteration 116250, loss = 1.22105
I0523 19:59:23.545485 15542 solver.cpp:253]     Train net output #0: loss = 1.22105 (* 1 = 1.22105 loss)
I0523 19:59:23.545503 15542 sgd_solver.cpp:106] Iteration 116250, lr = 0.0035
I0523 19:59:32.565796 15542 solver.cpp:237] Iteration 116500, loss = 1.07481
I0523 19:59:32.565973 15542 solver.cpp:253]     Train net output #0: loss = 1.07481 (* 1 = 1.07481 loss)
I0523 19:59:32.565986 15542 sgd_solver.cpp:106] Iteration 116500, lr = 0.0035
I0523 20:00:02.486098 15542 solver.cpp:237] Iteration 116750, loss = 1.31047
I0523 20:00:02.486147 15542 solver.cpp:253]     Train net output #0: loss = 1.31047 (* 1 = 1.31047 loss)
I0523 20:00:02.486163 15542 sgd_solver.cpp:106] Iteration 116750, lr = 0.0035
I0523 20:00:11.495261 15542 solver.cpp:237] Iteration 117000, loss = 1.06042
I0523 20:00:11.495467 15542 solver.cpp:253]     Train net output #0: loss = 1.06042 (* 1 = 1.06042 loss)
I0523 20:00:11.495481 15542 sgd_solver.cpp:106] Iteration 117000, lr = 0.0035
I0523 20:00:20.509161 15542 solver.cpp:237] Iteration 117250, loss = 1.19988
I0523 20:00:20.509196 15542 solver.cpp:253]     Train net output #0: loss = 1.19988 (* 1 = 1.19988 loss)
I0523 20:00:20.509213 15542 sgd_solver.cpp:106] Iteration 117250, lr = 0.0035
I0523 20:00:29.495764 15542 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_117500.caffemodel
I0523 20:00:29.558545 15542 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0035_2016-05-20T15.49.11.024507_iter_117500.solverstate
I0523 20:00:29.595079 15542 solver.cpp:237] Iteration 117500, loss = 1.08022
I0523 20:00:29.595124 15542 solver.cpp:253]     Train net output #0: loss = 1.08022 (* 1 = 1.08022 loss)
I0523 20:00:29.595139 15542 sgd_solver.cpp:106] Iteration 117500, lr = 0.0035
I0523 20:00:38.610501 15542 solver.cpp:237] Iteration 117750, loss = 1.22021
I0523 20:00:38.610540 15542 solver.cpp:253]     Train net output #0: loss = 1.22021 (* 1 = 1.22021 loss)
I0523 20:00:38.610558 15542 sgd_solver.cpp:106] Iteration 117750, lr = 0.0035
I0523 20:00:47.628288 15542 solver.cpp:237] Iteration 118000, loss = 1.29016
I0523 20:00:47.628475 15542 solver.cpp:253]     Train net output #0: loss = 1.29016 (* 1 = 1.29016 loss)
I0523 20:00:47.628490 15542 sgd_solver.cpp:106] Iteration 118000, lr = 0.0035
I0523 20:00:56.642357 15542 solver.cpp:237] Iteration 118250, loss = 0.891111
I0523 20:00:56.642405 15542 solver.cpp:253]     Train net output #0: loss = 0.891112 (* 1 = 0.891112 loss)
I0523 20:00:56.642421 15542 sgd_solver.cpp:106] Iteration 118250, lr = 0.0035
aprun: Apid 11257501: Caught signal Terminated, sending to application
*** Aborted at 1464048066 (unix time) try "date -d @1464048066" if you are using GNU date ***
aprun: Apid 11257501: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9b848 (unknown)
aprun: Apid 11257501: Caught signal Terminated, sending to application
*** SIGTERM (@0x3cb3) received by PID 15542 (TID 0x2aaac746f900) from PID 15539; stack trace: ***
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaac5e9b848 (unknown)
    @     0x2aaac5e9c9d5 inflate
=>> PBS: job killed: walltime 7206 exceeded limit 7200
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
    @     0x2aaab128ac92 H5D__chunk_lock
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaab128be08 H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11257501: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11257501: Caught signal Terminated, sending to application
aprun: Apid 11257501: Caught signal Terminated, sending to application
aprun: Apid 11257501: Caught signal Terminated, sending to application
aprun: Apid 11257501: Caught signal Terminated, sending to application
aprun: Apid 11257501: Caught signal Terminated, sending to application
aprun: Apid 11257501: Caught signal Terminated, sending to application
