2811738
I0526 11:33:24.866799 26141 caffe.cpp:184] Using GPUs 0
I0526 11:33:25.297294 26141 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0005
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147.prototxt"
I0526 11:33:25.299057 26141 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147.prototxt
I0526 11:33:25.314393 26141 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 11:33:25.314448 26141 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 11:33:25.314796 26141 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 11:33:25.314980 26141 layer_factory.hpp:77] Creating layer data_hdf5
I0526 11:33:25.315003 26141 net.cpp:106] Creating Layer data_hdf5
I0526 11:33:25.315017 26141 net.cpp:411] data_hdf5 -> data
I0526 11:33:25.315050 26141 net.cpp:411] data_hdf5 -> label
I0526 11:33:25.315083 26141 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 11:33:25.316259 26141 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 11:33:25.318418 26141 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 11:33:46.875738 26141 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 11:33:46.880910 26141 net.cpp:150] Setting up data_hdf5
I0526 11:33:46.880952 26141 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 11:33:46.880966 26141 net.cpp:157] Top shape: 20 (20)
I0526 11:33:46.880976 26141 net.cpp:165] Memory required for data: 508080
I0526 11:33:46.880990 26141 layer_factory.hpp:77] Creating layer conv1
I0526 11:33:46.881023 26141 net.cpp:106] Creating Layer conv1
I0526 11:33:46.881036 26141 net.cpp:454] conv1 <- data
I0526 11:33:46.881057 26141 net.cpp:411] conv1 -> conv1
I0526 11:33:47.880710 26141 net.cpp:150] Setting up conv1
I0526 11:33:47.880759 26141 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 11:33:47.880769 26141 net.cpp:165] Memory required for data: 6037680
I0526 11:33:47.880797 26141 layer_factory.hpp:77] Creating layer relu1
I0526 11:33:47.880820 26141 net.cpp:106] Creating Layer relu1
I0526 11:33:47.880830 26141 net.cpp:454] relu1 <- conv1
I0526 11:33:47.880843 26141 net.cpp:397] relu1 -> conv1 (in-place)
I0526 11:33:47.881362 26141 net.cpp:150] Setting up relu1
I0526 11:33:47.881379 26141 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 11:33:47.881391 26141 net.cpp:165] Memory required for data: 11567280
I0526 11:33:47.881400 26141 layer_factory.hpp:77] Creating layer pool1
I0526 11:33:47.881417 26141 net.cpp:106] Creating Layer pool1
I0526 11:33:47.881427 26141 net.cpp:454] pool1 <- conv1
I0526 11:33:47.881441 26141 net.cpp:411] pool1 -> pool1
I0526 11:33:47.881522 26141 net.cpp:150] Setting up pool1
I0526 11:33:47.881536 26141 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 11:33:47.881547 26141 net.cpp:165] Memory required for data: 14332080
I0526 11:33:47.881557 26141 layer_factory.hpp:77] Creating layer conv2
I0526 11:33:47.881579 26141 net.cpp:106] Creating Layer conv2
I0526 11:33:47.881589 26141 net.cpp:454] conv2 <- pool1
I0526 11:33:47.881603 26141 net.cpp:411] conv2 -> conv2
I0526 11:33:47.884312 26141 net.cpp:150] Setting up conv2
I0526 11:33:47.884335 26141 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 11:33:47.884346 26141 net.cpp:165] Memory required for data: 18306480
I0526 11:33:47.884364 26141 layer_factory.hpp:77] Creating layer relu2
I0526 11:33:47.884379 26141 net.cpp:106] Creating Layer relu2
I0526 11:33:47.884389 26141 net.cpp:454] relu2 <- conv2
I0526 11:33:47.884402 26141 net.cpp:397] relu2 -> conv2 (in-place)
I0526 11:33:47.884733 26141 net.cpp:150] Setting up relu2
I0526 11:33:47.884747 26141 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 11:33:47.884757 26141 net.cpp:165] Memory required for data: 22280880
I0526 11:33:47.884768 26141 layer_factory.hpp:77] Creating layer pool2
I0526 11:33:47.884780 26141 net.cpp:106] Creating Layer pool2
I0526 11:33:47.884790 26141 net.cpp:454] pool2 <- conv2
I0526 11:33:47.884802 26141 net.cpp:411] pool2 -> pool2
I0526 11:33:47.884884 26141 net.cpp:150] Setting up pool2
I0526 11:33:47.884897 26141 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 11:33:47.884907 26141 net.cpp:165] Memory required for data: 24268080
I0526 11:33:47.884915 26141 layer_factory.hpp:77] Creating layer conv3
I0526 11:33:47.884933 26141 net.cpp:106] Creating Layer conv3
I0526 11:33:47.884943 26141 net.cpp:454] conv3 <- pool2
I0526 11:33:47.884956 26141 net.cpp:411] conv3 -> conv3
I0526 11:33:47.886906 26141 net.cpp:150] Setting up conv3
I0526 11:33:47.886924 26141 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 11:33:47.886939 26141 net.cpp:165] Memory required for data: 26436400
I0526 11:33:47.886958 26141 layer_factory.hpp:77] Creating layer relu3
I0526 11:33:47.886975 26141 net.cpp:106] Creating Layer relu3
I0526 11:33:47.886984 26141 net.cpp:454] relu3 <- conv3
I0526 11:33:47.886997 26141 net.cpp:397] relu3 -> conv3 (in-place)
I0526 11:33:47.887468 26141 net.cpp:150] Setting up relu3
I0526 11:33:47.887486 26141 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 11:33:47.887496 26141 net.cpp:165] Memory required for data: 28604720
I0526 11:33:47.887506 26141 layer_factory.hpp:77] Creating layer pool3
I0526 11:33:47.887519 26141 net.cpp:106] Creating Layer pool3
I0526 11:33:47.887529 26141 net.cpp:454] pool3 <- conv3
I0526 11:33:47.887542 26141 net.cpp:411] pool3 -> pool3
I0526 11:33:47.887610 26141 net.cpp:150] Setting up pool3
I0526 11:33:47.887624 26141 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 11:33:47.887634 26141 net.cpp:165] Memory required for data: 29688880
I0526 11:33:47.887644 26141 layer_factory.hpp:77] Creating layer conv4
I0526 11:33:47.887660 26141 net.cpp:106] Creating Layer conv4
I0526 11:33:47.887670 26141 net.cpp:454] conv4 <- pool3
I0526 11:33:47.887683 26141 net.cpp:411] conv4 -> conv4
I0526 11:33:47.890403 26141 net.cpp:150] Setting up conv4
I0526 11:33:47.890429 26141 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 11:33:47.890440 26141 net.cpp:165] Memory required for data: 30414640
I0526 11:33:47.890455 26141 layer_factory.hpp:77] Creating layer relu4
I0526 11:33:47.890470 26141 net.cpp:106] Creating Layer relu4
I0526 11:33:47.890480 26141 net.cpp:454] relu4 <- conv4
I0526 11:33:47.890492 26141 net.cpp:397] relu4 -> conv4 (in-place)
I0526 11:33:47.890956 26141 net.cpp:150] Setting up relu4
I0526 11:33:47.890972 26141 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 11:33:47.890982 26141 net.cpp:165] Memory required for data: 31140400
I0526 11:33:47.890992 26141 layer_factory.hpp:77] Creating layer pool4
I0526 11:33:47.891005 26141 net.cpp:106] Creating Layer pool4
I0526 11:33:47.891016 26141 net.cpp:454] pool4 <- conv4
I0526 11:33:47.891027 26141 net.cpp:411] pool4 -> pool4
I0526 11:33:47.891095 26141 net.cpp:150] Setting up pool4
I0526 11:33:47.891109 26141 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 11:33:47.891119 26141 net.cpp:165] Memory required for data: 31503280
I0526 11:33:47.891129 26141 layer_factory.hpp:77] Creating layer ip1
I0526 11:33:47.891149 26141 net.cpp:106] Creating Layer ip1
I0526 11:33:47.891160 26141 net.cpp:454] ip1 <- pool4
I0526 11:33:47.891175 26141 net.cpp:411] ip1 -> ip1
I0526 11:33:47.906630 26141 net.cpp:150] Setting up ip1
I0526 11:33:47.906657 26141 net.cpp:157] Top shape: 20 196 (3920)
I0526 11:33:47.906669 26141 net.cpp:165] Memory required for data: 31518960
I0526 11:33:47.906692 26141 layer_factory.hpp:77] Creating layer relu5
I0526 11:33:47.906707 26141 net.cpp:106] Creating Layer relu5
I0526 11:33:47.906716 26141 net.cpp:454] relu5 <- ip1
I0526 11:33:47.906729 26141 net.cpp:397] relu5 -> ip1 (in-place)
I0526 11:33:47.907073 26141 net.cpp:150] Setting up relu5
I0526 11:33:47.907086 26141 net.cpp:157] Top shape: 20 196 (3920)
I0526 11:33:47.907096 26141 net.cpp:165] Memory required for data: 31534640
I0526 11:33:47.907106 26141 layer_factory.hpp:77] Creating layer drop1
I0526 11:33:47.907130 26141 net.cpp:106] Creating Layer drop1
I0526 11:33:47.907140 26141 net.cpp:454] drop1 <- ip1
I0526 11:33:47.907152 26141 net.cpp:397] drop1 -> ip1 (in-place)
I0526 11:33:47.907212 26141 net.cpp:150] Setting up drop1
I0526 11:33:47.907227 26141 net.cpp:157] Top shape: 20 196 (3920)
I0526 11:33:47.907237 26141 net.cpp:165] Memory required for data: 31550320
I0526 11:33:47.907246 26141 layer_factory.hpp:77] Creating layer ip2
I0526 11:33:47.907264 26141 net.cpp:106] Creating Layer ip2
I0526 11:33:47.907274 26141 net.cpp:454] ip2 <- ip1
I0526 11:33:47.907289 26141 net.cpp:411] ip2 -> ip2
I0526 11:33:47.907752 26141 net.cpp:150] Setting up ip2
I0526 11:33:47.907764 26141 net.cpp:157] Top shape: 20 98 (1960)
I0526 11:33:47.907774 26141 net.cpp:165] Memory required for data: 31558160
I0526 11:33:47.907789 26141 layer_factory.hpp:77] Creating layer relu6
I0526 11:33:47.907802 26141 net.cpp:106] Creating Layer relu6
I0526 11:33:47.907811 26141 net.cpp:454] relu6 <- ip2
I0526 11:33:47.907824 26141 net.cpp:397] relu6 -> ip2 (in-place)
I0526 11:33:47.908342 26141 net.cpp:150] Setting up relu6
I0526 11:33:47.908359 26141 net.cpp:157] Top shape: 20 98 (1960)
I0526 11:33:47.908370 26141 net.cpp:165] Memory required for data: 31566000
I0526 11:33:47.908380 26141 layer_factory.hpp:77] Creating layer drop2
I0526 11:33:47.908395 26141 net.cpp:106] Creating Layer drop2
I0526 11:33:47.908403 26141 net.cpp:454] drop2 <- ip2
I0526 11:33:47.908416 26141 net.cpp:397] drop2 -> ip2 (in-place)
I0526 11:33:47.908459 26141 net.cpp:150] Setting up drop2
I0526 11:33:47.908473 26141 net.cpp:157] Top shape: 20 98 (1960)
I0526 11:33:47.908483 26141 net.cpp:165] Memory required for data: 31573840
I0526 11:33:47.908493 26141 layer_factory.hpp:77] Creating layer ip3
I0526 11:33:47.908506 26141 net.cpp:106] Creating Layer ip3
I0526 11:33:47.908516 26141 net.cpp:454] ip3 <- ip2
I0526 11:33:47.908529 26141 net.cpp:411] ip3 -> ip3
I0526 11:33:47.908740 26141 net.cpp:150] Setting up ip3
I0526 11:33:47.908752 26141 net.cpp:157] Top shape: 20 11 (220)
I0526 11:33:47.908762 26141 net.cpp:165] Memory required for data: 31574720
I0526 11:33:47.908777 26141 layer_factory.hpp:77] Creating layer drop3
I0526 11:33:47.908790 26141 net.cpp:106] Creating Layer drop3
I0526 11:33:47.908799 26141 net.cpp:454] drop3 <- ip3
I0526 11:33:47.908812 26141 net.cpp:397] drop3 -> ip3 (in-place)
I0526 11:33:47.908851 26141 net.cpp:150] Setting up drop3
I0526 11:33:47.908864 26141 net.cpp:157] Top shape: 20 11 (220)
I0526 11:33:47.908874 26141 net.cpp:165] Memory required for data: 31575600
I0526 11:33:47.908885 26141 layer_factory.hpp:77] Creating layer loss
I0526 11:33:47.908903 26141 net.cpp:106] Creating Layer loss
I0526 11:33:47.908913 26141 net.cpp:454] loss <- ip3
I0526 11:33:47.908924 26141 net.cpp:454] loss <- label
I0526 11:33:47.908937 26141 net.cpp:411] loss -> loss
I0526 11:33:47.908954 26141 layer_factory.hpp:77] Creating layer loss
I0526 11:33:47.909593 26141 net.cpp:150] Setting up loss
I0526 11:33:47.909613 26141 net.cpp:157] Top shape: (1)
I0526 11:33:47.909627 26141 net.cpp:160]     with loss weight 1
I0526 11:33:47.909668 26141 net.cpp:165] Memory required for data: 31575604
I0526 11:33:47.909679 26141 net.cpp:226] loss needs backward computation.
I0526 11:33:47.909690 26141 net.cpp:226] drop3 needs backward computation.
I0526 11:33:47.909699 26141 net.cpp:226] ip3 needs backward computation.
I0526 11:33:47.909709 26141 net.cpp:226] drop2 needs backward computation.
I0526 11:33:47.909719 26141 net.cpp:226] relu6 needs backward computation.
I0526 11:33:47.909729 26141 net.cpp:226] ip2 needs backward computation.
I0526 11:33:47.909739 26141 net.cpp:226] drop1 needs backward computation.
I0526 11:33:47.909749 26141 net.cpp:226] relu5 needs backward computation.
I0526 11:33:47.909759 26141 net.cpp:226] ip1 needs backward computation.
I0526 11:33:47.909768 26141 net.cpp:226] pool4 needs backward computation.
I0526 11:33:47.909778 26141 net.cpp:226] relu4 needs backward computation.
I0526 11:33:47.909788 26141 net.cpp:226] conv4 needs backward computation.
I0526 11:33:47.909798 26141 net.cpp:226] pool3 needs backward computation.
I0526 11:33:47.909808 26141 net.cpp:226] relu3 needs backward computation.
I0526 11:33:47.909818 26141 net.cpp:226] conv3 needs backward computation.
I0526 11:33:47.909837 26141 net.cpp:226] pool2 needs backward computation.
I0526 11:33:47.909848 26141 net.cpp:226] relu2 needs backward computation.
I0526 11:33:47.909858 26141 net.cpp:226] conv2 needs backward computation.
I0526 11:33:47.909869 26141 net.cpp:226] pool1 needs backward computation.
I0526 11:33:47.909880 26141 net.cpp:226] relu1 needs backward computation.
I0526 11:33:47.909890 26141 net.cpp:226] conv1 needs backward computation.
I0526 11:33:47.909901 26141 net.cpp:228] data_hdf5 does not need backward computation.
I0526 11:33:47.909910 26141 net.cpp:270] This network produces output loss
I0526 11:33:47.909934 26141 net.cpp:283] Network initialization done.
I0526 11:33:47.911540 26141 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147.prototxt
I0526 11:33:47.911612 26141 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 11:33:47.911968 26141 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 11:33:47.912158 26141 layer_factory.hpp:77] Creating layer data_hdf5
I0526 11:33:47.912173 26141 net.cpp:106] Creating Layer data_hdf5
I0526 11:33:47.912184 26141 net.cpp:411] data_hdf5 -> data
I0526 11:33:47.912201 26141 net.cpp:411] data_hdf5 -> label
I0526 11:33:47.912217 26141 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 11:33:47.913470 26141 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 11:34:09.285790 26141 net.cpp:150] Setting up data_hdf5
I0526 11:34:09.285955 26141 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 11:34:09.285970 26141 net.cpp:157] Top shape: 20 (20)
I0526 11:34:09.285984 26141 net.cpp:165] Memory required for data: 508080
I0526 11:34:09.285997 26141 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 11:34:09.286026 26141 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 11:34:09.286036 26141 net.cpp:454] label_data_hdf5_1_split <- label
I0526 11:34:09.286051 26141 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 11:34:09.286072 26141 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 11:34:09.286145 26141 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 11:34:09.286159 26141 net.cpp:157] Top shape: 20 (20)
I0526 11:34:09.286171 26141 net.cpp:157] Top shape: 20 (20)
I0526 11:34:09.286180 26141 net.cpp:165] Memory required for data: 508240
I0526 11:34:09.286191 26141 layer_factory.hpp:77] Creating layer conv1
I0526 11:34:09.286213 26141 net.cpp:106] Creating Layer conv1
I0526 11:34:09.286224 26141 net.cpp:454] conv1 <- data
I0526 11:34:09.286239 26141 net.cpp:411] conv1 -> conv1
I0526 11:34:09.288168 26141 net.cpp:150] Setting up conv1
I0526 11:34:09.288188 26141 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 11:34:09.288198 26141 net.cpp:165] Memory required for data: 6037840
I0526 11:34:09.288223 26141 layer_factory.hpp:77] Creating layer relu1
I0526 11:34:09.288238 26141 net.cpp:106] Creating Layer relu1
I0526 11:34:09.288247 26141 net.cpp:454] relu1 <- conv1
I0526 11:34:09.288260 26141 net.cpp:397] relu1 -> conv1 (in-place)
I0526 11:34:09.288755 26141 net.cpp:150] Setting up relu1
I0526 11:34:09.288771 26141 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 11:34:09.288781 26141 net.cpp:165] Memory required for data: 11567440
I0526 11:34:09.288791 26141 layer_factory.hpp:77] Creating layer pool1
I0526 11:34:09.288808 26141 net.cpp:106] Creating Layer pool1
I0526 11:34:09.288817 26141 net.cpp:454] pool1 <- conv1
I0526 11:34:09.288830 26141 net.cpp:411] pool1 -> pool1
I0526 11:34:09.288905 26141 net.cpp:150] Setting up pool1
I0526 11:34:09.288918 26141 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 11:34:09.288928 26141 net.cpp:165] Memory required for data: 14332240
I0526 11:34:09.288938 26141 layer_factory.hpp:77] Creating layer conv2
I0526 11:34:09.288956 26141 net.cpp:106] Creating Layer conv2
I0526 11:34:09.288966 26141 net.cpp:454] conv2 <- pool1
I0526 11:34:09.288981 26141 net.cpp:411] conv2 -> conv2
I0526 11:34:09.290899 26141 net.cpp:150] Setting up conv2
I0526 11:34:09.290920 26141 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 11:34:09.290933 26141 net.cpp:165] Memory required for data: 18306640
I0526 11:34:09.290951 26141 layer_factory.hpp:77] Creating layer relu2
I0526 11:34:09.290964 26141 net.cpp:106] Creating Layer relu2
I0526 11:34:09.290974 26141 net.cpp:454] relu2 <- conv2
I0526 11:34:09.290987 26141 net.cpp:397] relu2 -> conv2 (in-place)
I0526 11:34:09.291321 26141 net.cpp:150] Setting up relu2
I0526 11:34:09.291335 26141 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 11:34:09.291345 26141 net.cpp:165] Memory required for data: 22281040
I0526 11:34:09.291355 26141 layer_factory.hpp:77] Creating layer pool2
I0526 11:34:09.291368 26141 net.cpp:106] Creating Layer pool2
I0526 11:34:09.291378 26141 net.cpp:454] pool2 <- conv2
I0526 11:34:09.291390 26141 net.cpp:411] pool2 -> pool2
I0526 11:34:09.291461 26141 net.cpp:150] Setting up pool2
I0526 11:34:09.291474 26141 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 11:34:09.291484 26141 net.cpp:165] Memory required for data: 24268240
I0526 11:34:09.291494 26141 layer_factory.hpp:77] Creating layer conv3
I0526 11:34:09.291512 26141 net.cpp:106] Creating Layer conv3
I0526 11:34:09.291522 26141 net.cpp:454] conv3 <- pool2
I0526 11:34:09.291537 26141 net.cpp:411] conv3 -> conv3
I0526 11:34:09.293503 26141 net.cpp:150] Setting up conv3
I0526 11:34:09.293526 26141 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 11:34:09.293539 26141 net.cpp:165] Memory required for data: 26436560
I0526 11:34:09.293556 26141 layer_factory.hpp:77] Creating layer relu3
I0526 11:34:09.293583 26141 net.cpp:106] Creating Layer relu3
I0526 11:34:09.293593 26141 net.cpp:454] relu3 <- conv3
I0526 11:34:09.293606 26141 net.cpp:397] relu3 -> conv3 (in-place)
I0526 11:34:09.294077 26141 net.cpp:150] Setting up relu3
I0526 11:34:09.294093 26141 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 11:34:09.294103 26141 net.cpp:165] Memory required for data: 28604880
I0526 11:34:09.294114 26141 layer_factory.hpp:77] Creating layer pool3
I0526 11:34:09.294127 26141 net.cpp:106] Creating Layer pool3
I0526 11:34:09.294137 26141 net.cpp:454] pool3 <- conv3
I0526 11:34:09.294149 26141 net.cpp:411] pool3 -> pool3
I0526 11:34:09.294221 26141 net.cpp:150] Setting up pool3
I0526 11:34:09.294235 26141 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 11:34:09.294245 26141 net.cpp:165] Memory required for data: 29689040
I0526 11:34:09.294262 26141 layer_factory.hpp:77] Creating layer conv4
I0526 11:34:09.294281 26141 net.cpp:106] Creating Layer conv4
I0526 11:34:09.294291 26141 net.cpp:454] conv4 <- pool3
I0526 11:34:09.294306 26141 net.cpp:411] conv4 -> conv4
I0526 11:34:09.296360 26141 net.cpp:150] Setting up conv4
I0526 11:34:09.296376 26141 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 11:34:09.296388 26141 net.cpp:165] Memory required for data: 30414800
I0526 11:34:09.296403 26141 layer_factory.hpp:77] Creating layer relu4
I0526 11:34:09.296416 26141 net.cpp:106] Creating Layer relu4
I0526 11:34:09.296427 26141 net.cpp:454] relu4 <- conv4
I0526 11:34:09.296439 26141 net.cpp:397] relu4 -> conv4 (in-place)
I0526 11:34:09.296906 26141 net.cpp:150] Setting up relu4
I0526 11:34:09.296922 26141 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 11:34:09.296932 26141 net.cpp:165] Memory required for data: 31140560
I0526 11:34:09.296942 26141 layer_factory.hpp:77] Creating layer pool4
I0526 11:34:09.296955 26141 net.cpp:106] Creating Layer pool4
I0526 11:34:09.296965 26141 net.cpp:454] pool4 <- conv4
I0526 11:34:09.296978 26141 net.cpp:411] pool4 -> pool4
I0526 11:34:09.297050 26141 net.cpp:150] Setting up pool4
I0526 11:34:09.297065 26141 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 11:34:09.297073 26141 net.cpp:165] Memory required for data: 31503440
I0526 11:34:09.297081 26141 layer_factory.hpp:77] Creating layer ip1
I0526 11:34:09.297097 26141 net.cpp:106] Creating Layer ip1
I0526 11:34:09.297107 26141 net.cpp:454] ip1 <- pool4
I0526 11:34:09.297122 26141 net.cpp:411] ip1 -> ip1
I0526 11:34:09.312567 26141 net.cpp:150] Setting up ip1
I0526 11:34:09.312597 26141 net.cpp:157] Top shape: 20 196 (3920)
I0526 11:34:09.312608 26141 net.cpp:165] Memory required for data: 31519120
I0526 11:34:09.312631 26141 layer_factory.hpp:77] Creating layer relu5
I0526 11:34:09.312646 26141 net.cpp:106] Creating Layer relu5
I0526 11:34:09.312656 26141 net.cpp:454] relu5 <- ip1
I0526 11:34:09.312670 26141 net.cpp:397] relu5 -> ip1 (in-place)
I0526 11:34:09.313017 26141 net.cpp:150] Setting up relu5
I0526 11:34:09.313031 26141 net.cpp:157] Top shape: 20 196 (3920)
I0526 11:34:09.313041 26141 net.cpp:165] Memory required for data: 31534800
I0526 11:34:09.313051 26141 layer_factory.hpp:77] Creating layer drop1
I0526 11:34:09.313071 26141 net.cpp:106] Creating Layer drop1
I0526 11:34:09.313081 26141 net.cpp:454] drop1 <- ip1
I0526 11:34:09.313093 26141 net.cpp:397] drop1 -> ip1 (in-place)
I0526 11:34:09.313138 26141 net.cpp:150] Setting up drop1
I0526 11:34:09.313151 26141 net.cpp:157] Top shape: 20 196 (3920)
I0526 11:34:09.313161 26141 net.cpp:165] Memory required for data: 31550480
I0526 11:34:09.313170 26141 layer_factory.hpp:77] Creating layer ip2
I0526 11:34:09.313185 26141 net.cpp:106] Creating Layer ip2
I0526 11:34:09.313195 26141 net.cpp:454] ip2 <- ip1
I0526 11:34:09.313210 26141 net.cpp:411] ip2 -> ip2
I0526 11:34:09.313693 26141 net.cpp:150] Setting up ip2
I0526 11:34:09.313706 26141 net.cpp:157] Top shape: 20 98 (1960)
I0526 11:34:09.313716 26141 net.cpp:165] Memory required for data: 31558320
I0526 11:34:09.313731 26141 layer_factory.hpp:77] Creating layer relu6
I0526 11:34:09.313756 26141 net.cpp:106] Creating Layer relu6
I0526 11:34:09.313766 26141 net.cpp:454] relu6 <- ip2
I0526 11:34:09.313779 26141 net.cpp:397] relu6 -> ip2 (in-place)
I0526 11:34:09.314316 26141 net.cpp:150] Setting up relu6
I0526 11:34:09.314337 26141 net.cpp:157] Top shape: 20 98 (1960)
I0526 11:34:09.314347 26141 net.cpp:165] Memory required for data: 31566160
I0526 11:34:09.314357 26141 layer_factory.hpp:77] Creating layer drop2
I0526 11:34:09.314370 26141 net.cpp:106] Creating Layer drop2
I0526 11:34:09.314380 26141 net.cpp:454] drop2 <- ip2
I0526 11:34:09.314393 26141 net.cpp:397] drop2 -> ip2 (in-place)
I0526 11:34:09.314437 26141 net.cpp:150] Setting up drop2
I0526 11:34:09.314450 26141 net.cpp:157] Top shape: 20 98 (1960)
I0526 11:34:09.314460 26141 net.cpp:165] Memory required for data: 31574000
I0526 11:34:09.314471 26141 layer_factory.hpp:77] Creating layer ip3
I0526 11:34:09.314483 26141 net.cpp:106] Creating Layer ip3
I0526 11:34:09.314493 26141 net.cpp:454] ip3 <- ip2
I0526 11:34:09.314507 26141 net.cpp:411] ip3 -> ip3
I0526 11:34:09.314733 26141 net.cpp:150] Setting up ip3
I0526 11:34:09.314745 26141 net.cpp:157] Top shape: 20 11 (220)
I0526 11:34:09.314755 26141 net.cpp:165] Memory required for data: 31574880
I0526 11:34:09.314770 26141 layer_factory.hpp:77] Creating layer drop3
I0526 11:34:09.314784 26141 net.cpp:106] Creating Layer drop3
I0526 11:34:09.314792 26141 net.cpp:454] drop3 <- ip3
I0526 11:34:09.314805 26141 net.cpp:397] drop3 -> ip3 (in-place)
I0526 11:34:09.314846 26141 net.cpp:150] Setting up drop3
I0526 11:34:09.314859 26141 net.cpp:157] Top shape: 20 11 (220)
I0526 11:34:09.314868 26141 net.cpp:165] Memory required for data: 31575760
I0526 11:34:09.314878 26141 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 11:34:09.314891 26141 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 11:34:09.314901 26141 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 11:34:09.314914 26141 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 11:34:09.314929 26141 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 11:34:09.315002 26141 net.cpp:150] Setting up ip3_drop3_0_split
I0526 11:34:09.315016 26141 net.cpp:157] Top shape: 20 11 (220)
I0526 11:34:09.315028 26141 net.cpp:157] Top shape: 20 11 (220)
I0526 11:34:09.315040 26141 net.cpp:165] Memory required for data: 31577520
I0526 11:34:09.315050 26141 layer_factory.hpp:77] Creating layer accuracy
I0526 11:34:09.315071 26141 net.cpp:106] Creating Layer accuracy
I0526 11:34:09.315081 26141 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 11:34:09.315093 26141 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 11:34:09.315106 26141 net.cpp:411] accuracy -> accuracy
I0526 11:34:09.315130 26141 net.cpp:150] Setting up accuracy
I0526 11:34:09.315143 26141 net.cpp:157] Top shape: (1)
I0526 11:34:09.315153 26141 net.cpp:165] Memory required for data: 31577524
I0526 11:34:09.315162 26141 layer_factory.hpp:77] Creating layer loss
I0526 11:34:09.315176 26141 net.cpp:106] Creating Layer loss
I0526 11:34:09.315187 26141 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 11:34:09.315198 26141 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 11:34:09.315212 26141 net.cpp:411] loss -> loss
I0526 11:34:09.315229 26141 layer_factory.hpp:77] Creating layer loss
I0526 11:34:09.315711 26141 net.cpp:150] Setting up loss
I0526 11:34:09.315724 26141 net.cpp:157] Top shape: (1)
I0526 11:34:09.315734 26141 net.cpp:160]     with loss weight 1
I0526 11:34:09.315752 26141 net.cpp:165] Memory required for data: 31577528
I0526 11:34:09.315762 26141 net.cpp:226] loss needs backward computation.
I0526 11:34:09.315773 26141 net.cpp:228] accuracy does not need backward computation.
I0526 11:34:09.315785 26141 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 11:34:09.315795 26141 net.cpp:226] drop3 needs backward computation.
I0526 11:34:09.315804 26141 net.cpp:226] ip3 needs backward computation.
I0526 11:34:09.315815 26141 net.cpp:226] drop2 needs backward computation.
I0526 11:34:09.315825 26141 net.cpp:226] relu6 needs backward computation.
I0526 11:34:09.315845 26141 net.cpp:226] ip2 needs backward computation.
I0526 11:34:09.315855 26141 net.cpp:226] drop1 needs backward computation.
I0526 11:34:09.315865 26141 net.cpp:226] relu5 needs backward computation.
I0526 11:34:09.315876 26141 net.cpp:226] ip1 needs backward computation.
I0526 11:34:09.315886 26141 net.cpp:226] pool4 needs backward computation.
I0526 11:34:09.315896 26141 net.cpp:226] relu4 needs backward computation.
I0526 11:34:09.315907 26141 net.cpp:226] conv4 needs backward computation.
I0526 11:34:09.315917 26141 net.cpp:226] pool3 needs backward computation.
I0526 11:34:09.315928 26141 net.cpp:226] relu3 needs backward computation.
I0526 11:34:09.315938 26141 net.cpp:226] conv3 needs backward computation.
I0526 11:34:09.315948 26141 net.cpp:226] pool2 needs backward computation.
I0526 11:34:09.315959 26141 net.cpp:226] relu2 needs backward computation.
I0526 11:34:09.315968 26141 net.cpp:226] conv2 needs backward computation.
I0526 11:34:09.315979 26141 net.cpp:226] pool1 needs backward computation.
I0526 11:34:09.315989 26141 net.cpp:226] relu1 needs backward computation.
I0526 11:34:09.315999 26141 net.cpp:226] conv1 needs backward computation.
I0526 11:34:09.316010 26141 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 11:34:09.316022 26141 net.cpp:228] data_hdf5 does not need backward computation.
I0526 11:34:09.316032 26141 net.cpp:270] This network produces output accuracy
I0526 11:34:09.316045 26141 net.cpp:270] This network produces output loss
I0526 11:34:09.316073 26141 net.cpp:283] Network initialization done.
I0526 11:34:09.316205 26141 solver.cpp:60] Solver scaffolding done.
I0526 11:34:09.317342 26141 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_285000.solverstate
I0526 11:34:09.535574 26141 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 11:34:09.541040 26141 caffe.cpp:212] Starting Optimization
I0526 11:34:09.541080 26141 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 11:34:09.541091 26141 solver.cpp:289] Learning Rate Policy: fixed
I0526 11:34:09.542444 26141 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 11:35:02.475657 26141 solver.cpp:409]     Test net output #0: accuracy = 0.889396
I0526 11:35:02.475811 26141 solver.cpp:409]     Test net output #1: loss = 0.357078 (* 1 = 0.357078 loss)
I0526 11:35:02.494822 26141 solver.cpp:237] Iteration 285000, loss = 1.15775
I0526 11:35:02.494858 26141 solver.cpp:253]     Train net output #0: loss = 1.15775 (* 1 = 1.15775 loss)
I0526 11:35:02.494876 26141 sgd_solver.cpp:106] Iteration 285000, lr = 0.0005
I0526 11:35:14.648279 26141 solver.cpp:237] Iteration 285750, loss = 1.34804
I0526 11:35:14.648329 26141 solver.cpp:253]     Train net output #0: loss = 1.34804 (* 1 = 1.34804 loss)
I0526 11:35:14.648344 26141 sgd_solver.cpp:106] Iteration 285750, lr = 0.0005
I0526 11:35:26.847379 26141 solver.cpp:237] Iteration 286500, loss = 1.52078
I0526 11:35:26.847415 26141 solver.cpp:253]     Train net output #0: loss = 1.52078 (* 1 = 1.52078 loss)
I0526 11:35:26.847429 26141 sgd_solver.cpp:106] Iteration 286500, lr = 0.0005
I0526 11:35:39.074378 26141 solver.cpp:237] Iteration 287250, loss = 1.04803
I0526 11:35:39.074537 26141 solver.cpp:253]     Train net output #0: loss = 1.04803 (* 1 = 1.04803 loss)
I0526 11:35:39.074553 26141 sgd_solver.cpp:106] Iteration 287250, lr = 0.0005
I0526 11:35:51.251607 26141 solver.cpp:237] Iteration 288000, loss = 0.851989
I0526 11:35:51.251643 26141 solver.cpp:253]     Train net output #0: loss = 0.851989 (* 1 = 0.851989 loss)
I0526 11:35:51.251659 26141 sgd_solver.cpp:106] Iteration 288000, lr = 0.0005
I0526 11:36:03.403143 26141 solver.cpp:237] Iteration 288750, loss = 1.10799
I0526 11:36:03.403188 26141 solver.cpp:253]     Train net output #0: loss = 1.10799 (* 1 = 1.10799 loss)
I0526 11:36:03.403201 26141 sgd_solver.cpp:106] Iteration 288750, lr = 0.0005
I0526 11:36:15.552449 26141 solver.cpp:237] Iteration 289500, loss = 1.09577
I0526 11:36:15.552587 26141 solver.cpp:253]     Train net output #0: loss = 1.09577 (* 1 = 1.09577 loss)
I0526 11:36:15.552602 26141 sgd_solver.cpp:106] Iteration 289500, lr = 0.0005
I0526 11:36:49.898494 26141 solver.cpp:237] Iteration 290250, loss = 1.54673
I0526 11:36:49.898649 26141 solver.cpp:253]     Train net output #0: loss = 1.54673 (* 1 = 1.54673 loss)
I0526 11:36:49.898664 26141 sgd_solver.cpp:106] Iteration 290250, lr = 0.0005
I0526 11:37:02.085484 26141 solver.cpp:237] Iteration 291000, loss = 1.31759
I0526 11:37:02.085520 26141 solver.cpp:253]     Train net output #0: loss = 1.3176 (* 1 = 1.3176 loss)
I0526 11:37:02.085533 26141 sgd_solver.cpp:106] Iteration 291000, lr = 0.0005
I0526 11:37:14.301009 26141 solver.cpp:237] Iteration 291750, loss = 2.41597
I0526 11:37:14.301045 26141 solver.cpp:253]     Train net output #0: loss = 2.41597 (* 1 = 2.41597 loss)
I0526 11:37:14.301059 26141 sgd_solver.cpp:106] Iteration 291750, lr = 0.0005
I0526 11:37:26.456121 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_292500.caffemodel
I0526 11:37:26.508327 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_292500.solverstate
I0526 11:37:26.540506 26141 solver.cpp:237] Iteration 292500, loss = 1.12165
I0526 11:37:26.540555 26141 solver.cpp:253]     Train net output #0: loss = 1.12165 (* 1 = 1.12165 loss)
I0526 11:37:26.540570 26141 sgd_solver.cpp:106] Iteration 292500, lr = 0.0005
I0526 11:37:38.723830 26141 solver.cpp:237] Iteration 293250, loss = 1.26194
I0526 11:37:38.723867 26141 solver.cpp:253]     Train net output #0: loss = 1.26194 (* 1 = 1.26194 loss)
I0526 11:37:38.723881 26141 sgd_solver.cpp:106] Iteration 293250, lr = 0.0005
I0526 11:37:50.863587 26141 solver.cpp:237] Iteration 294000, loss = 0.775228
I0526 11:37:50.863638 26141 solver.cpp:253]     Train net output #0: loss = 0.775229 (* 1 = 0.775229 loss)
I0526 11:37:50.863652 26141 sgd_solver.cpp:106] Iteration 294000, lr = 0.0005
I0526 11:38:02.950919 26141 solver.cpp:237] Iteration 294750, loss = 1.24733
I0526 11:38:02.951061 26141 solver.cpp:253]     Train net output #0: loss = 1.24733 (* 1 = 1.24733 loss)
I0526 11:38:02.951076 26141 sgd_solver.cpp:106] Iteration 294750, lr = 0.0005
I0526 11:38:37.221483 26141 solver.cpp:237] Iteration 295500, loss = 0.713687
I0526 11:38:37.221657 26141 solver.cpp:253]     Train net output #0: loss = 0.713687 (* 1 = 0.713687 loss)
I0526 11:38:37.221671 26141 sgd_solver.cpp:106] Iteration 295500, lr = 0.0005
I0526 11:38:49.375730 26141 solver.cpp:237] Iteration 296250, loss = 1.30985
I0526 11:38:49.375766 26141 solver.cpp:253]     Train net output #0: loss = 1.30985 (* 1 = 1.30985 loss)
I0526 11:38:49.375782 26141 sgd_solver.cpp:106] Iteration 296250, lr = 0.0005
I0526 11:39:01.544584 26141 solver.cpp:237] Iteration 297000, loss = 0.886594
I0526 11:39:01.544636 26141 solver.cpp:253]     Train net output #0: loss = 0.886595 (* 1 = 0.886595 loss)
I0526 11:39:01.544649 26141 sgd_solver.cpp:106] Iteration 297000, lr = 0.0005
I0526 11:39:13.716572 26141 solver.cpp:237] Iteration 297750, loss = 1.35928
I0526 11:39:13.716709 26141 solver.cpp:253]     Train net output #0: loss = 1.35928 (* 1 = 1.35928 loss)
I0526 11:39:13.716724 26141 sgd_solver.cpp:106] Iteration 297750, lr = 0.0005
I0526 11:39:25.890763 26141 solver.cpp:237] Iteration 298500, loss = 1.39078
I0526 11:39:25.890810 26141 solver.cpp:253]     Train net output #0: loss = 1.39078 (* 1 = 1.39078 loss)
I0526 11:39:25.890825 26141 sgd_solver.cpp:106] Iteration 298500, lr = 0.0005
I0526 11:39:38.114212 26141 solver.cpp:237] Iteration 299250, loss = 1.4531
I0526 11:39:38.114248 26141 solver.cpp:253]     Train net output #0: loss = 1.4531 (* 1 = 1.4531 loss)
I0526 11:39:38.114270 26141 sgd_solver.cpp:106] Iteration 299250, lr = 0.0005
I0526 11:39:50.291786 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_300000.caffemodel
I0526 11:39:50.342681 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_300000.solverstate
I0526 11:39:50.369176 26141 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 11:40:42.300298 26141 solver.cpp:409]     Test net output #0: accuracy = 0.890203
I0526 11:40:42.300456 26141 solver.cpp:409]     Test net output #1: loss = 0.342546 (* 1 = 0.342546 loss)
I0526 11:41:04.460306 26141 solver.cpp:237] Iteration 300000, loss = 1.04752
I0526 11:41:04.460355 26141 solver.cpp:253]     Train net output #0: loss = 1.04752 (* 1 = 1.04752 loss)
I0526 11:41:04.460371 26141 sgd_solver.cpp:106] Iteration 300000, lr = 0.0005
I0526 11:41:16.603729 26141 solver.cpp:237] Iteration 300750, loss = 1.18404
I0526 11:41:16.603873 26141 solver.cpp:253]     Train net output #0: loss = 1.18404 (* 1 = 1.18404 loss)
I0526 11:41:16.603886 26141 sgd_solver.cpp:106] Iteration 300750, lr = 0.0005
I0526 11:41:28.753358 26141 solver.cpp:237] Iteration 301500, loss = 1.37918
I0526 11:41:28.753404 26141 solver.cpp:253]     Train net output #0: loss = 1.37918 (* 1 = 1.37918 loss)
I0526 11:41:28.753418 26141 sgd_solver.cpp:106] Iteration 301500, lr = 0.0005
I0526 11:41:40.898541 26141 solver.cpp:237] Iteration 302250, loss = 1.14912
I0526 11:41:40.898577 26141 solver.cpp:253]     Train net output #0: loss = 1.14912 (* 1 = 1.14912 loss)
I0526 11:41:40.898591 26141 sgd_solver.cpp:106] Iteration 302250, lr = 0.0005
I0526 11:41:53.050570 26141 solver.cpp:237] Iteration 303000, loss = 0.668397
I0526 11:41:53.050717 26141 solver.cpp:253]     Train net output #0: loss = 0.668398 (* 1 = 0.668398 loss)
I0526 11:41:53.050732 26141 sgd_solver.cpp:106] Iteration 303000, lr = 0.0005
I0526 11:42:05.206153 26141 solver.cpp:237] Iteration 303750, loss = 0.976498
I0526 11:42:05.206190 26141 solver.cpp:253]     Train net output #0: loss = 0.976498 (* 1 = 0.976498 loss)
I0526 11:42:05.206203 26141 sgd_solver.cpp:106] Iteration 303750, lr = 0.0005
I0526 11:42:17.371330 26141 solver.cpp:237] Iteration 304500, loss = 1.24145
I0526 11:42:17.371377 26141 solver.cpp:253]     Train net output #0: loss = 1.24145 (* 1 = 1.24145 loss)
I0526 11:42:17.371392 26141 sgd_solver.cpp:106] Iteration 304500, lr = 0.0005
I0526 11:42:51.704201 26141 solver.cpp:237] Iteration 305250, loss = 1.16866
I0526 11:42:51.704375 26141 solver.cpp:253]     Train net output #0: loss = 1.16866 (* 1 = 1.16866 loss)
I0526 11:42:51.704388 26141 sgd_solver.cpp:106] Iteration 305250, lr = 0.0005
I0526 11:43:03.859158 26141 solver.cpp:237] Iteration 306000, loss = 0.954517
I0526 11:43:03.859194 26141 solver.cpp:253]     Train net output #0: loss = 0.954517 (* 1 = 0.954517 loss)
I0526 11:43:03.859207 26141 sgd_solver.cpp:106] Iteration 306000, lr = 0.0005
I0526 11:43:16.028937 26141 solver.cpp:237] Iteration 306750, loss = 1.12142
I0526 11:43:16.028981 26141 solver.cpp:253]     Train net output #0: loss = 1.12142 (* 1 = 1.12142 loss)
I0526 11:43:16.028995 26141 sgd_solver.cpp:106] Iteration 306750, lr = 0.0005
I0526 11:43:28.176168 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_307500.caffemodel
I0526 11:43:28.227733 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_307500.solverstate
I0526 11:43:28.260283 26141 solver.cpp:237] Iteration 307500, loss = 1.35887
I0526 11:43:28.260332 26141 solver.cpp:253]     Train net output #0: loss = 1.35887 (* 1 = 1.35887 loss)
I0526 11:43:28.260347 26141 sgd_solver.cpp:106] Iteration 307500, lr = 0.0005
I0526 11:43:40.404959 26141 solver.cpp:237] Iteration 308250, loss = 0.852161
I0526 11:43:40.405009 26141 solver.cpp:253]     Train net output #0: loss = 0.852161 (* 1 = 0.852161 loss)
I0526 11:43:40.405022 26141 sgd_solver.cpp:106] Iteration 308250, lr = 0.0005
I0526 11:43:52.574086 26141 solver.cpp:237] Iteration 309000, loss = 1.00201
I0526 11:43:52.574123 26141 solver.cpp:253]     Train net output #0: loss = 1.00201 (* 1 = 1.00201 loss)
I0526 11:43:52.574136 26141 sgd_solver.cpp:106] Iteration 309000, lr = 0.0005
I0526 11:44:04.761555 26141 solver.cpp:237] Iteration 309750, loss = 0.830844
I0526 11:44:04.761711 26141 solver.cpp:253]     Train net output #0: loss = 0.830844 (* 1 = 0.830844 loss)
I0526 11:44:04.761726 26141 sgd_solver.cpp:106] Iteration 309750, lr = 0.0005
I0526 11:44:39.109436 26141 solver.cpp:237] Iteration 310500, loss = 0.825625
I0526 11:44:39.109592 26141 solver.cpp:253]     Train net output #0: loss = 0.825625 (* 1 = 0.825625 loss)
I0526 11:44:39.109608 26141 sgd_solver.cpp:106] Iteration 310500, lr = 0.0005
I0526 11:44:51.273212 26141 solver.cpp:237] Iteration 311250, loss = 1.42637
I0526 11:44:51.273258 26141 solver.cpp:253]     Train net output #0: loss = 1.42637 (* 1 = 1.42637 loss)
I0526 11:44:51.273272 26141 sgd_solver.cpp:106] Iteration 311250, lr = 0.0005
I0526 11:45:03.440816 26141 solver.cpp:237] Iteration 312000, loss = 0.959456
I0526 11:45:03.440853 26141 solver.cpp:253]     Train net output #0: loss = 0.959456 (* 1 = 0.959456 loss)
I0526 11:45:03.440870 26141 sgd_solver.cpp:106] Iteration 312000, lr = 0.0005
I0526 11:45:15.583719 26141 solver.cpp:237] Iteration 312750, loss = 1.00802
I0526 11:45:15.583871 26141 solver.cpp:253]     Train net output #0: loss = 1.00802 (* 1 = 1.00802 loss)
I0526 11:45:15.583885 26141 sgd_solver.cpp:106] Iteration 312750, lr = 0.0005
I0526 11:45:27.718929 26141 solver.cpp:237] Iteration 313500, loss = 1.28555
I0526 11:45:27.718963 26141 solver.cpp:253]     Train net output #0: loss = 1.28555 (* 1 = 1.28555 loss)
I0526 11:45:27.718977 26141 sgd_solver.cpp:106] Iteration 313500, lr = 0.0005
I0526 11:45:39.854707 26141 solver.cpp:237] Iteration 314250, loss = 1.42602
I0526 11:45:39.854751 26141 solver.cpp:253]     Train net output #0: loss = 1.42602 (* 1 = 1.42602 loss)
I0526 11:45:39.854764 26141 sgd_solver.cpp:106] Iteration 314250, lr = 0.0005
I0526 11:45:51.968881 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_315000.caffemodel
I0526 11:45:52.021184 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_315000.solverstate
I0526 11:45:52.049280 26141 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 11:47:04.823395 26141 solver.cpp:409]     Test net output #0: accuracy = 0.892076
I0526 11:47:04.823551 26141 solver.cpp:409]     Test net output #1: loss = 0.355149 (* 1 = 0.355149 loss)
I0526 11:47:27.045866 26141 solver.cpp:237] Iteration 315000, loss = 1.30283
I0526 11:47:27.045918 26141 solver.cpp:253]     Train net output #0: loss = 1.30283 (* 1 = 1.30283 loss)
I0526 11:47:27.045933 26141 sgd_solver.cpp:106] Iteration 315000, lr = 0.0005
I0526 11:47:39.216099 26141 solver.cpp:237] Iteration 315750, loss = 1.09366
I0526 11:47:39.216235 26141 solver.cpp:253]     Train net output #0: loss = 1.09366 (* 1 = 1.09366 loss)
I0526 11:47:39.216249 26141 sgd_solver.cpp:106] Iteration 315750, lr = 0.0005
I0526 11:47:51.408941 26141 solver.cpp:237] Iteration 316500, loss = 0.954266
I0526 11:47:51.408985 26141 solver.cpp:253]     Train net output #0: loss = 0.954266 (* 1 = 0.954266 loss)
I0526 11:47:51.408998 26141 sgd_solver.cpp:106] Iteration 316500, lr = 0.0005
I0526 11:48:03.587478 26141 solver.cpp:237] Iteration 317250, loss = 1.37858
I0526 11:48:03.587514 26141 solver.cpp:253]     Train net output #0: loss = 1.37858 (* 1 = 1.37858 loss)
I0526 11:48:03.587527 26141 sgd_solver.cpp:106] Iteration 317250, lr = 0.0005
I0526 11:48:15.787123 26141 solver.cpp:237] Iteration 318000, loss = 0.881798
I0526 11:48:15.787278 26141 solver.cpp:253]     Train net output #0: loss = 0.881798 (* 1 = 0.881798 loss)
I0526 11:48:15.787293 26141 sgd_solver.cpp:106] Iteration 318000, lr = 0.0005
I0526 11:48:27.934572 26141 solver.cpp:237] Iteration 318750, loss = 1.09116
I0526 11:48:27.934603 26141 solver.cpp:253]     Train net output #0: loss = 1.09116 (* 1 = 1.09116 loss)
I0526 11:48:27.934617 26141 sgd_solver.cpp:106] Iteration 318750, lr = 0.0005
I0526 11:48:40.059694 26141 solver.cpp:237] Iteration 319500, loss = 1.03561
I0526 11:48:40.059741 26141 solver.cpp:253]     Train net output #0: loss = 1.03561 (* 1 = 1.03561 loss)
I0526 11:48:40.059753 26141 sgd_solver.cpp:106] Iteration 319500, lr = 0.0005
I0526 11:49:14.386293 26141 solver.cpp:237] Iteration 320250, loss = 1.36795
I0526 11:49:14.386462 26141 solver.cpp:253]     Train net output #0: loss = 1.36795 (* 1 = 1.36795 loss)
I0526 11:49:14.386476 26141 sgd_solver.cpp:106] Iteration 320250, lr = 0.0005
I0526 11:49:26.641533 26141 solver.cpp:237] Iteration 321000, loss = 0.974391
I0526 11:49:26.641582 26141 solver.cpp:253]     Train net output #0: loss = 0.974391 (* 1 = 0.974391 loss)
I0526 11:49:26.641598 26141 sgd_solver.cpp:106] Iteration 321000, lr = 0.0005
I0526 11:49:38.856653 26141 solver.cpp:237] Iteration 321750, loss = 1.11174
I0526 11:49:38.856711 26141 solver.cpp:253]     Train net output #0: loss = 1.11174 (* 1 = 1.11174 loss)
I0526 11:49:38.856724 26141 sgd_solver.cpp:106] Iteration 321750, lr = 0.0005
I0526 11:49:51.064390 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_322500.caffemodel
I0526 11:49:51.116736 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_322500.solverstate
I0526 11:49:51.149958 26141 solver.cpp:237] Iteration 322500, loss = 1.10776
I0526 11:49:51.150007 26141 solver.cpp:253]     Train net output #0: loss = 1.10776 (* 1 = 1.10776 loss)
I0526 11:49:51.150022 26141 sgd_solver.cpp:106] Iteration 322500, lr = 0.0005
I0526 11:50:03.377341 26141 solver.cpp:237] Iteration 323250, loss = 1.02575
I0526 11:50:03.377377 26141 solver.cpp:253]     Train net output #0: loss = 1.02576 (* 1 = 1.02576 loss)
I0526 11:50:03.377390 26141 sgd_solver.cpp:106] Iteration 323250, lr = 0.0005
I0526 11:50:15.587430 26141 solver.cpp:237] Iteration 324000, loss = 0.952594
I0526 11:50:15.587476 26141 solver.cpp:253]     Train net output #0: loss = 0.952595 (* 1 = 0.952595 loss)
I0526 11:50:15.587491 26141 sgd_solver.cpp:106] Iteration 324000, lr = 0.0005
I0526 11:50:27.794322 26141 solver.cpp:237] Iteration 324750, loss = 0.552618
I0526 11:50:27.794479 26141 solver.cpp:253]     Train net output #0: loss = 0.552618 (* 1 = 0.552618 loss)
I0526 11:50:27.794494 26141 sgd_solver.cpp:106] Iteration 324750, lr = 0.0005
I0526 11:51:02.165076 26141 solver.cpp:237] Iteration 325500, loss = 0.930384
I0526 11:51:02.165236 26141 solver.cpp:253]     Train net output #0: loss = 0.930384 (* 1 = 0.930384 loss)
I0526 11:51:02.165251 26141 sgd_solver.cpp:106] Iteration 325500, lr = 0.0005
I0526 11:51:14.343358 26141 solver.cpp:237] Iteration 326250, loss = 0.788209
I0526 11:51:14.343394 26141 solver.cpp:253]     Train net output #0: loss = 0.78821 (* 1 = 0.78821 loss)
I0526 11:51:14.343408 26141 sgd_solver.cpp:106] Iteration 326250, lr = 0.0005
I0526 11:51:26.522708 26141 solver.cpp:237] Iteration 327000, loss = 1.57357
I0526 11:51:26.522752 26141 solver.cpp:253]     Train net output #0: loss = 1.57357 (* 1 = 1.57357 loss)
I0526 11:51:26.522768 26141 sgd_solver.cpp:106] Iteration 327000, lr = 0.0005
I0526 11:51:38.710695 26141 solver.cpp:237] Iteration 327750, loss = 1.09559
I0526 11:51:38.710835 26141 solver.cpp:253]     Train net output #0: loss = 1.09559 (* 1 = 1.09559 loss)
I0526 11:51:38.710850 26141 sgd_solver.cpp:106] Iteration 327750, lr = 0.0005
I0526 11:51:50.876610 26141 solver.cpp:237] Iteration 328500, loss = 1.13852
I0526 11:51:50.876652 26141 solver.cpp:253]     Train net output #0: loss = 1.13852 (* 1 = 1.13852 loss)
I0526 11:51:50.876664 26141 sgd_solver.cpp:106] Iteration 328500, lr = 0.0005
I0526 11:52:03.060400 26141 solver.cpp:237] Iteration 329250, loss = 1.00887
I0526 11:52:03.060436 26141 solver.cpp:253]     Train net output #0: loss = 1.00887 (* 1 = 1.00887 loss)
I0526 11:52:03.060448 26141 sgd_solver.cpp:106] Iteration 329250, lr = 0.0005
I0526 11:52:15.193552 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_330000.caffemodel
I0526 11:52:15.242621 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_330000.solverstate
I0526 11:52:15.267675 26141 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 11:53:07.018503 26141 solver.cpp:409]     Test net output #0: accuracy = 0.892579
I0526 11:53:07.018663 26141 solver.cpp:409]     Test net output #1: loss = 0.34498 (* 1 = 0.34498 loss)
I0526 11:53:29.135695 26141 solver.cpp:237] Iteration 330000, loss = 1.23598
I0526 11:53:29.135747 26141 solver.cpp:253]     Train net output #0: loss = 1.23598 (* 1 = 1.23598 loss)
I0526 11:53:29.135762 26141 sgd_solver.cpp:106] Iteration 330000, lr = 0.0005
I0526 11:53:41.309974 26141 solver.cpp:237] Iteration 330750, loss = 1.03468
I0526 11:53:41.310124 26141 solver.cpp:253]     Train net output #0: loss = 1.03468 (* 1 = 1.03468 loss)
I0526 11:53:41.310138 26141 sgd_solver.cpp:106] Iteration 330750, lr = 0.0005
I0526 11:53:53.502419 26141 solver.cpp:237] Iteration 331500, loss = 1.34034
I0526 11:53:53.502455 26141 solver.cpp:253]     Train net output #0: loss = 1.34035 (* 1 = 1.34035 loss)
I0526 11:53:53.502470 26141 sgd_solver.cpp:106] Iteration 331500, lr = 0.0005
I0526 11:54:05.667883 26141 solver.cpp:237] Iteration 332250, loss = 1.50498
I0526 11:54:05.667932 26141 solver.cpp:253]     Train net output #0: loss = 1.50498 (* 1 = 1.50498 loss)
I0526 11:54:05.667948 26141 sgd_solver.cpp:106] Iteration 332250, lr = 0.0005
I0526 11:54:17.818387 26141 solver.cpp:237] Iteration 333000, loss = 1.10314
I0526 11:54:17.818527 26141 solver.cpp:253]     Train net output #0: loss = 1.10314 (* 1 = 1.10314 loss)
I0526 11:54:17.818542 26141 sgd_solver.cpp:106] Iteration 333000, lr = 0.0005
I0526 11:54:29.964519 26141 solver.cpp:237] Iteration 333750, loss = 1.32777
I0526 11:54:29.964567 26141 solver.cpp:253]     Train net output #0: loss = 1.32778 (* 1 = 1.32778 loss)
I0526 11:54:29.964581 26141 sgd_solver.cpp:106] Iteration 333750, lr = 0.0005
I0526 11:54:42.096973 26141 solver.cpp:237] Iteration 334500, loss = 1.10081
I0526 11:54:42.097009 26141 solver.cpp:253]     Train net output #0: loss = 1.10081 (* 1 = 1.10081 loss)
I0526 11:54:42.097023 26141 sgd_solver.cpp:106] Iteration 334500, lr = 0.0005
I0526 11:55:16.426218 26141 solver.cpp:237] Iteration 335250, loss = 1.04437
I0526 11:55:16.426399 26141 solver.cpp:253]     Train net output #0: loss = 1.04437 (* 1 = 1.04437 loss)
I0526 11:55:16.426414 26141 sgd_solver.cpp:106] Iteration 335250, lr = 0.0005
I0526 11:55:28.648908 26141 solver.cpp:237] Iteration 336000, loss = 0.979604
I0526 11:55:28.648946 26141 solver.cpp:253]     Train net output #0: loss = 0.979605 (* 1 = 0.979605 loss)
I0526 11:55:28.648958 26141 sgd_solver.cpp:106] Iteration 336000, lr = 0.0005
I0526 11:55:40.865370 26141 solver.cpp:237] Iteration 336750, loss = 1.25641
I0526 11:55:40.865416 26141 solver.cpp:253]     Train net output #0: loss = 1.25641 (* 1 = 1.25641 loss)
I0526 11:55:40.865428 26141 sgd_solver.cpp:106] Iteration 336750, lr = 0.0005
I0526 11:55:53.077093 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_337500.caffemodel
I0526 11:55:53.126708 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_337500.solverstate
I0526 11:55:53.157369 26141 solver.cpp:237] Iteration 337500, loss = 1.07551
I0526 11:55:53.157412 26141 solver.cpp:253]     Train net output #0: loss = 1.07551 (* 1 = 1.07551 loss)
I0526 11:55:53.157428 26141 sgd_solver.cpp:106] Iteration 337500, lr = 0.0005
I0526 11:56:05.384909 26141 solver.cpp:237] Iteration 338250, loss = 0.932264
I0526 11:56:05.384958 26141 solver.cpp:253]     Train net output #0: loss = 0.932265 (* 1 = 0.932265 loss)
I0526 11:56:05.384971 26141 sgd_solver.cpp:106] Iteration 338250, lr = 0.0005
I0526 11:56:17.600169 26141 solver.cpp:237] Iteration 339000, loss = 0.690269
I0526 11:56:17.600206 26141 solver.cpp:253]     Train net output #0: loss = 0.69027 (* 1 = 0.69027 loss)
I0526 11:56:17.600219 26141 sgd_solver.cpp:106] Iteration 339000, lr = 0.0005
I0526 11:56:29.822469 26141 solver.cpp:237] Iteration 339750, loss = 0.929687
I0526 11:56:29.822624 26141 solver.cpp:253]     Train net output #0: loss = 0.929689 (* 1 = 0.929689 loss)
I0526 11:56:29.822639 26141 sgd_solver.cpp:106] Iteration 339750, lr = 0.0005
I0526 11:57:04.195390 26141 solver.cpp:237] Iteration 340500, loss = 1.19056
I0526 11:57:04.195560 26141 solver.cpp:253]     Train net output #0: loss = 1.19056 (* 1 = 1.19056 loss)
I0526 11:57:04.195575 26141 sgd_solver.cpp:106] Iteration 340500, lr = 0.0005
I0526 11:57:16.360594 26141 solver.cpp:237] Iteration 341250, loss = 1.07321
I0526 11:57:16.360635 26141 solver.cpp:253]     Train net output #0: loss = 1.07321 (* 1 = 1.07321 loss)
I0526 11:57:16.360654 26141 sgd_solver.cpp:106] Iteration 341250, lr = 0.0005
I0526 11:57:28.475201 26141 solver.cpp:237] Iteration 342000, loss = 0.787235
I0526 11:57:28.475239 26141 solver.cpp:253]     Train net output #0: loss = 0.787236 (* 1 = 0.787236 loss)
I0526 11:57:28.475252 26141 sgd_solver.cpp:106] Iteration 342000, lr = 0.0005
I0526 11:57:40.598914 26141 solver.cpp:237] Iteration 342750, loss = 0.941882
I0526 11:57:40.599069 26141 solver.cpp:253]     Train net output #0: loss = 0.941883 (* 1 = 0.941883 loss)
I0526 11:57:40.599083 26141 sgd_solver.cpp:106] Iteration 342750, lr = 0.0005
I0526 11:57:52.747725 26141 solver.cpp:237] Iteration 343500, loss = 1.60174
I0526 11:57:52.747761 26141 solver.cpp:253]     Train net output #0: loss = 1.60174 (* 1 = 1.60174 loss)
I0526 11:57:52.747773 26141 sgd_solver.cpp:106] Iteration 343500, lr = 0.0005
I0526 11:58:04.941293 26141 solver.cpp:237] Iteration 344250, loss = 1.10787
I0526 11:58:04.941339 26141 solver.cpp:253]     Train net output #0: loss = 1.10787 (* 1 = 1.10787 loss)
I0526 11:58:04.941352 26141 sgd_solver.cpp:106] Iteration 344250, lr = 0.0005
I0526 11:58:17.138453 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_345000.caffemodel
I0526 11:58:17.187665 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_345000.solverstate
I0526 11:58:17.213574 26141 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 11:59:30.172735 26141 solver.cpp:409]     Test net output #0: accuracy = 0.889377
I0526 11:59:30.172902 26141 solver.cpp:409]     Test net output #1: loss = 0.36294 (* 1 = 0.36294 loss)
I0526 11:59:52.325498 26141 solver.cpp:237] Iteration 345000, loss = 2.07819
I0526 11:59:52.325549 26141 solver.cpp:253]     Train net output #0: loss = 2.07819 (* 1 = 2.07819 loss)
I0526 11:59:52.325567 26141 sgd_solver.cpp:106] Iteration 345000, lr = 0.0005
I0526 12:00:04.492801 26141 solver.cpp:237] Iteration 345750, loss = 0.930369
I0526 12:00:04.492959 26141 solver.cpp:253]     Train net output #0: loss = 0.930371 (* 1 = 0.930371 loss)
I0526 12:00:04.492974 26141 sgd_solver.cpp:106] Iteration 345750, lr = 0.0005
I0526 12:00:16.646486 26141 solver.cpp:237] Iteration 346500, loss = 0.93143
I0526 12:00:16.646533 26141 solver.cpp:253]     Train net output #0: loss = 0.931431 (* 1 = 0.931431 loss)
I0526 12:00:16.646546 26141 sgd_solver.cpp:106] Iteration 346500, lr = 0.0005
I0526 12:00:28.774590 26141 solver.cpp:237] Iteration 347250, loss = 1.10173
I0526 12:00:28.774626 26141 solver.cpp:253]     Train net output #0: loss = 1.10174 (* 1 = 1.10174 loss)
I0526 12:00:28.774638 26141 sgd_solver.cpp:106] Iteration 347250, lr = 0.0005
I0526 12:00:40.902905 26141 solver.cpp:237] Iteration 348000, loss = 1.03434
I0526 12:00:40.903058 26141 solver.cpp:253]     Train net output #0: loss = 1.03434 (* 1 = 1.03434 loss)
I0526 12:00:40.903071 26141 sgd_solver.cpp:106] Iteration 348000, lr = 0.0005
I0526 12:00:53.027014 26141 solver.cpp:237] Iteration 348750, loss = 1.29265
I0526 12:00:53.027050 26141 solver.cpp:253]     Train net output #0: loss = 1.29265 (* 1 = 1.29265 loss)
I0526 12:00:53.027062 26141 sgd_solver.cpp:106] Iteration 348750, lr = 0.0005
I0526 12:01:05.204790 26141 solver.cpp:237] Iteration 349500, loss = 1.3533
I0526 12:01:05.204835 26141 solver.cpp:253]     Train net output #0: loss = 1.3533 (* 1 = 1.3533 loss)
I0526 12:01:05.204849 26141 sgd_solver.cpp:106] Iteration 349500, lr = 0.0005
I0526 12:01:39.540626 26141 solver.cpp:237] Iteration 350250, loss = 1.35558
I0526 12:01:39.540796 26141 solver.cpp:253]     Train net output #0: loss = 1.35558 (* 1 = 1.35558 loss)
I0526 12:01:39.540812 26141 sgd_solver.cpp:106] Iteration 350250, lr = 0.0005
I0526 12:01:51.708432 26141 solver.cpp:237] Iteration 351000, loss = 1.41025
I0526 12:01:51.708477 26141 solver.cpp:253]     Train net output #0: loss = 1.41025 (* 1 = 1.41025 loss)
I0526 12:01:51.708495 26141 sgd_solver.cpp:106] Iteration 351000, lr = 0.0005
I0526 12:02:03.892496 26141 solver.cpp:237] Iteration 351750, loss = 1.27448
I0526 12:02:03.892534 26141 solver.cpp:253]     Train net output #0: loss = 1.27448 (* 1 = 1.27448 loss)
I0526 12:02:03.892551 26141 sgd_solver.cpp:106] Iteration 351750, lr = 0.0005
I0526 12:02:16.040482 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_352500.caffemodel
I0526 12:02:16.095654 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_352500.solverstate
I0526 12:02:16.128051 26141 solver.cpp:237] Iteration 352500, loss = 1.577
I0526 12:02:16.128099 26141 solver.cpp:253]     Train net output #0: loss = 1.577 (* 1 = 1.577 loss)
I0526 12:02:16.128114 26141 sgd_solver.cpp:106] Iteration 352500, lr = 0.0005
I0526 12:02:28.284055 26141 solver.cpp:237] Iteration 353250, loss = 0.928579
I0526 12:02:28.284093 26141 solver.cpp:253]     Train net output #0: loss = 0.928581 (* 1 = 0.928581 loss)
I0526 12:02:28.284106 26141 sgd_solver.cpp:106] Iteration 353250, lr = 0.0005
I0526 12:02:40.447204 26141 solver.cpp:237] Iteration 354000, loss = 1.78771
I0526 12:02:40.447247 26141 solver.cpp:253]     Train net output #0: loss = 1.78771 (* 1 = 1.78771 loss)
I0526 12:02:40.447264 26141 sgd_solver.cpp:106] Iteration 354000, lr = 0.0005
I0526 12:02:52.636370 26141 solver.cpp:237] Iteration 354750, loss = 1.05142
I0526 12:02:52.636533 26141 solver.cpp:253]     Train net output #0: loss = 1.05142 (* 1 = 1.05142 loss)
I0526 12:02:52.636548 26141 sgd_solver.cpp:106] Iteration 354750, lr = 0.0005
I0526 12:03:26.934943 26141 solver.cpp:237] Iteration 355500, loss = 1.05272
I0526 12:03:26.935116 26141 solver.cpp:253]     Train net output #0: loss = 1.05272 (* 1 = 1.05272 loss)
I0526 12:03:26.935132 26141 sgd_solver.cpp:106] Iteration 355500, lr = 0.0005
I0526 12:03:39.077282 26141 solver.cpp:237] Iteration 356250, loss = 1.15872
I0526 12:03:39.077328 26141 solver.cpp:253]     Train net output #0: loss = 1.15873 (* 1 = 1.15873 loss)
I0526 12:03:39.077342 26141 sgd_solver.cpp:106] Iteration 356250, lr = 0.0005
I0526 12:03:51.266290 26141 solver.cpp:237] Iteration 357000, loss = 1.0366
I0526 12:03:51.266326 26141 solver.cpp:253]     Train net output #0: loss = 1.0366 (* 1 = 1.0366 loss)
I0526 12:03:51.266340 26141 sgd_solver.cpp:106] Iteration 357000, lr = 0.0005
I0526 12:04:03.427117 26141 solver.cpp:237] Iteration 357750, loss = 1.14117
I0526 12:04:03.427278 26141 solver.cpp:253]     Train net output #0: loss = 1.14117 (* 1 = 1.14117 loss)
I0526 12:04:03.427292 26141 sgd_solver.cpp:106] Iteration 357750, lr = 0.0005
I0526 12:04:15.547406 26141 solver.cpp:237] Iteration 358500, loss = 1.17594
I0526 12:04:15.547442 26141 solver.cpp:253]     Train net output #0: loss = 1.17594 (* 1 = 1.17594 loss)
I0526 12:04:15.547456 26141 sgd_solver.cpp:106] Iteration 358500, lr = 0.0005
I0526 12:04:27.676669 26141 solver.cpp:237] Iteration 359250, loss = 1.47629
I0526 12:04:27.676717 26141 solver.cpp:253]     Train net output #0: loss = 1.4763 (* 1 = 1.4763 loss)
I0526 12:04:27.676733 26141 sgd_solver.cpp:106] Iteration 359250, lr = 0.0005
I0526 12:04:39.782073 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_360000.caffemodel
I0526 12:04:39.833605 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_360000.solverstate
I0526 12:04:39.861294 26141 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 12:05:31.866595 26141 solver.cpp:409]     Test net output #0: accuracy = 0.892096
I0526 12:05:31.866751 26141 solver.cpp:409]     Test net output #1: loss = 0.335049 (* 1 = 0.335049 loss)
I0526 12:05:52.721345 26141 solver.cpp:237] Iteration 360000, loss = 1.12736
I0526 12:05:52.721392 26141 solver.cpp:253]     Train net output #0: loss = 1.12736 (* 1 = 1.12736 loss)
I0526 12:05:52.721410 26141 sgd_solver.cpp:106] Iteration 360000, lr = 0.0005
I0526 12:06:04.877471 26141 solver.cpp:237] Iteration 360750, loss = 1.34627
I0526 12:06:04.877632 26141 solver.cpp:253]     Train net output #0: loss = 1.34627 (* 1 = 1.34627 loss)
I0526 12:06:04.877647 26141 sgd_solver.cpp:106] Iteration 360750, lr = 0.0005
I0526 12:06:17.037729 26141 solver.cpp:237] Iteration 361500, loss = 0.97066
I0526 12:06:17.037765 26141 solver.cpp:253]     Train net output #0: loss = 0.970662 (* 1 = 0.970662 loss)
I0526 12:06:17.037780 26141 sgd_solver.cpp:106] Iteration 361500, lr = 0.0005
I0526 12:06:29.267127 26141 solver.cpp:237] Iteration 362250, loss = 1.41296
I0526 12:06:29.267174 26141 solver.cpp:253]     Train net output #0: loss = 1.41296 (* 1 = 1.41296 loss)
I0526 12:06:29.267187 26141 sgd_solver.cpp:106] Iteration 362250, lr = 0.0005
I0526 12:06:41.486780 26141 solver.cpp:237] Iteration 363000, loss = 0.979071
I0526 12:06:41.486932 26141 solver.cpp:253]     Train net output #0: loss = 0.979073 (* 1 = 0.979073 loss)
I0526 12:06:41.486946 26141 sgd_solver.cpp:106] Iteration 363000, lr = 0.0005
I0526 12:06:53.709646 26141 solver.cpp:237] Iteration 363750, loss = 1.08905
I0526 12:06:53.709692 26141 solver.cpp:253]     Train net output #0: loss = 1.08906 (* 1 = 1.08906 loss)
I0526 12:06:53.709704 26141 sgd_solver.cpp:106] Iteration 363750, lr = 0.0005
I0526 12:07:05.961829 26141 solver.cpp:237] Iteration 364500, loss = 1.70432
I0526 12:07:05.961865 26141 solver.cpp:253]     Train net output #0: loss = 1.70432 (* 1 = 1.70432 loss)
I0526 12:07:05.961879 26141 sgd_solver.cpp:106] Iteration 364500, lr = 0.0005
I0526 12:07:39.022917 26141 solver.cpp:237] Iteration 365250, loss = 1.08166
I0526 12:07:39.023087 26141 solver.cpp:253]     Train net output #0: loss = 1.08166 (* 1 = 1.08166 loss)
I0526 12:07:39.023102 26141 sgd_solver.cpp:106] Iteration 365250, lr = 0.0005
I0526 12:07:51.233446 26141 solver.cpp:237] Iteration 366000, loss = 1.10556
I0526 12:07:51.233489 26141 solver.cpp:253]     Train net output #0: loss = 1.10556 (* 1 = 1.10556 loss)
I0526 12:07:51.233502 26141 sgd_solver.cpp:106] Iteration 366000, lr = 0.0005
I0526 12:08:03.405299 26141 solver.cpp:237] Iteration 366750, loss = 2.36761
I0526 12:08:03.405335 26141 solver.cpp:253]     Train net output #0: loss = 2.36761 (* 1 = 2.36761 loss)
I0526 12:08:03.405349 26141 sgd_solver.cpp:106] Iteration 366750, lr = 0.0005
I0526 12:08:15.552270 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_367500.caffemodel
I0526 12:08:15.600919 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_367500.solverstate
I0526 12:08:15.631022 26141 solver.cpp:237] Iteration 367500, loss = 1.11372
I0526 12:08:15.631067 26141 solver.cpp:253]     Train net output #0: loss = 1.11372 (* 1 = 1.11372 loss)
I0526 12:08:15.631081 26141 sgd_solver.cpp:106] Iteration 367500, lr = 0.0005
I0526 12:08:27.823837 26141 solver.cpp:237] Iteration 368250, loss = 1.32853
I0526 12:08:27.823873 26141 solver.cpp:253]     Train net output #0: loss = 1.32853 (* 1 = 1.32853 loss)
I0526 12:08:27.823886 26141 sgd_solver.cpp:106] Iteration 368250, lr = 0.0005
I0526 12:08:40.020257 26141 solver.cpp:237] Iteration 369000, loss = 0.828579
I0526 12:08:40.020304 26141 solver.cpp:253]     Train net output #0: loss = 0.828582 (* 1 = 0.828582 loss)
I0526 12:08:40.020318 26141 sgd_solver.cpp:106] Iteration 369000, lr = 0.0005
I0526 12:08:52.231442 26141 solver.cpp:237] Iteration 369750, loss = 1.37777
I0526 12:08:52.231595 26141 solver.cpp:253]     Train net output #0: loss = 1.37777 (* 1 = 1.37777 loss)
I0526 12:08:52.231611 26141 sgd_solver.cpp:106] Iteration 369750, lr = 0.0005
I0526 12:09:25.228389 26141 solver.cpp:237] Iteration 370500, loss = 1.37421
I0526 12:09:25.228557 26141 solver.cpp:253]     Train net output #0: loss = 1.37422 (* 1 = 1.37422 loss)
I0526 12:09:25.228572 26141 sgd_solver.cpp:106] Iteration 370500, lr = 0.0005
I0526 12:09:37.397825 26141 solver.cpp:237] Iteration 371250, loss = 0.986226
I0526 12:09:37.397861 26141 solver.cpp:253]     Train net output #0: loss = 0.986229 (* 1 = 0.986229 loss)
I0526 12:09:37.397876 26141 sgd_solver.cpp:106] Iteration 371250, lr = 0.0005
I0526 12:09:49.602756 26141 solver.cpp:237] Iteration 372000, loss = 0.846575
I0526 12:09:49.602802 26141 solver.cpp:253]     Train net output #0: loss = 0.846578 (* 1 = 0.846578 loss)
I0526 12:09:49.602816 26141 sgd_solver.cpp:106] Iteration 372000, lr = 0.0005
I0526 12:10:01.827049 26141 solver.cpp:237] Iteration 372750, loss = 1.11225
I0526 12:10:01.827206 26141 solver.cpp:253]     Train net output #0: loss = 1.11225 (* 1 = 1.11225 loss)
I0526 12:10:01.827220 26141 sgd_solver.cpp:106] Iteration 372750, lr = 0.0005
I0526 12:10:14.031000 26141 solver.cpp:237] Iteration 373500, loss = 1.1089
I0526 12:10:14.031047 26141 solver.cpp:253]     Train net output #0: loss = 1.1089 (* 1 = 1.1089 loss)
I0526 12:10:14.031062 26141 sgd_solver.cpp:106] Iteration 373500, lr = 0.0005
I0526 12:10:26.229478 26141 solver.cpp:237] Iteration 374250, loss = 1.23456
I0526 12:10:26.229513 26141 solver.cpp:253]     Train net output #0: loss = 1.23457 (* 1 = 1.23457 loss)
I0526 12:10:26.229527 26141 sgd_solver.cpp:106] Iteration 374250, lr = 0.0005
I0526 12:10:38.385882 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_375000.caffemodel
I0526 12:10:38.434748 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_375000.solverstate
I0526 12:10:38.459894 26141 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 12:11:51.135396 26141 solver.cpp:409]     Test net output #0: accuracy = 0.891829
I0526 12:11:51.135561 26141 solver.cpp:409]     Test net output #1: loss = 0.357375 (* 1 = 0.357375 loss)
I0526 12:12:11.957059 26141 solver.cpp:237] Iteration 375000, loss = 1.10021
I0526 12:12:11.957111 26141 solver.cpp:253]     Train net output #0: loss = 1.10022 (* 1 = 1.10022 loss)
I0526 12:12:11.957126 26141 sgd_solver.cpp:106] Iteration 375000, lr = 0.0005
I0526 12:12:24.128057 26141 solver.cpp:237] Iteration 375750, loss = 1.23954
I0526 12:12:24.128231 26141 solver.cpp:253]     Train net output #0: loss = 1.23954 (* 1 = 1.23954 loss)
I0526 12:12:24.128245 26141 sgd_solver.cpp:106] Iteration 375750, lr = 0.0005
I0526 12:12:36.200824 26141 solver.cpp:237] Iteration 376500, loss = 0.876693
I0526 12:12:36.200860 26141 solver.cpp:253]     Train net output #0: loss = 0.876697 (* 1 = 0.876697 loss)
I0526 12:12:36.200875 26141 sgd_solver.cpp:106] Iteration 376500, lr = 0.0005
I0526 12:12:48.294069 26141 solver.cpp:237] Iteration 377250, loss = 1.62129
I0526 12:12:48.294113 26141 solver.cpp:253]     Train net output #0: loss = 1.62129 (* 1 = 1.62129 loss)
I0526 12:12:48.294127 26141 sgd_solver.cpp:106] Iteration 377250, lr = 0.0005
I0526 12:13:00.467875 26141 solver.cpp:237] Iteration 378000, loss = 1.11518
I0526 12:13:00.468024 26141 solver.cpp:253]     Train net output #0: loss = 1.11518 (* 1 = 1.11518 loss)
I0526 12:13:00.468039 26141 sgd_solver.cpp:106] Iteration 378000, lr = 0.0005
I0526 12:13:12.648152 26141 solver.cpp:237] Iteration 378750, loss = 1.68032
I0526 12:13:12.648202 26141 solver.cpp:253]     Train net output #0: loss = 1.68032 (* 1 = 1.68032 loss)
I0526 12:13:12.648216 26141 sgd_solver.cpp:106] Iteration 378750, lr = 0.0005
I0526 12:13:24.769373 26141 solver.cpp:237] Iteration 379500, loss = 0.895998
I0526 12:13:24.769410 26141 solver.cpp:253]     Train net output #0: loss = 0.896002 (* 1 = 0.896002 loss)
I0526 12:13:24.769424 26141 sgd_solver.cpp:106] Iteration 379500, lr = 0.0005
I0526 12:13:57.763247 26141 solver.cpp:237] Iteration 380250, loss = 1.42669
I0526 12:13:57.763414 26141 solver.cpp:253]     Train net output #0: loss = 1.42669 (* 1 = 1.42669 loss)
I0526 12:13:57.763429 26141 sgd_solver.cpp:106] Iteration 380250, lr = 0.0005
I0526 12:14:09.854075 26141 solver.cpp:237] Iteration 381000, loss = 0.98797
I0526 12:14:09.854111 26141 solver.cpp:253]     Train net output #0: loss = 0.987974 (* 1 = 0.987974 loss)
I0526 12:14:09.854125 26141 sgd_solver.cpp:106] Iteration 381000, lr = 0.0005
I0526 12:14:21.940330 26141 solver.cpp:237] Iteration 381750, loss = 1.24972
I0526 12:14:21.940373 26141 solver.cpp:253]     Train net output #0: loss = 1.24973 (* 1 = 1.24973 loss)
I0526 12:14:21.940387 26141 sgd_solver.cpp:106] Iteration 381750, lr = 0.0005
I0526 12:14:34.009351 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_382500.caffemodel
I0526 12:14:34.058709 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_382500.solverstate
I0526 12:14:34.091881 26141 solver.cpp:237] Iteration 382500, loss = 1.1706
I0526 12:14:34.091933 26141 solver.cpp:253]     Train net output #0: loss = 1.17061 (* 1 = 1.17061 loss)
I0526 12:14:34.091946 26141 sgd_solver.cpp:106] Iteration 382500, lr = 0.0005
I0526 12:14:46.192137 26141 solver.cpp:237] Iteration 383250, loss = 0.687595
I0526 12:14:46.192189 26141 solver.cpp:253]     Train net output #0: loss = 0.687599 (* 1 = 0.687599 loss)
I0526 12:14:46.192203 26141 sgd_solver.cpp:106] Iteration 383250, lr = 0.0005
I0526 12:14:58.330592 26141 solver.cpp:237] Iteration 384000, loss = 1.22235
I0526 12:14:58.330628 26141 solver.cpp:253]     Train net output #0: loss = 1.22235 (* 1 = 1.22235 loss)
I0526 12:14:58.330641 26141 sgd_solver.cpp:106] Iteration 384000, lr = 0.0005
I0526 12:15:10.434334 26141 solver.cpp:237] Iteration 384750, loss = 1.22558
I0526 12:15:10.434507 26141 solver.cpp:253]     Train net output #0: loss = 1.22558 (* 1 = 1.22558 loss)
I0526 12:15:10.434521 26141 sgd_solver.cpp:106] Iteration 384750, lr = 0.0005
I0526 12:15:43.417003 26141 solver.cpp:237] Iteration 385500, loss = 0.897796
I0526 12:15:43.417176 26141 solver.cpp:253]     Train net output #0: loss = 0.8978 (* 1 = 0.8978 loss)
I0526 12:15:43.417191 26141 sgd_solver.cpp:106] Iteration 385500, lr = 0.0005
I0526 12:15:55.557384 26141 solver.cpp:237] Iteration 386250, loss = 1.40633
I0526 12:15:55.557420 26141 solver.cpp:253]     Train net output #0: loss = 1.40634 (* 1 = 1.40634 loss)
I0526 12:15:55.557432 26141 sgd_solver.cpp:106] Iteration 386250, lr = 0.0005
I0526 12:16:07.697113 26141 solver.cpp:237] Iteration 387000, loss = 1.00266
I0526 12:16:07.697154 26141 solver.cpp:253]     Train net output #0: loss = 1.00266 (* 1 = 1.00266 loss)
I0526 12:16:07.697168 26141 sgd_solver.cpp:106] Iteration 387000, lr = 0.0005
I0526 12:16:19.841681 26141 solver.cpp:237] Iteration 387750, loss = 0.913731
I0526 12:16:19.841836 26141 solver.cpp:253]     Train net output #0: loss = 0.913735 (* 1 = 0.913735 loss)
I0526 12:16:19.841852 26141 sgd_solver.cpp:106] Iteration 387750, lr = 0.0005
I0526 12:16:31.989724 26141 solver.cpp:237] Iteration 388500, loss = 0.931399
I0526 12:16:31.989773 26141 solver.cpp:253]     Train net output #0: loss = 0.931402 (* 1 = 0.931402 loss)
I0526 12:16:31.989785 26141 sgd_solver.cpp:106] Iteration 388500, lr = 0.0005
I0526 12:16:44.127895 26141 solver.cpp:237] Iteration 389250, loss = 1.10861
I0526 12:16:44.127931 26141 solver.cpp:253]     Train net output #0: loss = 1.10862 (* 1 = 1.10862 loss)
I0526 12:16:44.127945 26141 sgd_solver.cpp:106] Iteration 389250, lr = 0.0005
I0526 12:16:56.223754 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_390000.caffemodel
I0526 12:16:56.275310 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_390000.solverstate
I0526 12:16:56.302172 26141 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 12:17:48.007457 26141 solver.cpp:409]     Test net output #0: accuracy = 0.892782
I0526 12:17:48.007622 26141 solver.cpp:409]     Test net output #1: loss = 0.345296 (* 1 = 0.345296 loss)
I0526 12:18:08.892922 26141 solver.cpp:237] Iteration 390000, loss = 1.20674
I0526 12:18:08.892971 26141 solver.cpp:253]     Train net output #0: loss = 1.20675 (* 1 = 1.20675 loss)
I0526 12:18:08.892988 26141 sgd_solver.cpp:106] Iteration 390000, lr = 0.0005
I0526 12:18:20.999740 26141 solver.cpp:237] Iteration 390750, loss = 0.56638
I0526 12:18:20.999922 26141 solver.cpp:253]     Train net output #0: loss = 0.566384 (* 1 = 0.566384 loss)
I0526 12:18:20.999938 26141 sgd_solver.cpp:106] Iteration 390750, lr = 0.0005
I0526 12:18:33.112948 26141 solver.cpp:237] Iteration 391500, loss = 0.892097
I0526 12:18:33.112994 26141 solver.cpp:253]     Train net output #0: loss = 0.892101 (* 1 = 0.892101 loss)
I0526 12:18:33.113008 26141 sgd_solver.cpp:106] Iteration 391500, lr = 0.0005
I0526 12:18:45.231456 26141 solver.cpp:237] Iteration 392250, loss = 1.52833
I0526 12:18:45.231492 26141 solver.cpp:253]     Train net output #0: loss = 1.52833 (* 1 = 1.52833 loss)
I0526 12:18:45.231508 26141 sgd_solver.cpp:106] Iteration 392250, lr = 0.0005
I0526 12:18:57.350471 26141 solver.cpp:237] Iteration 393000, loss = 1.23781
I0526 12:18:57.350638 26141 solver.cpp:253]     Train net output #0: loss = 1.23782 (* 1 = 1.23782 loss)
I0526 12:18:57.350653 26141 sgd_solver.cpp:106] Iteration 393000, lr = 0.0005
I0526 12:19:09.515166 26141 solver.cpp:237] Iteration 393750, loss = 1.16577
I0526 12:19:09.515202 26141 solver.cpp:253]     Train net output #0: loss = 1.16577 (* 1 = 1.16577 loss)
I0526 12:19:09.515215 26141 sgd_solver.cpp:106] Iteration 393750, lr = 0.0005
I0526 12:19:21.643396 26141 solver.cpp:237] Iteration 394500, loss = 1.24253
I0526 12:19:21.643441 26141 solver.cpp:253]     Train net output #0: loss = 1.24253 (* 1 = 1.24253 loss)
I0526 12:19:21.643455 26141 sgd_solver.cpp:106] Iteration 394500, lr = 0.0005
I0526 12:19:54.666908 26141 solver.cpp:237] Iteration 395250, loss = 1.51506
I0526 12:19:54.667083 26141 solver.cpp:253]     Train net output #0: loss = 1.51506 (* 1 = 1.51506 loss)
I0526 12:19:54.667098 26141 sgd_solver.cpp:106] Iteration 395250, lr = 0.0005
I0526 12:20:06.801729 26141 solver.cpp:237] Iteration 396000, loss = 0.908916
I0526 12:20:06.801766 26141 solver.cpp:253]     Train net output #0: loss = 0.908919 (* 1 = 0.908919 loss)
I0526 12:20:06.801779 26141 sgd_solver.cpp:106] Iteration 396000, lr = 0.0005
I0526 12:20:18.984822 26141 solver.cpp:237] Iteration 396750, loss = 1.18195
I0526 12:20:18.984866 26141 solver.cpp:253]     Train net output #0: loss = 1.18196 (* 1 = 1.18196 loss)
I0526 12:20:18.984882 26141 sgd_solver.cpp:106] Iteration 396750, lr = 0.0005
I0526 12:20:31.157574 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_397500.caffemodel
I0526 12:20:31.209318 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_397500.solverstate
I0526 12:20:31.241763 26141 solver.cpp:237] Iteration 397500, loss = 1.05994
I0526 12:20:31.241809 26141 solver.cpp:253]     Train net output #0: loss = 1.05995 (* 1 = 1.05995 loss)
I0526 12:20:31.241829 26141 sgd_solver.cpp:106] Iteration 397500, lr = 0.0005
I0526 12:20:43.352252 26141 solver.cpp:237] Iteration 398250, loss = 1.59393
I0526 12:20:43.352300 26141 solver.cpp:253]     Train net output #0: loss = 1.59393 (* 1 = 1.59393 loss)
I0526 12:20:43.352314 26141 sgd_solver.cpp:106] Iteration 398250, lr = 0.0005
I0526 12:20:55.518192 26141 solver.cpp:237] Iteration 399000, loss = 1.15434
I0526 12:20:55.518225 26141 solver.cpp:253]     Train net output #0: loss = 1.15435 (* 1 = 1.15435 loss)
I0526 12:20:55.518240 26141 sgd_solver.cpp:106] Iteration 399000, lr = 0.0005
I0526 12:21:07.663480 26141 solver.cpp:237] Iteration 399750, loss = 1.11549
I0526 12:21:07.663651 26141 solver.cpp:253]     Train net output #0: loss = 1.1155 (* 1 = 1.1155 loss)
I0526 12:21:07.663667 26141 sgd_solver.cpp:106] Iteration 399750, lr = 0.0005
I0526 12:21:40.621696 26141 solver.cpp:237] Iteration 400500, loss = 1.10035
I0526 12:21:40.621872 26141 solver.cpp:253]     Train net output #0: loss = 1.10036 (* 1 = 1.10036 loss)
I0526 12:21:40.621886 26141 sgd_solver.cpp:106] Iteration 400500, lr = 0.0005
I0526 12:21:52.705668 26141 solver.cpp:237] Iteration 401250, loss = 1.1039
I0526 12:21:52.705713 26141 solver.cpp:253]     Train net output #0: loss = 1.1039 (* 1 = 1.1039 loss)
I0526 12:21:52.705729 26141 sgd_solver.cpp:106] Iteration 401250, lr = 0.0005
I0526 12:22:04.890139 26141 solver.cpp:237] Iteration 402000, loss = 1.6707
I0526 12:22:04.890177 26141 solver.cpp:253]     Train net output #0: loss = 1.6707 (* 1 = 1.6707 loss)
I0526 12:22:04.890192 26141 sgd_solver.cpp:106] Iteration 402000, lr = 0.0005
I0526 12:22:17.063484 26141 solver.cpp:237] Iteration 402750, loss = 1.08573
I0526 12:22:17.063654 26141 solver.cpp:253]     Train net output #0: loss = 1.08574 (* 1 = 1.08574 loss)
I0526 12:22:17.063668 26141 sgd_solver.cpp:106] Iteration 402750, lr = 0.0005
I0526 12:22:29.192916 26141 solver.cpp:237] Iteration 403500, loss = 1.23119
I0526 12:22:29.192952 26141 solver.cpp:253]     Train net output #0: loss = 1.23119 (* 1 = 1.23119 loss)
I0526 12:22:29.192965 26141 sgd_solver.cpp:106] Iteration 403500, lr = 0.0005
I0526 12:22:41.315018 26141 solver.cpp:237] Iteration 404250, loss = 0.939442
I0526 12:22:41.315055 26141 solver.cpp:253]     Train net output #0: loss = 0.939446 (* 1 = 0.939446 loss)
I0526 12:22:41.315073 26141 sgd_solver.cpp:106] Iteration 404250, lr = 0.0005
I0526 12:22:53.420454 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_405000.caffemodel
I0526 12:22:53.470087 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_405000.solverstate
I0526 12:22:53.495560 26141 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 12:24:06.347594 26141 solver.cpp:409]     Test net output #0: accuracy = 0.896378
I0526 12:24:06.347766 26141 solver.cpp:409]     Test net output #1: loss = 0.339507 (* 1 = 0.339507 loss)
I0526 12:24:27.220101 26141 solver.cpp:237] Iteration 405000, loss = 0.784728
I0526 12:24:27.220155 26141 solver.cpp:253]     Train net output #0: loss = 0.784732 (* 1 = 0.784732 loss)
I0526 12:24:27.220170 26141 sgd_solver.cpp:106] Iteration 405000, lr = 0.0005
I0526 12:24:39.370061 26141 solver.cpp:237] Iteration 405750, loss = 1.26517
I0526 12:24:39.370220 26141 solver.cpp:253]     Train net output #0: loss = 1.26518 (* 1 = 1.26518 loss)
I0526 12:24:39.370235 26141 sgd_solver.cpp:106] Iteration 405750, lr = 0.0005
I0526 12:24:51.545099 26141 solver.cpp:237] Iteration 406500, loss = 1.74929
I0526 12:24:51.545143 26141 solver.cpp:253]     Train net output #0: loss = 1.74929 (* 1 = 1.74929 loss)
I0526 12:24:51.545156 26141 sgd_solver.cpp:106] Iteration 406500, lr = 0.0005
I0526 12:25:03.715165 26141 solver.cpp:237] Iteration 407250, loss = 1.1451
I0526 12:25:03.715201 26141 solver.cpp:253]     Train net output #0: loss = 1.1451 (* 1 = 1.1451 loss)
I0526 12:25:03.715220 26141 sgd_solver.cpp:106] Iteration 407250, lr = 0.0005
I0526 12:25:15.912145 26141 solver.cpp:237] Iteration 408000, loss = 1.37257
I0526 12:25:15.912302 26141 solver.cpp:253]     Train net output #0: loss = 1.37257 (* 1 = 1.37257 loss)
I0526 12:25:15.912317 26141 sgd_solver.cpp:106] Iteration 408000, lr = 0.0005
I0526 12:25:28.066200 26141 solver.cpp:237] Iteration 408750, loss = 0.895496
I0526 12:25:28.066237 26141 solver.cpp:253]     Train net output #0: loss = 0.8955 (* 1 = 0.8955 loss)
I0526 12:25:28.066262 26141 sgd_solver.cpp:106] Iteration 408750, lr = 0.0005
I0526 12:25:40.227358 26141 solver.cpp:237] Iteration 409500, loss = 1.12935
I0526 12:25:40.227402 26141 solver.cpp:253]     Train net output #0: loss = 1.12935 (* 1 = 1.12935 loss)
I0526 12:25:40.227416 26141 sgd_solver.cpp:106] Iteration 409500, lr = 0.0005
I0526 12:26:13.312791 26141 solver.cpp:237] Iteration 410250, loss = 1.16402
I0526 12:26:13.312968 26141 solver.cpp:253]     Train net output #0: loss = 1.16402 (* 1 = 1.16402 loss)
I0526 12:26:13.312983 26141 sgd_solver.cpp:106] Iteration 410250, lr = 0.0005
I0526 12:26:25.485333 26141 solver.cpp:237] Iteration 411000, loss = 0.774578
I0526 12:26:25.485380 26141 solver.cpp:253]     Train net output #0: loss = 0.774582 (* 1 = 0.774582 loss)
I0526 12:26:25.485394 26141 sgd_solver.cpp:106] Iteration 411000, lr = 0.0005
I0526 12:26:37.644412 26141 solver.cpp:237] Iteration 411750, loss = 1.00425
I0526 12:26:37.644448 26141 solver.cpp:253]     Train net output #0: loss = 1.00426 (* 1 = 1.00426 loss)
I0526 12:26:37.644462 26141 sgd_solver.cpp:106] Iteration 411750, lr = 0.0005
I0526 12:26:49.779675 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_412500.caffemodel
I0526 12:26:49.828637 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_412500.solverstate
I0526 12:26:49.858794 26141 solver.cpp:237] Iteration 412500, loss = 1.45974
I0526 12:26:49.858836 26141 solver.cpp:253]     Train net output #0: loss = 1.45975 (* 1 = 1.45975 loss)
I0526 12:26:49.858853 26141 sgd_solver.cpp:106] Iteration 412500, lr = 0.0005
I0526 12:27:02.041553 26141 solver.cpp:237] Iteration 413250, loss = 0.983178
I0526 12:27:02.041589 26141 solver.cpp:253]     Train net output #0: loss = 0.983182 (* 1 = 0.983182 loss)
I0526 12:27:02.041604 26141 sgd_solver.cpp:106] Iteration 413250, lr = 0.0005
I0526 12:27:14.175158 26141 solver.cpp:237] Iteration 414000, loss = 1.10294
I0526 12:27:14.175191 26141 solver.cpp:253]     Train net output #0: loss = 1.10294 (* 1 = 1.10294 loss)
I0526 12:27:14.175205 26141 sgd_solver.cpp:106] Iteration 414000, lr = 0.0005
I0526 12:27:26.307194 26141 solver.cpp:237] Iteration 414750, loss = 0.969304
I0526 12:27:26.307363 26141 solver.cpp:253]     Train net output #0: loss = 0.969308 (* 1 = 0.969308 loss)
I0526 12:27:26.307379 26141 sgd_solver.cpp:106] Iteration 414750, lr = 0.0005
I0526 12:27:59.329253 26141 solver.cpp:237] Iteration 415500, loss = 1.28561
I0526 12:27:59.329432 26141 solver.cpp:253]     Train net output #0: loss = 1.28562 (* 1 = 1.28562 loss)
I0526 12:27:59.329447 26141 sgd_solver.cpp:106] Iteration 415500, lr = 0.0005
I0526 12:28:11.493290 26141 solver.cpp:237] Iteration 416250, loss = 1.27702
I0526 12:28:11.493333 26141 solver.cpp:253]     Train net output #0: loss = 1.27703 (* 1 = 1.27703 loss)
I0526 12:28:11.493346 26141 sgd_solver.cpp:106] Iteration 416250, lr = 0.0005
I0526 12:28:23.706629 26141 solver.cpp:237] Iteration 417000, loss = 1.23245
I0526 12:28:23.706665 26141 solver.cpp:253]     Train net output #0: loss = 1.23245 (* 1 = 1.23245 loss)
I0526 12:28:23.706678 26141 sgd_solver.cpp:106] Iteration 417000, lr = 0.0005
I0526 12:28:35.867725 26141 solver.cpp:237] Iteration 417750, loss = 0.712133
I0526 12:28:35.867885 26141 solver.cpp:253]     Train net output #0: loss = 0.712137 (* 1 = 0.712137 loss)
I0526 12:28:35.867899 26141 sgd_solver.cpp:106] Iteration 417750, lr = 0.0005
I0526 12:28:47.994833 26141 solver.cpp:237] Iteration 418500, loss = 0.941594
I0526 12:28:47.994868 26141 solver.cpp:253]     Train net output #0: loss = 0.941598 (* 1 = 0.941598 loss)
I0526 12:28:47.994885 26141 sgd_solver.cpp:106] Iteration 418500, lr = 0.0005
I0526 12:29:00.150518 26141 solver.cpp:237] Iteration 419250, loss = 0.948991
I0526 12:29:00.150564 26141 solver.cpp:253]     Train net output #0: loss = 0.948995 (* 1 = 0.948995 loss)
I0526 12:29:00.150578 26141 sgd_solver.cpp:106] Iteration 419250, lr = 0.0005
I0526 12:29:12.308588 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_420000.caffemodel
I0526 12:29:12.358651 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_420000.solverstate
I0526 12:29:12.384173 26141 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 12:30:04.403421 26141 solver.cpp:409]     Test net output #0: accuracy = 0.894829
I0526 12:30:04.403604 26141 solver.cpp:409]     Test net output #1: loss = 0.331896 (* 1 = 0.331896 loss)
I0526 12:30:25.263535 26141 solver.cpp:237] Iteration 420000, loss = 1.6071
I0526 12:30:25.263587 26141 solver.cpp:253]     Train net output #0: loss = 1.6071 (* 1 = 1.6071 loss)
I0526 12:30:25.263602 26141 sgd_solver.cpp:106] Iteration 420000, lr = 0.0005
I0526 12:30:37.399166 26141 solver.cpp:237] Iteration 420750, loss = 1.09717
I0526 12:30:37.399340 26141 solver.cpp:253]     Train net output #0: loss = 1.09718 (* 1 = 1.09718 loss)
I0526 12:30:37.399356 26141 sgd_solver.cpp:106] Iteration 420750, lr = 0.0005
I0526 12:30:49.561310 26141 solver.cpp:237] Iteration 421500, loss = 1.07917
I0526 12:30:49.561345 26141 solver.cpp:253]     Train net output #0: loss = 1.07917 (* 1 = 1.07917 loss)
I0526 12:30:49.561358 26141 sgd_solver.cpp:106] Iteration 421500, lr = 0.0005
I0526 12:31:01.738780 26141 solver.cpp:237] Iteration 422250, loss = 1.34581
I0526 12:31:01.738821 26141 solver.cpp:253]     Train net output #0: loss = 1.34581 (* 1 = 1.34581 loss)
I0526 12:31:01.738842 26141 sgd_solver.cpp:106] Iteration 422250, lr = 0.0005
I0526 12:31:13.876896 26141 solver.cpp:237] Iteration 423000, loss = 1.05285
I0526 12:31:13.877048 26141 solver.cpp:253]     Train net output #0: loss = 1.05285 (* 1 = 1.05285 loss)
I0526 12:31:13.877063 26141 sgd_solver.cpp:106] Iteration 423000, lr = 0.0005
I0526 12:31:25.987247 26141 solver.cpp:237] Iteration 423750, loss = 1.07331
I0526 12:31:25.987284 26141 solver.cpp:253]     Train net output #0: loss = 1.07331 (* 1 = 1.07331 loss)
I0526 12:31:25.987301 26141 sgd_solver.cpp:106] Iteration 423750, lr = 0.0005
I0526 12:31:38.151594 26141 solver.cpp:237] Iteration 424500, loss = 0.832913
I0526 12:31:38.151631 26141 solver.cpp:253]     Train net output #0: loss = 0.832917 (* 1 = 0.832917 loss)
I0526 12:31:38.151645 26141 sgd_solver.cpp:106] Iteration 424500, lr = 0.0005
I0526 12:32:11.259258 26141 solver.cpp:237] Iteration 425250, loss = 1.18407
I0526 12:32:11.259433 26141 solver.cpp:253]     Train net output #0: loss = 1.18407 (* 1 = 1.18407 loss)
I0526 12:32:11.259448 26141 sgd_solver.cpp:106] Iteration 425250, lr = 0.0005
I0526 12:32:23.422142 26141 solver.cpp:237] Iteration 426000, loss = 1.56932
I0526 12:32:23.422191 26141 solver.cpp:253]     Train net output #0: loss = 1.56933 (* 1 = 1.56933 loss)
I0526 12:32:23.422204 26141 sgd_solver.cpp:106] Iteration 426000, lr = 0.0005
I0526 12:32:35.559402 26141 solver.cpp:237] Iteration 426750, loss = 1.04199
I0526 12:32:35.559438 26141 solver.cpp:253]     Train net output #0: loss = 1.04199 (* 1 = 1.04199 loss)
I0526 12:32:35.559450 26141 sgd_solver.cpp:106] Iteration 426750, lr = 0.0005
I0526 12:32:47.696910 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_427500.caffemodel
I0526 12:32:47.749989 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_427500.solverstate
I0526 12:32:47.782369 26141 solver.cpp:237] Iteration 427500, loss = 1.59268
I0526 12:32:47.782418 26141 solver.cpp:253]     Train net output #0: loss = 1.59268 (* 1 = 1.59268 loss)
I0526 12:32:47.782433 26141 sgd_solver.cpp:106] Iteration 427500, lr = 0.0005
I0526 12:32:59.941524 26141 solver.cpp:237] Iteration 428250, loss = 1.08667
I0526 12:32:59.941560 26141 solver.cpp:253]     Train net output #0: loss = 1.08668 (* 1 = 1.08668 loss)
I0526 12:32:59.941573 26141 sgd_solver.cpp:106] Iteration 428250, lr = 0.0005
I0526 12:33:12.120715 26141 solver.cpp:237] Iteration 429000, loss = 1.53563
I0526 12:33:12.120767 26141 solver.cpp:253]     Train net output #0: loss = 1.53563 (* 1 = 1.53563 loss)
I0526 12:33:12.120780 26141 sgd_solver.cpp:106] Iteration 429000, lr = 0.0005
I0526 12:33:24.312702 26141 solver.cpp:237] Iteration 429750, loss = 1.24334
I0526 12:33:24.312873 26141 solver.cpp:253]     Train net output #0: loss = 1.24335 (* 1 = 1.24335 loss)
I0526 12:33:24.312887 26141 sgd_solver.cpp:106] Iteration 429750, lr = 0.0005
I0526 12:33:57.391899 26141 solver.cpp:237] Iteration 430500, loss = 1.35885
I0526 12:33:57.392078 26141 solver.cpp:253]     Train net output #0: loss = 1.35886 (* 1 = 1.35886 loss)
I0526 12:33:57.392093 26141 sgd_solver.cpp:106] Iteration 430500, lr = 0.0005
I0526 12:34:09.522833 26141 solver.cpp:237] Iteration 431250, loss = 1.06937
I0526 12:34:09.522869 26141 solver.cpp:253]     Train net output #0: loss = 1.06937 (* 1 = 1.06937 loss)
I0526 12:34:09.522883 26141 sgd_solver.cpp:106] Iteration 431250, lr = 0.0005
I0526 12:34:21.631542 26141 solver.cpp:237] Iteration 432000, loss = 1.2329
I0526 12:34:21.631583 26141 solver.cpp:253]     Train net output #0: loss = 1.23291 (* 1 = 1.23291 loss)
I0526 12:34:21.631600 26141 sgd_solver.cpp:106] Iteration 432000, lr = 0.0005
I0526 12:34:33.746441 26141 solver.cpp:237] Iteration 432750, loss = 1.14602
I0526 12:34:33.746595 26141 solver.cpp:253]     Train net output #0: loss = 1.14602 (* 1 = 1.14602 loss)
I0526 12:34:33.746610 26141 sgd_solver.cpp:106] Iteration 432750, lr = 0.0005
I0526 12:34:45.862023 26141 solver.cpp:237] Iteration 433500, loss = 1.12633
I0526 12:34:45.862069 26141 solver.cpp:253]     Train net output #0: loss = 1.12633 (* 1 = 1.12633 loss)
I0526 12:34:45.862087 26141 sgd_solver.cpp:106] Iteration 433500, lr = 0.0005
I0526 12:34:57.983300 26141 solver.cpp:237] Iteration 434250, loss = 1.31675
I0526 12:34:57.983336 26141 solver.cpp:253]     Train net output #0: loss = 1.31675 (* 1 = 1.31675 loss)
I0526 12:34:57.983350 26141 sgd_solver.cpp:106] Iteration 434250, lr = 0.0005
I0526 12:35:10.169258 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_435000.caffemodel
I0526 12:35:10.220713 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_435000.solverstate
I0526 12:35:10.248364 26141 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 12:36:23.121459 26141 solver.cpp:409]     Test net output #0: accuracy = 0.896017
I0526 12:36:23.121634 26141 solver.cpp:409]     Test net output #1: loss = 0.32658 (* 1 = 0.32658 loss)
I0526 12:36:43.994215 26141 solver.cpp:237] Iteration 435000, loss = 1.14171
I0526 12:36:43.994271 26141 solver.cpp:253]     Train net output #0: loss = 1.14171 (* 1 = 1.14171 loss)
I0526 12:36:43.994287 26141 sgd_solver.cpp:106] Iteration 435000, lr = 0.0005
I0526 12:36:56.133548 26141 solver.cpp:237] Iteration 435750, loss = 1.06468
I0526 12:36:56.133714 26141 solver.cpp:253]     Train net output #0: loss = 1.06468 (* 1 = 1.06468 loss)
I0526 12:36:56.133728 26141 sgd_solver.cpp:106] Iteration 435750, lr = 0.0005
I0526 12:37:08.258661 26141 solver.cpp:237] Iteration 436500, loss = 1.33694
I0526 12:37:08.258697 26141 solver.cpp:253]     Train net output #0: loss = 1.33695 (* 1 = 1.33695 loss)
I0526 12:37:08.258709 26141 sgd_solver.cpp:106] Iteration 436500, lr = 0.0005
I0526 12:37:20.367620 26141 solver.cpp:237] Iteration 437250, loss = 1.44353
I0526 12:37:20.367667 26141 solver.cpp:253]     Train net output #0: loss = 1.44354 (* 1 = 1.44354 loss)
I0526 12:37:20.367682 26141 sgd_solver.cpp:106] Iteration 437250, lr = 0.0005
I0526 12:37:32.481397 26141 solver.cpp:237] Iteration 438000, loss = 1.02075
I0526 12:37:32.481554 26141 solver.cpp:253]     Train net output #0: loss = 1.02075 (* 1 = 1.02075 loss)
I0526 12:37:32.481570 26141 sgd_solver.cpp:106] Iteration 438000, lr = 0.0005
I0526 12:37:44.638712 26141 solver.cpp:237] Iteration 438750, loss = 1.21697
I0526 12:37:44.638756 26141 solver.cpp:253]     Train net output #0: loss = 1.21697 (* 1 = 1.21697 loss)
I0526 12:37:44.638769 26141 sgd_solver.cpp:106] Iteration 438750, lr = 0.0005
I0526 12:37:56.811066 26141 solver.cpp:237] Iteration 439500, loss = 1.4499
I0526 12:37:56.811102 26141 solver.cpp:253]     Train net output #0: loss = 1.4499 (* 1 = 1.4499 loss)
I0526 12:37:56.811115 26141 sgd_solver.cpp:106] Iteration 439500, lr = 0.0005
I0526 12:38:29.832798 26141 solver.cpp:237] Iteration 440250, loss = 1.37911
I0526 12:38:29.832980 26141 solver.cpp:253]     Train net output #0: loss = 1.37912 (* 1 = 1.37912 loss)
I0526 12:38:29.832994 26141 sgd_solver.cpp:106] Iteration 440250, lr = 0.0005
I0526 12:38:41.926669 26141 solver.cpp:237] Iteration 441000, loss = 1.13639
I0526 12:38:41.926705 26141 solver.cpp:253]     Train net output #0: loss = 1.13639 (* 1 = 1.13639 loss)
I0526 12:38:41.926719 26141 sgd_solver.cpp:106] Iteration 441000, lr = 0.0005
I0526 12:38:54.033051 26141 solver.cpp:237] Iteration 441750, loss = 1.779
I0526 12:38:54.033087 26141 solver.cpp:253]     Train net output #0: loss = 1.77901 (* 1 = 1.77901 loss)
I0526 12:38:54.033100 26141 sgd_solver.cpp:106] Iteration 441750, lr = 0.0005
I0526 12:39:06.108274 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_442500.caffemodel
I0526 12:39:06.157397 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_442500.solverstate
I0526 12:39:06.187317 26141 solver.cpp:237] Iteration 442500, loss = 1.27171
I0526 12:39:06.187362 26141 solver.cpp:253]     Train net output #0: loss = 1.27171 (* 1 = 1.27171 loss)
I0526 12:39:06.187376 26141 sgd_solver.cpp:106] Iteration 442500, lr = 0.0005
I0526 12:39:18.331073 26141 solver.cpp:237] Iteration 443250, loss = 1.08639
I0526 12:39:18.331110 26141 solver.cpp:253]     Train net output #0: loss = 1.08639 (* 1 = 1.08639 loss)
I0526 12:39:18.331125 26141 sgd_solver.cpp:106] Iteration 443250, lr = 0.0005
I0526 12:39:30.520112 26141 solver.cpp:237] Iteration 444000, loss = 0.704783
I0526 12:39:30.520158 26141 solver.cpp:253]     Train net output #0: loss = 0.704786 (* 1 = 0.704786 loss)
I0526 12:39:30.520170 26141 sgd_solver.cpp:106] Iteration 444000, lr = 0.0005
I0526 12:39:42.711057 26141 solver.cpp:237] Iteration 444750, loss = 0.961964
I0526 12:39:42.711221 26141 solver.cpp:253]     Train net output #0: loss = 0.961968 (* 1 = 0.961968 loss)
I0526 12:39:42.711236 26141 sgd_solver.cpp:106] Iteration 444750, lr = 0.0005
I0526 12:40:15.723155 26141 solver.cpp:237] Iteration 445500, loss = 1.08785
I0526 12:40:15.723333 26141 solver.cpp:253]     Train net output #0: loss = 1.08785 (* 1 = 1.08785 loss)
I0526 12:40:15.723347 26141 sgd_solver.cpp:106] Iteration 445500, lr = 0.0005
I0526 12:40:27.872819 26141 solver.cpp:237] Iteration 446250, loss = 1.39012
I0526 12:40:27.872855 26141 solver.cpp:253]     Train net output #0: loss = 1.39013 (* 1 = 1.39013 loss)
I0526 12:40:27.872869 26141 sgd_solver.cpp:106] Iteration 446250, lr = 0.0005
I0526 12:40:40.037902 26141 solver.cpp:237] Iteration 447000, loss = 1.2456
I0526 12:40:40.037948 26141 solver.cpp:253]     Train net output #0: loss = 1.24561 (* 1 = 1.24561 loss)
I0526 12:40:40.037961 26141 sgd_solver.cpp:106] Iteration 447000, lr = 0.0005
I0526 12:40:52.206192 26141 solver.cpp:237] Iteration 447750, loss = 1.32275
I0526 12:40:52.206354 26141 solver.cpp:253]     Train net output #0: loss = 1.32275 (* 1 = 1.32275 loss)
I0526 12:40:52.206370 26141 sgd_solver.cpp:106] Iteration 447750, lr = 0.0005
I0526 12:41:04.378564 26141 solver.cpp:237] Iteration 448500, loss = 1.01817
I0526 12:41:04.378604 26141 solver.cpp:253]     Train net output #0: loss = 1.01817 (* 1 = 1.01817 loss)
I0526 12:41:04.378618 26141 sgd_solver.cpp:106] Iteration 448500, lr = 0.0005
I0526 12:41:16.555886 26141 solver.cpp:237] Iteration 449250, loss = 1.22767
I0526 12:41:16.555922 26141 solver.cpp:253]     Train net output #0: loss = 1.22767 (* 1 = 1.22767 loss)
I0526 12:41:16.555938 26141 sgd_solver.cpp:106] Iteration 449250, lr = 0.0005
I0526 12:41:28.705817 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_450000.caffemodel
I0526 12:41:28.754585 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_450000.solverstate
I0526 12:41:28.779386 26141 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 12:42:20.459947 26141 solver.cpp:409]     Test net output #0: accuracy = 0.896312
I0526 12:42:20.460124 26141 solver.cpp:409]     Test net output #1: loss = 0.317667 (* 1 = 0.317667 loss)
I0526 12:42:41.351701 26141 solver.cpp:237] Iteration 450000, loss = 1.04462
I0526 12:42:41.351752 26141 solver.cpp:253]     Train net output #0: loss = 1.04462 (* 1 = 1.04462 loss)
I0526 12:42:41.351766 26141 sgd_solver.cpp:106] Iteration 450000, lr = 0.0005
I0526 12:42:53.542865 26141 solver.cpp:237] Iteration 450750, loss = 0.998979
I0526 12:42:53.543030 26141 solver.cpp:253]     Train net output #0: loss = 0.998982 (* 1 = 0.998982 loss)
I0526 12:42:53.543046 26141 sgd_solver.cpp:106] Iteration 450750, lr = 0.0005
I0526 12:43:05.751339 26141 solver.cpp:237] Iteration 451500, loss = 1.10995
I0526 12:43:05.751385 26141 solver.cpp:253]     Train net output #0: loss = 1.10995 (* 1 = 1.10995 loss)
I0526 12:43:05.751399 26141 sgd_solver.cpp:106] Iteration 451500, lr = 0.0005
I0526 12:43:17.917315 26141 solver.cpp:237] Iteration 452250, loss = 1.01572
I0526 12:43:17.917351 26141 solver.cpp:253]     Train net output #0: loss = 1.01573 (* 1 = 1.01573 loss)
I0526 12:43:17.917366 26141 sgd_solver.cpp:106] Iteration 452250, lr = 0.0005
I0526 12:43:30.074720 26141 solver.cpp:237] Iteration 453000, loss = 1.03013
I0526 12:43:30.074878 26141 solver.cpp:253]     Train net output #0: loss = 1.03014 (* 1 = 1.03014 loss)
I0526 12:43:30.074893 26141 sgd_solver.cpp:106] Iteration 453000, lr = 0.0005
I0526 12:43:42.244833 26141 solver.cpp:237] Iteration 453750, loss = 1.43884
I0526 12:43:42.244868 26141 solver.cpp:253]     Train net output #0: loss = 1.43885 (* 1 = 1.43885 loss)
I0526 12:43:42.244882 26141 sgd_solver.cpp:106] Iteration 453750, lr = 0.0005
I0526 12:43:54.444321 26141 solver.cpp:237] Iteration 454500, loss = 1.07901
I0526 12:43:54.444356 26141 solver.cpp:253]     Train net output #0: loss = 1.07901 (* 1 = 1.07901 loss)
I0526 12:43:54.444370 26141 sgd_solver.cpp:106] Iteration 454500, lr = 0.0005
I0526 12:44:27.512475 26141 solver.cpp:237] Iteration 455250, loss = 1.12955
I0526 12:44:27.512655 26141 solver.cpp:253]     Train net output #0: loss = 1.12955 (* 1 = 1.12955 loss)
I0526 12:44:27.512671 26141 sgd_solver.cpp:106] Iteration 455250, lr = 0.0005
I0526 12:44:39.743341 26141 solver.cpp:237] Iteration 456000, loss = 1.04428
I0526 12:44:39.743377 26141 solver.cpp:253]     Train net output #0: loss = 1.04428 (* 1 = 1.04428 loss)
I0526 12:44:39.743396 26141 sgd_solver.cpp:106] Iteration 456000, lr = 0.0005
I0526 12:44:51.964139 26141 solver.cpp:237] Iteration 456750, loss = 1.30492
I0526 12:44:51.964182 26141 solver.cpp:253]     Train net output #0: loss = 1.30492 (* 1 = 1.30492 loss)
I0526 12:44:51.964200 26141 sgd_solver.cpp:106] Iteration 456750, lr = 0.0005
I0526 12:45:04.164713 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_457500.caffemodel
I0526 12:45:04.214293 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_457500.solverstate
I0526 12:45:04.244581 26141 solver.cpp:237] Iteration 457500, loss = 1.2101
I0526 12:45:04.244623 26141 solver.cpp:253]     Train net output #0: loss = 1.2101 (* 1 = 1.2101 loss)
I0526 12:45:04.244640 26141 sgd_solver.cpp:106] Iteration 457500, lr = 0.0005
I0526 12:45:16.458683 26141 solver.cpp:237] Iteration 458250, loss = 0.988
I0526 12:45:16.458730 26141 solver.cpp:253]     Train net output #0: loss = 0.988002 (* 1 = 0.988002 loss)
I0526 12:45:16.458745 26141 sgd_solver.cpp:106] Iteration 458250, lr = 0.0005
I0526 12:45:28.705255 26141 solver.cpp:237] Iteration 459000, loss = 0.716341
I0526 12:45:28.705291 26141 solver.cpp:253]     Train net output #0: loss = 0.716344 (* 1 = 0.716344 loss)
I0526 12:45:28.705304 26141 sgd_solver.cpp:106] Iteration 459000, lr = 0.0005
I0526 12:45:40.933596 26141 solver.cpp:237] Iteration 459750, loss = 1.01964
I0526 12:45:40.933779 26141 solver.cpp:253]     Train net output #0: loss = 1.01964 (* 1 = 1.01964 loss)
I0526 12:45:40.933794 26141 sgd_solver.cpp:106] Iteration 459750, lr = 0.0005
I0526 12:46:13.995767 26141 solver.cpp:237] Iteration 460500, loss = 1.35314
I0526 12:46:13.995951 26141 solver.cpp:253]     Train net output #0: loss = 1.35315 (* 1 = 1.35315 loss)
I0526 12:46:13.995966 26141 sgd_solver.cpp:106] Iteration 460500, lr = 0.0005
I0526 12:46:26.194028 26141 solver.cpp:237] Iteration 461250, loss = 1.28709
I0526 12:46:26.194074 26141 solver.cpp:253]     Train net output #0: loss = 1.28709 (* 1 = 1.28709 loss)
I0526 12:46:26.194088 26141 sgd_solver.cpp:106] Iteration 461250, lr = 0.0005
I0526 12:46:38.452838 26141 solver.cpp:237] Iteration 462000, loss = 1.37064
I0526 12:46:38.452874 26141 solver.cpp:253]     Train net output #0: loss = 1.37064 (* 1 = 1.37064 loss)
I0526 12:46:38.452888 26141 sgd_solver.cpp:106] Iteration 462000, lr = 0.0005
I0526 12:46:50.651914 26141 solver.cpp:237] Iteration 462750, loss = 1.08684
I0526 12:46:50.652096 26141 solver.cpp:253]     Train net output #0: loss = 1.08684 (* 1 = 1.08684 loss)
I0526 12:46:50.652110 26141 sgd_solver.cpp:106] Iteration 462750, lr = 0.0005
I0526 12:47:02.855461 26141 solver.cpp:237] Iteration 463500, loss = 1.03009
I0526 12:47:02.855497 26141 solver.cpp:253]     Train net output #0: loss = 1.03009 (* 1 = 1.03009 loss)
I0526 12:47:02.855510 26141 sgd_solver.cpp:106] Iteration 463500, lr = 0.0005
I0526 12:47:15.064784 26141 solver.cpp:237] Iteration 464250, loss = 0.738847
I0526 12:47:15.064821 26141 solver.cpp:253]     Train net output #0: loss = 0.738849 (* 1 = 0.738849 loss)
I0526 12:47:15.064842 26141 sgd_solver.cpp:106] Iteration 464250, lr = 0.0005
I0526 12:47:27.267781 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_465000.caffemodel
I0526 12:47:27.320396 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_465000.solverstate
I0526 12:47:27.347352 26141 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 12:48:40.192131 26141 solver.cpp:409]     Test net output #0: accuracy = 0.89605
I0526 12:48:40.192312 26141 solver.cpp:409]     Test net output #1: loss = 0.337562 (* 1 = 0.337562 loss)
I0526 12:49:01.097439 26141 solver.cpp:237] Iteration 465000, loss = 1.28465
I0526 12:49:01.097492 26141 solver.cpp:253]     Train net output #0: loss = 1.28465 (* 1 = 1.28465 loss)
I0526 12:49:01.097506 26141 sgd_solver.cpp:106] Iteration 465000, lr = 0.0005
I0526 12:49:13.293762 26141 solver.cpp:237] Iteration 465750, loss = 0.653065
I0526 12:49:13.293928 26141 solver.cpp:253]     Train net output #0: loss = 0.653067 (* 1 = 0.653067 loss)
I0526 12:49:13.293943 26141 sgd_solver.cpp:106] Iteration 465750, lr = 0.0005
I0526 12:49:25.477834 26141 solver.cpp:237] Iteration 466500, loss = 1.21093
I0526 12:49:25.477879 26141 solver.cpp:253]     Train net output #0: loss = 1.21093 (* 1 = 1.21093 loss)
I0526 12:49:25.477891 26141 sgd_solver.cpp:106] Iteration 466500, lr = 0.0005
I0526 12:49:37.649072 26141 solver.cpp:237] Iteration 467250, loss = 1.11056
I0526 12:49:37.649108 26141 solver.cpp:253]     Train net output #0: loss = 1.11056 (* 1 = 1.11056 loss)
I0526 12:49:37.649123 26141 sgd_solver.cpp:106] Iteration 467250, lr = 0.0005
I0526 12:49:49.806731 26141 solver.cpp:237] Iteration 468000, loss = 1.27276
I0526 12:49:49.806913 26141 solver.cpp:253]     Train net output #0: loss = 1.27276 (* 1 = 1.27276 loss)
I0526 12:49:49.806928 26141 sgd_solver.cpp:106] Iteration 468000, lr = 0.0005
I0526 12:50:01.982141 26141 solver.cpp:237] Iteration 468750, loss = 1.12994
I0526 12:50:01.982177 26141 solver.cpp:253]     Train net output #0: loss = 1.12994 (* 1 = 1.12994 loss)
I0526 12:50:01.982190 26141 sgd_solver.cpp:106] Iteration 468750, lr = 0.0005
I0526 12:50:14.161084 26141 solver.cpp:237] Iteration 469500, loss = 1.00115
I0526 12:50:14.161126 26141 solver.cpp:253]     Train net output #0: loss = 1.00115 (* 1 = 1.00115 loss)
I0526 12:50:14.161142 26141 sgd_solver.cpp:106] Iteration 469500, lr = 0.0005
I0526 12:50:47.224289 26141 solver.cpp:237] Iteration 470250, loss = 1.44152
I0526 12:50:47.224472 26141 solver.cpp:253]     Train net output #0: loss = 1.44152 (* 1 = 1.44152 loss)
I0526 12:50:47.224488 26141 sgd_solver.cpp:106] Iteration 470250, lr = 0.0005
I0526 12:50:59.398627 26141 solver.cpp:237] Iteration 471000, loss = 1.09273
I0526 12:50:59.398661 26141 solver.cpp:253]     Train net output #0: loss = 1.09273 (* 1 = 1.09273 loss)
I0526 12:50:59.398675 26141 sgd_solver.cpp:106] Iteration 471000, lr = 0.0005
I0526 12:51:11.611168 26141 solver.cpp:237] Iteration 471750, loss = 1.22477
I0526 12:51:11.611207 26141 solver.cpp:253]     Train net output #0: loss = 1.22478 (* 1 = 1.22478 loss)
I0526 12:51:11.611222 26141 sgd_solver.cpp:106] Iteration 471750, lr = 0.0005
I0526 12:51:23.835796 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_472500.caffemodel
I0526 12:51:23.887118 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_472500.solverstate
I0526 12:51:23.919421 26141 solver.cpp:237] Iteration 472500, loss = 1.09861
I0526 12:51:23.919467 26141 solver.cpp:253]     Train net output #0: loss = 1.09861 (* 1 = 1.09861 loss)
I0526 12:51:23.919483 26141 sgd_solver.cpp:106] Iteration 472500, lr = 0.0005
I0526 12:51:36.039913 26141 solver.cpp:237] Iteration 473250, loss = 0.999689
I0526 12:51:36.039961 26141 solver.cpp:253]     Train net output #0: loss = 0.999691 (* 1 = 0.999691 loss)
I0526 12:51:36.039975 26141 sgd_solver.cpp:106] Iteration 473250, lr = 0.0005
I0526 12:51:48.192730 26141 solver.cpp:237] Iteration 474000, loss = 1.21223
I0526 12:51:48.192765 26141 solver.cpp:253]     Train net output #0: loss = 1.21223 (* 1 = 1.21223 loss)
I0526 12:51:48.192782 26141 sgd_solver.cpp:106] Iteration 474000, lr = 0.0005
I0526 12:52:00.432894 26141 solver.cpp:237] Iteration 474750, loss = 0.82753
I0526 12:52:00.433085 26141 solver.cpp:253]     Train net output #0: loss = 0.827532 (* 1 = 0.827532 loss)
I0526 12:52:00.433101 26141 sgd_solver.cpp:106] Iteration 474750, lr = 0.0005
I0526 12:52:33.533027 26141 solver.cpp:237] Iteration 475500, loss = 1.14
I0526 12:52:33.533208 26141 solver.cpp:253]     Train net output #0: loss = 1.14001 (* 1 = 1.14001 loss)
I0526 12:52:33.533223 26141 sgd_solver.cpp:106] Iteration 475500, lr = 0.0005
I0526 12:52:45.708920 26141 solver.cpp:237] Iteration 476250, loss = 0.903203
I0526 12:52:45.708967 26141 solver.cpp:253]     Train net output #0: loss = 0.903205 (* 1 = 0.903205 loss)
I0526 12:52:45.708981 26141 sgd_solver.cpp:106] Iteration 476250, lr = 0.0005
I0526 12:52:57.888448 26141 solver.cpp:237] Iteration 477000, loss = 1.20586
I0526 12:52:57.888484 26141 solver.cpp:253]     Train net output #0: loss = 1.20586 (* 1 = 1.20586 loss)
I0526 12:52:57.888497 26141 sgd_solver.cpp:106] Iteration 477000, lr = 0.0005
I0526 12:53:10.080984 26141 solver.cpp:237] Iteration 477750, loss = 1.3227
I0526 12:53:10.081156 26141 solver.cpp:253]     Train net output #0: loss = 1.32271 (* 1 = 1.32271 loss)
I0526 12:53:10.081171 26141 sgd_solver.cpp:106] Iteration 477750, lr = 0.0005
I0526 12:53:22.271245 26141 solver.cpp:237] Iteration 478500, loss = 0.899188
I0526 12:53:22.271281 26141 solver.cpp:253]     Train net output #0: loss = 0.89919 (* 1 = 0.89919 loss)
I0526 12:53:22.271297 26141 sgd_solver.cpp:106] Iteration 478500, lr = 0.0005
I0526 12:53:34.471058 26141 solver.cpp:237] Iteration 479250, loss = 1.19046
I0526 12:53:34.471107 26141 solver.cpp:253]     Train net output #0: loss = 1.19046 (* 1 = 1.19046 loss)
I0526 12:53:34.471120 26141 sgd_solver.cpp:106] Iteration 479250, lr = 0.0005
I0526 12:53:46.622654 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_480000.caffemodel
I0526 12:53:46.671808 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_480000.solverstate
I0526 12:53:46.696811 26141 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 12:54:38.695575 26141 solver.cpp:409]     Test net output #0: accuracy = 0.89765
I0526 12:54:38.695757 26141 solver.cpp:409]     Test net output #1: loss = 0.318157 (* 1 = 0.318157 loss)
I0526 12:54:59.542958 26141 solver.cpp:237] Iteration 480000, loss = 1.06348
I0526 12:54:59.543009 26141 solver.cpp:253]     Train net output #0: loss = 1.06349 (* 1 = 1.06349 loss)
I0526 12:54:59.543025 26141 sgd_solver.cpp:106] Iteration 480000, lr = 0.0005
I0526 12:55:11.720799 26141 solver.cpp:237] Iteration 480750, loss = 1.16236
I0526 12:55:11.720978 26141 solver.cpp:253]     Train net output #0: loss = 1.16236 (* 1 = 1.16236 loss)
I0526 12:55:11.720993 26141 sgd_solver.cpp:106] Iteration 480750, lr = 0.0005
I0526 12:55:23.865463 26141 solver.cpp:237] Iteration 481500, loss = 1.12168
I0526 12:55:23.865500 26141 solver.cpp:253]     Train net output #0: loss = 1.12169 (* 1 = 1.12169 loss)
I0526 12:55:23.865514 26141 sgd_solver.cpp:106] Iteration 481500, lr = 0.0005
I0526 12:55:36.004844 26141 solver.cpp:237] Iteration 482250, loss = 1.12178
I0526 12:55:36.004886 26141 solver.cpp:253]     Train net output #0: loss = 1.12178 (* 1 = 1.12178 loss)
I0526 12:55:36.004902 26141 sgd_solver.cpp:106] Iteration 482250, lr = 0.0005
I0526 12:55:48.138326 26141 solver.cpp:237] Iteration 483000, loss = 1.13691
I0526 12:55:48.138485 26141 solver.cpp:253]     Train net output #0: loss = 1.13692 (* 1 = 1.13692 loss)
I0526 12:55:48.138499 26141 sgd_solver.cpp:106] Iteration 483000, lr = 0.0005
I0526 12:56:00.305299 26141 solver.cpp:237] Iteration 483750, loss = 1.12357
I0526 12:56:00.305348 26141 solver.cpp:253]     Train net output #0: loss = 1.12358 (* 1 = 1.12358 loss)
I0526 12:56:00.305362 26141 sgd_solver.cpp:106] Iteration 483750, lr = 0.0005
I0526 12:56:12.531250 26141 solver.cpp:237] Iteration 484500, loss = 0.630895
I0526 12:56:12.531286 26141 solver.cpp:253]     Train net output #0: loss = 0.630897 (* 1 = 0.630897 loss)
I0526 12:56:12.531301 26141 sgd_solver.cpp:106] Iteration 484500, lr = 0.0005
I0526 12:56:45.589283 26141 solver.cpp:237] Iteration 485250, loss = 0.800861
I0526 12:56:45.589469 26141 solver.cpp:253]     Train net output #0: loss = 0.800863 (* 1 = 0.800863 loss)
I0526 12:56:45.589483 26141 sgd_solver.cpp:106] Iteration 485250, lr = 0.0005
I0526 12:56:57.780591 26141 solver.cpp:237] Iteration 486000, loss = 1.02671
I0526 12:56:57.780635 26141 solver.cpp:253]     Train net output #0: loss = 1.02672 (* 1 = 1.02672 loss)
I0526 12:56:57.780650 26141 sgd_solver.cpp:106] Iteration 486000, lr = 0.0005
I0526 12:57:09.974046 26141 solver.cpp:237] Iteration 486750, loss = 1.41406
I0526 12:57:09.974082 26141 solver.cpp:253]     Train net output #0: loss = 1.41406 (* 1 = 1.41406 loss)
I0526 12:57:09.974097 26141 sgd_solver.cpp:106] Iteration 486750, lr = 0.0005
I0526 12:57:22.152614 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_487500.caffemodel
I0526 12:57:22.202167 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_487500.solverstate
I0526 12:57:22.232725 26141 solver.cpp:237] Iteration 487500, loss = 1.37826
I0526 12:57:22.232771 26141 solver.cpp:253]     Train net output #0: loss = 1.37826 (* 1 = 1.37826 loss)
I0526 12:57:22.232785 26141 sgd_solver.cpp:106] Iteration 487500, lr = 0.0005
I0526 12:57:34.427378 26141 solver.cpp:237] Iteration 488250, loss = 0.52583
I0526 12:57:34.427415 26141 solver.cpp:253]     Train net output #0: loss = 0.525832 (* 1 = 0.525832 loss)
I0526 12:57:34.427429 26141 sgd_solver.cpp:106] Iteration 488250, lr = 0.0005
I0526 12:57:46.589434 26141 solver.cpp:237] Iteration 489000, loss = 1.03596
I0526 12:57:46.589481 26141 solver.cpp:253]     Train net output #0: loss = 1.03596 (* 1 = 1.03596 loss)
I0526 12:57:46.589496 26141 sgd_solver.cpp:106] Iteration 489000, lr = 0.0005
I0526 12:57:58.709650 26141 solver.cpp:237] Iteration 489750, loss = 0.737524
I0526 12:57:58.709828 26141 solver.cpp:253]     Train net output #0: loss = 0.737526 (* 1 = 0.737526 loss)
I0526 12:57:58.709842 26141 sgd_solver.cpp:106] Iteration 489750, lr = 0.0005
I0526 12:58:31.708715 26141 solver.cpp:237] Iteration 490500, loss = 1.18167
I0526 12:58:31.708900 26141 solver.cpp:253]     Train net output #0: loss = 1.18167 (* 1 = 1.18167 loss)
I0526 12:58:31.708914 26141 sgd_solver.cpp:106] Iteration 490500, lr = 0.0005
I0526 12:58:43.931463 26141 solver.cpp:237] Iteration 491250, loss = 1.59379
I0526 12:58:43.931498 26141 solver.cpp:253]     Train net output #0: loss = 1.59379 (* 1 = 1.59379 loss)
I0526 12:58:43.931511 26141 sgd_solver.cpp:106] Iteration 491250, lr = 0.0005
I0526 12:58:56.147689 26141 solver.cpp:237] Iteration 492000, loss = 1.43581
I0526 12:58:56.147732 26141 solver.cpp:253]     Train net output #0: loss = 1.43581 (* 1 = 1.43581 loss)
I0526 12:58:56.147750 26141 sgd_solver.cpp:106] Iteration 492000, lr = 0.0005
I0526 12:59:08.316215 26141 solver.cpp:237] Iteration 492750, loss = 1.32195
I0526 12:59:08.316377 26141 solver.cpp:253]     Train net output #0: loss = 1.32195 (* 1 = 1.32195 loss)
I0526 12:59:08.316390 26141 sgd_solver.cpp:106] Iteration 492750, lr = 0.0005
I0526 12:59:20.460196 26141 solver.cpp:237] Iteration 493500, loss = 1.35841
I0526 12:59:20.460245 26141 solver.cpp:253]     Train net output #0: loss = 1.35841 (* 1 = 1.35841 loss)
I0526 12:59:20.460259 26141 sgd_solver.cpp:106] Iteration 493500, lr = 0.0005
I0526 12:59:32.557620 26141 solver.cpp:237] Iteration 494250, loss = 0.771364
I0526 12:59:32.557656 26141 solver.cpp:253]     Train net output #0: loss = 0.771366 (* 1 = 0.771366 loss)
I0526 12:59:32.557669 26141 sgd_solver.cpp:106] Iteration 494250, lr = 0.0005
I0526 12:59:44.636122 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_495000.caffemodel
I0526 12:59:44.686493 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_495000.solverstate
I0526 12:59:44.712036 26141 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 13:00:57.400125 26141 solver.cpp:409]     Test net output #0: accuracy = 0.898291
I0526 13:00:57.400305 26141 solver.cpp:409]     Test net output #1: loss = 0.319608 (* 1 = 0.319608 loss)
I0526 13:01:18.221488 26141 solver.cpp:237] Iteration 495000, loss = 1.57614
I0526 13:01:18.221541 26141 solver.cpp:253]     Train net output #0: loss = 1.57614 (* 1 = 1.57614 loss)
I0526 13:01:18.221555 26141 sgd_solver.cpp:106] Iteration 495000, lr = 0.0005
I0526 13:01:30.456634 26141 solver.cpp:237] Iteration 495750, loss = 0.971405
I0526 13:01:30.456812 26141 solver.cpp:253]     Train net output #0: loss = 0.971407 (* 1 = 0.971407 loss)
I0526 13:01:30.456826 26141 sgd_solver.cpp:106] Iteration 495750, lr = 0.0005
I0526 13:01:42.638767 26141 solver.cpp:237] Iteration 496500, loss = 1.00777
I0526 13:01:42.638803 26141 solver.cpp:253]     Train net output #0: loss = 1.00778 (* 1 = 1.00778 loss)
I0526 13:01:42.638818 26141 sgd_solver.cpp:106] Iteration 496500, lr = 0.0005
I0526 13:01:54.827708 26141 solver.cpp:237] Iteration 497250, loss = 1.29759
I0526 13:01:54.827750 26141 solver.cpp:253]     Train net output #0: loss = 1.29759 (* 1 = 1.29759 loss)
I0526 13:01:54.827764 26141 sgd_solver.cpp:106] Iteration 497250, lr = 0.0005
I0526 13:02:07.086158 26141 solver.cpp:237] Iteration 498000, loss = 1.15598
I0526 13:02:07.086335 26141 solver.cpp:253]     Train net output #0: loss = 1.15599 (* 1 = 1.15599 loss)
I0526 13:02:07.086352 26141 sgd_solver.cpp:106] Iteration 498000, lr = 0.0005
I0526 13:02:19.335073 26141 solver.cpp:237] Iteration 498750, loss = 1.1828
I0526 13:02:19.335117 26141 solver.cpp:253]     Train net output #0: loss = 1.1828 (* 1 = 1.1828 loss)
I0526 13:02:19.335130 26141 sgd_solver.cpp:106] Iteration 498750, lr = 0.0005
I0526 13:02:31.548421 26141 solver.cpp:237] Iteration 499500, loss = 1.02356
I0526 13:02:31.548457 26141 solver.cpp:253]     Train net output #0: loss = 1.02357 (* 1 = 1.02357 loss)
I0526 13:02:31.548471 26141 sgd_solver.cpp:106] Iteration 499500, lr = 0.0005
I0526 13:03:04.614356 26141 solver.cpp:237] Iteration 500250, loss = 1.28017
I0526 13:03:04.629384 26141 solver.cpp:253]     Train net output #0: loss = 1.28017 (* 1 = 1.28017 loss)
I0526 13:03:04.629400 26141 sgd_solver.cpp:106] Iteration 500250, lr = 0.0005
I0526 13:03:16.756012 26141 solver.cpp:237] Iteration 501000, loss = 0.892165
I0526 13:03:16.756049 26141 solver.cpp:253]     Train net output #0: loss = 0.892167 (* 1 = 0.892167 loss)
I0526 13:03:16.756063 26141 sgd_solver.cpp:106] Iteration 501000, lr = 0.0005
I0526 13:03:28.916550 26141 solver.cpp:237] Iteration 501750, loss = 0.84186
I0526 13:03:28.916587 26141 solver.cpp:253]     Train net output #0: loss = 0.841863 (* 1 = 0.841863 loss)
I0526 13:03:28.916601 26141 sgd_solver.cpp:106] Iteration 501750, lr = 0.0005
I0526 13:03:41.114775 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_502500.caffemodel
I0526 13:03:41.166079 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_502500.solverstate
I0526 13:03:41.198612 26141 solver.cpp:237] Iteration 502500, loss = 1.35179
I0526 13:03:41.198662 26141 solver.cpp:253]     Train net output #0: loss = 1.35179 (* 1 = 1.35179 loss)
I0526 13:03:41.198678 26141 sgd_solver.cpp:106] Iteration 502500, lr = 0.0005
I0526 13:03:53.415216 26141 solver.cpp:237] Iteration 503250, loss = 0.951583
I0526 13:03:53.415253 26141 solver.cpp:253]     Train net output #0: loss = 0.951585 (* 1 = 0.951585 loss)
I0526 13:03:53.415267 26141 sgd_solver.cpp:106] Iteration 503250, lr = 0.0005
I0526 13:04:05.612788 26141 solver.cpp:237] Iteration 504000, loss = 1.0194
I0526 13:04:05.612839 26141 solver.cpp:253]     Train net output #0: loss = 1.0194 (* 1 = 1.0194 loss)
I0526 13:04:05.612854 26141 sgd_solver.cpp:106] Iteration 504000, lr = 0.0005
I0526 13:04:17.813841 26141 solver.cpp:237] Iteration 504750, loss = 1.0502
I0526 13:04:17.814009 26141 solver.cpp:253]     Train net output #0: loss = 1.0502 (* 1 = 1.0502 loss)
I0526 13:04:17.814023 26141 sgd_solver.cpp:106] Iteration 504750, lr = 0.0005
I0526 13:04:50.888515 26141 solver.cpp:237] Iteration 505500, loss = 1.19814
I0526 13:04:50.888710 26141 solver.cpp:253]     Train net output #0: loss = 1.19814 (* 1 = 1.19814 loss)
I0526 13:04:50.888723 26141 sgd_solver.cpp:106] Iteration 505500, lr = 0.0005
I0526 13:05:03.117748 26141 solver.cpp:237] Iteration 506250, loss = 0.876705
I0526 13:05:03.117785 26141 solver.cpp:253]     Train net output #0: loss = 0.876707 (* 1 = 0.876707 loss)
I0526 13:05:03.117799 26141 sgd_solver.cpp:106] Iteration 506250, lr = 0.0005
I0526 13:05:15.281235 26141 solver.cpp:237] Iteration 507000, loss = 1.24355
I0526 13:05:15.281280 26141 solver.cpp:253]     Train net output #0: loss = 1.24355 (* 1 = 1.24355 loss)
I0526 13:05:15.281293 26141 sgd_solver.cpp:106] Iteration 507000, lr = 0.0005
I0526 13:05:27.462425 26141 solver.cpp:237] Iteration 507750, loss = 1.33798
I0526 13:05:27.462600 26141 solver.cpp:253]     Train net output #0: loss = 1.33798 (* 1 = 1.33798 loss)
I0526 13:05:27.462615 26141 sgd_solver.cpp:106] Iteration 507750, lr = 0.0005
I0526 13:05:39.607709 26141 solver.cpp:237] Iteration 508500, loss = 1.50623
I0526 13:05:39.607755 26141 solver.cpp:253]     Train net output #0: loss = 1.50623 (* 1 = 1.50623 loss)
I0526 13:05:39.607769 26141 sgd_solver.cpp:106] Iteration 508500, lr = 0.0005
I0526 13:05:51.685178 26141 solver.cpp:237] Iteration 509250, loss = 1.6345
I0526 13:05:51.685214 26141 solver.cpp:253]     Train net output #0: loss = 1.6345 (* 1 = 1.6345 loss)
I0526 13:05:51.685227 26141 sgd_solver.cpp:106] Iteration 509250, lr = 0.0005
I0526 13:06:03.744201 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_510000.caffemodel
I0526 13:06:03.796008 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_510000.solverstate
I0526 13:06:03.823657 26141 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 13:06:55.496172 26141 solver.cpp:409]     Test net output #0: accuracy = 0.898956
I0526 13:06:55.496356 26141 solver.cpp:409]     Test net output #1: loss = 0.314653 (* 1 = 0.314653 loss)
I0526 13:07:16.397202 26141 solver.cpp:237] Iteration 510000, loss = 1.32943
I0526 13:07:16.397255 26141 solver.cpp:253]     Train net output #0: loss = 1.32943 (* 1 = 1.32943 loss)
I0526 13:07:16.397270 26141 sgd_solver.cpp:106] Iteration 510000, lr = 0.0005
I0526 13:07:28.570762 26141 solver.cpp:237] Iteration 510750, loss = 1.16502
I0526 13:07:28.570935 26141 solver.cpp:253]     Train net output #0: loss = 1.16503 (* 1 = 1.16503 loss)
I0526 13:07:28.570948 26141 sgd_solver.cpp:106] Iteration 510750, lr = 0.0005
I0526 13:07:40.747279 26141 solver.cpp:237] Iteration 511500, loss = 1.39852
I0526 13:07:40.747328 26141 solver.cpp:253]     Train net output #0: loss = 1.39853 (* 1 = 1.39853 loss)
I0526 13:07:40.747342 26141 sgd_solver.cpp:106] Iteration 511500, lr = 0.0005
I0526 13:07:52.925153 26141 solver.cpp:237] Iteration 512250, loss = 1.67394
I0526 13:07:52.925189 26141 solver.cpp:253]     Train net output #0: loss = 1.67394 (* 1 = 1.67394 loss)
I0526 13:07:52.925204 26141 sgd_solver.cpp:106] Iteration 512250, lr = 0.0005
I0526 13:08:05.097237 26141 solver.cpp:237] Iteration 513000, loss = 0.933902
I0526 13:08:05.097424 26141 solver.cpp:253]     Train net output #0: loss = 0.933904 (* 1 = 0.933904 loss)
I0526 13:08:05.097437 26141 sgd_solver.cpp:106] Iteration 513000, lr = 0.0005
I0526 13:08:17.332078 26141 solver.cpp:237] Iteration 513750, loss = 0.950951
I0526 13:08:17.332115 26141 solver.cpp:253]     Train net output #0: loss = 0.950954 (* 1 = 0.950954 loss)
I0526 13:08:17.332129 26141 sgd_solver.cpp:106] Iteration 513750, lr = 0.0005
I0526 13:08:29.586866 26141 solver.cpp:237] Iteration 514500, loss = 1.63474
I0526 13:08:29.586901 26141 solver.cpp:253]     Train net output #0: loss = 1.63475 (* 1 = 1.63475 loss)
I0526 13:08:29.586916 26141 sgd_solver.cpp:106] Iteration 514500, lr = 0.0005
I0526 13:09:02.683959 26141 solver.cpp:237] Iteration 515250, loss = 1.23422
I0526 13:09:02.684145 26141 solver.cpp:253]     Train net output #0: loss = 1.23422 (* 1 = 1.23422 loss)
I0526 13:09:02.684160 26141 sgd_solver.cpp:106] Iteration 515250, lr = 0.0005
I0526 13:09:14.876312 26141 solver.cpp:237] Iteration 516000, loss = 1.1339
I0526 13:09:14.876348 26141 solver.cpp:253]     Train net output #0: loss = 1.1339 (* 1 = 1.1339 loss)
I0526 13:09:14.876363 26141 sgd_solver.cpp:106] Iteration 516000, lr = 0.0005
I0526 13:09:27.101784 26141 solver.cpp:237] Iteration 516750, loss = 1.76792
I0526 13:09:27.101830 26141 solver.cpp:253]     Train net output #0: loss = 1.76793 (* 1 = 1.76793 loss)
I0526 13:09:27.101843 26141 sgd_solver.cpp:106] Iteration 516750, lr = 0.0005
I0526 13:09:39.251922 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_517500.caffemodel
I0526 13:09:39.301200 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_517500.solverstate
I0526 13:09:39.331818 26141 solver.cpp:237] Iteration 517500, loss = 1.33389
I0526 13:09:39.331863 26141 solver.cpp:253]     Train net output #0: loss = 1.33389 (* 1 = 1.33389 loss)
I0526 13:09:39.331879 26141 sgd_solver.cpp:106] Iteration 517500, lr = 0.0005
I0526 13:09:51.499615 26141 solver.cpp:237] Iteration 518250, loss = 1.71106
I0526 13:09:51.499662 26141 solver.cpp:253]     Train net output #0: loss = 1.71106 (* 1 = 1.71106 loss)
I0526 13:09:51.499676 26141 sgd_solver.cpp:106] Iteration 518250, lr = 0.0005
I0526 13:10:03.693553 26141 solver.cpp:237] Iteration 519000, loss = 1.23676
I0526 13:10:03.693589 26141 solver.cpp:253]     Train net output #0: loss = 1.23676 (* 1 = 1.23676 loss)
I0526 13:10:03.693605 26141 sgd_solver.cpp:106] Iteration 519000, lr = 0.0005
I0526 13:10:15.916049 26141 solver.cpp:237] Iteration 519750, loss = 1.13864
I0526 13:10:15.916234 26141 solver.cpp:253]     Train net output #0: loss = 1.13864 (* 1 = 1.13864 loss)
I0526 13:10:15.916249 26141 sgd_solver.cpp:106] Iteration 519750, lr = 0.0005
I0526 13:10:49.024185 26141 solver.cpp:237] Iteration 520500, loss = 0.945718
I0526 13:10:49.024384 26141 solver.cpp:253]     Train net output #0: loss = 0.945721 (* 1 = 0.945721 loss)
I0526 13:10:49.024399 26141 sgd_solver.cpp:106] Iteration 520500, lr = 0.0005
I0526 13:11:01.170742 26141 solver.cpp:237] Iteration 521250, loss = 1.43072
I0526 13:11:01.170781 26141 solver.cpp:253]     Train net output #0: loss = 1.43072 (* 1 = 1.43072 loss)
I0526 13:11:01.170799 26141 sgd_solver.cpp:106] Iteration 521250, lr = 0.0005
I0526 13:11:13.329773 26141 solver.cpp:237] Iteration 522000, loss = 0.643647
I0526 13:11:13.329810 26141 solver.cpp:253]     Train net output #0: loss = 0.643649 (* 1 = 0.643649 loss)
I0526 13:11:13.329824 26141 sgd_solver.cpp:106] Iteration 522000, lr = 0.0005
I0526 13:11:25.562631 26141 solver.cpp:237] Iteration 522750, loss = 1.16225
I0526 13:11:25.562805 26141 solver.cpp:253]     Train net output #0: loss = 1.16226 (* 1 = 1.16226 loss)
I0526 13:11:25.562819 26141 sgd_solver.cpp:106] Iteration 522750, lr = 0.0005
I0526 13:11:37.796430 26141 solver.cpp:237] Iteration 523500, loss = 1.23001
I0526 13:11:37.796466 26141 solver.cpp:253]     Train net output #0: loss = 1.23001 (* 1 = 1.23001 loss)
I0526 13:11:37.796480 26141 sgd_solver.cpp:106] Iteration 523500, lr = 0.0005
I0526 13:11:50.026708 26141 solver.cpp:237] Iteration 524250, loss = 1.08607
I0526 13:11:50.026753 26141 solver.cpp:253]     Train net output #0: loss = 1.08608 (* 1 = 1.08608 loss)
I0526 13:11:50.026767 26141 sgd_solver.cpp:106] Iteration 524250, lr = 0.0005
I0526 13:12:02.186990 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_525000.caffemodel
I0526 13:12:02.236610 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_525000.solverstate
I0526 13:12:02.262195 26141 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 13:13:15.139657 26141 solver.cpp:409]     Test net output #0: accuracy = 0.899288
I0526 13:13:15.139843 26141 solver.cpp:409]     Test net output #1: loss = 0.317113 (* 1 = 0.317113 loss)
I0526 13:13:36.020285 26141 solver.cpp:237] Iteration 525000, loss = 1.40003
I0526 13:13:36.020337 26141 solver.cpp:253]     Train net output #0: loss = 1.40003 (* 1 = 1.40003 loss)
I0526 13:13:36.020352 26141 sgd_solver.cpp:106] Iteration 525000, lr = 0.0005
I0526 13:13:48.120741 26141 solver.cpp:237] Iteration 525750, loss = 0.917833
I0526 13:13:48.120925 26141 solver.cpp:253]     Train net output #0: loss = 0.917836 (* 1 = 0.917836 loss)
I0526 13:13:48.120939 26141 sgd_solver.cpp:106] Iteration 525750, lr = 0.0005
I0526 13:14:00.273720 26141 solver.cpp:237] Iteration 526500, loss = 1.37998
I0526 13:14:00.273769 26141 solver.cpp:253]     Train net output #0: loss = 1.37998 (* 1 = 1.37998 loss)
I0526 13:14:00.273783 26141 sgd_solver.cpp:106] Iteration 526500, lr = 0.0005
I0526 13:14:12.380333 26141 solver.cpp:237] Iteration 527250, loss = 1.13319
I0526 13:14:12.380370 26141 solver.cpp:253]     Train net output #0: loss = 1.13319 (* 1 = 1.13319 loss)
I0526 13:14:12.380385 26141 sgd_solver.cpp:106] Iteration 527250, lr = 0.0005
I0526 13:14:24.535447 26141 solver.cpp:237] Iteration 528000, loss = 1.25803
I0526 13:14:24.535632 26141 solver.cpp:253]     Train net output #0: loss = 1.25803 (* 1 = 1.25803 loss)
I0526 13:14:24.535650 26141 sgd_solver.cpp:106] Iteration 528000, lr = 0.0005
I0526 13:14:36.677876 26141 solver.cpp:237] Iteration 528750, loss = 1.64387
I0526 13:14:36.677912 26141 solver.cpp:253]     Train net output #0: loss = 1.64387 (* 1 = 1.64387 loss)
I0526 13:14:36.677929 26141 sgd_solver.cpp:106] Iteration 528750, lr = 0.0005
I0526 13:14:48.823776 26141 solver.cpp:237] Iteration 529500, loss = 1.18354
I0526 13:14:48.823817 26141 solver.cpp:253]     Train net output #0: loss = 1.18354 (* 1 = 1.18354 loss)
I0526 13:14:48.823832 26141 sgd_solver.cpp:106] Iteration 529500, lr = 0.0005
I0526 13:15:21.848294 26141 solver.cpp:237] Iteration 530250, loss = 1.33667
I0526 13:15:21.848484 26141 solver.cpp:253]     Train net output #0: loss = 1.33667 (* 1 = 1.33667 loss)
I0526 13:15:21.848497 26141 sgd_solver.cpp:106] Iteration 530250, lr = 0.0005
I0526 13:15:34.000015 26141 solver.cpp:237] Iteration 531000, loss = 0.740863
I0526 13:15:34.000052 26141 solver.cpp:253]     Train net output #0: loss = 0.740866 (* 1 = 0.740866 loss)
I0526 13:15:34.000066 26141 sgd_solver.cpp:106] Iteration 531000, lr = 0.0005
I0526 13:15:46.153393 26141 solver.cpp:237] Iteration 531750, loss = 1.34581
I0526 13:15:46.153437 26141 solver.cpp:253]     Train net output #0: loss = 1.34581 (* 1 = 1.34581 loss)
I0526 13:15:46.153451 26141 sgd_solver.cpp:106] Iteration 531750, lr = 0.0005
I0526 13:15:58.307019 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_532500.caffemodel
I0526 13:15:58.357028 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_532500.solverstate
I0526 13:15:58.390725 26141 solver.cpp:237] Iteration 532500, loss = 0.960104
I0526 13:15:58.390776 26141 solver.cpp:253]     Train net output #0: loss = 0.960106 (* 1 = 0.960106 loss)
I0526 13:15:58.390791 26141 sgd_solver.cpp:106] Iteration 532500, lr = 0.0005
I0526 13:16:10.585218 26141 solver.cpp:237] Iteration 533250, loss = 1.15806
I0526 13:16:10.585263 26141 solver.cpp:253]     Train net output #0: loss = 1.15807 (* 1 = 1.15807 loss)
I0526 13:16:10.585278 26141 sgd_solver.cpp:106] Iteration 533250, lr = 0.0005
I0526 13:16:22.786396 26141 solver.cpp:237] Iteration 534000, loss = 0.689209
I0526 13:16:22.786433 26141 solver.cpp:253]     Train net output #0: loss = 0.689211 (* 1 = 0.689211 loss)
I0526 13:16:22.786448 26141 sgd_solver.cpp:106] Iteration 534000, lr = 0.0005
I0526 13:16:34.959934 26141 solver.cpp:237] Iteration 534750, loss = 1.30616
I0526 13:16:34.960122 26141 solver.cpp:253]     Train net output #0: loss = 1.30617 (* 1 = 1.30617 loss)
I0526 13:16:34.960137 26141 sgd_solver.cpp:106] Iteration 534750, lr = 0.0005
I0526 13:17:08.027096 26141 solver.cpp:237] Iteration 535500, loss = 1.07188
I0526 13:17:08.027297 26141 solver.cpp:253]     Train net output #0: loss = 1.07188 (* 1 = 1.07188 loss)
I0526 13:17:08.027312 26141 sgd_solver.cpp:106] Iteration 535500, lr = 0.0005
I0526 13:17:20.147475 26141 solver.cpp:237] Iteration 536250, loss = 1.23612
I0526 13:17:20.147521 26141 solver.cpp:253]     Train net output #0: loss = 1.23612 (* 1 = 1.23612 loss)
I0526 13:17:20.147534 26141 sgd_solver.cpp:106] Iteration 536250, lr = 0.0005
I0526 13:17:32.297693 26141 solver.cpp:237] Iteration 537000, loss = 1.20699
I0526 13:17:32.297729 26141 solver.cpp:253]     Train net output #0: loss = 1.20699 (* 1 = 1.20699 loss)
I0526 13:17:32.297744 26141 sgd_solver.cpp:106] Iteration 537000, lr = 0.0005
I0526 13:17:44.394129 26141 solver.cpp:237] Iteration 537750, loss = 1.14224
I0526 13:17:44.394323 26141 solver.cpp:253]     Train net output #0: loss = 1.14224 (* 1 = 1.14224 loss)
I0526 13:17:44.394340 26141 sgd_solver.cpp:106] Iteration 537750, lr = 0.0005
I0526 13:17:56.544698 26141 solver.cpp:237] Iteration 538500, loss = 0.98177
I0526 13:17:56.544735 26141 solver.cpp:253]     Train net output #0: loss = 0.981772 (* 1 = 0.981772 loss)
I0526 13:17:56.544749 26141 sgd_solver.cpp:106] Iteration 538500, lr = 0.0005
I0526 13:18:08.723875 26141 solver.cpp:237] Iteration 539250, loss = 0.934355
I0526 13:18:08.723923 26141 solver.cpp:253]     Train net output #0: loss = 0.934357 (* 1 = 0.934357 loss)
I0526 13:18:08.723937 26141 sgd_solver.cpp:106] Iteration 539250, lr = 0.0005
I0526 13:18:20.879425 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_540000.caffemodel
I0526 13:18:20.930326 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_540000.solverstate
I0526 13:18:20.957157 26141 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 13:19:12.857924 26141 solver.cpp:409]     Test net output #0: accuracy = 0.897718
I0526 13:19:12.858110 26141 solver.cpp:409]     Test net output #1: loss = 0.330423 (* 1 = 0.330423 loss)
I0526 13:19:33.724259 26141 solver.cpp:237] Iteration 540000, loss = 1.16598
I0526 13:19:33.724308 26141 solver.cpp:253]     Train net output #0: loss = 1.16598 (* 1 = 1.16598 loss)
I0526 13:19:33.724326 26141 sgd_solver.cpp:106] Iteration 540000, lr = 0.0005
I0526 13:19:45.921674 26141 solver.cpp:237] Iteration 540750, loss = 0.779024
I0526 13:19:45.921860 26141 solver.cpp:253]     Train net output #0: loss = 0.779026 (* 1 = 0.779026 loss)
I0526 13:19:45.921875 26141 sgd_solver.cpp:106] Iteration 540750, lr = 0.0005
I0526 13:19:58.047698 26141 solver.cpp:237] Iteration 541500, loss = 1.0905
I0526 13:19:58.047734 26141 solver.cpp:253]     Train net output #0: loss = 1.0905 (* 1 = 1.0905 loss)
I0526 13:19:58.047747 26141 sgd_solver.cpp:106] Iteration 541500, lr = 0.0005
I0526 13:20:10.240347 26141 solver.cpp:237] Iteration 542250, loss = 1.38467
I0526 13:20:10.240388 26141 solver.cpp:253]     Train net output #0: loss = 1.38467 (* 1 = 1.38467 loss)
I0526 13:20:10.240408 26141 sgd_solver.cpp:106] Iteration 542250, lr = 0.0005
I0526 13:20:22.386255 26141 solver.cpp:237] Iteration 543000, loss = 1.20764
I0526 13:20:22.386423 26141 solver.cpp:253]     Train net output #0: loss = 1.20764 (* 1 = 1.20764 loss)
I0526 13:20:22.386437 26141 sgd_solver.cpp:106] Iteration 543000, lr = 0.0005
I0526 13:20:34.500584 26141 solver.cpp:237] Iteration 543750, loss = 1.29226
I0526 13:20:34.500620 26141 solver.cpp:253]     Train net output #0: loss = 1.29227 (* 1 = 1.29227 loss)
I0526 13:20:34.500634 26141 sgd_solver.cpp:106] Iteration 543750, lr = 0.0005
I0526 13:20:46.644541 26141 solver.cpp:237] Iteration 544500, loss = 1.18414
I0526 13:20:46.644582 26141 solver.cpp:253]     Train net output #0: loss = 1.18414 (* 1 = 1.18414 loss)
I0526 13:20:46.644596 26141 sgd_solver.cpp:106] Iteration 544500, lr = 0.0005
I0526 13:21:19.642012 26141 solver.cpp:237] Iteration 545250, loss = 1.5658
I0526 13:21:19.642213 26141 solver.cpp:253]     Train net output #0: loss = 1.5658 (* 1 = 1.5658 loss)
I0526 13:21:19.642227 26141 sgd_solver.cpp:106] Iteration 545250, lr = 0.0005
I0526 13:21:31.776134 26141 solver.cpp:237] Iteration 546000, loss = 1.35579
I0526 13:21:31.776182 26141 solver.cpp:253]     Train net output #0: loss = 1.35579 (* 1 = 1.35579 loss)
I0526 13:21:31.776196 26141 sgd_solver.cpp:106] Iteration 546000, lr = 0.0005
I0526 13:21:43.932001 26141 solver.cpp:237] Iteration 546750, loss = 1.31167
I0526 13:21:43.932037 26141 solver.cpp:253]     Train net output #0: loss = 1.31167 (* 1 = 1.31167 loss)
I0526 13:21:43.932052 26141 sgd_solver.cpp:106] Iteration 546750, lr = 0.0005
I0526 13:21:56.082427 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_547500.caffemodel
I0526 13:21:56.138013 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_547500.solverstate
I0526 13:21:56.170943 26141 solver.cpp:237] Iteration 547500, loss = 0.988588
I0526 13:21:56.170991 26141 solver.cpp:253]     Train net output #0: loss = 0.98859 (* 1 = 0.98859 loss)
I0526 13:21:56.171010 26141 sgd_solver.cpp:106] Iteration 547500, lr = 0.0005
I0526 13:22:08.326539 26141 solver.cpp:237] Iteration 548250, loss = 1.0145
I0526 13:22:08.326575 26141 solver.cpp:253]     Train net output #0: loss = 1.01451 (* 1 = 1.01451 loss)
I0526 13:22:08.326588 26141 sgd_solver.cpp:106] Iteration 548250, lr = 0.0005
I0526 13:22:20.483626 26141 solver.cpp:237] Iteration 549000, loss = 1.53842
I0526 13:22:20.483676 26141 solver.cpp:253]     Train net output #0: loss = 1.53842 (* 1 = 1.53842 loss)
I0526 13:22:20.483690 26141 sgd_solver.cpp:106] Iteration 549000, lr = 0.0005
I0526 13:22:32.601631 26141 solver.cpp:237] Iteration 549750, loss = 1.25437
I0526 13:22:32.601806 26141 solver.cpp:253]     Train net output #0: loss = 1.25437 (* 1 = 1.25437 loss)
I0526 13:22:32.601820 26141 sgd_solver.cpp:106] Iteration 549750, lr = 0.0005
I0526 13:23:05.571024 26141 solver.cpp:237] Iteration 550500, loss = 1.03614
I0526 13:23:05.571213 26141 solver.cpp:253]     Train net output #0: loss = 1.03614 (* 1 = 1.03614 loss)
I0526 13:23:05.571228 26141 sgd_solver.cpp:106] Iteration 550500, lr = 0.0005
I0526 13:23:17.691712 26141 solver.cpp:237] Iteration 551250, loss = 1.47359
I0526 13:23:17.691747 26141 solver.cpp:253]     Train net output #0: loss = 1.47359 (* 1 = 1.47359 loss)
I0526 13:23:17.691762 26141 sgd_solver.cpp:106] Iteration 551250, lr = 0.0005
I0526 13:23:29.870729 26141 solver.cpp:237] Iteration 552000, loss = 0.8974
I0526 13:23:29.870777 26141 solver.cpp:253]     Train net output #0: loss = 0.897402 (* 1 = 0.897402 loss)
I0526 13:23:29.870792 26141 sgd_solver.cpp:106] Iteration 552000, lr = 0.0005
I0526 13:23:42.035231 26141 solver.cpp:237] Iteration 552750, loss = 1.37078
I0526 13:23:42.035403 26141 solver.cpp:253]     Train net output #0: loss = 1.37078 (* 1 = 1.37078 loss)
I0526 13:23:42.035418 26141 sgd_solver.cpp:106] Iteration 552750, lr = 0.0005
I0526 13:23:54.171624 26141 solver.cpp:237] Iteration 553500, loss = 1.20838
I0526 13:23:54.171660 26141 solver.cpp:253]     Train net output #0: loss = 1.20838 (* 1 = 1.20838 loss)
I0526 13:23:54.171675 26141 sgd_solver.cpp:106] Iteration 553500, lr = 0.0005
I0526 13:24:06.321976 26141 solver.cpp:237] Iteration 554250, loss = 1.09258
I0526 13:24:06.322021 26141 solver.cpp:253]     Train net output #0: loss = 1.09258 (* 1 = 1.09258 loss)
I0526 13:24:06.322036 26141 sgd_solver.cpp:106] Iteration 554250, lr = 0.0005
I0526 13:24:18.489187 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_555000.caffemodel
I0526 13:24:18.544977 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_555000.solverstate
I0526 13:24:18.576854 26141 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 13:25:31.458032 26141 solver.cpp:409]     Test net output #0: accuracy = 0.899752
I0526 13:25:31.458231 26141 solver.cpp:409]     Test net output #1: loss = 0.320502 (* 1 = 0.320502 loss)
I0526 13:25:52.311763 26141 solver.cpp:237] Iteration 555000, loss = 0.983581
I0526 13:25:52.311810 26141 solver.cpp:253]     Train net output #0: loss = 0.983583 (* 1 = 0.983583 loss)
I0526 13:25:52.311830 26141 sgd_solver.cpp:106] Iteration 555000, lr = 0.0005
I0526 13:26:04.489177 26141 solver.cpp:237] Iteration 555750, loss = 1.48162
I0526 13:26:04.489367 26141 solver.cpp:253]     Train net output #0: loss = 1.48162 (* 1 = 1.48162 loss)
I0526 13:26:04.489382 26141 sgd_solver.cpp:106] Iteration 555750, lr = 0.0005
I0526 13:26:16.639430 26141 solver.cpp:237] Iteration 556500, loss = 1.40784
I0526 13:26:16.639467 26141 solver.cpp:253]     Train net output #0: loss = 1.40784 (* 1 = 1.40784 loss)
I0526 13:26:16.639480 26141 sgd_solver.cpp:106] Iteration 556500, lr = 0.0005
I0526 13:26:28.775535 26141 solver.cpp:237] Iteration 557250, loss = 1.30404
I0526 13:26:28.775583 26141 solver.cpp:253]     Train net output #0: loss = 1.30404 (* 1 = 1.30404 loss)
I0526 13:26:28.775596 26141 sgd_solver.cpp:106] Iteration 557250, lr = 0.0005
I0526 13:26:40.942494 26141 solver.cpp:237] Iteration 558000, loss = 1.18224
I0526 13:26:40.942664 26141 solver.cpp:253]     Train net output #0: loss = 1.18224 (* 1 = 1.18224 loss)
I0526 13:26:40.942678 26141 sgd_solver.cpp:106] Iteration 558000, lr = 0.0005
I0526 13:26:53.176208 26141 solver.cpp:237] Iteration 558750, loss = 1.35643
I0526 13:26:53.176252 26141 solver.cpp:253]     Train net output #0: loss = 1.35643 (* 1 = 1.35643 loss)
I0526 13:26:53.176266 26141 sgd_solver.cpp:106] Iteration 558750, lr = 0.0005
I0526 13:27:05.415343 26141 solver.cpp:237] Iteration 559500, loss = 1.00925
I0526 13:27:05.415379 26141 solver.cpp:253]     Train net output #0: loss = 1.00926 (* 1 = 1.00926 loss)
I0526 13:27:05.415393 26141 sgd_solver.cpp:106] Iteration 559500, lr = 0.0005
I0526 13:27:38.476564 26141 solver.cpp:237] Iteration 560250, loss = 1.12585
I0526 13:27:38.476755 26141 solver.cpp:253]     Train net output #0: loss = 1.12586 (* 1 = 1.12586 loss)
I0526 13:27:38.476770 26141 sgd_solver.cpp:106] Iteration 560250, lr = 0.0005
I0526 13:27:50.657807 26141 solver.cpp:237] Iteration 561000, loss = 0.979332
I0526 13:27:50.657856 26141 solver.cpp:253]     Train net output #0: loss = 0.979334 (* 1 = 0.979334 loss)
I0526 13:27:50.657871 26141 sgd_solver.cpp:106] Iteration 561000, lr = 0.0005
I0526 13:28:02.831248 26141 solver.cpp:237] Iteration 561750, loss = 1.21035
I0526 13:28:02.831284 26141 solver.cpp:253]     Train net output #0: loss = 1.21035 (* 1 = 1.21035 loss)
I0526 13:28:02.831300 26141 sgd_solver.cpp:106] Iteration 561750, lr = 0.0005
I0526 13:28:14.961132 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_562500.caffemodel
I0526 13:28:15.010110 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_562500.solverstate
I0526 13:28:15.040576 26141 solver.cpp:237] Iteration 562500, loss = 1.46336
I0526 13:28:15.040621 26141 solver.cpp:253]     Train net output #0: loss = 1.46336 (* 1 = 1.46336 loss)
I0526 13:28:15.040637 26141 sgd_solver.cpp:106] Iteration 562500, lr = 0.0005
I0526 13:28:27.177824 26141 solver.cpp:237] Iteration 563250, loss = 1.11942
I0526 13:28:27.177861 26141 solver.cpp:253]     Train net output #0: loss = 1.11943 (* 1 = 1.11943 loss)
I0526 13:28:27.177875 26141 sgd_solver.cpp:106] Iteration 563250, lr = 0.0005
I0526 13:28:39.348645 26141 solver.cpp:237] Iteration 564000, loss = 0.967834
I0526 13:28:39.348693 26141 solver.cpp:253]     Train net output #0: loss = 0.967837 (* 1 = 0.967837 loss)
I0526 13:28:39.348706 26141 sgd_solver.cpp:106] Iteration 564000, lr = 0.0005
I0526 13:28:51.526602 26141 solver.cpp:237] Iteration 564750, loss = 0.93951
I0526 13:28:51.526789 26141 solver.cpp:253]     Train net output #0: loss = 0.939512 (* 1 = 0.939512 loss)
I0526 13:28:51.526803 26141 sgd_solver.cpp:106] Iteration 564750, lr = 0.0005
I0526 13:29:24.577402 26141 solver.cpp:237] Iteration 565500, loss = 1.28199
I0526 13:29:24.577599 26141 solver.cpp:253]     Train net output #0: loss = 1.28199 (* 1 = 1.28199 loss)
I0526 13:29:24.577612 26141 sgd_solver.cpp:106] Iteration 565500, lr = 0.0005
I0526 13:29:36.699362 26141 solver.cpp:237] Iteration 566250, loss = 1.12531
I0526 13:29:36.699398 26141 solver.cpp:253]     Train net output #0: loss = 1.12531 (* 1 = 1.12531 loss)
I0526 13:29:36.699411 26141 sgd_solver.cpp:106] Iteration 566250, lr = 0.0005
I0526 13:29:48.830714 26141 solver.cpp:237] Iteration 567000, loss = 1.03394
I0526 13:29:48.830763 26141 solver.cpp:253]     Train net output #0: loss = 1.03394 (* 1 = 1.03394 loss)
I0526 13:29:48.830776 26141 sgd_solver.cpp:106] Iteration 567000, lr = 0.0005
I0526 13:30:01.011293 26141 solver.cpp:237] Iteration 567750, loss = 1.48009
I0526 13:30:01.011476 26141 solver.cpp:253]     Train net output #0: loss = 1.48009 (* 1 = 1.48009 loss)
I0526 13:30:01.011490 26141 sgd_solver.cpp:106] Iteration 567750, lr = 0.0005
I0526 13:30:13.191483 26141 solver.cpp:237] Iteration 568500, loss = 1.29172
I0526 13:30:13.191531 26141 solver.cpp:253]     Train net output #0: loss = 1.29172 (* 1 = 1.29172 loss)
I0526 13:30:13.191545 26141 sgd_solver.cpp:106] Iteration 568500, lr = 0.0005
I0526 13:30:25.349627 26141 solver.cpp:237] Iteration 569250, loss = 1.19455
I0526 13:30:25.349663 26141 solver.cpp:253]     Train net output #0: loss = 1.19455 (* 1 = 1.19455 loss)
I0526 13:30:25.349678 26141 sgd_solver.cpp:106] Iteration 569250, lr = 0.0005
I0526 13:30:37.507316 26141 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_570000.caffemodel
I0526 13:30:37.556442 26141 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_570000.solverstate
I0526 13:30:37.581593 26141 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 13:31:29.183723 26141 solver.cpp:409]     Test net output #0: accuracy = 0.899584
I0526 13:31:29.183914 26141 solver.cpp:409]     Test net output #1: loss = 0.320533 (* 1 = 0.320533 loss)
I0526 13:31:50.043184 26141 solver.cpp:237] Iteration 570000, loss = 1.38579
I0526 13:31:50.043236 26141 solver.cpp:253]     Train net output #0: loss = 1.3858 (* 1 = 1.3858 loss)
I0526 13:31:50.043251 26141 sgd_solver.cpp:106] Iteration 570000, lr = 0.0005
I0526 13:32:02.151731 26141 solver.cpp:237] Iteration 570750, loss = 1.41287
I0526 13:32:02.151918 26141 solver.cpp:253]     Train net output #0: loss = 1.41287 (* 1 = 1.41287 loss)
I0526 13:32:02.151932 26141 sgd_solver.cpp:106] Iteration 570750, lr = 0.0005
I0526 13:32:14.308179 26141 solver.cpp:237] Iteration 571500, loss = 1.10018
I0526 13:32:14.308217 26141 solver.cpp:253]     Train net output #0: loss = 1.10018 (* 1 = 1.10018 loss)
I0526 13:32:14.308230 26141 sgd_solver.cpp:106] Iteration 571500, lr = 0.0005
I0526 13:32:26.430863 26141 solver.cpp:237] Iteration 572250, loss = 0.995071
I0526 13:32:26.430905 26141 solver.cpp:253]     Train net output #0: loss = 0.995074 (* 1 = 0.995074 loss)
I0526 13:32:26.430919 26141 sgd_solver.cpp:106] Iteration 572250, lr = 0.0005
I0526 13:32:38.596897 26141 solver.cpp:237] Iteration 573000, loss = 1.1512
I0526 13:32:38.597070 26141 solver.cpp:253]     Train net output #0: loss = 1.1512 (* 1 = 1.1512 loss)
I0526 13:32:38.597084 26141 sgd_solver.cpp:106] Iteration 573000, lr = 0.0005
I0526 13:32:50.750625 26141 solver.cpp:237] Iteration 573750, loss = 1.16408
I0526 13:32:50.750663 26141 solver.cpp:253]     Train net output #0: loss = 1.16408 (* 1 = 1.16408 loss)
I0526 13:32:50.750676 26141 sgd_solver.cpp:106] Iteration 573750, lr = 0.0005
I0526 13:33:02.912793 26141 solver.cpp:237] Iteration 574500, loss = 0.826643
I0526 13:33:02.912830 26141 solver.cpp:253]     Train net output #0: loss = 0.826645 (* 1 = 0.826645 loss)
I0526 13:33:02.912843 26141 sgd_solver.cpp:106] Iteration 574500, lr = 0.0005
I0526 13:33:35.908881 26141 solver.cpp:237] Iteration 575250, loss = 0.786067
I0526 13:33:35.909086 26141 solver.cpp:253]     Train net output #0: loss = 0.78607 (* 1 = 0.78607 loss)
I0526 13:33:35.909101 26141 sgd_solver.cpp:106] Iteration 575250, lr = 0.0005
aprun: Apid 11268344: Caught signal Terminated, sending to application
*** Aborted at 1464284022 (unix time) try "date -d @1464284022" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x661a) received by PID 26141 (TID 0x2aaac746f900) from PID 26138; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11268344: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7227 exceeded limit 7200
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11268344: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11268344: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11268344: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11268344: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11268344: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11268344: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
aprun: Apid 11268344: Caught signal Terminated, sending to application
