2806968
I0521 20:02:37.799538 12468 caffe.cpp:184] Using GPUs 0
I0521 20:02:38.226443 12468 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0005
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147.prototxt"
I0521 20:02:38.228263 12468 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147.prototxt
I0521 20:02:38.242164 12468 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 20:02:38.242223 12468 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 20:02:38.242569 12468 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 20:02:38.242749 12468 layer_factory.hpp:77] Creating layer data_hdf5
I0521 20:02:38.242774 12468 net.cpp:106] Creating Layer data_hdf5
I0521 20:02:38.242789 12468 net.cpp:411] data_hdf5 -> data
I0521 20:02:38.242822 12468 net.cpp:411] data_hdf5 -> label
I0521 20:02:38.242854 12468 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 20:02:38.244093 12468 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 20:02:38.246322 12468 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 20:02:59.793407 12468 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 20:02:59.798547 12468 net.cpp:150] Setting up data_hdf5
I0521 20:02:59.798588 12468 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0521 20:02:59.798604 12468 net.cpp:157] Top shape: 20 (20)
I0521 20:02:59.798614 12468 net.cpp:165] Memory required for data: 508080
I0521 20:02:59.798627 12468 layer_factory.hpp:77] Creating layer conv1
I0521 20:02:59.798661 12468 net.cpp:106] Creating Layer conv1
I0521 20:02:59.798673 12468 net.cpp:454] conv1 <- data
I0521 20:02:59.798696 12468 net.cpp:411] conv1 -> conv1
I0521 20:03:00.163986 12468 net.cpp:150] Setting up conv1
I0521 20:03:00.164028 12468 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 20:03:00.164041 12468 net.cpp:165] Memory required for data: 6037680
I0521 20:03:00.164072 12468 layer_factory.hpp:77] Creating layer relu1
I0521 20:03:00.164093 12468 net.cpp:106] Creating Layer relu1
I0521 20:03:00.164104 12468 net.cpp:454] relu1 <- conv1
I0521 20:03:00.164118 12468 net.cpp:397] relu1 -> conv1 (in-place)
I0521 20:03:00.164630 12468 net.cpp:150] Setting up relu1
I0521 20:03:00.164646 12468 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 20:03:00.164657 12468 net.cpp:165] Memory required for data: 11567280
I0521 20:03:00.164669 12468 layer_factory.hpp:77] Creating layer pool1
I0521 20:03:00.164685 12468 net.cpp:106] Creating Layer pool1
I0521 20:03:00.164695 12468 net.cpp:454] pool1 <- conv1
I0521 20:03:00.164707 12468 net.cpp:411] pool1 -> pool1
I0521 20:03:00.164788 12468 net.cpp:150] Setting up pool1
I0521 20:03:00.164801 12468 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0521 20:03:00.164811 12468 net.cpp:165] Memory required for data: 14332080
I0521 20:03:00.164821 12468 layer_factory.hpp:77] Creating layer conv2
I0521 20:03:00.164842 12468 net.cpp:106] Creating Layer conv2
I0521 20:03:00.164852 12468 net.cpp:454] conv2 <- pool1
I0521 20:03:00.164866 12468 net.cpp:411] conv2 -> conv2
I0521 20:03:00.167554 12468 net.cpp:150] Setting up conv2
I0521 20:03:00.167582 12468 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 20:03:00.167593 12468 net.cpp:165] Memory required for data: 18306480
I0521 20:03:00.167613 12468 layer_factory.hpp:77] Creating layer relu2
I0521 20:03:00.167626 12468 net.cpp:106] Creating Layer relu2
I0521 20:03:00.167636 12468 net.cpp:454] relu2 <- conv2
I0521 20:03:00.167649 12468 net.cpp:397] relu2 -> conv2 (in-place)
I0521 20:03:00.167981 12468 net.cpp:150] Setting up relu2
I0521 20:03:00.167996 12468 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 20:03:00.168006 12468 net.cpp:165] Memory required for data: 22280880
I0521 20:03:00.168016 12468 layer_factory.hpp:77] Creating layer pool2
I0521 20:03:00.168030 12468 net.cpp:106] Creating Layer pool2
I0521 20:03:00.168040 12468 net.cpp:454] pool2 <- conv2
I0521 20:03:00.168052 12468 net.cpp:411] pool2 -> pool2
I0521 20:03:00.168133 12468 net.cpp:150] Setting up pool2
I0521 20:03:00.168145 12468 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0521 20:03:00.168155 12468 net.cpp:165] Memory required for data: 24268080
I0521 20:03:00.168166 12468 layer_factory.hpp:77] Creating layer conv3
I0521 20:03:00.168185 12468 net.cpp:106] Creating Layer conv3
I0521 20:03:00.168196 12468 net.cpp:454] conv3 <- pool2
I0521 20:03:00.168210 12468 net.cpp:411] conv3 -> conv3
I0521 20:03:00.170145 12468 net.cpp:150] Setting up conv3
I0521 20:03:00.170168 12468 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 20:03:00.170181 12468 net.cpp:165] Memory required for data: 26436400
I0521 20:03:00.170198 12468 layer_factory.hpp:77] Creating layer relu3
I0521 20:03:00.170215 12468 net.cpp:106] Creating Layer relu3
I0521 20:03:00.170225 12468 net.cpp:454] relu3 <- conv3
I0521 20:03:00.170238 12468 net.cpp:397] relu3 -> conv3 (in-place)
I0521 20:03:00.170704 12468 net.cpp:150] Setting up relu3
I0521 20:03:00.170722 12468 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 20:03:00.170732 12468 net.cpp:165] Memory required for data: 28604720
I0521 20:03:00.170742 12468 layer_factory.hpp:77] Creating layer pool3
I0521 20:03:00.170755 12468 net.cpp:106] Creating Layer pool3
I0521 20:03:00.170765 12468 net.cpp:454] pool3 <- conv3
I0521 20:03:00.170778 12468 net.cpp:411] pool3 -> pool3
I0521 20:03:00.170845 12468 net.cpp:150] Setting up pool3
I0521 20:03:00.170858 12468 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0521 20:03:00.170868 12468 net.cpp:165] Memory required for data: 29688880
I0521 20:03:00.170877 12468 layer_factory.hpp:77] Creating layer conv4
I0521 20:03:00.170895 12468 net.cpp:106] Creating Layer conv4
I0521 20:03:00.170905 12468 net.cpp:454] conv4 <- pool3
I0521 20:03:00.170919 12468 net.cpp:411] conv4 -> conv4
I0521 20:03:00.173617 12468 net.cpp:150] Setting up conv4
I0521 20:03:00.173645 12468 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 20:03:00.173656 12468 net.cpp:165] Memory required for data: 30414640
I0521 20:03:00.173671 12468 layer_factory.hpp:77] Creating layer relu4
I0521 20:03:00.173686 12468 net.cpp:106] Creating Layer relu4
I0521 20:03:00.173696 12468 net.cpp:454] relu4 <- conv4
I0521 20:03:00.173708 12468 net.cpp:397] relu4 -> conv4 (in-place)
I0521 20:03:00.174170 12468 net.cpp:150] Setting up relu4
I0521 20:03:00.174186 12468 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 20:03:00.174197 12468 net.cpp:165] Memory required for data: 31140400
I0521 20:03:00.174207 12468 layer_factory.hpp:77] Creating layer pool4
I0521 20:03:00.174221 12468 net.cpp:106] Creating Layer pool4
I0521 20:03:00.174231 12468 net.cpp:454] pool4 <- conv4
I0521 20:03:00.174243 12468 net.cpp:411] pool4 -> pool4
I0521 20:03:00.174311 12468 net.cpp:150] Setting up pool4
I0521 20:03:00.174325 12468 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0521 20:03:00.174336 12468 net.cpp:165] Memory required for data: 31503280
I0521 20:03:00.174346 12468 layer_factory.hpp:77] Creating layer ip1
I0521 20:03:00.174367 12468 net.cpp:106] Creating Layer ip1
I0521 20:03:00.174377 12468 net.cpp:454] ip1 <- pool4
I0521 20:03:00.174391 12468 net.cpp:411] ip1 -> ip1
I0521 20:03:00.189776 12468 net.cpp:150] Setting up ip1
I0521 20:03:00.189805 12468 net.cpp:157] Top shape: 20 196 (3920)
I0521 20:03:00.189820 12468 net.cpp:165] Memory required for data: 31518960
I0521 20:03:00.189841 12468 layer_factory.hpp:77] Creating layer relu5
I0521 20:03:00.189857 12468 net.cpp:106] Creating Layer relu5
I0521 20:03:00.189867 12468 net.cpp:454] relu5 <- ip1
I0521 20:03:00.189882 12468 net.cpp:397] relu5 -> ip1 (in-place)
I0521 20:03:00.190222 12468 net.cpp:150] Setting up relu5
I0521 20:03:00.190235 12468 net.cpp:157] Top shape: 20 196 (3920)
I0521 20:03:00.190245 12468 net.cpp:165] Memory required for data: 31534640
I0521 20:03:00.190256 12468 layer_factory.hpp:77] Creating layer drop1
I0521 20:03:00.190277 12468 net.cpp:106] Creating Layer drop1
I0521 20:03:00.190289 12468 net.cpp:454] drop1 <- ip1
I0521 20:03:00.190300 12468 net.cpp:397] drop1 -> ip1 (in-place)
I0521 20:03:00.190359 12468 net.cpp:150] Setting up drop1
I0521 20:03:00.190372 12468 net.cpp:157] Top shape: 20 196 (3920)
I0521 20:03:00.190382 12468 net.cpp:165] Memory required for data: 31550320
I0521 20:03:00.190392 12468 layer_factory.hpp:77] Creating layer ip2
I0521 20:03:00.190412 12468 net.cpp:106] Creating Layer ip2
I0521 20:03:00.190423 12468 net.cpp:454] ip2 <- ip1
I0521 20:03:00.190435 12468 net.cpp:411] ip2 -> ip2
I0521 20:03:00.190897 12468 net.cpp:150] Setting up ip2
I0521 20:03:00.190910 12468 net.cpp:157] Top shape: 20 98 (1960)
I0521 20:03:00.190920 12468 net.cpp:165] Memory required for data: 31558160
I0521 20:03:00.190935 12468 layer_factory.hpp:77] Creating layer relu6
I0521 20:03:00.190948 12468 net.cpp:106] Creating Layer relu6
I0521 20:03:00.190958 12468 net.cpp:454] relu6 <- ip2
I0521 20:03:00.190970 12468 net.cpp:397] relu6 -> ip2 (in-place)
I0521 20:03:00.191499 12468 net.cpp:150] Setting up relu6
I0521 20:03:00.191515 12468 net.cpp:157] Top shape: 20 98 (1960)
I0521 20:03:00.191526 12468 net.cpp:165] Memory required for data: 31566000
I0521 20:03:00.191536 12468 layer_factory.hpp:77] Creating layer drop2
I0521 20:03:00.191550 12468 net.cpp:106] Creating Layer drop2
I0521 20:03:00.191560 12468 net.cpp:454] drop2 <- ip2
I0521 20:03:00.191571 12468 net.cpp:397] drop2 -> ip2 (in-place)
I0521 20:03:00.191613 12468 net.cpp:150] Setting up drop2
I0521 20:03:00.191627 12468 net.cpp:157] Top shape: 20 98 (1960)
I0521 20:03:00.191638 12468 net.cpp:165] Memory required for data: 31573840
I0521 20:03:00.191648 12468 layer_factory.hpp:77] Creating layer ip3
I0521 20:03:00.191663 12468 net.cpp:106] Creating Layer ip3
I0521 20:03:00.191673 12468 net.cpp:454] ip3 <- ip2
I0521 20:03:00.191685 12468 net.cpp:411] ip3 -> ip3
I0521 20:03:00.191893 12468 net.cpp:150] Setting up ip3
I0521 20:03:00.191906 12468 net.cpp:157] Top shape: 20 11 (220)
I0521 20:03:00.191916 12468 net.cpp:165] Memory required for data: 31574720
I0521 20:03:00.191932 12468 layer_factory.hpp:77] Creating layer drop3
I0521 20:03:00.191944 12468 net.cpp:106] Creating Layer drop3
I0521 20:03:00.191954 12468 net.cpp:454] drop3 <- ip3
I0521 20:03:00.191967 12468 net.cpp:397] drop3 -> ip3 (in-place)
I0521 20:03:00.192006 12468 net.cpp:150] Setting up drop3
I0521 20:03:00.192018 12468 net.cpp:157] Top shape: 20 11 (220)
I0521 20:03:00.192028 12468 net.cpp:165] Memory required for data: 31575600
I0521 20:03:00.192039 12468 layer_factory.hpp:77] Creating layer loss
I0521 20:03:00.192057 12468 net.cpp:106] Creating Layer loss
I0521 20:03:00.192067 12468 net.cpp:454] loss <- ip3
I0521 20:03:00.192078 12468 net.cpp:454] loss <- label
I0521 20:03:00.192091 12468 net.cpp:411] loss -> loss
I0521 20:03:00.192107 12468 layer_factory.hpp:77] Creating layer loss
I0521 20:03:00.192746 12468 net.cpp:150] Setting up loss
I0521 20:03:00.192767 12468 net.cpp:157] Top shape: (1)
I0521 20:03:00.192777 12468 net.cpp:160]     with loss weight 1
I0521 20:03:00.192821 12468 net.cpp:165] Memory required for data: 31575604
I0521 20:03:00.192831 12468 net.cpp:226] loss needs backward computation.
I0521 20:03:00.192842 12468 net.cpp:226] drop3 needs backward computation.
I0521 20:03:00.192852 12468 net.cpp:226] ip3 needs backward computation.
I0521 20:03:00.192862 12468 net.cpp:226] drop2 needs backward computation.
I0521 20:03:00.192873 12468 net.cpp:226] relu6 needs backward computation.
I0521 20:03:00.192883 12468 net.cpp:226] ip2 needs backward computation.
I0521 20:03:00.192893 12468 net.cpp:226] drop1 needs backward computation.
I0521 20:03:00.192903 12468 net.cpp:226] relu5 needs backward computation.
I0521 20:03:00.192911 12468 net.cpp:226] ip1 needs backward computation.
I0521 20:03:00.192922 12468 net.cpp:226] pool4 needs backward computation.
I0521 20:03:00.192932 12468 net.cpp:226] relu4 needs backward computation.
I0521 20:03:00.192942 12468 net.cpp:226] conv4 needs backward computation.
I0521 20:03:00.192953 12468 net.cpp:226] pool3 needs backward computation.
I0521 20:03:00.192963 12468 net.cpp:226] relu3 needs backward computation.
I0521 20:03:00.192973 12468 net.cpp:226] conv3 needs backward computation.
I0521 20:03:00.192992 12468 net.cpp:226] pool2 needs backward computation.
I0521 20:03:00.193003 12468 net.cpp:226] relu2 needs backward computation.
I0521 20:03:00.193013 12468 net.cpp:226] conv2 needs backward computation.
I0521 20:03:00.193024 12468 net.cpp:226] pool1 needs backward computation.
I0521 20:03:00.193035 12468 net.cpp:226] relu1 needs backward computation.
I0521 20:03:00.193044 12468 net.cpp:226] conv1 needs backward computation.
I0521 20:03:00.193055 12468 net.cpp:228] data_hdf5 does not need backward computation.
I0521 20:03:00.193066 12468 net.cpp:270] This network produces output loss
I0521 20:03:00.193087 12468 net.cpp:283] Network initialization done.
I0521 20:03:00.194766 12468 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147.prototxt
I0521 20:03:00.194836 12468 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 20:03:00.195199 12468 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 20:03:00.195389 12468 layer_factory.hpp:77] Creating layer data_hdf5
I0521 20:03:00.195405 12468 net.cpp:106] Creating Layer data_hdf5
I0521 20:03:00.195417 12468 net.cpp:411] data_hdf5 -> data
I0521 20:03:00.195435 12468 net.cpp:411] data_hdf5 -> label
I0521 20:03:00.195449 12468 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 20:03:00.196748 12468 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 20:03:21.469667 12468 net.cpp:150] Setting up data_hdf5
I0521 20:03:21.469831 12468 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0521 20:03:21.469846 12468 net.cpp:157] Top shape: 20 (20)
I0521 20:03:21.469856 12468 net.cpp:165] Memory required for data: 508080
I0521 20:03:21.469871 12468 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 20:03:21.469898 12468 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 20:03:21.469909 12468 net.cpp:454] label_data_hdf5_1_split <- label
I0521 20:03:21.469924 12468 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 20:03:21.469945 12468 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 20:03:21.470018 12468 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 20:03:21.470032 12468 net.cpp:157] Top shape: 20 (20)
I0521 20:03:21.470046 12468 net.cpp:157] Top shape: 20 (20)
I0521 20:03:21.470054 12468 net.cpp:165] Memory required for data: 508240
I0521 20:03:21.470064 12468 layer_factory.hpp:77] Creating layer conv1
I0521 20:03:21.470087 12468 net.cpp:106] Creating Layer conv1
I0521 20:03:21.470096 12468 net.cpp:454] conv1 <- data
I0521 20:03:21.470110 12468 net.cpp:411] conv1 -> conv1
I0521 20:03:21.472064 12468 net.cpp:150] Setting up conv1
I0521 20:03:21.472089 12468 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 20:03:21.472100 12468 net.cpp:165] Memory required for data: 6037840
I0521 20:03:21.472121 12468 layer_factory.hpp:77] Creating layer relu1
I0521 20:03:21.472136 12468 net.cpp:106] Creating Layer relu1
I0521 20:03:21.472146 12468 net.cpp:454] relu1 <- conv1
I0521 20:03:21.472158 12468 net.cpp:397] relu1 -> conv1 (in-place)
I0521 20:03:21.472651 12468 net.cpp:150] Setting up relu1
I0521 20:03:21.472666 12468 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 20:03:21.472676 12468 net.cpp:165] Memory required for data: 11567440
I0521 20:03:21.472687 12468 layer_factory.hpp:77] Creating layer pool1
I0521 20:03:21.472703 12468 net.cpp:106] Creating Layer pool1
I0521 20:03:21.472713 12468 net.cpp:454] pool1 <- conv1
I0521 20:03:21.472726 12468 net.cpp:411] pool1 -> pool1
I0521 20:03:21.472801 12468 net.cpp:150] Setting up pool1
I0521 20:03:21.472815 12468 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0521 20:03:21.472826 12468 net.cpp:165] Memory required for data: 14332240
I0521 20:03:21.472833 12468 layer_factory.hpp:77] Creating layer conv2
I0521 20:03:21.472851 12468 net.cpp:106] Creating Layer conv2
I0521 20:03:21.472862 12468 net.cpp:454] conv2 <- pool1
I0521 20:03:21.472875 12468 net.cpp:411] conv2 -> conv2
I0521 20:03:21.474791 12468 net.cpp:150] Setting up conv2
I0521 20:03:21.474812 12468 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 20:03:21.474825 12468 net.cpp:165] Memory required for data: 18306640
I0521 20:03:21.474843 12468 layer_factory.hpp:77] Creating layer relu2
I0521 20:03:21.474856 12468 net.cpp:106] Creating Layer relu2
I0521 20:03:21.474866 12468 net.cpp:454] relu2 <- conv2
I0521 20:03:21.474879 12468 net.cpp:397] relu2 -> conv2 (in-place)
I0521 20:03:21.475219 12468 net.cpp:150] Setting up relu2
I0521 20:03:21.475231 12468 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 20:03:21.475242 12468 net.cpp:165] Memory required for data: 22281040
I0521 20:03:21.475252 12468 layer_factory.hpp:77] Creating layer pool2
I0521 20:03:21.475266 12468 net.cpp:106] Creating Layer pool2
I0521 20:03:21.475275 12468 net.cpp:454] pool2 <- conv2
I0521 20:03:21.475288 12468 net.cpp:411] pool2 -> pool2
I0521 20:03:21.475360 12468 net.cpp:150] Setting up pool2
I0521 20:03:21.475374 12468 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0521 20:03:21.475384 12468 net.cpp:165] Memory required for data: 24268240
I0521 20:03:21.475394 12468 layer_factory.hpp:77] Creating layer conv3
I0521 20:03:21.475411 12468 net.cpp:106] Creating Layer conv3
I0521 20:03:21.475422 12468 net.cpp:454] conv3 <- pool2
I0521 20:03:21.475436 12468 net.cpp:411] conv3 -> conv3
I0521 20:03:21.477401 12468 net.cpp:150] Setting up conv3
I0521 20:03:21.477419 12468 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 20:03:21.477430 12468 net.cpp:165] Memory required for data: 26436560
I0521 20:03:21.477448 12468 layer_factory.hpp:77] Creating layer relu3
I0521 20:03:21.477473 12468 net.cpp:106] Creating Layer relu3
I0521 20:03:21.477483 12468 net.cpp:454] relu3 <- conv3
I0521 20:03:21.477497 12468 net.cpp:397] relu3 -> conv3 (in-place)
I0521 20:03:21.477969 12468 net.cpp:150] Setting up relu3
I0521 20:03:21.477985 12468 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 20:03:21.477996 12468 net.cpp:165] Memory required for data: 28604880
I0521 20:03:21.478006 12468 layer_factory.hpp:77] Creating layer pool3
I0521 20:03:21.478019 12468 net.cpp:106] Creating Layer pool3
I0521 20:03:21.478029 12468 net.cpp:454] pool3 <- conv3
I0521 20:03:21.478042 12468 net.cpp:411] pool3 -> pool3
I0521 20:03:21.478114 12468 net.cpp:150] Setting up pool3
I0521 20:03:21.478128 12468 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0521 20:03:21.478138 12468 net.cpp:165] Memory required for data: 29689040
I0521 20:03:21.478147 12468 layer_factory.hpp:77] Creating layer conv4
I0521 20:03:21.478164 12468 net.cpp:106] Creating Layer conv4
I0521 20:03:21.478174 12468 net.cpp:454] conv4 <- pool3
I0521 20:03:21.478188 12468 net.cpp:411] conv4 -> conv4
I0521 20:03:21.480240 12468 net.cpp:150] Setting up conv4
I0521 20:03:21.480262 12468 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 20:03:21.480275 12468 net.cpp:165] Memory required for data: 30414800
I0521 20:03:21.480290 12468 layer_factory.hpp:77] Creating layer relu4
I0521 20:03:21.480304 12468 net.cpp:106] Creating Layer relu4
I0521 20:03:21.480314 12468 net.cpp:454] relu4 <- conv4
I0521 20:03:21.480327 12468 net.cpp:397] relu4 -> conv4 (in-place)
I0521 20:03:21.480800 12468 net.cpp:150] Setting up relu4
I0521 20:03:21.480816 12468 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 20:03:21.480828 12468 net.cpp:165] Memory required for data: 31140560
I0521 20:03:21.480837 12468 layer_factory.hpp:77] Creating layer pool4
I0521 20:03:21.480850 12468 net.cpp:106] Creating Layer pool4
I0521 20:03:21.480860 12468 net.cpp:454] pool4 <- conv4
I0521 20:03:21.480875 12468 net.cpp:411] pool4 -> pool4
I0521 20:03:21.480947 12468 net.cpp:150] Setting up pool4
I0521 20:03:21.480959 12468 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0521 20:03:21.480969 12468 net.cpp:165] Memory required for data: 31503440
I0521 20:03:21.480978 12468 layer_factory.hpp:77] Creating layer ip1
I0521 20:03:21.480993 12468 net.cpp:106] Creating Layer ip1
I0521 20:03:21.481003 12468 net.cpp:454] ip1 <- pool4
I0521 20:03:21.481017 12468 net.cpp:411] ip1 -> ip1
I0521 20:03:21.496453 12468 net.cpp:150] Setting up ip1
I0521 20:03:21.496481 12468 net.cpp:157] Top shape: 20 196 (3920)
I0521 20:03:21.496496 12468 net.cpp:165] Memory required for data: 31519120
I0521 20:03:21.496518 12468 layer_factory.hpp:77] Creating layer relu5
I0521 20:03:21.496533 12468 net.cpp:106] Creating Layer relu5
I0521 20:03:21.496544 12468 net.cpp:454] relu5 <- ip1
I0521 20:03:21.496556 12468 net.cpp:397] relu5 -> ip1 (in-place)
I0521 20:03:21.496904 12468 net.cpp:150] Setting up relu5
I0521 20:03:21.496918 12468 net.cpp:157] Top shape: 20 196 (3920)
I0521 20:03:21.496932 12468 net.cpp:165] Memory required for data: 31534800
I0521 20:03:21.496942 12468 layer_factory.hpp:77] Creating layer drop1
I0521 20:03:21.496960 12468 net.cpp:106] Creating Layer drop1
I0521 20:03:21.496970 12468 net.cpp:454] drop1 <- ip1
I0521 20:03:21.496984 12468 net.cpp:397] drop1 -> ip1 (in-place)
I0521 20:03:21.497030 12468 net.cpp:150] Setting up drop1
I0521 20:03:21.497042 12468 net.cpp:157] Top shape: 20 196 (3920)
I0521 20:03:21.497051 12468 net.cpp:165] Memory required for data: 31550480
I0521 20:03:21.497061 12468 layer_factory.hpp:77] Creating layer ip2
I0521 20:03:21.497076 12468 net.cpp:106] Creating Layer ip2
I0521 20:03:21.497086 12468 net.cpp:454] ip2 <- ip1
I0521 20:03:21.497099 12468 net.cpp:411] ip2 -> ip2
I0521 20:03:21.497577 12468 net.cpp:150] Setting up ip2
I0521 20:03:21.497591 12468 net.cpp:157] Top shape: 20 98 (1960)
I0521 20:03:21.497601 12468 net.cpp:165] Memory required for data: 31558320
I0521 20:03:21.497617 12468 layer_factory.hpp:77] Creating layer relu6
I0521 20:03:21.497642 12468 net.cpp:106] Creating Layer relu6
I0521 20:03:21.497653 12468 net.cpp:454] relu6 <- ip2
I0521 20:03:21.497665 12468 net.cpp:397] relu6 -> ip2 (in-place)
I0521 20:03:21.498198 12468 net.cpp:150] Setting up relu6
I0521 20:03:21.498220 12468 net.cpp:157] Top shape: 20 98 (1960)
I0521 20:03:21.498230 12468 net.cpp:165] Memory required for data: 31566160
I0521 20:03:21.498240 12468 layer_factory.hpp:77] Creating layer drop2
I0521 20:03:21.498255 12468 net.cpp:106] Creating Layer drop2
I0521 20:03:21.498265 12468 net.cpp:454] drop2 <- ip2
I0521 20:03:21.498277 12468 net.cpp:397] drop2 -> ip2 (in-place)
I0521 20:03:21.498322 12468 net.cpp:150] Setting up drop2
I0521 20:03:21.498334 12468 net.cpp:157] Top shape: 20 98 (1960)
I0521 20:03:21.498344 12468 net.cpp:165] Memory required for data: 31574000
I0521 20:03:21.498354 12468 layer_factory.hpp:77] Creating layer ip3
I0521 20:03:21.498368 12468 net.cpp:106] Creating Layer ip3
I0521 20:03:21.498378 12468 net.cpp:454] ip3 <- ip2
I0521 20:03:21.498390 12468 net.cpp:411] ip3 -> ip3
I0521 20:03:21.498611 12468 net.cpp:150] Setting up ip3
I0521 20:03:21.498625 12468 net.cpp:157] Top shape: 20 11 (220)
I0521 20:03:21.498634 12468 net.cpp:165] Memory required for data: 31574880
I0521 20:03:21.498651 12468 layer_factory.hpp:77] Creating layer drop3
I0521 20:03:21.498663 12468 net.cpp:106] Creating Layer drop3
I0521 20:03:21.498673 12468 net.cpp:454] drop3 <- ip3
I0521 20:03:21.498687 12468 net.cpp:397] drop3 -> ip3 (in-place)
I0521 20:03:21.498728 12468 net.cpp:150] Setting up drop3
I0521 20:03:21.498740 12468 net.cpp:157] Top shape: 20 11 (220)
I0521 20:03:21.498750 12468 net.cpp:165] Memory required for data: 31575760
I0521 20:03:21.498759 12468 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 20:03:21.498774 12468 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 20:03:21.498782 12468 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 20:03:21.498795 12468 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 20:03:21.498810 12468 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 20:03:21.498883 12468 net.cpp:150] Setting up ip3_drop3_0_split
I0521 20:03:21.498896 12468 net.cpp:157] Top shape: 20 11 (220)
I0521 20:03:21.498909 12468 net.cpp:157] Top shape: 20 11 (220)
I0521 20:03:21.498919 12468 net.cpp:165] Memory required for data: 31577520
I0521 20:03:21.498929 12468 layer_factory.hpp:77] Creating layer accuracy
I0521 20:03:21.498950 12468 net.cpp:106] Creating Layer accuracy
I0521 20:03:21.498960 12468 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 20:03:21.498971 12468 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 20:03:21.498986 12468 net.cpp:411] accuracy -> accuracy
I0521 20:03:21.499009 12468 net.cpp:150] Setting up accuracy
I0521 20:03:21.499022 12468 net.cpp:157] Top shape: (1)
I0521 20:03:21.499032 12468 net.cpp:165] Memory required for data: 31577524
I0521 20:03:21.499042 12468 layer_factory.hpp:77] Creating layer loss
I0521 20:03:21.499056 12468 net.cpp:106] Creating Layer loss
I0521 20:03:21.499066 12468 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 20:03:21.499078 12468 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 20:03:21.499090 12468 net.cpp:411] loss -> loss
I0521 20:03:21.499107 12468 layer_factory.hpp:77] Creating layer loss
I0521 20:03:21.499595 12468 net.cpp:150] Setting up loss
I0521 20:03:21.499609 12468 net.cpp:157] Top shape: (1)
I0521 20:03:21.499619 12468 net.cpp:160]     with loss weight 1
I0521 20:03:21.499639 12468 net.cpp:165] Memory required for data: 31577528
I0521 20:03:21.499650 12468 net.cpp:226] loss needs backward computation.
I0521 20:03:21.499660 12468 net.cpp:228] accuracy does not need backward computation.
I0521 20:03:21.499672 12468 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 20:03:21.499683 12468 net.cpp:226] drop3 needs backward computation.
I0521 20:03:21.499693 12468 net.cpp:226] ip3 needs backward computation.
I0521 20:03:21.499704 12468 net.cpp:226] drop2 needs backward computation.
I0521 20:03:21.499713 12468 net.cpp:226] relu6 needs backward computation.
I0521 20:03:21.499733 12468 net.cpp:226] ip2 needs backward computation.
I0521 20:03:21.499744 12468 net.cpp:226] drop1 needs backward computation.
I0521 20:03:21.499753 12468 net.cpp:226] relu5 needs backward computation.
I0521 20:03:21.499763 12468 net.cpp:226] ip1 needs backward computation.
I0521 20:03:21.499773 12468 net.cpp:226] pool4 needs backward computation.
I0521 20:03:21.499783 12468 net.cpp:226] relu4 needs backward computation.
I0521 20:03:21.499794 12468 net.cpp:226] conv4 needs backward computation.
I0521 20:03:21.499801 12468 net.cpp:226] pool3 needs backward computation.
I0521 20:03:21.499812 12468 net.cpp:226] relu3 needs backward computation.
I0521 20:03:21.499822 12468 net.cpp:226] conv3 needs backward computation.
I0521 20:03:21.499835 12468 net.cpp:226] pool2 needs backward computation.
I0521 20:03:21.499845 12468 net.cpp:226] relu2 needs backward computation.
I0521 20:03:21.499855 12468 net.cpp:226] conv2 needs backward computation.
I0521 20:03:21.499864 12468 net.cpp:226] pool1 needs backward computation.
I0521 20:03:21.499874 12468 net.cpp:226] relu1 needs backward computation.
I0521 20:03:21.499884 12468 net.cpp:226] conv1 needs backward computation.
I0521 20:03:21.499897 12468 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 20:03:21.499910 12468 net.cpp:228] data_hdf5 does not need backward computation.
I0521 20:03:21.499920 12468 net.cpp:270] This network produces output accuracy
I0521 20:03:21.499932 12468 net.cpp:270] This network produces output loss
I0521 20:03:21.499959 12468 net.cpp:283] Network initialization done.
I0521 20:03:21.500093 12468 solver.cpp:60] Solver scaffolding done.
I0521 20:03:21.501222 12468 caffe.cpp:212] Starting Optimization
I0521 20:03:21.501235 12468 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 20:03:21.501247 12468 solver.cpp:289] Learning Rate Policy: fixed
I0521 20:03:21.502468 12468 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 20:04:14.275568 12468 solver.cpp:409]     Test net output #0: accuracy = 0.121205
I0521 20:04:14.275732 12468 solver.cpp:409]     Test net output #1: loss = 2.3968 (* 1 = 2.3968 loss)
I0521 20:04:14.294839 12468 solver.cpp:237] Iteration 0, loss = 2.39921
I0521 20:04:14.294877 12468 solver.cpp:253]     Train net output #0: loss = 2.39921 (* 1 = 2.39921 loss)
I0521 20:04:14.294894 12468 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0521 20:04:26.451015 12468 solver.cpp:237] Iteration 750, loss = 2.34042
I0521 20:04:26.451053 12468 solver.cpp:253]     Train net output #0: loss = 2.34042 (* 1 = 2.34042 loss)
I0521 20:04:26.451066 12468 sgd_solver.cpp:106] Iteration 750, lr = 0.0005
I0521 20:04:38.659612 12468 solver.cpp:237] Iteration 1500, loss = 2.24976
I0521 20:04:38.659659 12468 solver.cpp:253]     Train net output #0: loss = 2.24976 (* 1 = 2.24976 loss)
I0521 20:04:38.659677 12468 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0521 20:04:50.788714 12468 solver.cpp:237] Iteration 2250, loss = 2.11922
I0521 20:04:50.788872 12468 solver.cpp:253]     Train net output #0: loss = 2.11922 (* 1 = 2.11922 loss)
I0521 20:04:50.788887 12468 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0521 20:05:02.964758 12468 solver.cpp:237] Iteration 3000, loss = 1.77036
I0521 20:05:02.964804 12468 solver.cpp:253]     Train net output #0: loss = 1.77036 (* 1 = 1.77036 loss)
I0521 20:05:02.964819 12468 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0521 20:05:15.171881 12468 solver.cpp:237] Iteration 3750, loss = 2.08105
I0521 20:05:15.171918 12468 solver.cpp:253]     Train net output #0: loss = 2.08105 (* 1 = 2.08105 loss)
I0521 20:05:15.171936 12468 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0521 20:05:27.365440 12468 solver.cpp:237] Iteration 4500, loss = 1.73149
I0521 20:05:27.365586 12468 solver.cpp:253]     Train net output #0: loss = 1.73149 (* 1 = 1.73149 loss)
I0521 20:05:27.365602 12468 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0521 20:06:01.616842 12468 solver.cpp:237] Iteration 5250, loss = 1.77009
I0521 20:06:01.617013 12468 solver.cpp:253]     Train net output #0: loss = 1.77009 (* 1 = 1.77009 loss)
I0521 20:06:01.617029 12468 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0521 20:06:13.752485 12468 solver.cpp:237] Iteration 6000, loss = 1.97467
I0521 20:06:13.752521 12468 solver.cpp:253]     Train net output #0: loss = 1.97467 (* 1 = 1.97467 loss)
I0521 20:06:13.752537 12468 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0521 20:06:25.872288 12468 solver.cpp:237] Iteration 6750, loss = 2.28669
I0521 20:06:25.872334 12468 solver.cpp:253]     Train net output #0: loss = 2.28669 (* 1 = 2.28669 loss)
I0521 20:06:25.872350 12468 sgd_solver.cpp:106] Iteration 6750, lr = 0.0005
I0521 20:06:38.014394 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_7500.caffemodel
I0521 20:06:38.075441 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_7500.solverstate
I0521 20:06:38.105532 12468 solver.cpp:237] Iteration 7500, loss = 1.67836
I0521 20:06:38.105578 12468 solver.cpp:253]     Train net output #0: loss = 1.67836 (* 1 = 1.67836 loss)
I0521 20:06:38.105597 12468 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0521 20:06:50.297760 12468 solver.cpp:237] Iteration 8250, loss = 1.76163
I0521 20:06:50.297811 12468 solver.cpp:253]     Train net output #0: loss = 1.76163 (* 1 = 1.76163 loss)
I0521 20:06:50.297824 12468 sgd_solver.cpp:106] Iteration 8250, lr = 0.0005
I0521 20:07:02.508538 12468 solver.cpp:237] Iteration 9000, loss = 1.61642
I0521 20:07:02.508574 12468 solver.cpp:253]     Train net output #0: loss = 1.61642 (* 1 = 1.61642 loss)
I0521 20:07:02.508591 12468 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0521 20:07:14.729182 12468 solver.cpp:237] Iteration 9750, loss = 1.96779
I0521 20:07:14.729338 12468 solver.cpp:253]     Train net output #0: loss = 1.96779 (* 1 = 1.96779 loss)
I0521 20:07:14.729354 12468 sgd_solver.cpp:106] Iteration 9750, lr = 0.0005
I0521 20:07:49.056594 12468 solver.cpp:237] Iteration 10500, loss = 1.7245
I0521 20:07:49.056756 12468 solver.cpp:253]     Train net output #0: loss = 1.7245 (* 1 = 1.7245 loss)
I0521 20:07:49.056771 12468 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0521 20:08:01.225237 12468 solver.cpp:237] Iteration 11250, loss = 1.59243
I0521 20:08:01.225283 12468 solver.cpp:253]     Train net output #0: loss = 1.59243 (* 1 = 1.59243 loss)
I0521 20:08:01.225301 12468 sgd_solver.cpp:106] Iteration 11250, lr = 0.0005
I0521 20:08:13.393132 12468 solver.cpp:237] Iteration 12000, loss = 1.52265
I0521 20:08:13.393168 12468 solver.cpp:253]     Train net output #0: loss = 1.52265 (* 1 = 1.52265 loss)
I0521 20:08:13.393184 12468 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0521 20:08:25.556287 12468 solver.cpp:237] Iteration 12750, loss = 1.729
I0521 20:08:25.556452 12468 solver.cpp:253]     Train net output #0: loss = 1.729 (* 1 = 1.729 loss)
I0521 20:08:25.556466 12468 sgd_solver.cpp:106] Iteration 12750, lr = 0.0005
I0521 20:08:37.776274 12468 solver.cpp:237] Iteration 13500, loss = 1.6407
I0521 20:08:37.776311 12468 solver.cpp:253]     Train net output #0: loss = 1.6407 (* 1 = 1.6407 loss)
I0521 20:08:37.776326 12468 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0521 20:08:49.951046 12468 solver.cpp:237] Iteration 14250, loss = 1.68325
I0521 20:08:49.951097 12468 solver.cpp:253]     Train net output #0: loss = 1.68325 (* 1 = 1.68325 loss)
I0521 20:08:49.951110 12468 sgd_solver.cpp:106] Iteration 14250, lr = 0.0005
I0521 20:09:02.091977 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_15000.caffemodel
I0521 20:09:02.141567 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_15000.solverstate
I0521 20:09:02.166571 12468 solver.cpp:341] Iteration 15000, Testing net (#0)
I0521 20:09:54.020920 12468 solver.cpp:409]     Test net output #0: accuracy = 0.699319
I0521 20:09:54.021080 12468 solver.cpp:409]     Test net output #1: loss = 1.01696 (* 1 = 1.01696 loss)
I0521 20:10:16.135931 12468 solver.cpp:237] Iteration 15000, loss = 1.62837
I0521 20:10:16.135983 12468 solver.cpp:253]     Train net output #0: loss = 1.62837 (* 1 = 1.62837 loss)
I0521 20:10:16.135999 12468 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0521 20:10:28.275864 12468 solver.cpp:237] Iteration 15750, loss = 1.75945
I0521 20:10:28.276024 12468 solver.cpp:253]     Train net output #0: loss = 1.75945 (* 1 = 1.75945 loss)
I0521 20:10:28.276039 12468 sgd_solver.cpp:106] Iteration 15750, lr = 0.0005
I0521 20:10:40.407600 12468 solver.cpp:237] Iteration 16500, loss = 1.79349
I0521 20:10:40.407636 12468 solver.cpp:253]     Train net output #0: loss = 1.79349 (* 1 = 1.79349 loss)
I0521 20:10:40.407651 12468 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0521 20:10:52.535078 12468 solver.cpp:237] Iteration 17250, loss = 1.44074
I0521 20:10:52.535125 12468 solver.cpp:253]     Train net output #0: loss = 1.44074 (* 1 = 1.44074 loss)
I0521 20:10:52.535138 12468 sgd_solver.cpp:106] Iteration 17250, lr = 0.0005
I0521 20:11:04.659035 12468 solver.cpp:237] Iteration 18000, loss = 1.30256
I0521 20:11:04.659189 12468 solver.cpp:253]     Train net output #0: loss = 1.30256 (* 1 = 1.30256 loss)
I0521 20:11:04.659204 12468 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0521 20:11:16.764562 12468 solver.cpp:237] Iteration 18750, loss = 1.63886
I0521 20:11:16.764608 12468 solver.cpp:253]     Train net output #0: loss = 1.63886 (* 1 = 1.63886 loss)
I0521 20:11:16.764626 12468 sgd_solver.cpp:106] Iteration 18750, lr = 0.0005
I0521 20:11:28.857172 12468 solver.cpp:237] Iteration 19500, loss = 1.38804
I0521 20:11:28.857208 12468 solver.cpp:253]     Train net output #0: loss = 1.38804 (* 1 = 1.38804 loss)
I0521 20:11:28.857223 12468 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0521 20:12:03.100973 12468 solver.cpp:237] Iteration 20250, loss = 1.30179
I0521 20:12:03.101136 12468 solver.cpp:253]     Train net output #0: loss = 1.30179 (* 1 = 1.30179 loss)
I0521 20:12:03.101150 12468 sgd_solver.cpp:106] Iteration 20250, lr = 0.0005
I0521 20:12:15.232885 12468 solver.cpp:237] Iteration 21000, loss = 1.37761
I0521 20:12:15.232931 12468 solver.cpp:253]     Train net output #0: loss = 1.37761 (* 1 = 1.37761 loss)
I0521 20:12:15.232947 12468 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0521 20:12:27.375676 12468 solver.cpp:237] Iteration 21750, loss = 1.45703
I0521 20:12:27.375713 12468 solver.cpp:253]     Train net output #0: loss = 1.45703 (* 1 = 1.45703 loss)
I0521 20:12:27.375730 12468 sgd_solver.cpp:106] Iteration 21750, lr = 0.0005
I0521 20:12:39.496387 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_22500.caffemodel
I0521 20:12:39.548202 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_22500.solverstate
I0521 20:12:39.581693 12468 solver.cpp:237] Iteration 22500, loss = 1.62428
I0521 20:12:39.581743 12468 solver.cpp:253]     Train net output #0: loss = 1.62428 (* 1 = 1.62428 loss)
I0521 20:12:39.581760 12468 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0521 20:12:51.710702 12468 solver.cpp:237] Iteration 23250, loss = 1.45245
I0521 20:12:51.710738 12468 solver.cpp:253]     Train net output #0: loss = 1.45245 (* 1 = 1.45245 loss)
I0521 20:12:51.710754 12468 sgd_solver.cpp:106] Iteration 23250, lr = 0.0005
I0521 20:13:03.774837 12468 solver.cpp:237] Iteration 24000, loss = 1.35545
I0521 20:13:03.774888 12468 solver.cpp:253]     Train net output #0: loss = 1.35545 (* 1 = 1.35545 loss)
I0521 20:13:03.774902 12468 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0521 20:13:15.837199 12468 solver.cpp:237] Iteration 24750, loss = 1.58796
I0521 20:13:15.837343 12468 solver.cpp:253]     Train net output #0: loss = 1.58796 (* 1 = 1.58796 loss)
I0521 20:13:15.837357 12468 sgd_solver.cpp:106] Iteration 24750, lr = 0.0005
I0521 20:13:50.074827 12468 solver.cpp:237] Iteration 25500, loss = 1.50231
I0521 20:13:50.074991 12468 solver.cpp:253]     Train net output #0: loss = 1.50231 (* 1 = 1.50231 loss)
I0521 20:13:50.075006 12468 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0521 20:14:02.234705 12468 solver.cpp:237] Iteration 26250, loss = 1.56036
I0521 20:14:02.234741 12468 solver.cpp:253]     Train net output #0: loss = 1.56036 (* 1 = 1.56036 loss)
I0521 20:14:02.234757 12468 sgd_solver.cpp:106] Iteration 26250, lr = 0.0005
I0521 20:14:14.370683 12468 solver.cpp:237] Iteration 27000, loss = 1.56293
I0521 20:14:14.370731 12468 solver.cpp:253]     Train net output #0: loss = 1.56293 (* 1 = 1.56293 loss)
I0521 20:14:14.370746 12468 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0521 20:14:26.575332 12468 solver.cpp:237] Iteration 27750, loss = 1.63238
I0521 20:14:26.575479 12468 solver.cpp:253]     Train net output #0: loss = 1.63238 (* 1 = 1.63238 loss)
I0521 20:14:26.575494 12468 sgd_solver.cpp:106] Iteration 27750, lr = 0.0005
I0521 20:14:38.762001 12468 solver.cpp:237] Iteration 28500, loss = 1.44027
I0521 20:14:38.762051 12468 solver.cpp:253]     Train net output #0: loss = 1.44027 (* 1 = 1.44027 loss)
I0521 20:14:38.762065 12468 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0521 20:14:50.941373 12468 solver.cpp:237] Iteration 29250, loss = 1.12171
I0521 20:14:50.941406 12468 solver.cpp:253]     Train net output #0: loss = 1.12171 (* 1 = 1.12171 loss)
I0521 20:14:50.941419 12468 sgd_solver.cpp:106] Iteration 29250, lr = 0.0005
I0521 20:15:03.081532 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_30000.caffemodel
I0521 20:15:03.132997 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_30000.solverstate
I0521 20:15:03.161590 12468 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 20:16:16.076305 12468 solver.cpp:409]     Test net output #0: accuracy = 0.805719
I0521 20:16:16.076470 12468 solver.cpp:409]     Test net output #1: loss = 0.732214 (* 1 = 0.732214 loss)
I0521 20:16:38.226099 12468 solver.cpp:237] Iteration 30000, loss = 1.43219
I0521 20:16:38.226150 12468 solver.cpp:253]     Train net output #0: loss = 1.43219 (* 1 = 1.43219 loss)
I0521 20:16:38.226166 12468 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0521 20:16:50.330842 12468 solver.cpp:237] Iteration 30750, loss = 0.85069
I0521 20:16:50.331010 12468 solver.cpp:253]     Train net output #0: loss = 0.85069 (* 1 = 0.85069 loss)
I0521 20:16:50.331027 12468 sgd_solver.cpp:106] Iteration 30750, lr = 0.0005
I0521 20:17:02.435456 12468 solver.cpp:237] Iteration 31500, loss = 1.47445
I0521 20:17:02.435492 12468 solver.cpp:253]     Train net output #0: loss = 1.47445 (* 1 = 1.47445 loss)
I0521 20:17:02.435508 12468 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0521 20:17:14.539654 12468 solver.cpp:237] Iteration 32250, loss = 1.89078
I0521 20:17:14.539700 12468 solver.cpp:253]     Train net output #0: loss = 1.89078 (* 1 = 1.89078 loss)
I0521 20:17:14.539716 12468 sgd_solver.cpp:106] Iteration 32250, lr = 0.0005
I0521 20:17:26.651388 12468 solver.cpp:237] Iteration 33000, loss = 1.68256
I0521 20:17:26.651538 12468 solver.cpp:253]     Train net output #0: loss = 1.68256 (* 1 = 1.68256 loss)
I0521 20:17:26.651552 12468 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0521 20:17:38.759023 12468 solver.cpp:237] Iteration 33750, loss = 1.64344
I0521 20:17:38.759068 12468 solver.cpp:253]     Train net output #0: loss = 1.64344 (* 1 = 1.64344 loss)
I0521 20:17:38.759081 12468 sgd_solver.cpp:106] Iteration 33750, lr = 0.0005
I0521 20:17:50.888362 12468 solver.cpp:237] Iteration 34500, loss = 1.21011
I0521 20:17:50.888398 12468 solver.cpp:253]     Train net output #0: loss = 1.21011 (* 1 = 1.21011 loss)
I0521 20:17:50.888414 12468 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0521 20:18:25.190619 12468 solver.cpp:237] Iteration 35250, loss = 1.30635
I0521 20:18:25.190783 12468 solver.cpp:253]     Train net output #0: loss = 1.30636 (* 1 = 1.30636 loss)
I0521 20:18:25.190798 12468 sgd_solver.cpp:106] Iteration 35250, lr = 0.0005
I0521 20:18:37.298688 12468 solver.cpp:237] Iteration 36000, loss = 1.07843
I0521 20:18:37.298724 12468 solver.cpp:253]     Train net output #0: loss = 1.07843 (* 1 = 1.07843 loss)
I0521 20:18:37.298740 12468 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0521 20:18:49.398535 12468 solver.cpp:237] Iteration 36750, loss = 1.60572
I0521 20:18:49.398581 12468 solver.cpp:253]     Train net output #0: loss = 1.60572 (* 1 = 1.60572 loss)
I0521 20:18:49.398597 12468 sgd_solver.cpp:106] Iteration 36750, lr = 0.0005
I0521 20:19:01.526760 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_37500.caffemodel
I0521 20:19:01.578322 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_37500.solverstate
I0521 20:19:01.611781 12468 solver.cpp:237] Iteration 37500, loss = 1.43299
I0521 20:19:01.611831 12468 solver.cpp:253]     Train net output #0: loss = 1.43299 (* 1 = 1.43299 loss)
I0521 20:19:01.611845 12468 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0521 20:19:13.770289 12468 solver.cpp:237] Iteration 38250, loss = 1.62254
I0521 20:19:13.770340 12468 solver.cpp:253]     Train net output #0: loss = 1.62254 (* 1 = 1.62254 loss)
I0521 20:19:13.770354 12468 sgd_solver.cpp:106] Iteration 38250, lr = 0.0005
I0521 20:19:25.864651 12468 solver.cpp:237] Iteration 39000, loss = 1.36558
I0521 20:19:25.864687 12468 solver.cpp:253]     Train net output #0: loss = 1.36558 (* 1 = 1.36558 loss)
I0521 20:19:25.864704 12468 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0521 20:19:37.958430 12468 solver.cpp:237] Iteration 39750, loss = 1.71177
I0521 20:19:37.958585 12468 solver.cpp:253]     Train net output #0: loss = 1.71177 (* 1 = 1.71177 loss)
I0521 20:19:37.958600 12468 sgd_solver.cpp:106] Iteration 39750, lr = 0.0005
I0521 20:20:12.238127 12468 solver.cpp:237] Iteration 40500, loss = 1.1762
I0521 20:20:12.238302 12468 solver.cpp:253]     Train net output #0: loss = 1.1762 (* 1 = 1.1762 loss)
I0521 20:20:12.238317 12468 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0521 20:20:24.331954 12468 solver.cpp:237] Iteration 41250, loss = 1.11052
I0521 20:20:24.331990 12468 solver.cpp:253]     Train net output #0: loss = 1.11052 (* 1 = 1.11052 loss)
I0521 20:20:24.332003 12468 sgd_solver.cpp:106] Iteration 41250, lr = 0.0005
I0521 20:20:36.430364 12468 solver.cpp:237] Iteration 42000, loss = 1.25391
I0521 20:20:36.430413 12468 solver.cpp:253]     Train net output #0: loss = 1.25391 (* 1 = 1.25391 loss)
I0521 20:20:36.430428 12468 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0521 20:20:48.547906 12468 solver.cpp:237] Iteration 42750, loss = 1.06678
I0521 20:20:48.548048 12468 solver.cpp:253]     Train net output #0: loss = 1.06678 (* 1 = 1.06678 loss)
I0521 20:20:48.548064 12468 sgd_solver.cpp:106] Iteration 42750, lr = 0.0005
I0521 20:21:00.651373 12468 solver.cpp:237] Iteration 43500, loss = 1.53771
I0521 20:21:00.651419 12468 solver.cpp:253]     Train net output #0: loss = 1.53771 (* 1 = 1.53771 loss)
I0521 20:21:00.651433 12468 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0521 20:21:12.759834 12468 solver.cpp:237] Iteration 44250, loss = 1.2441
I0521 20:21:12.759870 12468 solver.cpp:253]     Train net output #0: loss = 1.2441 (* 1 = 1.2441 loss)
I0521 20:21:12.759886 12468 sgd_solver.cpp:106] Iteration 44250, lr = 0.0005
I0521 20:21:24.845641 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_45000.caffemodel
I0521 20:21:24.895421 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_45000.solverstate
I0521 20:21:24.921581 12468 solver.cpp:341] Iteration 45000, Testing net (#0)
I0521 20:22:16.533342 12468 solver.cpp:409]     Test net output #0: accuracy = 0.825899
I0521 20:22:16.533500 12468 solver.cpp:409]     Test net output #1: loss = 0.634586 (* 1 = 0.634586 loss)
I0521 20:22:38.700014 12468 solver.cpp:237] Iteration 45000, loss = 1.06951
I0521 20:22:38.700065 12468 solver.cpp:253]     Train net output #0: loss = 1.06951 (* 1 = 1.06951 loss)
I0521 20:22:38.700083 12468 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0521 20:22:50.823873 12468 solver.cpp:237] Iteration 45750, loss = 1.42411
I0521 20:22:50.824025 12468 solver.cpp:253]     Train net output #0: loss = 1.42411 (* 1 = 1.42411 loss)
I0521 20:22:50.824038 12468 sgd_solver.cpp:106] Iteration 45750, lr = 0.0005
I0521 20:23:02.949352 12468 solver.cpp:237] Iteration 46500, loss = 1.51589
I0521 20:23:02.949398 12468 solver.cpp:253]     Train net output #0: loss = 1.51589 (* 1 = 1.51589 loss)
I0521 20:23:02.949412 12468 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0521 20:23:15.087337 12468 solver.cpp:237] Iteration 47250, loss = 1.58602
I0521 20:23:15.087373 12468 solver.cpp:253]     Train net output #0: loss = 1.58602 (* 1 = 1.58602 loss)
I0521 20:23:15.087388 12468 sgd_solver.cpp:106] Iteration 47250, lr = 0.0005
I0521 20:23:27.186633 12468 solver.cpp:237] Iteration 48000, loss = 1.5733
I0521 20:23:27.186784 12468 solver.cpp:253]     Train net output #0: loss = 1.5733 (* 1 = 1.5733 loss)
I0521 20:23:27.186800 12468 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0521 20:23:39.237390 12468 solver.cpp:237] Iteration 48750, loss = 1.45746
I0521 20:23:39.237426 12468 solver.cpp:253]     Train net output #0: loss = 1.45746 (* 1 = 1.45746 loss)
I0521 20:23:39.237442 12468 sgd_solver.cpp:106] Iteration 48750, lr = 0.0005
I0521 20:23:51.286453 12468 solver.cpp:237] Iteration 49500, loss = 1.36303
I0521 20:23:51.286499 12468 solver.cpp:253]     Train net output #0: loss = 1.36303 (* 1 = 1.36303 loss)
I0521 20:23:51.286514 12468 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0521 20:24:25.497378 12468 solver.cpp:237] Iteration 50250, loss = 1.40793
I0521 20:24:25.497552 12468 solver.cpp:253]     Train net output #0: loss = 1.40793 (* 1 = 1.40793 loss)
I0521 20:24:25.497567 12468 sgd_solver.cpp:106] Iteration 50250, lr = 0.0005
I0521 20:24:37.581776 12468 solver.cpp:237] Iteration 51000, loss = 1.16015
I0521 20:24:37.581827 12468 solver.cpp:253]     Train net output #0: loss = 1.16015 (* 1 = 1.16015 loss)
I0521 20:24:37.581841 12468 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0521 20:24:49.702764 12468 solver.cpp:237] Iteration 51750, loss = 1.54283
I0521 20:24:49.702800 12468 solver.cpp:253]     Train net output #0: loss = 1.54283 (* 1 = 1.54283 loss)
I0521 20:24:49.702816 12468 sgd_solver.cpp:106] Iteration 51750, lr = 0.0005
I0521 20:25:01.804019 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_52500.caffemodel
I0521 20:25:01.852870 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_52500.solverstate
I0521 20:25:01.883883 12468 solver.cpp:237] Iteration 52500, loss = 1.55528
I0521 20:25:01.883924 12468 solver.cpp:253]     Train net output #0: loss = 1.55528 (* 1 = 1.55528 loss)
I0521 20:25:01.883945 12468 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0521 20:25:14.000366 12468 solver.cpp:237] Iteration 53250, loss = 1.29936
I0521 20:25:14.000403 12468 solver.cpp:253]     Train net output #0: loss = 1.29936 (* 1 = 1.29936 loss)
I0521 20:25:14.000419 12468 sgd_solver.cpp:106] Iteration 53250, lr = 0.0005
I0521 20:25:26.112016 12468 solver.cpp:237] Iteration 54000, loss = 1.23387
I0521 20:25:26.112063 12468 solver.cpp:253]     Train net output #0: loss = 1.23387 (* 1 = 1.23387 loss)
I0521 20:25:26.112079 12468 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0521 20:25:38.223134 12468 solver.cpp:237] Iteration 54750, loss = 0.796406
I0521 20:25:38.223289 12468 solver.cpp:253]     Train net output #0: loss = 0.796406 (* 1 = 0.796406 loss)
I0521 20:25:38.223304 12468 sgd_solver.cpp:106] Iteration 54750, lr = 0.0005
I0521 20:26:12.510661 12468 solver.cpp:237] Iteration 55500, loss = 1.06017
I0521 20:26:12.510839 12468 solver.cpp:253]     Train net output #0: loss = 1.06017 (* 1 = 1.06017 loss)
I0521 20:26:12.510855 12468 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0521 20:26:24.623543 12468 solver.cpp:237] Iteration 56250, loss = 1.52822
I0521 20:26:24.623589 12468 solver.cpp:253]     Train net output #0: loss = 1.52822 (* 1 = 1.52822 loss)
I0521 20:26:24.623605 12468 sgd_solver.cpp:106] Iteration 56250, lr = 0.0005
I0521 20:26:36.792528 12468 solver.cpp:237] Iteration 57000, loss = 1.48282
I0521 20:26:36.792563 12468 solver.cpp:253]     Train net output #0: loss = 1.48282 (* 1 = 1.48282 loss)
I0521 20:26:36.792580 12468 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0521 20:26:48.968148 12468 solver.cpp:237] Iteration 57750, loss = 1.10819
I0521 20:26:48.968305 12468 solver.cpp:253]     Train net output #0: loss = 1.10819 (* 1 = 1.10819 loss)
I0521 20:26:48.968320 12468 sgd_solver.cpp:106] Iteration 57750, lr = 0.0005
I0521 20:27:01.095443 12468 solver.cpp:237] Iteration 58500, loss = 1.06585
I0521 20:27:01.095479 12468 solver.cpp:253]     Train net output #0: loss = 1.06585 (* 1 = 1.06585 loss)
I0521 20:27:01.095494 12468 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0521 20:27:13.179575 12468 solver.cpp:237] Iteration 59250, loss = 1.442
I0521 20:27:13.179616 12468 solver.cpp:253]     Train net output #0: loss = 1.442 (* 1 = 1.442 loss)
I0521 20:27:13.179630 12468 sgd_solver.cpp:106] Iteration 59250, lr = 0.0005
I0521 20:27:25.284577 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_60000.caffemodel
I0521 20:27:25.342139 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_60000.solverstate
I0521 20:27:25.368299 12468 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 20:28:38.083927 12468 solver.cpp:409]     Test net output #0: accuracy = 0.840173
I0521 20:28:38.084101 12468 solver.cpp:409]     Test net output #1: loss = 0.527413 (* 1 = 0.527413 loss)
I0521 20:29:00.222764 12468 solver.cpp:237] Iteration 60000, loss = 2.28428
I0521 20:29:00.222817 12468 solver.cpp:253]     Train net output #0: loss = 2.28428 (* 1 = 2.28428 loss)
I0521 20:29:00.222833 12468 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0521 20:29:12.412786 12468 solver.cpp:237] Iteration 60750, loss = 1.47728
I0521 20:29:12.412945 12468 solver.cpp:253]     Train net output #0: loss = 1.47728 (* 1 = 1.47728 loss)
I0521 20:29:12.412958 12468 sgd_solver.cpp:106] Iteration 60750, lr = 0.0005
I0521 20:29:24.544630 12468 solver.cpp:237] Iteration 61500, loss = 1.16784
I0521 20:29:24.544664 12468 solver.cpp:253]     Train net output #0: loss = 1.16784 (* 1 = 1.16784 loss)
I0521 20:29:24.544683 12468 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0521 20:29:36.706164 12468 solver.cpp:237] Iteration 62250, loss = 0.977013
I0521 20:29:36.706215 12468 solver.cpp:253]     Train net output #0: loss = 0.977012 (* 1 = 0.977012 loss)
I0521 20:29:36.706229 12468 sgd_solver.cpp:106] Iteration 62250, lr = 0.0005
I0521 20:29:48.882179 12468 solver.cpp:237] Iteration 63000, loss = 1.28355
I0521 20:29:48.882325 12468 solver.cpp:253]     Train net output #0: loss = 1.28355 (* 1 = 1.28355 loss)
I0521 20:29:48.882340 12468 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0521 20:30:01.037698 12468 solver.cpp:237] Iteration 63750, loss = 1.34712
I0521 20:30:01.037745 12468 solver.cpp:253]     Train net output #0: loss = 1.34712 (* 1 = 1.34712 loss)
I0521 20:30:01.037762 12468 sgd_solver.cpp:106] Iteration 63750, lr = 0.0005
I0521 20:30:13.173666 12468 solver.cpp:237] Iteration 64500, loss = 1.59267
I0521 20:30:13.173702 12468 solver.cpp:253]     Train net output #0: loss = 1.59267 (* 1 = 1.59267 loss)
I0521 20:30:13.173714 12468 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0521 20:30:47.460701 12468 solver.cpp:237] Iteration 65250, loss = 1.54608
I0521 20:30:47.460868 12468 solver.cpp:253]     Train net output #0: loss = 1.54608 (* 1 = 1.54608 loss)
I0521 20:30:47.460883 12468 sgd_solver.cpp:106] Iteration 65250, lr = 0.0005
I0521 20:30:59.560919 12468 solver.cpp:237] Iteration 66000, loss = 1.28638
I0521 20:30:59.560968 12468 solver.cpp:253]     Train net output #0: loss = 1.28638 (* 1 = 1.28638 loss)
I0521 20:30:59.560984 12468 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0521 20:31:11.730208 12468 solver.cpp:237] Iteration 66750, loss = 1.41869
I0521 20:31:11.730245 12468 solver.cpp:253]     Train net output #0: loss = 1.41869 (* 1 = 1.41869 loss)
I0521 20:31:11.730262 12468 sgd_solver.cpp:106] Iteration 66750, lr = 0.0005
I0521 20:31:23.856145 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_67500.caffemodel
I0521 20:31:23.908079 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_67500.solverstate
I0521 20:31:23.941519 12468 solver.cpp:237] Iteration 67500, loss = 1.76109
I0521 20:31:23.941570 12468 solver.cpp:253]     Train net output #0: loss = 1.76109 (* 1 = 1.76109 loss)
I0521 20:31:23.941583 12468 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0521 20:31:36.052845 12468 solver.cpp:237] Iteration 68250, loss = 1.01124
I0521 20:31:36.052882 12468 solver.cpp:253]     Train net output #0: loss = 1.01124 (* 1 = 1.01124 loss)
I0521 20:31:36.052898 12468 sgd_solver.cpp:106] Iteration 68250, lr = 0.0005
I0521 20:31:48.171345 12468 solver.cpp:237] Iteration 69000, loss = 1.77892
I0521 20:31:48.171396 12468 solver.cpp:253]     Train net output #0: loss = 1.77892 (* 1 = 1.77892 loss)
I0521 20:31:48.171411 12468 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0521 20:32:00.321593 12468 solver.cpp:237] Iteration 69750, loss = 1.06541
I0521 20:32:00.321753 12468 solver.cpp:253]     Train net output #0: loss = 1.06541 (* 1 = 1.06541 loss)
I0521 20:32:00.321768 12468 sgd_solver.cpp:106] Iteration 69750, lr = 0.0005
I0521 20:32:34.646211 12468 solver.cpp:237] Iteration 70500, loss = 0.953601
I0521 20:32:34.646383 12468 solver.cpp:253]     Train net output #0: loss = 0.953601 (* 1 = 0.953601 loss)
I0521 20:32:34.646396 12468 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0521 20:32:46.808189 12468 solver.cpp:237] Iteration 71250, loss = 1.08329
I0521 20:32:46.808225 12468 solver.cpp:253]     Train net output #0: loss = 1.08329 (* 1 = 1.08329 loss)
I0521 20:32:46.808241 12468 sgd_solver.cpp:106] Iteration 71250, lr = 0.0005
I0521 20:32:58.997005 12468 solver.cpp:237] Iteration 72000, loss = 1.56901
I0521 20:32:58.997053 12468 solver.cpp:253]     Train net output #0: loss = 1.56901 (* 1 = 1.56901 loss)
I0521 20:32:58.997069 12468 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0521 20:33:11.178241 12468 solver.cpp:237] Iteration 72750, loss = 1.7204
I0521 20:33:11.178386 12468 solver.cpp:253]     Train net output #0: loss = 1.7204 (* 1 = 1.7204 loss)
I0521 20:33:11.178401 12468 sgd_solver.cpp:106] Iteration 72750, lr = 0.0005
I0521 20:33:23.308842 12468 solver.cpp:237] Iteration 73500, loss = 1.11267
I0521 20:33:23.308888 12468 solver.cpp:253]     Train net output #0: loss = 1.11267 (* 1 = 1.11267 loss)
I0521 20:33:23.308903 12468 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I0521 20:33:35.393600 12468 solver.cpp:237] Iteration 74250, loss = 1.58999
I0521 20:33:35.393636 12468 solver.cpp:253]     Train net output #0: loss = 1.58999 (* 1 = 1.58999 loss)
I0521 20:33:35.393653 12468 sgd_solver.cpp:106] Iteration 74250, lr = 0.0005
I0521 20:33:47.474222 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_75000.caffemodel
I0521 20:33:47.525538 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_75000.solverstate
I0521 20:33:47.553932 12468 solver.cpp:341] Iteration 75000, Testing net (#0)
I0521 20:34:39.588703 12468 solver.cpp:409]     Test net output #0: accuracy = 0.850407
I0521 20:34:39.588865 12468 solver.cpp:409]     Test net output #1: loss = 0.4809 (* 1 = 0.4809 loss)
I0521 20:35:00.467754 12468 solver.cpp:237] Iteration 75000, loss = 1.26313
I0521 20:35:00.467805 12468 solver.cpp:253]     Train net output #0: loss = 1.26313 (* 1 = 1.26313 loss)
I0521 20:35:00.467828 12468 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I0521 20:35:12.621939 12468 solver.cpp:237] Iteration 75750, loss = 1.36548
I0521 20:35:12.622092 12468 solver.cpp:253]     Train net output #0: loss = 1.36548 (* 1 = 1.36548 loss)
I0521 20:35:12.622107 12468 sgd_solver.cpp:106] Iteration 75750, lr = 0.0005
I0521 20:35:24.748040 12468 solver.cpp:237] Iteration 76500, loss = 1.69328
I0521 20:35:24.748076 12468 solver.cpp:253]     Train net output #0: loss = 1.69327 (* 1 = 1.69327 loss)
I0521 20:35:24.748090 12468 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I0521 20:35:36.854840 12468 solver.cpp:237] Iteration 77250, loss = 0.956245
I0521 20:35:36.854881 12468 solver.cpp:253]     Train net output #0: loss = 0.956245 (* 1 = 0.956245 loss)
I0521 20:35:36.854893 12468 sgd_solver.cpp:106] Iteration 77250, lr = 0.0005
I0521 20:35:48.955770 12468 solver.cpp:237] Iteration 78000, loss = 1.186
I0521 20:35:48.955914 12468 solver.cpp:253]     Train net output #0: loss = 1.186 (* 1 = 1.186 loss)
I0521 20:35:48.955927 12468 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I0521 20:36:01.066766 12468 solver.cpp:237] Iteration 78750, loss = 1.77188
I0521 20:36:01.066812 12468 solver.cpp:253]     Train net output #0: loss = 1.77188 (* 1 = 1.77188 loss)
I0521 20:36:01.066828 12468 sgd_solver.cpp:106] Iteration 78750, lr = 0.0005
I0521 20:36:13.226050 12468 solver.cpp:237] Iteration 79500, loss = 0.982835
I0521 20:36:13.226088 12468 solver.cpp:253]     Train net output #0: loss = 0.982835 (* 1 = 0.982835 loss)
I0521 20:36:13.226104 12468 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I0521 20:36:46.260737 12468 solver.cpp:237] Iteration 80250, loss = 1.30512
I0521 20:36:46.260911 12468 solver.cpp:253]     Train net output #0: loss = 1.30512 (* 1 = 1.30512 loss)
I0521 20:36:46.260927 12468 sgd_solver.cpp:106] Iteration 80250, lr = 0.0005
I0521 20:36:58.422076 12468 solver.cpp:237] Iteration 81000, loss = 1.61241
I0521 20:36:58.422113 12468 solver.cpp:253]     Train net output #0: loss = 1.61241 (* 1 = 1.61241 loss)
I0521 20:36:58.422127 12468 sgd_solver.cpp:106] Iteration 81000, lr = 0.0005
I0521 20:37:10.576021 12468 solver.cpp:237] Iteration 81750, loss = 1.8343
I0521 20:37:10.576067 12468 solver.cpp:253]     Train net output #0: loss = 1.8343 (* 1 = 1.8343 loss)
I0521 20:37:10.576082 12468 sgd_solver.cpp:106] Iteration 81750, lr = 0.0005
I0521 20:37:22.694185 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_82500.caffemodel
I0521 20:37:22.745110 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_82500.solverstate
I0521 20:37:22.776558 12468 solver.cpp:237] Iteration 82500, loss = 1.17696
I0521 20:37:22.776602 12468 solver.cpp:253]     Train net output #0: loss = 1.17696 (* 1 = 1.17696 loss)
I0521 20:37:22.776623 12468 sgd_solver.cpp:106] Iteration 82500, lr = 0.0005
I0521 20:37:34.909425 12468 solver.cpp:237] Iteration 83250, loss = 1.66817
I0521 20:37:34.909476 12468 solver.cpp:253]     Train net output #0: loss = 1.66817 (* 1 = 1.66817 loss)
I0521 20:37:34.909489 12468 sgd_solver.cpp:106] Iteration 83250, lr = 0.0005
I0521 20:37:47.049384 12468 solver.cpp:237] Iteration 84000, loss = 1.19596
I0521 20:37:47.049420 12468 solver.cpp:253]     Train net output #0: loss = 1.19596 (* 1 = 1.19596 loss)
I0521 20:37:47.049437 12468 sgd_solver.cpp:106] Iteration 84000, lr = 0.0005
I0521 20:37:59.185729 12468 solver.cpp:237] Iteration 84750, loss = 1.44551
I0521 20:37:59.185892 12468 solver.cpp:253]     Train net output #0: loss = 1.44551 (* 1 = 1.44551 loss)
I0521 20:37:59.185907 12468 sgd_solver.cpp:106] Iteration 84750, lr = 0.0005
I0521 20:38:32.178961 12468 solver.cpp:237] Iteration 85500, loss = 0.881559
I0521 20:38:32.179128 12468 solver.cpp:253]     Train net output #0: loss = 0.881558 (* 1 = 0.881558 loss)
I0521 20:38:32.179143 12468 sgd_solver.cpp:106] Iteration 85500, lr = 0.0005
I0521 20:38:44.290972 12468 solver.cpp:237] Iteration 86250, loss = 1.02218
I0521 20:38:44.291008 12468 solver.cpp:253]     Train net output #0: loss = 1.02218 (* 1 = 1.02218 loss)
I0521 20:38:44.291023 12468 sgd_solver.cpp:106] Iteration 86250, lr = 0.0005
I0521 20:38:56.451916 12468 solver.cpp:237] Iteration 87000, loss = 1.43979
I0521 20:38:56.451964 12468 solver.cpp:253]     Train net output #0: loss = 1.43979 (* 1 = 1.43979 loss)
I0521 20:38:56.451980 12468 sgd_solver.cpp:106] Iteration 87000, lr = 0.0005
I0521 20:39:08.586915 12468 solver.cpp:237] Iteration 87750, loss = 1.53374
I0521 20:39:08.587059 12468 solver.cpp:253]     Train net output #0: loss = 1.53374 (* 1 = 1.53374 loss)
I0521 20:39:08.587074 12468 sgd_solver.cpp:106] Iteration 87750, lr = 0.0005
I0521 20:39:20.697649 12468 solver.cpp:237] Iteration 88500, loss = 1.71217
I0521 20:39:20.697696 12468 solver.cpp:253]     Train net output #0: loss = 1.71217 (* 1 = 1.71217 loss)
I0521 20:39:20.697711 12468 sgd_solver.cpp:106] Iteration 88500, lr = 0.0005
I0521 20:39:32.820466 12468 solver.cpp:237] Iteration 89250, loss = 1.3565
I0521 20:39:32.820502 12468 solver.cpp:253]     Train net output #0: loss = 1.3565 (* 1 = 1.3565 loss)
I0521 20:39:32.820518 12468 sgd_solver.cpp:106] Iteration 89250, lr = 0.0005
I0521 20:39:44.918642 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_90000.caffemodel
I0521 20:39:44.967967 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_90000.solverstate
I0521 20:39:44.994307 12468 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 20:40:57.863026 12468 solver.cpp:409]     Test net output #0: accuracy = 0.857107
I0521 20:40:57.863196 12468 solver.cpp:409]     Test net output #1: loss = 0.467673 (* 1 = 0.467673 loss)
I0521 20:41:18.737773 12468 solver.cpp:237] Iteration 90000, loss = 1.13724
I0521 20:41:18.737826 12468 solver.cpp:253]     Train net output #0: loss = 1.13724 (* 1 = 1.13724 loss)
I0521 20:41:18.737841 12468 sgd_solver.cpp:106] Iteration 90000, lr = 0.0005
I0521 20:41:30.818048 12468 solver.cpp:237] Iteration 90750, loss = 1.09952
I0521 20:41:30.818212 12468 solver.cpp:253]     Train net output #0: loss = 1.09952 (* 1 = 1.09952 loss)
I0521 20:41:30.818228 12468 sgd_solver.cpp:106] Iteration 90750, lr = 0.0005
I0521 20:41:42.893743 12468 solver.cpp:237] Iteration 91500, loss = 1.63342
I0521 20:41:42.893787 12468 solver.cpp:253]     Train net output #0: loss = 1.63342 (* 1 = 1.63342 loss)
I0521 20:41:42.893802 12468 sgd_solver.cpp:106] Iteration 91500, lr = 0.0005
I0521 20:41:55.018635 12468 solver.cpp:237] Iteration 92250, loss = 1.21215
I0521 20:41:55.018672 12468 solver.cpp:253]     Train net output #0: loss = 1.21215 (* 1 = 1.21215 loss)
I0521 20:41:55.018688 12468 sgd_solver.cpp:106] Iteration 92250, lr = 0.0005
I0521 20:42:07.157199 12468 solver.cpp:237] Iteration 93000, loss = 1.28769
I0521 20:42:07.157357 12468 solver.cpp:253]     Train net output #0: loss = 1.28768 (* 1 = 1.28768 loss)
I0521 20:42:07.157371 12468 sgd_solver.cpp:106] Iteration 93000, lr = 0.0005
I0521 20:42:19.286628 12468 solver.cpp:237] Iteration 93750, loss = 1.20532
I0521 20:42:19.286664 12468 solver.cpp:253]     Train net output #0: loss = 1.20532 (* 1 = 1.20532 loss)
I0521 20:42:19.286680 12468 sgd_solver.cpp:106] Iteration 93750, lr = 0.0005
I0521 20:42:31.417763 12468 solver.cpp:237] Iteration 94500, loss = 0.926751
I0521 20:42:31.417809 12468 solver.cpp:253]     Train net output #0: loss = 0.926749 (* 1 = 0.926749 loss)
I0521 20:42:31.417824 12468 sgd_solver.cpp:106] Iteration 94500, lr = 0.0005
I0521 20:43:04.385033 12468 solver.cpp:237] Iteration 95250, loss = 1.1465
I0521 20:43:04.385203 12468 solver.cpp:253]     Train net output #0: loss = 1.1465 (* 1 = 1.1465 loss)
I0521 20:43:04.385218 12468 sgd_solver.cpp:106] Iteration 95250, lr = 0.0005
I0521 20:43:16.470479 12468 solver.cpp:237] Iteration 96000, loss = 1.01086
I0521 20:43:16.470515 12468 solver.cpp:253]     Train net output #0: loss = 1.01086 (* 1 = 1.01086 loss)
I0521 20:43:16.470532 12468 sgd_solver.cpp:106] Iteration 96000, lr = 0.0005
I0521 20:43:28.543891 12468 solver.cpp:237] Iteration 96750, loss = 1.37965
I0521 20:43:28.543936 12468 solver.cpp:253]     Train net output #0: loss = 1.37965 (* 1 = 1.37965 loss)
I0521 20:43:28.543951 12468 sgd_solver.cpp:106] Iteration 96750, lr = 0.0005
I0521 20:43:40.640355 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_97500.caffemodel
I0521 20:43:40.690013 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_97500.solverstate
I0521 20:43:40.721098 12468 solver.cpp:237] Iteration 97500, loss = 1.52919
I0521 20:43:40.721143 12468 solver.cpp:253]     Train net output #0: loss = 1.52918 (* 1 = 1.52918 loss)
I0521 20:43:40.721160 12468 sgd_solver.cpp:106] Iteration 97500, lr = 0.0005
I0521 20:43:52.852756 12468 solver.cpp:237] Iteration 98250, loss = 1.1243
I0521 20:43:52.852800 12468 solver.cpp:253]     Train net output #0: loss = 1.1243 (* 1 = 1.1243 loss)
I0521 20:43:52.852815 12468 sgd_solver.cpp:106] Iteration 98250, lr = 0.0005
I0521 20:44:04.953194 12468 solver.cpp:237] Iteration 99000, loss = 0.884015
I0521 20:44:04.953232 12468 solver.cpp:253]     Train net output #0: loss = 0.884014 (* 1 = 0.884014 loss)
I0521 20:44:04.953248 12468 sgd_solver.cpp:106] Iteration 99000, lr = 0.0005
I0521 20:44:17.084035 12468 solver.cpp:237] Iteration 99750, loss = 0.806713
I0521 20:44:17.084214 12468 solver.cpp:253]     Train net output #0: loss = 0.806712 (* 1 = 0.806712 loss)
I0521 20:44:17.084231 12468 sgd_solver.cpp:106] Iteration 99750, lr = 0.0005
I0521 20:44:50.138592 12468 solver.cpp:237] Iteration 100500, loss = 1.4789
I0521 20:44:50.138766 12468 solver.cpp:253]     Train net output #0: loss = 1.4789 (* 1 = 1.4789 loss)
I0521 20:44:50.138782 12468 sgd_solver.cpp:106] Iteration 100500, lr = 0.0005
I0521 20:45:02.350574 12468 solver.cpp:237] Iteration 101250, loss = 1.47201
I0521 20:45:02.350620 12468 solver.cpp:253]     Train net output #0: loss = 1.47201 (* 1 = 1.47201 loss)
I0521 20:45:02.350636 12468 sgd_solver.cpp:106] Iteration 101250, lr = 0.0005
I0521 20:45:14.523699 12468 solver.cpp:237] Iteration 102000, loss = 1.1537
I0521 20:45:14.523736 12468 solver.cpp:253]     Train net output #0: loss = 1.15369 (* 1 = 1.15369 loss)
I0521 20:45:14.523751 12468 sgd_solver.cpp:106] Iteration 102000, lr = 0.0005
I0521 20:45:26.754815 12468 solver.cpp:237] Iteration 102750, loss = 1.21671
I0521 20:45:26.754976 12468 solver.cpp:253]     Train net output #0: loss = 1.21671 (* 1 = 1.21671 loss)
I0521 20:45:26.754992 12468 sgd_solver.cpp:106] Iteration 102750, lr = 0.0005
I0521 20:45:38.932529 12468 solver.cpp:237] Iteration 103500, loss = 0.945869
I0521 20:45:38.932566 12468 solver.cpp:253]     Train net output #0: loss = 0.945867 (* 1 = 0.945867 loss)
I0521 20:45:38.932582 12468 sgd_solver.cpp:106] Iteration 103500, lr = 0.0005
I0521 20:45:51.145491 12468 solver.cpp:237] Iteration 104250, loss = 0.979471
I0521 20:45:51.145539 12468 solver.cpp:253]     Train net output #0: loss = 0.979469 (* 1 = 0.979469 loss)
I0521 20:45:51.145555 12468 sgd_solver.cpp:106] Iteration 104250, lr = 0.0005
I0521 20:46:03.307960 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_105000.caffemodel
I0521 20:46:03.357118 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_105000.solverstate
I0521 20:46:03.382468 12468 solver.cpp:341] Iteration 105000, Testing net (#0)
I0521 20:46:55.134064 12468 solver.cpp:409]     Test net output #0: accuracy = 0.861334
I0521 20:46:55.134243 12468 solver.cpp:409]     Test net output #1: loss = 0.457713 (* 1 = 0.457713 loss)
I0521 20:47:16.030905 12468 solver.cpp:237] Iteration 105000, loss = 0.730441
I0521 20:47:16.030959 12468 solver.cpp:253]     Train net output #0: loss = 0.73044 (* 1 = 0.73044 loss)
I0521 20:47:16.030974 12468 sgd_solver.cpp:106] Iteration 105000, lr = 0.0005
I0521 20:47:28.207787 12468 solver.cpp:237] Iteration 105750, loss = 0.776367
I0521 20:47:28.207944 12468 solver.cpp:253]     Train net output #0: loss = 0.776366 (* 1 = 0.776366 loss)
I0521 20:47:28.207959 12468 sgd_solver.cpp:106] Iteration 105750, lr = 0.0005
I0521 20:47:40.356521 12468 solver.cpp:237] Iteration 106500, loss = 1.05436
I0521 20:47:40.356567 12468 solver.cpp:253]     Train net output #0: loss = 1.05436 (* 1 = 1.05436 loss)
I0521 20:47:40.356582 12468 sgd_solver.cpp:106] Iteration 106500, lr = 0.0005
I0521 20:47:52.514976 12468 solver.cpp:237] Iteration 107250, loss = 1.45177
I0521 20:47:52.515012 12468 solver.cpp:253]     Train net output #0: loss = 1.45177 (* 1 = 1.45177 loss)
I0521 20:47:52.515029 12468 sgd_solver.cpp:106] Iteration 107250, lr = 0.0005
I0521 20:48:04.670235 12468 solver.cpp:237] Iteration 108000, loss = 1.39616
I0521 20:48:04.670406 12468 solver.cpp:253]     Train net output #0: loss = 1.39616 (* 1 = 1.39616 loss)
I0521 20:48:04.670421 12468 sgd_solver.cpp:106] Iteration 108000, lr = 0.0005
I0521 20:48:16.866791 12468 solver.cpp:237] Iteration 108750, loss = 1.24809
I0521 20:48:16.866827 12468 solver.cpp:253]     Train net output #0: loss = 1.24808 (* 1 = 1.24808 loss)
I0521 20:48:16.866843 12468 sgd_solver.cpp:106] Iteration 108750, lr = 0.0005
I0521 20:48:28.990224 12468 solver.cpp:237] Iteration 109500, loss = 0.792256
I0521 20:48:28.990270 12468 solver.cpp:253]     Train net output #0: loss = 0.792254 (* 1 = 0.792254 loss)
I0521 20:48:28.990285 12468 sgd_solver.cpp:106] Iteration 109500, lr = 0.0005
I0521 20:49:01.989171 12468 solver.cpp:237] Iteration 110250, loss = 1.56652
I0521 20:49:01.989356 12468 solver.cpp:253]     Train net output #0: loss = 1.56652 (* 1 = 1.56652 loss)
I0521 20:49:01.989370 12468 sgd_solver.cpp:106] Iteration 110250, lr = 0.0005
I0521 20:49:14.115738 12468 solver.cpp:237] Iteration 111000, loss = 1.14087
I0521 20:49:14.115782 12468 solver.cpp:253]     Train net output #0: loss = 1.14087 (* 1 = 1.14087 loss)
I0521 20:49:14.115797 12468 sgd_solver.cpp:106] Iteration 111000, lr = 0.0005
I0521 20:49:26.267263 12468 solver.cpp:237] Iteration 111750, loss = 1.34317
I0521 20:49:26.267299 12468 solver.cpp:253]     Train net output #0: loss = 1.34317 (* 1 = 1.34317 loss)
I0521 20:49:26.267315 12468 sgd_solver.cpp:106] Iteration 111750, lr = 0.0005
I0521 20:49:38.370110 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_112500.caffemodel
I0521 20:49:38.426012 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_112500.solverstate
I0521 20:49:38.458498 12468 solver.cpp:237] Iteration 112500, loss = 1.5891
I0521 20:49:38.458549 12468 solver.cpp:253]     Train net output #0: loss = 1.5891 (* 1 = 1.5891 loss)
I0521 20:49:38.458565 12468 sgd_solver.cpp:106] Iteration 112500, lr = 0.0005
I0521 20:49:50.573035 12468 solver.cpp:237] Iteration 113250, loss = 1.26074
I0521 20:49:50.573072 12468 solver.cpp:253]     Train net output #0: loss = 1.26074 (* 1 = 1.26074 loss)
I0521 20:49:50.573088 12468 sgd_solver.cpp:106] Iteration 113250, lr = 0.0005
I0521 20:50:02.723253 12468 solver.cpp:237] Iteration 114000, loss = 1.48254
I0521 20:50:02.723299 12468 solver.cpp:253]     Train net output #0: loss = 1.48254 (* 1 = 1.48254 loss)
I0521 20:50:02.723315 12468 sgd_solver.cpp:106] Iteration 114000, lr = 0.0005
I0521 20:50:14.907464 12468 solver.cpp:237] Iteration 114750, loss = 0.931543
I0521 20:50:14.907623 12468 solver.cpp:253]     Train net output #0: loss = 0.931541 (* 1 = 0.931541 loss)
I0521 20:50:14.907636 12468 sgd_solver.cpp:106] Iteration 114750, lr = 0.0005
I0521 20:50:47.922276 12468 solver.cpp:237] Iteration 115500, loss = 1.23659
I0521 20:50:47.922451 12468 solver.cpp:253]     Train net output #0: loss = 1.23658 (* 1 = 1.23658 loss)
I0521 20:50:47.922466 12468 sgd_solver.cpp:106] Iteration 115500, lr = 0.0005
I0521 20:51:00.045217 12468 solver.cpp:237] Iteration 116250, loss = 0.826864
I0521 20:51:00.045269 12468 solver.cpp:253]     Train net output #0: loss = 0.826862 (* 1 = 0.826862 loss)
I0521 20:51:00.045282 12468 sgd_solver.cpp:106] Iteration 116250, lr = 0.0005
I0521 20:51:12.160646 12468 solver.cpp:237] Iteration 117000, loss = 1.4413
I0521 20:51:12.160682 12468 solver.cpp:253]     Train net output #0: loss = 1.44129 (* 1 = 1.44129 loss)
I0521 20:51:12.160699 12468 sgd_solver.cpp:106] Iteration 117000, lr = 0.0005
I0521 20:51:24.292475 12468 solver.cpp:237] Iteration 117750, loss = 0.990083
I0521 20:51:24.292632 12468 solver.cpp:253]     Train net output #0: loss = 0.990081 (* 1 = 0.990081 loss)
I0521 20:51:24.292646 12468 sgd_solver.cpp:106] Iteration 117750, lr = 0.0005
I0521 20:51:36.428534 12468 solver.cpp:237] Iteration 118500, loss = 1.62389
I0521 20:51:36.428570 12468 solver.cpp:253]     Train net output #0: loss = 1.62389 (* 1 = 1.62389 loss)
I0521 20:51:36.428586 12468 sgd_solver.cpp:106] Iteration 118500, lr = 0.0005
I0521 20:51:48.562129 12468 solver.cpp:237] Iteration 119250, loss = 1.21166
I0521 20:51:48.562171 12468 solver.cpp:253]     Train net output #0: loss = 1.21166 (* 1 = 1.21166 loss)
I0521 20:51:48.562189 12468 sgd_solver.cpp:106] Iteration 119250, lr = 0.0005
I0521 20:52:00.691366 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_120000.caffemodel
I0521 20:52:00.740414 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_120000.solverstate
I0521 20:52:00.765823 12468 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 20:53:13.583374 12468 solver.cpp:409]     Test net output #0: accuracy = 0.868755
I0521 20:53:13.583547 12468 solver.cpp:409]     Test net output #1: loss = 0.458955 (* 1 = 0.458955 loss)
I0521 20:53:34.449708 12468 solver.cpp:237] Iteration 120000, loss = 1.01498
I0521 20:53:34.449761 12468 solver.cpp:253]     Train net output #0: loss = 1.01497 (* 1 = 1.01497 loss)
I0521 20:53:34.449777 12468 sgd_solver.cpp:106] Iteration 120000, lr = 0.0005
I0521 20:53:46.584280 12468 solver.cpp:237] Iteration 120750, loss = 0.752542
I0521 20:53:46.584450 12468 solver.cpp:253]     Train net output #0: loss = 0.752541 (* 1 = 0.752541 loss)
I0521 20:53:46.584465 12468 sgd_solver.cpp:106] Iteration 120750, lr = 0.0005
I0521 20:53:58.685046 12468 solver.cpp:237] Iteration 121500, loss = 1.07218
I0521 20:53:58.685082 12468 solver.cpp:253]     Train net output #0: loss = 1.07218 (* 1 = 1.07218 loss)
I0521 20:53:58.685098 12468 sgd_solver.cpp:106] Iteration 121500, lr = 0.0005
I0521 20:54:10.730129 12468 solver.cpp:237] Iteration 122250, loss = 1.64565
I0521 20:54:10.730173 12468 solver.cpp:253]     Train net output #0: loss = 1.64565 (* 1 = 1.64565 loss)
I0521 20:54:10.730191 12468 sgd_solver.cpp:106] Iteration 122250, lr = 0.0005
I0521 20:54:22.778394 12468 solver.cpp:237] Iteration 123000, loss = 1.17825
I0521 20:54:22.778545 12468 solver.cpp:253]     Train net output #0: loss = 1.17825 (* 1 = 1.17825 loss)
I0521 20:54:22.778560 12468 sgd_solver.cpp:106] Iteration 123000, lr = 0.0005
I0521 20:54:34.821547 12468 solver.cpp:237] Iteration 123750, loss = 1.84033
I0521 20:54:34.821583 12468 solver.cpp:253]     Train net output #0: loss = 1.84032 (* 1 = 1.84032 loss)
I0521 20:54:34.821599 12468 sgd_solver.cpp:106] Iteration 123750, lr = 0.0005
I0521 20:54:46.960434 12468 solver.cpp:237] Iteration 124500, loss = 1.21163
I0521 20:54:46.960480 12468 solver.cpp:253]     Train net output #0: loss = 1.21162 (* 1 = 1.21162 loss)
I0521 20:54:46.960495 12468 sgd_solver.cpp:106] Iteration 124500, lr = 0.0005
I0521 20:55:19.953572 12468 solver.cpp:237] Iteration 125250, loss = 1.38047
I0521 20:55:19.953747 12468 solver.cpp:253]     Train net output #0: loss = 1.38047 (* 1 = 1.38047 loss)
I0521 20:55:19.953763 12468 sgd_solver.cpp:106] Iteration 125250, lr = 0.0005
I0521 20:55:32.072631 12468 solver.cpp:237] Iteration 126000, loss = 1.17087
I0521 20:55:32.072677 12468 solver.cpp:253]     Train net output #0: loss = 1.17086 (* 1 = 1.17086 loss)
I0521 20:55:32.072692 12468 sgd_solver.cpp:106] Iteration 126000, lr = 0.0005
I0521 20:55:44.185374 12468 solver.cpp:237] Iteration 126750, loss = 1.15864
I0521 20:55:44.185410 12468 solver.cpp:253]     Train net output #0: loss = 1.15864 (* 1 = 1.15864 loss)
I0521 20:55:44.185425 12468 sgd_solver.cpp:106] Iteration 126750, lr = 0.0005
I0521 20:55:56.292156 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_127500.caffemodel
I0521 20:55:56.341289 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_127500.solverstate
I0521 20:55:56.370986 12468 solver.cpp:237] Iteration 127500, loss = 1.22349
I0521 20:55:56.371026 12468 solver.cpp:253]     Train net output #0: loss = 1.22349 (* 1 = 1.22349 loss)
I0521 20:55:56.371047 12468 sgd_solver.cpp:106] Iteration 127500, lr = 0.0005
I0521 20:56:08.474205 12468 solver.cpp:237] Iteration 128250, loss = 1.44026
I0521 20:56:08.474241 12468 solver.cpp:253]     Train net output #0: loss = 1.44025 (* 1 = 1.44025 loss)
I0521 20:56:08.474256 12468 sgd_solver.cpp:106] Iteration 128250, lr = 0.0005
I0521 20:56:20.615258 12468 solver.cpp:237] Iteration 129000, loss = 1.14172
I0521 20:56:20.615305 12468 solver.cpp:253]     Train net output #0: loss = 1.14172 (* 1 = 1.14172 loss)
I0521 20:56:20.615320 12468 sgd_solver.cpp:106] Iteration 129000, lr = 0.0005
I0521 20:56:32.757786 12468 solver.cpp:237] Iteration 129750, loss = 1.11396
I0521 20:56:32.757946 12468 solver.cpp:253]     Train net output #0: loss = 1.11396 (* 1 = 1.11396 loss)
I0521 20:56:32.757959 12468 sgd_solver.cpp:106] Iteration 129750, lr = 0.0005
I0521 20:57:05.779726 12468 solver.cpp:237] Iteration 130500, loss = 1.11873
I0521 20:57:05.779896 12468 solver.cpp:253]     Train net output #0: loss = 1.11873 (* 1 = 1.11873 loss)
I0521 20:57:05.779911 12468 sgd_solver.cpp:106] Iteration 130500, lr = 0.0005
I0521 20:57:17.953845 12468 solver.cpp:237] Iteration 131250, loss = 1.59684
I0521 20:57:17.953881 12468 solver.cpp:253]     Train net output #0: loss = 1.59684 (* 1 = 1.59684 loss)
I0521 20:57:17.953899 12468 sgd_solver.cpp:106] Iteration 131250, lr = 0.0005
I0521 20:57:30.127300 12468 solver.cpp:237] Iteration 132000, loss = 1.46489
I0521 20:57:30.127336 12468 solver.cpp:253]     Train net output #0: loss = 1.46489 (* 1 = 1.46489 loss)
I0521 20:57:30.127351 12468 sgd_solver.cpp:106] Iteration 132000, lr = 0.0005
I0521 20:57:42.277371 12468 solver.cpp:237] Iteration 132750, loss = 1.00871
I0521 20:57:42.277532 12468 solver.cpp:253]     Train net output #0: loss = 1.0087 (* 1 = 1.0087 loss)
I0521 20:57:42.277546 12468 sgd_solver.cpp:106] Iteration 132750, lr = 0.0005
I0521 20:57:54.425578 12468 solver.cpp:237] Iteration 133500, loss = 1.2832
I0521 20:57:54.425616 12468 solver.cpp:253]     Train net output #0: loss = 1.2832 (* 1 = 1.2832 loss)
I0521 20:57:54.425631 12468 sgd_solver.cpp:106] Iteration 133500, lr = 0.0005
I0521 20:58:06.575171 12468 solver.cpp:237] Iteration 134250, loss = 1.37238
I0521 20:58:06.575223 12468 solver.cpp:253]     Train net output #0: loss = 1.37237 (* 1 = 1.37237 loss)
I0521 20:58:06.575237 12468 sgd_solver.cpp:106] Iteration 134250, lr = 0.0005
I0521 20:58:18.713804 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_135000.caffemodel
I0521 20:58:18.763129 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_135000.solverstate
I0521 20:58:18.788408 12468 solver.cpp:341] Iteration 135000, Testing net (#0)
I0521 20:59:10.757268 12468 solver.cpp:409]     Test net output #0: accuracy = 0.871768
I0521 20:59:10.757441 12468 solver.cpp:409]     Test net output #1: loss = 0.405415 (* 1 = 0.405415 loss)
I0521 20:59:31.632272 12468 solver.cpp:237] Iteration 135000, loss = 1.53969
I0521 20:59:31.632323 12468 solver.cpp:253]     Train net output #0: loss = 1.53969 (* 1 = 1.53969 loss)
I0521 20:59:31.632339 12468 sgd_solver.cpp:106] Iteration 135000, lr = 0.0005
I0521 20:59:43.749588 12468 solver.cpp:237] Iteration 135750, loss = 1.29894
I0521 20:59:43.749761 12468 solver.cpp:253]     Train net output #0: loss = 1.29894 (* 1 = 1.29894 loss)
I0521 20:59:43.749774 12468 sgd_solver.cpp:106] Iteration 135750, lr = 0.0005
I0521 20:59:55.873692 12468 solver.cpp:237] Iteration 136500, loss = 0.791742
I0521 20:59:55.873728 12468 solver.cpp:253]     Train net output #0: loss = 0.79174 (* 1 = 0.79174 loss)
I0521 20:59:55.873744 12468 sgd_solver.cpp:106] Iteration 136500, lr = 0.0005
I0521 21:00:07.994810 12468 solver.cpp:237] Iteration 137250, loss = 1.11588
I0521 21:00:07.994860 12468 solver.cpp:253]     Train net output #0: loss = 1.11587 (* 1 = 1.11587 loss)
I0521 21:00:07.994875 12468 sgd_solver.cpp:106] Iteration 137250, lr = 0.0005
I0521 21:00:20.116600 12468 solver.cpp:237] Iteration 138000, loss = 0.983215
I0521 21:00:20.116767 12468 solver.cpp:253]     Train net output #0: loss = 0.983213 (* 1 = 0.983213 loss)
I0521 21:00:20.116782 12468 sgd_solver.cpp:106] Iteration 138000, lr = 0.0005
I0521 21:00:32.293586 12468 solver.cpp:237] Iteration 138750, loss = 1.38109
I0521 21:00:32.293634 12468 solver.cpp:253]     Train net output #0: loss = 1.38108 (* 1 = 1.38108 loss)
I0521 21:00:32.293649 12468 sgd_solver.cpp:106] Iteration 138750, lr = 0.0005
I0521 21:00:44.464663 12468 solver.cpp:237] Iteration 139500, loss = 1.15856
I0521 21:00:44.464699 12468 solver.cpp:253]     Train net output #0: loss = 1.15856 (* 1 = 1.15856 loss)
I0521 21:00:44.464716 12468 sgd_solver.cpp:106] Iteration 139500, lr = 0.0005
I0521 21:01:17.493103 12468 solver.cpp:237] Iteration 140250, loss = 1.48406
I0521 21:01:17.493276 12468 solver.cpp:253]     Train net output #0: loss = 1.48406 (* 1 = 1.48406 loss)
I0521 21:01:17.493290 12468 sgd_solver.cpp:106] Iteration 140250, lr = 0.0005
I0521 21:01:29.621426 12468 solver.cpp:237] Iteration 141000, loss = 1.20774
I0521 21:01:29.621464 12468 solver.cpp:253]     Train net output #0: loss = 1.20774 (* 1 = 1.20774 loss)
I0521 21:01:29.621479 12468 sgd_solver.cpp:106] Iteration 141000, lr = 0.0005
I0521 21:01:41.792558 12468 solver.cpp:237] Iteration 141750, loss = 1.23127
I0521 21:01:41.792608 12468 solver.cpp:253]     Train net output #0: loss = 1.23127 (* 1 = 1.23127 loss)
I0521 21:01:41.792623 12468 sgd_solver.cpp:106] Iteration 141750, lr = 0.0005
I0521 21:01:53.941079 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_142500.caffemodel
I0521 21:01:53.992854 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_142500.solverstate
I0521 21:01:54.025535 12468 solver.cpp:237] Iteration 142500, loss = 1.55718
I0521 21:01:54.025585 12468 solver.cpp:253]     Train net output #0: loss = 1.55717 (* 1 = 1.55717 loss)
I0521 21:01:54.025600 12468 sgd_solver.cpp:106] Iteration 142500, lr = 0.0005
I0521 21:02:06.193053 12468 solver.cpp:237] Iteration 143250, loss = 1.02627
I0521 21:02:06.193094 12468 solver.cpp:253]     Train net output #0: loss = 1.02627 (* 1 = 1.02627 loss)
I0521 21:02:06.193117 12468 sgd_solver.cpp:106] Iteration 143250, lr = 0.0005
I0521 21:02:18.357460 12468 solver.cpp:237] Iteration 144000, loss = 1.53083
I0521 21:02:18.357496 12468 solver.cpp:253]     Train net output #0: loss = 1.53083 (* 1 = 1.53083 loss)
I0521 21:02:18.357513 12468 sgd_solver.cpp:106] Iteration 144000, lr = 0.0005
I0521 21:02:30.525493 12468 solver.cpp:237] Iteration 144750, loss = 0.926107
I0521 21:02:30.525665 12468 solver.cpp:253]     Train net output #0: loss = 0.926104 (* 1 = 0.926104 loss)
I0521 21:02:30.525681 12468 sgd_solver.cpp:106] Iteration 144750, lr = 0.0005
I0521 21:03:03.579373 12468 solver.cpp:237] Iteration 145500, loss = 1.09734
I0521 21:03:03.579548 12468 solver.cpp:253]     Train net output #0: loss = 1.09734 (* 1 = 1.09734 loss)
I0521 21:03:03.579565 12468 sgd_solver.cpp:106] Iteration 145500, lr = 0.0005
I0521 21:03:15.729998 12468 solver.cpp:237] Iteration 146250, loss = 1.34204
I0521 21:03:15.730034 12468 solver.cpp:253]     Train net output #0: loss = 1.34204 (* 1 = 1.34204 loss)
I0521 21:03:15.730052 12468 sgd_solver.cpp:106] Iteration 146250, lr = 0.0005
I0521 21:03:27.899255 12468 solver.cpp:237] Iteration 147000, loss = 1.40625
I0521 21:03:27.899301 12468 solver.cpp:253]     Train net output #0: loss = 1.40625 (* 1 = 1.40625 loss)
I0521 21:03:27.899317 12468 sgd_solver.cpp:106] Iteration 147000, lr = 0.0005
I0521 21:03:40.095487 12468 solver.cpp:237] Iteration 147750, loss = 1.44293
I0521 21:03:40.095652 12468 solver.cpp:253]     Train net output #0: loss = 1.44293 (* 1 = 1.44293 loss)
I0521 21:03:40.095669 12468 sgd_solver.cpp:106] Iteration 147750, lr = 0.0005
I0521 21:03:52.281976 12468 solver.cpp:237] Iteration 148500, loss = 1.45057
I0521 21:03:52.282022 12468 solver.cpp:253]     Train net output #0: loss = 1.45057 (* 1 = 1.45057 loss)
I0521 21:03:52.282038 12468 sgd_solver.cpp:106] Iteration 148500, lr = 0.0005
I0521 21:04:04.437877 12468 solver.cpp:237] Iteration 149250, loss = 1.39063
I0521 21:04:04.437914 12468 solver.cpp:253]     Train net output #0: loss = 1.39062 (* 1 = 1.39062 loss)
I0521 21:04:04.437930 12468 sgd_solver.cpp:106] Iteration 149250, lr = 0.0005
I0521 21:04:16.561471 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_150000.caffemodel
I0521 21:04:16.612776 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_150000.solverstate
I0521 21:04:16.640516 12468 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 21:05:29.432512 12468 solver.cpp:409]     Test net output #0: accuracy = 0.873102
I0521 21:05:29.432682 12468 solver.cpp:409]     Test net output #1: loss = 0.402054 (* 1 = 0.402054 loss)
I0521 21:05:50.306937 12468 solver.cpp:237] Iteration 150000, loss = 1.13816
I0521 21:05:50.306989 12468 solver.cpp:253]     Train net output #0: loss = 1.13815 (* 1 = 1.13815 loss)
I0521 21:05:50.307008 12468 sgd_solver.cpp:106] Iteration 150000, lr = 0.0005
I0521 21:06:02.385726 12468 solver.cpp:237] Iteration 150750, loss = 1.13257
I0521 21:06:02.385887 12468 solver.cpp:253]     Train net output #0: loss = 1.13256 (* 1 = 1.13256 loss)
I0521 21:06:02.385900 12468 sgd_solver.cpp:106] Iteration 150750, lr = 0.0005
I0521 21:06:14.487231 12468 solver.cpp:237] Iteration 151500, loss = 1.58061
I0521 21:06:14.487267 12468 solver.cpp:253]     Train net output #0: loss = 1.58061 (* 1 = 1.58061 loss)
I0521 21:06:14.487283 12468 sgd_solver.cpp:106] Iteration 151500, lr = 0.0005
I0521 21:06:26.666687 12468 solver.cpp:237] Iteration 152250, loss = 1.07514
I0521 21:06:26.666733 12468 solver.cpp:253]     Train net output #0: loss = 1.07514 (* 1 = 1.07514 loss)
I0521 21:06:26.666748 12468 sgd_solver.cpp:106] Iteration 152250, lr = 0.0005
I0521 21:06:38.841805 12468 solver.cpp:237] Iteration 153000, loss = 0.927352
I0521 21:06:38.841971 12468 solver.cpp:253]     Train net output #0: loss = 0.927349 (* 1 = 0.927349 loss)
I0521 21:06:38.841986 12468 sgd_solver.cpp:106] Iteration 153000, lr = 0.0005
I0521 21:06:51.039521 12468 solver.cpp:237] Iteration 153750, loss = 1.09478
I0521 21:06:51.039568 12468 solver.cpp:253]     Train net output #0: loss = 1.09477 (* 1 = 1.09477 loss)
I0521 21:06:51.039582 12468 sgd_solver.cpp:106] Iteration 153750, lr = 0.0005
I0521 21:07:03.240298 12468 solver.cpp:237] Iteration 154500, loss = 1.66935
I0521 21:07:03.240334 12468 solver.cpp:253]     Train net output #0: loss = 1.66934 (* 1 = 1.66934 loss)
I0521 21:07:03.240347 12468 sgd_solver.cpp:106] Iteration 154500, lr = 0.0005
I0521 21:07:36.227893 12468 solver.cpp:237] Iteration 155250, loss = 1.25531
I0521 21:07:36.228068 12468 solver.cpp:253]     Train net output #0: loss = 1.25531 (* 1 = 1.25531 loss)
I0521 21:07:36.228085 12468 sgd_solver.cpp:106] Iteration 155250, lr = 0.0005
I0521 21:07:48.364725 12468 solver.cpp:237] Iteration 156000, loss = 1.35056
I0521 21:07:48.364761 12468 solver.cpp:253]     Train net output #0: loss = 1.35055 (* 1 = 1.35055 loss)
I0521 21:07:48.364778 12468 sgd_solver.cpp:106] Iteration 156000, lr = 0.0005
I0521 21:08:00.534117 12468 solver.cpp:237] Iteration 156750, loss = 2.04339
I0521 21:08:00.534163 12468 solver.cpp:253]     Train net output #0: loss = 2.04338 (* 1 = 2.04338 loss)
I0521 21:08:00.534179 12468 sgd_solver.cpp:106] Iteration 156750, lr = 0.0005
I0521 21:08:12.689718 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_157500.caffemodel
I0521 21:08:12.739289 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_157500.solverstate
I0521 21:08:12.769309 12468 solver.cpp:237] Iteration 157500, loss = 1.27344
I0521 21:08:12.769353 12468 solver.cpp:253]     Train net output #0: loss = 1.27344 (* 1 = 1.27344 loss)
I0521 21:08:12.769369 12468 sgd_solver.cpp:106] Iteration 157500, lr = 0.0005
I0521 21:08:24.913221 12468 solver.cpp:237] Iteration 158250, loss = 1.44344
I0521 21:08:24.913271 12468 solver.cpp:253]     Train net output #0: loss = 1.44344 (* 1 = 1.44344 loss)
I0521 21:08:24.913285 12468 sgd_solver.cpp:106] Iteration 158250, lr = 0.0005
I0521 21:08:36.964411 12468 solver.cpp:237] Iteration 159000, loss = 0.651971
I0521 21:08:36.964448 12468 solver.cpp:253]     Train net output #0: loss = 0.651968 (* 1 = 0.651968 loss)
I0521 21:08:36.964464 12468 sgd_solver.cpp:106] Iteration 159000, lr = 0.0005
I0521 21:08:49.029690 12468 solver.cpp:237] Iteration 159750, loss = 1.06473
I0521 21:08:49.029865 12468 solver.cpp:253]     Train net output #0: loss = 1.06472 (* 1 = 1.06472 loss)
I0521 21:08:49.029881 12468 sgd_solver.cpp:106] Iteration 159750, lr = 0.0005
I0521 21:09:22.037987 12468 solver.cpp:237] Iteration 160500, loss = 0.73446
I0521 21:09:22.038167 12468 solver.cpp:253]     Train net output #0: loss = 0.734457 (* 1 = 0.734457 loss)
I0521 21:09:22.038183 12468 sgd_solver.cpp:106] Iteration 160500, lr = 0.0005
I0521 21:09:34.149493 12468 solver.cpp:237] Iteration 161250, loss = 1.27249
I0521 21:09:34.149529 12468 solver.cpp:253]     Train net output #0: loss = 1.27249 (* 1 = 1.27249 loss)
I0521 21:09:34.149545 12468 sgd_solver.cpp:106] Iteration 161250, lr = 0.0005
I0521 21:09:46.277834 12468 solver.cpp:237] Iteration 162000, loss = 1.48068
I0521 21:09:46.277883 12468 solver.cpp:253]     Train net output #0: loss = 1.48068 (* 1 = 1.48068 loss)
I0521 21:09:46.277896 12468 sgd_solver.cpp:106] Iteration 162000, lr = 0.0005
I0521 21:09:58.433698 12468 solver.cpp:237] Iteration 162750, loss = 1.38358
I0521 21:09:58.433857 12468 solver.cpp:253]     Train net output #0: loss = 1.38358 (* 1 = 1.38358 loss)
I0521 21:09:58.433872 12468 sgd_solver.cpp:106] Iteration 162750, lr = 0.0005
I0521 21:10:10.553799 12468 solver.cpp:237] Iteration 163500, loss = 1.14421
I0521 21:10:10.553850 12468 solver.cpp:253]     Train net output #0: loss = 1.1442 (* 1 = 1.1442 loss)
I0521 21:10:10.553864 12468 sgd_solver.cpp:106] Iteration 163500, lr = 0.0005
I0521 21:10:22.661626 12468 solver.cpp:237] Iteration 164250, loss = 1.59111
I0521 21:10:22.661664 12468 solver.cpp:253]     Train net output #0: loss = 1.59111 (* 1 = 1.59111 loss)
I0521 21:10:22.661679 12468 sgd_solver.cpp:106] Iteration 164250, lr = 0.0005
I0521 21:10:34.752511 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_165000.caffemodel
I0521 21:10:34.801601 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_165000.solverstate
I0521 21:10:34.826963 12468 solver.cpp:341] Iteration 165000, Testing net (#0)
I0521 21:11:26.367856 12468 solver.cpp:409]     Test net output #0: accuracy = 0.874689
I0521 21:11:26.368029 12468 solver.cpp:409]     Test net output #1: loss = 0.392092 (* 1 = 0.392092 loss)
I0521 21:11:47.219439 12468 solver.cpp:237] Iteration 165000, loss = 1.47412
I0521 21:11:47.219491 12468 solver.cpp:253]     Train net output #0: loss = 1.47412 (* 1 = 1.47412 loss)
I0521 21:11:47.219506 12468 sgd_solver.cpp:106] Iteration 165000, lr = 0.0005
I0521 21:11:59.337246 12468 solver.cpp:237] Iteration 165750, loss = 0.847927
I0521 21:11:59.337420 12468 solver.cpp:253]     Train net output #0: loss = 0.847924 (* 1 = 0.847924 loss)
I0521 21:11:59.337435 12468 sgd_solver.cpp:106] Iteration 165750, lr = 0.0005
I0521 21:12:11.451611 12468 solver.cpp:237] Iteration 166500, loss = 1.23277
I0521 21:12:11.451658 12468 solver.cpp:253]     Train net output #0: loss = 1.23277 (* 1 = 1.23277 loss)
I0521 21:12:11.451674 12468 sgd_solver.cpp:106] Iteration 166500, lr = 0.0005
I0521 21:12:23.557394 12468 solver.cpp:237] Iteration 167250, loss = 1.28676
I0521 21:12:23.557430 12468 solver.cpp:253]     Train net output #0: loss = 1.28676 (* 1 = 1.28676 loss)
I0521 21:12:23.557446 12468 sgd_solver.cpp:106] Iteration 167250, lr = 0.0005
I0521 21:12:35.682796 12468 solver.cpp:237] Iteration 168000, loss = 0.922267
I0521 21:12:35.682968 12468 solver.cpp:253]     Train net output #0: loss = 0.922265 (* 1 = 0.922265 loss)
I0521 21:12:35.682983 12468 sgd_solver.cpp:106] Iteration 168000, lr = 0.0005
I0521 21:12:47.806457 12468 solver.cpp:237] Iteration 168750, loss = 1.27149
I0521 21:12:47.806493 12468 solver.cpp:253]     Train net output #0: loss = 1.27149 (* 1 = 1.27149 loss)
I0521 21:12:47.806509 12468 sgd_solver.cpp:106] Iteration 168750, lr = 0.0005
I0521 21:12:59.948540 12468 solver.cpp:237] Iteration 169500, loss = 1.05037
I0521 21:12:59.948590 12468 solver.cpp:253]     Train net output #0: loss = 1.05037 (* 1 = 1.05037 loss)
I0521 21:12:59.948604 12468 sgd_solver.cpp:106] Iteration 169500, lr = 0.0005
I0521 21:13:32.984077 12468 solver.cpp:237] Iteration 170250, loss = 1.1525
I0521 21:13:32.984268 12468 solver.cpp:253]     Train net output #0: loss = 1.1525 (* 1 = 1.1525 loss)
I0521 21:13:32.984283 12468 sgd_solver.cpp:106] Iteration 170250, lr = 0.0005
I0521 21:13:45.129576 12468 solver.cpp:237] Iteration 171000, loss = 1.23612
I0521 21:13:45.129612 12468 solver.cpp:253]     Train net output #0: loss = 1.23612 (* 1 = 1.23612 loss)
I0521 21:13:45.129628 12468 sgd_solver.cpp:106] Iteration 171000, lr = 0.0005
I0521 21:13:57.333519 12468 solver.cpp:237] Iteration 171750, loss = 1.40636
I0521 21:13:57.333566 12468 solver.cpp:253]     Train net output #0: loss = 1.40636 (* 1 = 1.40636 loss)
I0521 21:13:57.333581 12468 sgd_solver.cpp:106] Iteration 171750, lr = 0.0005
I0521 21:14:09.527869 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_172500.caffemodel
I0521 21:14:09.577584 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_172500.solverstate
I0521 21:14:09.607730 12468 solver.cpp:237] Iteration 172500, loss = 1.14618
I0521 21:14:09.607776 12468 solver.cpp:253]     Train net output #0: loss = 1.14618 (* 1 = 1.14618 loss)
I0521 21:14:09.607795 12468 sgd_solver.cpp:106] Iteration 172500, lr = 0.0005
I0521 21:14:21.774073 12468 solver.cpp:237] Iteration 173250, loss = 1.06315
I0521 21:14:21.774121 12468 solver.cpp:253]     Train net output #0: loss = 1.06314 (* 1 = 1.06314 loss)
I0521 21:14:21.774137 12468 sgd_solver.cpp:106] Iteration 173250, lr = 0.0005
I0521 21:14:33.967710 12468 solver.cpp:237] Iteration 174000, loss = 0.672804
I0521 21:14:33.967748 12468 solver.cpp:253]     Train net output #0: loss = 0.672801 (* 1 = 0.672801 loss)
I0521 21:14:33.967763 12468 sgd_solver.cpp:106] Iteration 174000, lr = 0.0005
I0521 21:14:46.182400 12468 solver.cpp:237] Iteration 174750, loss = 1.05352
I0521 21:14:46.182574 12468 solver.cpp:253]     Train net output #0: loss = 1.05351 (* 1 = 1.05351 loss)
I0521 21:14:46.182590 12468 sgd_solver.cpp:106] Iteration 174750, lr = 0.0005
I0521 21:15:19.270674 12468 solver.cpp:237] Iteration 175500, loss = 0.947927
I0521 21:15:19.270866 12468 solver.cpp:253]     Train net output #0: loss = 0.947925 (* 1 = 0.947925 loss)
I0521 21:15:19.270881 12468 sgd_solver.cpp:106] Iteration 175500, lr = 0.0005
I0521 21:15:31.433954 12468 solver.cpp:237] Iteration 176250, loss = 1.67099
I0521 21:15:31.434001 12468 solver.cpp:253]     Train net output #0: loss = 1.67098 (* 1 = 1.67098 loss)
I0521 21:15:31.434016 12468 sgd_solver.cpp:106] Iteration 176250, lr = 0.0005
I0521 21:15:43.637082 12468 solver.cpp:237] Iteration 177000, loss = 1.1046
I0521 21:15:43.637120 12468 solver.cpp:253]     Train net output #0: loss = 1.10459 (* 1 = 1.10459 loss)
I0521 21:15:43.637132 12468 sgd_solver.cpp:106] Iteration 177000, lr = 0.0005
I0521 21:15:55.781913 12468 solver.cpp:237] Iteration 177750, loss = 0.917605
I0521 21:15:55.782080 12468 solver.cpp:253]     Train net output #0: loss = 0.917603 (* 1 = 0.917603 loss)
I0521 21:15:55.782096 12468 sgd_solver.cpp:106] Iteration 177750, lr = 0.0005
I0521 21:16:07.931129 12468 solver.cpp:237] Iteration 178500, loss = 1.0841
I0521 21:16:07.931166 12468 solver.cpp:253]     Train net output #0: loss = 1.08409 (* 1 = 1.08409 loss)
I0521 21:16:07.931190 12468 sgd_solver.cpp:106] Iteration 178500, lr = 0.0005
I0521 21:16:20.074054 12468 solver.cpp:237] Iteration 179250, loss = 1.3264
I0521 21:16:20.074098 12468 solver.cpp:253]     Train net output #0: loss = 1.32639 (* 1 = 1.32639 loss)
I0521 21:16:20.074113 12468 sgd_solver.cpp:106] Iteration 179250, lr = 0.0005
I0521 21:16:32.193503 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_180000.caffemodel
I0521 21:16:32.242535 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_180000.solverstate
I0521 21:16:32.267382 12468 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 21:17:45.069110 12468 solver.cpp:409]     Test net output #0: accuracy = 0.878501
I0521 21:17:45.069289 12468 solver.cpp:409]     Test net output #1: loss = 0.406656 (* 1 = 0.406656 loss)
I0521 21:18:05.924824 12468 solver.cpp:237] Iteration 180000, loss = 1.12466
I0521 21:18:05.924878 12468 solver.cpp:253]     Train net output #0: loss = 1.12466 (* 1 = 1.12466 loss)
I0521 21:18:05.924893 12468 sgd_solver.cpp:106] Iteration 180000, lr = 0.0005
I0521 21:18:18.125118 12468 solver.cpp:237] Iteration 180750, loss = 1.23343
I0521 21:18:18.125284 12468 solver.cpp:253]     Train net output #0: loss = 1.23343 (* 1 = 1.23343 loss)
I0521 21:18:18.125299 12468 sgd_solver.cpp:106] Iteration 180750, lr = 0.0005
I0521 21:18:30.360362 12468 solver.cpp:237] Iteration 181500, loss = 1.28396
I0521 21:18:30.360409 12468 solver.cpp:253]     Train net output #0: loss = 1.28396 (* 1 = 1.28396 loss)
I0521 21:18:30.360422 12468 sgd_solver.cpp:106] Iteration 181500, lr = 0.0005
I0521 21:18:42.598912 12468 solver.cpp:237] Iteration 182250, loss = 1.02797
I0521 21:18:42.598948 12468 solver.cpp:253]     Train net output #0: loss = 1.02797 (* 1 = 1.02797 loss)
I0521 21:18:42.598965 12468 sgd_solver.cpp:106] Iteration 182250, lr = 0.0005
I0521 21:18:54.777375 12468 solver.cpp:237] Iteration 183000, loss = 1.34535
I0521 21:18:54.777544 12468 solver.cpp:253]     Train net output #0: loss = 1.34534 (* 1 = 1.34534 loss)
I0521 21:18:54.777559 12468 sgd_solver.cpp:106] Iteration 183000, lr = 0.0005
I0521 21:19:06.974071 12468 solver.cpp:237] Iteration 183750, loss = 1.00454
I0521 21:19:06.974107 12468 solver.cpp:253]     Train net output #0: loss = 1.00453 (* 1 = 1.00453 loss)
I0521 21:19:06.974123 12468 sgd_solver.cpp:106] Iteration 183750, lr = 0.0005
I0521 21:19:19.188200 12468 solver.cpp:237] Iteration 184500, loss = 0.938065
I0521 21:19:19.188246 12468 solver.cpp:253]     Train net output #0: loss = 0.938063 (* 1 = 0.938063 loss)
I0521 21:19:19.188261 12468 sgd_solver.cpp:106] Iteration 184500, lr = 0.0005
I0521 21:19:52.268735 12468 solver.cpp:237] Iteration 185250, loss = 1.61996
I0521 21:19:52.268926 12468 solver.cpp:253]     Train net output #0: loss = 1.61996 (* 1 = 1.61996 loss)
I0521 21:19:52.268941 12468 sgd_solver.cpp:106] Iteration 185250, lr = 0.0005
I0521 21:20:04.461166 12468 solver.cpp:237] Iteration 186000, loss = 1.42916
I0521 21:20:04.461213 12468 solver.cpp:253]     Train net output #0: loss = 1.42916 (* 1 = 1.42916 loss)
I0521 21:20:04.461228 12468 sgd_solver.cpp:106] Iteration 186000, lr = 0.0005
I0521 21:20:16.657071 12468 solver.cpp:237] Iteration 186750, loss = 1.09321
I0521 21:20:16.657107 12468 solver.cpp:253]     Train net output #0: loss = 1.09321 (* 1 = 1.09321 loss)
I0521 21:20:16.657126 12468 sgd_solver.cpp:106] Iteration 186750, lr = 0.0005
I0521 21:20:28.848634 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_187500.caffemodel
I0521 21:20:28.904647 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_187500.solverstate
I0521 21:20:28.936914 12468 solver.cpp:237] Iteration 187500, loss = 1.38852
I0521 21:20:28.936964 12468 solver.cpp:253]     Train net output #0: loss = 1.38852 (* 1 = 1.38852 loss)
I0521 21:20:28.936980 12468 sgd_solver.cpp:106] Iteration 187500, lr = 0.0005
I0521 21:20:41.126592 12468 solver.cpp:237] Iteration 188250, loss = 1.24529
I0521 21:20:41.126628 12468 solver.cpp:253]     Train net output #0: loss = 1.24529 (* 1 = 1.24529 loss)
I0521 21:20:41.126646 12468 sgd_solver.cpp:106] Iteration 188250, lr = 0.0005
I0521 21:20:53.327409 12468 solver.cpp:237] Iteration 189000, loss = 1.04021
I0521 21:20:53.327462 12468 solver.cpp:253]     Train net output #0: loss = 1.04021 (* 1 = 1.04021 loss)
I0521 21:20:53.327476 12468 sgd_solver.cpp:106] Iteration 189000, lr = 0.0005
I0521 21:21:05.592200 12468 solver.cpp:237] Iteration 189750, loss = 1.10938
I0521 21:21:05.592366 12468 solver.cpp:253]     Train net output #0: loss = 1.10938 (* 1 = 1.10938 loss)
I0521 21:21:05.592380 12468 sgd_solver.cpp:106] Iteration 189750, lr = 0.0005
I0521 21:21:38.668108 12468 solver.cpp:237] Iteration 190500, loss = 1.50169
I0521 21:21:38.668292 12468 solver.cpp:253]     Train net output #0: loss = 1.50169 (* 1 = 1.50169 loss)
I0521 21:21:38.668306 12468 sgd_solver.cpp:106] Iteration 190500, lr = 0.0005
I0521 21:21:50.850451 12468 solver.cpp:237] Iteration 191250, loss = 1.21699
I0521 21:21:50.850497 12468 solver.cpp:253]     Train net output #0: loss = 1.21699 (* 1 = 1.21699 loss)
I0521 21:21:50.850512 12468 sgd_solver.cpp:106] Iteration 191250, lr = 0.0005
I0521 21:22:03.028759 12468 solver.cpp:237] Iteration 192000, loss = 1.33752
I0521 21:22:03.028795 12468 solver.cpp:253]     Train net output #0: loss = 1.33752 (* 1 = 1.33752 loss)
I0521 21:22:03.028812 12468 sgd_solver.cpp:106] Iteration 192000, lr = 0.0005
I0521 21:22:15.232228 12468 solver.cpp:237] Iteration 192750, loss = 1.43732
I0521 21:22:15.232410 12468 solver.cpp:253]     Train net output #0: loss = 1.43731 (* 1 = 1.43731 loss)
I0521 21:22:15.232425 12468 sgd_solver.cpp:106] Iteration 192750, lr = 0.0005
I0521 21:22:27.428596 12468 solver.cpp:237] Iteration 193500, loss = 1.11333
I0521 21:22:27.428632 12468 solver.cpp:253]     Train net output #0: loss = 1.11333 (* 1 = 1.11333 loss)
I0521 21:22:27.428648 12468 sgd_solver.cpp:106] Iteration 193500, lr = 0.0005
I0521 21:22:39.624860 12468 solver.cpp:237] Iteration 194250, loss = 0.886389
I0521 21:22:39.624904 12468 solver.cpp:253]     Train net output #0: loss = 0.886386 (* 1 = 0.886386 loss)
I0521 21:22:39.624919 12468 sgd_solver.cpp:106] Iteration 194250, lr = 0.0005
I0521 21:22:51.796563 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_195000.caffemodel
I0521 21:22:51.845691 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_195000.solverstate
I0521 21:22:51.870712 12468 solver.cpp:341] Iteration 195000, Testing net (#0)
I0521 21:23:43.798205 12468 solver.cpp:409]     Test net output #0: accuracy = 0.88216
I0521 21:23:43.798387 12468 solver.cpp:409]     Test net output #1: loss = 0.383591 (* 1 = 0.383591 loss)
I0521 21:24:04.639691 12468 solver.cpp:237] Iteration 195000, loss = 0.785478
I0521 21:24:04.639744 12468 solver.cpp:253]     Train net output #0: loss = 0.785475 (* 1 = 0.785475 loss)
I0521 21:24:04.639758 12468 sgd_solver.cpp:106] Iteration 195000, lr = 0.0005
I0521 21:24:16.799103 12468 solver.cpp:237] Iteration 195750, loss = 1.18451
I0521 21:24:16.799324 12468 solver.cpp:253]     Train net output #0: loss = 1.18451 (* 1 = 1.18451 loss)
I0521 21:24:16.799340 12468 sgd_solver.cpp:106] Iteration 195750, lr = 0.0005
I0521 21:24:28.949542 12468 solver.cpp:237] Iteration 196500, loss = 1.70431
I0521 21:24:28.949579 12468 solver.cpp:253]     Train net output #0: loss = 1.70431 (* 1 = 1.70431 loss)
I0521 21:24:28.949594 12468 sgd_solver.cpp:106] Iteration 196500, lr = 0.0005
I0521 21:24:41.094651 12468 solver.cpp:237] Iteration 197250, loss = 1.16602
I0521 21:24:41.094699 12468 solver.cpp:253]     Train net output #0: loss = 1.16602 (* 1 = 1.16602 loss)
I0521 21:24:41.094714 12468 sgd_solver.cpp:106] Iteration 197250, lr = 0.0005
I0521 21:24:53.232748 12468 solver.cpp:237] Iteration 198000, loss = 0.885563
I0521 21:24:53.232909 12468 solver.cpp:253]     Train net output #0: loss = 0.88556 (* 1 = 0.88556 loss)
I0521 21:24:53.232924 12468 sgd_solver.cpp:106] Iteration 198000, lr = 0.0005
I0521 21:25:05.369498 12468 solver.cpp:237] Iteration 198750, loss = 1.18659
I0521 21:25:05.369547 12468 solver.cpp:253]     Train net output #0: loss = 1.18659 (* 1 = 1.18659 loss)
I0521 21:25:05.369561 12468 sgd_solver.cpp:106] Iteration 198750, lr = 0.0005
I0521 21:25:17.503065 12468 solver.cpp:237] Iteration 199500, loss = 1.24596
I0521 21:25:17.503101 12468 solver.cpp:253]     Train net output #0: loss = 1.24596 (* 1 = 1.24596 loss)
I0521 21:25:17.503118 12468 sgd_solver.cpp:106] Iteration 199500, lr = 0.0005
I0521 21:25:50.457638 12468 solver.cpp:237] Iteration 200250, loss = 1.34899
I0521 21:25:50.457818 12468 solver.cpp:253]     Train net output #0: loss = 1.34899 (* 1 = 1.34899 loss)
I0521 21:25:50.457833 12468 sgd_solver.cpp:106] Iteration 200250, lr = 0.0005
I0521 21:26:02.641702 12468 solver.cpp:237] Iteration 201000, loss = 0.816718
I0521 21:26:02.641738 12468 solver.cpp:253]     Train net output #0: loss = 0.816714 (* 1 = 0.816714 loss)
I0521 21:26:02.641754 12468 sgd_solver.cpp:106] Iteration 201000, lr = 0.0005
I0521 21:26:14.826747 12468 solver.cpp:237] Iteration 201750, loss = 1.41112
I0521 21:26:14.826783 12468 solver.cpp:253]     Train net output #0: loss = 1.41111 (* 1 = 1.41111 loss)
I0521 21:26:14.826799 12468 sgd_solver.cpp:106] Iteration 201750, lr = 0.0005
I0521 21:26:26.985749 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_202500.caffemodel
I0521 21:26:27.034898 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_202500.solverstate
I0521 21:26:27.065012 12468 solver.cpp:237] Iteration 202500, loss = 1.18512
I0521 21:26:27.065057 12468 solver.cpp:253]     Train net output #0: loss = 1.18511 (* 1 = 1.18511 loss)
I0521 21:26:27.065075 12468 sgd_solver.cpp:106] Iteration 202500, lr = 0.0005
I0521 21:26:39.226089 12468 solver.cpp:237] Iteration 203250, loss = 1.49463
I0521 21:26:39.226125 12468 solver.cpp:253]     Train net output #0: loss = 1.49462 (* 1 = 1.49462 loss)
I0521 21:26:39.226141 12468 sgd_solver.cpp:106] Iteration 203250, lr = 0.0005
I0521 21:26:51.398044 12468 solver.cpp:237] Iteration 204000, loss = 1.07763
I0521 21:26:51.398088 12468 solver.cpp:253]     Train net output #0: loss = 1.07762 (* 1 = 1.07762 loss)
I0521 21:26:51.398105 12468 sgd_solver.cpp:106] Iteration 204000, lr = 0.0005
I0521 21:27:03.547114 12468 solver.cpp:237] Iteration 204750, loss = 1.16888
I0521 21:27:03.547293 12468 solver.cpp:253]     Train net output #0: loss = 1.16888 (* 1 = 1.16888 loss)
I0521 21:27:03.547308 12468 sgd_solver.cpp:106] Iteration 204750, lr = 0.0005
I0521 21:27:36.474223 12468 solver.cpp:237] Iteration 205500, loss = 1.47641
I0521 21:27:36.474406 12468 solver.cpp:253]     Train net output #0: loss = 1.47641 (* 1 = 1.47641 loss)
I0521 21:27:36.474422 12468 sgd_solver.cpp:106] Iteration 205500, lr = 0.0005
I0521 21:27:48.536443 12468 solver.cpp:237] Iteration 206250, loss = 1.42404
I0521 21:27:48.536480 12468 solver.cpp:253]     Train net output #0: loss = 1.42403 (* 1 = 1.42403 loss)
I0521 21:27:48.536496 12468 sgd_solver.cpp:106] Iteration 206250, lr = 0.0005
I0521 21:28:00.639137 12468 solver.cpp:237] Iteration 207000, loss = 1.20082
I0521 21:28:00.639194 12468 solver.cpp:253]     Train net output #0: loss = 1.20082 (* 1 = 1.20082 loss)
I0521 21:28:00.639210 12468 sgd_solver.cpp:106] Iteration 207000, lr = 0.0005
I0521 21:28:12.763752 12468 solver.cpp:237] Iteration 207750, loss = 1.29659
I0521 21:28:12.763916 12468 solver.cpp:253]     Train net output #0: loss = 1.29658 (* 1 = 1.29658 loss)
I0521 21:28:12.763929 12468 sgd_solver.cpp:106] Iteration 207750, lr = 0.0005
I0521 21:28:24.880987 12468 solver.cpp:237] Iteration 208500, loss = 1.13479
I0521 21:28:24.881036 12468 solver.cpp:253]     Train net output #0: loss = 1.13479 (* 1 = 1.13479 loss)
I0521 21:28:24.881052 12468 sgd_solver.cpp:106] Iteration 208500, lr = 0.0005
I0521 21:28:37.032548 12468 solver.cpp:237] Iteration 209250, loss = 1.60059
I0521 21:28:37.032584 12468 solver.cpp:253]     Train net output #0: loss = 1.60059 (* 1 = 1.60059 loss)
I0521 21:28:37.032600 12468 sgd_solver.cpp:106] Iteration 209250, lr = 0.0005
I0521 21:28:49.175390 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_210000.caffemodel
I0521 21:28:49.224453 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_210000.solverstate
I0521 21:28:49.249708 12468 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 21:30:02.047909 12468 solver.cpp:409]     Test net output #0: accuracy = 0.879263
I0521 21:30:02.048089 12468 solver.cpp:409]     Test net output #1: loss = 0.388414 (* 1 = 0.388414 loss)
I0521 21:30:22.869333 12468 solver.cpp:237] Iteration 210000, loss = 1.40162
I0521 21:30:22.869386 12468 solver.cpp:253]     Train net output #0: loss = 1.40162 (* 1 = 1.40162 loss)
I0521 21:30:22.869401 12468 sgd_solver.cpp:106] Iteration 210000, lr = 0.0005
I0521 21:30:35.027617 12468 solver.cpp:237] Iteration 210750, loss = 1.1806
I0521 21:30:35.027794 12468 solver.cpp:253]     Train net output #0: loss = 1.1806 (* 1 = 1.1806 loss)
I0521 21:30:35.027809 12468 sgd_solver.cpp:106] Iteration 210750, lr = 0.0005
I0521 21:30:47.195785 12468 solver.cpp:237] Iteration 211500, loss = 0.705667
I0521 21:30:47.195822 12468 solver.cpp:253]     Train net output #0: loss = 0.705664 (* 1 = 0.705664 loss)
I0521 21:30:47.195837 12468 sgd_solver.cpp:106] Iteration 211500, lr = 0.0005
I0521 21:30:59.387130 12468 solver.cpp:237] Iteration 212250, loss = 0.910755
I0521 21:30:59.387181 12468 solver.cpp:253]     Train net output #0: loss = 0.910752 (* 1 = 0.910752 loss)
I0521 21:30:59.387202 12468 sgd_solver.cpp:106] Iteration 212250, lr = 0.0005
I0521 21:31:11.577764 12468 solver.cpp:237] Iteration 213000, loss = 1.34783
I0521 21:31:11.577929 12468 solver.cpp:253]     Train net output #0: loss = 1.34783 (* 1 = 1.34783 loss)
I0521 21:31:11.577942 12468 sgd_solver.cpp:106] Iteration 213000, lr = 0.0005
I0521 21:31:23.777762 12468 solver.cpp:237] Iteration 213750, loss = 1.10568
I0521 21:31:23.777811 12468 solver.cpp:253]     Train net output #0: loss = 1.10568 (* 1 = 1.10568 loss)
I0521 21:31:23.777827 12468 sgd_solver.cpp:106] Iteration 213750, lr = 0.0005
I0521 21:31:35.935981 12468 solver.cpp:237] Iteration 214500, loss = 0.827584
I0521 21:31:35.936017 12468 solver.cpp:253]     Train net output #0: loss = 0.827581 (* 1 = 0.827581 loss)
I0521 21:31:35.936033 12468 sgd_solver.cpp:106] Iteration 214500, lr = 0.0005
I0521 21:32:08.878381 12468 solver.cpp:237] Iteration 215250, loss = 1.14929
I0521 21:32:08.878577 12468 solver.cpp:253]     Train net output #0: loss = 1.14928 (* 1 = 1.14928 loss)
I0521 21:32:08.878593 12468 sgd_solver.cpp:106] Iteration 215250, lr = 0.0005
I0521 21:32:20.999115 12468 solver.cpp:237] Iteration 216000, loss = 1.06066
I0521 21:32:20.999151 12468 solver.cpp:253]     Train net output #0: loss = 1.06065 (* 1 = 1.06065 loss)
I0521 21:32:20.999167 12468 sgd_solver.cpp:106] Iteration 216000, lr = 0.0005
I0521 21:32:33.141387 12468 solver.cpp:237] Iteration 216750, loss = 0.838872
I0521 21:32:33.141438 12468 solver.cpp:253]     Train net output #0: loss = 0.838869 (* 1 = 0.838869 loss)
I0521 21:32:33.141453 12468 sgd_solver.cpp:106] Iteration 216750, lr = 0.0005
I0521 21:32:45.338331 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_217500.caffemodel
I0521 21:32:45.390172 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_217500.solverstate
I0521 21:32:45.423243 12468 solver.cpp:237] Iteration 217500, loss = 1.55316
I0521 21:32:45.423287 12468 solver.cpp:253]     Train net output #0: loss = 1.55316 (* 1 = 1.55316 loss)
I0521 21:32:45.423307 12468 sgd_solver.cpp:106] Iteration 217500, lr = 0.0005
I0521 21:32:57.610229 12468 solver.cpp:237] Iteration 218250, loss = 1.31486
I0521 21:32:57.610278 12468 solver.cpp:253]     Train net output #0: loss = 1.31485 (* 1 = 1.31485 loss)
I0521 21:32:57.610293 12468 sgd_solver.cpp:106] Iteration 218250, lr = 0.0005
I0521 21:33:09.748549 12468 solver.cpp:237] Iteration 219000, loss = 1.80737
I0521 21:33:09.748585 12468 solver.cpp:253]     Train net output #0: loss = 1.80737 (* 1 = 1.80737 loss)
I0521 21:33:09.748600 12468 sgd_solver.cpp:106] Iteration 219000, lr = 0.0005
I0521 21:33:21.925802 12468 solver.cpp:237] Iteration 219750, loss = 1.32046
I0521 21:33:21.925986 12468 solver.cpp:253]     Train net output #0: loss = 1.32046 (* 1 = 1.32046 loss)
I0521 21:33:21.925999 12468 sgd_solver.cpp:106] Iteration 219750, lr = 0.0005
I0521 21:33:54.976835 12468 solver.cpp:237] Iteration 220500, loss = 1.24022
I0521 21:33:54.977023 12468 solver.cpp:253]     Train net output #0: loss = 1.24022 (* 1 = 1.24022 loss)
I0521 21:33:54.977038 12468 sgd_solver.cpp:106] Iteration 220500, lr = 0.0005
I0521 21:34:07.202515 12468 solver.cpp:237] Iteration 221250, loss = 1.02294
I0521 21:34:07.202551 12468 solver.cpp:253]     Train net output #0: loss = 1.02293 (* 1 = 1.02293 loss)
I0521 21:34:07.202567 12468 sgd_solver.cpp:106] Iteration 221250, lr = 0.0005
I0521 21:34:19.378360 12468 solver.cpp:237] Iteration 222000, loss = 1.29508
I0521 21:34:19.378407 12468 solver.cpp:253]     Train net output #0: loss = 1.29507 (* 1 = 1.29507 loss)
I0521 21:34:19.378422 12468 sgd_solver.cpp:106] Iteration 222000, lr = 0.0005
I0521 21:34:31.549506 12468 solver.cpp:237] Iteration 222750, loss = 1.20037
I0521 21:34:31.549670 12468 solver.cpp:253]     Train net output #0: loss = 1.20037 (* 1 = 1.20037 loss)
I0521 21:34:31.549685 12468 sgd_solver.cpp:106] Iteration 222750, lr = 0.0005
I0521 21:34:43.714958 12468 solver.cpp:237] Iteration 223500, loss = 1.30411
I0521 21:34:43.715001 12468 solver.cpp:253]     Train net output #0: loss = 1.30411 (* 1 = 1.30411 loss)
I0521 21:34:43.715018 12468 sgd_solver.cpp:106] Iteration 223500, lr = 0.0005
I0521 21:34:55.883419 12468 solver.cpp:237] Iteration 224250, loss = 1.35589
I0521 21:34:55.883450 12468 solver.cpp:253]     Train net output #0: loss = 1.35589 (* 1 = 1.35589 loss)
I0521 21:34:55.883463 12468 sgd_solver.cpp:106] Iteration 224250, lr = 0.0005
I0521 21:35:08.039615 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_225000.caffemodel
I0521 21:35:08.091220 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_225000.solverstate
I0521 21:35:08.118470 12468 solver.cpp:341] Iteration 225000, Testing net (#0)
I0521 21:35:59.758867 12468 solver.cpp:409]     Test net output #0: accuracy = 0.884527
I0521 21:35:59.759050 12468 solver.cpp:409]     Test net output #1: loss = 0.36577 (* 1 = 0.36577 loss)
I0521 21:36:20.598630 12468 solver.cpp:237] Iteration 225000, loss = 1.2907
I0521 21:36:20.598682 12468 solver.cpp:253]     Train net output #0: loss = 1.2907 (* 1 = 1.2907 loss)
I0521 21:36:20.598697 12468 sgd_solver.cpp:106] Iteration 225000, lr = 0.0005
I0521 21:36:32.742163 12468 solver.cpp:237] Iteration 225750, loss = 1.00485
I0521 21:36:32.742334 12468 solver.cpp:253]     Train net output #0: loss = 1.00484 (* 1 = 1.00484 loss)
I0521 21:36:32.742348 12468 sgd_solver.cpp:106] Iteration 225750, lr = 0.0005
I0521 21:36:44.901423 12468 solver.cpp:237] Iteration 226500, loss = 1.35074
I0521 21:36:44.901471 12468 solver.cpp:253]     Train net output #0: loss = 1.35073 (* 1 = 1.35073 loss)
I0521 21:36:44.901486 12468 sgd_solver.cpp:106] Iteration 226500, lr = 0.0005
I0521 21:36:57.095532 12468 solver.cpp:237] Iteration 227250, loss = 1.39293
I0521 21:36:57.095567 12468 solver.cpp:253]     Train net output #0: loss = 1.39293 (* 1 = 1.39293 loss)
I0521 21:36:57.095584 12468 sgd_solver.cpp:106] Iteration 227250, lr = 0.0005
I0521 21:37:09.195278 12468 solver.cpp:237] Iteration 228000, loss = 1.26223
I0521 21:37:09.195456 12468 solver.cpp:253]     Train net output #0: loss = 1.26222 (* 1 = 1.26222 loss)
I0521 21:37:09.195472 12468 sgd_solver.cpp:106] Iteration 228000, lr = 0.0005
I0521 21:37:21.283541 12468 solver.cpp:237] Iteration 228750, loss = 1.31906
I0521 21:37:21.283577 12468 solver.cpp:253]     Train net output #0: loss = 1.31906 (* 1 = 1.31906 loss)
I0521 21:37:21.283594 12468 sgd_solver.cpp:106] Iteration 228750, lr = 0.0005
I0521 21:37:33.418404 12468 solver.cpp:237] Iteration 229500, loss = 0.843188
I0521 21:37:33.418452 12468 solver.cpp:253]     Train net output #0: loss = 0.843185 (* 1 = 0.843185 loss)
I0521 21:37:33.418467 12468 sgd_solver.cpp:106] Iteration 229500, lr = 0.0005
I0521 21:38:06.413261 12468 solver.cpp:237] Iteration 230250, loss = 1.01305
I0521 21:38:06.413444 12468 solver.cpp:253]     Train net output #0: loss = 1.01304 (* 1 = 1.01304 loss)
I0521 21:38:06.413458 12468 sgd_solver.cpp:106] Iteration 230250, lr = 0.0005
I0521 21:38:18.559975 12468 solver.cpp:237] Iteration 231000, loss = 1.29705
I0521 21:38:18.560011 12468 solver.cpp:253]     Train net output #0: loss = 1.29705 (* 1 = 1.29705 loss)
I0521 21:38:18.560029 12468 sgd_solver.cpp:106] Iteration 231000, lr = 0.0005
I0521 21:38:30.733115 12468 solver.cpp:237] Iteration 231750, loss = 2.07966
I0521 21:38:30.733165 12468 solver.cpp:253]     Train net output #0: loss = 2.07966 (* 1 = 2.07966 loss)
I0521 21:38:30.733178 12468 sgd_solver.cpp:106] Iteration 231750, lr = 0.0005
I0521 21:38:42.889904 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_232500.caffemodel
I0521 21:38:42.941143 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_232500.solverstate
I0521 21:38:42.971002 12468 solver.cpp:237] Iteration 232500, loss = 0.98062
I0521 21:38:42.971050 12468 solver.cpp:253]     Train net output #0: loss = 0.980617 (* 1 = 0.980617 loss)
I0521 21:38:42.971065 12468 sgd_solver.cpp:106] Iteration 232500, lr = 0.0005
I0521 21:38:55.127770 12468 solver.cpp:237] Iteration 233250, loss = 1.15763
I0521 21:38:55.127813 12468 solver.cpp:253]     Train net output #0: loss = 1.15763 (* 1 = 1.15763 loss)
I0521 21:38:55.127830 12468 sgd_solver.cpp:106] Iteration 233250, lr = 0.0005
I0521 21:39:07.312126 12468 solver.cpp:237] Iteration 234000, loss = 1.24414
I0521 21:39:07.312162 12468 solver.cpp:253]     Train net output #0: loss = 1.24414 (* 1 = 1.24414 loss)
I0521 21:39:07.312180 12468 sgd_solver.cpp:106] Iteration 234000, lr = 0.0005
I0521 21:39:19.518126 12468 solver.cpp:237] Iteration 234750, loss = 0.973683
I0521 21:39:19.518321 12468 solver.cpp:253]     Train net output #0: loss = 0.97368 (* 1 = 0.97368 loss)
I0521 21:39:19.518335 12468 sgd_solver.cpp:106] Iteration 234750, lr = 0.0005
I0521 21:39:52.583843 12468 solver.cpp:237] Iteration 235500, loss = 1.14002
I0521 21:39:52.584033 12468 solver.cpp:253]     Train net output #0: loss = 1.14002 (* 1 = 1.14002 loss)
I0521 21:39:52.584048 12468 sgd_solver.cpp:106] Iteration 235500, lr = 0.0005
I0521 21:40:04.684702 12468 solver.cpp:237] Iteration 236250, loss = 0.9084
I0521 21:40:04.684751 12468 solver.cpp:253]     Train net output #0: loss = 0.908397 (* 1 = 0.908397 loss)
I0521 21:40:04.684765 12468 sgd_solver.cpp:106] Iteration 236250, lr = 0.0005
I0521 21:40:16.777951 12468 solver.cpp:237] Iteration 237000, loss = 0.989612
I0521 21:40:16.777987 12468 solver.cpp:253]     Train net output #0: loss = 0.989609 (* 1 = 0.989609 loss)
I0521 21:40:16.778002 12468 sgd_solver.cpp:106] Iteration 237000, lr = 0.0005
I0521 21:40:28.878059 12468 solver.cpp:237] Iteration 237750, loss = 1.21963
I0521 21:40:28.878239 12468 solver.cpp:253]     Train net output #0: loss = 1.21963 (* 1 = 1.21963 loss)
I0521 21:40:28.878255 12468 sgd_solver.cpp:106] Iteration 237750, lr = 0.0005
I0521 21:40:40.971715 12468 solver.cpp:237] Iteration 238500, loss = 1.60473
I0521 21:40:40.971751 12468 solver.cpp:253]     Train net output #0: loss = 1.60473 (* 1 = 1.60473 loss)
I0521 21:40:40.971767 12468 sgd_solver.cpp:106] Iteration 238500, lr = 0.0005
I0521 21:40:53.069135 12468 solver.cpp:237] Iteration 239250, loss = 1.20777
I0521 21:40:53.069185 12468 solver.cpp:253]     Train net output #0: loss = 1.20777 (* 1 = 1.20777 loss)
I0521 21:40:53.069200 12468 sgd_solver.cpp:106] Iteration 239250, lr = 0.0005
I0521 21:41:05.143939 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_240000.caffemodel
I0521 21:41:05.193192 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_240000.solverstate
I0521 21:41:05.218220 12468 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 21:42:17.916024 12468 solver.cpp:409]     Test net output #0: accuracy = 0.883787
I0521 21:42:17.916208 12468 solver.cpp:409]     Test net output #1: loss = 0.361922 (* 1 = 0.361922 loss)
I0521 21:42:38.746698 12468 solver.cpp:237] Iteration 240000, loss = 1.10298
I0521 21:42:38.746752 12468 solver.cpp:253]     Train net output #0: loss = 1.10297 (* 1 = 1.10297 loss)
I0521 21:42:38.746767 12468 sgd_solver.cpp:106] Iteration 240000, lr = 0.0005
I0521 21:42:50.901283 12468 solver.cpp:237] Iteration 240750, loss = 1.19994
I0521 21:42:50.901458 12468 solver.cpp:253]     Train net output #0: loss = 1.19994 (* 1 = 1.19994 loss)
I0521 21:42:50.901473 12468 sgd_solver.cpp:106] Iteration 240750, lr = 0.0005
I0521 21:43:03.098093 12468 solver.cpp:237] Iteration 241500, loss = 0.947576
I0521 21:43:03.098141 12468 solver.cpp:253]     Train net output #0: loss = 0.947573 (* 1 = 0.947573 loss)
I0521 21:43:03.098155 12468 sgd_solver.cpp:106] Iteration 241500, lr = 0.0005
I0521 21:43:15.293373 12468 solver.cpp:237] Iteration 242250, loss = 1.3092
I0521 21:43:15.293409 12468 solver.cpp:253]     Train net output #0: loss = 1.3092 (* 1 = 1.3092 loss)
I0521 21:43:15.293424 12468 sgd_solver.cpp:106] Iteration 242250, lr = 0.0005
I0521 21:43:27.478111 12468 solver.cpp:237] Iteration 243000, loss = 0.886913
I0521 21:43:27.478298 12468 solver.cpp:253]     Train net output #0: loss = 0.88691 (* 1 = 0.88691 loss)
I0521 21:43:27.478314 12468 sgd_solver.cpp:106] Iteration 243000, lr = 0.0005
I0521 21:43:39.637627 12468 solver.cpp:237] Iteration 243750, loss = 1.18775
I0521 21:43:39.637663 12468 solver.cpp:253]     Train net output #0: loss = 1.18775 (* 1 = 1.18775 loss)
I0521 21:43:39.637681 12468 sgd_solver.cpp:106] Iteration 243750, lr = 0.0005
I0521 21:43:51.797345 12468 solver.cpp:237] Iteration 244500, loss = 1.10677
I0521 21:43:51.797389 12468 solver.cpp:253]     Train net output #0: loss = 1.10677 (* 1 = 1.10677 loss)
I0521 21:43:51.797404 12468 sgd_solver.cpp:106] Iteration 244500, lr = 0.0005
I0521 21:44:24.791270 12468 solver.cpp:237] Iteration 245250, loss = 1.38044
I0521 21:44:24.791456 12468 solver.cpp:253]     Train net output #0: loss = 1.38044 (* 1 = 1.38044 loss)
I0521 21:44:24.791471 12468 sgd_solver.cpp:106] Iteration 245250, lr = 0.0005
I0521 21:44:37.090255 12468 solver.cpp:237] Iteration 246000, loss = 0.953896
I0521 21:44:37.090294 12468 solver.cpp:253]     Train net output #0: loss = 0.953893 (* 1 = 0.953893 loss)
I0521 21:44:37.090315 12468 sgd_solver.cpp:106] Iteration 246000, lr = 0.0005
I0521 21:44:49.380280 12468 solver.cpp:237] Iteration 246750, loss = 1.05792
I0521 21:44:49.380316 12468 solver.cpp:253]     Train net output #0: loss = 1.05792 (* 1 = 1.05792 loss)
I0521 21:44:49.380329 12468 sgd_solver.cpp:106] Iteration 246750, lr = 0.0005
I0521 21:45:01.661005 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_247500.caffemodel
I0521 21:45:01.710320 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_247500.solverstate
I0521 21:45:01.740355 12468 solver.cpp:237] Iteration 247500, loss = 1.38109
I0521 21:45:01.740398 12468 solver.cpp:253]     Train net output #0: loss = 1.38108 (* 1 = 1.38108 loss)
I0521 21:45:01.740417 12468 sgd_solver.cpp:106] Iteration 247500, lr = 0.0005
I0521 21:45:14.033285 12468 solver.cpp:237] Iteration 248250, loss = 0.858229
I0521 21:45:14.033323 12468 solver.cpp:253]     Train net output #0: loss = 0.858226 (* 1 = 0.858226 loss)
I0521 21:45:14.033337 12468 sgd_solver.cpp:106] Iteration 248250, lr = 0.0005
I0521 21:45:26.286286 12468 solver.cpp:237] Iteration 249000, loss = 0.989886
I0521 21:45:26.286325 12468 solver.cpp:253]     Train net output #0: loss = 0.989883 (* 1 = 0.989883 loss)
I0521 21:45:26.286346 12468 sgd_solver.cpp:106] Iteration 249000, lr = 0.0005
I0521 21:45:38.535948 12468 solver.cpp:237] Iteration 249750, loss = 1.21394
I0521 21:45:38.536118 12468 solver.cpp:253]     Train net output #0: loss = 1.21394 (* 1 = 1.21394 loss)
I0521 21:45:38.536133 12468 sgd_solver.cpp:106] Iteration 249750, lr = 0.0005
I0521 21:46:11.581805 12468 solver.cpp:237] Iteration 250500, loss = 1.04916
I0521 21:46:11.581990 12468 solver.cpp:253]     Train net output #0: loss = 1.04916 (* 1 = 1.04916 loss)
I0521 21:46:11.582006 12468 sgd_solver.cpp:106] Iteration 250500, lr = 0.0005
I0521 21:46:23.782304 12468 solver.cpp:237] Iteration 251250, loss = 2.0486
I0521 21:46:23.782348 12468 solver.cpp:253]     Train net output #0: loss = 2.0486 (* 1 = 2.0486 loss)
I0521 21:46:23.782363 12468 sgd_solver.cpp:106] Iteration 251250, lr = 0.0005
I0521 21:46:36.009963 12468 solver.cpp:237] Iteration 252000, loss = 0.839196
I0521 21:46:36.009999 12468 solver.cpp:253]     Train net output #0: loss = 0.839193 (* 1 = 0.839193 loss)
I0521 21:46:36.010015 12468 sgd_solver.cpp:106] Iteration 252000, lr = 0.0005
I0521 21:46:48.257983 12468 solver.cpp:237] Iteration 252750, loss = 1.02861
I0521 21:46:48.258174 12468 solver.cpp:253]     Train net output #0: loss = 1.0286 (* 1 = 1.0286 loss)
I0521 21:46:48.258190 12468 sgd_solver.cpp:106] Iteration 252750, lr = 0.0005
I0521 21:47:00.507230 12468 solver.cpp:237] Iteration 253500, loss = 1.33531
I0521 21:47:00.507267 12468 solver.cpp:253]     Train net output #0: loss = 1.33531 (* 1 = 1.33531 loss)
I0521 21:47:00.507285 12468 sgd_solver.cpp:106] Iteration 253500, lr = 0.0005
I0521 21:47:12.736623 12468 solver.cpp:237] Iteration 254250, loss = 1.11597
I0521 21:47:12.736671 12468 solver.cpp:253]     Train net output #0: loss = 1.11596 (* 1 = 1.11596 loss)
I0521 21:47:12.736686 12468 sgd_solver.cpp:106] Iteration 254250, lr = 0.0005
I0521 21:47:24.956722 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_255000.caffemodel
I0521 21:47:25.005556 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_255000.solverstate
I0521 21:47:25.030706 12468 solver.cpp:341] Iteration 255000, Testing net (#0)
I0521 21:48:16.995481 12468 solver.cpp:409]     Test net output #0: accuracy = 0.887043
I0521 21:48:16.995669 12468 solver.cpp:409]     Test net output #1: loss = 0.382141 (* 1 = 0.382141 loss)
I0521 21:48:37.901958 12468 solver.cpp:237] Iteration 255000, loss = 1.03675
I0521 21:48:37.902011 12468 solver.cpp:253]     Train net output #0: loss = 1.03675 (* 1 = 1.03675 loss)
I0521 21:48:37.902029 12468 sgd_solver.cpp:106] Iteration 255000, lr = 0.0005
I0521 21:48:50.046819 12468 solver.cpp:237] Iteration 255750, loss = 0.924905
I0521 21:48:50.047004 12468 solver.cpp:253]     Train net output #0: loss = 0.924902 (* 1 = 0.924902 loss)
I0521 21:48:50.047020 12468 sgd_solver.cpp:106] Iteration 255750, lr = 0.0005
I0521 21:49:02.190110 12468 solver.cpp:237] Iteration 256500, loss = 0.854438
I0521 21:49:02.190147 12468 solver.cpp:253]     Train net output #0: loss = 0.854435 (* 1 = 0.854435 loss)
I0521 21:49:02.190162 12468 sgd_solver.cpp:106] Iteration 256500, lr = 0.0005
I0521 21:49:14.323948 12468 solver.cpp:237] Iteration 257250, loss = 1.34834
I0521 21:49:14.323994 12468 solver.cpp:253]     Train net output #0: loss = 1.34833 (* 1 = 1.34833 loss)
I0521 21:49:14.324010 12468 sgd_solver.cpp:106] Iteration 257250, lr = 0.0005
I0521 21:49:26.474504 12468 solver.cpp:237] Iteration 258000, loss = 1.60375
I0521 21:49:26.474689 12468 solver.cpp:253]     Train net output #0: loss = 1.60375 (* 1 = 1.60375 loss)
I0521 21:49:26.474704 12468 sgd_solver.cpp:106] Iteration 258000, lr = 0.0005
I0521 21:49:38.629609 12468 solver.cpp:237] Iteration 258750, loss = 1.27705
I0521 21:49:38.629659 12468 solver.cpp:253]     Train net output #0: loss = 1.27705 (* 1 = 1.27705 loss)
I0521 21:49:38.629673 12468 sgd_solver.cpp:106] Iteration 258750, lr = 0.0005
I0521 21:49:50.791282 12468 solver.cpp:237] Iteration 259500, loss = 1.3604
I0521 21:49:50.791318 12468 solver.cpp:253]     Train net output #0: loss = 1.3604 (* 1 = 1.3604 loss)
I0521 21:49:50.791334 12468 sgd_solver.cpp:106] Iteration 259500, lr = 0.0005
I0521 21:50:23.818383 12468 solver.cpp:237] Iteration 260250, loss = 1.17506
I0521 21:50:23.818572 12468 solver.cpp:253]     Train net output #0: loss = 1.17506 (* 1 = 1.17506 loss)
I0521 21:50:23.818588 12468 sgd_solver.cpp:106] Iteration 260250, lr = 0.0005
I0521 21:50:35.985299 12468 solver.cpp:237] Iteration 261000, loss = 1.11695
I0521 21:50:35.985344 12468 solver.cpp:253]     Train net output #0: loss = 1.11694 (* 1 = 1.11694 loss)
I0521 21:50:35.985360 12468 sgd_solver.cpp:106] Iteration 261000, lr = 0.0005
I0521 21:50:48.136319 12468 solver.cpp:237] Iteration 261750, loss = 1.01735
I0521 21:50:48.136354 12468 solver.cpp:253]     Train net output #0: loss = 1.01735 (* 1 = 1.01735 loss)
I0521 21:50:48.136370 12468 sgd_solver.cpp:106] Iteration 261750, lr = 0.0005
I0521 21:51:00.316771 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_262500.caffemodel
I0521 21:51:00.368788 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_262500.solverstate
I0521 21:51:00.401521 12468 solver.cpp:237] Iteration 262500, loss = 1.55284
I0521 21:51:00.401566 12468 solver.cpp:253]     Train net output #0: loss = 1.55283 (* 1 = 1.55283 loss)
I0521 21:51:00.401587 12468 sgd_solver.cpp:106] Iteration 262500, lr = 0.0005
I0521 21:51:12.564813 12468 solver.cpp:237] Iteration 263250, loss = 1.13805
I0521 21:51:12.564849 12468 solver.cpp:253]     Train net output #0: loss = 1.13804 (* 1 = 1.13804 loss)
I0521 21:51:12.564865 12468 sgd_solver.cpp:106] Iteration 263250, lr = 0.0005
I0521 21:51:24.740185 12468 solver.cpp:237] Iteration 264000, loss = 0.867452
I0521 21:51:24.740238 12468 solver.cpp:253]     Train net output #0: loss = 0.867449 (* 1 = 0.867449 loss)
I0521 21:51:24.740253 12468 sgd_solver.cpp:106] Iteration 264000, lr = 0.0005
I0521 21:51:36.933006 12468 solver.cpp:237] Iteration 264750, loss = 1.03932
I0521 21:51:36.933181 12468 solver.cpp:253]     Train net output #0: loss = 1.03932 (* 1 = 1.03932 loss)
I0521 21:51:36.933194 12468 sgd_solver.cpp:106] Iteration 264750, lr = 0.0005
I0521 21:52:09.955587 12468 solver.cpp:237] Iteration 265500, loss = 1.16895
I0521 21:52:09.955785 12468 solver.cpp:253]     Train net output #0: loss = 1.16895 (* 1 = 1.16895 loss)
I0521 21:52:09.955801 12468 sgd_solver.cpp:106] Iteration 265500, lr = 0.0005
I0521 21:52:22.093449 12468 solver.cpp:237] Iteration 266250, loss = 1.20674
I0521 21:52:22.093485 12468 solver.cpp:253]     Train net output #0: loss = 1.20674 (* 1 = 1.20674 loss)
I0521 21:52:22.093502 12468 sgd_solver.cpp:106] Iteration 266250, lr = 0.0005
I0521 21:52:34.238750 12468 solver.cpp:237] Iteration 267000, loss = 1.24893
I0521 21:52:34.238802 12468 solver.cpp:253]     Train net output #0: loss = 1.24893 (* 1 = 1.24893 loss)
I0521 21:52:34.238818 12468 sgd_solver.cpp:106] Iteration 267000, lr = 0.0005
I0521 21:52:46.390213 12468 solver.cpp:237] Iteration 267750, loss = 1.21035
I0521 21:52:46.390385 12468 solver.cpp:253]     Train net output #0: loss = 1.21035 (* 1 = 1.21035 loss)
I0521 21:52:46.390399 12468 sgd_solver.cpp:106] Iteration 267750, lr = 0.0005
I0521 21:52:58.492274 12468 solver.cpp:237] Iteration 268500, loss = 1.32867
I0521 21:52:58.492321 12468 solver.cpp:253]     Train net output #0: loss = 1.32866 (* 1 = 1.32866 loss)
I0521 21:52:58.492336 12468 sgd_solver.cpp:106] Iteration 268500, lr = 0.0005
I0521 21:53:10.607623 12468 solver.cpp:237] Iteration 269250, loss = 0.703191
I0521 21:53:10.607661 12468 solver.cpp:253]     Train net output #0: loss = 0.703188 (* 1 = 0.703188 loss)
I0521 21:53:10.607676 12468 sgd_solver.cpp:106] Iteration 269250, lr = 0.0005
I0521 21:53:22.708622 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_270000.caffemodel
I0521 21:53:22.759809 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_270000.solverstate
I0521 21:53:22.787343 12468 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 21:54:35.601083 12468 solver.cpp:409]     Test net output #0: accuracy = 0.88633
I0521 21:54:35.601260 12468 solver.cpp:409]     Test net output #1: loss = 0.3523 (* 1 = 0.3523 loss)
I0521 21:54:56.439568 12468 solver.cpp:237] Iteration 270000, loss = 0.836648
I0521 21:54:56.439621 12468 solver.cpp:253]     Train net output #0: loss = 0.836645 (* 1 = 0.836645 loss)
I0521 21:54:56.439637 12468 sgd_solver.cpp:106] Iteration 270000, lr = 0.0005
I0521 21:55:08.509099 12468 solver.cpp:237] Iteration 270750, loss = 0.952459
I0521 21:55:08.509301 12468 solver.cpp:253]     Train net output #0: loss = 0.952456 (* 1 = 0.952456 loss)
I0521 21:55:08.509315 12468 sgd_solver.cpp:106] Iteration 270750, lr = 0.0005
I0521 21:55:20.624111 12468 solver.cpp:237] Iteration 271500, loss = 1.29213
I0521 21:55:20.624148 12468 solver.cpp:253]     Train net output #0: loss = 1.29213 (* 1 = 1.29213 loss)
I0521 21:55:20.624163 12468 sgd_solver.cpp:106] Iteration 271500, lr = 0.0005
I0521 21:55:32.741552 12468 solver.cpp:237] Iteration 272250, loss = 1.38592
I0521 21:55:32.741595 12468 solver.cpp:253]     Train net output #0: loss = 1.38592 (* 1 = 1.38592 loss)
I0521 21:55:32.741612 12468 sgd_solver.cpp:106] Iteration 272250, lr = 0.0005
I0521 21:55:44.858029 12468 solver.cpp:237] Iteration 273000, loss = 1.2976
I0521 21:55:44.858202 12468 solver.cpp:253]     Train net output #0: loss = 1.2976 (* 1 = 1.2976 loss)
I0521 21:55:44.858217 12468 sgd_solver.cpp:106] Iteration 273000, lr = 0.0005
I0521 21:55:56.982281 12468 solver.cpp:237] Iteration 273750, loss = 0.955025
I0521 21:55:56.982326 12468 solver.cpp:253]     Train net output #0: loss = 0.955022 (* 1 = 0.955022 loss)
I0521 21:55:56.982342 12468 sgd_solver.cpp:106] Iteration 273750, lr = 0.0005
I0521 21:56:09.109302 12468 solver.cpp:237] Iteration 274500, loss = 0.931366
I0521 21:56:09.109338 12468 solver.cpp:253]     Train net output #0: loss = 0.931363 (* 1 = 0.931363 loss)
I0521 21:56:09.109354 12468 sgd_solver.cpp:106] Iteration 274500, lr = 0.0005
I0521 21:56:42.061750 12468 solver.cpp:237] Iteration 275250, loss = 1.49041
I0521 21:56:42.061941 12468 solver.cpp:253]     Train net output #0: loss = 1.4904 (* 1 = 1.4904 loss)
I0521 21:56:42.061955 12468 sgd_solver.cpp:106] Iteration 275250, lr = 0.0005
I0521 21:56:54.122161 12468 solver.cpp:237] Iteration 276000, loss = 1.33894
I0521 21:56:54.122196 12468 solver.cpp:253]     Train net output #0: loss = 1.33893 (* 1 = 1.33893 loss)
I0521 21:56:54.122213 12468 sgd_solver.cpp:106] Iteration 276000, lr = 0.0005
I0521 21:57:06.195808 12468 solver.cpp:237] Iteration 276750, loss = 1.18012
I0521 21:57:06.195852 12468 solver.cpp:253]     Train net output #0: loss = 1.18012 (* 1 = 1.18012 loss)
I0521 21:57:06.195866 12468 sgd_solver.cpp:106] Iteration 276750, lr = 0.0005
I0521 21:57:18.292228 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_277500.caffemodel
I0521 21:57:18.342030 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_277500.solverstate
I0521 21:57:18.372776 12468 solver.cpp:237] Iteration 277500, loss = 1.49764
I0521 21:57:18.372822 12468 solver.cpp:253]     Train net output #0: loss = 1.49764 (* 1 = 1.49764 loss)
I0521 21:57:18.372835 12468 sgd_solver.cpp:106] Iteration 277500, lr = 0.0005
I0521 21:57:30.509481 12468 solver.cpp:237] Iteration 278250, loss = 1.32459
I0521 21:57:30.509529 12468 solver.cpp:253]     Train net output #0: loss = 1.32459 (* 1 = 1.32459 loss)
I0521 21:57:30.509546 12468 sgd_solver.cpp:106] Iteration 278250, lr = 0.0005
I0521 21:57:42.702697 12468 solver.cpp:237] Iteration 279000, loss = 1.24698
I0521 21:57:42.702734 12468 solver.cpp:253]     Train net output #0: loss = 1.24698 (* 1 = 1.24698 loss)
I0521 21:57:42.702750 12468 sgd_solver.cpp:106] Iteration 279000, lr = 0.0005
I0521 21:57:54.892889 12468 solver.cpp:237] Iteration 279750, loss = 0.847302
I0521 21:57:54.893076 12468 solver.cpp:253]     Train net output #0: loss = 0.847299 (* 1 = 0.847299 loss)
I0521 21:57:54.893090 12468 sgd_solver.cpp:106] Iteration 279750, lr = 0.0005
I0521 21:58:27.885772 12468 solver.cpp:237] Iteration 280500, loss = 0.993184
I0521 21:58:27.885965 12468 solver.cpp:253]     Train net output #0: loss = 0.993181 (* 1 = 0.993181 loss)
I0521 21:58:27.885982 12468 sgd_solver.cpp:106] Iteration 280500, lr = 0.0005
I0521 21:58:40.006459 12468 solver.cpp:237] Iteration 281250, loss = 1.46491
I0521 21:58:40.006495 12468 solver.cpp:253]     Train net output #0: loss = 1.46491 (* 1 = 1.46491 loss)
I0521 21:58:40.006512 12468 sgd_solver.cpp:106] Iteration 281250, lr = 0.0005
I0521 21:58:52.131904 12468 solver.cpp:237] Iteration 282000, loss = 1.37502
I0521 21:58:52.131948 12468 solver.cpp:253]     Train net output #0: loss = 1.37502 (* 1 = 1.37502 loss)
I0521 21:58:52.131963 12468 sgd_solver.cpp:106] Iteration 282000, lr = 0.0005
I0521 21:59:04.253345 12468 solver.cpp:237] Iteration 282750, loss = 0.883091
I0521 21:59:04.253526 12468 solver.cpp:253]     Train net output #0: loss = 0.883088 (* 1 = 0.883088 loss)
I0521 21:59:04.253540 12468 sgd_solver.cpp:106] Iteration 282750, lr = 0.0005
I0521 21:59:16.351912 12468 solver.cpp:237] Iteration 283500, loss = 1.19043
I0521 21:59:16.351958 12468 solver.cpp:253]     Train net output #0: loss = 1.19043 (* 1 = 1.19043 loss)
I0521 21:59:16.351971 12468 sgd_solver.cpp:106] Iteration 283500, lr = 0.0005
I0521 21:59:28.458943 12468 solver.cpp:237] Iteration 284250, loss = 1.3034
I0521 21:59:28.458979 12468 solver.cpp:253]     Train net output #0: loss = 1.3034 (* 1 = 1.3034 loss)
I0521 21:59:28.458995 12468 sgd_solver.cpp:106] Iteration 284250, lr = 0.0005
I0521 21:59:40.579993 12468 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_285000.caffemodel
I0521 21:59:40.629286 12468 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0005_2016-05-20T15.48.53.207147_iter_285000.solverstate
I0521 21:59:40.655140 12468 solver.cpp:341] Iteration 285000, Testing net (#0)
I0521 22:00:32.342022 12468 solver.cpp:409]     Test net output #0: accuracy = 0.89009
I0521 22:00:32.342211 12468 solver.cpp:409]     Test net output #1: loss = 0.355921 (* 1 = 0.355921 loss)
I0521 22:00:53.227521 12468 solver.cpp:237] Iteration 285000, loss = 1.38159
I0521 22:00:53.227574 12468 solver.cpp:253]     Train net output #0: loss = 1.38158 (* 1 = 1.38158 loss)
I0521 22:00:53.227592 12468 sgd_solver.cpp:106] Iteration 285000, lr = 0.0005
I0521 22:01:05.293848 12468 solver.cpp:237] Iteration 285750, loss = 1.44339
I0521 22:01:05.294024 12468 solver.cpp:253]     Train net output #0: loss = 1.44339 (* 1 = 1.44339 loss)
I0521 22:01:05.294040 12468 sgd_solver.cpp:106] Iteration 285750, lr = 0.0005
I0521 22:01:17.388115 12468 solver.cpp:237] Iteration 286500, loss = 1.10782
I0521 22:01:17.388164 12468 solver.cpp:253]     Train net output #0: loss = 1.10782 (* 1 = 1.10782 loss)
I0521 22:01:17.388180 12468 sgd_solver.cpp:106] Iteration 286500, lr = 0.0005
I0521 22:01:29.543553 12468 solver.cpp:237] Iteration 287250, loss = 1.16557
I0521 22:01:29.543589 12468 solver.cpp:253]     Train net output #0: loss = 1.16557 (* 1 = 1.16557 loss)
I0521 22:01:29.543606 12468 sgd_solver.cpp:106] Iteration 287250, lr = 0.0005
I0521 22:01:41.669464 12468 solver.cpp:237] Iteration 288000, loss = 0.984293
I0521 22:01:41.669646 12468 solver.cpp:253]     Train net output #0: loss = 0.98429 (* 1 = 0.98429 loss)
I0521 22:01:41.669661 12468 sgd_solver.cpp:106] Iteration 288000, lr = 0.0005
I0521 22:01:53.785806 12468 solver.cpp:237] Iteration 288750, loss = 1.18975
I0521 22:01:53.785843 12468 solver.cpp:253]     Train net output #0: loss = 1.18974 (* 1 = 1.18974 loss)
I0521 22:01:53.785859 12468 sgd_solver.cpp:106] Iteration 288750, lr = 0.0005
I0521 22:02:05.941715 12468 solver.cpp:237] Iteration 289500, loss = 0.797243
I0521 22:02:05.941766 12468 solver.cpp:253]     Train net output #0: loss = 0.79724 (* 1 = 0.79724 loss)
I0521 22:02:05.941779 12468 sgd_solver.cpp:106] Iteration 289500, lr = 0.0005
aprun: Apid 11241526: Caught signal Terminated, sending to application
*** Aborted at 1463882554 (unix time) try "date -d @1463882554" if you are using GNU date ***
PC: @     0x2aaab7f0d263 __GI_memcpy
=>> PBS: job killed: walltime 7206 exceeded limit 7200
*** SIGTERM (@0x30b1) received by PID 12468 (TID 0x2aaac746f900) from PID 12465; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab7f0d263 __GI_memcpy
aprun: Apid 11241526: Caught signal Terminated, sending to application
    @     0x2aaab144ca16 H5VM_memcpyvv
aprun: Apid 11241526: Caught signal Terminated, sending to application
    @     0x2aaab12905af H5D__compact_readvv
    @     0x2aaab12a3143 H5D__select_io
    @     0x2aaab12a38cd H5D__select_read
    @     0x2aaab128be3d H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11241526: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11241526: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11241526: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
aprun: Apid 11241526: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02350] [c6-1c0s7n2] [Sat May 21 22:02:36 2016] PE RANK 0 exit signal Terminated
Application 11241526 exit codes: 143
Application 11241526 resources: utime ~6275s, stime ~922s, Rss ~5332952, inblocks ~13317181, outblocks ~592959
