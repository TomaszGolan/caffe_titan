2810756
I0525 16:56:31.256959 21434 caffe.cpp:184] Using GPUs 0
I0525 16:56:31.682165 21434 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.0025
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346.prototxt"
I0525 16:56:31.684063 21434 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346.prototxt
I0525 16:56:31.697428 21434 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 16:56:31.697487 21434 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 16:56:31.697830 21434 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 16:56:31.698012 21434 layer_factory.hpp:77] Creating layer data_hdf5
I0525 16:56:31.698036 21434 net.cpp:106] Creating Layer data_hdf5
I0525 16:56:31.698050 21434 net.cpp:411] data_hdf5 -> data
I0525 16:56:31.698083 21434 net.cpp:411] data_hdf5 -> label
I0525 16:56:31.698117 21434 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 16:56:31.699421 21434 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 16:56:31.701577 21434 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 16:56:53.192419 21434 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 16:56:53.197576 21434 net.cpp:150] Setting up data_hdf5
I0525 16:56:53.197615 21434 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 16:56:53.197630 21434 net.cpp:157] Top shape: 100 (100)
I0525 16:56:53.197643 21434 net.cpp:165] Memory required for data: 2540400
I0525 16:56:53.197657 21434 layer_factory.hpp:77] Creating layer conv1
I0525 16:56:53.197690 21434 net.cpp:106] Creating Layer conv1
I0525 16:56:53.197701 21434 net.cpp:454] conv1 <- data
I0525 16:56:53.197721 21434 net.cpp:411] conv1 -> conv1
I0525 16:56:53.575520 21434 net.cpp:150] Setting up conv1
I0525 16:56:53.575567 21434 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 16:56:53.575577 21434 net.cpp:165] Memory required for data: 30188400
I0525 16:56:53.575605 21434 layer_factory.hpp:77] Creating layer relu1
I0525 16:56:53.575628 21434 net.cpp:106] Creating Layer relu1
I0525 16:56:53.575639 21434 net.cpp:454] relu1 <- conv1
I0525 16:56:53.575651 21434 net.cpp:397] relu1 -> conv1 (in-place)
I0525 16:56:53.576164 21434 net.cpp:150] Setting up relu1
I0525 16:56:53.576181 21434 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 16:56:53.576192 21434 net.cpp:165] Memory required for data: 57836400
I0525 16:56:53.576202 21434 layer_factory.hpp:77] Creating layer pool1
I0525 16:56:53.576220 21434 net.cpp:106] Creating Layer pool1
I0525 16:56:53.576230 21434 net.cpp:454] pool1 <- conv1
I0525 16:56:53.576243 21434 net.cpp:411] pool1 -> pool1
I0525 16:56:53.576323 21434 net.cpp:150] Setting up pool1
I0525 16:56:53.576338 21434 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 16:56:53.576349 21434 net.cpp:165] Memory required for data: 71660400
I0525 16:56:53.576359 21434 layer_factory.hpp:77] Creating layer conv2
I0525 16:56:53.576381 21434 net.cpp:106] Creating Layer conv2
I0525 16:56:53.576391 21434 net.cpp:454] conv2 <- pool1
I0525 16:56:53.576405 21434 net.cpp:411] conv2 -> conv2
I0525 16:56:53.579104 21434 net.cpp:150] Setting up conv2
I0525 16:56:53.579146 21434 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 16:56:53.579157 21434 net.cpp:165] Memory required for data: 91532400
I0525 16:56:53.579179 21434 layer_factory.hpp:77] Creating layer relu2
I0525 16:56:53.579191 21434 net.cpp:106] Creating Layer relu2
I0525 16:56:53.579202 21434 net.cpp:454] relu2 <- conv2
I0525 16:56:53.579216 21434 net.cpp:397] relu2 -> conv2 (in-place)
I0525 16:56:53.579547 21434 net.cpp:150] Setting up relu2
I0525 16:56:53.579561 21434 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 16:56:53.579572 21434 net.cpp:165] Memory required for data: 111404400
I0525 16:56:53.579582 21434 layer_factory.hpp:77] Creating layer pool2
I0525 16:56:53.579594 21434 net.cpp:106] Creating Layer pool2
I0525 16:56:53.579604 21434 net.cpp:454] pool2 <- conv2
I0525 16:56:53.579617 21434 net.cpp:411] pool2 -> pool2
I0525 16:56:53.579699 21434 net.cpp:150] Setting up pool2
I0525 16:56:53.579712 21434 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 16:56:53.579722 21434 net.cpp:165] Memory required for data: 121340400
I0525 16:56:53.579730 21434 layer_factory.hpp:77] Creating layer conv3
I0525 16:56:53.579748 21434 net.cpp:106] Creating Layer conv3
I0525 16:56:53.579759 21434 net.cpp:454] conv3 <- pool2
I0525 16:56:53.579772 21434 net.cpp:411] conv3 -> conv3
I0525 16:56:53.581694 21434 net.cpp:150] Setting up conv3
I0525 16:56:53.581717 21434 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 16:56:53.581730 21434 net.cpp:165] Memory required for data: 132182000
I0525 16:56:53.581748 21434 layer_factory.hpp:77] Creating layer relu3
I0525 16:56:53.581764 21434 net.cpp:106] Creating Layer relu3
I0525 16:56:53.581774 21434 net.cpp:454] relu3 <- conv3
I0525 16:56:53.581787 21434 net.cpp:397] relu3 -> conv3 (in-place)
I0525 16:56:53.582257 21434 net.cpp:150] Setting up relu3
I0525 16:56:53.582274 21434 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 16:56:53.582284 21434 net.cpp:165] Memory required for data: 143023600
I0525 16:56:53.582294 21434 layer_factory.hpp:77] Creating layer pool3
I0525 16:56:53.582307 21434 net.cpp:106] Creating Layer pool3
I0525 16:56:53.582317 21434 net.cpp:454] pool3 <- conv3
I0525 16:56:53.582330 21434 net.cpp:411] pool3 -> pool3
I0525 16:56:53.582397 21434 net.cpp:150] Setting up pool3
I0525 16:56:53.582411 21434 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 16:56:53.582420 21434 net.cpp:165] Memory required for data: 148444400
I0525 16:56:53.582428 21434 layer_factory.hpp:77] Creating layer conv4
I0525 16:56:53.582445 21434 net.cpp:106] Creating Layer conv4
I0525 16:56:53.582456 21434 net.cpp:454] conv4 <- pool3
I0525 16:56:53.582469 21434 net.cpp:411] conv4 -> conv4
I0525 16:56:53.585400 21434 net.cpp:150] Setting up conv4
I0525 16:56:53.585424 21434 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 16:56:53.585436 21434 net.cpp:165] Memory required for data: 152073200
I0525 16:56:53.585451 21434 layer_factory.hpp:77] Creating layer relu4
I0525 16:56:53.585465 21434 net.cpp:106] Creating Layer relu4
I0525 16:56:53.585475 21434 net.cpp:454] relu4 <- conv4
I0525 16:56:53.585489 21434 net.cpp:397] relu4 -> conv4 (in-place)
I0525 16:56:53.585952 21434 net.cpp:150] Setting up relu4
I0525 16:56:53.585968 21434 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 16:56:53.585979 21434 net.cpp:165] Memory required for data: 155702000
I0525 16:56:53.585989 21434 layer_factory.hpp:77] Creating layer pool4
I0525 16:56:53.586001 21434 net.cpp:106] Creating Layer pool4
I0525 16:56:53.586011 21434 net.cpp:454] pool4 <- conv4
I0525 16:56:53.586024 21434 net.cpp:411] pool4 -> pool4
I0525 16:56:53.586092 21434 net.cpp:150] Setting up pool4
I0525 16:56:53.586107 21434 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 16:56:53.586115 21434 net.cpp:165] Memory required for data: 157516400
I0525 16:56:53.586125 21434 layer_factory.hpp:77] Creating layer ip1
I0525 16:56:53.586145 21434 net.cpp:106] Creating Layer ip1
I0525 16:56:53.586155 21434 net.cpp:454] ip1 <- pool4
I0525 16:56:53.586169 21434 net.cpp:411] ip1 -> ip1
I0525 16:56:53.601554 21434 net.cpp:150] Setting up ip1
I0525 16:56:53.601583 21434 net.cpp:157] Top shape: 100 196 (19600)
I0525 16:56:53.601594 21434 net.cpp:165] Memory required for data: 157594800
I0525 16:56:53.601616 21434 layer_factory.hpp:77] Creating layer relu5
I0525 16:56:53.601630 21434 net.cpp:106] Creating Layer relu5
I0525 16:56:53.601640 21434 net.cpp:454] relu5 <- ip1
I0525 16:56:53.601655 21434 net.cpp:397] relu5 -> ip1 (in-place)
I0525 16:56:53.601995 21434 net.cpp:150] Setting up relu5
I0525 16:56:53.602010 21434 net.cpp:157] Top shape: 100 196 (19600)
I0525 16:56:53.602020 21434 net.cpp:165] Memory required for data: 157673200
I0525 16:56:53.602030 21434 layer_factory.hpp:77] Creating layer drop1
I0525 16:56:53.602051 21434 net.cpp:106] Creating Layer drop1
I0525 16:56:53.602061 21434 net.cpp:454] drop1 <- ip1
I0525 16:56:53.602073 21434 net.cpp:397] drop1 -> ip1 (in-place)
I0525 16:56:53.602131 21434 net.cpp:150] Setting up drop1
I0525 16:56:53.602145 21434 net.cpp:157] Top shape: 100 196 (19600)
I0525 16:56:53.602155 21434 net.cpp:165] Memory required for data: 157751600
I0525 16:56:53.602164 21434 layer_factory.hpp:77] Creating layer ip2
I0525 16:56:53.602183 21434 net.cpp:106] Creating Layer ip2
I0525 16:56:53.602193 21434 net.cpp:454] ip2 <- ip1
I0525 16:56:53.602206 21434 net.cpp:411] ip2 -> ip2
I0525 16:56:53.602670 21434 net.cpp:150] Setting up ip2
I0525 16:56:53.602684 21434 net.cpp:157] Top shape: 100 98 (9800)
I0525 16:56:53.602694 21434 net.cpp:165] Memory required for data: 157790800
I0525 16:56:53.602708 21434 layer_factory.hpp:77] Creating layer relu6
I0525 16:56:53.602722 21434 net.cpp:106] Creating Layer relu6
I0525 16:56:53.602731 21434 net.cpp:454] relu6 <- ip2
I0525 16:56:53.602743 21434 net.cpp:397] relu6 -> ip2 (in-place)
I0525 16:56:53.603272 21434 net.cpp:150] Setting up relu6
I0525 16:56:53.603288 21434 net.cpp:157] Top shape: 100 98 (9800)
I0525 16:56:53.603298 21434 net.cpp:165] Memory required for data: 157830000
I0525 16:56:53.603308 21434 layer_factory.hpp:77] Creating layer drop2
I0525 16:56:53.603322 21434 net.cpp:106] Creating Layer drop2
I0525 16:56:53.603332 21434 net.cpp:454] drop2 <- ip2
I0525 16:56:53.603344 21434 net.cpp:397] drop2 -> ip2 (in-place)
I0525 16:56:53.603386 21434 net.cpp:150] Setting up drop2
I0525 16:56:53.603399 21434 net.cpp:157] Top shape: 100 98 (9800)
I0525 16:56:53.603410 21434 net.cpp:165] Memory required for data: 157869200
I0525 16:56:53.603420 21434 layer_factory.hpp:77] Creating layer ip3
I0525 16:56:53.603432 21434 net.cpp:106] Creating Layer ip3
I0525 16:56:53.603443 21434 net.cpp:454] ip3 <- ip2
I0525 16:56:53.603456 21434 net.cpp:411] ip3 -> ip3
I0525 16:56:53.603664 21434 net.cpp:150] Setting up ip3
I0525 16:56:53.603677 21434 net.cpp:157] Top shape: 100 11 (1100)
I0525 16:56:53.603688 21434 net.cpp:165] Memory required for data: 157873600
I0525 16:56:53.603703 21434 layer_factory.hpp:77] Creating layer drop3
I0525 16:56:53.603715 21434 net.cpp:106] Creating Layer drop3
I0525 16:56:53.603725 21434 net.cpp:454] drop3 <- ip3
I0525 16:56:53.603736 21434 net.cpp:397] drop3 -> ip3 (in-place)
I0525 16:56:53.603776 21434 net.cpp:150] Setting up drop3
I0525 16:56:53.603788 21434 net.cpp:157] Top shape: 100 11 (1100)
I0525 16:56:53.603799 21434 net.cpp:165] Memory required for data: 157878000
I0525 16:56:53.603809 21434 layer_factory.hpp:77] Creating layer loss
I0525 16:56:53.603828 21434 net.cpp:106] Creating Layer loss
I0525 16:56:53.603837 21434 net.cpp:454] loss <- ip3
I0525 16:56:53.603847 21434 net.cpp:454] loss <- label
I0525 16:56:53.603860 21434 net.cpp:411] loss -> loss
I0525 16:56:53.603878 21434 layer_factory.hpp:77] Creating layer loss
I0525 16:56:53.604516 21434 net.cpp:150] Setting up loss
I0525 16:56:53.604537 21434 net.cpp:157] Top shape: (1)
I0525 16:56:53.604549 21434 net.cpp:160]     with loss weight 1
I0525 16:56:53.604593 21434 net.cpp:165] Memory required for data: 157878004
I0525 16:56:53.604605 21434 net.cpp:226] loss needs backward computation.
I0525 16:56:53.604616 21434 net.cpp:226] drop3 needs backward computation.
I0525 16:56:53.604626 21434 net.cpp:226] ip3 needs backward computation.
I0525 16:56:53.604637 21434 net.cpp:226] drop2 needs backward computation.
I0525 16:56:53.604647 21434 net.cpp:226] relu6 needs backward computation.
I0525 16:56:53.604657 21434 net.cpp:226] ip2 needs backward computation.
I0525 16:56:53.604667 21434 net.cpp:226] drop1 needs backward computation.
I0525 16:56:53.604677 21434 net.cpp:226] relu5 needs backward computation.
I0525 16:56:53.604686 21434 net.cpp:226] ip1 needs backward computation.
I0525 16:56:53.604697 21434 net.cpp:226] pool4 needs backward computation.
I0525 16:56:53.604707 21434 net.cpp:226] relu4 needs backward computation.
I0525 16:56:53.604717 21434 net.cpp:226] conv4 needs backward computation.
I0525 16:56:53.604727 21434 net.cpp:226] pool3 needs backward computation.
I0525 16:56:53.604738 21434 net.cpp:226] relu3 needs backward computation.
I0525 16:56:53.604756 21434 net.cpp:226] conv3 needs backward computation.
I0525 16:56:53.604768 21434 net.cpp:226] pool2 needs backward computation.
I0525 16:56:53.604779 21434 net.cpp:226] relu2 needs backward computation.
I0525 16:56:53.604789 21434 net.cpp:226] conv2 needs backward computation.
I0525 16:56:53.604800 21434 net.cpp:226] pool1 needs backward computation.
I0525 16:56:53.604810 21434 net.cpp:226] relu1 needs backward computation.
I0525 16:56:53.604820 21434 net.cpp:226] conv1 needs backward computation.
I0525 16:56:53.604832 21434 net.cpp:228] data_hdf5 does not need backward computation.
I0525 16:56:53.604841 21434 net.cpp:270] This network produces output loss
I0525 16:56:53.604866 21434 net.cpp:283] Network initialization done.
I0525 16:56:53.606626 21434 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346.prototxt
I0525 16:56:53.606698 21434 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 16:56:53.607053 21434 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 16:56:53.607256 21434 layer_factory.hpp:77] Creating layer data_hdf5
I0525 16:56:53.607271 21434 net.cpp:106] Creating Layer data_hdf5
I0525 16:56:53.607283 21434 net.cpp:411] data_hdf5 -> data
I0525 16:56:53.607300 21434 net.cpp:411] data_hdf5 -> label
I0525 16:56:53.607316 21434 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 16:56:53.608705 21434 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 16:57:14.944720 21434 net.cpp:150] Setting up data_hdf5
I0525 16:57:14.944887 21434 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 16:57:14.944902 21434 net.cpp:157] Top shape: 100 (100)
I0525 16:57:14.944914 21434 net.cpp:165] Memory required for data: 2540400
I0525 16:57:14.944928 21434 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 16:57:14.944957 21434 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 16:57:14.944968 21434 net.cpp:454] label_data_hdf5_1_split <- label
I0525 16:57:14.944983 21434 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 16:57:14.945004 21434 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 16:57:14.945077 21434 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 16:57:14.945092 21434 net.cpp:157] Top shape: 100 (100)
I0525 16:57:14.945103 21434 net.cpp:157] Top shape: 100 (100)
I0525 16:57:14.945113 21434 net.cpp:165] Memory required for data: 2541200
I0525 16:57:14.945123 21434 layer_factory.hpp:77] Creating layer conv1
I0525 16:57:14.945142 21434 net.cpp:106] Creating Layer conv1
I0525 16:57:14.945153 21434 net.cpp:454] conv1 <- data
I0525 16:57:14.945168 21434 net.cpp:411] conv1 -> conv1
I0525 16:57:14.947131 21434 net.cpp:150] Setting up conv1
I0525 16:57:14.947154 21434 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 16:57:14.947167 21434 net.cpp:165] Memory required for data: 30189200
I0525 16:57:14.947187 21434 layer_factory.hpp:77] Creating layer relu1
I0525 16:57:14.947201 21434 net.cpp:106] Creating Layer relu1
I0525 16:57:14.947211 21434 net.cpp:454] relu1 <- conv1
I0525 16:57:14.947224 21434 net.cpp:397] relu1 -> conv1 (in-place)
I0525 16:57:14.947723 21434 net.cpp:150] Setting up relu1
I0525 16:57:14.947739 21434 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 16:57:14.947749 21434 net.cpp:165] Memory required for data: 57837200
I0525 16:57:14.947759 21434 layer_factory.hpp:77] Creating layer pool1
I0525 16:57:14.947775 21434 net.cpp:106] Creating Layer pool1
I0525 16:57:14.947785 21434 net.cpp:454] pool1 <- conv1
I0525 16:57:14.947798 21434 net.cpp:411] pool1 -> pool1
I0525 16:57:14.947873 21434 net.cpp:150] Setting up pool1
I0525 16:57:14.947887 21434 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 16:57:14.947897 21434 net.cpp:165] Memory required for data: 71661200
I0525 16:57:14.947907 21434 layer_factory.hpp:77] Creating layer conv2
I0525 16:57:14.947926 21434 net.cpp:106] Creating Layer conv2
I0525 16:57:14.947935 21434 net.cpp:454] conv2 <- pool1
I0525 16:57:14.947948 21434 net.cpp:411] conv2 -> conv2
I0525 16:57:14.949862 21434 net.cpp:150] Setting up conv2
I0525 16:57:14.949884 21434 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 16:57:14.949898 21434 net.cpp:165] Memory required for data: 91533200
I0525 16:57:14.949914 21434 layer_factory.hpp:77] Creating layer relu2
I0525 16:57:14.949928 21434 net.cpp:106] Creating Layer relu2
I0525 16:57:14.949939 21434 net.cpp:454] relu2 <- conv2
I0525 16:57:14.949951 21434 net.cpp:397] relu2 -> conv2 (in-place)
I0525 16:57:14.950286 21434 net.cpp:150] Setting up relu2
I0525 16:57:14.950300 21434 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 16:57:14.950310 21434 net.cpp:165] Memory required for data: 111405200
I0525 16:57:14.950320 21434 layer_factory.hpp:77] Creating layer pool2
I0525 16:57:14.950335 21434 net.cpp:106] Creating Layer pool2
I0525 16:57:14.950345 21434 net.cpp:454] pool2 <- conv2
I0525 16:57:14.950356 21434 net.cpp:411] pool2 -> pool2
I0525 16:57:14.950428 21434 net.cpp:150] Setting up pool2
I0525 16:57:14.950443 21434 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 16:57:14.950451 21434 net.cpp:165] Memory required for data: 121341200
I0525 16:57:14.950461 21434 layer_factory.hpp:77] Creating layer conv3
I0525 16:57:14.950481 21434 net.cpp:106] Creating Layer conv3
I0525 16:57:14.950491 21434 net.cpp:454] conv3 <- pool2
I0525 16:57:14.950505 21434 net.cpp:411] conv3 -> conv3
I0525 16:57:14.952494 21434 net.cpp:150] Setting up conv3
I0525 16:57:14.952512 21434 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 16:57:14.952527 21434 net.cpp:165] Memory required for data: 132182800
I0525 16:57:14.952560 21434 layer_factory.hpp:77] Creating layer relu3
I0525 16:57:14.952574 21434 net.cpp:106] Creating Layer relu3
I0525 16:57:14.952584 21434 net.cpp:454] relu3 <- conv3
I0525 16:57:14.952594 21434 net.cpp:397] relu3 -> conv3 (in-place)
I0525 16:57:14.953065 21434 net.cpp:150] Setting up relu3
I0525 16:57:14.953081 21434 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 16:57:14.953090 21434 net.cpp:165] Memory required for data: 143024400
I0525 16:57:14.953100 21434 layer_factory.hpp:77] Creating layer pool3
I0525 16:57:14.953114 21434 net.cpp:106] Creating Layer pool3
I0525 16:57:14.953124 21434 net.cpp:454] pool3 <- conv3
I0525 16:57:14.953136 21434 net.cpp:411] pool3 -> pool3
I0525 16:57:14.953207 21434 net.cpp:150] Setting up pool3
I0525 16:57:14.953220 21434 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 16:57:14.953230 21434 net.cpp:165] Memory required for data: 148445200
I0525 16:57:14.953240 21434 layer_factory.hpp:77] Creating layer conv4
I0525 16:57:14.953255 21434 net.cpp:106] Creating Layer conv4
I0525 16:57:14.953266 21434 net.cpp:454] conv4 <- pool3
I0525 16:57:14.953280 21434 net.cpp:411] conv4 -> conv4
I0525 16:57:14.955359 21434 net.cpp:150] Setting up conv4
I0525 16:57:14.955380 21434 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 16:57:14.955394 21434 net.cpp:165] Memory required for data: 152074000
I0525 16:57:14.955410 21434 layer_factory.hpp:77] Creating layer relu4
I0525 16:57:14.955422 21434 net.cpp:106] Creating Layer relu4
I0525 16:57:14.955432 21434 net.cpp:454] relu4 <- conv4
I0525 16:57:14.955446 21434 net.cpp:397] relu4 -> conv4 (in-place)
I0525 16:57:14.955916 21434 net.cpp:150] Setting up relu4
I0525 16:57:14.955932 21434 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 16:57:14.955942 21434 net.cpp:165] Memory required for data: 155702800
I0525 16:57:14.955952 21434 layer_factory.hpp:77] Creating layer pool4
I0525 16:57:14.955965 21434 net.cpp:106] Creating Layer pool4
I0525 16:57:14.955976 21434 net.cpp:454] pool4 <- conv4
I0525 16:57:14.955988 21434 net.cpp:411] pool4 -> pool4
I0525 16:57:14.956059 21434 net.cpp:150] Setting up pool4
I0525 16:57:14.956073 21434 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 16:57:14.956082 21434 net.cpp:165] Memory required for data: 157517200
I0525 16:57:14.956091 21434 layer_factory.hpp:77] Creating layer ip1
I0525 16:57:14.956105 21434 net.cpp:106] Creating Layer ip1
I0525 16:57:14.956116 21434 net.cpp:454] ip1 <- pool4
I0525 16:57:14.956130 21434 net.cpp:411] ip1 -> ip1
I0525 16:57:14.971581 21434 net.cpp:150] Setting up ip1
I0525 16:57:14.971608 21434 net.cpp:157] Top shape: 100 196 (19600)
I0525 16:57:14.971621 21434 net.cpp:165] Memory required for data: 157595600
I0525 16:57:14.971643 21434 layer_factory.hpp:77] Creating layer relu5
I0525 16:57:14.971657 21434 net.cpp:106] Creating Layer relu5
I0525 16:57:14.971668 21434 net.cpp:454] relu5 <- ip1
I0525 16:57:14.971681 21434 net.cpp:397] relu5 -> ip1 (in-place)
I0525 16:57:14.972030 21434 net.cpp:150] Setting up relu5
I0525 16:57:14.972043 21434 net.cpp:157] Top shape: 100 196 (19600)
I0525 16:57:14.972054 21434 net.cpp:165] Memory required for data: 157674000
I0525 16:57:14.972064 21434 layer_factory.hpp:77] Creating layer drop1
I0525 16:57:14.972082 21434 net.cpp:106] Creating Layer drop1
I0525 16:57:14.972091 21434 net.cpp:454] drop1 <- ip1
I0525 16:57:14.972105 21434 net.cpp:397] drop1 -> ip1 (in-place)
I0525 16:57:14.972149 21434 net.cpp:150] Setting up drop1
I0525 16:57:14.972162 21434 net.cpp:157] Top shape: 100 196 (19600)
I0525 16:57:14.972172 21434 net.cpp:165] Memory required for data: 157752400
I0525 16:57:14.972180 21434 layer_factory.hpp:77] Creating layer ip2
I0525 16:57:14.972195 21434 net.cpp:106] Creating Layer ip2
I0525 16:57:14.972205 21434 net.cpp:454] ip2 <- ip1
I0525 16:57:14.972218 21434 net.cpp:411] ip2 -> ip2
I0525 16:57:14.972697 21434 net.cpp:150] Setting up ip2
I0525 16:57:14.972712 21434 net.cpp:157] Top shape: 100 98 (9800)
I0525 16:57:14.972720 21434 net.cpp:165] Memory required for data: 157791600
I0525 16:57:14.972736 21434 layer_factory.hpp:77] Creating layer relu6
I0525 16:57:14.972761 21434 net.cpp:106] Creating Layer relu6
I0525 16:57:14.972771 21434 net.cpp:454] relu6 <- ip2
I0525 16:57:14.972784 21434 net.cpp:397] relu6 -> ip2 (in-place)
I0525 16:57:14.973326 21434 net.cpp:150] Setting up relu6
I0525 16:57:14.973342 21434 net.cpp:157] Top shape: 100 98 (9800)
I0525 16:57:14.973352 21434 net.cpp:165] Memory required for data: 157830800
I0525 16:57:14.973362 21434 layer_factory.hpp:77] Creating layer drop2
I0525 16:57:14.973376 21434 net.cpp:106] Creating Layer drop2
I0525 16:57:14.973386 21434 net.cpp:454] drop2 <- ip2
I0525 16:57:14.973398 21434 net.cpp:397] drop2 -> ip2 (in-place)
I0525 16:57:14.973443 21434 net.cpp:150] Setting up drop2
I0525 16:57:14.973455 21434 net.cpp:157] Top shape: 100 98 (9800)
I0525 16:57:14.973465 21434 net.cpp:165] Memory required for data: 157870000
I0525 16:57:14.973474 21434 layer_factory.hpp:77] Creating layer ip3
I0525 16:57:14.973489 21434 net.cpp:106] Creating Layer ip3
I0525 16:57:14.973498 21434 net.cpp:454] ip3 <- ip2
I0525 16:57:14.973511 21434 net.cpp:411] ip3 -> ip3
I0525 16:57:14.973737 21434 net.cpp:150] Setting up ip3
I0525 16:57:14.973749 21434 net.cpp:157] Top shape: 100 11 (1100)
I0525 16:57:14.973759 21434 net.cpp:165] Memory required for data: 157874400
I0525 16:57:14.973774 21434 layer_factory.hpp:77] Creating layer drop3
I0525 16:57:14.973788 21434 net.cpp:106] Creating Layer drop3
I0525 16:57:14.973798 21434 net.cpp:454] drop3 <- ip3
I0525 16:57:14.973810 21434 net.cpp:397] drop3 -> ip3 (in-place)
I0525 16:57:14.973852 21434 net.cpp:150] Setting up drop3
I0525 16:57:14.973865 21434 net.cpp:157] Top shape: 100 11 (1100)
I0525 16:57:14.973875 21434 net.cpp:165] Memory required for data: 157878800
I0525 16:57:14.973884 21434 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 16:57:14.973897 21434 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 16:57:14.973907 21434 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 16:57:14.973920 21434 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 16:57:14.973935 21434 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 16:57:14.974009 21434 net.cpp:150] Setting up ip3_drop3_0_split
I0525 16:57:14.974021 21434 net.cpp:157] Top shape: 100 11 (1100)
I0525 16:57:14.974033 21434 net.cpp:157] Top shape: 100 11 (1100)
I0525 16:57:14.974043 21434 net.cpp:165] Memory required for data: 157887600
I0525 16:57:14.974053 21434 layer_factory.hpp:77] Creating layer accuracy
I0525 16:57:14.974074 21434 net.cpp:106] Creating Layer accuracy
I0525 16:57:14.974084 21434 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 16:57:14.974095 21434 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 16:57:14.974109 21434 net.cpp:411] accuracy -> accuracy
I0525 16:57:14.974133 21434 net.cpp:150] Setting up accuracy
I0525 16:57:14.974144 21434 net.cpp:157] Top shape: (1)
I0525 16:57:14.974154 21434 net.cpp:165] Memory required for data: 157887604
I0525 16:57:14.974164 21434 layer_factory.hpp:77] Creating layer loss
I0525 16:57:14.974177 21434 net.cpp:106] Creating Layer loss
I0525 16:57:14.974189 21434 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 16:57:14.974200 21434 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 16:57:14.974212 21434 net.cpp:411] loss -> loss
I0525 16:57:14.974231 21434 layer_factory.hpp:77] Creating layer loss
I0525 16:57:14.974716 21434 net.cpp:150] Setting up loss
I0525 16:57:14.974730 21434 net.cpp:157] Top shape: (1)
I0525 16:57:14.974740 21434 net.cpp:160]     with loss weight 1
I0525 16:57:14.974761 21434 net.cpp:165] Memory required for data: 157887608
I0525 16:57:14.974771 21434 net.cpp:226] loss needs backward computation.
I0525 16:57:14.974781 21434 net.cpp:228] accuracy does not need backward computation.
I0525 16:57:14.974792 21434 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 16:57:14.974802 21434 net.cpp:226] drop3 needs backward computation.
I0525 16:57:14.974812 21434 net.cpp:226] ip3 needs backward computation.
I0525 16:57:14.974823 21434 net.cpp:226] drop2 needs backward computation.
I0525 16:57:14.974840 21434 net.cpp:226] relu6 needs backward computation.
I0525 16:57:14.974850 21434 net.cpp:226] ip2 needs backward computation.
I0525 16:57:14.974860 21434 net.cpp:226] drop1 needs backward computation.
I0525 16:57:14.974869 21434 net.cpp:226] relu5 needs backward computation.
I0525 16:57:14.974879 21434 net.cpp:226] ip1 needs backward computation.
I0525 16:57:14.974889 21434 net.cpp:226] pool4 needs backward computation.
I0525 16:57:14.974900 21434 net.cpp:226] relu4 needs backward computation.
I0525 16:57:14.974908 21434 net.cpp:226] conv4 needs backward computation.
I0525 16:57:14.974920 21434 net.cpp:226] pool3 needs backward computation.
I0525 16:57:14.974930 21434 net.cpp:226] relu3 needs backward computation.
I0525 16:57:14.974939 21434 net.cpp:226] conv3 needs backward computation.
I0525 16:57:14.974951 21434 net.cpp:226] pool2 needs backward computation.
I0525 16:57:14.974961 21434 net.cpp:226] relu2 needs backward computation.
I0525 16:57:14.974968 21434 net.cpp:226] conv2 needs backward computation.
I0525 16:57:14.974982 21434 net.cpp:226] pool1 needs backward computation.
I0525 16:57:14.974992 21434 net.cpp:226] relu1 needs backward computation.
I0525 16:57:14.975002 21434 net.cpp:226] conv1 needs backward computation.
I0525 16:57:14.975013 21434 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 16:57:14.975024 21434 net.cpp:228] data_hdf5 does not need backward computation.
I0525 16:57:14.975035 21434 net.cpp:270] This network produces output accuracy
I0525 16:57:14.975045 21434 net.cpp:270] This network produces output loss
I0525 16:57:14.975074 21434 net.cpp:283] Network initialization done.
I0525 16:57:14.975214 21434 solver.cpp:60] Solver scaffolding done.
I0525 16:57:14.976351 21434 caffe.cpp:212] Starting Optimization
I0525 16:57:14.976368 21434 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 16:57:14.976382 21434 solver.cpp:289] Learning Rate Policy: fixed
I0525 16:57:14.977447 21434 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 16:58:02.742962 21434 solver.cpp:409]     Test net output #0: accuracy = 0.0754866
I0525 16:58:02.743132 21434 solver.cpp:409]     Test net output #1: loss = 2.39789 (* 1 = 2.39789 loss)
I0525 16:58:02.776073 21434 solver.cpp:237] Iteration 0, loss = 2.39719
I0525 16:58:02.776110 21434 solver.cpp:253]     Train net output #0: loss = 2.39719 (* 1 = 2.39719 loss)
I0525 16:58:02.776129 21434 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0525 16:58:11.497881 21434 solver.cpp:237] Iteration 150, loss = 2.29951
I0525 16:58:11.497918 21434 solver.cpp:253]     Train net output #0: loss = 2.29951 (* 1 = 2.29951 loss)
I0525 16:58:11.497931 21434 sgd_solver.cpp:106] Iteration 150, lr = 0.0025
I0525 16:58:20.222198 21434 solver.cpp:237] Iteration 300, loss = 2.13881
I0525 16:58:20.222241 21434 solver.cpp:253]     Train net output #0: loss = 2.13881 (* 1 = 2.13881 loss)
I0525 16:58:20.222262 21434 sgd_solver.cpp:106] Iteration 300, lr = 0.0025
I0525 16:58:28.941339 21434 solver.cpp:237] Iteration 450, loss = 1.97586
I0525 16:58:28.941375 21434 solver.cpp:253]     Train net output #0: loss = 1.97586 (* 1 = 1.97586 loss)
I0525 16:58:28.941390 21434 sgd_solver.cpp:106] Iteration 450, lr = 0.0025
I0525 16:58:37.664333 21434 solver.cpp:237] Iteration 600, loss = 1.84197
I0525 16:58:37.664484 21434 solver.cpp:253]     Train net output #0: loss = 1.84197 (* 1 = 1.84197 loss)
I0525 16:58:37.664497 21434 sgd_solver.cpp:106] Iteration 600, lr = 0.0025
I0525 16:58:46.384769 21434 solver.cpp:237] Iteration 750, loss = 2.0235
I0525 16:58:46.384814 21434 solver.cpp:253]     Train net output #0: loss = 2.0235 (* 1 = 2.0235 loss)
I0525 16:58:46.384835 21434 sgd_solver.cpp:106] Iteration 750, lr = 0.0025
I0525 16:58:55.106763 21434 solver.cpp:237] Iteration 900, loss = 1.80741
I0525 16:58:55.106798 21434 solver.cpp:253]     Train net output #0: loss = 1.80741 (* 1 = 1.80741 loss)
I0525 16:58:55.106815 21434 sgd_solver.cpp:106] Iteration 900, lr = 0.0025
I0525 16:59:25.917553 21434 solver.cpp:237] Iteration 1050, loss = 1.83774
I0525 16:59:25.917717 21434 solver.cpp:253]     Train net output #0: loss = 1.83774 (* 1 = 1.83774 loss)
I0525 16:59:25.917732 21434 sgd_solver.cpp:106] Iteration 1050, lr = 0.0025
I0525 16:59:34.641459 21434 solver.cpp:237] Iteration 1200, loss = 1.66753
I0525 16:59:34.641499 21434 solver.cpp:253]     Train net output #0: loss = 1.66753 (* 1 = 1.66753 loss)
I0525 16:59:34.641520 21434 sgd_solver.cpp:106] Iteration 1200, lr = 0.0025
I0525 16:59:43.358911 21434 solver.cpp:237] Iteration 1350, loss = 1.80135
I0525 16:59:43.358945 21434 solver.cpp:253]     Train net output #0: loss = 1.80135 (* 1 = 1.80135 loss)
I0525 16:59:43.358963 21434 sgd_solver.cpp:106] Iteration 1350, lr = 0.0025
I0525 16:59:52.023947 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_1500.caffemodel
I0525 16:59:52.110410 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_1500.solverstate
I0525 16:59:52.157322 21434 solver.cpp:237] Iteration 1500, loss = 1.7091
I0525 16:59:52.157374 21434 solver.cpp:253]     Train net output #0: loss = 1.7091 (* 1 = 1.7091 loss)
I0525 16:59:52.157392 21434 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0525 17:00:00.881745 21434 solver.cpp:237] Iteration 1650, loss = 1.78965
I0525 17:00:00.881896 21434 solver.cpp:253]     Train net output #0: loss = 1.78965 (* 1 = 1.78965 loss)
I0525 17:00:00.881911 21434 sgd_solver.cpp:106] Iteration 1650, lr = 0.0025
I0525 17:00:09.605178 21434 solver.cpp:237] Iteration 1800, loss = 1.587
I0525 17:00:09.605211 21434 solver.cpp:253]     Train net output #0: loss = 1.587 (* 1 = 1.587 loss)
I0525 17:00:09.605229 21434 sgd_solver.cpp:106] Iteration 1800, lr = 0.0025
I0525 17:00:18.330513 21434 solver.cpp:237] Iteration 1950, loss = 1.74415
I0525 17:00:18.330546 21434 solver.cpp:253]     Train net output #0: loss = 1.74415 (* 1 = 1.74415 loss)
I0525 17:00:18.330564 21434 sgd_solver.cpp:106] Iteration 1950, lr = 0.0025
I0525 17:00:49.176570 21434 solver.cpp:237] Iteration 2100, loss = 1.70629
I0525 17:00:49.176731 21434 solver.cpp:253]     Train net output #0: loss = 1.70629 (* 1 = 1.70629 loss)
I0525 17:00:49.176748 21434 sgd_solver.cpp:106] Iteration 2100, lr = 0.0025
I0525 17:00:57.899963 21434 solver.cpp:237] Iteration 2250, loss = 1.81739
I0525 17:00:57.899999 21434 solver.cpp:253]     Train net output #0: loss = 1.81739 (* 1 = 1.81739 loss)
I0525 17:00:57.900017 21434 sgd_solver.cpp:106] Iteration 2250, lr = 0.0025
I0525 17:01:06.625767 21434 solver.cpp:237] Iteration 2400, loss = 1.72068
I0525 17:01:06.625802 21434 solver.cpp:253]     Train net output #0: loss = 1.72068 (* 1 = 1.72068 loss)
I0525 17:01:06.625818 21434 sgd_solver.cpp:106] Iteration 2400, lr = 0.0025
I0525 17:01:15.348883 21434 solver.cpp:237] Iteration 2550, loss = 1.56871
I0525 17:01:15.348930 21434 solver.cpp:253]     Train net output #0: loss = 1.56871 (* 1 = 1.56871 loss)
I0525 17:01:15.348951 21434 sgd_solver.cpp:106] Iteration 2550, lr = 0.0025
I0525 17:01:24.073016 21434 solver.cpp:237] Iteration 2700, loss = 1.69612
I0525 17:01:24.073165 21434 solver.cpp:253]     Train net output #0: loss = 1.69612 (* 1 = 1.69612 loss)
I0525 17:01:24.073179 21434 sgd_solver.cpp:106] Iteration 2700, lr = 0.0025
I0525 17:01:32.803613 21434 solver.cpp:237] Iteration 2850, loss = 1.69538
I0525 17:01:32.803647 21434 solver.cpp:253]     Train net output #0: loss = 1.69538 (* 1 = 1.69538 loss)
I0525 17:01:32.803665 21434 sgd_solver.cpp:106] Iteration 2850, lr = 0.0025
I0525 17:01:41.475884 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_3000.caffemodel
I0525 17:01:41.555979 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_3000.solverstate
I0525 17:01:41.583014 21434 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 17:02:28.386430 21434 solver.cpp:409]     Test net output #0: accuracy = 0.69204
I0525 17:02:28.386595 21434 solver.cpp:409]     Test net output #1: loss = 1.04466 (* 1 = 1.04466 loss)
I0525 17:02:50.531594 21434 solver.cpp:237] Iteration 3000, loss = 1.54316
I0525 17:02:50.531649 21434 solver.cpp:253]     Train net output #0: loss = 1.54316 (* 1 = 1.54316 loss)
I0525 17:02:50.531667 21434 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0525 17:02:59.268672 21434 solver.cpp:237] Iteration 3150, loss = 1.6432
I0525 17:02:59.268815 21434 solver.cpp:253]     Train net output #0: loss = 1.6432 (* 1 = 1.6432 loss)
I0525 17:02:59.268829 21434 sgd_solver.cpp:106] Iteration 3150, lr = 0.0025
I0525 17:03:08.008821 21434 solver.cpp:237] Iteration 3300, loss = 1.84005
I0525 17:03:08.008855 21434 solver.cpp:253]     Train net output #0: loss = 1.84005 (* 1 = 1.84005 loss)
I0525 17:03:08.008872 21434 sgd_solver.cpp:106] Iteration 3300, lr = 0.0025
I0525 17:03:16.746254 21434 solver.cpp:237] Iteration 3450, loss = 1.73313
I0525 17:03:16.746305 21434 solver.cpp:253]     Train net output #0: loss = 1.73313 (* 1 = 1.73313 loss)
I0525 17:03:16.746321 21434 sgd_solver.cpp:106] Iteration 3450, lr = 0.0025
I0525 17:03:25.481952 21434 solver.cpp:237] Iteration 3600, loss = 1.61799
I0525 17:03:25.481987 21434 solver.cpp:253]     Train net output #0: loss = 1.61799 (* 1 = 1.61799 loss)
I0525 17:03:25.482002 21434 sgd_solver.cpp:106] Iteration 3600, lr = 0.0025
I0525 17:03:34.218812 21434 solver.cpp:237] Iteration 3750, loss = 1.56188
I0525 17:03:34.218950 21434 solver.cpp:253]     Train net output #0: loss = 1.56188 (* 1 = 1.56188 loss)
I0525 17:03:34.218964 21434 sgd_solver.cpp:106] Iteration 3750, lr = 0.0025
I0525 17:03:42.956156 21434 solver.cpp:237] Iteration 3900, loss = 1.38977
I0525 17:03:42.956202 21434 solver.cpp:253]     Train net output #0: loss = 1.38977 (* 1 = 1.38977 loss)
I0525 17:03:42.956221 21434 sgd_solver.cpp:106] Iteration 3900, lr = 0.0025
I0525 17:04:13.807201 21434 solver.cpp:237] Iteration 4050, loss = 1.61936
I0525 17:04:13.807370 21434 solver.cpp:253]     Train net output #0: loss = 1.61936 (* 1 = 1.61936 loss)
I0525 17:04:13.807385 21434 sgd_solver.cpp:106] Iteration 4050, lr = 0.0025
I0525 17:04:22.548344 21434 solver.cpp:237] Iteration 4200, loss = 1.39503
I0525 17:04:22.548379 21434 solver.cpp:253]     Train net output #0: loss = 1.39503 (* 1 = 1.39503 loss)
I0525 17:04:22.548393 21434 sgd_solver.cpp:106] Iteration 4200, lr = 0.0025
I0525 17:04:31.282852 21434 solver.cpp:237] Iteration 4350, loss = 1.32549
I0525 17:04:31.282899 21434 solver.cpp:253]     Train net output #0: loss = 1.32549 (* 1 = 1.32549 loss)
I0525 17:04:31.282913 21434 sgd_solver.cpp:106] Iteration 4350, lr = 0.0025
I0525 17:04:39.960714 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_4500.caffemodel
I0525 17:04:40.042098 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_4500.solverstate
I0525 17:04:40.087963 21434 solver.cpp:237] Iteration 4500, loss = 1.51891
I0525 17:04:40.088016 21434 solver.cpp:253]     Train net output #0: loss = 1.51891 (* 1 = 1.51891 loss)
I0525 17:04:40.088033 21434 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0525 17:04:48.825399 21434 solver.cpp:237] Iteration 4650, loss = 1.53583
I0525 17:04:48.825551 21434 solver.cpp:253]     Train net output #0: loss = 1.53583 (* 1 = 1.53583 loss)
I0525 17:04:48.825564 21434 sgd_solver.cpp:106] Iteration 4650, lr = 0.0025
I0525 17:04:57.567502 21434 solver.cpp:237] Iteration 4800, loss = 1.51551
I0525 17:04:57.567543 21434 solver.cpp:253]     Train net output #0: loss = 1.51551 (* 1 = 1.51551 loss)
I0525 17:04:57.567564 21434 sgd_solver.cpp:106] Iteration 4800, lr = 0.0025
I0525 17:05:06.300505 21434 solver.cpp:237] Iteration 4950, loss = 1.40419
I0525 17:05:06.300540 21434 solver.cpp:253]     Train net output #0: loss = 1.40419 (* 1 = 1.40419 loss)
I0525 17:05:06.300557 21434 sgd_solver.cpp:106] Iteration 4950, lr = 0.0025
I0525 17:05:37.173564 21434 solver.cpp:237] Iteration 5100, loss = 1.37212
I0525 17:05:37.173732 21434 solver.cpp:253]     Train net output #0: loss = 1.37212 (* 1 = 1.37212 loss)
I0525 17:05:37.173748 21434 sgd_solver.cpp:106] Iteration 5100, lr = 0.0025
I0525 17:05:45.909489 21434 solver.cpp:237] Iteration 5250, loss = 1.37585
I0525 17:05:45.909534 21434 solver.cpp:253]     Train net output #0: loss = 1.37585 (* 1 = 1.37585 loss)
I0525 17:05:45.909555 21434 sgd_solver.cpp:106] Iteration 5250, lr = 0.0025
I0525 17:05:54.643543 21434 solver.cpp:237] Iteration 5400, loss = 1.36183
I0525 17:05:54.643579 21434 solver.cpp:253]     Train net output #0: loss = 1.36183 (* 1 = 1.36183 loss)
I0525 17:05:54.643595 21434 sgd_solver.cpp:106] Iteration 5400, lr = 0.0025
I0525 17:06:03.378371 21434 solver.cpp:237] Iteration 5550, loss = 1.55035
I0525 17:06:03.378407 21434 solver.cpp:253]     Train net output #0: loss = 1.55035 (* 1 = 1.55035 loss)
I0525 17:06:03.378422 21434 sgd_solver.cpp:106] Iteration 5550, lr = 0.0025
I0525 17:06:12.110430 21434 solver.cpp:237] Iteration 5700, loss = 1.4635
I0525 17:06:12.110563 21434 solver.cpp:253]     Train net output #0: loss = 1.4635 (* 1 = 1.4635 loss)
I0525 17:06:12.110577 21434 sgd_solver.cpp:106] Iteration 5700, lr = 0.0025
I0525 17:06:20.853981 21434 solver.cpp:237] Iteration 5850, loss = 1.29337
I0525 17:06:20.854014 21434 solver.cpp:253]     Train net output #0: loss = 1.29337 (* 1 = 1.29337 loss)
I0525 17:06:20.854029 21434 sgd_solver.cpp:106] Iteration 5850, lr = 0.0025
I0525 17:06:29.533395 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_6000.caffemodel
I0525 17:06:29.613704 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_6000.solverstate
I0525 17:06:29.642974 21434 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 17:07:37.284410 21434 solver.cpp:409]     Test net output #0: accuracy = 0.796595
I0525 17:07:37.284584 21434 solver.cpp:409]     Test net output #1: loss = 0.724717 (* 1 = 0.724717 loss)
I0525 17:07:59.462664 21434 solver.cpp:237] Iteration 6000, loss = 1.61414
I0525 17:07:59.462721 21434 solver.cpp:253]     Train net output #0: loss = 1.61414 (* 1 = 1.61414 loss)
I0525 17:07:59.462735 21434 sgd_solver.cpp:106] Iteration 6000, lr = 0.0025
I0525 17:08:08.195603 21434 solver.cpp:237] Iteration 6150, loss = 1.46631
I0525 17:08:08.195750 21434 solver.cpp:253]     Train net output #0: loss = 1.46631 (* 1 = 1.46631 loss)
I0525 17:08:08.195765 21434 sgd_solver.cpp:106] Iteration 6150, lr = 0.0025
I0525 17:08:16.929898 21434 solver.cpp:237] Iteration 6300, loss = 1.43669
I0525 17:08:16.929945 21434 solver.cpp:253]     Train net output #0: loss = 1.43669 (* 1 = 1.43669 loss)
I0525 17:08:16.929963 21434 sgd_solver.cpp:106] Iteration 6300, lr = 0.0025
I0525 17:08:25.664911 21434 solver.cpp:237] Iteration 6450, loss = 1.58745
I0525 17:08:25.664947 21434 solver.cpp:253]     Train net output #0: loss = 1.58745 (* 1 = 1.58745 loss)
I0525 17:08:25.664963 21434 sgd_solver.cpp:106] Iteration 6450, lr = 0.0025
I0525 17:08:34.392508 21434 solver.cpp:237] Iteration 6600, loss = 1.42931
I0525 17:08:34.392542 21434 solver.cpp:253]     Train net output #0: loss = 1.42931 (* 1 = 1.42931 loss)
I0525 17:08:34.392557 21434 sgd_solver.cpp:106] Iteration 6600, lr = 0.0025
I0525 17:08:43.130638 21434 solver.cpp:237] Iteration 6750, loss = 1.48807
I0525 17:08:43.130791 21434 solver.cpp:253]     Train net output #0: loss = 1.48807 (* 1 = 1.48807 loss)
I0525 17:08:43.130805 21434 sgd_solver.cpp:106] Iteration 6750, lr = 0.0025
I0525 17:08:51.862649 21434 solver.cpp:237] Iteration 6900, loss = 1.47771
I0525 17:08:51.862684 21434 solver.cpp:253]     Train net output #0: loss = 1.47771 (* 1 = 1.47771 loss)
I0525 17:08:51.862701 21434 sgd_solver.cpp:106] Iteration 6900, lr = 0.0025
I0525 17:09:22.748718 21434 solver.cpp:237] Iteration 7050, loss = 1.39887
I0525 17:09:22.748883 21434 solver.cpp:253]     Train net output #0: loss = 1.39887 (* 1 = 1.39887 loss)
I0525 17:09:22.748898 21434 sgd_solver.cpp:106] Iteration 7050, lr = 0.0025
I0525 17:09:31.483180 21434 solver.cpp:237] Iteration 7200, loss = 1.37445
I0525 17:09:31.483227 21434 solver.cpp:253]     Train net output #0: loss = 1.37445 (* 1 = 1.37445 loss)
I0525 17:09:31.483242 21434 sgd_solver.cpp:106] Iteration 7200, lr = 0.0025
I0525 17:09:40.215935 21434 solver.cpp:237] Iteration 7350, loss = 1.39834
I0525 17:09:40.215971 21434 solver.cpp:253]     Train net output #0: loss = 1.39834 (* 1 = 1.39834 loss)
I0525 17:09:40.215987 21434 sgd_solver.cpp:106] Iteration 7350, lr = 0.0025
I0525 17:09:48.896301 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_7500.caffemodel
I0525 17:09:48.976920 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_7500.solverstate
I0525 17:09:49.024180 21434 solver.cpp:237] Iteration 7500, loss = 1.36986
I0525 17:09:49.024232 21434 solver.cpp:253]     Train net output #0: loss = 1.36986 (* 1 = 1.36986 loss)
I0525 17:09:49.024248 21434 sgd_solver.cpp:106] Iteration 7500, lr = 0.0025
I0525 17:09:57.756732 21434 solver.cpp:237] Iteration 7650, loss = 1.28163
I0525 17:09:57.756886 21434 solver.cpp:253]     Train net output #0: loss = 1.28163 (* 1 = 1.28163 loss)
I0525 17:09:57.756901 21434 sgd_solver.cpp:106] Iteration 7650, lr = 0.0025
I0525 17:10:06.492524 21434 solver.cpp:237] Iteration 7800, loss = 1.27719
I0525 17:10:06.492559 21434 solver.cpp:253]     Train net output #0: loss = 1.27719 (* 1 = 1.27719 loss)
I0525 17:10:06.492576 21434 sgd_solver.cpp:106] Iteration 7800, lr = 0.0025
I0525 17:10:15.225709 21434 solver.cpp:237] Iteration 7950, loss = 1.39928
I0525 17:10:15.225744 21434 solver.cpp:253]     Train net output #0: loss = 1.39928 (* 1 = 1.39928 loss)
I0525 17:10:15.225760 21434 sgd_solver.cpp:106] Iteration 7950, lr = 0.0025
I0525 17:10:46.157244 21434 solver.cpp:237] Iteration 8100, loss = 1.39703
I0525 17:10:46.157418 21434 solver.cpp:253]     Train net output #0: loss = 1.39703 (* 1 = 1.39703 loss)
I0525 17:10:46.157433 21434 sgd_solver.cpp:106] Iteration 8100, lr = 0.0025
I0525 17:10:54.890549 21434 solver.cpp:237] Iteration 8250, loss = 1.30784
I0525 17:10:54.890584 21434 solver.cpp:253]     Train net output #0: loss = 1.30784 (* 1 = 1.30784 loss)
I0525 17:10:54.890602 21434 sgd_solver.cpp:106] Iteration 8250, lr = 0.0025
I0525 17:11:03.629456 21434 solver.cpp:237] Iteration 8400, loss = 1.49192
I0525 17:11:03.629492 21434 solver.cpp:253]     Train net output #0: loss = 1.49192 (* 1 = 1.49192 loss)
I0525 17:11:03.629506 21434 sgd_solver.cpp:106] Iteration 8400, lr = 0.0025
I0525 17:11:12.362978 21434 solver.cpp:237] Iteration 8550, loss = 1.3538
I0525 17:11:12.363023 21434 solver.cpp:253]     Train net output #0: loss = 1.3538 (* 1 = 1.3538 loss)
I0525 17:11:12.363042 21434 sgd_solver.cpp:106] Iteration 8550, lr = 0.0025
I0525 17:11:21.091524 21434 solver.cpp:237] Iteration 8700, loss = 1.50831
I0525 17:11:21.091665 21434 solver.cpp:253]     Train net output #0: loss = 1.50831 (* 1 = 1.50831 loss)
I0525 17:11:21.091677 21434 sgd_solver.cpp:106] Iteration 8700, lr = 0.0025
I0525 17:11:29.821575 21434 solver.cpp:237] Iteration 8850, loss = 1.2541
I0525 17:11:29.821609 21434 solver.cpp:253]     Train net output #0: loss = 1.2541 (* 1 = 1.2541 loss)
I0525 17:11:29.821626 21434 sgd_solver.cpp:106] Iteration 8850, lr = 0.0025
I0525 17:11:38.497242 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_9000.caffemodel
I0525 17:11:38.575458 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_9000.solverstate
I0525 17:11:38.601079 21434 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 17:12:25.068765 21434 solver.cpp:409]     Test net output #0: accuracy = 0.822514
I0525 17:12:25.068934 21434 solver.cpp:409]     Test net output #1: loss = 0.60155 (* 1 = 0.60155 loss)
I0525 17:12:47.243919 21434 solver.cpp:237] Iteration 9000, loss = 1.26653
I0525 17:12:47.243973 21434 solver.cpp:253]     Train net output #0: loss = 1.26653 (* 1 = 1.26653 loss)
I0525 17:12:47.243989 21434 sgd_solver.cpp:106] Iteration 9000, lr = 0.0025
I0525 17:12:55.979643 21434 solver.cpp:237] Iteration 9150, loss = 1.13104
I0525 17:12:55.979809 21434 solver.cpp:253]     Train net output #0: loss = 1.13104 (* 1 = 1.13104 loss)
I0525 17:12:55.979821 21434 sgd_solver.cpp:106] Iteration 9150, lr = 0.0025
I0525 17:13:04.711947 21434 solver.cpp:237] Iteration 9300, loss = 1.40403
I0525 17:13:04.711982 21434 solver.cpp:253]     Train net output #0: loss = 1.40403 (* 1 = 1.40403 loss)
I0525 17:13:04.711999 21434 sgd_solver.cpp:106] Iteration 9300, lr = 0.0025
I0525 17:13:13.455476 21434 solver.cpp:237] Iteration 9450, loss = 1.46554
I0525 17:13:13.455512 21434 solver.cpp:253]     Train net output #0: loss = 1.46554 (* 1 = 1.46554 loss)
I0525 17:13:13.455525 21434 sgd_solver.cpp:106] Iteration 9450, lr = 0.0025
I0525 17:13:22.189349 21434 solver.cpp:237] Iteration 9600, loss = 1.3356
I0525 17:13:22.189399 21434 solver.cpp:253]     Train net output #0: loss = 1.3356 (* 1 = 1.3356 loss)
I0525 17:13:22.189414 21434 sgd_solver.cpp:106] Iteration 9600, lr = 0.0025
I0525 17:13:30.920420 21434 solver.cpp:237] Iteration 9750, loss = 1.38824
I0525 17:13:30.920563 21434 solver.cpp:253]     Train net output #0: loss = 1.38824 (* 1 = 1.38824 loss)
I0525 17:13:30.920577 21434 sgd_solver.cpp:106] Iteration 9750, lr = 0.0025
I0525 17:13:39.653589 21434 solver.cpp:237] Iteration 9900, loss = 1.46858
I0525 17:13:39.653638 21434 solver.cpp:253]     Train net output #0: loss = 1.46858 (* 1 = 1.46858 loss)
I0525 17:13:39.653655 21434 sgd_solver.cpp:106] Iteration 9900, lr = 0.0025
I0525 17:14:10.550204 21434 solver.cpp:237] Iteration 10050, loss = 1.40608
I0525 17:14:10.550381 21434 solver.cpp:253]     Train net output #0: loss = 1.40608 (* 1 = 1.40608 loss)
I0525 17:14:10.550397 21434 sgd_solver.cpp:106] Iteration 10050, lr = 0.0025
I0525 17:14:19.287139 21434 solver.cpp:237] Iteration 10200, loss = 1.38932
I0525 17:14:19.287173 21434 solver.cpp:253]     Train net output #0: loss = 1.38932 (* 1 = 1.38932 loss)
I0525 17:14:19.287191 21434 sgd_solver.cpp:106] Iteration 10200, lr = 0.0025
I0525 17:14:28.026986 21434 solver.cpp:237] Iteration 10350, loss = 1.31409
I0525 17:14:28.027021 21434 solver.cpp:253]     Train net output #0: loss = 1.31409 (* 1 = 1.31409 loss)
I0525 17:14:28.027037 21434 sgd_solver.cpp:106] Iteration 10350, lr = 0.0025
I0525 17:14:36.706087 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_10500.caffemodel
I0525 17:14:36.784626 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_10500.solverstate
I0525 17:14:36.844686 21434 solver.cpp:237] Iteration 10500, loss = 1.3307
I0525 17:14:36.844735 21434 solver.cpp:253]     Train net output #0: loss = 1.3307 (* 1 = 1.3307 loss)
I0525 17:14:36.844749 21434 sgd_solver.cpp:106] Iteration 10500, lr = 0.0025
I0525 17:14:45.582600 21434 solver.cpp:237] Iteration 10650, loss = 1.30652
I0525 17:14:45.582747 21434 solver.cpp:253]     Train net output #0: loss = 1.30652 (* 1 = 1.30652 loss)
I0525 17:14:45.582761 21434 sgd_solver.cpp:106] Iteration 10650, lr = 0.0025
I0525 17:14:54.320600 21434 solver.cpp:237] Iteration 10800, loss = 1.37478
I0525 17:14:54.320647 21434 solver.cpp:253]     Train net output #0: loss = 1.37478 (* 1 = 1.37478 loss)
I0525 17:14:54.320667 21434 sgd_solver.cpp:106] Iteration 10800, lr = 0.0025
I0525 17:15:03.057343 21434 solver.cpp:237] Iteration 10950, loss = 1.32653
I0525 17:15:03.057379 21434 solver.cpp:253]     Train net output #0: loss = 1.32653 (* 1 = 1.32653 loss)
I0525 17:15:03.057394 21434 sgd_solver.cpp:106] Iteration 10950, lr = 0.0025
I0525 17:15:33.934653 21434 solver.cpp:237] Iteration 11100, loss = 1.34829
I0525 17:15:33.934834 21434 solver.cpp:253]     Train net output #0: loss = 1.34829 (* 1 = 1.34829 loss)
I0525 17:15:33.934850 21434 sgd_solver.cpp:106] Iteration 11100, lr = 0.0025
I0525 17:15:42.668942 21434 solver.cpp:237] Iteration 11250, loss = 1.26832
I0525 17:15:42.668977 21434 solver.cpp:253]     Train net output #0: loss = 1.26832 (* 1 = 1.26832 loss)
I0525 17:15:42.668994 21434 sgd_solver.cpp:106] Iteration 11250, lr = 0.0025
I0525 17:15:51.409242 21434 solver.cpp:237] Iteration 11400, loss = 1.41376
I0525 17:15:51.409286 21434 solver.cpp:253]     Train net output #0: loss = 1.41376 (* 1 = 1.41376 loss)
I0525 17:15:51.409302 21434 sgd_solver.cpp:106] Iteration 11400, lr = 0.0025
I0525 17:16:00.145112 21434 solver.cpp:237] Iteration 11550, loss = 1.34554
I0525 17:16:00.145148 21434 solver.cpp:253]     Train net output #0: loss = 1.34554 (* 1 = 1.34554 loss)
I0525 17:16:00.145164 21434 sgd_solver.cpp:106] Iteration 11550, lr = 0.0025
I0525 17:16:08.881721 21434 solver.cpp:237] Iteration 11700, loss = 1.36026
I0525 17:16:08.881862 21434 solver.cpp:253]     Train net output #0: loss = 1.36026 (* 1 = 1.36026 loss)
I0525 17:16:08.881876 21434 sgd_solver.cpp:106] Iteration 11700, lr = 0.0025
I0525 17:16:17.617923 21434 solver.cpp:237] Iteration 11850, loss = 1.48386
I0525 17:16:17.617962 21434 solver.cpp:253]     Train net output #0: loss = 1.48386 (* 1 = 1.48386 loss)
I0525 17:16:17.617980 21434 sgd_solver.cpp:106] Iteration 11850, lr = 0.0025
I0525 17:16:26.300046 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_12000.caffemodel
I0525 17:16:26.378291 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_12000.solverstate
I0525 17:16:26.404441 21434 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 17:17:34.096012 21434 solver.cpp:409]     Test net output #0: accuracy = 0.833653
I0525 17:17:34.096194 21434 solver.cpp:409]     Test net output #1: loss = 0.540945 (* 1 = 0.540945 loss)
I0525 17:17:56.246243 21434 solver.cpp:237] Iteration 12000, loss = 1.32977
I0525 17:17:56.246299 21434 solver.cpp:253]     Train net output #0: loss = 1.32977 (* 1 = 1.32977 loss)
I0525 17:17:56.246315 21434 sgd_solver.cpp:106] Iteration 12000, lr = 0.0025
I0525 17:18:04.970221 21434 solver.cpp:237] Iteration 12150, loss = 1.25007
I0525 17:18:04.970376 21434 solver.cpp:253]     Train net output #0: loss = 1.25007 (* 1 = 1.25007 loss)
I0525 17:18:04.970389 21434 sgd_solver.cpp:106] Iteration 12150, lr = 0.0025
I0525 17:18:13.701478 21434 solver.cpp:237] Iteration 12300, loss = 1.288
I0525 17:18:13.701513 21434 solver.cpp:253]     Train net output #0: loss = 1.288 (* 1 = 1.288 loss)
I0525 17:18:13.701530 21434 sgd_solver.cpp:106] Iteration 12300, lr = 0.0025
I0525 17:18:22.426318 21434 solver.cpp:237] Iteration 12450, loss = 1.30879
I0525 17:18:22.426368 21434 solver.cpp:253]     Train net output #0: loss = 1.30879 (* 1 = 1.30879 loss)
I0525 17:18:22.426383 21434 sgd_solver.cpp:106] Iteration 12450, lr = 0.0025
I0525 17:18:31.151496 21434 solver.cpp:237] Iteration 12600, loss = 1.19975
I0525 17:18:31.151531 21434 solver.cpp:253]     Train net output #0: loss = 1.19975 (* 1 = 1.19975 loss)
I0525 17:18:31.151547 21434 sgd_solver.cpp:106] Iteration 12600, lr = 0.0025
I0525 17:18:39.878183 21434 solver.cpp:237] Iteration 12750, loss = 1.42114
I0525 17:18:39.878342 21434 solver.cpp:253]     Train net output #0: loss = 1.42114 (* 1 = 1.42114 loss)
I0525 17:18:39.878357 21434 sgd_solver.cpp:106] Iteration 12750, lr = 0.0025
I0525 17:18:48.601811 21434 solver.cpp:237] Iteration 12900, loss = 1.19073
I0525 17:18:48.601846 21434 solver.cpp:253]     Train net output #0: loss = 1.19073 (* 1 = 1.19073 loss)
I0525 17:18:48.601863 21434 sgd_solver.cpp:106] Iteration 12900, lr = 0.0025
I0525 17:19:19.478560 21434 solver.cpp:237] Iteration 13050, loss = 1.34587
I0525 17:19:19.478727 21434 solver.cpp:253]     Train net output #0: loss = 1.34587 (* 1 = 1.34587 loss)
I0525 17:19:19.478744 21434 sgd_solver.cpp:106] Iteration 13050, lr = 0.0025
I0525 17:19:28.206142 21434 solver.cpp:237] Iteration 13200, loss = 1.01558
I0525 17:19:28.206176 21434 solver.cpp:253]     Train net output #0: loss = 1.01558 (* 1 = 1.01558 loss)
I0525 17:19:28.206193 21434 sgd_solver.cpp:106] Iteration 13200, lr = 0.0025
I0525 17:19:36.934370 21434 solver.cpp:237] Iteration 13350, loss = 1.28
I0525 17:19:36.934412 21434 solver.cpp:253]     Train net output #0: loss = 1.28 (* 1 = 1.28 loss)
I0525 17:19:36.934432 21434 sgd_solver.cpp:106] Iteration 13350, lr = 0.0025
I0525 17:19:45.605331 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_13500.caffemodel
I0525 17:19:45.686020 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_13500.solverstate
I0525 17:19:45.732616 21434 solver.cpp:237] Iteration 13500, loss = 1.42424
I0525 17:19:45.732673 21434 solver.cpp:253]     Train net output #0: loss = 1.42424 (* 1 = 1.42424 loss)
I0525 17:19:45.732687 21434 sgd_solver.cpp:106] Iteration 13500, lr = 0.0025
I0525 17:19:54.459280 21434 solver.cpp:237] Iteration 13650, loss = 1.32459
I0525 17:19:54.459439 21434 solver.cpp:253]     Train net output #0: loss = 1.32459 (* 1 = 1.32459 loss)
I0525 17:19:54.459452 21434 sgd_solver.cpp:106] Iteration 13650, lr = 0.0025
I0525 17:20:03.191068 21434 solver.cpp:237] Iteration 13800, loss = 1.70058
I0525 17:20:03.191102 21434 solver.cpp:253]     Train net output #0: loss = 1.70058 (* 1 = 1.70058 loss)
I0525 17:20:03.191126 21434 sgd_solver.cpp:106] Iteration 13800, lr = 0.0025
I0525 17:20:11.917489 21434 solver.cpp:237] Iteration 13950, loss = 1.37084
I0525 17:20:11.917522 21434 solver.cpp:253]     Train net output #0: loss = 1.37084 (* 1 = 1.37084 loss)
I0525 17:20:11.917538 21434 sgd_solver.cpp:106] Iteration 13950, lr = 0.0025
I0525 17:20:42.806815 21434 solver.cpp:237] Iteration 14100, loss = 1.28267
I0525 17:20:42.807009 21434 solver.cpp:253]     Train net output #0: loss = 1.28267 (* 1 = 1.28267 loss)
I0525 17:20:42.807025 21434 sgd_solver.cpp:106] Iteration 14100, lr = 0.0025
I0525 17:20:51.532135 21434 solver.cpp:237] Iteration 14250, loss = 1.18594
I0525 17:20:51.532176 21434 solver.cpp:253]     Train net output #0: loss = 1.18594 (* 1 = 1.18594 loss)
I0525 17:20:51.532197 21434 sgd_solver.cpp:106] Iteration 14250, lr = 0.0025
I0525 17:21:00.257623 21434 solver.cpp:237] Iteration 14400, loss = 1.31005
I0525 17:21:00.257658 21434 solver.cpp:253]     Train net output #0: loss = 1.31005 (* 1 = 1.31005 loss)
I0525 17:21:00.257674 21434 sgd_solver.cpp:106] Iteration 14400, lr = 0.0025
I0525 17:21:08.982347 21434 solver.cpp:237] Iteration 14550, loss = 1.48269
I0525 17:21:08.982383 21434 solver.cpp:253]     Train net output #0: loss = 1.48269 (* 1 = 1.48269 loss)
I0525 17:21:08.982398 21434 sgd_solver.cpp:106] Iteration 14550, lr = 0.0025
I0525 17:21:17.707290 21434 solver.cpp:237] Iteration 14700, loss = 1.29061
I0525 17:21:17.707451 21434 solver.cpp:253]     Train net output #0: loss = 1.29061 (* 1 = 1.29061 loss)
I0525 17:21:17.707465 21434 sgd_solver.cpp:106] Iteration 14700, lr = 0.0025
I0525 17:21:26.429441 21434 solver.cpp:237] Iteration 14850, loss = 1.27011
I0525 17:21:26.429476 21434 solver.cpp:253]     Train net output #0: loss = 1.27011 (* 1 = 1.27011 loss)
I0525 17:21:26.429492 21434 sgd_solver.cpp:106] Iteration 14850, lr = 0.0025
I0525 17:21:35.091377 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_15000.caffemodel
I0525 17:21:35.171774 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_15000.solverstate
I0525 17:21:35.199919 21434 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 17:22:22.008419 21434 solver.cpp:409]     Test net output #0: accuracy = 0.841779
I0525 17:22:22.008590 21434 solver.cpp:409]     Test net output #1: loss = 0.487773 (* 1 = 0.487773 loss)
I0525 17:22:42.897622 21434 solver.cpp:237] Iteration 15000, loss = 1.0924
I0525 17:22:42.897677 21434 solver.cpp:253]     Train net output #0: loss = 1.0924 (* 1 = 1.0924 loss)
I0525 17:22:42.897693 21434 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0525 17:22:51.636883 21434 solver.cpp:237] Iteration 15150, loss = 1.37649
I0525 17:22:51.636921 21434 solver.cpp:253]     Train net output #0: loss = 1.37649 (* 1 = 1.37649 loss)
I0525 17:22:51.636943 21434 sgd_solver.cpp:106] Iteration 15150, lr = 0.0025
I0525 17:23:00.372714 21434 solver.cpp:237] Iteration 15300, loss = 1.09297
I0525 17:23:00.372862 21434 solver.cpp:253]     Train net output #0: loss = 1.09297 (* 1 = 1.09297 loss)
I0525 17:23:00.372876 21434 sgd_solver.cpp:106] Iteration 15300, lr = 0.0025
I0525 17:23:09.109210 21434 solver.cpp:237] Iteration 15450, loss = 1.242
I0525 17:23:09.109243 21434 solver.cpp:253]     Train net output #0: loss = 1.242 (* 1 = 1.242 loss)
I0525 17:23:09.109257 21434 sgd_solver.cpp:106] Iteration 15450, lr = 0.0025
I0525 17:23:17.849002 21434 solver.cpp:237] Iteration 15600, loss = 1.26916
I0525 17:23:17.849052 21434 solver.cpp:253]     Train net output #0: loss = 1.26916 (* 1 = 1.26916 loss)
I0525 17:23:17.849066 21434 sgd_solver.cpp:106] Iteration 15600, lr = 0.0025
I0525 17:23:26.588179 21434 solver.cpp:237] Iteration 15750, loss = 1.37263
I0525 17:23:26.588214 21434 solver.cpp:253]     Train net output #0: loss = 1.37263 (* 1 = 1.37263 loss)
I0525 17:23:26.588230 21434 sgd_solver.cpp:106] Iteration 15750, lr = 0.0025
I0525 17:23:35.327559 21434 solver.cpp:237] Iteration 15900, loss = 1.36822
I0525 17:23:35.327714 21434 solver.cpp:253]     Train net output #0: loss = 1.36822 (* 1 = 1.36822 loss)
I0525 17:23:35.327728 21434 sgd_solver.cpp:106] Iteration 15900, lr = 0.0025
I0525 17:24:04.912865 21434 solver.cpp:237] Iteration 16050, loss = 1.3174
I0525 17:24:04.912916 21434 solver.cpp:253]     Train net output #0: loss = 1.3174 (* 1 = 1.3174 loss)
I0525 17:24:04.912936 21434 sgd_solver.cpp:106] Iteration 16050, lr = 0.0025
I0525 17:24:13.655936 21434 solver.cpp:237] Iteration 16200, loss = 1.09329
I0525 17:24:13.656087 21434 solver.cpp:253]     Train net output #0: loss = 1.09329 (* 1 = 1.09329 loss)
I0525 17:24:13.656100 21434 sgd_solver.cpp:106] Iteration 16200, lr = 0.0025
I0525 17:24:22.394048 21434 solver.cpp:237] Iteration 16350, loss = 1.39326
I0525 17:24:22.394083 21434 solver.cpp:253]     Train net output #0: loss = 1.39326 (* 1 = 1.39326 loss)
I0525 17:24:22.394096 21434 sgd_solver.cpp:106] Iteration 16350, lr = 0.0025
I0525 17:24:31.075978 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_16500.caffemodel
I0525 17:24:31.154184 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_16500.solverstate
I0525 17:24:31.197357 21434 solver.cpp:237] Iteration 16500, loss = 1.19561
I0525 17:24:31.197405 21434 solver.cpp:253]     Train net output #0: loss = 1.19561 (* 1 = 1.19561 loss)
I0525 17:24:31.197418 21434 sgd_solver.cpp:106] Iteration 16500, lr = 0.0025
I0525 17:24:39.935112 21434 solver.cpp:237] Iteration 16650, loss = 1.65768
I0525 17:24:39.935151 21434 solver.cpp:253]     Train net output #0: loss = 1.65768 (* 1 = 1.65768 loss)
I0525 17:24:39.935168 21434 sgd_solver.cpp:106] Iteration 16650, lr = 0.0025
I0525 17:24:48.673388 21434 solver.cpp:237] Iteration 16800, loss = 1.41284
I0525 17:24:48.673537 21434 solver.cpp:253]     Train net output #0: loss = 1.41284 (* 1 = 1.41284 loss)
I0525 17:24:48.673550 21434 sgd_solver.cpp:106] Iteration 16800, lr = 0.0025
I0525 17:24:57.407060 21434 solver.cpp:237] Iteration 16950, loss = 1.31638
I0525 17:24:57.407105 21434 solver.cpp:253]     Train net output #0: loss = 1.31638 (* 1 = 1.31638 loss)
I0525 17:24:57.407130 21434 sgd_solver.cpp:106] Iteration 16950, lr = 0.0025
I0525 17:25:26.969900 21434 solver.cpp:237] Iteration 17100, loss = 1.18011
I0525 17:25:26.970077 21434 solver.cpp:253]     Train net output #0: loss = 1.18011 (* 1 = 1.18011 loss)
I0525 17:25:26.970090 21434 sgd_solver.cpp:106] Iteration 17100, lr = 0.0025
I0525 17:25:35.709244 21434 solver.cpp:237] Iteration 17250, loss = 1.13749
I0525 17:25:35.709280 21434 solver.cpp:253]     Train net output #0: loss = 1.13749 (* 1 = 1.13749 loss)
I0525 17:25:35.709296 21434 sgd_solver.cpp:106] Iteration 17250, lr = 0.0025
I0525 17:25:44.446657 21434 solver.cpp:237] Iteration 17400, loss = 1.35721
I0525 17:25:44.446708 21434 solver.cpp:253]     Train net output #0: loss = 1.35721 (* 1 = 1.35721 loss)
I0525 17:25:44.446724 21434 sgd_solver.cpp:106] Iteration 17400, lr = 0.0025
I0525 17:25:53.188407 21434 solver.cpp:237] Iteration 17550, loss = 1.2825
I0525 17:25:53.188442 21434 solver.cpp:253]     Train net output #0: loss = 1.2825 (* 1 = 1.2825 loss)
I0525 17:25:53.188458 21434 sgd_solver.cpp:106] Iteration 17550, lr = 0.0025
I0525 17:26:01.924913 21434 solver.cpp:237] Iteration 17700, loss = 1.02158
I0525 17:26:01.925060 21434 solver.cpp:253]     Train net output #0: loss = 1.02158 (* 1 = 1.02158 loss)
I0525 17:26:01.925074 21434 sgd_solver.cpp:106] Iteration 17700, lr = 0.0025
I0525 17:26:10.659512 21434 solver.cpp:237] Iteration 17850, loss = 1.43102
I0525 17:26:10.659559 21434 solver.cpp:253]     Train net output #0: loss = 1.43102 (* 1 = 1.43102 loss)
I0525 17:26:10.659577 21434 sgd_solver.cpp:106] Iteration 17850, lr = 0.0025
I0525 17:26:19.335686 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_18000.caffemodel
I0525 17:26:19.414490 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_18000.solverstate
I0525 17:26:19.440389 21434 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 17:27:27.133517 21434 solver.cpp:409]     Test net output #0: accuracy = 0.84838
I0525 17:27:27.133692 21434 solver.cpp:409]     Test net output #1: loss = 0.466273 (* 1 = 0.466273 loss)
I0525 17:27:47.987311 21434 solver.cpp:237] Iteration 18000, loss = 1.40771
I0525 17:27:47.987367 21434 solver.cpp:253]     Train net output #0: loss = 1.40771 (* 1 = 1.40771 loss)
I0525 17:27:47.987382 21434 sgd_solver.cpp:106] Iteration 18000, lr = 0.0025
I0525 17:27:56.724114 21434 solver.cpp:237] Iteration 18150, loss = 1.25172
I0525 17:27:56.724154 21434 solver.cpp:253]     Train net output #0: loss = 1.25172 (* 1 = 1.25172 loss)
I0525 17:27:56.724176 21434 sgd_solver.cpp:106] Iteration 18150, lr = 0.0025
I0525 17:28:05.460371 21434 solver.cpp:237] Iteration 18300, loss = 1.36354
I0525 17:28:05.460521 21434 solver.cpp:253]     Train net output #0: loss = 1.36354 (* 1 = 1.36354 loss)
I0525 17:28:05.460536 21434 sgd_solver.cpp:106] Iteration 18300, lr = 0.0025
I0525 17:28:14.188678 21434 solver.cpp:237] Iteration 18450, loss = 1.21114
I0525 17:28:14.188712 21434 solver.cpp:253]     Train net output #0: loss = 1.21114 (* 1 = 1.21114 loss)
I0525 17:28:14.188726 21434 sgd_solver.cpp:106] Iteration 18450, lr = 0.0025
I0525 17:28:22.925137 21434 solver.cpp:237] Iteration 18600, loss = 1.23513
I0525 17:28:22.925171 21434 solver.cpp:253]     Train net output #0: loss = 1.23513 (* 1 = 1.23513 loss)
I0525 17:28:22.925194 21434 sgd_solver.cpp:106] Iteration 18600, lr = 0.0025
I0525 17:28:31.654306 21434 solver.cpp:237] Iteration 18750, loss = 1.22076
I0525 17:28:31.654341 21434 solver.cpp:253]     Train net output #0: loss = 1.22076 (* 1 = 1.22076 loss)
I0525 17:28:31.654355 21434 sgd_solver.cpp:106] Iteration 18750, lr = 0.0025
I0525 17:28:40.388177 21434 solver.cpp:237] Iteration 18900, loss = 1.12785
I0525 17:28:40.388339 21434 solver.cpp:253]     Train net output #0: loss = 1.12785 (* 1 = 1.12785 loss)
I0525 17:28:40.388353 21434 sgd_solver.cpp:106] Iteration 18900, lr = 0.0025
I0525 17:29:10.006693 21434 solver.cpp:237] Iteration 19050, loss = 1.39793
I0525 17:29:10.006747 21434 solver.cpp:253]     Train net output #0: loss = 1.39793 (* 1 = 1.39793 loss)
I0525 17:29:10.006764 21434 sgd_solver.cpp:106] Iteration 19050, lr = 0.0025
I0525 17:29:18.744482 21434 solver.cpp:237] Iteration 19200, loss = 1.07044
I0525 17:29:18.744635 21434 solver.cpp:253]     Train net output #0: loss = 1.07044 (* 1 = 1.07044 loss)
I0525 17:29:18.744648 21434 sgd_solver.cpp:106] Iteration 19200, lr = 0.0025
I0525 17:29:27.479518 21434 solver.cpp:237] Iteration 19350, loss = 1.27099
I0525 17:29:27.479553 21434 solver.cpp:253]     Train net output #0: loss = 1.27099 (* 1 = 1.27099 loss)
I0525 17:29:27.479569 21434 sgd_solver.cpp:106] Iteration 19350, lr = 0.0025
I0525 17:29:36.152950 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_19500.caffemodel
I0525 17:29:36.232182 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_19500.solverstate
I0525 17:29:36.278666 21434 solver.cpp:237] Iteration 19500, loss = 1.14016
I0525 17:29:36.278719 21434 solver.cpp:253]     Train net output #0: loss = 1.14016 (* 1 = 1.14016 loss)
I0525 17:29:36.278735 21434 sgd_solver.cpp:106] Iteration 19500, lr = 0.0025
I0525 17:29:45.010421 21434 solver.cpp:237] Iteration 19650, loss = 1.36873
I0525 17:29:45.010457 21434 solver.cpp:253]     Train net output #0: loss = 1.36873 (* 1 = 1.36873 loss)
I0525 17:29:45.010473 21434 sgd_solver.cpp:106] Iteration 19650, lr = 0.0025
I0525 17:29:53.747529 21434 solver.cpp:237] Iteration 19800, loss = 1.44946
I0525 17:29:53.747691 21434 solver.cpp:253]     Train net output #0: loss = 1.44946 (* 1 = 1.44946 loss)
I0525 17:29:53.747705 21434 sgd_solver.cpp:106] Iteration 19800, lr = 0.0025
I0525 17:30:02.481848 21434 solver.cpp:237] Iteration 19950, loss = 1.50692
I0525 17:30:02.481892 21434 solver.cpp:253]     Train net output #0: loss = 1.50692 (* 1 = 1.50692 loss)
I0525 17:30:02.481911 21434 sgd_solver.cpp:106] Iteration 19950, lr = 0.0025
I0525 17:30:32.076108 21434 solver.cpp:237] Iteration 20100, loss = 1.28719
I0525 17:30:32.076287 21434 solver.cpp:253]     Train net output #0: loss = 1.28719 (* 1 = 1.28719 loss)
I0525 17:30:32.076300 21434 sgd_solver.cpp:106] Iteration 20100, lr = 0.0025
I0525 17:30:40.807960 21434 solver.cpp:237] Iteration 20250, loss = 1.416
I0525 17:30:40.807993 21434 solver.cpp:253]     Train net output #0: loss = 1.416 (* 1 = 1.416 loss)
I0525 17:30:40.808008 21434 sgd_solver.cpp:106] Iteration 20250, lr = 0.0025
I0525 17:30:49.537526 21434 solver.cpp:237] Iteration 20400, loss = 1.26176
I0525 17:30:49.537569 21434 solver.cpp:253]     Train net output #0: loss = 1.26176 (* 1 = 1.26176 loss)
I0525 17:30:49.537590 21434 sgd_solver.cpp:106] Iteration 20400, lr = 0.0025
I0525 17:30:58.272550 21434 solver.cpp:237] Iteration 20550, loss = 1.11789
I0525 17:30:58.272585 21434 solver.cpp:253]     Train net output #0: loss = 1.11789 (* 1 = 1.11789 loss)
I0525 17:30:58.272601 21434 sgd_solver.cpp:106] Iteration 20550, lr = 0.0025
I0525 17:31:07.010953 21434 solver.cpp:237] Iteration 20700, loss = 1.33704
I0525 17:31:07.011099 21434 solver.cpp:253]     Train net output #0: loss = 1.33704 (* 1 = 1.33704 loss)
I0525 17:31:07.011112 21434 sgd_solver.cpp:106] Iteration 20700, lr = 0.0025
I0525 17:31:15.742967 21434 solver.cpp:237] Iteration 20850, loss = 1.33933
I0525 17:31:15.743001 21434 solver.cpp:253]     Train net output #0: loss = 1.33933 (* 1 = 1.33933 loss)
I0525 17:31:15.743026 21434 sgd_solver.cpp:106] Iteration 20850, lr = 0.0025
I0525 17:31:24.424461 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_21000.caffemodel
I0525 17:31:24.505060 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_21000.solverstate
I0525 17:31:24.532013 21434 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 17:32:11.043782 21434 solver.cpp:409]     Test net output #0: accuracy = 0.854873
I0525 17:32:11.043956 21434 solver.cpp:409]     Test net output #1: loss = 0.503967 (* 1 = 0.503967 loss)
I0525 17:32:31.926583 21434 solver.cpp:237] Iteration 21000, loss = 1.33927
I0525 17:32:31.926640 21434 solver.cpp:253]     Train net output #0: loss = 1.33927 (* 1 = 1.33927 loss)
I0525 17:32:31.926654 21434 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0525 17:32:40.668177 21434 solver.cpp:237] Iteration 21150, loss = 1.22178
I0525 17:32:40.668212 21434 solver.cpp:253]     Train net output #0: loss = 1.22178 (* 1 = 1.22178 loss)
I0525 17:32:40.668229 21434 sgd_solver.cpp:106] Iteration 21150, lr = 0.0025
I0525 17:32:49.409238 21434 solver.cpp:237] Iteration 21300, loss = 1.1922
I0525 17:32:49.409412 21434 solver.cpp:253]     Train net output #0: loss = 1.1922 (* 1 = 1.1922 loss)
I0525 17:32:49.409426 21434 sgd_solver.cpp:106] Iteration 21300, lr = 0.0025
I0525 17:32:58.143414 21434 solver.cpp:237] Iteration 21450, loss = 1.27649
I0525 17:32:58.143450 21434 solver.cpp:253]     Train net output #0: loss = 1.27649 (* 1 = 1.27649 loss)
I0525 17:32:58.143466 21434 sgd_solver.cpp:106] Iteration 21450, lr = 0.0025
I0525 17:33:06.886579 21434 solver.cpp:237] Iteration 21600, loss = 1.12351
I0525 17:33:06.886615 21434 solver.cpp:253]     Train net output #0: loss = 1.12351 (* 1 = 1.12351 loss)
I0525 17:33:06.886627 21434 sgd_solver.cpp:106] Iteration 21600, lr = 0.0025
I0525 17:33:15.627233 21434 solver.cpp:237] Iteration 21750, loss = 1.23708
I0525 17:33:15.627282 21434 solver.cpp:253]     Train net output #0: loss = 1.23708 (* 1 = 1.23708 loss)
I0525 17:33:15.627297 21434 sgd_solver.cpp:106] Iteration 21750, lr = 0.0025
I0525 17:33:24.366528 21434 solver.cpp:237] Iteration 21900, loss = 1.11752
I0525 17:33:24.366688 21434 solver.cpp:253]     Train net output #0: loss = 1.11752 (* 1 = 1.11752 loss)
I0525 17:33:24.366703 21434 sgd_solver.cpp:106] Iteration 21900, lr = 0.0025
I0525 17:33:53.945004 21434 solver.cpp:237] Iteration 22050, loss = 1.15925
I0525 17:33:53.945055 21434 solver.cpp:253]     Train net output #0: loss = 1.15925 (* 1 = 1.15925 loss)
I0525 17:33:53.945075 21434 sgd_solver.cpp:106] Iteration 22050, lr = 0.0025
I0525 17:34:02.684448 21434 solver.cpp:237] Iteration 22200, loss = 1.22715
I0525 17:34:02.684609 21434 solver.cpp:253]     Train net output #0: loss = 1.22715 (* 1 = 1.22715 loss)
I0525 17:34:02.684623 21434 sgd_solver.cpp:106] Iteration 22200, lr = 0.0025
I0525 17:34:11.425483 21434 solver.cpp:237] Iteration 22350, loss = 1.1552
I0525 17:34:11.425529 21434 solver.cpp:253]     Train net output #0: loss = 1.1552 (* 1 = 1.1552 loss)
I0525 17:34:11.425547 21434 sgd_solver.cpp:106] Iteration 22350, lr = 0.0025
I0525 17:34:20.106341 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_22500.caffemodel
I0525 17:34:20.187291 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_22500.solverstate
I0525 17:34:20.233028 21434 solver.cpp:237] Iteration 22500, loss = 1.31956
I0525 17:34:20.233081 21434 solver.cpp:253]     Train net output #0: loss = 1.31956 (* 1 = 1.31956 loss)
I0525 17:34:20.233095 21434 sgd_solver.cpp:106] Iteration 22500, lr = 0.0025
I0525 17:34:28.968847 21434 solver.cpp:237] Iteration 22650, loss = 1.31983
I0525 17:34:28.968881 21434 solver.cpp:253]     Train net output #0: loss = 1.31983 (* 1 = 1.31983 loss)
I0525 17:34:28.968897 21434 sgd_solver.cpp:106] Iteration 22650, lr = 0.0025
I0525 17:34:37.705121 21434 solver.cpp:237] Iteration 22800, loss = 1.16678
I0525 17:34:37.705294 21434 solver.cpp:253]     Train net output #0: loss = 1.16678 (* 1 = 1.16678 loss)
I0525 17:34:37.705309 21434 sgd_solver.cpp:106] Iteration 22800, lr = 0.0025
I0525 17:34:46.442277 21434 solver.cpp:237] Iteration 22950, loss = 1.27145
I0525 17:34:46.442312 21434 solver.cpp:253]     Train net output #0: loss = 1.27145 (* 1 = 1.27145 loss)
I0525 17:34:46.442328 21434 sgd_solver.cpp:106] Iteration 22950, lr = 0.0025
I0525 17:35:16.046748 21434 solver.cpp:237] Iteration 23100, loss = 1.28828
I0525 17:35:16.046926 21434 solver.cpp:253]     Train net output #0: loss = 1.28828 (* 1 = 1.28828 loss)
I0525 17:35:16.046941 21434 sgd_solver.cpp:106] Iteration 23100, lr = 0.0025
I0525 17:35:24.785226 21434 solver.cpp:237] Iteration 23250, loss = 1.33065
I0525 17:35:24.785267 21434 solver.cpp:253]     Train net output #0: loss = 1.33065 (* 1 = 1.33065 loss)
I0525 17:35:24.785287 21434 sgd_solver.cpp:106] Iteration 23250, lr = 0.0025
I0525 17:35:33.520666 21434 solver.cpp:237] Iteration 23400, loss = 1.25538
I0525 17:35:33.520701 21434 solver.cpp:253]     Train net output #0: loss = 1.25538 (* 1 = 1.25538 loss)
I0525 17:35:33.520717 21434 sgd_solver.cpp:106] Iteration 23400, lr = 0.0025
I0525 17:35:42.256266 21434 solver.cpp:237] Iteration 23550, loss = 1.34295
I0525 17:35:42.256301 21434 solver.cpp:253]     Train net output #0: loss = 1.34295 (* 1 = 1.34295 loss)
I0525 17:35:42.256315 21434 sgd_solver.cpp:106] Iteration 23550, lr = 0.0025
I0525 17:35:50.997444 21434 solver.cpp:237] Iteration 23700, loss = 1.27929
I0525 17:35:50.997620 21434 solver.cpp:253]     Train net output #0: loss = 1.27929 (* 1 = 1.27929 loss)
I0525 17:35:50.997635 21434 sgd_solver.cpp:106] Iteration 23700, lr = 0.0025
I0525 17:35:59.735324 21434 solver.cpp:237] Iteration 23850, loss = 1.17484
I0525 17:35:59.735358 21434 solver.cpp:253]     Train net output #0: loss = 1.17484 (* 1 = 1.17484 loss)
I0525 17:35:59.735375 21434 sgd_solver.cpp:106] Iteration 23850, lr = 0.0025
I0525 17:36:08.418419 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_24000.caffemodel
I0525 17:36:08.496407 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_24000.solverstate
I0525 17:36:08.521535 21434 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 17:37:16.184044 21434 solver.cpp:409]     Test net output #0: accuracy = 0.860032
I0525 17:37:16.184226 21434 solver.cpp:409]     Test net output #1: loss = 0.456802 (* 1 = 0.456802 loss)
I0525 17:37:37.041170 21434 solver.cpp:237] Iteration 24000, loss = 1.33159
I0525 17:37:37.041227 21434 solver.cpp:253]     Train net output #0: loss = 1.33159 (* 1 = 1.33159 loss)
I0525 17:37:37.041241 21434 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0525 17:37:45.767772 21434 solver.cpp:237] Iteration 24150, loss = 1.15277
I0525 17:37:45.767808 21434 solver.cpp:253]     Train net output #0: loss = 1.15277 (* 1 = 1.15277 loss)
I0525 17:37:45.767822 21434 sgd_solver.cpp:106] Iteration 24150, lr = 0.0025
I0525 17:37:54.491360 21434 solver.cpp:237] Iteration 24300, loss = 1.29333
I0525 17:37:54.491525 21434 solver.cpp:253]     Train net output #0: loss = 1.29333 (* 1 = 1.29333 loss)
I0525 17:37:54.491540 21434 sgd_solver.cpp:106] Iteration 24300, lr = 0.0025
I0525 17:38:03.211421 21434 solver.cpp:237] Iteration 24450, loss = 1.19871
I0525 17:38:03.211455 21434 solver.cpp:253]     Train net output #0: loss = 1.19871 (* 1 = 1.19871 loss)
I0525 17:38:03.211473 21434 sgd_solver.cpp:106] Iteration 24450, lr = 0.0025
I0525 17:38:11.938217 21434 solver.cpp:237] Iteration 24600, loss = 1.28922
I0525 17:38:11.938252 21434 solver.cpp:253]     Train net output #0: loss = 1.28922 (* 1 = 1.28922 loss)
I0525 17:38:11.938268 21434 sgd_solver.cpp:106] Iteration 24600, lr = 0.0025
I0525 17:38:20.662645 21434 solver.cpp:237] Iteration 24750, loss = 1.15243
I0525 17:38:20.662693 21434 solver.cpp:253]     Train net output #0: loss = 1.15243 (* 1 = 1.15243 loss)
I0525 17:38:20.662714 21434 sgd_solver.cpp:106] Iteration 24750, lr = 0.0025
I0525 17:38:29.385313 21434 solver.cpp:237] Iteration 24900, loss = 1.09371
I0525 17:38:29.385467 21434 solver.cpp:253]     Train net output #0: loss = 1.09371 (* 1 = 1.09371 loss)
I0525 17:38:29.385480 21434 sgd_solver.cpp:106] Iteration 24900, lr = 0.0025
I0525 17:38:58.948158 21434 solver.cpp:237] Iteration 25050, loss = 1.33658
I0525 17:38:58.948212 21434 solver.cpp:253]     Train net output #0: loss = 1.33658 (* 1 = 1.33658 loss)
I0525 17:38:58.948228 21434 sgd_solver.cpp:106] Iteration 25050, lr = 0.0025
I0525 17:39:07.676234 21434 solver.cpp:237] Iteration 25200, loss = 1.09111
I0525 17:39:07.676404 21434 solver.cpp:253]     Train net output #0: loss = 1.09111 (* 1 = 1.09111 loss)
I0525 17:39:07.676419 21434 sgd_solver.cpp:106] Iteration 25200, lr = 0.0025
I0525 17:39:16.400383 21434 solver.cpp:237] Iteration 25350, loss = 1.13012
I0525 17:39:16.400419 21434 solver.cpp:253]     Train net output #0: loss = 1.13012 (* 1 = 1.13012 loss)
I0525 17:39:16.400434 21434 sgd_solver.cpp:106] Iteration 25350, lr = 0.0025
I0525 17:39:25.069237 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_25500.caffemodel
I0525 17:39:25.152298 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_25500.solverstate
I0525 17:39:25.195336 21434 solver.cpp:237] Iteration 25500, loss = 1.04536
I0525 17:39:25.195384 21434 solver.cpp:253]     Train net output #0: loss = 1.04536 (* 1 = 1.04536 loss)
I0525 17:39:25.195399 21434 sgd_solver.cpp:106] Iteration 25500, lr = 0.0025
I0525 17:39:33.920264 21434 solver.cpp:237] Iteration 25650, loss = 1.38084
I0525 17:39:33.920310 21434 solver.cpp:253]     Train net output #0: loss = 1.38084 (* 1 = 1.38084 loss)
I0525 17:39:33.920326 21434 sgd_solver.cpp:106] Iteration 25650, lr = 0.0025
I0525 17:39:42.646970 21434 solver.cpp:237] Iteration 25800, loss = 1.2311
I0525 17:39:42.647140 21434 solver.cpp:253]     Train net output #0: loss = 1.2311 (* 1 = 1.2311 loss)
I0525 17:39:42.647153 21434 sgd_solver.cpp:106] Iteration 25800, lr = 0.0025
I0525 17:39:51.370095 21434 solver.cpp:237] Iteration 25950, loss = 1.21047
I0525 17:39:51.370128 21434 solver.cpp:253]     Train net output #0: loss = 1.21047 (* 1 = 1.21047 loss)
I0525 17:39:51.370146 21434 sgd_solver.cpp:106] Iteration 25950, lr = 0.0025
I0525 17:40:20.899487 21434 solver.cpp:237] Iteration 26100, loss = 1.1236
I0525 17:40:20.899680 21434 solver.cpp:253]     Train net output #0: loss = 1.1236 (* 1 = 1.1236 loss)
I0525 17:40:20.899694 21434 sgd_solver.cpp:106] Iteration 26100, lr = 0.0025
I0525 17:40:29.625102 21434 solver.cpp:237] Iteration 26250, loss = 1.27112
I0525 17:40:29.625133 21434 solver.cpp:253]     Train net output #0: loss = 1.27112 (* 1 = 1.27112 loss)
I0525 17:40:29.625145 21434 sgd_solver.cpp:106] Iteration 26250, lr = 0.0025
I0525 17:40:38.351773 21434 solver.cpp:237] Iteration 26400, loss = 1.32206
I0525 17:40:38.351809 21434 solver.cpp:253]     Train net output #0: loss = 1.32206 (* 1 = 1.32206 loss)
I0525 17:40:38.351826 21434 sgd_solver.cpp:106] Iteration 26400, lr = 0.0025
I0525 17:40:47.078794 21434 solver.cpp:237] Iteration 26550, loss = 1.2241
I0525 17:40:47.078835 21434 solver.cpp:253]     Train net output #0: loss = 1.2241 (* 1 = 1.2241 loss)
I0525 17:40:47.078855 21434 sgd_solver.cpp:106] Iteration 26550, lr = 0.0025
I0525 17:40:55.805145 21434 solver.cpp:237] Iteration 26700, loss = 1.18732
I0525 17:40:55.805294 21434 solver.cpp:253]     Train net output #0: loss = 1.18732 (* 1 = 1.18732 loss)
I0525 17:40:55.805306 21434 sgd_solver.cpp:106] Iteration 26700, lr = 0.0025
I0525 17:41:04.530203 21434 solver.cpp:237] Iteration 26850, loss = 1.09076
I0525 17:41:04.530237 21434 solver.cpp:253]     Train net output #0: loss = 1.09076 (* 1 = 1.09076 loss)
I0525 17:41:04.530252 21434 sgd_solver.cpp:106] Iteration 26850, lr = 0.0025
I0525 17:41:13.199548 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_27000.caffemodel
I0525 17:41:13.279189 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_27000.solverstate
I0525 17:41:13.304888 21434 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 17:42:00.063838 21434 solver.cpp:409]     Test net output #0: accuracy = 0.863632
I0525 17:42:00.064023 21434 solver.cpp:409]     Test net output #1: loss = 0.453492 (* 1 = 0.453492 loss)
I0525 17:42:20.874395 21434 solver.cpp:237] Iteration 27000, loss = 1.24297
I0525 17:42:20.874451 21434 solver.cpp:253]     Train net output #0: loss = 1.24297 (* 1 = 1.24297 loss)
I0525 17:42:20.874467 21434 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0525 17:42:29.610124 21434 solver.cpp:237] Iteration 27150, loss = 1.28115
I0525 17:42:29.610172 21434 solver.cpp:253]     Train net output #0: loss = 1.28115 (* 1 = 1.28115 loss)
I0525 17:42:29.610190 21434 sgd_solver.cpp:106] Iteration 27150, lr = 0.0025
I0525 17:42:38.340708 21434 solver.cpp:237] Iteration 27300, loss = 1.30826
I0525 17:42:38.340863 21434 solver.cpp:253]     Train net output #0: loss = 1.30826 (* 1 = 1.30826 loss)
I0525 17:42:38.340876 21434 sgd_solver.cpp:106] Iteration 27300, lr = 0.0025
I0525 17:42:47.074594 21434 solver.cpp:237] Iteration 27450, loss = 1.19534
I0525 17:42:47.074628 21434 solver.cpp:253]     Train net output #0: loss = 1.19534 (* 1 = 1.19534 loss)
I0525 17:42:47.074646 21434 sgd_solver.cpp:106] Iteration 27450, lr = 0.0025
I0525 17:42:55.815803 21434 solver.cpp:237] Iteration 27600, loss = 1.37432
I0525 17:42:55.815843 21434 solver.cpp:253]     Train net output #0: loss = 1.37432 (* 1 = 1.37432 loss)
I0525 17:42:55.815863 21434 sgd_solver.cpp:106] Iteration 27600, lr = 0.0025
I0525 17:43:04.554224 21434 solver.cpp:237] Iteration 27750, loss = 1.08216
I0525 17:43:04.554257 21434 solver.cpp:253]     Train net output #0: loss = 1.08216 (* 1 = 1.08216 loss)
I0525 17:43:04.554275 21434 sgd_solver.cpp:106] Iteration 27750, lr = 0.0025
I0525 17:43:13.287611 21434 solver.cpp:237] Iteration 27900, loss = 1.12201
I0525 17:43:13.287784 21434 solver.cpp:253]     Train net output #0: loss = 1.12201 (* 1 = 1.12201 loss)
I0525 17:43:13.287798 21434 sgd_solver.cpp:106] Iteration 27900, lr = 0.0025
I0525 17:43:42.880007 21434 solver.cpp:237] Iteration 28050, loss = 1.27024
I0525 17:43:42.880060 21434 solver.cpp:253]     Train net output #0: loss = 1.27024 (* 1 = 1.27024 loss)
I0525 17:43:42.880079 21434 sgd_solver.cpp:106] Iteration 28050, lr = 0.0025
I0525 17:43:51.611263 21434 solver.cpp:237] Iteration 28200, loss = 1.3551
I0525 17:43:51.611423 21434 solver.cpp:253]     Train net output #0: loss = 1.3551 (* 1 = 1.3551 loss)
I0525 17:43:51.611438 21434 sgd_solver.cpp:106] Iteration 28200, lr = 0.0025
I0525 17:44:00.346957 21434 solver.cpp:237] Iteration 28350, loss = 1.16993
I0525 17:44:00.346992 21434 solver.cpp:253]     Train net output #0: loss = 1.16993 (* 1 = 1.16993 loss)
I0525 17:44:00.347008 21434 sgd_solver.cpp:106] Iteration 28350, lr = 0.0025
I0525 17:44:09.027442 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_28500.caffemodel
I0525 17:44:09.108996 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_28500.solverstate
I0525 17:44:09.154307 21434 solver.cpp:237] Iteration 28500, loss = 1.37104
I0525 17:44:09.154359 21434 solver.cpp:253]     Train net output #0: loss = 1.37104 (* 1 = 1.37104 loss)
I0525 17:44:09.154373 21434 sgd_solver.cpp:106] Iteration 28500, lr = 0.0025
I0525 17:44:17.888067 21434 solver.cpp:237] Iteration 28650, loss = 1.18164
I0525 17:44:17.888101 21434 solver.cpp:253]     Train net output #0: loss = 1.18164 (* 1 = 1.18164 loss)
I0525 17:44:17.888119 21434 sgd_solver.cpp:106] Iteration 28650, lr = 0.0025
I0525 17:44:26.627322 21434 solver.cpp:237] Iteration 28800, loss = 1.42572
I0525 17:44:26.627481 21434 solver.cpp:253]     Train net output #0: loss = 1.42572 (* 1 = 1.42572 loss)
I0525 17:44:26.627495 21434 sgd_solver.cpp:106] Iteration 28800, lr = 0.0025
I0525 17:44:35.367599 21434 solver.cpp:237] Iteration 28950, loss = 1.16385
I0525 17:44:35.367648 21434 solver.cpp:253]     Train net output #0: loss = 1.16385 (* 1 = 1.16385 loss)
I0525 17:44:35.367668 21434 sgd_solver.cpp:106] Iteration 28950, lr = 0.0025
I0525 17:45:04.926681 21434 solver.cpp:237] Iteration 29100, loss = 1.18357
I0525 17:45:04.926873 21434 solver.cpp:253]     Train net output #0: loss = 1.18357 (* 1 = 1.18357 loss)
I0525 17:45:04.926888 21434 sgd_solver.cpp:106] Iteration 29100, lr = 0.0025
I0525 17:45:13.667042 21434 solver.cpp:237] Iteration 29250, loss = 1.37013
I0525 17:45:13.667076 21434 solver.cpp:253]     Train net output #0: loss = 1.37013 (* 1 = 1.37013 loss)
I0525 17:45:13.667094 21434 sgd_solver.cpp:106] Iteration 29250, lr = 0.0025
I0525 17:45:22.407274 21434 solver.cpp:237] Iteration 29400, loss = 1.13836
I0525 17:45:22.407316 21434 solver.cpp:253]     Train net output #0: loss = 1.13836 (* 1 = 1.13836 loss)
I0525 17:45:22.407337 21434 sgd_solver.cpp:106] Iteration 29400, lr = 0.0025
I0525 17:45:31.147891 21434 solver.cpp:237] Iteration 29550, loss = 1.43236
I0525 17:45:31.147927 21434 solver.cpp:253]     Train net output #0: loss = 1.43236 (* 1 = 1.43236 loss)
I0525 17:45:31.147941 21434 sgd_solver.cpp:106] Iteration 29550, lr = 0.0025
I0525 17:45:39.884093 21434 solver.cpp:237] Iteration 29700, loss = 1.32862
I0525 17:45:39.884256 21434 solver.cpp:253]     Train net output #0: loss = 1.32862 (* 1 = 1.32862 loss)
I0525 17:45:39.884270 21434 sgd_solver.cpp:106] Iteration 29700, lr = 0.0025
I0525 17:45:48.616875 21434 solver.cpp:237] Iteration 29850, loss = 1.11726
I0525 17:45:48.616917 21434 solver.cpp:253]     Train net output #0: loss = 1.11726 (* 1 = 1.11726 loss)
I0525 17:45:48.616936 21434 sgd_solver.cpp:106] Iteration 29850, lr = 0.0025
I0525 17:45:57.298641 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_30000.caffemodel
I0525 17:45:57.380198 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_30000.solverstate
I0525 17:45:57.408217 21434 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 17:47:05.072468 21434 solver.cpp:409]     Test net output #0: accuracy = 0.866046
I0525 17:47:05.072648 21434 solver.cpp:409]     Test net output #1: loss = 0.414845 (* 1 = 0.414845 loss)
I0525 17:47:25.922943 21434 solver.cpp:237] Iteration 30000, loss = 1.40094
I0525 17:47:25.922993 21434 solver.cpp:253]     Train net output #0: loss = 1.40094 (* 1 = 1.40094 loss)
I0525 17:47:25.923012 21434 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0525 17:47:34.653825 21434 solver.cpp:237] Iteration 30150, loss = 1.15777
I0525 17:47:34.653858 21434 solver.cpp:253]     Train net output #0: loss = 1.15777 (* 1 = 1.15777 loss)
I0525 17:47:34.653875 21434 sgd_solver.cpp:106] Iteration 30150, lr = 0.0025
I0525 17:47:43.389524 21434 solver.cpp:237] Iteration 30300, loss = 1.22757
I0525 17:47:43.389683 21434 solver.cpp:253]     Train net output #0: loss = 1.22757 (* 1 = 1.22757 loss)
I0525 17:47:43.389698 21434 sgd_solver.cpp:106] Iteration 30300, lr = 0.0025
I0525 17:47:52.122913 21434 solver.cpp:237] Iteration 30450, loss = 1.19389
I0525 17:47:52.122961 21434 solver.cpp:253]     Train net output #0: loss = 1.19389 (* 1 = 1.19389 loss)
I0525 17:47:52.122977 21434 sgd_solver.cpp:106] Iteration 30450, lr = 0.0025
I0525 17:48:00.857841 21434 solver.cpp:237] Iteration 30600, loss = 1.24626
I0525 17:48:00.857877 21434 solver.cpp:253]     Train net output #0: loss = 1.24626 (* 1 = 1.24626 loss)
I0525 17:48:00.857892 21434 sgd_solver.cpp:106] Iteration 30600, lr = 0.0025
I0525 17:48:09.584569 21434 solver.cpp:237] Iteration 30750, loss = 1.14401
I0525 17:48:09.584604 21434 solver.cpp:253]     Train net output #0: loss = 1.14401 (* 1 = 1.14401 loss)
I0525 17:48:09.584619 21434 sgd_solver.cpp:106] Iteration 30750, lr = 0.0025
I0525 17:48:18.316752 21434 solver.cpp:237] Iteration 30900, loss = 1.34532
I0525 17:48:18.316926 21434 solver.cpp:253]     Train net output #0: loss = 1.34532 (* 1 = 1.34532 loss)
I0525 17:48:18.316939 21434 sgd_solver.cpp:106] Iteration 30900, lr = 0.0025
I0525 17:48:47.899852 21434 solver.cpp:237] Iteration 31050, loss = 1.3529
I0525 17:48:47.899904 21434 solver.cpp:253]     Train net output #0: loss = 1.3529 (* 1 = 1.3529 loss)
I0525 17:48:47.899924 21434 sgd_solver.cpp:106] Iteration 31050, lr = 0.0025
I0525 17:48:56.638360 21434 solver.cpp:237] Iteration 31200, loss = 1.05904
I0525 17:48:56.638516 21434 solver.cpp:253]     Train net output #0: loss = 1.05904 (* 1 = 1.05904 loss)
I0525 17:48:56.638530 21434 sgd_solver.cpp:106] Iteration 31200, lr = 0.0025
I0525 17:49:05.371093 21434 solver.cpp:237] Iteration 31350, loss = 1.18783
I0525 17:49:05.371139 21434 solver.cpp:253]     Train net output #0: loss = 1.18783 (* 1 = 1.18783 loss)
I0525 17:49:05.371160 21434 sgd_solver.cpp:106] Iteration 31350, lr = 0.0025
I0525 17:49:14.051931 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_31500.caffemodel
I0525 17:49:14.130841 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_31500.solverstate
I0525 17:49:14.174660 21434 solver.cpp:237] Iteration 31500, loss = 1.10235
I0525 17:49:14.174710 21434 solver.cpp:253]     Train net output #0: loss = 1.10235 (* 1 = 1.10235 loss)
I0525 17:49:14.174722 21434 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0525 17:49:22.909576 21434 solver.cpp:237] Iteration 31650, loss = 1.31609
I0525 17:49:22.909612 21434 solver.cpp:253]     Train net output #0: loss = 1.31609 (* 1 = 1.31609 loss)
I0525 17:49:22.909628 21434 sgd_solver.cpp:106] Iteration 31650, lr = 0.0025
I0525 17:49:31.646884 21434 solver.cpp:237] Iteration 31800, loss = 1.30267
I0525 17:49:31.647068 21434 solver.cpp:253]     Train net output #0: loss = 1.30267 (* 1 = 1.30267 loss)
I0525 17:49:31.647081 21434 sgd_solver.cpp:106] Iteration 31800, lr = 0.0025
I0525 17:49:40.378574 21434 solver.cpp:237] Iteration 31950, loss = 1.27509
I0525 17:49:40.378608 21434 solver.cpp:253]     Train net output #0: loss = 1.27509 (* 1 = 1.27509 loss)
I0525 17:49:40.378626 21434 sgd_solver.cpp:106] Iteration 31950, lr = 0.0025
I0525 17:50:09.926939 21434 solver.cpp:237] Iteration 32100, loss = 1.18206
I0525 17:50:09.927129 21434 solver.cpp:253]     Train net output #0: loss = 1.18206 (* 1 = 1.18206 loss)
I0525 17:50:09.927142 21434 sgd_solver.cpp:106] Iteration 32100, lr = 0.0025
I0525 17:50:18.661392 21434 solver.cpp:237] Iteration 32250, loss = 1.25581
I0525 17:50:18.661427 21434 solver.cpp:253]     Train net output #0: loss = 1.25581 (* 1 = 1.25581 loss)
I0525 17:50:18.661443 21434 sgd_solver.cpp:106] Iteration 32250, lr = 0.0025
I0525 17:50:27.394541 21434 solver.cpp:237] Iteration 32400, loss = 1.0485
I0525 17:50:27.394582 21434 solver.cpp:253]     Train net output #0: loss = 1.0485 (* 1 = 1.0485 loss)
I0525 17:50:27.394603 21434 sgd_solver.cpp:106] Iteration 32400, lr = 0.0025
I0525 17:50:36.128211 21434 solver.cpp:237] Iteration 32550, loss = 1.22536
I0525 17:50:36.128247 21434 solver.cpp:253]     Train net output #0: loss = 1.22536 (* 1 = 1.22536 loss)
I0525 17:50:36.128262 21434 sgd_solver.cpp:106] Iteration 32550, lr = 0.0025
I0525 17:50:44.855234 21434 solver.cpp:237] Iteration 32700, loss = 1.14081
I0525 17:50:44.855401 21434 solver.cpp:253]     Train net output #0: loss = 1.14081 (* 1 = 1.14081 loss)
I0525 17:50:44.855415 21434 sgd_solver.cpp:106] Iteration 32700, lr = 0.0025
I0525 17:50:53.590296 21434 solver.cpp:237] Iteration 32850, loss = 1.46486
I0525 17:50:53.590329 21434 solver.cpp:253]     Train net output #0: loss = 1.46486 (* 1 = 1.46486 loss)
I0525 17:50:53.590347 21434 sgd_solver.cpp:106] Iteration 32850, lr = 0.0025
I0525 17:51:02.265368 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_33000.caffemodel
I0525 17:51:02.343788 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_33000.solverstate
I0525 17:51:02.369022 21434 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 17:51:48.858597 21434 solver.cpp:409]     Test net output #0: accuracy = 0.866667
I0525 17:51:48.858775 21434 solver.cpp:409]     Test net output #1: loss = 0.407555 (* 1 = 0.407555 loss)
I0525 17:52:09.685014 21434 solver.cpp:237] Iteration 33000, loss = 1.27212
I0525 17:52:09.685070 21434 solver.cpp:253]     Train net output #0: loss = 1.27212 (* 1 = 1.27212 loss)
I0525 17:52:09.685086 21434 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0525 17:52:18.418232 21434 solver.cpp:237] Iteration 33150, loss = 1.18326
I0525 17:52:18.418269 21434 solver.cpp:253]     Train net output #0: loss = 1.18326 (* 1 = 1.18326 loss)
I0525 17:52:18.418285 21434 sgd_solver.cpp:106] Iteration 33150, lr = 0.0025
I0525 17:52:27.157363 21434 solver.cpp:237] Iteration 33300, loss = 1.40032
I0525 17:52:27.157546 21434 solver.cpp:253]     Train net output #0: loss = 1.40032 (* 1 = 1.40032 loss)
I0525 17:52:27.157560 21434 sgd_solver.cpp:106] Iteration 33300, lr = 0.0025
I0525 17:52:35.900116 21434 solver.cpp:237] Iteration 33450, loss = 1.3452
I0525 17:52:35.900151 21434 solver.cpp:253]     Train net output #0: loss = 1.3452 (* 1 = 1.3452 loss)
I0525 17:52:35.900168 21434 sgd_solver.cpp:106] Iteration 33450, lr = 0.0025
I0525 17:52:44.640821 21434 solver.cpp:237] Iteration 33600, loss = 1.43811
I0525 17:52:44.640856 21434 solver.cpp:253]     Train net output #0: loss = 1.43811 (* 1 = 1.43811 loss)
I0525 17:52:44.640873 21434 sgd_solver.cpp:106] Iteration 33600, lr = 0.0025
I0525 17:52:53.376318 21434 solver.cpp:237] Iteration 33750, loss = 1.29728
I0525 17:52:53.376366 21434 solver.cpp:253]     Train net output #0: loss = 1.29728 (* 1 = 1.29728 loss)
I0525 17:52:53.376385 21434 sgd_solver.cpp:106] Iteration 33750, lr = 0.0025
I0525 17:53:02.107652 21434 solver.cpp:237] Iteration 33900, loss = 1.21843
I0525 17:53:02.107810 21434 solver.cpp:253]     Train net output #0: loss = 1.21843 (* 1 = 1.21843 loss)
I0525 17:53:02.107825 21434 sgd_solver.cpp:106] Iteration 33900, lr = 0.0025
I0525 17:53:31.702759 21434 solver.cpp:237] Iteration 34050, loss = 1.32694
I0525 17:53:31.702813 21434 solver.cpp:253]     Train net output #0: loss = 1.32694 (* 1 = 1.32694 loss)
I0525 17:53:31.702829 21434 sgd_solver.cpp:106] Iteration 34050, lr = 0.0025
I0525 17:53:40.446076 21434 solver.cpp:237] Iteration 34200, loss = 1.28834
I0525 17:53:40.446249 21434 solver.cpp:253]     Train net output #0: loss = 1.28834 (* 1 = 1.28834 loss)
I0525 17:53:40.446264 21434 sgd_solver.cpp:106] Iteration 34200, lr = 0.0025
I0525 17:53:49.181524 21434 solver.cpp:237] Iteration 34350, loss = 1.46483
I0525 17:53:49.181560 21434 solver.cpp:253]     Train net output #0: loss = 1.46483 (* 1 = 1.46483 loss)
I0525 17:53:49.181574 21434 sgd_solver.cpp:106] Iteration 34350, lr = 0.0025
I0525 17:53:57.862982 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_34500.caffemodel
I0525 17:53:57.941334 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_34500.solverstate
I0525 17:53:57.984395 21434 solver.cpp:237] Iteration 34500, loss = 1.24125
I0525 17:53:57.984444 21434 solver.cpp:253]     Train net output #0: loss = 1.24125 (* 1 = 1.24125 loss)
I0525 17:53:57.984458 21434 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0525 17:54:06.718853 21434 solver.cpp:237] Iteration 34650, loss = 1.32136
I0525 17:54:06.718899 21434 solver.cpp:253]     Train net output #0: loss = 1.32136 (* 1 = 1.32136 loss)
I0525 17:54:06.718919 21434 sgd_solver.cpp:106] Iteration 34650, lr = 0.0025
I0525 17:54:15.457515 21434 solver.cpp:237] Iteration 34800, loss = 1.19523
I0525 17:54:15.457676 21434 solver.cpp:253]     Train net output #0: loss = 1.19523 (* 1 = 1.19523 loss)
I0525 17:54:15.457690 21434 sgd_solver.cpp:106] Iteration 34800, lr = 0.0025
I0525 17:54:24.198256 21434 solver.cpp:237] Iteration 34950, loss = 1.27396
I0525 17:54:24.198290 21434 solver.cpp:253]     Train net output #0: loss = 1.27396 (* 1 = 1.27396 loss)
I0525 17:54:24.198307 21434 sgd_solver.cpp:106] Iteration 34950, lr = 0.0025
I0525 17:54:53.767406 21434 solver.cpp:237] Iteration 35100, loss = 1.15226
I0525 17:54:53.767590 21434 solver.cpp:253]     Train net output #0: loss = 1.15226 (* 1 = 1.15226 loss)
I0525 17:54:53.767606 21434 sgd_solver.cpp:106] Iteration 35100, lr = 0.0025
I0525 17:55:02.500833 21434 solver.cpp:237] Iteration 35250, loss = 1.17687
I0525 17:55:02.500874 21434 solver.cpp:253]     Train net output #0: loss = 1.17687 (* 1 = 1.17687 loss)
I0525 17:55:02.500896 21434 sgd_solver.cpp:106] Iteration 35250, lr = 0.0025
I0525 17:55:11.241358 21434 solver.cpp:237] Iteration 35400, loss = 1.24122
I0525 17:55:11.241394 21434 solver.cpp:253]     Train net output #0: loss = 1.24122 (* 1 = 1.24122 loss)
I0525 17:55:11.241410 21434 sgd_solver.cpp:106] Iteration 35400, lr = 0.0025
I0525 17:55:19.980522 21434 solver.cpp:237] Iteration 35550, loss = 1.13499
I0525 17:55:19.980564 21434 solver.cpp:253]     Train net output #0: loss = 1.13499 (* 1 = 1.13499 loss)
I0525 17:55:19.980583 21434 sgd_solver.cpp:106] Iteration 35550, lr = 0.0025
I0525 17:55:28.720657 21434 solver.cpp:237] Iteration 35700, loss = 1.21259
I0525 17:55:28.720824 21434 solver.cpp:253]     Train net output #0: loss = 1.21259 (* 1 = 1.21259 loss)
I0525 17:55:28.720839 21434 sgd_solver.cpp:106] Iteration 35700, lr = 0.0025
I0525 17:55:37.459460 21434 solver.cpp:237] Iteration 35850, loss = 1.28735
I0525 17:55:37.459493 21434 solver.cpp:253]     Train net output #0: loss = 1.28735 (* 1 = 1.28735 loss)
I0525 17:55:37.459511 21434 sgd_solver.cpp:106] Iteration 35850, lr = 0.0025
I0525 17:55:46.140563 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_36000.caffemodel
I0525 17:55:46.221639 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_36000.solverstate
I0525 17:55:46.248548 21434 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 17:56:53.951885 21434 solver.cpp:409]     Test net output #0: accuracy = 0.87238
I0525 17:56:53.952069 21434 solver.cpp:409]     Test net output #1: loss = 0.427717 (* 1 = 0.427717 loss)
I0525 17:57:14.831336 21434 solver.cpp:237] Iteration 36000, loss = 1.01649
I0525 17:57:14.831393 21434 solver.cpp:253]     Train net output #0: loss = 1.01649 (* 1 = 1.01649 loss)
I0525 17:57:14.831408 21434 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0525 17:57:23.557061 21434 solver.cpp:237] Iteration 36150, loss = 1.31341
I0525 17:57:23.557096 21434 solver.cpp:253]     Train net output #0: loss = 1.31341 (* 1 = 1.31341 loss)
I0525 17:57:23.557112 21434 sgd_solver.cpp:106] Iteration 36150, lr = 0.0025
I0525 17:57:32.282503 21434 solver.cpp:237] Iteration 36300, loss = 1.27791
I0525 17:57:32.282680 21434 solver.cpp:253]     Train net output #0: loss = 1.27791 (* 1 = 1.27791 loss)
I0525 17:57:32.282693 21434 sgd_solver.cpp:106] Iteration 36300, lr = 0.0025
I0525 17:57:41.012245 21434 solver.cpp:237] Iteration 36450, loss = 1.35989
I0525 17:57:41.012280 21434 solver.cpp:253]     Train net output #0: loss = 1.35989 (* 1 = 1.35989 loss)
I0525 17:57:41.012297 21434 sgd_solver.cpp:106] Iteration 36450, lr = 0.0025
I0525 17:57:49.742341 21434 solver.cpp:237] Iteration 36600, loss = 1.22729
I0525 17:57:49.742389 21434 solver.cpp:253]     Train net output #0: loss = 1.22729 (* 1 = 1.22729 loss)
I0525 17:57:49.742406 21434 sgd_solver.cpp:106] Iteration 36600, lr = 0.0025
I0525 17:57:58.464098 21434 solver.cpp:237] Iteration 36750, loss = 1.26721
I0525 17:57:58.464134 21434 solver.cpp:253]     Train net output #0: loss = 1.26721 (* 1 = 1.26721 loss)
I0525 17:57:58.464150 21434 sgd_solver.cpp:106] Iteration 36750, lr = 0.0025
I0525 17:58:07.189707 21434 solver.cpp:237] Iteration 36900, loss = 1.16248
I0525 17:58:07.189864 21434 solver.cpp:253]     Train net output #0: loss = 1.16248 (* 1 = 1.16248 loss)
I0525 17:58:07.189878 21434 sgd_solver.cpp:106] Iteration 36900, lr = 0.0025
I0525 17:58:36.758186 21434 solver.cpp:237] Iteration 37050, loss = 1.24442
I0525 17:58:36.758240 21434 solver.cpp:253]     Train net output #0: loss = 1.24442 (* 1 = 1.24442 loss)
I0525 17:58:36.758256 21434 sgd_solver.cpp:106] Iteration 37050, lr = 0.0025
I0525 17:58:45.481436 21434 solver.cpp:237] Iteration 37200, loss = 1.27453
I0525 17:58:45.481619 21434 solver.cpp:253]     Train net output #0: loss = 1.27453 (* 1 = 1.27453 loss)
I0525 17:58:45.481633 21434 sgd_solver.cpp:106] Iteration 37200, lr = 0.0025
I0525 17:58:54.204841 21434 solver.cpp:237] Iteration 37350, loss = 1.20679
I0525 17:58:54.204875 21434 solver.cpp:253]     Train net output #0: loss = 1.20679 (* 1 = 1.20679 loss)
I0525 17:58:54.204893 21434 sgd_solver.cpp:106] Iteration 37350, lr = 0.0025
I0525 17:59:02.869323 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_37500.caffemodel
I0525 17:59:02.950078 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_37500.solverstate
I0525 17:59:02.995748 21434 solver.cpp:237] Iteration 37500, loss = 1.30458
I0525 17:59:02.995801 21434 solver.cpp:253]     Train net output #0: loss = 1.30458 (* 1 = 1.30458 loss)
I0525 17:59:02.995818 21434 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0525 17:59:11.722410 21434 solver.cpp:237] Iteration 37650, loss = 1.2472
I0525 17:59:11.722455 21434 solver.cpp:253]     Train net output #0: loss = 1.2472 (* 1 = 1.2472 loss)
I0525 17:59:11.722473 21434 sgd_solver.cpp:106] Iteration 37650, lr = 0.0025
I0525 17:59:20.448463 21434 solver.cpp:237] Iteration 37800, loss = 1.27938
I0525 17:59:20.448626 21434 solver.cpp:253]     Train net output #0: loss = 1.27938 (* 1 = 1.27938 loss)
I0525 17:59:20.448639 21434 sgd_solver.cpp:106] Iteration 37800, lr = 0.0025
I0525 17:59:29.174705 21434 solver.cpp:237] Iteration 37950, loss = 1.1074
I0525 17:59:29.174741 21434 solver.cpp:253]     Train net output #0: loss = 1.1074 (* 1 = 1.1074 loss)
I0525 17:59:29.174757 21434 sgd_solver.cpp:106] Iteration 37950, lr = 0.0025
I0525 17:59:58.746306 21434 solver.cpp:237] Iteration 38100, loss = 1.10353
I0525 17:59:58.746489 21434 solver.cpp:253]     Train net output #0: loss = 1.10353 (* 1 = 1.10353 loss)
I0525 17:59:58.746502 21434 sgd_solver.cpp:106] Iteration 38100, lr = 0.0025
I0525 18:00:07.474781 21434 solver.cpp:237] Iteration 38250, loss = 1.35351
I0525 18:00:07.474815 21434 solver.cpp:253]     Train net output #0: loss = 1.35351 (* 1 = 1.35351 loss)
I0525 18:00:07.474829 21434 sgd_solver.cpp:106] Iteration 38250, lr = 0.0025
I0525 18:00:16.204604 21434 solver.cpp:237] Iteration 38400, loss = 1.26609
I0525 18:00:16.204639 21434 solver.cpp:253]     Train net output #0: loss = 1.26609 (* 1 = 1.26609 loss)
I0525 18:00:16.204655 21434 sgd_solver.cpp:106] Iteration 38400, lr = 0.0025
I0525 18:00:24.931375 21434 solver.cpp:237] Iteration 38550, loss = 1.51512
I0525 18:00:24.931427 21434 solver.cpp:253]     Train net output #0: loss = 1.51512 (* 1 = 1.51512 loss)
I0525 18:00:24.931442 21434 sgd_solver.cpp:106] Iteration 38550, lr = 0.0025
I0525 18:00:33.651211 21434 solver.cpp:237] Iteration 38700, loss = 1.34611
I0525 18:00:33.651370 21434 solver.cpp:253]     Train net output #0: loss = 1.34611 (* 1 = 1.34611 loss)
I0525 18:00:33.651382 21434 sgd_solver.cpp:106] Iteration 38700, lr = 0.0025
I0525 18:00:42.375113 21434 solver.cpp:237] Iteration 38850, loss = 1.08264
I0525 18:00:42.375152 21434 solver.cpp:253]     Train net output #0: loss = 1.08264 (* 1 = 1.08264 loss)
I0525 18:00:42.375169 21434 sgd_solver.cpp:106] Iteration 38850, lr = 0.0025
I0525 18:00:51.042049 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_39000.caffemodel
I0525 18:00:51.120733 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_39000.solverstate
I0525 18:00:51.146178 21434 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 18:01:37.995709 21434 solver.cpp:409]     Test net output #0: accuracy = 0.87092
I0525 18:01:37.995905 21434 solver.cpp:409]     Test net output #1: loss = 0.419839 (* 1 = 0.419839 loss)
I0525 18:01:58.852792 21434 solver.cpp:237] Iteration 39000, loss = 1.29108
I0525 18:01:58.852847 21434 solver.cpp:253]     Train net output #0: loss = 1.29108 (* 1 = 1.29108 loss)
I0525 18:01:58.852862 21434 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0525 18:02:07.594876 21434 solver.cpp:237] Iteration 39150, loss = 1.05478
I0525 18:02:07.594926 21434 solver.cpp:253]     Train net output #0: loss = 1.05478 (* 1 = 1.05478 loss)
I0525 18:02:07.594945 21434 sgd_solver.cpp:106] Iteration 39150, lr = 0.0025
I0525 18:02:16.332929 21434 solver.cpp:237] Iteration 39300, loss = 1.0917
I0525 18:02:16.333102 21434 solver.cpp:253]     Train net output #0: loss = 1.0917 (* 1 = 1.0917 loss)
I0525 18:02:16.333117 21434 sgd_solver.cpp:106] Iteration 39300, lr = 0.0025
I0525 18:02:25.064610 21434 solver.cpp:237] Iteration 39450, loss = 1.3678
I0525 18:02:25.064658 21434 solver.cpp:253]     Train net output #0: loss = 1.3678 (* 1 = 1.3678 loss)
I0525 18:02:25.064676 21434 sgd_solver.cpp:106] Iteration 39450, lr = 0.0025
I0525 18:02:33.802923 21434 solver.cpp:237] Iteration 39600, loss = 1.30019
I0525 18:02:33.802958 21434 solver.cpp:253]     Train net output #0: loss = 1.30019 (* 1 = 1.30019 loss)
I0525 18:02:33.802974 21434 sgd_solver.cpp:106] Iteration 39600, lr = 0.0025
I0525 18:02:42.545855 21434 solver.cpp:237] Iteration 39750, loss = 1.31689
I0525 18:02:42.545889 21434 solver.cpp:253]     Train net output #0: loss = 1.31689 (* 1 = 1.31689 loss)
I0525 18:02:42.545905 21434 sgd_solver.cpp:106] Iteration 39750, lr = 0.0025
I0525 18:02:51.283959 21434 solver.cpp:237] Iteration 39900, loss = 1.18373
I0525 18:02:51.284145 21434 solver.cpp:253]     Train net output #0: loss = 1.18373 (* 1 = 1.18373 loss)
I0525 18:02:51.284159 21434 sgd_solver.cpp:106] Iteration 39900, lr = 0.0025
I0525 18:03:20.842579 21434 solver.cpp:237] Iteration 40050, loss = 1.49527
I0525 18:03:20.842630 21434 solver.cpp:253]     Train net output #0: loss = 1.49527 (* 1 = 1.49527 loss)
I0525 18:03:20.842650 21434 sgd_solver.cpp:106] Iteration 40050, lr = 0.0025
I0525 18:03:29.581735 21434 solver.cpp:237] Iteration 40200, loss = 1.22027
I0525 18:03:29.581902 21434 solver.cpp:253]     Train net output #0: loss = 1.22027 (* 1 = 1.22027 loss)
I0525 18:03:29.581915 21434 sgd_solver.cpp:106] Iteration 40200, lr = 0.0025
I0525 18:03:38.320986 21434 solver.cpp:237] Iteration 40350, loss = 1.25269
I0525 18:03:38.321022 21434 solver.cpp:253]     Train net output #0: loss = 1.25269 (* 1 = 1.25269 loss)
I0525 18:03:38.321038 21434 sgd_solver.cpp:106] Iteration 40350, lr = 0.0025
I0525 18:03:46.997916 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_40500.caffemodel
I0525 18:03:47.076372 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_40500.solverstate
I0525 18:03:47.119911 21434 solver.cpp:237] Iteration 40500, loss = 1.27854
I0525 18:03:47.119961 21434 solver.cpp:253]     Train net output #0: loss = 1.27854 (* 1 = 1.27854 loss)
I0525 18:03:47.119974 21434 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0525 18:03:55.861176 21434 solver.cpp:237] Iteration 40650, loss = 1.27132
I0525 18:03:55.861212 21434 solver.cpp:253]     Train net output #0: loss = 1.27132 (* 1 = 1.27132 loss)
I0525 18:03:55.861228 21434 sgd_solver.cpp:106] Iteration 40650, lr = 0.0025
I0525 18:04:04.597798 21434 solver.cpp:237] Iteration 40800, loss = 1.1931
I0525 18:04:04.597980 21434 solver.cpp:253]     Train net output #0: loss = 1.1931 (* 1 = 1.1931 loss)
I0525 18:04:04.597995 21434 sgd_solver.cpp:106] Iteration 40800, lr = 0.0025
I0525 18:04:13.332315 21434 solver.cpp:237] Iteration 40950, loss = 1.11837
I0525 18:04:13.332350 21434 solver.cpp:253]     Train net output #0: loss = 1.11837 (* 1 = 1.11837 loss)
I0525 18:04:13.332367 21434 sgd_solver.cpp:106] Iteration 40950, lr = 0.0025
I0525 18:04:42.904876 21434 solver.cpp:237] Iteration 41100, loss = 1.1701
I0525 18:04:42.905073 21434 solver.cpp:253]     Train net output #0: loss = 1.1701 (* 1 = 1.1701 loss)
I0525 18:04:42.905089 21434 sgd_solver.cpp:106] Iteration 41100, lr = 0.0025
I0525 18:04:51.641320 21434 solver.cpp:237] Iteration 41250, loss = 1.2614
I0525 18:04:51.641355 21434 solver.cpp:253]     Train net output #0: loss = 1.2614 (* 1 = 1.2614 loss)
I0525 18:04:51.641371 21434 sgd_solver.cpp:106] Iteration 41250, lr = 0.0025
I0525 18:05:00.375532 21434 solver.cpp:237] Iteration 41400, loss = 1.06283
I0525 18:05:00.375576 21434 solver.cpp:253]     Train net output #0: loss = 1.06283 (* 1 = 1.06283 loss)
I0525 18:05:00.375597 21434 sgd_solver.cpp:106] Iteration 41400, lr = 0.0025
I0525 18:05:09.117123 21434 solver.cpp:237] Iteration 41550, loss = 1.18563
I0525 18:05:09.117159 21434 solver.cpp:253]     Train net output #0: loss = 1.18563 (* 1 = 1.18563 loss)
I0525 18:05:09.117175 21434 sgd_solver.cpp:106] Iteration 41550, lr = 0.0025
I0525 18:05:17.851851 21434 solver.cpp:237] Iteration 41700, loss = 1.08975
I0525 18:05:17.852012 21434 solver.cpp:253]     Train net output #0: loss = 1.08975 (* 1 = 1.08975 loss)
I0525 18:05:17.852026 21434 sgd_solver.cpp:106] Iteration 41700, lr = 0.0025
I0525 18:05:26.590200 21434 solver.cpp:237] Iteration 41850, loss = 1.1689
I0525 18:05:26.590246 21434 solver.cpp:253]     Train net output #0: loss = 1.1689 (* 1 = 1.1689 loss)
I0525 18:05:26.590262 21434 sgd_solver.cpp:106] Iteration 41850, lr = 0.0025
I0525 18:05:35.273952 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_42000.caffemodel
I0525 18:05:35.352852 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_42000.solverstate
I0525 18:05:35.378446 21434 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 18:06:43.107269 21434 solver.cpp:409]     Test net output #0: accuracy = 0.874747
I0525 18:06:43.107456 21434 solver.cpp:409]     Test net output #1: loss = 0.395039 (* 1 = 0.395039 loss)
I0525 18:07:03.947417 21434 solver.cpp:237] Iteration 42000, loss = 1.28829
I0525 18:07:03.947474 21434 solver.cpp:253]     Train net output #0: loss = 1.28829 (* 1 = 1.28829 loss)
I0525 18:07:03.947489 21434 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0525 18:07:12.675647 21434 solver.cpp:237] Iteration 42150, loss = 1.12462
I0525 18:07:12.675681 21434 solver.cpp:253]     Train net output #0: loss = 1.12462 (* 1 = 1.12462 loss)
I0525 18:07:12.675698 21434 sgd_solver.cpp:106] Iteration 42150, lr = 0.0025
I0525 18:07:21.405143 21434 solver.cpp:237] Iteration 42300, loss = 0.980232
I0525 18:07:21.405313 21434 solver.cpp:253]     Train net output #0: loss = 0.980232 (* 1 = 0.980232 loss)
I0525 18:07:21.405329 21434 sgd_solver.cpp:106] Iteration 42300, lr = 0.0025
I0525 18:07:30.139662 21434 solver.cpp:237] Iteration 42450, loss = 1.28928
I0525 18:07:30.139704 21434 solver.cpp:253]     Train net output #0: loss = 1.28928 (* 1 = 1.28928 loss)
I0525 18:07:30.139725 21434 sgd_solver.cpp:106] Iteration 42450, lr = 0.0025
I0525 18:07:38.874050 21434 solver.cpp:237] Iteration 42600, loss = 1.33195
I0525 18:07:38.874084 21434 solver.cpp:253]     Train net output #0: loss = 1.33195 (* 1 = 1.33195 loss)
I0525 18:07:38.874100 21434 sgd_solver.cpp:106] Iteration 42600, lr = 0.0025
I0525 18:07:47.607628 21434 solver.cpp:237] Iteration 42750, loss = 1.18185
I0525 18:07:47.607663 21434 solver.cpp:253]     Train net output #0: loss = 1.18185 (* 1 = 1.18185 loss)
I0525 18:07:47.607679 21434 sgd_solver.cpp:106] Iteration 42750, lr = 0.0025
I0525 18:07:56.346575 21434 solver.cpp:237] Iteration 42900, loss = 0.960688
I0525 18:07:56.346752 21434 solver.cpp:253]     Train net output #0: loss = 0.960688 (* 1 = 0.960688 loss)
I0525 18:07:56.346767 21434 sgd_solver.cpp:106] Iteration 42900, lr = 0.0025
I0525 18:08:25.925709 21434 solver.cpp:237] Iteration 43050, loss = 1.11637
I0525 18:08:25.925760 21434 solver.cpp:253]     Train net output #0: loss = 1.11637 (* 1 = 1.11637 loss)
I0525 18:08:25.925781 21434 sgd_solver.cpp:106] Iteration 43050, lr = 0.0025
I0525 18:08:34.657289 21434 solver.cpp:237] Iteration 43200, loss = 1.3883
I0525 18:08:34.657467 21434 solver.cpp:253]     Train net output #0: loss = 1.3883 (* 1 = 1.3883 loss)
I0525 18:08:34.657482 21434 sgd_solver.cpp:106] Iteration 43200, lr = 0.0025
I0525 18:08:43.390779 21434 solver.cpp:237] Iteration 43350, loss = 1.26749
I0525 18:08:43.390825 21434 solver.cpp:253]     Train net output #0: loss = 1.26749 (* 1 = 1.26749 loss)
I0525 18:08:43.390841 21434 sgd_solver.cpp:106] Iteration 43350, lr = 0.0025
I0525 18:08:52.064117 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_43500.caffemodel
I0525 18:08:52.145423 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_43500.solverstate
I0525 18:08:52.191087 21434 solver.cpp:237] Iteration 43500, loss = 1.34579
I0525 18:08:52.191140 21434 solver.cpp:253]     Train net output #0: loss = 1.34579 (* 1 = 1.34579 loss)
I0525 18:08:52.191157 21434 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0525 18:09:00.928874 21434 solver.cpp:237] Iteration 43650, loss = 1.18826
I0525 18:09:00.928908 21434 solver.cpp:253]     Train net output #0: loss = 1.18826 (* 1 = 1.18826 loss)
I0525 18:09:00.928925 21434 sgd_solver.cpp:106] Iteration 43650, lr = 0.0025
I0525 18:09:09.662358 21434 solver.cpp:237] Iteration 43800, loss = 1.15292
I0525 18:09:09.662545 21434 solver.cpp:253]     Train net output #0: loss = 1.15292 (* 1 = 1.15292 loss)
I0525 18:09:09.662560 21434 sgd_solver.cpp:106] Iteration 43800, lr = 0.0025
I0525 18:09:18.399665 21434 solver.cpp:237] Iteration 43950, loss = 1.17518
I0525 18:09:18.399699 21434 solver.cpp:253]     Train net output #0: loss = 1.17518 (* 1 = 1.17518 loss)
I0525 18:09:18.399716 21434 sgd_solver.cpp:106] Iteration 43950, lr = 0.0025
I0525 18:09:47.987463 21434 solver.cpp:237] Iteration 44100, loss = 1.1211
I0525 18:09:47.987651 21434 solver.cpp:253]     Train net output #0: loss = 1.1211 (* 1 = 1.1211 loss)
I0525 18:09:47.987668 21434 sgd_solver.cpp:106] Iteration 44100, lr = 0.0025
I0525 18:09:56.723425 21434 solver.cpp:237] Iteration 44250, loss = 1.31775
I0525 18:09:56.723469 21434 solver.cpp:253]     Train net output #0: loss = 1.31775 (* 1 = 1.31775 loss)
I0525 18:09:56.723489 21434 sgd_solver.cpp:106] Iteration 44250, lr = 0.0025
I0525 18:10:05.459055 21434 solver.cpp:237] Iteration 44400, loss = 1.16719
I0525 18:10:05.459090 21434 solver.cpp:253]     Train net output #0: loss = 1.16719 (* 1 = 1.16719 loss)
I0525 18:10:05.459106 21434 sgd_solver.cpp:106] Iteration 44400, lr = 0.0025
I0525 18:10:14.187441 21434 solver.cpp:237] Iteration 44550, loss = 1.32806
I0525 18:10:14.187475 21434 solver.cpp:253]     Train net output #0: loss = 1.32806 (* 1 = 1.32806 loss)
I0525 18:10:14.187492 21434 sgd_solver.cpp:106] Iteration 44550, lr = 0.0025
I0525 18:10:22.922345 21434 solver.cpp:237] Iteration 44700, loss = 1.33507
I0525 18:10:22.922518 21434 solver.cpp:253]     Train net output #0: loss = 1.33507 (* 1 = 1.33507 loss)
I0525 18:10:22.922533 21434 sgd_solver.cpp:106] Iteration 44700, lr = 0.0025
I0525 18:10:31.658387 21434 solver.cpp:237] Iteration 44850, loss = 1.20549
I0525 18:10:31.658422 21434 solver.cpp:253]     Train net output #0: loss = 1.20549 (* 1 = 1.20549 loss)
I0525 18:10:31.658438 21434 sgd_solver.cpp:106] Iteration 44850, lr = 0.0025
I0525 18:10:40.336318 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_45000.caffemodel
I0525 18:10:40.417289 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_45000.solverstate
I0525 18:10:40.445083 21434 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 18:11:26.979224 21434 solver.cpp:409]     Test net output #0: accuracy = 0.878648
I0525 18:11:26.979423 21434 solver.cpp:409]     Test net output #1: loss = 0.39827 (* 1 = 0.39827 loss)
I0525 18:11:47.845263 21434 solver.cpp:237] Iteration 45000, loss = 1.21474
I0525 18:11:47.845319 21434 solver.cpp:253]     Train net output #0: loss = 1.21474 (* 1 = 1.21474 loss)
I0525 18:11:47.845336 21434 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0525 18:11:56.582281 21434 solver.cpp:237] Iteration 45150, loss = 1.10624
I0525 18:11:56.582316 21434 solver.cpp:253]     Train net output #0: loss = 1.10624 (* 1 = 1.10624 loss)
I0525 18:11:56.582332 21434 sgd_solver.cpp:106] Iteration 45150, lr = 0.0025
I0525 18:12:05.316712 21434 solver.cpp:237] Iteration 45300, loss = 1.34774
I0525 18:12:05.316890 21434 solver.cpp:253]     Train net output #0: loss = 1.34774 (* 1 = 1.34774 loss)
I0525 18:12:05.316903 21434 sgd_solver.cpp:106] Iteration 45300, lr = 0.0025
I0525 18:12:14.052006 21434 solver.cpp:237] Iteration 45450, loss = 1.17336
I0525 18:12:14.052040 21434 solver.cpp:253]     Train net output #0: loss = 1.17336 (* 1 = 1.17336 loss)
I0525 18:12:14.052057 21434 sgd_solver.cpp:106] Iteration 45450, lr = 0.0025
I0525 18:12:22.784400 21434 solver.cpp:237] Iteration 45600, loss = 1.01431
I0525 18:12:22.784435 21434 solver.cpp:253]     Train net output #0: loss = 1.01431 (* 1 = 1.01431 loss)
I0525 18:12:22.784451 21434 sgd_solver.cpp:106] Iteration 45600, lr = 0.0025
I0525 18:12:31.522248 21434 solver.cpp:237] Iteration 45750, loss = 1.33069
I0525 18:12:31.522295 21434 solver.cpp:253]     Train net output #0: loss = 1.33069 (* 1 = 1.33069 loss)
I0525 18:12:31.522311 21434 sgd_solver.cpp:106] Iteration 45750, lr = 0.0025
I0525 18:12:40.257563 21434 solver.cpp:237] Iteration 45900, loss = 1.16439
I0525 18:12:40.257728 21434 solver.cpp:253]     Train net output #0: loss = 1.16439 (* 1 = 1.16439 loss)
I0525 18:12:40.257743 21434 sgd_solver.cpp:106] Iteration 45900, lr = 0.0025
I0525 18:13:09.864225 21434 solver.cpp:237] Iteration 46050, loss = 1.26758
I0525 18:13:09.864281 21434 solver.cpp:253]     Train net output #0: loss = 1.26758 (* 1 = 1.26758 loss)
I0525 18:13:09.864298 21434 sgd_solver.cpp:106] Iteration 46050, lr = 0.0025
I0525 18:13:18.595983 21434 solver.cpp:237] Iteration 46200, loss = 1.07646
I0525 18:13:18.596165 21434 solver.cpp:253]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I0525 18:13:18.596179 21434 sgd_solver.cpp:106] Iteration 46200, lr = 0.0025
I0525 18:13:27.335245 21434 solver.cpp:237] Iteration 46350, loss = 1.21405
I0525 18:13:27.335281 21434 solver.cpp:253]     Train net output #0: loss = 1.21405 (* 1 = 1.21405 loss)
I0525 18:13:27.335299 21434 sgd_solver.cpp:106] Iteration 46350, lr = 0.0025
I0525 18:13:36.016377 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_46500.caffemodel
I0525 18:13:36.094614 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_46500.solverstate
I0525 18:13:36.137997 21434 solver.cpp:237] Iteration 46500, loss = 1.22109
I0525 18:13:36.138041 21434 solver.cpp:253]     Train net output #0: loss = 1.22109 (* 1 = 1.22109 loss)
I0525 18:13:36.138059 21434 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0525 18:13:44.872921 21434 solver.cpp:237] Iteration 46650, loss = 1.31871
I0525 18:13:44.872961 21434 solver.cpp:253]     Train net output #0: loss = 1.31871 (* 1 = 1.31871 loss)
I0525 18:13:44.872979 21434 sgd_solver.cpp:106] Iteration 46650, lr = 0.0025
I0525 18:13:53.609390 21434 solver.cpp:237] Iteration 46800, loss = 1.09339
I0525 18:13:53.609566 21434 solver.cpp:253]     Train net output #0: loss = 1.09339 (* 1 = 1.09339 loss)
I0525 18:13:53.609580 21434 sgd_solver.cpp:106] Iteration 46800, lr = 0.0025
I0525 18:14:02.347384 21434 solver.cpp:237] Iteration 46950, loss = 1.21129
I0525 18:14:02.347417 21434 solver.cpp:253]     Train net output #0: loss = 1.21129 (* 1 = 1.21129 loss)
I0525 18:14:02.347434 21434 sgd_solver.cpp:106] Iteration 46950, lr = 0.0025
I0525 18:14:31.902551 21434 solver.cpp:237] Iteration 47100, loss = 1.18254
I0525 18:14:31.902743 21434 solver.cpp:253]     Train net output #0: loss = 1.18254 (* 1 = 1.18254 loss)
I0525 18:14:31.902757 21434 sgd_solver.cpp:106] Iteration 47100, lr = 0.0025
I0525 18:14:40.639472 21434 solver.cpp:237] Iteration 47250, loss = 1.2745
I0525 18:14:40.639508 21434 solver.cpp:253]     Train net output #0: loss = 1.2745 (* 1 = 1.2745 loss)
I0525 18:14:40.639523 21434 sgd_solver.cpp:106] Iteration 47250, lr = 0.0025
I0525 18:14:49.364565 21434 solver.cpp:237] Iteration 47400, loss = 1.2512
I0525 18:14:49.364600 21434 solver.cpp:253]     Train net output #0: loss = 1.2512 (* 1 = 1.2512 loss)
I0525 18:14:49.364616 21434 sgd_solver.cpp:106] Iteration 47400, lr = 0.0025
I0525 18:14:58.097159 21434 solver.cpp:237] Iteration 47550, loss = 1.09456
I0525 18:14:58.097201 21434 solver.cpp:253]     Train net output #0: loss = 1.09456 (* 1 = 1.09456 loss)
I0525 18:14:58.097221 21434 sgd_solver.cpp:106] Iteration 47550, lr = 0.0025
I0525 18:15:06.829273 21434 solver.cpp:237] Iteration 47700, loss = 1.23598
I0525 18:15:06.829438 21434 solver.cpp:253]     Train net output #0: loss = 1.23598 (* 1 = 1.23598 loss)
I0525 18:15:06.829452 21434 sgd_solver.cpp:106] Iteration 47700, lr = 0.0025
I0525 18:15:15.569056 21434 solver.cpp:237] Iteration 47850, loss = 1.18722
I0525 18:15:15.569089 21434 solver.cpp:253]     Train net output #0: loss = 1.18722 (* 1 = 1.18722 loss)
I0525 18:15:15.569106 21434 sgd_solver.cpp:106] Iteration 47850, lr = 0.0025
I0525 18:15:24.241463 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_48000.caffemodel
I0525 18:15:24.320001 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_48000.solverstate
I0525 18:15:24.345736 21434 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 18:16:32.056269 21434 solver.cpp:409]     Test net output #0: accuracy = 0.880361
I0525 18:16:32.056458 21434 solver.cpp:409]     Test net output #1: loss = 0.380917 (* 1 = 0.380917 loss)
I0525 18:16:52.927989 21434 solver.cpp:237] Iteration 48000, loss = 1.02625
I0525 18:16:52.928043 21434 solver.cpp:253]     Train net output #0: loss = 1.02625 (* 1 = 1.02625 loss)
I0525 18:16:52.928061 21434 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0525 18:17:01.659768 21434 solver.cpp:237] Iteration 48150, loss = 1.16153
I0525 18:17:01.659816 21434 solver.cpp:253]     Train net output #0: loss = 1.16153 (* 1 = 1.16153 loss)
I0525 18:17:01.659837 21434 sgd_solver.cpp:106] Iteration 48150, lr = 0.0025
I0525 18:17:10.384912 21434 solver.cpp:237] Iteration 48300, loss = 1.12889
I0525 18:17:10.385089 21434 solver.cpp:253]     Train net output #0: loss = 1.12889 (* 1 = 1.12889 loss)
I0525 18:17:10.385104 21434 sgd_solver.cpp:106] Iteration 48300, lr = 0.0025
I0525 18:17:19.107100 21434 solver.cpp:237] Iteration 48450, loss = 1.18505
I0525 18:17:19.107141 21434 solver.cpp:253]     Train net output #0: loss = 1.18505 (* 1 = 1.18505 loss)
I0525 18:17:19.107157 21434 sgd_solver.cpp:106] Iteration 48450, lr = 0.0025
I0525 18:17:27.831701 21434 solver.cpp:237] Iteration 48600, loss = 1.04984
I0525 18:17:27.831745 21434 solver.cpp:253]     Train net output #0: loss = 1.04984 (* 1 = 1.04984 loss)
I0525 18:17:27.831764 21434 sgd_solver.cpp:106] Iteration 48600, lr = 0.0025
I0525 18:17:36.558259 21434 solver.cpp:237] Iteration 48750, loss = 1.12303
I0525 18:17:36.558295 21434 solver.cpp:253]     Train net output #0: loss = 1.12303 (* 1 = 1.12303 loss)
I0525 18:17:36.558311 21434 sgd_solver.cpp:106] Iteration 48750, lr = 0.0025
I0525 18:17:45.285787 21434 solver.cpp:237] Iteration 48900, loss = 1.09204
I0525 18:17:45.285962 21434 solver.cpp:253]     Train net output #0: loss = 1.09204 (* 1 = 1.09204 loss)
I0525 18:17:45.285979 21434 sgd_solver.cpp:106] Iteration 48900, lr = 0.0025
I0525 18:18:14.887094 21434 solver.cpp:237] Iteration 49050, loss = 1.41908
I0525 18:18:14.887150 21434 solver.cpp:253]     Train net output #0: loss = 1.41908 (* 1 = 1.41908 loss)
I0525 18:18:14.887171 21434 sgd_solver.cpp:106] Iteration 49050, lr = 0.0025
I0525 18:18:23.615173 21434 solver.cpp:237] Iteration 49200, loss = 1.18924
I0525 18:18:23.615346 21434 solver.cpp:253]     Train net output #0: loss = 1.18924 (* 1 = 1.18924 loss)
I0525 18:18:23.615360 21434 sgd_solver.cpp:106] Iteration 49200, lr = 0.0025
I0525 18:18:32.338857 21434 solver.cpp:237] Iteration 49350, loss = 1.07314
I0525 18:18:32.338891 21434 solver.cpp:253]     Train net output #0: loss = 1.07314 (* 1 = 1.07314 loss)
I0525 18:18:32.338910 21434 sgd_solver.cpp:106] Iteration 49350, lr = 0.0025
I0525 18:18:41.004712 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_49500.caffemodel
I0525 18:18:41.083663 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_49500.solverstate
I0525 18:18:41.129659 21434 solver.cpp:237] Iteration 49500, loss = 1.0427
I0525 18:18:41.129712 21434 solver.cpp:253]     Train net output #0: loss = 1.0427 (* 1 = 1.0427 loss)
I0525 18:18:41.129726 21434 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0525 18:18:49.858337 21434 solver.cpp:237] Iteration 49650, loss = 1.15745
I0525 18:18:49.858372 21434 solver.cpp:253]     Train net output #0: loss = 1.15745 (* 1 = 1.15745 loss)
I0525 18:18:49.858389 21434 sgd_solver.cpp:106] Iteration 49650, lr = 0.0025
I0525 18:18:58.587800 21434 solver.cpp:237] Iteration 49800, loss = 1.21935
I0525 18:18:58.587970 21434 solver.cpp:253]     Train net output #0: loss = 1.21935 (* 1 = 1.21935 loss)
I0525 18:18:58.587983 21434 sgd_solver.cpp:106] Iteration 49800, lr = 0.0025
I0525 18:19:07.314291 21434 solver.cpp:237] Iteration 49950, loss = 1.29509
I0525 18:19:07.314343 21434 solver.cpp:253]     Train net output #0: loss = 1.29509 (* 1 = 1.29509 loss)
I0525 18:19:07.314360 21434 sgd_solver.cpp:106] Iteration 49950, lr = 0.0025
I0525 18:19:36.926390 21434 solver.cpp:237] Iteration 50100, loss = 1.14359
I0525 18:19:36.926583 21434 solver.cpp:253]     Train net output #0: loss = 1.14359 (* 1 = 1.14359 loss)
I0525 18:19:36.926596 21434 sgd_solver.cpp:106] Iteration 50100, lr = 0.0025
I0525 18:19:45.647722 21434 solver.cpp:237] Iteration 50250, loss = 1.16986
I0525 18:19:45.647755 21434 solver.cpp:253]     Train net output #0: loss = 1.16986 (* 1 = 1.16986 loss)
I0525 18:19:45.647773 21434 sgd_solver.cpp:106] Iteration 50250, lr = 0.0025
I0525 18:19:54.370720 21434 solver.cpp:237] Iteration 50400, loss = 1.00231
I0525 18:19:54.370774 21434 solver.cpp:253]     Train net output #0: loss = 1.00231 (* 1 = 1.00231 loss)
I0525 18:19:54.370789 21434 sgd_solver.cpp:106] Iteration 50400, lr = 0.0025
I0525 18:20:03.098024 21434 solver.cpp:237] Iteration 50550, loss = 1.04636
I0525 18:20:03.098060 21434 solver.cpp:253]     Train net output #0: loss = 1.04636 (* 1 = 1.04636 loss)
I0525 18:20:03.098078 21434 sgd_solver.cpp:106] Iteration 50550, lr = 0.0025
I0525 18:20:11.824182 21434 solver.cpp:237] Iteration 50700, loss = 1.22064
I0525 18:20:11.824347 21434 solver.cpp:253]     Train net output #0: loss = 1.22064 (* 1 = 1.22064 loss)
I0525 18:20:11.824362 21434 sgd_solver.cpp:106] Iteration 50700, lr = 0.0025
I0525 18:20:20.553725 21434 solver.cpp:237] Iteration 50850, loss = 1.15064
I0525 18:20:20.553771 21434 solver.cpp:253]     Train net output #0: loss = 1.15064 (* 1 = 1.15064 loss)
I0525 18:20:20.553792 21434 sgd_solver.cpp:106] Iteration 50850, lr = 0.0025
I0525 18:20:29.224373 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_51000.caffemodel
I0525 18:20:29.304347 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_51000.solverstate
I0525 18:20:29.331207 21434 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 18:21:16.182646 21434 solver.cpp:409]     Test net output #0: accuracy = 0.878294
I0525 18:21:16.182847 21434 solver.cpp:409]     Test net output #1: loss = 0.426193 (* 1 = 0.426193 loss)
I0525 18:21:37.059444 21434 solver.cpp:237] Iteration 51000, loss = 1.12013
I0525 18:21:37.059501 21434 solver.cpp:253]     Train net output #0: loss = 1.12013 (* 1 = 1.12013 loss)
I0525 18:21:37.059516 21434 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0525 18:21:45.798470 21434 solver.cpp:237] Iteration 51150, loss = 1.18687
I0525 18:21:45.798504 21434 solver.cpp:253]     Train net output #0: loss = 1.18687 (* 1 = 1.18687 loss)
I0525 18:21:45.798521 21434 sgd_solver.cpp:106] Iteration 51150, lr = 0.0025
I0525 18:21:54.538396 21434 solver.cpp:237] Iteration 51300, loss = 1.11838
I0525 18:21:54.538570 21434 solver.cpp:253]     Train net output #0: loss = 1.11838 (* 1 = 1.11838 loss)
I0525 18:21:54.538584 21434 sgd_solver.cpp:106] Iteration 51300, lr = 0.0025
I0525 18:22:03.275202 21434 solver.cpp:237] Iteration 51450, loss = 1.24832
I0525 18:22:03.275243 21434 solver.cpp:253]     Train net output #0: loss = 1.24832 (* 1 = 1.24832 loss)
I0525 18:22:03.275264 21434 sgd_solver.cpp:106] Iteration 51450, lr = 0.0025
I0525 18:22:12.013042 21434 solver.cpp:237] Iteration 51600, loss = 1.33102
I0525 18:22:12.013078 21434 solver.cpp:253]     Train net output #0: loss = 1.33102 (* 1 = 1.33102 loss)
I0525 18:22:12.013094 21434 sgd_solver.cpp:106] Iteration 51600, lr = 0.0025
I0525 18:22:20.748497 21434 solver.cpp:237] Iteration 51750, loss = 1.21523
I0525 18:22:20.748533 21434 solver.cpp:253]     Train net output #0: loss = 1.21523 (* 1 = 1.21523 loss)
I0525 18:22:20.748545 21434 sgd_solver.cpp:106] Iteration 51750, lr = 0.0025
I0525 18:22:29.481806 21434 solver.cpp:237] Iteration 51900, loss = 1.17816
I0525 18:22:29.481983 21434 solver.cpp:253]     Train net output #0: loss = 1.17816 (* 1 = 1.17816 loss)
I0525 18:22:29.481997 21434 sgd_solver.cpp:106] Iteration 51900, lr = 0.0025
I0525 18:22:59.082311 21434 solver.cpp:237] Iteration 52050, loss = 1.38372
I0525 18:22:59.082365 21434 solver.cpp:253]     Train net output #0: loss = 1.38372 (* 1 = 1.38372 loss)
I0525 18:22:59.082381 21434 sgd_solver.cpp:106] Iteration 52050, lr = 0.0025
I0525 18:23:07.819983 21434 solver.cpp:237] Iteration 52200, loss = 1.23564
I0525 18:23:07.820158 21434 solver.cpp:253]     Train net output #0: loss = 1.23564 (* 1 = 1.23564 loss)
I0525 18:23:07.820170 21434 sgd_solver.cpp:106] Iteration 52200, lr = 0.0025
I0525 18:23:16.562158 21434 solver.cpp:237] Iteration 52350, loss = 1.16504
I0525 18:23:16.562208 21434 solver.cpp:253]     Train net output #0: loss = 1.16504 (* 1 = 1.16504 loss)
I0525 18:23:16.562223 21434 sgd_solver.cpp:106] Iteration 52350, lr = 0.0025
I0525 18:23:25.247637 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_52500.caffemodel
I0525 18:23:25.328696 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_52500.solverstate
I0525 18:23:25.373795 21434 solver.cpp:237] Iteration 52500, loss = 1.39626
I0525 18:23:25.373847 21434 solver.cpp:253]     Train net output #0: loss = 1.39626 (* 1 = 1.39626 loss)
I0525 18:23:25.373860 21434 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0525 18:23:34.106770 21434 solver.cpp:237] Iteration 52650, loss = 1.18958
I0525 18:23:34.106806 21434 solver.cpp:253]     Train net output #0: loss = 1.18958 (* 1 = 1.18958 loss)
I0525 18:23:34.106823 21434 sgd_solver.cpp:106] Iteration 52650, lr = 0.0025
I0525 18:23:42.845994 21434 solver.cpp:237] Iteration 52800, loss = 1.07596
I0525 18:23:42.846191 21434 solver.cpp:253]     Train net output #0: loss = 1.07596 (* 1 = 1.07596 loss)
I0525 18:23:42.846205 21434 sgd_solver.cpp:106] Iteration 52800, lr = 0.0025
I0525 18:23:51.578829 21434 solver.cpp:237] Iteration 52950, loss = 1.25165
I0525 18:23:51.578862 21434 solver.cpp:253]     Train net output #0: loss = 1.25165 (* 1 = 1.25165 loss)
I0525 18:23:51.578879 21434 sgd_solver.cpp:106] Iteration 52950, lr = 0.0025
I0525 18:24:21.176802 21434 solver.cpp:237] Iteration 53100, loss = 1.08436
I0525 18:24:21.176998 21434 solver.cpp:253]     Train net output #0: loss = 1.08436 (* 1 = 1.08436 loss)
I0525 18:24:21.177014 21434 sgd_solver.cpp:106] Iteration 53100, lr = 0.0025
I0525 18:24:29.916597 21434 solver.cpp:237] Iteration 53250, loss = 1.21465
I0525 18:24:29.916640 21434 solver.cpp:253]     Train net output #0: loss = 1.21465 (* 1 = 1.21465 loss)
I0525 18:24:29.916661 21434 sgd_solver.cpp:106] Iteration 53250, lr = 0.0025
I0525 18:24:38.654287 21434 solver.cpp:237] Iteration 53400, loss = 1.18528
I0525 18:24:38.654323 21434 solver.cpp:253]     Train net output #0: loss = 1.18528 (* 1 = 1.18528 loss)
I0525 18:24:38.654341 21434 sgd_solver.cpp:106] Iteration 53400, lr = 0.0025
I0525 18:24:47.392784 21434 solver.cpp:237] Iteration 53550, loss = 1.14736
I0525 18:24:47.392819 21434 solver.cpp:253]     Train net output #0: loss = 1.14736 (* 1 = 1.14736 loss)
I0525 18:24:47.392837 21434 sgd_solver.cpp:106] Iteration 53550, lr = 0.0025
I0525 18:24:56.135624 21434 solver.cpp:237] Iteration 53700, loss = 1.25266
I0525 18:24:56.135802 21434 solver.cpp:253]     Train net output #0: loss = 1.25266 (* 1 = 1.25266 loss)
I0525 18:24:56.135814 21434 sgd_solver.cpp:106] Iteration 53700, lr = 0.0025
I0525 18:25:04.876065 21434 solver.cpp:237] Iteration 53850, loss = 0.935251
I0525 18:25:04.876099 21434 solver.cpp:253]     Train net output #0: loss = 0.935251 (* 1 = 0.935251 loss)
I0525 18:25:04.876116 21434 sgd_solver.cpp:106] Iteration 53850, lr = 0.0025
I0525 18:25:13.552444 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_54000.caffemodel
I0525 18:25:13.634451 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_54000.solverstate
I0525 18:25:13.665654 21434 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 18:26:21.431704 21434 solver.cpp:409]     Test net output #0: accuracy = 0.878194
I0525 18:26:21.431897 21434 solver.cpp:409]     Test net output #1: loss = 0.384337 (* 1 = 0.384337 loss)
I0525 18:26:42.319514 21434 solver.cpp:237] Iteration 54000, loss = 1.16676
I0525 18:26:42.319569 21434 solver.cpp:253]     Train net output #0: loss = 1.16676 (* 1 = 1.16676 loss)
I0525 18:26:42.319584 21434 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0525 18:26:51.047812 21434 solver.cpp:237] Iteration 54150, loss = 1.02639
I0525 18:26:51.047847 21434 solver.cpp:253]     Train net output #0: loss = 1.02639 (* 1 = 1.02639 loss)
I0525 18:26:51.047863 21434 sgd_solver.cpp:106] Iteration 54150, lr = 0.0025
I0525 18:26:59.785838 21434 solver.cpp:237] Iteration 54300, loss = 1.28733
I0525 18:26:59.786027 21434 solver.cpp:253]     Train net output #0: loss = 1.28733 (* 1 = 1.28733 loss)
I0525 18:26:59.786042 21434 sgd_solver.cpp:106] Iteration 54300, lr = 0.0025
I0525 18:27:08.519377 21434 solver.cpp:237] Iteration 54450, loss = 1.23375
I0525 18:27:08.519412 21434 solver.cpp:253]     Train net output #0: loss = 1.23375 (* 1 = 1.23375 loss)
I0525 18:27:08.519430 21434 sgd_solver.cpp:106] Iteration 54450, lr = 0.0025
I0525 18:27:17.252892 21434 solver.cpp:237] Iteration 54600, loss = 1.29018
I0525 18:27:17.252928 21434 solver.cpp:253]     Train net output #0: loss = 1.29018 (* 1 = 1.29018 loss)
I0525 18:27:17.252943 21434 sgd_solver.cpp:106] Iteration 54600, lr = 0.0025
I0525 18:27:25.982954 21434 solver.cpp:237] Iteration 54750, loss = 1.28965
I0525 18:27:25.983002 21434 solver.cpp:253]     Train net output #0: loss = 1.28965 (* 1 = 1.28965 loss)
I0525 18:27:25.983021 21434 sgd_solver.cpp:106] Iteration 54750, lr = 0.0025
I0525 18:27:34.722719 21434 solver.cpp:237] Iteration 54900, loss = 0.994141
I0525 18:27:34.722899 21434 solver.cpp:253]     Train net output #0: loss = 0.994141 (* 1 = 0.994141 loss)
I0525 18:27:34.722914 21434 sgd_solver.cpp:106] Iteration 54900, lr = 0.0025
I0525 18:28:04.308993 21434 solver.cpp:237] Iteration 55050, loss = 1.2689
I0525 18:28:04.309046 21434 solver.cpp:253]     Train net output #0: loss = 1.2689 (* 1 = 1.2689 loss)
I0525 18:28:04.309065 21434 sgd_solver.cpp:106] Iteration 55050, lr = 0.0025
I0525 18:28:13.040434 21434 solver.cpp:237] Iteration 55200, loss = 1.27842
I0525 18:28:13.040608 21434 solver.cpp:253]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I0525 18:28:13.040622 21434 sgd_solver.cpp:106] Iteration 55200, lr = 0.0025
I0525 18:28:21.771663 21434 solver.cpp:237] Iteration 55350, loss = 1.1277
I0525 18:28:21.771704 21434 solver.cpp:253]     Train net output #0: loss = 1.1277 (* 1 = 1.1277 loss)
I0525 18:28:21.771724 21434 sgd_solver.cpp:106] Iteration 55350, lr = 0.0025
I0525 18:28:30.445749 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_55500.caffemodel
I0525 18:28:30.524931 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_55500.solverstate
I0525 18:28:30.568557 21434 solver.cpp:237] Iteration 55500, loss = 1.13751
I0525 18:28:30.568603 21434 solver.cpp:253]     Train net output #0: loss = 1.13751 (* 1 = 1.13751 loss)
I0525 18:28:30.568621 21434 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0525 18:28:39.302188 21434 solver.cpp:237] Iteration 55650, loss = 1.1521
I0525 18:28:39.302237 21434 solver.cpp:253]     Train net output #0: loss = 1.1521 (* 1 = 1.1521 loss)
I0525 18:28:39.302251 21434 sgd_solver.cpp:106] Iteration 55650, lr = 0.0025
I0525 18:28:48.035043 21434 solver.cpp:237] Iteration 55800, loss = 1.39063
I0525 18:28:48.035223 21434 solver.cpp:253]     Train net output #0: loss = 1.39063 (* 1 = 1.39063 loss)
I0525 18:28:48.035236 21434 sgd_solver.cpp:106] Iteration 55800, lr = 0.0025
I0525 18:28:56.768849 21434 solver.cpp:237] Iteration 55950, loss = 1.24808
I0525 18:28:56.768883 21434 solver.cpp:253]     Train net output #0: loss = 1.24808 (* 1 = 1.24808 loss)
I0525 18:28:56.768899 21434 sgd_solver.cpp:106] Iteration 55950, lr = 0.0025
I0525 18:29:26.353849 21434 solver.cpp:237] Iteration 56100, loss = 1.20919
I0525 18:29:26.354043 21434 solver.cpp:253]     Train net output #0: loss = 1.20919 (* 1 = 1.20919 loss)
I0525 18:29:26.354058 21434 sgd_solver.cpp:106] Iteration 56100, lr = 0.0025
I0525 18:29:35.090615 21434 solver.cpp:237] Iteration 56250, loss = 1.27069
I0525 18:29:35.090662 21434 solver.cpp:253]     Train net output #0: loss = 1.27069 (* 1 = 1.27069 loss)
I0525 18:29:35.090679 21434 sgd_solver.cpp:106] Iteration 56250, lr = 0.0025
I0525 18:29:43.823843 21434 solver.cpp:237] Iteration 56400, loss = 1.15485
I0525 18:29:43.823878 21434 solver.cpp:253]     Train net output #0: loss = 1.15485 (* 1 = 1.15485 loss)
I0525 18:29:43.823894 21434 sgd_solver.cpp:106] Iteration 56400, lr = 0.0025
I0525 18:29:52.558265 21434 solver.cpp:237] Iteration 56550, loss = 1.21768
I0525 18:29:52.558300 21434 solver.cpp:253]     Train net output #0: loss = 1.21768 (* 1 = 1.21768 loss)
I0525 18:29:52.558316 21434 sgd_solver.cpp:106] Iteration 56550, lr = 0.0025
I0525 18:30:01.292462 21434 solver.cpp:237] Iteration 56700, loss = 1.27579
I0525 18:30:01.292654 21434 solver.cpp:253]     Train net output #0: loss = 1.27579 (* 1 = 1.27579 loss)
I0525 18:30:01.292670 21434 sgd_solver.cpp:106] Iteration 56700, lr = 0.0025
I0525 18:30:10.028287 21434 solver.cpp:237] Iteration 56850, loss = 1.16268
I0525 18:30:10.028322 21434 solver.cpp:253]     Train net output #0: loss = 1.16268 (* 1 = 1.16268 loss)
I0525 18:30:10.028338 21434 sgd_solver.cpp:106] Iteration 56850, lr = 0.0025
I0525 18:30:18.706513 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_57000.caffemodel
I0525 18:30:18.785212 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_57000.solverstate
I0525 18:30:18.810720 21434 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 18:31:05.325417 21434 solver.cpp:409]     Test net output #0: accuracy = 0.883082
I0525 18:31:05.325623 21434 solver.cpp:409]     Test net output #1: loss = 0.35502 (* 1 = 0.35502 loss)
I0525 18:31:26.198792 21434 solver.cpp:237] Iteration 57000, loss = 1.2997
I0525 18:31:26.198848 21434 solver.cpp:253]     Train net output #0: loss = 1.2997 (* 1 = 1.2997 loss)
I0525 18:31:26.198865 21434 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0525 18:31:34.931640 21434 solver.cpp:237] Iteration 57150, loss = 1.14306
I0525 18:31:34.931689 21434 solver.cpp:253]     Train net output #0: loss = 1.14306 (* 1 = 1.14306 loss)
I0525 18:31:34.931706 21434 sgd_solver.cpp:106] Iteration 57150, lr = 0.0025
I0525 18:31:43.666630 21434 solver.cpp:237] Iteration 57300, loss = 1.11248
I0525 18:31:43.666807 21434 solver.cpp:253]     Train net output #0: loss = 1.11248 (* 1 = 1.11248 loss)
I0525 18:31:43.666821 21434 sgd_solver.cpp:106] Iteration 57300, lr = 0.0025
I0525 18:31:52.407286 21434 solver.cpp:237] Iteration 57450, loss = 1.34892
I0525 18:31:52.407320 21434 solver.cpp:253]     Train net output #0: loss = 1.34892 (* 1 = 1.34892 loss)
I0525 18:31:52.407338 21434 sgd_solver.cpp:106] Iteration 57450, lr = 0.0025
I0525 18:32:01.144484 21434 solver.cpp:237] Iteration 57600, loss = 1.11904
I0525 18:32:01.144536 21434 solver.cpp:253]     Train net output #0: loss = 1.11904 (* 1 = 1.11904 loss)
I0525 18:32:01.144551 21434 sgd_solver.cpp:106] Iteration 57600, lr = 0.0025
I0525 18:32:09.880475 21434 solver.cpp:237] Iteration 57750, loss = 1.24275
I0525 18:32:09.880511 21434 solver.cpp:253]     Train net output #0: loss = 1.24275 (* 1 = 1.24275 loss)
I0525 18:32:09.880527 21434 sgd_solver.cpp:106] Iteration 57750, lr = 0.0025
I0525 18:32:18.615978 21434 solver.cpp:237] Iteration 57900, loss = 1.23429
I0525 18:32:18.616149 21434 solver.cpp:253]     Train net output #0: loss = 1.23429 (* 1 = 1.23429 loss)
I0525 18:32:18.616163 21434 sgd_solver.cpp:106] Iteration 57900, lr = 0.0025
I0525 18:32:48.202826 21434 solver.cpp:237] Iteration 58050, loss = 1.1282
I0525 18:32:48.202882 21434 solver.cpp:253]     Train net output #0: loss = 1.1282 (* 1 = 1.1282 loss)
I0525 18:32:48.202898 21434 sgd_solver.cpp:106] Iteration 58050, lr = 0.0025
I0525 18:32:56.943928 21434 solver.cpp:237] Iteration 58200, loss = 1.32309
I0525 18:32:56.944115 21434 solver.cpp:253]     Train net output #0: loss = 1.32309 (* 1 = 1.32309 loss)
I0525 18:32:56.944129 21434 sgd_solver.cpp:106] Iteration 58200, lr = 0.0025
I0525 18:33:05.681783 21434 solver.cpp:237] Iteration 58350, loss = 1.15803
I0525 18:33:05.681818 21434 solver.cpp:253]     Train net output #0: loss = 1.15803 (* 1 = 1.15803 loss)
I0525 18:33:05.681833 21434 sgd_solver.cpp:106] Iteration 58350, lr = 0.0025
I0525 18:33:14.362781 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_58500.caffemodel
I0525 18:33:14.442096 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_58500.solverstate
I0525 18:33:14.486274 21434 solver.cpp:237] Iteration 58500, loss = 1.37156
I0525 18:33:14.486321 21434 solver.cpp:253]     Train net output #0: loss = 1.37156 (* 1 = 1.37156 loss)
I0525 18:33:14.486341 21434 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
I0525 18:33:23.223644 21434 solver.cpp:237] Iteration 58650, loss = 1.12175
I0525 18:33:23.223678 21434 solver.cpp:253]     Train net output #0: loss = 1.12175 (* 1 = 1.12175 loss)
I0525 18:33:23.223695 21434 sgd_solver.cpp:106] Iteration 58650, lr = 0.0025
I0525 18:33:31.957440 21434 solver.cpp:237] Iteration 58800, loss = 1.36953
I0525 18:33:31.957625 21434 solver.cpp:253]     Train net output #0: loss = 1.36953 (* 1 = 1.36953 loss)
I0525 18:33:31.957638 21434 sgd_solver.cpp:106] Iteration 58800, lr = 0.0025
I0525 18:33:40.691611 21434 solver.cpp:237] Iteration 58950, loss = 1.25514
I0525 18:33:40.691663 21434 solver.cpp:253]     Train net output #0: loss = 1.25514 (* 1 = 1.25514 loss)
I0525 18:33:40.691678 21434 sgd_solver.cpp:106] Iteration 58950, lr = 0.0025
I0525 18:34:10.297108 21434 solver.cpp:237] Iteration 59100, loss = 1.12814
I0525 18:34:10.297308 21434 solver.cpp:253]     Train net output #0: loss = 1.12814 (* 1 = 1.12814 loss)
I0525 18:34:10.297322 21434 sgd_solver.cpp:106] Iteration 59100, lr = 0.0025
I0525 18:34:19.033824 21434 solver.cpp:237] Iteration 59250, loss = 1.1823
I0525 18:34:19.033859 21434 solver.cpp:253]     Train net output #0: loss = 1.1823 (* 1 = 1.1823 loss)
I0525 18:34:19.033876 21434 sgd_solver.cpp:106] Iteration 59250, lr = 0.0025
I0525 18:34:27.771281 21434 solver.cpp:237] Iteration 59400, loss = 1.17429
I0525 18:34:27.771314 21434 solver.cpp:253]     Train net output #0: loss = 1.17429 (* 1 = 1.17429 loss)
I0525 18:34:27.771328 21434 sgd_solver.cpp:106] Iteration 59400, lr = 0.0025
I0525 18:34:36.504483 21434 solver.cpp:237] Iteration 59550, loss = 1.29006
I0525 18:34:36.504524 21434 solver.cpp:253]     Train net output #0: loss = 1.29006 (* 1 = 1.29006 loss)
I0525 18:34:36.504545 21434 sgd_solver.cpp:106] Iteration 59550, lr = 0.0025
I0525 18:34:45.243949 21434 solver.cpp:237] Iteration 59700, loss = 1.02225
I0525 18:34:45.244120 21434 solver.cpp:253]     Train net output #0: loss = 1.02225 (* 1 = 1.02225 loss)
I0525 18:34:45.244133 21434 sgd_solver.cpp:106] Iteration 59700, lr = 0.0025
I0525 18:34:53.981328 21434 solver.cpp:237] Iteration 59850, loss = 1.3019
I0525 18:34:53.981362 21434 solver.cpp:253]     Train net output #0: loss = 1.3019 (* 1 = 1.3019 loss)
I0525 18:34:53.981379 21434 sgd_solver.cpp:106] Iteration 59850, lr = 0.0025
I0525 18:35:02.658361 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_60000.caffemodel
I0525 18:35:02.739998 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_60000.solverstate
I0525 18:35:02.767799 21434 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 18:36:10.524701 21434 solver.cpp:409]     Test net output #0: accuracy = 0.885055
I0525 18:36:10.524905 21434 solver.cpp:409]     Test net output #1: loss = 0.374938 (* 1 = 0.374938 loss)
I0525 18:36:31.402102 21434 solver.cpp:237] Iteration 60000, loss = 1.31903
I0525 18:36:31.402158 21434 solver.cpp:253]     Train net output #0: loss = 1.31903 (* 1 = 1.31903 loss)
I0525 18:36:31.402173 21434 sgd_solver.cpp:106] Iteration 60000, lr = 0.0025
I0525 18:36:40.122148 21434 solver.cpp:237] Iteration 60150, loss = 1.14279
I0525 18:36:40.122192 21434 solver.cpp:253]     Train net output #0: loss = 1.14279 (* 1 = 1.14279 loss)
I0525 18:36:40.122212 21434 sgd_solver.cpp:106] Iteration 60150, lr = 0.0025
I0525 18:36:48.850822 21434 solver.cpp:237] Iteration 60300, loss = 1.22859
I0525 18:36:48.851009 21434 solver.cpp:253]     Train net output #0: loss = 1.22859 (* 1 = 1.22859 loss)
I0525 18:36:48.851023 21434 sgd_solver.cpp:106] Iteration 60300, lr = 0.0025
I0525 18:36:57.581135 21434 solver.cpp:237] Iteration 60450, loss = 1.01367
I0525 18:36:57.581168 21434 solver.cpp:253]     Train net output #0: loss = 1.01367 (* 1 = 1.01367 loss)
I0525 18:36:57.581185 21434 sgd_solver.cpp:106] Iteration 60450, lr = 0.0025
I0525 18:37:06.303505 21434 solver.cpp:237] Iteration 60600, loss = 1.13623
I0525 18:37:06.303553 21434 solver.cpp:253]     Train net output #0: loss = 1.13623 (* 1 = 1.13623 loss)
I0525 18:37:06.303570 21434 sgd_solver.cpp:106] Iteration 60600, lr = 0.0025
I0525 18:37:15.031926 21434 solver.cpp:237] Iteration 60750, loss = 0.977638
I0525 18:37:15.031962 21434 solver.cpp:253]     Train net output #0: loss = 0.977638 (* 1 = 0.977638 loss)
I0525 18:37:15.031978 21434 sgd_solver.cpp:106] Iteration 60750, lr = 0.0025
I0525 18:37:23.765277 21434 solver.cpp:237] Iteration 60900, loss = 1.35058
I0525 18:37:23.765453 21434 solver.cpp:253]     Train net output #0: loss = 1.35058 (* 1 = 1.35058 loss)
I0525 18:37:23.765468 21434 sgd_solver.cpp:106] Iteration 60900, lr = 0.0025
I0525 18:37:53.329007 21434 solver.cpp:237] Iteration 61050, loss = 1.17414
I0525 18:37:53.329061 21434 solver.cpp:253]     Train net output #0: loss = 1.17414 (* 1 = 1.17414 loss)
I0525 18:37:53.329080 21434 sgd_solver.cpp:106] Iteration 61050, lr = 0.0025
I0525 18:38:02.053318 21434 solver.cpp:237] Iteration 61200, loss = 1.12696
I0525 18:38:02.053498 21434 solver.cpp:253]     Train net output #0: loss = 1.12696 (* 1 = 1.12696 loss)
I0525 18:38:02.053511 21434 sgd_solver.cpp:106] Iteration 61200, lr = 0.0025
I0525 18:38:10.780174 21434 solver.cpp:237] Iteration 61350, loss = 1.1495
I0525 18:38:10.780208 21434 solver.cpp:253]     Train net output #0: loss = 1.1495 (* 1 = 1.1495 loss)
I0525 18:38:10.780225 21434 sgd_solver.cpp:106] Iteration 61350, lr = 0.0025
I0525 18:38:19.447960 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_61500.caffemodel
I0525 18:38:19.526234 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_61500.solverstate
I0525 18:38:19.569674 21434 solver.cpp:237] Iteration 61500, loss = 0.879424
I0525 18:38:19.569723 21434 solver.cpp:253]     Train net output #0: loss = 0.879424 (* 1 = 0.879424 loss)
I0525 18:38:19.569737 21434 sgd_solver.cpp:106] Iteration 61500, lr = 0.0025
I0525 18:38:28.300690 21434 solver.cpp:237] Iteration 61650, loss = 1.14965
I0525 18:38:28.300724 21434 solver.cpp:253]     Train net output #0: loss = 1.14965 (* 1 = 1.14965 loss)
I0525 18:38:28.300741 21434 sgd_solver.cpp:106] Iteration 61650, lr = 0.0025
I0525 18:38:37.029448 21434 solver.cpp:237] Iteration 61800, loss = 1.11723
I0525 18:38:37.029634 21434 solver.cpp:253]     Train net output #0: loss = 1.11723 (* 1 = 1.11723 loss)
I0525 18:38:37.029649 21434 sgd_solver.cpp:106] Iteration 61800, lr = 0.0025
I0525 18:38:45.757361 21434 solver.cpp:237] Iteration 61950, loss = 1.27172
I0525 18:38:45.757406 21434 solver.cpp:253]     Train net output #0: loss = 1.27172 (* 1 = 1.27172 loss)
I0525 18:38:45.757426 21434 sgd_solver.cpp:106] Iteration 61950, lr = 0.0025
I0525 18:39:15.331327 21434 solver.cpp:237] Iteration 62100, loss = 0.998617
I0525 18:39:15.331519 21434 solver.cpp:253]     Train net output #0: loss = 0.998617 (* 1 = 0.998617 loss)
I0525 18:39:15.331535 21434 sgd_solver.cpp:106] Iteration 62100, lr = 0.0025
I0525 18:39:24.060343 21434 solver.cpp:237] Iteration 62250, loss = 1.22386
I0525 18:39:24.060377 21434 solver.cpp:253]     Train net output #0: loss = 1.22386 (* 1 = 1.22386 loss)
I0525 18:39:24.060395 21434 sgd_solver.cpp:106] Iteration 62250, lr = 0.0025
I0525 18:39:32.789352 21434 solver.cpp:237] Iteration 62400, loss = 1.13477
I0525 18:39:32.789398 21434 solver.cpp:253]     Train net output #0: loss = 1.13477 (* 1 = 1.13477 loss)
I0525 18:39:32.789413 21434 sgd_solver.cpp:106] Iteration 62400, lr = 0.0025
I0525 18:39:41.514137 21434 solver.cpp:237] Iteration 62550, loss = 0.925073
I0525 18:39:41.514173 21434 solver.cpp:253]     Train net output #0: loss = 0.925073 (* 1 = 0.925073 loss)
I0525 18:39:41.514189 21434 sgd_solver.cpp:106] Iteration 62550, lr = 0.0025
I0525 18:39:50.243013 21434 solver.cpp:237] Iteration 62700, loss = 1.23276
I0525 18:39:50.243206 21434 solver.cpp:253]     Train net output #0: loss = 1.23276 (* 1 = 1.23276 loss)
I0525 18:39:50.243219 21434 sgd_solver.cpp:106] Iteration 62700, lr = 0.0025
I0525 18:39:58.971340 21434 solver.cpp:237] Iteration 62850, loss = 1.32993
I0525 18:39:58.971390 21434 solver.cpp:253]     Train net output #0: loss = 1.32993 (* 1 = 1.32993 loss)
I0525 18:39:58.971406 21434 sgd_solver.cpp:106] Iteration 62850, lr = 0.0025
I0525 18:40:07.639421 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_63000.caffemodel
I0525 18:40:07.718196 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_63000.solverstate
I0525 18:40:07.743696 21434 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 18:40:54.605851 21434 solver.cpp:409]     Test net output #0: accuracy = 0.885468
I0525 18:40:54.606048 21434 solver.cpp:409]     Test net output #1: loss = 0.369577 (* 1 = 0.369577 loss)
I0525 18:41:15.461290 21434 solver.cpp:237] Iteration 63000, loss = 0.994393
I0525 18:41:15.461347 21434 solver.cpp:253]     Train net output #0: loss = 0.994393 (* 1 = 0.994393 loss)
I0525 18:41:15.461361 21434 sgd_solver.cpp:106] Iteration 63000, lr = 0.0025
I0525 18:41:24.195096 21434 solver.cpp:237] Iteration 63150, loss = 1.11151
I0525 18:41:24.195133 21434 solver.cpp:253]     Train net output #0: loss = 1.11151 (* 1 = 1.11151 loss)
I0525 18:41:24.195147 21434 sgd_solver.cpp:106] Iteration 63150, lr = 0.0025
I0525 18:41:32.930277 21434 solver.cpp:237] Iteration 63300, loss = 1.15553
I0525 18:41:32.930457 21434 solver.cpp:253]     Train net output #0: loss = 1.15553 (* 1 = 1.15553 loss)
I0525 18:41:32.930470 21434 sgd_solver.cpp:106] Iteration 63300, lr = 0.0025
I0525 18:41:41.671957 21434 solver.cpp:237] Iteration 63450, loss = 1.37002
I0525 18:41:41.672000 21434 solver.cpp:253]     Train net output #0: loss = 1.37002 (* 1 = 1.37002 loss)
I0525 18:41:41.672021 21434 sgd_solver.cpp:106] Iteration 63450, lr = 0.0025
I0525 18:41:50.407584 21434 solver.cpp:237] Iteration 63600, loss = 1.18503
I0525 18:41:50.407619 21434 solver.cpp:253]     Train net output #0: loss = 1.18503 (* 1 = 1.18503 loss)
I0525 18:41:50.407634 21434 sgd_solver.cpp:106] Iteration 63600, lr = 0.0025
I0525 18:41:59.141723 21434 solver.cpp:237] Iteration 63750, loss = 1.21948
I0525 18:41:59.141759 21434 solver.cpp:253]     Train net output #0: loss = 1.21948 (* 1 = 1.21948 loss)
I0525 18:41:59.141775 21434 sgd_solver.cpp:106] Iteration 63750, lr = 0.0025
I0525 18:42:07.880697 21434 solver.cpp:237] Iteration 63900, loss = 1.16122
I0525 18:42:07.880883 21434 solver.cpp:253]     Train net output #0: loss = 1.16122 (* 1 = 1.16122 loss)
I0525 18:42:07.880897 21434 sgd_solver.cpp:106] Iteration 63900, lr = 0.0025
I0525 18:42:37.490777 21434 solver.cpp:237] Iteration 64050, loss = 1.24949
I0525 18:42:37.490831 21434 solver.cpp:253]     Train net output #0: loss = 1.24949 (* 1 = 1.24949 loss)
I0525 18:42:37.490847 21434 sgd_solver.cpp:106] Iteration 64050, lr = 0.0025
I0525 18:42:46.231012 21434 solver.cpp:237] Iteration 64200, loss = 0.964591
I0525 18:42:46.231209 21434 solver.cpp:253]     Train net output #0: loss = 0.964591 (* 1 = 0.964591 loss)
I0525 18:42:46.231222 21434 sgd_solver.cpp:106] Iteration 64200, lr = 0.0025
I0525 18:42:54.962898 21434 solver.cpp:237] Iteration 64350, loss = 1.08184
I0525 18:42:54.962944 21434 solver.cpp:253]     Train net output #0: loss = 1.08184 (* 1 = 1.08184 loss)
I0525 18:42:54.962965 21434 sgd_solver.cpp:106] Iteration 64350, lr = 0.0025
I0525 18:43:03.642451 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_64500.caffemodel
I0525 18:43:03.721730 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_64500.solverstate
I0525 18:43:03.765125 21434 solver.cpp:237] Iteration 64500, loss = 1.06608
I0525 18:43:03.765174 21434 solver.cpp:253]     Train net output #0: loss = 1.06608 (* 1 = 1.06608 loss)
I0525 18:43:03.765188 21434 sgd_solver.cpp:106] Iteration 64500, lr = 0.0025
I0525 18:43:12.500603 21434 solver.cpp:237] Iteration 64650, loss = 1.2129
I0525 18:43:12.500638 21434 solver.cpp:253]     Train net output #0: loss = 1.2129 (* 1 = 1.2129 loss)
I0525 18:43:12.500655 21434 sgd_solver.cpp:106] Iteration 64650, lr = 0.0025
I0525 18:43:21.234910 21434 solver.cpp:237] Iteration 64800, loss = 1.09232
I0525 18:43:21.235115 21434 solver.cpp:253]     Train net output #0: loss = 1.09232 (* 1 = 1.09232 loss)
I0525 18:43:21.235137 21434 sgd_solver.cpp:106] Iteration 64800, lr = 0.0025
I0525 18:43:29.970026 21434 solver.cpp:237] Iteration 64950, loss = 1.29137
I0525 18:43:29.970059 21434 solver.cpp:253]     Train net output #0: loss = 1.29137 (* 1 = 1.29137 loss)
I0525 18:43:29.970077 21434 sgd_solver.cpp:106] Iteration 64950, lr = 0.0025
I0525 18:43:59.529253 21434 solver.cpp:237] Iteration 65100, loss = 0.966469
I0525 18:43:59.529458 21434 solver.cpp:253]     Train net output #0: loss = 0.966469 (* 1 = 0.966469 loss)
I0525 18:43:59.529474 21434 sgd_solver.cpp:106] Iteration 65100, lr = 0.0025
I0525 18:44:08.263483 21434 solver.cpp:237] Iteration 65250, loss = 1.00878
I0525 18:44:08.263521 21434 solver.cpp:253]     Train net output #0: loss = 1.00878 (* 1 = 1.00878 loss)
I0525 18:44:08.263542 21434 sgd_solver.cpp:106] Iteration 65250, lr = 0.0025
I0525 18:44:16.994004 21434 solver.cpp:237] Iteration 65400, loss = 1.31339
I0525 18:44:16.994038 21434 solver.cpp:253]     Train net output #0: loss = 1.31339 (* 1 = 1.31339 loss)
I0525 18:44:16.994055 21434 sgd_solver.cpp:106] Iteration 65400, lr = 0.0025
I0525 18:44:25.732316 21434 solver.cpp:237] Iteration 65550, loss = 1.24851
I0525 18:44:25.732350 21434 solver.cpp:253]     Train net output #0: loss = 1.24851 (* 1 = 1.24851 loss)
I0525 18:44:25.732367 21434 sgd_solver.cpp:106] Iteration 65550, lr = 0.0025
I0525 18:44:34.467272 21434 solver.cpp:237] Iteration 65700, loss = 1.15008
I0525 18:44:34.467458 21434 solver.cpp:253]     Train net output #0: loss = 1.15008 (* 1 = 1.15008 loss)
I0525 18:44:34.467471 21434 sgd_solver.cpp:106] Iteration 65700, lr = 0.0025
I0525 18:44:43.204496 21434 solver.cpp:237] Iteration 65850, loss = 1.16355
I0525 18:44:43.204530 21434 solver.cpp:253]     Train net output #0: loss = 1.16355 (* 1 = 1.16355 loss)
I0525 18:44:43.204548 21434 sgd_solver.cpp:106] Iteration 65850, lr = 0.0025
I0525 18:44:51.887717 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_66000.caffemodel
I0525 18:44:51.967638 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_66000.solverstate
I0525 18:44:51.994272 21434 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 18:45:59.643112 21434 solver.cpp:409]     Test net output #0: accuracy = 0.887394
I0525 18:45:59.643319 21434 solver.cpp:409]     Test net output #1: loss = 0.374387 (* 1 = 0.374387 loss)
I0525 18:46:20.488157 21434 solver.cpp:237] Iteration 66000, loss = 1.16714
I0525 18:46:20.488214 21434 solver.cpp:253]     Train net output #0: loss = 1.16714 (* 1 = 1.16714 loss)
I0525 18:46:20.488229 21434 sgd_solver.cpp:106] Iteration 66000, lr = 0.0025
I0525 18:46:29.219384 21434 solver.cpp:237] Iteration 66150, loss = 1.30334
I0525 18:46:29.219419 21434 solver.cpp:253]     Train net output #0: loss = 1.30334 (* 1 = 1.30334 loss)
I0525 18:46:29.219435 21434 sgd_solver.cpp:106] Iteration 66150, lr = 0.0025
I0525 18:46:37.949074 21434 solver.cpp:237] Iteration 66300, loss = 1.13799
I0525 18:46:37.949277 21434 solver.cpp:253]     Train net output #0: loss = 1.13799 (* 1 = 1.13799 loss)
I0525 18:46:37.949291 21434 sgd_solver.cpp:106] Iteration 66300, lr = 0.0025
I0525 18:46:46.682365 21434 solver.cpp:237] Iteration 66450, loss = 1.17382
I0525 18:46:46.682399 21434 solver.cpp:253]     Train net output #0: loss = 1.17382 (* 1 = 1.17382 loss)
I0525 18:46:46.682417 21434 sgd_solver.cpp:106] Iteration 66450, lr = 0.0025
I0525 18:46:55.415313 21434 solver.cpp:237] Iteration 66600, loss = 1.17892
I0525 18:46:55.415346 21434 solver.cpp:253]     Train net output #0: loss = 1.17892 (* 1 = 1.17892 loss)
I0525 18:46:55.415362 21434 sgd_solver.cpp:106] Iteration 66600, lr = 0.0025
I0525 18:47:04.144196 21434 solver.cpp:237] Iteration 66750, loss = 1.12481
I0525 18:47:04.144239 21434 solver.cpp:253]     Train net output #0: loss = 1.12481 (* 1 = 1.12481 loss)
I0525 18:47:04.144256 21434 sgd_solver.cpp:106] Iteration 66750, lr = 0.0025
I0525 18:47:12.880328 21434 solver.cpp:237] Iteration 66900, loss = 1.22124
I0525 18:47:12.880506 21434 solver.cpp:253]     Train net output #0: loss = 1.22124 (* 1 = 1.22124 loss)
I0525 18:47:12.880520 21434 sgd_solver.cpp:106] Iteration 66900, lr = 0.0025
I0525 18:47:42.435276 21434 solver.cpp:237] Iteration 67050, loss = 1.23873
I0525 18:47:42.435331 21434 solver.cpp:253]     Train net output #0: loss = 1.23873 (* 1 = 1.23873 loss)
I0525 18:47:42.435346 21434 sgd_solver.cpp:106] Iteration 67050, lr = 0.0025
I0525 18:47:51.165844 21434 solver.cpp:237] Iteration 67200, loss = 1.01305
I0525 18:47:51.166038 21434 solver.cpp:253]     Train net output #0: loss = 1.01305 (* 1 = 1.01305 loss)
I0525 18:47:51.166052 21434 sgd_solver.cpp:106] Iteration 67200, lr = 0.0025
I0525 18:47:59.895550 21434 solver.cpp:237] Iteration 67350, loss = 1.02442
I0525 18:47:59.895583 21434 solver.cpp:253]     Train net output #0: loss = 1.02442 (* 1 = 1.02442 loss)
I0525 18:47:59.895601 21434 sgd_solver.cpp:106] Iteration 67350, lr = 0.0025
I0525 18:48:08.568817 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_67500.caffemodel
I0525 18:48:08.649924 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_67500.solverstate
I0525 18:48:08.695487 21434 solver.cpp:237] Iteration 67500, loss = 1.3028
I0525 18:48:08.695538 21434 solver.cpp:253]     Train net output #0: loss = 1.3028 (* 1 = 1.3028 loss)
I0525 18:48:08.695551 21434 sgd_solver.cpp:106] Iteration 67500, lr = 0.0025
I0525 18:48:17.425302 21434 solver.cpp:237] Iteration 67650, loss = 1.21467
I0525 18:48:17.425346 21434 solver.cpp:253]     Train net output #0: loss = 1.21467 (* 1 = 1.21467 loss)
I0525 18:48:17.425366 21434 sgd_solver.cpp:106] Iteration 67650, lr = 0.0025
I0525 18:48:26.158367 21434 solver.cpp:237] Iteration 67800, loss = 1.1368
I0525 18:48:26.158550 21434 solver.cpp:253]     Train net output #0: loss = 1.1368 (* 1 = 1.1368 loss)
I0525 18:48:26.158563 21434 sgd_solver.cpp:106] Iteration 67800, lr = 0.0025
I0525 18:48:34.882534 21434 solver.cpp:237] Iteration 67950, loss = 1.19384
I0525 18:48:34.882567 21434 solver.cpp:253]     Train net output #0: loss = 1.19384 (* 1 = 1.19384 loss)
I0525 18:48:34.882585 21434 sgd_solver.cpp:106] Iteration 67950, lr = 0.0025
I0525 18:49:04.443192 21434 solver.cpp:237] Iteration 68100, loss = 0.945042
I0525 18:49:04.443393 21434 solver.cpp:253]     Train net output #0: loss = 0.945042 (* 1 = 0.945042 loss)
I0525 18:49:04.443408 21434 sgd_solver.cpp:106] Iteration 68100, lr = 0.0025
I0525 18:49:13.176359 21434 solver.cpp:237] Iteration 68250, loss = 1.10617
I0525 18:49:13.176393 21434 solver.cpp:253]     Train net output #0: loss = 1.10617 (* 1 = 1.10617 loss)
I0525 18:49:13.176410 21434 sgd_solver.cpp:106] Iteration 68250, lr = 0.0025
I0525 18:49:21.911756 21434 solver.cpp:237] Iteration 68400, loss = 1.21613
I0525 18:49:21.911792 21434 solver.cpp:253]     Train net output #0: loss = 1.21613 (* 1 = 1.21613 loss)
I0525 18:49:21.911808 21434 sgd_solver.cpp:106] Iteration 68400, lr = 0.0025
I0525 18:49:30.646586 21434 solver.cpp:237] Iteration 68550, loss = 1.14777
I0525 18:49:30.646628 21434 solver.cpp:253]     Train net output #0: loss = 1.14777 (* 1 = 1.14777 loss)
I0525 18:49:30.646648 21434 sgd_solver.cpp:106] Iteration 68550, lr = 0.0025
I0525 18:49:39.381353 21434 solver.cpp:237] Iteration 68700, loss = 1.18533
I0525 18:49:39.381541 21434 solver.cpp:253]     Train net output #0: loss = 1.18533 (* 1 = 1.18533 loss)
I0525 18:49:39.381553 21434 sgd_solver.cpp:106] Iteration 68700, lr = 0.0025
I0525 18:49:48.109614 21434 solver.cpp:237] Iteration 68850, loss = 1.12772
I0525 18:49:48.109648 21434 solver.cpp:253]     Train net output #0: loss = 1.12772 (* 1 = 1.12772 loss)
I0525 18:49:48.109665 21434 sgd_solver.cpp:106] Iteration 68850, lr = 0.0025
I0525 18:49:56.789484 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_69000.caffemodel
I0525 18:49:56.868052 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_69000.solverstate
I0525 18:49:56.893182 21434 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 18:50:43.379467 21434 solver.cpp:409]     Test net output #0: accuracy = 0.885401
I0525 18:50:43.379678 21434 solver.cpp:409]     Test net output #1: loss = 0.356039 (* 1 = 0.356039 loss)
I0525 18:51:04.191305 21434 solver.cpp:237] Iteration 69000, loss = 1.02471
I0525 18:51:04.191361 21434 solver.cpp:253]     Train net output #0: loss = 1.02471 (* 1 = 1.02471 loss)
I0525 18:51:04.191377 21434 sgd_solver.cpp:106] Iteration 69000, lr = 0.0025
I0525 18:51:12.927003 21434 solver.cpp:237] Iteration 69150, loss = 1.13227
I0525 18:51:12.927043 21434 solver.cpp:253]     Train net output #0: loss = 1.13227 (* 1 = 1.13227 loss)
I0525 18:51:12.927064 21434 sgd_solver.cpp:106] Iteration 69150, lr = 0.0025
I0525 18:51:21.661175 21434 solver.cpp:237] Iteration 69300, loss = 1.06933
I0525 18:51:21.661356 21434 solver.cpp:253]     Train net output #0: loss = 1.06933 (* 1 = 1.06933 loss)
I0525 18:51:21.661370 21434 sgd_solver.cpp:106] Iteration 69300, lr = 0.0025
I0525 18:51:30.400221 21434 solver.cpp:237] Iteration 69450, loss = 1.2073
I0525 18:51:30.400255 21434 solver.cpp:253]     Train net output #0: loss = 1.2073 (* 1 = 1.2073 loss)
I0525 18:51:30.400271 21434 sgd_solver.cpp:106] Iteration 69450, lr = 0.0025
I0525 18:51:39.139456 21434 solver.cpp:237] Iteration 69600, loss = 1.15391
I0525 18:51:39.139497 21434 solver.cpp:253]     Train net output #0: loss = 1.15391 (* 1 = 1.15391 loss)
I0525 18:51:39.139516 21434 sgd_solver.cpp:106] Iteration 69600, lr = 0.0025
I0525 18:51:47.879473 21434 solver.cpp:237] Iteration 69750, loss = 1.26185
I0525 18:51:47.879508 21434 solver.cpp:253]     Train net output #0: loss = 1.26185 (* 1 = 1.26185 loss)
I0525 18:51:47.879524 21434 sgd_solver.cpp:106] Iteration 69750, lr = 0.0025
I0525 18:51:56.615152 21434 solver.cpp:237] Iteration 69900, loss = 1.37133
I0525 18:51:56.615329 21434 solver.cpp:253]     Train net output #0: loss = 1.37133 (* 1 = 1.37133 loss)
I0525 18:51:56.615341 21434 sgd_solver.cpp:106] Iteration 69900, lr = 0.0025
I0525 18:52:26.172932 21434 solver.cpp:237] Iteration 70050, loss = 1.22461
I0525 18:52:26.172986 21434 solver.cpp:253]     Train net output #0: loss = 1.22461 (* 1 = 1.22461 loss)
I0525 18:52:26.173003 21434 sgd_solver.cpp:106] Iteration 70050, lr = 0.0025
I0525 18:52:34.910784 21434 solver.cpp:237] Iteration 70200, loss = 1.25938
I0525 18:52:34.910974 21434 solver.cpp:253]     Train net output #0: loss = 1.25938 (* 1 = 1.25938 loss)
I0525 18:52:34.910989 21434 sgd_solver.cpp:106] Iteration 70200, lr = 0.0025
I0525 18:52:43.651070 21434 solver.cpp:237] Iteration 70350, loss = 1.19848
I0525 18:52:43.651104 21434 solver.cpp:253]     Train net output #0: loss = 1.19848 (* 1 = 1.19848 loss)
I0525 18:52:43.651129 21434 sgd_solver.cpp:106] Iteration 70350, lr = 0.0025
I0525 18:52:52.331045 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_70500.caffemodel
I0525 18:52:52.409765 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_70500.solverstate
I0525 18:52:52.453330 21434 solver.cpp:237] Iteration 70500, loss = 1.15081
I0525 18:52:52.453377 21434 solver.cpp:253]     Train net output #0: loss = 1.15081 (* 1 = 1.15081 loss)
I0525 18:52:52.453392 21434 sgd_solver.cpp:106] Iteration 70500, lr = 0.0025
I0525 18:53:01.190832 21434 solver.cpp:237] Iteration 70650, loss = 1.09473
I0525 18:53:01.190867 21434 solver.cpp:253]     Train net output #0: loss = 1.09473 (* 1 = 1.09473 loss)
I0525 18:53:01.190884 21434 sgd_solver.cpp:106] Iteration 70650, lr = 0.0025
I0525 18:53:09.922091 21434 solver.cpp:237] Iteration 70800, loss = 1.25824
I0525 18:53:09.922276 21434 solver.cpp:253]     Train net output #0: loss = 1.25824 (* 1 = 1.25824 loss)
I0525 18:53:09.922289 21434 sgd_solver.cpp:106] Iteration 70800, lr = 0.0025
I0525 18:53:18.658103 21434 solver.cpp:237] Iteration 70950, loss = 1.21408
I0525 18:53:18.658146 21434 solver.cpp:253]     Train net output #0: loss = 1.21408 (* 1 = 1.21408 loss)
I0525 18:53:18.658165 21434 sgd_solver.cpp:106] Iteration 70950, lr = 0.0025
I0525 18:53:48.219805 21434 solver.cpp:237] Iteration 71100, loss = 0.925856
I0525 18:53:48.220012 21434 solver.cpp:253]     Train net output #0: loss = 0.925856 (* 1 = 0.925856 loss)
I0525 18:53:48.220027 21434 sgd_solver.cpp:106] Iteration 71100, lr = 0.0025
I0525 18:53:56.957859 21434 solver.cpp:237] Iteration 71250, loss = 1.13019
I0525 18:53:56.957892 21434 solver.cpp:253]     Train net output #0: loss = 1.13019 (* 1 = 1.13019 loss)
I0525 18:53:56.957909 21434 sgd_solver.cpp:106] Iteration 71250, lr = 0.0025
I0525 18:54:05.699478 21434 solver.cpp:237] Iteration 71400, loss = 1.0224
I0525 18:54:05.699522 21434 solver.cpp:253]     Train net output #0: loss = 1.0224 (* 1 = 1.0224 loss)
I0525 18:54:05.699542 21434 sgd_solver.cpp:106] Iteration 71400, lr = 0.0025
I0525 18:54:14.442870 21434 solver.cpp:237] Iteration 71550, loss = 1.11281
I0525 18:54:14.442905 21434 solver.cpp:253]     Train net output #0: loss = 1.11281 (* 1 = 1.11281 loss)
I0525 18:54:14.442921 21434 sgd_solver.cpp:106] Iteration 71550, lr = 0.0025
I0525 18:54:23.182978 21434 solver.cpp:237] Iteration 71700, loss = 1.22861
I0525 18:54:23.183166 21434 solver.cpp:253]     Train net output #0: loss = 1.22861 (* 1 = 1.22861 loss)
I0525 18:54:23.183179 21434 sgd_solver.cpp:106] Iteration 71700, lr = 0.0025
I0525 18:54:31.917158 21434 solver.cpp:237] Iteration 71850, loss = 0.981179
I0525 18:54:31.917209 21434 solver.cpp:253]     Train net output #0: loss = 0.981179 (* 1 = 0.981179 loss)
I0525 18:54:31.917227 21434 sgd_solver.cpp:106] Iteration 71850, lr = 0.0025
I0525 18:54:40.596252 21434 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_72000.caffemodel
I0525 18:54:40.674969 21434 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0025_2016-05-20T15.49.25.489346_iter_72000.solverstate
I0525 18:54:40.700448 21434 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 18:55:48.309193 21434 solver.cpp:409]     Test net output #0: accuracy = 0.886895
I0525 18:55:48.309407 21434 solver.cpp:409]     Test net output #1: loss = 0.372473 (* 1 = 0.372473 loss)
I0525 18:56:09.113277 21434 solver.cpp:237] Iteration 72000, loss = 1.22663
I0525 18:56:09.113334 21434 solver.cpp:253]     Train net output #0: loss = 1.22663 (* 1 = 1.22663 loss)
I0525 18:56:09.113348 21434 sgd_solver.cpp:106] Iteration 72000, lr = 0.0025
I0525 18:56:17.840242 21434 solver.cpp:237] Iteration 72150, loss = 1.19641
I0525 18:56:17.840288 21434 solver.cpp:253]     Train net output #0: loss = 1.19641 (* 1 = 1.19641 loss)
I0525 18:56:17.840306 21434 sgd_solver.cpp:106] Iteration 72150, lr = 0.0025
I0525 18:56:26.559813 21434 solver.cpp:237] Iteration 72300, loss = 1.09497
I0525 18:56:26.560009 21434 solver.cpp:253]     Train net output #0: loss = 1.09497 (* 1 = 1.09497 loss)
I0525 18:56:26.560021 21434 sgd_solver.cpp:106] Iteration 72300, lr = 0.0025
I0525 18:56:35.285190 21434 solver.cpp:237] Iteration 72450, loss = 1.21022
I0525 18:56:35.285240 21434 solver.cpp:253]     Train net output #0: loss = 1.21022 (* 1 = 1.21022 loss)
I0525 18:56:35.285255 21434 sgd_solver.cpp:106] Iteration 72450, lr = 0.0025
I0525 18:56:44.006983 21434 solver.cpp:237] Iteration 72600, loss = 1.19508
I0525 18:56:44.007019 21434 solver.cpp:253]     Train net output #0: loss = 1.19508 (* 1 = 1.19508 loss)
I0525 18:56:44.007035 21434 sgd_solver.cpp:106] Iteration 72600, lr = 0.0025
aprun: Apid 11265210: Caught signal Terminated, sending to application
*** Aborted at 1464217006 (unix time) try "date -d @1464217006" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x53b7) received by PID 21434 (TID 0x2aaac746f900) from PID 21431; stack trace: ***
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7226 exceeded limit 7200
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11265210: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
aprun: Apid 11265210: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03794] [c8-1c0s6n2] [Wed May 25 18:56:48 2016] PE RANK 0 exit signal Terminated
Application 11265210 exit codes: 143
Application 11265210 resources: utime ~6228s, stime ~987s, Rss ~5333168, inblocks ~16605764, outblocks ~740502
