2810094
I0525 08:53:28.710445 19426 caffe.cpp:184] Using GPUs 0
I0525 08:53:29.131492 19426 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.0035
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442.prototxt"
I0525 08:53:29.133313 19426 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442.prototxt
I0525 08:53:29.147122 19426 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 08:53:29.147181 19426 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 08:53:29.147526 19426 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 08:53:29.147706 19426 layer_factory.hpp:77] Creating layer data_hdf5
I0525 08:53:29.147729 19426 net.cpp:106] Creating Layer data_hdf5
I0525 08:53:29.147744 19426 net.cpp:411] data_hdf5 -> data
I0525 08:53:29.147776 19426 net.cpp:411] data_hdf5 -> label
I0525 08:53:29.147809 19426 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 08:53:29.149231 19426 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 08:53:29.151643 19426 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 08:53:50.628144 19426 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 08:53:50.633333 19426 net.cpp:150] Setting up data_hdf5
I0525 08:53:50.633373 19426 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 08:53:50.633388 19426 net.cpp:157] Top shape: 90 (90)
I0525 08:53:50.633401 19426 net.cpp:165] Memory required for data: 2286360
I0525 08:53:50.633415 19426 layer_factory.hpp:77] Creating layer conv1
I0525 08:53:50.633448 19426 net.cpp:106] Creating Layer conv1
I0525 08:53:50.633460 19426 net.cpp:454] conv1 <- data
I0525 08:53:50.633481 19426 net.cpp:411] conv1 -> conv1
I0525 08:53:51.001768 19426 net.cpp:150] Setting up conv1
I0525 08:53:51.001809 19426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 08:53:51.001826 19426 net.cpp:165] Memory required for data: 27169560
I0525 08:53:51.001855 19426 layer_factory.hpp:77] Creating layer relu1
I0525 08:53:51.001878 19426 net.cpp:106] Creating Layer relu1
I0525 08:53:51.001888 19426 net.cpp:454] relu1 <- conv1
I0525 08:53:51.001902 19426 net.cpp:397] relu1 -> conv1 (in-place)
I0525 08:53:51.002418 19426 net.cpp:150] Setting up relu1
I0525 08:53:51.002435 19426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 08:53:51.002446 19426 net.cpp:165] Memory required for data: 52052760
I0525 08:53:51.002457 19426 layer_factory.hpp:77] Creating layer pool1
I0525 08:53:51.002473 19426 net.cpp:106] Creating Layer pool1
I0525 08:53:51.002483 19426 net.cpp:454] pool1 <- conv1
I0525 08:53:51.002498 19426 net.cpp:411] pool1 -> pool1
I0525 08:53:51.002578 19426 net.cpp:150] Setting up pool1
I0525 08:53:51.002591 19426 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 08:53:51.002601 19426 net.cpp:165] Memory required for data: 64494360
I0525 08:53:51.002611 19426 layer_factory.hpp:77] Creating layer conv2
I0525 08:53:51.002635 19426 net.cpp:106] Creating Layer conv2
I0525 08:53:51.002645 19426 net.cpp:454] conv2 <- pool1
I0525 08:53:51.002658 19426 net.cpp:411] conv2 -> conv2
I0525 08:53:51.005401 19426 net.cpp:150] Setting up conv2
I0525 08:53:51.005429 19426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 08:53:51.005440 19426 net.cpp:165] Memory required for data: 82379160
I0525 08:53:51.005460 19426 layer_factory.hpp:77] Creating layer relu2
I0525 08:53:51.005475 19426 net.cpp:106] Creating Layer relu2
I0525 08:53:51.005484 19426 net.cpp:454] relu2 <- conv2
I0525 08:53:51.005497 19426 net.cpp:397] relu2 -> conv2 (in-place)
I0525 08:53:51.005826 19426 net.cpp:150] Setting up relu2
I0525 08:53:51.005841 19426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 08:53:51.005851 19426 net.cpp:165] Memory required for data: 100263960
I0525 08:53:51.005861 19426 layer_factory.hpp:77] Creating layer pool2
I0525 08:53:51.005874 19426 net.cpp:106] Creating Layer pool2
I0525 08:53:51.005884 19426 net.cpp:454] pool2 <- conv2
I0525 08:53:51.005897 19426 net.cpp:411] pool2 -> pool2
I0525 08:53:51.005976 19426 net.cpp:150] Setting up pool2
I0525 08:53:51.005990 19426 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 08:53:51.006000 19426 net.cpp:165] Memory required for data: 109206360
I0525 08:53:51.006009 19426 layer_factory.hpp:77] Creating layer conv3
I0525 08:53:51.006029 19426 net.cpp:106] Creating Layer conv3
I0525 08:53:51.006039 19426 net.cpp:454] conv3 <- pool2
I0525 08:53:51.006052 19426 net.cpp:411] conv3 -> conv3
I0525 08:53:51.007957 19426 net.cpp:150] Setting up conv3
I0525 08:53:51.007982 19426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 08:53:51.007993 19426 net.cpp:165] Memory required for data: 118963800
I0525 08:53:51.008013 19426 layer_factory.hpp:77] Creating layer relu3
I0525 08:53:51.008028 19426 net.cpp:106] Creating Layer relu3
I0525 08:53:51.008038 19426 net.cpp:454] relu3 <- conv3
I0525 08:53:51.008050 19426 net.cpp:397] relu3 -> conv3 (in-place)
I0525 08:53:51.008517 19426 net.cpp:150] Setting up relu3
I0525 08:53:51.008534 19426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 08:53:51.008544 19426 net.cpp:165] Memory required for data: 128721240
I0525 08:53:51.008555 19426 layer_factory.hpp:77] Creating layer pool3
I0525 08:53:51.008569 19426 net.cpp:106] Creating Layer pool3
I0525 08:53:51.008577 19426 net.cpp:454] pool3 <- conv3
I0525 08:53:51.008590 19426 net.cpp:411] pool3 -> pool3
I0525 08:53:51.008657 19426 net.cpp:150] Setting up pool3
I0525 08:53:51.008671 19426 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 08:53:51.008682 19426 net.cpp:165] Memory required for data: 133599960
I0525 08:53:51.008690 19426 layer_factory.hpp:77] Creating layer conv4
I0525 08:53:51.008708 19426 net.cpp:106] Creating Layer conv4
I0525 08:53:51.008718 19426 net.cpp:454] conv4 <- pool3
I0525 08:53:51.008733 19426 net.cpp:411] conv4 -> conv4
I0525 08:53:51.011680 19426 net.cpp:150] Setting up conv4
I0525 08:53:51.011709 19426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 08:53:51.011720 19426 net.cpp:165] Memory required for data: 136865880
I0525 08:53:51.011735 19426 layer_factory.hpp:77] Creating layer relu4
I0525 08:53:51.011750 19426 net.cpp:106] Creating Layer relu4
I0525 08:53:51.011760 19426 net.cpp:454] relu4 <- conv4
I0525 08:53:51.011773 19426 net.cpp:397] relu4 -> conv4 (in-place)
I0525 08:53:51.012238 19426 net.cpp:150] Setting up relu4
I0525 08:53:51.012253 19426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 08:53:51.012264 19426 net.cpp:165] Memory required for data: 140131800
I0525 08:53:51.012274 19426 layer_factory.hpp:77] Creating layer pool4
I0525 08:53:51.012286 19426 net.cpp:106] Creating Layer pool4
I0525 08:53:51.012296 19426 net.cpp:454] pool4 <- conv4
I0525 08:53:51.012308 19426 net.cpp:411] pool4 -> pool4
I0525 08:53:51.012377 19426 net.cpp:150] Setting up pool4
I0525 08:53:51.012390 19426 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 08:53:51.012400 19426 net.cpp:165] Memory required for data: 141764760
I0525 08:53:51.012410 19426 layer_factory.hpp:77] Creating layer ip1
I0525 08:53:51.012430 19426 net.cpp:106] Creating Layer ip1
I0525 08:53:51.012440 19426 net.cpp:454] ip1 <- pool4
I0525 08:53:51.012454 19426 net.cpp:411] ip1 -> ip1
I0525 08:53:51.027897 19426 net.cpp:150] Setting up ip1
I0525 08:53:51.027925 19426 net.cpp:157] Top shape: 90 196 (17640)
I0525 08:53:51.027936 19426 net.cpp:165] Memory required for data: 141835320
I0525 08:53:51.027958 19426 layer_factory.hpp:77] Creating layer relu5
I0525 08:53:51.027972 19426 net.cpp:106] Creating Layer relu5
I0525 08:53:51.027983 19426 net.cpp:454] relu5 <- ip1
I0525 08:53:51.027997 19426 net.cpp:397] relu5 -> ip1 (in-place)
I0525 08:53:51.028337 19426 net.cpp:150] Setting up relu5
I0525 08:53:51.028350 19426 net.cpp:157] Top shape: 90 196 (17640)
I0525 08:53:51.028360 19426 net.cpp:165] Memory required for data: 141905880
I0525 08:53:51.028370 19426 layer_factory.hpp:77] Creating layer drop1
I0525 08:53:51.028391 19426 net.cpp:106] Creating Layer drop1
I0525 08:53:51.028401 19426 net.cpp:454] drop1 <- ip1
I0525 08:53:51.028414 19426 net.cpp:397] drop1 -> ip1 (in-place)
I0525 08:53:51.028473 19426 net.cpp:150] Setting up drop1
I0525 08:53:51.028487 19426 net.cpp:157] Top shape: 90 196 (17640)
I0525 08:53:51.028496 19426 net.cpp:165] Memory required for data: 141976440
I0525 08:53:51.028506 19426 layer_factory.hpp:77] Creating layer ip2
I0525 08:53:51.028525 19426 net.cpp:106] Creating Layer ip2
I0525 08:53:51.028537 19426 net.cpp:454] ip2 <- ip1
I0525 08:53:51.028549 19426 net.cpp:411] ip2 -> ip2
I0525 08:53:51.029013 19426 net.cpp:150] Setting up ip2
I0525 08:53:51.029026 19426 net.cpp:157] Top shape: 90 98 (8820)
I0525 08:53:51.029043 19426 net.cpp:165] Memory required for data: 142011720
I0525 08:53:51.029059 19426 layer_factory.hpp:77] Creating layer relu6
I0525 08:53:51.029072 19426 net.cpp:106] Creating Layer relu6
I0525 08:53:51.029083 19426 net.cpp:454] relu6 <- ip2
I0525 08:53:51.029094 19426 net.cpp:397] relu6 -> ip2 (in-place)
I0525 08:53:51.029618 19426 net.cpp:150] Setting up relu6
I0525 08:53:51.029633 19426 net.cpp:157] Top shape: 90 98 (8820)
I0525 08:53:51.029644 19426 net.cpp:165] Memory required for data: 142047000
I0525 08:53:51.029654 19426 layer_factory.hpp:77] Creating layer drop2
I0525 08:53:51.029669 19426 net.cpp:106] Creating Layer drop2
I0525 08:53:51.029678 19426 net.cpp:454] drop2 <- ip2
I0525 08:53:51.029690 19426 net.cpp:397] drop2 -> ip2 (in-place)
I0525 08:53:51.029733 19426 net.cpp:150] Setting up drop2
I0525 08:53:51.029747 19426 net.cpp:157] Top shape: 90 98 (8820)
I0525 08:53:51.029757 19426 net.cpp:165] Memory required for data: 142082280
I0525 08:53:51.029767 19426 layer_factory.hpp:77] Creating layer ip3
I0525 08:53:51.029779 19426 net.cpp:106] Creating Layer ip3
I0525 08:53:51.029789 19426 net.cpp:454] ip3 <- ip2
I0525 08:53:51.029803 19426 net.cpp:411] ip3 -> ip3
I0525 08:53:51.030011 19426 net.cpp:150] Setting up ip3
I0525 08:53:51.030025 19426 net.cpp:157] Top shape: 90 11 (990)
I0525 08:53:51.030035 19426 net.cpp:165] Memory required for data: 142086240
I0525 08:53:51.030050 19426 layer_factory.hpp:77] Creating layer drop3
I0525 08:53:51.030061 19426 net.cpp:106] Creating Layer drop3
I0525 08:53:51.030071 19426 net.cpp:454] drop3 <- ip3
I0525 08:53:51.030083 19426 net.cpp:397] drop3 -> ip3 (in-place)
I0525 08:53:51.030122 19426 net.cpp:150] Setting up drop3
I0525 08:53:51.030135 19426 net.cpp:157] Top shape: 90 11 (990)
I0525 08:53:51.030145 19426 net.cpp:165] Memory required for data: 142090200
I0525 08:53:51.030155 19426 layer_factory.hpp:77] Creating layer loss
I0525 08:53:51.030174 19426 net.cpp:106] Creating Layer loss
I0525 08:53:51.030184 19426 net.cpp:454] loss <- ip3
I0525 08:53:51.030195 19426 net.cpp:454] loss <- label
I0525 08:53:51.030207 19426 net.cpp:411] loss -> loss
I0525 08:53:51.030225 19426 layer_factory.hpp:77] Creating layer loss
I0525 08:53:51.030869 19426 net.cpp:150] Setting up loss
I0525 08:53:51.030890 19426 net.cpp:157] Top shape: (1)
I0525 08:53:51.030900 19426 net.cpp:160]     with loss weight 1
I0525 08:53:51.030942 19426 net.cpp:165] Memory required for data: 142090204
I0525 08:53:51.030953 19426 net.cpp:226] loss needs backward computation.
I0525 08:53:51.030964 19426 net.cpp:226] drop3 needs backward computation.
I0525 08:53:51.030974 19426 net.cpp:226] ip3 needs backward computation.
I0525 08:53:51.030984 19426 net.cpp:226] drop2 needs backward computation.
I0525 08:53:51.030994 19426 net.cpp:226] relu6 needs backward computation.
I0525 08:53:51.031004 19426 net.cpp:226] ip2 needs backward computation.
I0525 08:53:51.031014 19426 net.cpp:226] drop1 needs backward computation.
I0525 08:53:51.031024 19426 net.cpp:226] relu5 needs backward computation.
I0525 08:53:51.031033 19426 net.cpp:226] ip1 needs backward computation.
I0525 08:53:51.031044 19426 net.cpp:226] pool4 needs backward computation.
I0525 08:53:51.031054 19426 net.cpp:226] relu4 needs backward computation.
I0525 08:53:51.031064 19426 net.cpp:226] conv4 needs backward computation.
I0525 08:53:51.031072 19426 net.cpp:226] pool3 needs backward computation.
I0525 08:53:51.031085 19426 net.cpp:226] relu3 needs backward computation.
I0525 08:53:51.031102 19426 net.cpp:226] conv3 needs backward computation.
I0525 08:53:51.031114 19426 net.cpp:226] pool2 needs backward computation.
I0525 08:53:51.031126 19426 net.cpp:226] relu2 needs backward computation.
I0525 08:53:51.031136 19426 net.cpp:226] conv2 needs backward computation.
I0525 08:53:51.031147 19426 net.cpp:226] pool1 needs backward computation.
I0525 08:53:51.031157 19426 net.cpp:226] relu1 needs backward computation.
I0525 08:53:51.031167 19426 net.cpp:226] conv1 needs backward computation.
I0525 08:53:51.031178 19426 net.cpp:228] data_hdf5 does not need backward computation.
I0525 08:53:51.031188 19426 net.cpp:270] This network produces output loss
I0525 08:53:51.031211 19426 net.cpp:283] Network initialization done.
I0525 08:53:51.033030 19426 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442.prototxt
I0525 08:53:51.033110 19426 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 08:53:51.033462 19426 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 08:53:51.033649 19426 layer_factory.hpp:77] Creating layer data_hdf5
I0525 08:53:51.033665 19426 net.cpp:106] Creating Layer data_hdf5
I0525 08:53:51.033679 19426 net.cpp:411] data_hdf5 -> data
I0525 08:53:51.033695 19426 net.cpp:411] data_hdf5 -> label
I0525 08:53:51.033711 19426 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 08:53:51.035102 19426 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 08:54:12.422605 19426 net.cpp:150] Setting up data_hdf5
I0525 08:54:12.422770 19426 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 08:54:12.422785 19426 net.cpp:157] Top shape: 90 (90)
I0525 08:54:12.422798 19426 net.cpp:165] Memory required for data: 2286360
I0525 08:54:12.422811 19426 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 08:54:12.422839 19426 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 08:54:12.422850 19426 net.cpp:454] label_data_hdf5_1_split <- label
I0525 08:54:12.422865 19426 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 08:54:12.422886 19426 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 08:54:12.422960 19426 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 08:54:12.422973 19426 net.cpp:157] Top shape: 90 (90)
I0525 08:54:12.422986 19426 net.cpp:157] Top shape: 90 (90)
I0525 08:54:12.422996 19426 net.cpp:165] Memory required for data: 2287080
I0525 08:54:12.423005 19426 layer_factory.hpp:77] Creating layer conv1
I0525 08:54:12.423025 19426 net.cpp:106] Creating Layer conv1
I0525 08:54:12.423037 19426 net.cpp:454] conv1 <- data
I0525 08:54:12.423050 19426 net.cpp:411] conv1 -> conv1
I0525 08:54:12.425006 19426 net.cpp:150] Setting up conv1
I0525 08:54:12.425030 19426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 08:54:12.425051 19426 net.cpp:165] Memory required for data: 27170280
I0525 08:54:12.425072 19426 layer_factory.hpp:77] Creating layer relu1
I0525 08:54:12.425087 19426 net.cpp:106] Creating Layer relu1
I0525 08:54:12.425097 19426 net.cpp:454] relu1 <- conv1
I0525 08:54:12.425109 19426 net.cpp:397] relu1 -> conv1 (in-place)
I0525 08:54:12.425606 19426 net.cpp:150] Setting up relu1
I0525 08:54:12.425622 19426 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 08:54:12.425633 19426 net.cpp:165] Memory required for data: 52053480
I0525 08:54:12.425643 19426 layer_factory.hpp:77] Creating layer pool1
I0525 08:54:12.425659 19426 net.cpp:106] Creating Layer pool1
I0525 08:54:12.425669 19426 net.cpp:454] pool1 <- conv1
I0525 08:54:12.425683 19426 net.cpp:411] pool1 -> pool1
I0525 08:54:12.425758 19426 net.cpp:150] Setting up pool1
I0525 08:54:12.425771 19426 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 08:54:12.425781 19426 net.cpp:165] Memory required for data: 64495080
I0525 08:54:12.425792 19426 layer_factory.hpp:77] Creating layer conv2
I0525 08:54:12.425811 19426 net.cpp:106] Creating Layer conv2
I0525 08:54:12.425820 19426 net.cpp:454] conv2 <- pool1
I0525 08:54:12.425834 19426 net.cpp:411] conv2 -> conv2
I0525 08:54:12.427747 19426 net.cpp:150] Setting up conv2
I0525 08:54:12.427769 19426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 08:54:12.427781 19426 net.cpp:165] Memory required for data: 82379880
I0525 08:54:12.427799 19426 layer_factory.hpp:77] Creating layer relu2
I0525 08:54:12.427812 19426 net.cpp:106] Creating Layer relu2
I0525 08:54:12.427822 19426 net.cpp:454] relu2 <- conv2
I0525 08:54:12.427834 19426 net.cpp:397] relu2 -> conv2 (in-place)
I0525 08:54:12.428169 19426 net.cpp:150] Setting up relu2
I0525 08:54:12.428184 19426 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 08:54:12.428194 19426 net.cpp:165] Memory required for data: 100264680
I0525 08:54:12.428203 19426 layer_factory.hpp:77] Creating layer pool2
I0525 08:54:12.428216 19426 net.cpp:106] Creating Layer pool2
I0525 08:54:12.428226 19426 net.cpp:454] pool2 <- conv2
I0525 08:54:12.428238 19426 net.cpp:411] pool2 -> pool2
I0525 08:54:12.428310 19426 net.cpp:150] Setting up pool2
I0525 08:54:12.428323 19426 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 08:54:12.428333 19426 net.cpp:165] Memory required for data: 109207080
I0525 08:54:12.428344 19426 layer_factory.hpp:77] Creating layer conv3
I0525 08:54:12.428364 19426 net.cpp:106] Creating Layer conv3
I0525 08:54:12.428374 19426 net.cpp:454] conv3 <- pool2
I0525 08:54:12.428387 19426 net.cpp:411] conv3 -> conv3
I0525 08:54:12.430377 19426 net.cpp:150] Setting up conv3
I0525 08:54:12.430400 19426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 08:54:12.430413 19426 net.cpp:165] Memory required for data: 118964520
I0525 08:54:12.430445 19426 layer_factory.hpp:77] Creating layer relu3
I0525 08:54:12.430459 19426 net.cpp:106] Creating Layer relu3
I0525 08:54:12.430469 19426 net.cpp:454] relu3 <- conv3
I0525 08:54:12.430483 19426 net.cpp:397] relu3 -> conv3 (in-place)
I0525 08:54:12.430950 19426 net.cpp:150] Setting up relu3
I0525 08:54:12.430966 19426 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 08:54:12.430976 19426 net.cpp:165] Memory required for data: 128721960
I0525 08:54:12.430986 19426 layer_factory.hpp:77] Creating layer pool3
I0525 08:54:12.430999 19426 net.cpp:106] Creating Layer pool3
I0525 08:54:12.431010 19426 net.cpp:454] pool3 <- conv3
I0525 08:54:12.431022 19426 net.cpp:411] pool3 -> pool3
I0525 08:54:12.431093 19426 net.cpp:150] Setting up pool3
I0525 08:54:12.431107 19426 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 08:54:12.431115 19426 net.cpp:165] Memory required for data: 133600680
I0525 08:54:12.431126 19426 layer_factory.hpp:77] Creating layer conv4
I0525 08:54:12.431143 19426 net.cpp:106] Creating Layer conv4
I0525 08:54:12.431154 19426 net.cpp:454] conv4 <- pool3
I0525 08:54:12.431166 19426 net.cpp:411] conv4 -> conv4
I0525 08:54:12.433250 19426 net.cpp:150] Setting up conv4
I0525 08:54:12.433274 19426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 08:54:12.433285 19426 net.cpp:165] Memory required for data: 136866600
I0525 08:54:12.433300 19426 layer_factory.hpp:77] Creating layer relu4
I0525 08:54:12.433315 19426 net.cpp:106] Creating Layer relu4
I0525 08:54:12.433325 19426 net.cpp:454] relu4 <- conv4
I0525 08:54:12.433337 19426 net.cpp:397] relu4 -> conv4 (in-place)
I0525 08:54:12.433809 19426 net.cpp:150] Setting up relu4
I0525 08:54:12.433825 19426 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 08:54:12.433835 19426 net.cpp:165] Memory required for data: 140132520
I0525 08:54:12.433845 19426 layer_factory.hpp:77] Creating layer pool4
I0525 08:54:12.433858 19426 net.cpp:106] Creating Layer pool4
I0525 08:54:12.433868 19426 net.cpp:454] pool4 <- conv4
I0525 08:54:12.433881 19426 net.cpp:411] pool4 -> pool4
I0525 08:54:12.433954 19426 net.cpp:150] Setting up pool4
I0525 08:54:12.433966 19426 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 08:54:12.433976 19426 net.cpp:165] Memory required for data: 141765480
I0525 08:54:12.433986 19426 layer_factory.hpp:77] Creating layer ip1
I0525 08:54:12.434002 19426 net.cpp:106] Creating Layer ip1
I0525 08:54:12.434012 19426 net.cpp:454] ip1 <- pool4
I0525 08:54:12.434026 19426 net.cpp:411] ip1 -> ip1
I0525 08:54:12.449506 19426 net.cpp:150] Setting up ip1
I0525 08:54:12.449533 19426 net.cpp:157] Top shape: 90 196 (17640)
I0525 08:54:12.449545 19426 net.cpp:165] Memory required for data: 141836040
I0525 08:54:12.449568 19426 layer_factory.hpp:77] Creating layer relu5
I0525 08:54:12.449582 19426 net.cpp:106] Creating Layer relu5
I0525 08:54:12.449594 19426 net.cpp:454] relu5 <- ip1
I0525 08:54:12.449606 19426 net.cpp:397] relu5 -> ip1 (in-place)
I0525 08:54:12.449955 19426 net.cpp:150] Setting up relu5
I0525 08:54:12.449970 19426 net.cpp:157] Top shape: 90 196 (17640)
I0525 08:54:12.449980 19426 net.cpp:165] Memory required for data: 141906600
I0525 08:54:12.449990 19426 layer_factory.hpp:77] Creating layer drop1
I0525 08:54:12.450007 19426 net.cpp:106] Creating Layer drop1
I0525 08:54:12.450017 19426 net.cpp:454] drop1 <- ip1
I0525 08:54:12.450031 19426 net.cpp:397] drop1 -> ip1 (in-place)
I0525 08:54:12.450078 19426 net.cpp:150] Setting up drop1
I0525 08:54:12.450090 19426 net.cpp:157] Top shape: 90 196 (17640)
I0525 08:54:12.450100 19426 net.cpp:165] Memory required for data: 141977160
I0525 08:54:12.450109 19426 layer_factory.hpp:77] Creating layer ip2
I0525 08:54:12.450124 19426 net.cpp:106] Creating Layer ip2
I0525 08:54:12.450134 19426 net.cpp:454] ip2 <- ip1
I0525 08:54:12.450147 19426 net.cpp:411] ip2 -> ip2
I0525 08:54:12.450628 19426 net.cpp:150] Setting up ip2
I0525 08:54:12.450641 19426 net.cpp:157] Top shape: 90 98 (8820)
I0525 08:54:12.450651 19426 net.cpp:165] Memory required for data: 142012440
I0525 08:54:12.450666 19426 layer_factory.hpp:77] Creating layer relu6
I0525 08:54:12.450692 19426 net.cpp:106] Creating Layer relu6
I0525 08:54:12.450702 19426 net.cpp:454] relu6 <- ip2
I0525 08:54:12.450714 19426 net.cpp:397] relu6 -> ip2 (in-place)
I0525 08:54:12.451249 19426 net.cpp:150] Setting up relu6
I0525 08:54:12.451266 19426 net.cpp:157] Top shape: 90 98 (8820)
I0525 08:54:12.451274 19426 net.cpp:165] Memory required for data: 142047720
I0525 08:54:12.451284 19426 layer_factory.hpp:77] Creating layer drop2
I0525 08:54:12.451298 19426 net.cpp:106] Creating Layer drop2
I0525 08:54:12.451308 19426 net.cpp:454] drop2 <- ip2
I0525 08:54:12.451321 19426 net.cpp:397] drop2 -> ip2 (in-place)
I0525 08:54:12.451365 19426 net.cpp:150] Setting up drop2
I0525 08:54:12.451378 19426 net.cpp:157] Top shape: 90 98 (8820)
I0525 08:54:12.451388 19426 net.cpp:165] Memory required for data: 142083000
I0525 08:54:12.451397 19426 layer_factory.hpp:77] Creating layer ip3
I0525 08:54:12.451412 19426 net.cpp:106] Creating Layer ip3
I0525 08:54:12.451421 19426 net.cpp:454] ip3 <- ip2
I0525 08:54:12.451436 19426 net.cpp:411] ip3 -> ip3
I0525 08:54:12.451659 19426 net.cpp:150] Setting up ip3
I0525 08:54:12.451673 19426 net.cpp:157] Top shape: 90 11 (990)
I0525 08:54:12.451683 19426 net.cpp:165] Memory required for data: 142086960
I0525 08:54:12.451697 19426 layer_factory.hpp:77] Creating layer drop3
I0525 08:54:12.451711 19426 net.cpp:106] Creating Layer drop3
I0525 08:54:12.451720 19426 net.cpp:454] drop3 <- ip3
I0525 08:54:12.451733 19426 net.cpp:397] drop3 -> ip3 (in-place)
I0525 08:54:12.451776 19426 net.cpp:150] Setting up drop3
I0525 08:54:12.451788 19426 net.cpp:157] Top shape: 90 11 (990)
I0525 08:54:12.451798 19426 net.cpp:165] Memory required for data: 142090920
I0525 08:54:12.451808 19426 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 08:54:12.451822 19426 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 08:54:12.451830 19426 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 08:54:12.451843 19426 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 08:54:12.451858 19426 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 08:54:12.451931 19426 net.cpp:150] Setting up ip3_drop3_0_split
I0525 08:54:12.451944 19426 net.cpp:157] Top shape: 90 11 (990)
I0525 08:54:12.451956 19426 net.cpp:157] Top shape: 90 11 (990)
I0525 08:54:12.451967 19426 net.cpp:165] Memory required for data: 142098840
I0525 08:54:12.451977 19426 layer_factory.hpp:77] Creating layer accuracy
I0525 08:54:12.451999 19426 net.cpp:106] Creating Layer accuracy
I0525 08:54:12.452008 19426 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 08:54:12.452020 19426 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 08:54:12.452033 19426 net.cpp:411] accuracy -> accuracy
I0525 08:54:12.452056 19426 net.cpp:150] Setting up accuracy
I0525 08:54:12.452069 19426 net.cpp:157] Top shape: (1)
I0525 08:54:12.452078 19426 net.cpp:165] Memory required for data: 142098844
I0525 08:54:12.452088 19426 layer_factory.hpp:77] Creating layer loss
I0525 08:54:12.452103 19426 net.cpp:106] Creating Layer loss
I0525 08:54:12.452113 19426 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 08:54:12.452123 19426 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 08:54:12.452137 19426 net.cpp:411] loss -> loss
I0525 08:54:12.452154 19426 layer_factory.hpp:77] Creating layer loss
I0525 08:54:12.452646 19426 net.cpp:150] Setting up loss
I0525 08:54:12.452661 19426 net.cpp:157] Top shape: (1)
I0525 08:54:12.452669 19426 net.cpp:160]     with loss weight 1
I0525 08:54:12.452688 19426 net.cpp:165] Memory required for data: 142098848
I0525 08:54:12.452698 19426 net.cpp:226] loss needs backward computation.
I0525 08:54:12.452709 19426 net.cpp:228] accuracy does not need backward computation.
I0525 08:54:12.452720 19426 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 08:54:12.452731 19426 net.cpp:226] drop3 needs backward computation.
I0525 08:54:12.452741 19426 net.cpp:226] ip3 needs backward computation.
I0525 08:54:12.452752 19426 net.cpp:226] drop2 needs backward computation.
I0525 08:54:12.452761 19426 net.cpp:226] relu6 needs backward computation.
I0525 08:54:12.452780 19426 net.cpp:226] ip2 needs backward computation.
I0525 08:54:12.452790 19426 net.cpp:226] drop1 needs backward computation.
I0525 08:54:12.452800 19426 net.cpp:226] relu5 needs backward computation.
I0525 08:54:12.452810 19426 net.cpp:226] ip1 needs backward computation.
I0525 08:54:12.452819 19426 net.cpp:226] pool4 needs backward computation.
I0525 08:54:12.452829 19426 net.cpp:226] relu4 needs backward computation.
I0525 08:54:12.452839 19426 net.cpp:226] conv4 needs backward computation.
I0525 08:54:12.452847 19426 net.cpp:226] pool3 needs backward computation.
I0525 08:54:12.452858 19426 net.cpp:226] relu3 needs backward computation.
I0525 08:54:12.452868 19426 net.cpp:226] conv3 needs backward computation.
I0525 08:54:12.452880 19426 net.cpp:226] pool2 needs backward computation.
I0525 08:54:12.452890 19426 net.cpp:226] relu2 needs backward computation.
I0525 08:54:12.452900 19426 net.cpp:226] conv2 needs backward computation.
I0525 08:54:12.452910 19426 net.cpp:226] pool1 needs backward computation.
I0525 08:54:12.452920 19426 net.cpp:226] relu1 needs backward computation.
I0525 08:54:12.452930 19426 net.cpp:226] conv1 needs backward computation.
I0525 08:54:12.452942 19426 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 08:54:12.452982 19426 net.cpp:228] data_hdf5 does not need backward computation.
I0525 08:54:12.452992 19426 net.cpp:270] This network produces output accuracy
I0525 08:54:12.453003 19426 net.cpp:270] This network produces output loss
I0525 08:54:12.453032 19426 net.cpp:283] Network initialization done.
I0525 08:54:12.453172 19426 solver.cpp:60] Solver scaffolding done.
I0525 08:54:12.454308 19426 caffe.cpp:212] Starting Optimization
I0525 08:54:12.454326 19426 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 08:54:12.454340 19426 solver.cpp:289] Learning Rate Policy: fixed
I0525 08:54:12.455405 19426 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 08:55:00.566246 19426 solver.cpp:409]     Test net output #0: accuracy = 0.0596503
I0525 08:55:00.566409 19426 solver.cpp:409]     Test net output #1: loss = 2.39802 (* 1 = 2.39802 loss)
I0525 08:55:00.597599 19426 solver.cpp:237] Iteration 0, loss = 2.39177
I0525 08:55:00.597635 19426 solver.cpp:253]     Train net output #0: loss = 2.39177 (* 1 = 2.39177 loss)
I0525 08:55:00.597652 19426 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0525 08:55:09.427042 19426 solver.cpp:237] Iteration 166, loss = 2.2629
I0525 08:55:09.427078 19426 solver.cpp:253]     Train net output #0: loss = 2.2629 (* 1 = 2.2629 loss)
I0525 08:55:09.427094 19426 sgd_solver.cpp:106] Iteration 166, lr = 0.0035
I0525 08:55:18.252457 19426 solver.cpp:237] Iteration 332, loss = 2.15517
I0525 08:55:18.252493 19426 solver.cpp:253]     Train net output #0: loss = 2.15517 (* 1 = 2.15517 loss)
I0525 08:55:18.252516 19426 sgd_solver.cpp:106] Iteration 332, lr = 0.0035
I0525 08:55:27.082222 19426 solver.cpp:237] Iteration 498, loss = 1.95496
I0525 08:55:27.082258 19426 solver.cpp:253]     Train net output #0: loss = 1.95496 (* 1 = 1.95496 loss)
I0525 08:55:27.082275 19426 sgd_solver.cpp:106] Iteration 498, lr = 0.0035
I0525 08:55:35.907707 19426 solver.cpp:237] Iteration 664, loss = 2.05597
I0525 08:55:35.907855 19426 solver.cpp:253]     Train net output #0: loss = 2.05597 (* 1 = 2.05597 loss)
I0525 08:55:35.907868 19426 sgd_solver.cpp:106] Iteration 664, lr = 0.0035
I0525 08:55:44.746795 19426 solver.cpp:237] Iteration 830, loss = 2.07795
I0525 08:55:44.746834 19426 solver.cpp:253]     Train net output #0: loss = 2.07795 (* 1 = 2.07795 loss)
I0525 08:55:44.746855 19426 sgd_solver.cpp:106] Iteration 830, lr = 0.0035
I0525 08:55:53.582183 19426 solver.cpp:237] Iteration 996, loss = 1.76464
I0525 08:55:53.582221 19426 solver.cpp:253]     Train net output #0: loss = 1.76464 (* 1 = 1.76464 loss)
I0525 08:55:53.582234 19426 sgd_solver.cpp:106] Iteration 996, lr = 0.0035
I0525 08:56:24.548604 19426 solver.cpp:237] Iteration 1162, loss = 1.68451
I0525 08:56:24.548764 19426 solver.cpp:253]     Train net output #0: loss = 1.68451 (* 1 = 1.68451 loss)
I0525 08:56:24.548779 19426 sgd_solver.cpp:106] Iteration 1162, lr = 0.0035
I0525 08:56:33.377343 19426 solver.cpp:237] Iteration 1328, loss = 1.55176
I0525 08:56:33.377382 19426 solver.cpp:253]     Train net output #0: loss = 1.55176 (* 1 = 1.55176 loss)
I0525 08:56:33.377403 19426 sgd_solver.cpp:106] Iteration 1328, lr = 0.0035
I0525 08:56:42.199213 19426 solver.cpp:237] Iteration 1494, loss = 1.8304
I0525 08:56:42.199249 19426 solver.cpp:253]     Train net output #0: loss = 1.8304 (* 1 = 1.8304 loss)
I0525 08:56:42.199265 19426 sgd_solver.cpp:106] Iteration 1494, lr = 0.0035
I0525 08:56:51.033301 19426 solver.cpp:237] Iteration 1660, loss = 1.77859
I0525 08:56:51.033337 19426 solver.cpp:253]     Train net output #0: loss = 1.77859 (* 1 = 1.77859 loss)
I0525 08:56:51.033350 19426 sgd_solver.cpp:106] Iteration 1660, lr = 0.0035
I0525 08:56:51.298888 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_1666.caffemodel
I0525 08:56:51.377873 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_1666.solverstate
I0525 08:56:59.929288 19426 solver.cpp:237] Iteration 1826, loss = 1.75598
I0525 08:56:59.929445 19426 solver.cpp:253]     Train net output #0: loss = 1.75598 (* 1 = 1.75598 loss)
I0525 08:56:59.929460 19426 sgd_solver.cpp:106] Iteration 1826, lr = 0.0035
I0525 08:57:08.763741 19426 solver.cpp:237] Iteration 1992, loss = 1.84167
I0525 08:57:08.763777 19426 solver.cpp:253]     Train net output #0: loss = 1.84167 (* 1 = 1.84167 loss)
I0525 08:57:08.763794 19426 sgd_solver.cpp:106] Iteration 1992, lr = 0.0035
I0525 08:57:17.601069 19426 solver.cpp:237] Iteration 2158, loss = 1.54286
I0525 08:57:17.601104 19426 solver.cpp:253]     Train net output #0: loss = 1.54286 (* 1 = 1.54286 loss)
I0525 08:57:17.601119 19426 sgd_solver.cpp:106] Iteration 2158, lr = 0.0035
I0525 08:57:48.540472 19426 solver.cpp:237] Iteration 2324, loss = 1.5442
I0525 08:57:48.540626 19426 solver.cpp:253]     Train net output #0: loss = 1.5442 (* 1 = 1.5442 loss)
I0525 08:57:48.540642 19426 sgd_solver.cpp:106] Iteration 2324, lr = 0.0035
I0525 08:57:57.380112 19426 solver.cpp:237] Iteration 2490, loss = 1.77499
I0525 08:57:57.380146 19426 solver.cpp:253]     Train net output #0: loss = 1.77499 (* 1 = 1.77499 loss)
I0525 08:57:57.380164 19426 sgd_solver.cpp:106] Iteration 2490, lr = 0.0035
I0525 08:58:06.212316 19426 solver.cpp:237] Iteration 2656, loss = 1.52771
I0525 08:58:06.212350 19426 solver.cpp:253]     Train net output #0: loss = 1.52771 (* 1 = 1.52771 loss)
I0525 08:58:06.212368 19426 sgd_solver.cpp:106] Iteration 2656, lr = 0.0035
I0525 08:58:15.040629 19426 solver.cpp:237] Iteration 2822, loss = 1.56552
I0525 08:58:15.040673 19426 solver.cpp:253]     Train net output #0: loss = 1.56552 (* 1 = 1.56552 loss)
I0525 08:58:15.040691 19426 sgd_solver.cpp:106] Iteration 2822, lr = 0.0035
I0525 08:58:23.869884 19426 solver.cpp:237] Iteration 2988, loss = 1.41629
I0525 08:58:23.870030 19426 solver.cpp:253]     Train net output #0: loss = 1.41629 (* 1 = 1.41629 loss)
I0525 08:58:23.870044 19426 sgd_solver.cpp:106] Iteration 2988, lr = 0.0035
I0525 08:58:32.705636 19426 solver.cpp:237] Iteration 3154, loss = 1.35054
I0525 08:58:32.705670 19426 solver.cpp:253]     Train net output #0: loss = 1.35054 (* 1 = 1.35054 loss)
I0525 08:58:32.705688 19426 sgd_solver.cpp:106] Iteration 3154, lr = 0.0035
I0525 08:58:41.546542 19426 solver.cpp:237] Iteration 3320, loss = 1.64407
I0525 08:58:41.546581 19426 solver.cpp:253]     Train net output #0: loss = 1.64407 (* 1 = 1.64407 loss)
I0525 08:58:41.546602 19426 sgd_solver.cpp:106] Iteration 3320, lr = 0.0035
I0525 08:58:42.132202 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_3332.caffemodel
I0525 08:58:42.206828 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_3332.solverstate
I0525 08:58:42.250757 19426 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 08:59:29.410313 19426 solver.cpp:409]     Test net output #0: accuracy = 0.77612
I0525 08:59:29.410472 19426 solver.cpp:409]     Test net output #1: loss = 0.876273 (* 1 = 0.876273 loss)
I0525 08:59:59.752100 19426 solver.cpp:237] Iteration 3486, loss = 1.46087
I0525 08:59:59.752259 19426 solver.cpp:253]     Train net output #0: loss = 1.46087 (* 1 = 1.46087 loss)
I0525 08:59:59.752274 19426 sgd_solver.cpp:106] Iteration 3486, lr = 0.0035
I0525 09:00:08.566982 19426 solver.cpp:237] Iteration 3652, loss = 1.44606
I0525 09:00:08.567016 19426 solver.cpp:253]     Train net output #0: loss = 1.44606 (* 1 = 1.44606 loss)
I0525 09:00:08.567034 19426 sgd_solver.cpp:106] Iteration 3652, lr = 0.0035
I0525 09:00:17.393920 19426 solver.cpp:237] Iteration 3818, loss = 1.54193
I0525 09:00:17.393968 19426 solver.cpp:253]     Train net output #0: loss = 1.54193 (* 1 = 1.54193 loss)
I0525 09:00:17.393985 19426 sgd_solver.cpp:106] Iteration 3818, lr = 0.0035
I0525 09:00:26.212601 19426 solver.cpp:237] Iteration 3984, loss = 1.50189
I0525 09:00:26.212637 19426 solver.cpp:253]     Train net output #0: loss = 1.50189 (* 1 = 1.50189 loss)
I0525 09:00:26.212651 19426 sgd_solver.cpp:106] Iteration 3984, lr = 0.0035
I0525 09:00:35.036090 19426 solver.cpp:237] Iteration 4150, loss = 1.34336
I0525 09:00:35.036228 19426 solver.cpp:253]     Train net output #0: loss = 1.34336 (* 1 = 1.34336 loss)
I0525 09:00:35.036242 19426 sgd_solver.cpp:106] Iteration 4150, lr = 0.0035
I0525 09:00:43.855293 19426 solver.cpp:237] Iteration 4316, loss = 1.56444
I0525 09:00:43.855332 19426 solver.cpp:253]     Train net output #0: loss = 1.56444 (* 1 = 1.56444 loss)
I0525 09:00:43.855350 19426 sgd_solver.cpp:106] Iteration 4316, lr = 0.0035
I0525 09:01:14.805912 19426 solver.cpp:237] Iteration 4482, loss = 1.48517
I0525 09:01:14.806076 19426 solver.cpp:253]     Train net output #0: loss = 1.48517 (* 1 = 1.48517 loss)
I0525 09:01:14.806092 19426 sgd_solver.cpp:106] Iteration 4482, lr = 0.0035
I0525 09:01:23.638712 19426 solver.cpp:237] Iteration 4648, loss = 1.38754
I0525 09:01:23.638746 19426 solver.cpp:253]     Train net output #0: loss = 1.38754 (* 1 = 1.38754 loss)
I0525 09:01:23.638763 19426 sgd_solver.cpp:106] Iteration 4648, lr = 0.0035
I0525 09:01:32.467494 19426 solver.cpp:237] Iteration 4814, loss = 1.08627
I0525 09:01:32.467543 19426 solver.cpp:253]     Train net output #0: loss = 1.08627 (* 1 = 1.08627 loss)
I0525 09:01:32.467558 19426 sgd_solver.cpp:106] Iteration 4814, lr = 0.0035
I0525 09:01:41.282753 19426 solver.cpp:237] Iteration 4980, loss = 1.31174
I0525 09:01:41.282789 19426 solver.cpp:253]     Train net output #0: loss = 1.31174 (* 1 = 1.31174 loss)
I0525 09:01:41.282804 19426 sgd_solver.cpp:106] Iteration 4980, lr = 0.0035
I0525 09:01:42.186604 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_4998.caffemodel
I0525 09:01:42.264066 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_4998.solverstate
I0525 09:01:50.178874 19426 solver.cpp:237] Iteration 5146, loss = 1.32001
I0525 09:01:50.179041 19426 solver.cpp:253]     Train net output #0: loss = 1.32001 (* 1 = 1.32001 loss)
I0525 09:01:50.179055 19426 sgd_solver.cpp:106] Iteration 5146, lr = 0.0035
I0525 09:01:58.995599 19426 solver.cpp:237] Iteration 5312, loss = 1.53252
I0525 09:01:58.995646 19426 solver.cpp:253]     Train net output #0: loss = 1.53252 (* 1 = 1.53252 loss)
I0525 09:01:58.995663 19426 sgd_solver.cpp:106] Iteration 5312, lr = 0.0035
I0525 09:02:07.817869 19426 solver.cpp:237] Iteration 5478, loss = 1.46808
I0525 09:02:07.817905 19426 solver.cpp:253]     Train net output #0: loss = 1.46808 (* 1 = 1.46808 loss)
I0525 09:02:07.817921 19426 sgd_solver.cpp:106] Iteration 5478, lr = 0.0035
I0525 09:02:38.856233 19426 solver.cpp:237] Iteration 5644, loss = 1.52125
I0525 09:02:38.856408 19426 solver.cpp:253]     Train net output #0: loss = 1.52125 (* 1 = 1.52125 loss)
I0525 09:02:38.856423 19426 sgd_solver.cpp:106] Iteration 5644, lr = 0.0035
I0525 09:02:47.683830 19426 solver.cpp:237] Iteration 5810, loss = 1.64807
I0525 09:02:47.683871 19426 solver.cpp:253]     Train net output #0: loss = 1.64807 (* 1 = 1.64807 loss)
I0525 09:02:47.683892 19426 sgd_solver.cpp:106] Iteration 5810, lr = 0.0035
I0525 09:02:56.508543 19426 solver.cpp:237] Iteration 5976, loss = 1.31977
I0525 09:02:56.508580 19426 solver.cpp:253]     Train net output #0: loss = 1.31977 (* 1 = 1.31977 loss)
I0525 09:02:56.508596 19426 sgd_solver.cpp:106] Iteration 5976, lr = 0.0035
I0525 09:03:05.336685 19426 solver.cpp:237] Iteration 6142, loss = 1.56195
I0525 09:03:05.336721 19426 solver.cpp:253]     Train net output #0: loss = 1.56195 (* 1 = 1.56195 loss)
I0525 09:03:05.336737 19426 sgd_solver.cpp:106] Iteration 6142, lr = 0.0035
I0525 09:03:14.166101 19426 solver.cpp:237] Iteration 6308, loss = 1.39036
I0525 09:03:14.166254 19426 solver.cpp:253]     Train net output #0: loss = 1.39036 (* 1 = 1.39036 loss)
I0525 09:03:14.166267 19426 sgd_solver.cpp:106] Iteration 6308, lr = 0.0035
I0525 09:03:22.976646 19426 solver.cpp:237] Iteration 6474, loss = 1.3513
I0525 09:03:22.976680 19426 solver.cpp:253]     Train net output #0: loss = 1.3513 (* 1 = 1.3513 loss)
I0525 09:03:22.976698 19426 sgd_solver.cpp:106] Iteration 6474, lr = 0.0035
I0525 09:03:31.791796 19426 solver.cpp:237] Iteration 6640, loss = 1.37438
I0525 09:03:31.791831 19426 solver.cpp:253]     Train net output #0: loss = 1.37438 (* 1 = 1.37438 loss)
I0525 09:03:31.791846 19426 sgd_solver.cpp:106] Iteration 6640, lr = 0.0035
I0525 09:03:33.017751 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_6664.caffemodel
I0525 09:03:33.093757 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_6664.solverstate
I0525 09:03:33.190273 19426 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 09:04:41.238862 19426 solver.cpp:409]     Test net output #0: accuracy = 0.822374
I0525 09:04:41.239033 19426 solver.cpp:409]     Test net output #1: loss = 0.58347 (* 1 = 0.58347 loss)
I0525 09:05:10.833978 19426 solver.cpp:237] Iteration 6806, loss = 1.33762
I0525 09:05:10.834028 19426 solver.cpp:253]     Train net output #0: loss = 1.33762 (* 1 = 1.33762 loss)
I0525 09:05:10.834044 19426 sgd_solver.cpp:106] Iteration 6806, lr = 0.0035
I0525 09:05:19.661223 19426 solver.cpp:237] Iteration 6972, loss = 1.25947
I0525 09:05:19.661378 19426 solver.cpp:253]     Train net output #0: loss = 1.25947 (* 1 = 1.25947 loss)
I0525 09:05:19.661392 19426 sgd_solver.cpp:106] Iteration 6972, lr = 0.0035
I0525 09:05:28.482834 19426 solver.cpp:237] Iteration 7138, loss = 1.27939
I0525 09:05:28.482868 19426 solver.cpp:253]     Train net output #0: loss = 1.27939 (* 1 = 1.27939 loss)
I0525 09:05:28.482885 19426 sgd_solver.cpp:106] Iteration 7138, lr = 0.0035
I0525 09:05:37.308430 19426 solver.cpp:237] Iteration 7304, loss = 1.24454
I0525 09:05:37.308465 19426 solver.cpp:253]     Train net output #0: loss = 1.24454 (* 1 = 1.24454 loss)
I0525 09:05:37.308481 19426 sgd_solver.cpp:106] Iteration 7304, lr = 0.0035
I0525 09:05:46.130056 19426 solver.cpp:237] Iteration 7470, loss = 1.49793
I0525 09:05:46.130105 19426 solver.cpp:253]     Train net output #0: loss = 1.49793 (* 1 = 1.49793 loss)
I0525 09:05:46.130120 19426 sgd_solver.cpp:106] Iteration 7470, lr = 0.0035
I0525 09:05:54.954649 19426 solver.cpp:237] Iteration 7636, loss = 1.36996
I0525 09:05:54.954790 19426 solver.cpp:253]     Train net output #0: loss = 1.36996 (* 1 = 1.36996 loss)
I0525 09:05:54.954804 19426 sgd_solver.cpp:106] Iteration 7636, lr = 0.0035
I0525 09:06:25.959594 19426 solver.cpp:237] Iteration 7802, loss = 1.16917
I0525 09:06:25.959758 19426 solver.cpp:253]     Train net output #0: loss = 1.16917 (* 1 = 1.16917 loss)
I0525 09:06:25.959774 19426 sgd_solver.cpp:106] Iteration 7802, lr = 0.0035
I0525 09:06:34.781159 19426 solver.cpp:237] Iteration 7968, loss = 1.40173
I0525 09:06:34.781208 19426 solver.cpp:253]     Train net output #0: loss = 1.40173 (* 1 = 1.40173 loss)
I0525 09:06:34.781224 19426 sgd_solver.cpp:106] Iteration 7968, lr = 0.0035
I0525 09:06:43.598949 19426 solver.cpp:237] Iteration 8134, loss = 1.49643
I0525 09:06:43.598985 19426 solver.cpp:253]     Train net output #0: loss = 1.49643 (* 1 = 1.49643 loss)
I0525 09:06:43.599002 19426 sgd_solver.cpp:106] Iteration 8134, lr = 0.0035
I0525 09:06:52.422117 19426 solver.cpp:237] Iteration 8300, loss = 1.39667
I0525 09:06:52.422153 19426 solver.cpp:253]     Train net output #0: loss = 1.39667 (* 1 = 1.39667 loss)
I0525 09:06:52.422169 19426 sgd_solver.cpp:106] Iteration 8300, lr = 0.0035
I0525 09:06:53.965535 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_8330.caffemodel
I0525 09:06:54.042770 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_8330.solverstate
I0525 09:07:01.317656 19426 solver.cpp:237] Iteration 8466, loss = 1.25505
I0525 09:07:01.317811 19426 solver.cpp:253]     Train net output #0: loss = 1.25505 (* 1 = 1.25505 loss)
I0525 09:07:01.317826 19426 sgd_solver.cpp:106] Iteration 8466, lr = 0.0035
I0525 09:07:10.140550 19426 solver.cpp:237] Iteration 8632, loss = 1.32886
I0525 09:07:10.140586 19426 solver.cpp:253]     Train net output #0: loss = 1.32886 (* 1 = 1.32886 loss)
I0525 09:07:10.140604 19426 sgd_solver.cpp:106] Iteration 8632, lr = 0.0035
I0525 09:07:18.965826 19426 solver.cpp:237] Iteration 8798, loss = 1.34664
I0525 09:07:18.965873 19426 solver.cpp:253]     Train net output #0: loss = 1.34664 (* 1 = 1.34664 loss)
I0525 09:07:18.965889 19426 sgd_solver.cpp:106] Iteration 8798, lr = 0.0035
I0525 09:07:49.946143 19426 solver.cpp:237] Iteration 8964, loss = 1.35689
I0525 09:07:49.946318 19426 solver.cpp:253]     Train net output #0: loss = 1.35689 (* 1 = 1.35689 loss)
I0525 09:07:49.946334 19426 sgd_solver.cpp:106] Iteration 8964, lr = 0.0035
I0525 09:07:58.766821 19426 solver.cpp:237] Iteration 9130, loss = 1.63259
I0525 09:07:58.766856 19426 solver.cpp:253]     Train net output #0: loss = 1.63259 (* 1 = 1.63259 loss)
I0525 09:07:58.766873 19426 sgd_solver.cpp:106] Iteration 9130, lr = 0.0035
I0525 09:08:07.586484 19426 solver.cpp:237] Iteration 9296, loss = 1.22586
I0525 09:08:07.586519 19426 solver.cpp:253]     Train net output #0: loss = 1.22586 (* 1 = 1.22586 loss)
I0525 09:08:07.586537 19426 sgd_solver.cpp:106] Iteration 9296, lr = 0.0035
I0525 09:08:16.412484 19426 solver.cpp:237] Iteration 9462, loss = 1.16961
I0525 09:08:16.412526 19426 solver.cpp:253]     Train net output #0: loss = 1.16961 (* 1 = 1.16961 loss)
I0525 09:08:16.412542 19426 sgd_solver.cpp:106] Iteration 9462, lr = 0.0035
I0525 09:08:25.242568 19426 solver.cpp:237] Iteration 9628, loss = 1.14282
I0525 09:08:25.242712 19426 solver.cpp:253]     Train net output #0: loss = 1.14282 (* 1 = 1.14282 loss)
I0525 09:08:25.242727 19426 sgd_solver.cpp:106] Iteration 9628, lr = 0.0035
I0525 09:08:34.073285 19426 solver.cpp:237] Iteration 9794, loss = 1.33606
I0525 09:08:34.073333 19426 solver.cpp:253]     Train net output #0: loss = 1.33606 (* 1 = 1.33606 loss)
I0525 09:08:34.073349 19426 sgd_solver.cpp:106] Iteration 9794, lr = 0.0035
I0525 09:08:42.895401 19426 solver.cpp:237] Iteration 9960, loss = 1.30713
I0525 09:08:42.895437 19426 solver.cpp:253]     Train net output #0: loss = 1.30713 (* 1 = 1.30713 loss)
I0525 09:08:42.895453 19426 sgd_solver.cpp:106] Iteration 9960, lr = 0.0035
I0525 09:08:44.758468 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_9996.caffemodel
I0525 09:08:44.832707 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_9996.solverstate
I0525 09:08:44.982756 19426 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 09:09:31.801887 19426 solver.cpp:409]     Test net output #0: accuracy = 0.839329
I0525 09:09:31.802058 19426 solver.cpp:409]     Test net output #1: loss = 0.524534 (* 1 = 0.524534 loss)
I0525 09:10:00.721017 19426 solver.cpp:237] Iteration 10126, loss = 1.1964
I0525 09:10:00.721072 19426 solver.cpp:253]     Train net output #0: loss = 1.1964 (* 1 = 1.1964 loss)
I0525 09:10:00.721086 19426 sgd_solver.cpp:106] Iteration 10126, lr = 0.0035
I0525 09:10:09.545198 19426 solver.cpp:237] Iteration 10292, loss = 1.35379
I0525 09:10:09.545348 19426 solver.cpp:253]     Train net output #0: loss = 1.35379 (* 1 = 1.35379 loss)
I0525 09:10:09.545361 19426 sgd_solver.cpp:106] Iteration 10292, lr = 0.0035
I0525 09:10:18.373474 19426 solver.cpp:237] Iteration 10458, loss = 1.27685
I0525 09:10:18.373520 19426 solver.cpp:253]     Train net output #0: loss = 1.27685 (* 1 = 1.27685 loss)
I0525 09:10:18.373536 19426 sgd_solver.cpp:106] Iteration 10458, lr = 0.0035
I0525 09:10:27.192324 19426 solver.cpp:237] Iteration 10624, loss = 1.28451
I0525 09:10:27.192360 19426 solver.cpp:253]     Train net output #0: loss = 1.28451 (* 1 = 1.28451 loss)
I0525 09:10:27.192373 19426 sgd_solver.cpp:106] Iteration 10624, lr = 0.0035
I0525 09:10:36.018906 19426 solver.cpp:237] Iteration 10790, loss = 1.12095
I0525 09:10:36.018942 19426 solver.cpp:253]     Train net output #0: loss = 1.12095 (* 1 = 1.12095 loss)
I0525 09:10:36.018959 19426 sgd_solver.cpp:106] Iteration 10790, lr = 0.0035
I0525 09:10:44.842661 19426 solver.cpp:237] Iteration 10956, loss = 1.28323
I0525 09:10:44.842831 19426 solver.cpp:253]     Train net output #0: loss = 1.28323 (* 1 = 1.28323 loss)
I0525 09:10:44.842846 19426 sgd_solver.cpp:106] Iteration 10956, lr = 0.0035
I0525 09:11:15.808704 19426 solver.cpp:237] Iteration 11122, loss = 1.29296
I0525 09:11:15.808877 19426 solver.cpp:253]     Train net output #0: loss = 1.29296 (* 1 = 1.29296 loss)
I0525 09:11:15.808892 19426 sgd_solver.cpp:106] Iteration 11122, lr = 0.0035
I0525 09:11:24.624253 19426 solver.cpp:237] Iteration 11288, loss = 1.10468
I0525 09:11:24.624289 19426 solver.cpp:253]     Train net output #0: loss = 1.10468 (* 1 = 1.10468 loss)
I0525 09:11:24.624305 19426 sgd_solver.cpp:106] Iteration 11288, lr = 0.0035
I0525 09:11:33.442390 19426 solver.cpp:237] Iteration 11454, loss = 1.18789
I0525 09:11:33.442440 19426 solver.cpp:253]     Train net output #0: loss = 1.18789 (* 1 = 1.18789 loss)
I0525 09:11:33.442454 19426 sgd_solver.cpp:106] Iteration 11454, lr = 0.0035
I0525 09:11:42.265952 19426 solver.cpp:237] Iteration 11620, loss = 1.07354
I0525 09:11:42.265988 19426 solver.cpp:253]     Train net output #0: loss = 1.07354 (* 1 = 1.07354 loss)
I0525 09:11:42.266005 19426 sgd_solver.cpp:106] Iteration 11620, lr = 0.0035
I0525 09:11:44.445050 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_11662.caffemodel
I0525 09:11:44.520761 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_11662.solverstate
I0525 09:11:51.155974 19426 solver.cpp:237] Iteration 11786, loss = 1.2829
I0525 09:11:51.156133 19426 solver.cpp:253]     Train net output #0: loss = 1.2829 (* 1 = 1.2829 loss)
I0525 09:11:51.156147 19426 sgd_solver.cpp:106] Iteration 11786, lr = 0.0035
I0525 09:11:59.979591 19426 solver.cpp:237] Iteration 11952, loss = 1.49223
I0525 09:11:59.979637 19426 solver.cpp:253]     Train net output #0: loss = 1.49223 (* 1 = 1.49223 loss)
I0525 09:11:59.979655 19426 sgd_solver.cpp:106] Iteration 11952, lr = 0.0035
I0525 09:12:08.803526 19426 solver.cpp:237] Iteration 12118, loss = 1.00324
I0525 09:12:08.803561 19426 solver.cpp:253]     Train net output #0: loss = 1.00324 (* 1 = 1.00324 loss)
I0525 09:12:08.803575 19426 sgd_solver.cpp:106] Iteration 12118, lr = 0.0035
I0525 09:12:39.771522 19426 solver.cpp:237] Iteration 12284, loss = 1.48237
I0525 09:12:39.771684 19426 solver.cpp:253]     Train net output #0: loss = 1.48237 (* 1 = 1.48237 loss)
I0525 09:12:39.771700 19426 sgd_solver.cpp:106] Iteration 12284, lr = 0.0035
I0525 09:12:48.587945 19426 solver.cpp:237] Iteration 12450, loss = 1.29139
I0525 09:12:48.587987 19426 solver.cpp:253]     Train net output #0: loss = 1.29139 (* 1 = 1.29139 loss)
I0525 09:12:48.588004 19426 sgd_solver.cpp:106] Iteration 12450, lr = 0.0035
I0525 09:12:57.414264 19426 solver.cpp:237] Iteration 12616, loss = 1.2721
I0525 09:12:57.414300 19426 solver.cpp:253]     Train net output #0: loss = 1.2721 (* 1 = 1.2721 loss)
I0525 09:12:57.414316 19426 sgd_solver.cpp:106] Iteration 12616, lr = 0.0035
I0525 09:13:06.227251 19426 solver.cpp:237] Iteration 12782, loss = 1.40856
I0525 09:13:06.227286 19426 solver.cpp:253]     Train net output #0: loss = 1.40856 (* 1 = 1.40856 loss)
I0525 09:13:06.227303 19426 sgd_solver.cpp:106] Iteration 12782, lr = 0.0035
I0525 09:13:15.047973 19426 solver.cpp:237] Iteration 12948, loss = 1.30033
I0525 09:13:15.048131 19426 solver.cpp:253]     Train net output #0: loss = 1.30033 (* 1 = 1.30033 loss)
I0525 09:13:15.048146 19426 sgd_solver.cpp:106] Iteration 12948, lr = 0.0035
I0525 09:13:23.870842 19426 solver.cpp:237] Iteration 13114, loss = 1.26721
I0525 09:13:23.870877 19426 solver.cpp:253]     Train net output #0: loss = 1.26721 (* 1 = 1.26721 loss)
I0525 09:13:23.870889 19426 sgd_solver.cpp:106] Iteration 13114, lr = 0.0035
I0525 09:13:32.695068 19426 solver.cpp:237] Iteration 13280, loss = 1.0963
I0525 09:13:32.695104 19426 solver.cpp:253]     Train net output #0: loss = 1.0963 (* 1 = 1.0963 loss)
I0525 09:13:32.695117 19426 sgd_solver.cpp:106] Iteration 13280, lr = 0.0035
I0525 09:13:35.198057 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_13328.caffemodel
I0525 09:13:35.272692 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_13328.solverstate
I0525 09:13:35.474395 19426 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 09:14:43.563801 19426 solver.cpp:409]     Test net output #0: accuracy = 0.856878
I0525 09:14:43.563967 19426 solver.cpp:409]     Test net output #1: loss = 0.47091 (* 1 = 0.47091 loss)
I0525 09:15:11.842638 19426 solver.cpp:237] Iteration 13446, loss = 1.54608
I0525 09:15:11.842689 19426 solver.cpp:253]     Train net output #0: loss = 1.54608 (* 1 = 1.54608 loss)
I0525 09:15:11.842705 19426 sgd_solver.cpp:106] Iteration 13446, lr = 0.0035
I0525 09:15:20.687016 19426 solver.cpp:237] Iteration 13612, loss = 1.20586
I0525 09:15:20.687180 19426 solver.cpp:253]     Train net output #0: loss = 1.20586 (* 1 = 1.20586 loss)
I0525 09:15:20.687193 19426 sgd_solver.cpp:106] Iteration 13612, lr = 0.0035
I0525 09:15:29.523460 19426 solver.cpp:237] Iteration 13778, loss = 1.1911
I0525 09:15:29.523496 19426 solver.cpp:253]     Train net output #0: loss = 1.1911 (* 1 = 1.1911 loss)
I0525 09:15:29.523512 19426 sgd_solver.cpp:106] Iteration 13778, lr = 0.0035
I0525 09:15:38.363013 19426 solver.cpp:237] Iteration 13944, loss = 1.12643
I0525 09:15:38.363049 19426 solver.cpp:253]     Train net output #0: loss = 1.12643 (* 1 = 1.12643 loss)
I0525 09:15:38.363065 19426 sgd_solver.cpp:106] Iteration 13944, lr = 0.0035
I0525 09:15:47.202234 19426 solver.cpp:237] Iteration 14110, loss = 1.40539
I0525 09:15:47.202277 19426 solver.cpp:253]     Train net output #0: loss = 1.40539 (* 1 = 1.40539 loss)
I0525 09:15:47.202293 19426 sgd_solver.cpp:106] Iteration 14110, lr = 0.0035
I0525 09:15:56.035382 19426 solver.cpp:237] Iteration 14276, loss = 1.10701
I0525 09:15:56.035524 19426 solver.cpp:253]     Train net output #0: loss = 1.10701 (* 1 = 1.10701 loss)
I0525 09:15:56.035538 19426 sgd_solver.cpp:106] Iteration 14276, lr = 0.0035
I0525 09:16:04.875247 19426 solver.cpp:237] Iteration 14442, loss = 1.31372
I0525 09:16:04.875286 19426 solver.cpp:253]     Train net output #0: loss = 1.31372 (* 1 = 1.31372 loss)
I0525 09:16:04.875308 19426 sgd_solver.cpp:106] Iteration 14442, lr = 0.0035
I0525 09:16:35.894155 19426 solver.cpp:237] Iteration 14608, loss = 1.41106
I0525 09:16:35.894322 19426 solver.cpp:253]     Train net output #0: loss = 1.41106 (* 1 = 1.41106 loss)
I0525 09:16:35.894338 19426 sgd_solver.cpp:106] Iteration 14608, lr = 0.0035
I0525 09:16:44.731271 19426 solver.cpp:237] Iteration 14774, loss = 1.26419
I0525 09:16:44.731307 19426 solver.cpp:253]     Train net output #0: loss = 1.26419 (* 1 = 1.26419 loss)
I0525 09:16:44.731323 19426 sgd_solver.cpp:106] Iteration 14774, lr = 0.0035
I0525 09:16:53.581076 19426 solver.cpp:237] Iteration 14940, loss = 1.20098
I0525 09:16:53.581121 19426 solver.cpp:253]     Train net output #0: loss = 1.20098 (* 1 = 1.20098 loss)
I0525 09:16:53.581135 19426 sgd_solver.cpp:106] Iteration 14940, lr = 0.0035
I0525 09:16:56.402309 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_14994.caffemodel
I0525 09:16:56.479338 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_14994.solverstate
I0525 09:17:02.482633 19426 solver.cpp:237] Iteration 15106, loss = 1.55549
I0525 09:17:02.482681 19426 solver.cpp:253]     Train net output #0: loss = 1.55549 (* 1 = 1.55549 loss)
I0525 09:17:02.482695 19426 sgd_solver.cpp:106] Iteration 15106, lr = 0.0035
I0525 09:17:11.322415 19426 solver.cpp:237] Iteration 15272, loss = 1.3778
I0525 09:17:11.322564 19426 solver.cpp:253]     Train net output #0: loss = 1.3778 (* 1 = 1.3778 loss)
I0525 09:17:11.322577 19426 sgd_solver.cpp:106] Iteration 15272, lr = 0.0035
I0525 09:17:20.155656 19426 solver.cpp:237] Iteration 15438, loss = 1.36353
I0525 09:17:20.155697 19426 solver.cpp:253]     Train net output #0: loss = 1.36353 (* 1 = 1.36353 loss)
I0525 09:17:20.155720 19426 sgd_solver.cpp:106] Iteration 15438, lr = 0.0035
I0525 09:17:51.153437 19426 solver.cpp:237] Iteration 15604, loss = 1.39299
I0525 09:17:51.153615 19426 solver.cpp:253]     Train net output #0: loss = 1.39299 (* 1 = 1.39299 loss)
I0525 09:17:51.153631 19426 sgd_solver.cpp:106] Iteration 15604, lr = 0.0035
I0525 09:17:59.991881 19426 solver.cpp:237] Iteration 15770, loss = 1.15681
I0525 09:17:59.991916 19426 solver.cpp:253]     Train net output #0: loss = 1.15681 (* 1 = 1.15681 loss)
I0525 09:17:59.991933 19426 sgd_solver.cpp:106] Iteration 15770, lr = 0.0035
I0525 09:18:08.825605 19426 solver.cpp:237] Iteration 15936, loss = 1.26997
I0525 09:18:08.825654 19426 solver.cpp:253]     Train net output #0: loss = 1.26997 (* 1 = 1.26997 loss)
I0525 09:18:08.825667 19426 sgd_solver.cpp:106] Iteration 15936, lr = 0.0035
I0525 09:18:17.656204 19426 solver.cpp:237] Iteration 16102, loss = 1.15652
I0525 09:18:17.656241 19426 solver.cpp:253]     Train net output #0: loss = 1.15652 (* 1 = 1.15652 loss)
I0525 09:18:17.656256 19426 sgd_solver.cpp:106] Iteration 16102, lr = 0.0035
I0525 09:18:26.491099 19426 solver.cpp:237] Iteration 16268, loss = 1.34925
I0525 09:18:26.491245 19426 solver.cpp:253]     Train net output #0: loss = 1.34925 (* 1 = 1.34925 loss)
I0525 09:18:26.491260 19426 sgd_solver.cpp:106] Iteration 16268, lr = 0.0035
I0525 09:18:35.340920 19426 solver.cpp:237] Iteration 16434, loss = 1.30613
I0525 09:18:35.340963 19426 solver.cpp:253]     Train net output #0: loss = 1.30613 (* 1 = 1.30613 loss)
I0525 09:18:35.340981 19426 sgd_solver.cpp:106] Iteration 16434, lr = 0.0035
I0525 09:18:44.173424 19426 solver.cpp:237] Iteration 16600, loss = 1.40296
I0525 09:18:44.173458 19426 solver.cpp:253]     Train net output #0: loss = 1.40296 (* 1 = 1.40296 loss)
I0525 09:18:44.173475 19426 sgd_solver.cpp:106] Iteration 16600, lr = 0.0035
I0525 09:18:47.311583 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_16660.caffemodel
I0525 09:18:47.387579 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_16660.solverstate
I0525 09:18:47.645937 19426 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 09:19:34.817929 19426 solver.cpp:409]     Test net output #0: accuracy = 0.860987
I0525 09:19:34.818092 19426 solver.cpp:409]     Test net output #1: loss = 0.440105 (* 1 = 0.440105 loss)
I0525 09:20:01.087244 19426 solver.cpp:237] Iteration 16766, loss = 1.1722
I0525 09:20:01.087296 19426 solver.cpp:253]     Train net output #0: loss = 1.1722 (* 1 = 1.1722 loss)
I0525 09:20:01.087311 19426 sgd_solver.cpp:106] Iteration 16766, lr = 0.0035
I0525 09:20:09.910249 19426 solver.cpp:237] Iteration 16932, loss = 1.19026
I0525 09:20:09.910400 19426 solver.cpp:253]     Train net output #0: loss = 1.19026 (* 1 = 1.19026 loss)
I0525 09:20:09.910416 19426 sgd_solver.cpp:106] Iteration 16932, lr = 0.0035
I0525 09:20:18.734200 19426 solver.cpp:237] Iteration 17098, loss = 1.13293
I0525 09:20:18.734238 19426 solver.cpp:253]     Train net output #0: loss = 1.13293 (* 1 = 1.13293 loss)
I0525 09:20:18.734259 19426 sgd_solver.cpp:106] Iteration 17098, lr = 0.0035
I0525 09:20:27.555927 19426 solver.cpp:237] Iteration 17264, loss = 1.41662
I0525 09:20:27.555961 19426 solver.cpp:253]     Train net output #0: loss = 1.41662 (* 1 = 1.41662 loss)
I0525 09:20:27.555979 19426 sgd_solver.cpp:106] Iteration 17264, lr = 0.0035
I0525 09:20:36.368921 19426 solver.cpp:237] Iteration 17430, loss = 1.41336
I0525 09:20:36.368955 19426 solver.cpp:253]     Train net output #0: loss = 1.41336 (* 1 = 1.41336 loss)
I0525 09:20:36.368971 19426 sgd_solver.cpp:106] Iteration 17430, lr = 0.0035
I0525 09:20:45.199589 19426 solver.cpp:237] Iteration 17596, loss = 1.31904
I0525 09:20:45.199759 19426 solver.cpp:253]     Train net output #0: loss = 1.31904 (* 1 = 1.31904 loss)
I0525 09:20:45.199772 19426 sgd_solver.cpp:106] Iteration 17596, lr = 0.0035
I0525 09:20:54.025605 19426 solver.cpp:237] Iteration 17762, loss = 1.24463
I0525 09:20:54.025640 19426 solver.cpp:253]     Train net output #0: loss = 1.24463 (* 1 = 1.24463 loss)
I0525 09:20:54.025657 19426 sgd_solver.cpp:106] Iteration 17762, lr = 0.0035
I0525 09:21:23.733950 19426 solver.cpp:237] Iteration 17928, loss = 1.36172
I0525 09:21:23.734119 19426 solver.cpp:253]     Train net output #0: loss = 1.36172 (* 1 = 1.36172 loss)
I0525 09:21:23.734135 19426 sgd_solver.cpp:106] Iteration 17928, lr = 0.0035
I0525 09:21:32.551580 19426 solver.cpp:237] Iteration 18094, loss = 1.1963
I0525 09:21:32.551621 19426 solver.cpp:253]     Train net output #0: loss = 1.1963 (* 1 = 1.1963 loss)
I0525 09:21:32.551642 19426 sgd_solver.cpp:106] Iteration 18094, lr = 0.0035
I0525 09:21:41.379993 19426 solver.cpp:237] Iteration 18260, loss = 1.48426
I0525 09:21:41.380029 19426 solver.cpp:253]     Train net output #0: loss = 1.48426 (* 1 = 1.48426 loss)
I0525 09:21:41.380045 19426 sgd_solver.cpp:106] Iteration 18260, lr = 0.0035
I0525 09:21:44.836954 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_18326.caffemodel
I0525 09:21:44.911568 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_18326.solverstate
I0525 09:21:50.264801 19426 solver.cpp:237] Iteration 18426, loss = 1.23931
I0525 09:21:50.264843 19426 solver.cpp:253]     Train net output #0: loss = 1.23931 (* 1 = 1.23931 loss)
I0525 09:21:50.264863 19426 sgd_solver.cpp:106] Iteration 18426, lr = 0.0035
I0525 09:21:59.096230 19426 solver.cpp:237] Iteration 18592, loss = 1.29342
I0525 09:21:59.096402 19426 solver.cpp:253]     Train net output #0: loss = 1.29342 (* 1 = 1.29342 loss)
I0525 09:21:59.096417 19426 sgd_solver.cpp:106] Iteration 18592, lr = 0.0035
I0525 09:22:07.929435 19426 solver.cpp:237] Iteration 18758, loss = 1.15671
I0525 09:22:07.929471 19426 solver.cpp:253]     Train net output #0: loss = 1.15671 (* 1 = 1.15671 loss)
I0525 09:22:07.929487 19426 sgd_solver.cpp:106] Iteration 18758, lr = 0.0035
I0525 09:22:37.622179 19426 solver.cpp:237] Iteration 18924, loss = 1.04406
I0525 09:22:37.622349 19426 solver.cpp:253]     Train net output #0: loss = 1.04406 (* 1 = 1.04406 loss)
I0525 09:22:37.622365 19426 sgd_solver.cpp:106] Iteration 18924, lr = 0.0035
I0525 09:22:46.454723 19426 solver.cpp:237] Iteration 19090, loss = 1.57585
I0525 09:22:46.454769 19426 solver.cpp:253]     Train net output #0: loss = 1.57585 (* 1 = 1.57585 loss)
I0525 09:22:46.454785 19426 sgd_solver.cpp:106] Iteration 19090, lr = 0.0035
I0525 09:22:55.286660 19426 solver.cpp:237] Iteration 19256, loss = 1.3726
I0525 09:22:55.286695 19426 solver.cpp:253]     Train net output #0: loss = 1.3726 (* 1 = 1.3726 loss)
I0525 09:22:55.286711 19426 sgd_solver.cpp:106] Iteration 19256, lr = 0.0035
I0525 09:23:04.124158 19426 solver.cpp:237] Iteration 19422, loss = 1.16248
I0525 09:23:04.124193 19426 solver.cpp:253]     Train net output #0: loss = 1.16248 (* 1 = 1.16248 loss)
I0525 09:23:04.124212 19426 sgd_solver.cpp:106] Iteration 19422, lr = 0.0035
I0525 09:23:12.943989 19426 solver.cpp:237] Iteration 19588, loss = 1.06857
I0525 09:23:12.944146 19426 solver.cpp:253]     Train net output #0: loss = 1.06857 (* 1 = 1.06857 loss)
I0525 09:23:12.944160 19426 sgd_solver.cpp:106] Iteration 19588, lr = 0.0035
I0525 09:23:21.766487 19426 solver.cpp:237] Iteration 19754, loss = 1.15155
I0525 09:23:21.766522 19426 solver.cpp:253]     Train net output #0: loss = 1.15155 (* 1 = 1.15155 loss)
I0525 09:23:21.766538 19426 sgd_solver.cpp:106] Iteration 19754, lr = 0.0035
I0525 09:23:30.594249 19426 solver.cpp:237] Iteration 19920, loss = 1.23265
I0525 09:23:30.594283 19426 solver.cpp:253]     Train net output #0: loss = 1.23265 (* 1 = 1.23265 loss)
I0525 09:23:30.594300 19426 sgd_solver.cpp:106] Iteration 19920, lr = 0.0035
I0525 09:23:34.370606 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_19992.caffemodel
I0525 09:23:34.445147 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_19992.solverstate
I0525 09:23:34.754101 19426 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 09:24:42.748425 19426 solver.cpp:409]     Test net output #0: accuracy = 0.868009
I0525 09:24:42.748601 19426 solver.cpp:409]     Test net output #1: loss = 0.40522 (* 1 = 0.40522 loss)
I0525 09:25:08.249971 19426 solver.cpp:237] Iteration 20086, loss = 1.09886
I0525 09:25:08.250021 19426 solver.cpp:253]     Train net output #0: loss = 1.09886 (* 1 = 1.09886 loss)
I0525 09:25:08.250037 19426 sgd_solver.cpp:106] Iteration 20086, lr = 0.0035
I0525 09:25:17.078495 19426 solver.cpp:237] Iteration 20252, loss = 1.16059
I0525 09:25:17.078658 19426 solver.cpp:253]     Train net output #0: loss = 1.16059 (* 1 = 1.16059 loss)
I0525 09:25:17.078672 19426 sgd_solver.cpp:106] Iteration 20252, lr = 0.0035
I0525 09:25:25.909389 19426 solver.cpp:237] Iteration 20418, loss = 1.24643
I0525 09:25:25.909425 19426 solver.cpp:253]     Train net output #0: loss = 1.24643 (* 1 = 1.24643 loss)
I0525 09:25:25.909440 19426 sgd_solver.cpp:106] Iteration 20418, lr = 0.0035
I0525 09:25:34.739377 19426 solver.cpp:237] Iteration 20584, loss = 1.29883
I0525 09:25:34.739413 19426 solver.cpp:253]     Train net output #0: loss = 1.29883 (* 1 = 1.29883 loss)
I0525 09:25:34.739424 19426 sgd_solver.cpp:106] Iteration 20584, lr = 0.0035
I0525 09:25:43.571986 19426 solver.cpp:237] Iteration 20750, loss = 1.10831
I0525 09:25:43.572027 19426 solver.cpp:253]     Train net output #0: loss = 1.10831 (* 1 = 1.10831 loss)
I0525 09:25:43.572046 19426 sgd_solver.cpp:106] Iteration 20750, lr = 0.0035
I0525 09:25:52.396562 19426 solver.cpp:237] Iteration 20916, loss = 1.14897
I0525 09:25:52.396708 19426 solver.cpp:253]     Train net output #0: loss = 1.14897 (* 1 = 1.14897 loss)
I0525 09:25:52.396723 19426 sgd_solver.cpp:106] Iteration 20916, lr = 0.0035
I0525 09:26:01.230574 19426 solver.cpp:237] Iteration 21082, loss = 1.0338
I0525 09:26:01.230608 19426 solver.cpp:253]     Train net output #0: loss = 1.0338 (* 1 = 1.0338 loss)
I0525 09:26:01.230625 19426 sgd_solver.cpp:106] Iteration 21082, lr = 0.0035
I0525 09:26:30.920794 19426 solver.cpp:237] Iteration 21248, loss = 1.17833
I0525 09:26:30.920963 19426 solver.cpp:253]     Train net output #0: loss = 1.17833 (* 1 = 1.17833 loss)
I0525 09:26:30.920977 19426 sgd_solver.cpp:106] Iteration 21248, lr = 0.0035
I0525 09:26:39.752220 19426 solver.cpp:237] Iteration 21414, loss = 1.17755
I0525 09:26:39.752254 19426 solver.cpp:253]     Train net output #0: loss = 1.17755 (* 1 = 1.17755 loss)
I0525 09:26:39.752272 19426 sgd_solver.cpp:106] Iteration 21414, lr = 0.0035
I0525 09:26:48.589431 19426 solver.cpp:237] Iteration 21580, loss = 1.1071
I0525 09:26:48.589465 19426 solver.cpp:253]     Train net output #0: loss = 1.1071 (* 1 = 1.1071 loss)
I0525 09:26:48.589483 19426 sgd_solver.cpp:106] Iteration 21580, lr = 0.0035
I0525 09:26:52.684190 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_21658.caffemodel
I0525 09:26:52.759368 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_21658.solverstate
I0525 09:26:57.490445 19426 solver.cpp:237] Iteration 21746, loss = 1.26517
I0525 09:26:57.490494 19426 solver.cpp:253]     Train net output #0: loss = 1.26517 (* 1 = 1.26517 loss)
I0525 09:26:57.490514 19426 sgd_solver.cpp:106] Iteration 21746, lr = 0.0035
I0525 09:27:06.326752 19426 solver.cpp:237] Iteration 21912, loss = 1.09796
I0525 09:27:06.326916 19426 solver.cpp:253]     Train net output #0: loss = 1.09796 (* 1 = 1.09796 loss)
I0525 09:27:06.326930 19426 sgd_solver.cpp:106] Iteration 21912, lr = 0.0035
I0525 09:27:15.159893 19426 solver.cpp:237] Iteration 22078, loss = 1.34055
I0525 09:27:15.159927 19426 solver.cpp:253]     Train net output #0: loss = 1.34055 (* 1 = 1.34055 loss)
I0525 09:27:15.159946 19426 sgd_solver.cpp:106] Iteration 22078, lr = 0.0035
I0525 09:27:44.834866 19426 solver.cpp:237] Iteration 22244, loss = 1.21262
I0525 09:27:44.835039 19426 solver.cpp:253]     Train net output #0: loss = 1.21262 (* 1 = 1.21262 loss)
I0525 09:27:44.835053 19426 sgd_solver.cpp:106] Iteration 22244, lr = 0.0035
I0525 09:27:53.662389 19426 solver.cpp:237] Iteration 22410, loss = 1.17413
I0525 09:27:53.662425 19426 solver.cpp:253]     Train net output #0: loss = 1.17413 (* 1 = 1.17413 loss)
I0525 09:27:53.662442 19426 sgd_solver.cpp:106] Iteration 22410, lr = 0.0035
I0525 09:28:02.490653 19426 solver.cpp:237] Iteration 22576, loss = 1.19864
I0525 09:28:02.490689 19426 solver.cpp:253]     Train net output #0: loss = 1.19864 (* 1 = 1.19864 loss)
I0525 09:28:02.490705 19426 sgd_solver.cpp:106] Iteration 22576, lr = 0.0035
I0525 09:28:11.328243 19426 solver.cpp:237] Iteration 22742, loss = 0.988433
I0525 09:28:11.328289 19426 solver.cpp:253]     Train net output #0: loss = 0.988433 (* 1 = 0.988433 loss)
I0525 09:28:11.328305 19426 sgd_solver.cpp:106] Iteration 22742, lr = 0.0035
I0525 09:28:20.165066 19426 solver.cpp:237] Iteration 22908, loss = 1.06503
I0525 09:28:20.165211 19426 solver.cpp:253]     Train net output #0: loss = 1.06503 (* 1 = 1.06503 loss)
I0525 09:28:20.165227 19426 sgd_solver.cpp:106] Iteration 22908, lr = 0.0035
I0525 09:28:28.994174 19426 solver.cpp:237] Iteration 23074, loss = 1.10844
I0525 09:28:28.994209 19426 solver.cpp:253]     Train net output #0: loss = 1.10844 (* 1 = 1.10844 loss)
I0525 09:28:28.994225 19426 sgd_solver.cpp:106] Iteration 23074, lr = 0.0035
I0525 09:28:37.820036 19426 solver.cpp:237] Iteration 23240, loss = 0.976069
I0525 09:28:37.820078 19426 solver.cpp:253]     Train net output #0: loss = 0.976069 (* 1 = 0.976069 loss)
I0525 09:28:37.820099 19426 sgd_solver.cpp:106] Iteration 23240, lr = 0.0035
I0525 09:28:42.237378 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_23324.caffemodel
I0525 09:28:42.321455 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_23324.solverstate
I0525 09:28:42.683655 19426 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 09:29:29.524258 19426 solver.cpp:409]     Test net output #0: accuracy = 0.871865
I0525 09:29:29.524435 19426 solver.cpp:409]     Test net output #1: loss = 0.42403 (* 1 = 0.42403 loss)
I0525 09:29:54.424091 19426 solver.cpp:237] Iteration 23406, loss = 1.20868
I0525 09:29:54.424142 19426 solver.cpp:253]     Train net output #0: loss = 1.20868 (* 1 = 1.20868 loss)
I0525 09:29:54.424157 19426 sgd_solver.cpp:106] Iteration 23406, lr = 0.0035
I0525 09:30:03.242450 19426 solver.cpp:237] Iteration 23572, loss = 1.23278
I0525 09:30:03.242612 19426 solver.cpp:253]     Train net output #0: loss = 1.23278 (* 1 = 1.23278 loss)
I0525 09:30:03.242626 19426 sgd_solver.cpp:106] Iteration 23572, lr = 0.0035
I0525 09:30:12.063364 19426 solver.cpp:237] Iteration 23738, loss = 1.3115
I0525 09:30:12.063393 19426 solver.cpp:253]     Train net output #0: loss = 1.3115 (* 1 = 1.3115 loss)
I0525 09:30:12.063415 19426 sgd_solver.cpp:106] Iteration 23738, lr = 0.0035
I0525 09:30:20.895263 19426 solver.cpp:237] Iteration 23904, loss = 1.10514
I0525 09:30:20.895306 19426 solver.cpp:253]     Train net output #0: loss = 1.10514 (* 1 = 1.10514 loss)
I0525 09:30:20.895326 19426 sgd_solver.cpp:106] Iteration 23904, lr = 0.0035
I0525 09:30:29.723716 19426 solver.cpp:237] Iteration 24070, loss = 1.41267
I0525 09:30:29.723752 19426 solver.cpp:253]     Train net output #0: loss = 1.41267 (* 1 = 1.41267 loss)
I0525 09:30:29.723765 19426 sgd_solver.cpp:106] Iteration 24070, lr = 0.0035
I0525 09:30:38.550467 19426 solver.cpp:237] Iteration 24236, loss = 1.38486
I0525 09:30:38.550634 19426 solver.cpp:253]     Train net output #0: loss = 1.38486 (* 1 = 1.38486 loss)
I0525 09:30:38.550649 19426 sgd_solver.cpp:106] Iteration 24236, lr = 0.0035
I0525 09:30:47.376543 19426 solver.cpp:237] Iteration 24402, loss = 1.11192
I0525 09:30:47.376577 19426 solver.cpp:253]     Train net output #0: loss = 1.11192 (* 1 = 1.11192 loss)
I0525 09:30:47.376596 19426 sgd_solver.cpp:106] Iteration 24402, lr = 0.0035
I0525 09:31:17.061269 19426 solver.cpp:237] Iteration 24568, loss = 1.087
I0525 09:31:17.061444 19426 solver.cpp:253]     Train net output #0: loss = 1.087 (* 1 = 1.087 loss)
I0525 09:31:17.061460 19426 sgd_solver.cpp:106] Iteration 24568, lr = 0.0035
I0525 09:31:25.875381 19426 solver.cpp:237] Iteration 24734, loss = 1.42411
I0525 09:31:25.875416 19426 solver.cpp:253]     Train net output #0: loss = 1.42411 (* 1 = 1.42411 loss)
I0525 09:31:25.875434 19426 sgd_solver.cpp:106] Iteration 24734, lr = 0.0035
I0525 09:31:34.690999 19426 solver.cpp:237] Iteration 24900, loss = 1.19621
I0525 09:31:34.691050 19426 solver.cpp:253]     Train net output #0: loss = 1.19621 (* 1 = 1.19621 loss)
I0525 09:31:34.691064 19426 sgd_solver.cpp:106] Iteration 24900, lr = 0.0035
I0525 09:31:39.424522 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_24990.caffemodel
I0525 09:31:39.501691 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_24990.solverstate
I0525 09:31:43.578778 19426 solver.cpp:237] Iteration 25066, loss = 1.28974
I0525 09:31:43.578826 19426 solver.cpp:253]     Train net output #0: loss = 1.28974 (* 1 = 1.28974 loss)
I0525 09:31:43.578842 19426 sgd_solver.cpp:106] Iteration 25066, lr = 0.0035
I0525 09:31:52.395627 19426 solver.cpp:237] Iteration 25232, loss = 1.32536
I0525 09:31:52.395781 19426 solver.cpp:253]     Train net output #0: loss = 1.32536 (* 1 = 1.32536 loss)
I0525 09:31:52.395795 19426 sgd_solver.cpp:106] Iteration 25232, lr = 0.0035
I0525 09:32:01.223256 19426 solver.cpp:237] Iteration 25398, loss = 1.00939
I0525 09:32:01.223305 19426 solver.cpp:253]     Train net output #0: loss = 1.00939 (* 1 = 1.00939 loss)
I0525 09:32:01.223320 19426 sgd_solver.cpp:106] Iteration 25398, lr = 0.0035
I0525 09:32:30.922637 19426 solver.cpp:237] Iteration 25564, loss = 1.39386
I0525 09:32:30.922806 19426 solver.cpp:253]     Train net output #0: loss = 1.39386 (* 1 = 1.39386 loss)
I0525 09:32:30.922819 19426 sgd_solver.cpp:106] Iteration 25564, lr = 0.0035
I0525 09:32:39.741520 19426 solver.cpp:237] Iteration 25730, loss = 1.16765
I0525 09:32:39.741555 19426 solver.cpp:253]     Train net output #0: loss = 1.16765 (* 1 = 1.16765 loss)
I0525 09:32:39.741575 19426 sgd_solver.cpp:106] Iteration 25730, lr = 0.0035
I0525 09:32:48.558593 19426 solver.cpp:237] Iteration 25896, loss = 1.2118
I0525 09:32:48.558634 19426 solver.cpp:253]     Train net output #0: loss = 1.2118 (* 1 = 1.2118 loss)
I0525 09:32:48.558655 19426 sgd_solver.cpp:106] Iteration 25896, lr = 0.0035
I0525 09:32:57.377346 19426 solver.cpp:237] Iteration 26062, loss = 1.28983
I0525 09:32:57.377382 19426 solver.cpp:253]     Train net output #0: loss = 1.28983 (* 1 = 1.28983 loss)
I0525 09:32:57.377398 19426 sgd_solver.cpp:106] Iteration 26062, lr = 0.0035
I0525 09:33:06.200377 19426 solver.cpp:237] Iteration 26228, loss = 1.18589
I0525 09:33:06.200538 19426 solver.cpp:253]     Train net output #0: loss = 1.18589 (* 1 = 1.18589 loss)
I0525 09:33:06.200552 19426 sgd_solver.cpp:106] Iteration 26228, lr = 0.0035
I0525 09:33:15.023340 19426 solver.cpp:237] Iteration 26394, loss = 1.12597
I0525 09:33:15.023382 19426 solver.cpp:253]     Train net output #0: loss = 1.12597 (* 1 = 1.12597 loss)
I0525 09:33:15.023402 19426 sgd_solver.cpp:106] Iteration 26394, lr = 0.0035
I0525 09:33:23.848264 19426 solver.cpp:237] Iteration 26560, loss = 1.2457
I0525 09:33:23.848299 19426 solver.cpp:253]     Train net output #0: loss = 1.2457 (* 1 = 1.2457 loss)
I0525 09:33:23.848315 19426 sgd_solver.cpp:106] Iteration 26560, lr = 0.0035
I0525 09:33:28.895298 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_26656.caffemodel
I0525 09:33:28.970407 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_26656.solverstate
I0525 09:33:29.386317 19426 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 09:34:37.422704 19426 solver.cpp:409]     Test net output #0: accuracy = 0.87442
I0525 09:34:37.422888 19426 solver.cpp:409]     Test net output #1: loss = 0.400077 (* 1 = 0.400077 loss)
I0525 09:35:01.592325 19426 solver.cpp:237] Iteration 26726, loss = 1.01345
I0525 09:35:01.592376 19426 solver.cpp:253]     Train net output #0: loss = 1.01345 (* 1 = 1.01345 loss)
I0525 09:35:01.592392 19426 sgd_solver.cpp:106] Iteration 26726, lr = 0.0035
I0525 09:35:10.419159 19426 solver.cpp:237] Iteration 26892, loss = 1.03481
I0525 09:35:10.419318 19426 solver.cpp:253]     Train net output #0: loss = 1.03481 (* 1 = 1.03481 loss)
I0525 09:35:10.419332 19426 sgd_solver.cpp:106] Iteration 26892, lr = 0.0035
I0525 09:35:19.250828 19426 solver.cpp:237] Iteration 27058, loss = 1.10657
I0525 09:35:19.250867 19426 solver.cpp:253]     Train net output #0: loss = 1.10657 (* 1 = 1.10657 loss)
I0525 09:35:19.250883 19426 sgd_solver.cpp:106] Iteration 27058, lr = 0.0035
I0525 09:35:28.080523 19426 solver.cpp:237] Iteration 27224, loss = 1.12574
I0525 09:35:28.080559 19426 solver.cpp:253]     Train net output #0: loss = 1.12574 (* 1 = 1.12574 loss)
I0525 09:35:28.080575 19426 sgd_solver.cpp:106] Iteration 27224, lr = 0.0035
I0525 09:35:36.905593 19426 solver.cpp:237] Iteration 27390, loss = 1.0294
I0525 09:35:36.905629 19426 solver.cpp:253]     Train net output #0: loss = 1.0294 (* 1 = 1.0294 loss)
I0525 09:35:36.905644 19426 sgd_solver.cpp:106] Iteration 27390, lr = 0.0035
I0525 09:35:45.737457 19426 solver.cpp:237] Iteration 27556, loss = 1.34601
I0525 09:35:45.737617 19426 solver.cpp:253]     Train net output #0: loss = 1.34601 (* 1 = 1.34601 loss)
I0525 09:35:45.737630 19426 sgd_solver.cpp:106] Iteration 27556, lr = 0.0035
I0525 09:35:54.565222 19426 solver.cpp:237] Iteration 27722, loss = 1.11234
I0525 09:35:54.565258 19426 solver.cpp:253]     Train net output #0: loss = 1.11234 (* 1 = 1.11234 loss)
I0525 09:35:54.565275 19426 sgd_solver.cpp:106] Iteration 27722, lr = 0.0035
I0525 09:36:24.273550 19426 solver.cpp:237] Iteration 27888, loss = 1.09726
I0525 09:36:24.273718 19426 solver.cpp:253]     Train net output #0: loss = 1.09726 (* 1 = 1.09726 loss)
I0525 09:36:24.273735 19426 sgd_solver.cpp:106] Iteration 27888, lr = 0.0035
I0525 09:36:33.100800 19426 solver.cpp:237] Iteration 28054, loss = 1.27029
I0525 09:36:33.100847 19426 solver.cpp:253]     Train net output #0: loss = 1.27029 (* 1 = 1.27029 loss)
I0525 09:36:33.100862 19426 sgd_solver.cpp:106] Iteration 28054, lr = 0.0035
I0525 09:36:41.932431 19426 solver.cpp:237] Iteration 28220, loss = 1.14628
I0525 09:36:41.932467 19426 solver.cpp:253]     Train net output #0: loss = 1.14628 (* 1 = 1.14628 loss)
I0525 09:36:41.932482 19426 sgd_solver.cpp:106] Iteration 28220, lr = 0.0035
I0525 09:36:47.311267 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_28322.caffemodel
I0525 09:36:47.386029 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_28322.solverstate
I0525 09:36:50.833540 19426 solver.cpp:237] Iteration 28386, loss = 1.13445
I0525 09:36:50.833585 19426 solver.cpp:253]     Train net output #0: loss = 1.13445 (* 1 = 1.13445 loss)
I0525 09:36:50.833601 19426 sgd_solver.cpp:106] Iteration 28386, lr = 0.0035
I0525 09:36:59.666882 19426 solver.cpp:237] Iteration 28552, loss = 1.01925
I0525 09:36:59.667062 19426 solver.cpp:253]     Train net output #0: loss = 1.01925 (* 1 = 1.01925 loss)
I0525 09:36:59.667076 19426 sgd_solver.cpp:106] Iteration 28552, lr = 0.0035
I0525 09:37:08.496511 19426 solver.cpp:237] Iteration 28718, loss = 1.15749
I0525 09:37:08.496546 19426 solver.cpp:253]     Train net output #0: loss = 1.15749 (* 1 = 1.15749 loss)
I0525 09:37:08.496563 19426 sgd_solver.cpp:106] Iteration 28718, lr = 0.0035
I0525 09:37:17.330551 19426 solver.cpp:237] Iteration 28884, loss = 1.23762
I0525 09:37:17.330586 19426 solver.cpp:253]     Train net output #0: loss = 1.23762 (* 1 = 1.23762 loss)
I0525 09:37:17.330602 19426 sgd_solver.cpp:106] Iteration 28884, lr = 0.0035
I0525 09:37:47.027226 19426 solver.cpp:237] Iteration 29050, loss = 1.15051
I0525 09:37:47.027407 19426 solver.cpp:253]     Train net output #0: loss = 1.15051 (* 1 = 1.15051 loss)
I0525 09:37:47.027422 19426 sgd_solver.cpp:106] Iteration 29050, lr = 0.0035
I0525 09:37:55.851583 19426 solver.cpp:237] Iteration 29216, loss = 1.19667
I0525 09:37:55.851619 19426 solver.cpp:253]     Train net output #0: loss = 1.19667 (* 1 = 1.19667 loss)
I0525 09:37:55.851632 19426 sgd_solver.cpp:106] Iteration 29216, lr = 0.0035
I0525 09:38:04.676743 19426 solver.cpp:237] Iteration 29382, loss = 1.01442
I0525 09:38:04.676777 19426 solver.cpp:253]     Train net output #0: loss = 1.01442 (* 1 = 1.01442 loss)
I0525 09:38:04.676794 19426 sgd_solver.cpp:106] Iteration 29382, lr = 0.0035
I0525 09:38:13.506769 19426 solver.cpp:237] Iteration 29548, loss = 1.27724
I0525 09:38:13.506819 19426 solver.cpp:253]     Train net output #0: loss = 1.27724 (* 1 = 1.27724 loss)
I0525 09:38:13.506832 19426 sgd_solver.cpp:106] Iteration 29548, lr = 0.0035
I0525 09:38:22.336710 19426 solver.cpp:237] Iteration 29714, loss = 1.2107
I0525 09:38:22.336863 19426 solver.cpp:253]     Train net output #0: loss = 1.2107 (* 1 = 1.2107 loss)
I0525 09:38:22.336876 19426 sgd_solver.cpp:106] Iteration 29714, lr = 0.0035
I0525 09:38:31.163389 19426 solver.cpp:237] Iteration 29880, loss = 1.18853
I0525 09:38:31.163424 19426 solver.cpp:253]     Train net output #0: loss = 1.18853 (* 1 = 1.18853 loss)
I0525 09:38:31.163441 19426 sgd_solver.cpp:106] Iteration 29880, lr = 0.0035
I0525 09:38:36.853374 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_29988.caffemodel
I0525 09:38:36.928542 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_29988.solverstate
I0525 09:38:37.397864 19426 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 09:39:24.603013 19426 solver.cpp:409]     Test net output #0: accuracy = 0.879049
I0525 09:39:24.603183 19426 solver.cpp:409]     Test net output #1: loss = 0.387871 (* 1 = 0.387871 loss)
I0525 09:39:48.106748 19426 solver.cpp:237] Iteration 30046, loss = 1.22215
I0525 09:39:48.106798 19426 solver.cpp:253]     Train net output #0: loss = 1.22215 (* 1 = 1.22215 loss)
I0525 09:39:48.106812 19426 sgd_solver.cpp:106] Iteration 30046, lr = 0.0035
I0525 09:39:56.925498 19426 solver.cpp:237] Iteration 30212, loss = 1.27299
I0525 09:39:56.925665 19426 solver.cpp:253]     Train net output #0: loss = 1.27299 (* 1 = 1.27299 loss)
I0525 09:39:56.925679 19426 sgd_solver.cpp:106] Iteration 30212, lr = 0.0035
I0525 09:40:05.743949 19426 solver.cpp:237] Iteration 30378, loss = 1.07867
I0525 09:40:05.743984 19426 solver.cpp:253]     Train net output #0: loss = 1.07867 (* 1 = 1.07867 loss)
I0525 09:40:05.744000 19426 sgd_solver.cpp:106] Iteration 30378, lr = 0.0035
I0525 09:40:14.559913 19426 solver.cpp:237] Iteration 30544, loss = 1.32199
I0525 09:40:14.559957 19426 solver.cpp:253]     Train net output #0: loss = 1.32199 (* 1 = 1.32199 loss)
I0525 09:40:14.559975 19426 sgd_solver.cpp:106] Iteration 30544, lr = 0.0035
I0525 09:40:23.385886 19426 solver.cpp:237] Iteration 30710, loss = 1.19937
I0525 09:40:23.385921 19426 solver.cpp:253]     Train net output #0: loss = 1.19937 (* 1 = 1.19937 loss)
I0525 09:40:23.385937 19426 sgd_solver.cpp:106] Iteration 30710, lr = 0.0035
I0525 09:40:32.204892 19426 solver.cpp:237] Iteration 30876, loss = 1.06246
I0525 09:40:32.205057 19426 solver.cpp:253]     Train net output #0: loss = 1.06246 (* 1 = 1.06246 loss)
I0525 09:40:32.205072 19426 sgd_solver.cpp:106] Iteration 30876, lr = 0.0035
I0525 09:40:41.020931 19426 solver.cpp:237] Iteration 31042, loss = 1.28558
I0525 09:40:41.020979 19426 solver.cpp:253]     Train net output #0: loss = 1.28558 (* 1 = 1.28558 loss)
I0525 09:40:41.020992 19426 sgd_solver.cpp:106] Iteration 31042, lr = 0.0035
I0525 09:41:10.697216 19426 solver.cpp:237] Iteration 31208, loss = 1.13298
I0525 09:41:10.697394 19426 solver.cpp:253]     Train net output #0: loss = 1.13298 (* 1 = 1.13298 loss)
I0525 09:41:10.697408 19426 sgd_solver.cpp:106] Iteration 31208, lr = 0.0035
I0525 09:41:19.503599 19426 solver.cpp:237] Iteration 31374, loss = 1.13355
I0525 09:41:19.503634 19426 solver.cpp:253]     Train net output #0: loss = 1.13355 (* 1 = 1.13355 loss)
I0525 09:41:19.503651 19426 sgd_solver.cpp:106] Iteration 31374, lr = 0.0035
I0525 09:41:28.326179 19426 solver.cpp:237] Iteration 31540, loss = 1.21822
I0525 09:41:28.326215 19426 solver.cpp:253]     Train net output #0: loss = 1.21822 (* 1 = 1.21822 loss)
I0525 09:41:28.326232 19426 sgd_solver.cpp:106] Iteration 31540, lr = 0.0035
I0525 09:41:34.329813 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_31654.caffemodel
I0525 09:41:34.407299 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_31654.solverstate
I0525 09:41:37.210203 19426 solver.cpp:237] Iteration 31706, loss = 1.44494
I0525 09:41:37.210248 19426 solver.cpp:253]     Train net output #0: loss = 1.44494 (* 1 = 1.44494 loss)
I0525 09:41:37.210268 19426 sgd_solver.cpp:106] Iteration 31706, lr = 0.0035
I0525 09:41:46.026321 19426 solver.cpp:237] Iteration 31872, loss = 1.12653
I0525 09:41:46.026478 19426 solver.cpp:253]     Train net output #0: loss = 1.12653 (* 1 = 1.12653 loss)
I0525 09:41:46.026491 19426 sgd_solver.cpp:106] Iteration 31872, lr = 0.0035
I0525 09:41:54.851514 19426 solver.cpp:237] Iteration 32038, loss = 1.24716
I0525 09:41:54.851558 19426 solver.cpp:253]     Train net output #0: loss = 1.24716 (* 1 = 1.24716 loss)
I0525 09:41:54.851577 19426 sgd_solver.cpp:106] Iteration 32038, lr = 0.0035
I0525 09:42:03.672602 19426 solver.cpp:237] Iteration 32204, loss = 1.18024
I0525 09:42:03.672638 19426 solver.cpp:253]     Train net output #0: loss = 1.18024 (* 1 = 1.18024 loss)
I0525 09:42:03.672654 19426 sgd_solver.cpp:106] Iteration 32204, lr = 0.0035
I0525 09:42:33.396600 19426 solver.cpp:237] Iteration 32370, loss = 1.17184
I0525 09:42:33.396780 19426 solver.cpp:253]     Train net output #0: loss = 1.17184 (* 1 = 1.17184 loss)
I0525 09:42:33.396795 19426 sgd_solver.cpp:106] Iteration 32370, lr = 0.0035
I0525 09:42:42.216614 19426 solver.cpp:237] Iteration 32536, loss = 1.23409
I0525 09:42:42.216648 19426 solver.cpp:253]     Train net output #0: loss = 1.23409 (* 1 = 1.23409 loss)
I0525 09:42:42.216665 19426 sgd_solver.cpp:106] Iteration 32536, lr = 0.0035
I0525 09:42:51.034401 19426 solver.cpp:237] Iteration 32702, loss = 1.31036
I0525 09:42:51.034445 19426 solver.cpp:253]     Train net output #0: loss = 1.31036 (* 1 = 1.31036 loss)
I0525 09:42:51.034461 19426 sgd_solver.cpp:106] Iteration 32702, lr = 0.0035
I0525 09:42:59.853833 19426 solver.cpp:237] Iteration 32868, loss = 1.41452
I0525 09:42:59.853869 19426 solver.cpp:253]     Train net output #0: loss = 1.41452 (* 1 = 1.41452 loss)
I0525 09:42:59.853885 19426 sgd_solver.cpp:106] Iteration 32868, lr = 0.0035
I0525 09:43:08.660759 19426 solver.cpp:237] Iteration 33034, loss = 1.39702
I0525 09:43:08.660938 19426 solver.cpp:253]     Train net output #0: loss = 1.39702 (* 1 = 1.39702 loss)
I0525 09:43:08.660953 19426 sgd_solver.cpp:106] Iteration 33034, lr = 0.0035
I0525 09:43:17.474288 19426 solver.cpp:237] Iteration 33200, loss = 1.26924
I0525 09:43:17.474323 19426 solver.cpp:253]     Train net output #0: loss = 1.26924 (* 1 = 1.26924 loss)
I0525 09:43:17.474340 19426 sgd_solver.cpp:106] Iteration 33200, lr = 0.0035
I0525 09:43:23.792939 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_33320.caffemodel
I0525 09:43:23.870002 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_33320.solverstate
I0525 09:43:24.394238 19426 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 09:44:32.481487 19426 solver.cpp:409]     Test net output #0: accuracy = 0.883397
I0525 09:44:32.481667 19426 solver.cpp:409]     Test net output #1: loss = 0.37913 (* 1 = 0.37913 loss)
I0525 09:44:55.286913 19426 solver.cpp:237] Iteration 33366, loss = 1.5286
I0525 09:44:55.286964 19426 solver.cpp:253]     Train net output #0: loss = 1.5286 (* 1 = 1.5286 loss)
I0525 09:44:55.286979 19426 sgd_solver.cpp:106] Iteration 33366, lr = 0.0035
I0525 09:45:04.109761 19426 solver.cpp:237] Iteration 33532, loss = 1.28016
I0525 09:45:04.109922 19426 solver.cpp:253]     Train net output #0: loss = 1.28016 (* 1 = 1.28016 loss)
I0525 09:45:04.109936 19426 sgd_solver.cpp:106] Iteration 33532, lr = 0.0035
I0525 09:45:12.934947 19426 solver.cpp:237] Iteration 33698, loss = 1.10895
I0525 09:45:12.934981 19426 solver.cpp:253]     Train net output #0: loss = 1.10895 (* 1 = 1.10895 loss)
I0525 09:45:12.934998 19426 sgd_solver.cpp:106] Iteration 33698, lr = 0.0035
I0525 09:45:21.760390 19426 solver.cpp:237] Iteration 33864, loss = 1.00917
I0525 09:45:21.760435 19426 solver.cpp:253]     Train net output #0: loss = 1.00917 (* 1 = 1.00917 loss)
I0525 09:45:21.760452 19426 sgd_solver.cpp:106] Iteration 33864, lr = 0.0035
I0525 09:45:30.592515 19426 solver.cpp:237] Iteration 34030, loss = 1.06496
I0525 09:45:30.592550 19426 solver.cpp:253]     Train net output #0: loss = 1.06496 (* 1 = 1.06496 loss)
I0525 09:45:30.592567 19426 sgd_solver.cpp:106] Iteration 34030, lr = 0.0035
I0525 09:45:39.420315 19426 solver.cpp:237] Iteration 34196, loss = 1.26463
I0525 09:45:39.420481 19426 solver.cpp:253]     Train net output #0: loss = 1.26463 (* 1 = 1.26463 loss)
I0525 09:45:39.420495 19426 sgd_solver.cpp:106] Iteration 34196, lr = 0.0035
I0525 09:45:48.250684 19426 solver.cpp:237] Iteration 34362, loss = 1.22349
I0525 09:45:48.250718 19426 solver.cpp:253]     Train net output #0: loss = 1.22349 (* 1 = 1.22349 loss)
I0525 09:45:48.250735 19426 sgd_solver.cpp:106] Iteration 34362, lr = 0.0035
I0525 09:46:17.980346 19426 solver.cpp:237] Iteration 34528, loss = 1.0857
I0525 09:46:17.980523 19426 solver.cpp:253]     Train net output #0: loss = 1.0857 (* 1 = 1.0857 loss)
I0525 09:46:17.980538 19426 sgd_solver.cpp:106] Iteration 34528, lr = 0.0035
I0525 09:46:26.805371 19426 solver.cpp:237] Iteration 34694, loss = 1.04225
I0525 09:46:26.805404 19426 solver.cpp:253]     Train net output #0: loss = 1.04225 (* 1 = 1.04225 loss)
I0525 09:46:26.805421 19426 sgd_solver.cpp:106] Iteration 34694, lr = 0.0035
I0525 09:46:35.629534 19426 solver.cpp:237] Iteration 34860, loss = 1.31862
I0525 09:46:35.629570 19426 solver.cpp:253]     Train net output #0: loss = 1.31862 (* 1 = 1.31862 loss)
I0525 09:46:35.629590 19426 sgd_solver.cpp:106] Iteration 34860, lr = 0.0035
I0525 09:46:42.276075 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_34986.caffemodel
I0525 09:46:42.350327 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_34986.solverstate
I0525 09:46:44.520591 19426 solver.cpp:237] Iteration 35026, loss = 1.28572
I0525 09:46:44.520637 19426 solver.cpp:253]     Train net output #0: loss = 1.28572 (* 1 = 1.28572 loss)
I0525 09:46:44.520653 19426 sgd_solver.cpp:106] Iteration 35026, lr = 0.0035
I0525 09:46:53.354348 19426 solver.cpp:237] Iteration 35192, loss = 1.09189
I0525 09:46:53.354516 19426 solver.cpp:253]     Train net output #0: loss = 1.09189 (* 1 = 1.09189 loss)
I0525 09:46:53.354529 19426 sgd_solver.cpp:106] Iteration 35192, lr = 0.0035
I0525 09:47:02.187496 19426 solver.cpp:237] Iteration 35358, loss = 1.02045
I0525 09:47:02.187530 19426 solver.cpp:253]     Train net output #0: loss = 1.02045 (* 1 = 1.02045 loss)
I0525 09:47:02.187551 19426 sgd_solver.cpp:106] Iteration 35358, lr = 0.0035
I0525 09:47:11.020831 19426 solver.cpp:237] Iteration 35524, loss = 1.22697
I0525 09:47:11.020867 19426 solver.cpp:253]     Train net output #0: loss = 1.22697 (* 1 = 1.22697 loss)
I0525 09:47:11.020882 19426 sgd_solver.cpp:106] Iteration 35524, lr = 0.0035
I0525 09:47:40.687289 19426 solver.cpp:237] Iteration 35690, loss = 0.920695
I0525 09:47:40.687468 19426 solver.cpp:253]     Train net output #0: loss = 0.920695 (* 1 = 0.920695 loss)
I0525 09:47:40.687482 19426 sgd_solver.cpp:106] Iteration 35690, lr = 0.0035
I0525 09:47:49.521924 19426 solver.cpp:237] Iteration 35856, loss = 1.15752
I0525 09:47:49.521965 19426 solver.cpp:253]     Train net output #0: loss = 1.15752 (* 1 = 1.15752 loss)
I0525 09:47:49.521982 19426 sgd_solver.cpp:106] Iteration 35856, lr = 0.0035
I0525 09:47:58.354507 19426 solver.cpp:237] Iteration 36022, loss = 0.997649
I0525 09:47:58.354543 19426 solver.cpp:253]     Train net output #0: loss = 0.997649 (* 1 = 0.997649 loss)
I0525 09:47:58.354560 19426 sgd_solver.cpp:106] Iteration 36022, lr = 0.0035
I0525 09:48:07.184702 19426 solver.cpp:237] Iteration 36188, loss = 1.2268
I0525 09:48:07.184738 19426 solver.cpp:253]     Train net output #0: loss = 1.2268 (* 1 = 1.2268 loss)
I0525 09:48:07.184754 19426 sgd_solver.cpp:106] Iteration 36188, lr = 0.0035
I0525 09:48:16.024287 19426 solver.cpp:237] Iteration 36354, loss = 1.16111
I0525 09:48:16.024446 19426 solver.cpp:253]     Train net output #0: loss = 1.16111 (* 1 = 1.16111 loss)
I0525 09:48:16.024461 19426 sgd_solver.cpp:106] Iteration 36354, lr = 0.0035
I0525 09:48:24.847095 19426 solver.cpp:237] Iteration 36520, loss = 1.03883
I0525 09:48:24.847131 19426 solver.cpp:253]     Train net output #0: loss = 1.03883 (* 1 = 1.03883 loss)
I0525 09:48:24.847147 19426 sgd_solver.cpp:106] Iteration 36520, lr = 0.0035
I0525 09:48:31.822527 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_36652.caffemodel
I0525 09:48:31.897809 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_36652.solverstate
I0525 09:48:32.471057 19426 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 09:49:19.376673 19426 solver.cpp:409]     Test net output #0: accuracy = 0.88303
I0525 09:49:19.376849 19426 solver.cpp:409]     Test net output #1: loss = 0.369542 (* 1 = 0.369542 loss)
I0525 09:49:41.468914 19426 solver.cpp:237] Iteration 36686, loss = 1.26374
I0525 09:49:41.468964 19426 solver.cpp:253]     Train net output #0: loss = 1.26374 (* 1 = 1.26374 loss)
I0525 09:49:41.468981 19426 sgd_solver.cpp:106] Iteration 36686, lr = 0.0035
I0525 09:49:50.298913 19426 solver.cpp:237] Iteration 36852, loss = 1.28744
I0525 09:49:50.299091 19426 solver.cpp:253]     Train net output #0: loss = 1.28744 (* 1 = 1.28744 loss)
I0525 09:49:50.299105 19426 sgd_solver.cpp:106] Iteration 36852, lr = 0.0035
I0525 09:49:59.127320 19426 solver.cpp:237] Iteration 37018, loss = 1.09083
I0525 09:49:59.127353 19426 solver.cpp:253]     Train net output #0: loss = 1.09083 (* 1 = 1.09083 loss)
I0525 09:49:59.127368 19426 sgd_solver.cpp:106] Iteration 37018, lr = 0.0035
I0525 09:50:07.953449 19426 solver.cpp:237] Iteration 37184, loss = 1.08394
I0525 09:50:07.953483 19426 solver.cpp:253]     Train net output #0: loss = 1.08394 (* 1 = 1.08394 loss)
I0525 09:50:07.953497 19426 sgd_solver.cpp:106] Iteration 37184, lr = 0.0035
I0525 09:50:16.792104 19426 solver.cpp:237] Iteration 37350, loss = 1.16961
I0525 09:50:16.792148 19426 solver.cpp:253]     Train net output #0: loss = 1.16961 (* 1 = 1.16961 loss)
I0525 09:50:16.792163 19426 sgd_solver.cpp:106] Iteration 37350, lr = 0.0035
I0525 09:50:25.626437 19426 solver.cpp:237] Iteration 37516, loss = 1.03155
I0525 09:50:25.626595 19426 solver.cpp:253]     Train net output #0: loss = 1.03155 (* 1 = 1.03155 loss)
I0525 09:50:25.626608 19426 sgd_solver.cpp:106] Iteration 37516, lr = 0.0035
I0525 09:50:34.455597 19426 solver.cpp:237] Iteration 37682, loss = 1.05685
I0525 09:50:34.455631 19426 solver.cpp:253]     Train net output #0: loss = 1.05685 (* 1 = 1.05685 loss)
I0525 09:50:34.455647 19426 sgd_solver.cpp:106] Iteration 37682, lr = 0.0035
I0525 09:51:04.156437 19426 solver.cpp:237] Iteration 37848, loss = 1.05931
I0525 09:51:04.156608 19426 solver.cpp:253]     Train net output #0: loss = 1.05931 (* 1 = 1.05931 loss)
I0525 09:51:04.156622 19426 sgd_solver.cpp:106] Iteration 37848, lr = 0.0035
I0525 09:51:12.983631 19426 solver.cpp:237] Iteration 38014, loss = 1.24258
I0525 09:51:12.983666 19426 solver.cpp:253]     Train net output #0: loss = 1.24258 (* 1 = 1.24258 loss)
I0525 09:51:12.983681 19426 sgd_solver.cpp:106] Iteration 38014, lr = 0.0035
I0525 09:51:21.810298 19426 solver.cpp:237] Iteration 38180, loss = 1.26693
I0525 09:51:21.810333 19426 solver.cpp:253]     Train net output #0: loss = 1.26693 (* 1 = 1.26693 loss)
I0525 09:51:21.810349 19426 sgd_solver.cpp:106] Iteration 38180, lr = 0.0035
I0525 09:51:29.092169 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_38318.caffemodel
I0525 09:51:29.171921 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_38318.solverstate
I0525 09:51:30.701320 19426 solver.cpp:237] Iteration 38346, loss = 1.29518
I0525 09:51:30.701365 19426 solver.cpp:253]     Train net output #0: loss = 1.29518 (* 1 = 1.29518 loss)
I0525 09:51:30.701444 19426 sgd_solver.cpp:106] Iteration 38346, lr = 0.0035
I0525 09:51:39.540027 19426 solver.cpp:237] Iteration 38512, loss = 1.34476
I0525 09:51:39.540189 19426 solver.cpp:253]     Train net output #0: loss = 1.34476 (* 1 = 1.34476 loss)
I0525 09:51:39.540201 19426 sgd_solver.cpp:106] Iteration 38512, lr = 0.0035
I0525 09:51:48.358644 19426 solver.cpp:237] Iteration 38678, loss = 0.896337
I0525 09:51:48.358681 19426 solver.cpp:253]     Train net output #0: loss = 0.896337 (* 1 = 0.896337 loss)
I0525 09:51:48.358695 19426 sgd_solver.cpp:106] Iteration 38678, lr = 0.0035
I0525 09:51:57.186955 19426 solver.cpp:237] Iteration 38844, loss = 1.12367
I0525 09:51:57.187006 19426 solver.cpp:253]     Train net output #0: loss = 1.12367 (* 1 = 1.12367 loss)
I0525 09:51:57.187021 19426 sgd_solver.cpp:106] Iteration 38844, lr = 0.0035
I0525 09:52:26.902547 19426 solver.cpp:237] Iteration 39010, loss = 1.39298
I0525 09:52:26.902736 19426 solver.cpp:253]     Train net output #0: loss = 1.39298 (* 1 = 1.39298 loss)
I0525 09:52:26.902750 19426 sgd_solver.cpp:106] Iteration 39010, lr = 0.0035
I0525 09:52:35.731565 19426 solver.cpp:237] Iteration 39176, loss = 1.1536
I0525 09:52:35.731600 19426 solver.cpp:253]     Train net output #0: loss = 1.1536 (* 1 = 1.1536 loss)
I0525 09:52:35.731616 19426 sgd_solver.cpp:106] Iteration 39176, lr = 0.0035
I0525 09:52:44.562036 19426 solver.cpp:237] Iteration 39342, loss = 1.22521
I0525 09:52:44.562078 19426 solver.cpp:253]     Train net output #0: loss = 1.22521 (* 1 = 1.22521 loss)
I0525 09:52:44.562098 19426 sgd_solver.cpp:106] Iteration 39342, lr = 0.0035
I0525 09:52:53.396193 19426 solver.cpp:237] Iteration 39508, loss = 1.06538
I0525 09:52:53.396229 19426 solver.cpp:253]     Train net output #0: loss = 1.06538 (* 1 = 1.06538 loss)
I0525 09:52:53.396245 19426 sgd_solver.cpp:106] Iteration 39508, lr = 0.0035
I0525 09:53:02.222306 19426 solver.cpp:237] Iteration 39674, loss = 1.18363
I0525 09:53:02.222465 19426 solver.cpp:253]     Train net output #0: loss = 1.18363 (* 1 = 1.18363 loss)
I0525 09:53:02.222479 19426 sgd_solver.cpp:106] Iteration 39674, lr = 0.0035
I0525 09:53:11.042940 19426 solver.cpp:237] Iteration 39840, loss = 1.07558
I0525 09:53:11.042989 19426 solver.cpp:253]     Train net output #0: loss = 1.07558 (* 1 = 1.07558 loss)
I0525 09:53:11.043004 19426 sgd_solver.cpp:106] Iteration 39840, lr = 0.0035
I0525 09:53:18.643132 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_39984.caffemodel
I0525 09:53:18.720224 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_39984.solverstate
I0525 09:53:19.347343 19426 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 09:54:27.367949 19426 solver.cpp:409]     Test net output #0: accuracy = 0.884291
I0525 09:54:27.368134 19426 solver.cpp:409]     Test net output #1: loss = 0.376964 (* 1 = 0.376964 loss)
I0525 09:54:48.754031 19426 solver.cpp:237] Iteration 40006, loss = 1.14317
I0525 09:54:48.754082 19426 solver.cpp:253]     Train net output #0: loss = 1.14317 (* 1 = 1.14317 loss)
I0525 09:54:48.754096 19426 sgd_solver.cpp:106] Iteration 40006, lr = 0.0035
I0525 09:54:57.580826 19426 solver.cpp:237] Iteration 40172, loss = 1.22826
I0525 09:54:57.580984 19426 solver.cpp:253]     Train net output #0: loss = 1.22826 (* 1 = 1.22826 loss)
I0525 09:54:57.580997 19426 sgd_solver.cpp:106] Iteration 40172, lr = 0.0035
I0525 09:55:06.422477 19426 solver.cpp:237] Iteration 40338, loss = 1.22059
I0525 09:55:06.422511 19426 solver.cpp:253]     Train net output #0: loss = 1.22059 (* 1 = 1.22059 loss)
I0525 09:55:06.422526 19426 sgd_solver.cpp:106] Iteration 40338, lr = 0.0035
I0525 09:55:15.271422 19426 solver.cpp:237] Iteration 40504, loss = 1.05003
I0525 09:55:15.271471 19426 solver.cpp:253]     Train net output #0: loss = 1.05003 (* 1 = 1.05003 loss)
I0525 09:55:15.271486 19426 sgd_solver.cpp:106] Iteration 40504, lr = 0.0035
I0525 09:55:24.105320 19426 solver.cpp:237] Iteration 40670, loss = 1.03084
I0525 09:55:24.105355 19426 solver.cpp:253]     Train net output #0: loss = 1.03084 (* 1 = 1.03084 loss)
I0525 09:55:24.105370 19426 sgd_solver.cpp:106] Iteration 40670, lr = 0.0035
I0525 09:55:32.947250 19426 solver.cpp:237] Iteration 40836, loss = 1.23846
I0525 09:55:32.947418 19426 solver.cpp:253]     Train net output #0: loss = 1.23846 (* 1 = 1.23846 loss)
I0525 09:55:32.947432 19426 sgd_solver.cpp:106] Iteration 40836, lr = 0.0035
I0525 09:55:41.773663 19426 solver.cpp:237] Iteration 41002, loss = 1.23013
I0525 09:55:41.773699 19426 solver.cpp:253]     Train net output #0: loss = 1.23013 (* 1 = 1.23013 loss)
I0525 09:55:41.773720 19426 sgd_solver.cpp:106] Iteration 41002, lr = 0.0035
I0525 09:56:11.407732 19426 solver.cpp:237] Iteration 41168, loss = 1.23374
I0525 09:56:11.407910 19426 solver.cpp:253]     Train net output #0: loss = 1.23374 (* 1 = 1.23374 loss)
I0525 09:56:11.407925 19426 sgd_solver.cpp:106] Iteration 41168, lr = 0.0035
I0525 09:56:20.249631 19426 solver.cpp:237] Iteration 41334, loss = 1.17758
I0525 09:56:20.249666 19426 solver.cpp:253]     Train net output #0: loss = 1.17758 (* 1 = 1.17758 loss)
I0525 09:56:20.249681 19426 sgd_solver.cpp:106] Iteration 41334, lr = 0.0035
I0525 09:56:29.098870 19426 solver.cpp:237] Iteration 41500, loss = 1.03089
I0525 09:56:29.098914 19426 solver.cpp:253]     Train net output #0: loss = 1.03089 (* 1 = 1.03089 loss)
I0525 09:56:29.098930 19426 sgd_solver.cpp:106] Iteration 41500, lr = 0.0035
I0525 09:56:37.035578 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_41650.caffemodel
I0525 09:56:37.112615 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_41650.solverstate
I0525 09:56:38.009405 19426 solver.cpp:237] Iteration 41666, loss = 1.15911
I0525 09:56:38.009452 19426 solver.cpp:253]     Train net output #0: loss = 1.15911 (* 1 = 1.15911 loss)
I0525 09:56:38.009469 19426 sgd_solver.cpp:106] Iteration 41666, lr = 0.0035
I0525 09:56:46.842586 19426 solver.cpp:237] Iteration 41832, loss = 1.10014
I0525 09:56:46.842767 19426 solver.cpp:253]     Train net output #0: loss = 1.10014 (* 1 = 1.10014 loss)
I0525 09:56:46.842782 19426 sgd_solver.cpp:106] Iteration 41832, lr = 0.0035
I0525 09:56:55.680609 19426 solver.cpp:237] Iteration 41998, loss = 1.24009
I0525 09:56:55.680658 19426 solver.cpp:253]     Train net output #0: loss = 1.24009 (* 1 = 1.24009 loss)
I0525 09:56:55.680675 19426 sgd_solver.cpp:106] Iteration 41998, lr = 0.0035
I0525 09:57:04.515103 19426 solver.cpp:237] Iteration 42164, loss = 1.13417
I0525 09:57:04.515138 19426 solver.cpp:253]     Train net output #0: loss = 1.13417 (* 1 = 1.13417 loss)
I0525 09:57:04.515153 19426 sgd_solver.cpp:106] Iteration 42164, lr = 0.0035
I0525 09:57:34.166719 19426 solver.cpp:237] Iteration 42330, loss = 1.1532
I0525 09:57:34.166900 19426 solver.cpp:253]     Train net output #0: loss = 1.1532 (* 1 = 1.1532 loss)
I0525 09:57:34.166914 19426 sgd_solver.cpp:106] Iteration 42330, lr = 0.0035
I0525 09:57:43.010428 19426 solver.cpp:237] Iteration 42496, loss = 1.1708
I0525 09:57:43.010463 19426 solver.cpp:253]     Train net output #0: loss = 1.1708 (* 1 = 1.1708 loss)
I0525 09:57:43.010479 19426 sgd_solver.cpp:106] Iteration 42496, lr = 0.0035
I0525 09:57:51.845602 19426 solver.cpp:237] Iteration 42662, loss = 1.30395
I0525 09:57:51.845639 19426 solver.cpp:253]     Train net output #0: loss = 1.30395 (* 1 = 1.30395 loss)
I0525 09:57:51.845654 19426 sgd_solver.cpp:106] Iteration 42662, lr = 0.0035
I0525 09:58:00.673933 19426 solver.cpp:237] Iteration 42828, loss = 1.15248
I0525 09:58:00.673969 19426 solver.cpp:253]     Train net output #0: loss = 1.15248 (* 1 = 1.15248 loss)
I0525 09:58:00.673982 19426 sgd_solver.cpp:106] Iteration 42828, lr = 0.0035
I0525 09:58:09.506417 19426 solver.cpp:237] Iteration 42994, loss = 1.37271
I0525 09:58:09.506587 19426 solver.cpp:253]     Train net output #0: loss = 1.37271 (* 1 = 1.37271 loss)
I0525 09:58:09.506602 19426 sgd_solver.cpp:106] Iteration 42994, lr = 0.0035
I0525 09:58:18.349781 19426 solver.cpp:237] Iteration 43160, loss = 1.17812
I0525 09:58:18.349814 19426 solver.cpp:253]     Train net output #0: loss = 1.17812 (* 1 = 1.17812 loss)
I0525 09:58:18.349829 19426 sgd_solver.cpp:106] Iteration 43160, lr = 0.0035
I0525 09:58:26.599784 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_43316.caffemodel
I0525 09:58:26.675074 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_43316.solverstate
I0525 09:58:27.250620 19426 solver.cpp:237] Iteration 43326, loss = 1.16578
I0525 09:58:27.250661 19426 solver.cpp:253]     Train net output #0: loss = 1.16578 (* 1 = 1.16578 loss)
I0525 09:58:27.250680 19426 sgd_solver.cpp:106] Iteration 43326, lr = 0.0035
I0525 09:58:27.357777 19426 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 09:59:14.520848 19426 solver.cpp:409]     Test net output #0: accuracy = 0.885178
I0525 09:59:14.521040 19426 solver.cpp:409]     Test net output #1: loss = 0.356988 (* 1 = 0.356988 loss)
I0525 09:59:44.037981 19426 solver.cpp:237] Iteration 43492, loss = 1.284
I0525 09:59:44.038033 19426 solver.cpp:253]     Train net output #0: loss = 1.284 (* 1 = 1.284 loss)
I0525 09:59:44.038046 19426 sgd_solver.cpp:106] Iteration 43492, lr = 0.0035
I0525 09:59:52.872555 19426 solver.cpp:237] Iteration 43658, loss = 1.09755
I0525 09:59:52.872731 19426 solver.cpp:253]     Train net output #0: loss = 1.09755 (* 1 = 1.09755 loss)
I0525 09:59:52.872745 19426 sgd_solver.cpp:106] Iteration 43658, lr = 0.0035
I0525 10:00:01.699352 19426 solver.cpp:237] Iteration 43824, loss = 1.28716
I0525 10:00:01.699388 19426 solver.cpp:253]     Train net output #0: loss = 1.28716 (* 1 = 1.28716 loss)
I0525 10:00:01.699403 19426 sgd_solver.cpp:106] Iteration 43824, lr = 0.0035
I0525 10:00:10.522913 19426 solver.cpp:237] Iteration 43990, loss = 1.18555
I0525 10:00:10.522949 19426 solver.cpp:253]     Train net output #0: loss = 1.18555 (* 1 = 1.18555 loss)
I0525 10:00:10.522964 19426 sgd_solver.cpp:106] Iteration 43990, lr = 0.0035
I0525 10:00:19.354868 19426 solver.cpp:237] Iteration 44156, loss = 1.24684
I0525 10:00:19.354918 19426 solver.cpp:253]     Train net output #0: loss = 1.24684 (* 1 = 1.24684 loss)
I0525 10:00:19.354934 19426 sgd_solver.cpp:106] Iteration 44156, lr = 0.0035
I0525 10:00:28.178903 19426 solver.cpp:237] Iteration 44322, loss = 1.0228
I0525 10:00:28.179065 19426 solver.cpp:253]     Train net output #0: loss = 1.0228 (* 1 = 1.0228 loss)
I0525 10:00:28.179078 19426 sgd_solver.cpp:106] Iteration 44322, lr = 0.0035
I0525 10:00:57.863492 19426 solver.cpp:237] Iteration 44488, loss = 1.10045
I0525 10:00:57.863543 19426 solver.cpp:253]     Train net output #0: loss = 1.10045 (* 1 = 1.10045 loss)
I0525 10:00:57.863557 19426 sgd_solver.cpp:106] Iteration 44488, lr = 0.0035
I0525 10:01:06.687682 19426 solver.cpp:237] Iteration 44654, loss = 1.20399
I0525 10:01:06.687858 19426 solver.cpp:253]     Train net output #0: loss = 1.20399 (* 1 = 1.20399 loss)
I0525 10:01:06.687873 19426 sgd_solver.cpp:106] Iteration 44654, lr = 0.0035
I0525 10:01:15.518313 19426 solver.cpp:237] Iteration 44820, loss = 1.19957
I0525 10:01:15.518348 19426 solver.cpp:253]     Train net output #0: loss = 1.19957 (* 1 = 1.19957 loss)
I0525 10:01:15.518363 19426 sgd_solver.cpp:106] Iteration 44820, lr = 0.0035
I0525 10:01:24.079701 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_44982.caffemodel
I0525 10:01:24.154824 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_44982.solverstate
I0525 10:01:24.408633 19426 solver.cpp:237] Iteration 44986, loss = 1.14576
I0525 10:01:24.408676 19426 solver.cpp:253]     Train net output #0: loss = 1.14576 (* 1 = 1.14576 loss)
I0525 10:01:24.408691 19426 sgd_solver.cpp:106] Iteration 44986, lr = 0.0035
I0525 10:01:33.248235 19426 solver.cpp:237] Iteration 45152, loss = 1.08794
I0525 10:01:33.248281 19426 solver.cpp:253]     Train net output #0: loss = 1.08794 (* 1 = 1.08794 loss)
I0525 10:01:33.248294 19426 sgd_solver.cpp:106] Iteration 45152, lr = 0.0035
I0525 10:01:42.080516 19426 solver.cpp:237] Iteration 45318, loss = 1.18467
I0525 10:01:42.080680 19426 solver.cpp:253]     Train net output #0: loss = 1.18467 (* 1 = 1.18467 loss)
I0525 10:01:42.080693 19426 sgd_solver.cpp:106] Iteration 45318, lr = 0.0035
I0525 10:01:50.908689 19426 solver.cpp:237] Iteration 45484, loss = 1.10183
I0525 10:01:50.908723 19426 solver.cpp:253]     Train net output #0: loss = 1.10183 (* 1 = 1.10183 loss)
I0525 10:01:50.908738 19426 sgd_solver.cpp:106] Iteration 45484, lr = 0.0035
I0525 10:02:20.532739 19426 solver.cpp:237] Iteration 45650, loss = 1.1418
I0525 10:02:20.532928 19426 solver.cpp:253]     Train net output #0: loss = 1.1418 (* 1 = 1.1418 loss)
I0525 10:02:20.532943 19426 sgd_solver.cpp:106] Iteration 45650, lr = 0.0035
I0525 10:02:29.363296 19426 solver.cpp:237] Iteration 45816, loss = 1.23118
I0525 10:02:29.363330 19426 solver.cpp:253]     Train net output #0: loss = 1.23118 (* 1 = 1.23118 loss)
I0525 10:02:29.363346 19426 sgd_solver.cpp:106] Iteration 45816, lr = 0.0035
I0525 10:02:38.185714 19426 solver.cpp:237] Iteration 45982, loss = 1.02288
I0525 10:02:38.185750 19426 solver.cpp:253]     Train net output #0: loss = 1.02288 (* 1 = 1.02288 loss)
I0525 10:02:38.185765 19426 sgd_solver.cpp:106] Iteration 45982, lr = 0.0035
I0525 10:02:47.014941 19426 solver.cpp:237] Iteration 46148, loss = 1.18757
I0525 10:02:47.014991 19426 solver.cpp:253]     Train net output #0: loss = 1.18757 (* 1 = 1.18757 loss)
I0525 10:02:47.015004 19426 sgd_solver.cpp:106] Iteration 46148, lr = 0.0035
I0525 10:02:55.841017 19426 solver.cpp:237] Iteration 46314, loss = 1.29649
I0525 10:02:55.841184 19426 solver.cpp:253]     Train net output #0: loss = 1.29649 (* 1 = 1.29649 loss)
I0525 10:02:55.841198 19426 sgd_solver.cpp:106] Iteration 46314, lr = 0.0035
I0525 10:03:04.663833 19426 solver.cpp:237] Iteration 46480, loss = 1.16466
I0525 10:03:04.663867 19426 solver.cpp:253]     Train net output #0: loss = 1.16466 (* 1 = 1.16466 loss)
I0525 10:03:04.663884 19426 sgd_solver.cpp:106] Iteration 46480, lr = 0.0035
I0525 10:03:13.500413 19426 solver.cpp:237] Iteration 46646, loss = 1.2592
I0525 10:03:13.500458 19426 solver.cpp:253]     Train net output #0: loss = 1.2592 (* 1 = 1.2592 loss)
I0525 10:03:13.500473 19426 sgd_solver.cpp:106] Iteration 46646, lr = 0.0035
I0525 10:03:13.553802 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_46648.caffemodel
I0525 10:03:13.628649 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_46648.solverstate
I0525 10:03:14.362471 19426 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 10:04:22.353902 19426 solver.cpp:409]     Test net output #0: accuracy = 0.890221
I0525 10:04:22.354082 19426 solver.cpp:409]     Test net output #1: loss = 0.348576 (* 1 = 0.348576 loss)
I0525 10:04:51.125973 19426 solver.cpp:237] Iteration 46812, loss = 1.13891
I0525 10:04:51.126022 19426 solver.cpp:253]     Train net output #0: loss = 1.13891 (* 1 = 1.13891 loss)
I0525 10:04:51.126039 19426 sgd_solver.cpp:106] Iteration 46812, lr = 0.0035
I0525 10:04:59.946888 19426 solver.cpp:237] Iteration 46978, loss = 1.06565
I0525 10:04:59.947064 19426 solver.cpp:253]     Train net output #0: loss = 1.06565 (* 1 = 1.06565 loss)
I0525 10:04:59.947077 19426 sgd_solver.cpp:106] Iteration 46978, lr = 0.0035
I0525 10:05:08.765790 19426 solver.cpp:237] Iteration 47144, loss = 1.15973
I0525 10:05:08.765825 19426 solver.cpp:253]     Train net output #0: loss = 1.15973 (* 1 = 1.15973 loss)
I0525 10:05:08.765839 19426 sgd_solver.cpp:106] Iteration 47144, lr = 0.0035
I0525 10:05:17.589882 19426 solver.cpp:237] Iteration 47310, loss = 1.09791
I0525 10:05:17.589932 19426 solver.cpp:253]     Train net output #0: loss = 1.09791 (* 1 = 1.09791 loss)
I0525 10:05:17.589946 19426 sgd_solver.cpp:106] Iteration 47310, lr = 0.0035
I0525 10:05:26.405879 19426 solver.cpp:237] Iteration 47476, loss = 1.31664
I0525 10:05:26.405913 19426 solver.cpp:253]     Train net output #0: loss = 1.31664 (* 1 = 1.31664 loss)
I0525 10:05:26.405926 19426 sgd_solver.cpp:106] Iteration 47476, lr = 0.0035
I0525 10:05:35.218984 19426 solver.cpp:237] Iteration 47642, loss = 1.32973
I0525 10:05:35.219159 19426 solver.cpp:253]     Train net output #0: loss = 1.32973 (* 1 = 1.32973 loss)
I0525 10:05:35.219172 19426 sgd_solver.cpp:106] Iteration 47642, lr = 0.0035
I0525 10:06:04.875995 19426 solver.cpp:237] Iteration 47808, loss = 1.26511
I0525 10:06:04.876044 19426 solver.cpp:253]     Train net output #0: loss = 1.26511 (* 1 = 1.26511 loss)
I0525 10:06:04.876060 19426 sgd_solver.cpp:106] Iteration 47808, lr = 0.0035
I0525 10:06:13.696560 19426 solver.cpp:237] Iteration 47974, loss = 1.44253
I0525 10:06:13.696727 19426 solver.cpp:253]     Train net output #0: loss = 1.44253 (* 1 = 1.44253 loss)
I0525 10:06:13.696741 19426 sgd_solver.cpp:106] Iteration 47974, lr = 0.0035
I0525 10:06:22.524781 19426 solver.cpp:237] Iteration 48140, loss = 0.892098
I0525 10:06:22.524817 19426 solver.cpp:253]     Train net output #0: loss = 0.892098 (* 1 = 0.892098 loss)
I0525 10:06:22.524832 19426 sgd_solver.cpp:106] Iteration 48140, lr = 0.0035
I0525 10:06:31.342460 19426 solver.cpp:237] Iteration 48306, loss = 1.08993
I0525 10:06:31.342499 19426 solver.cpp:253]     Train net output #0: loss = 1.08993 (* 1 = 1.08993 loss)
I0525 10:06:31.342519 19426 sgd_solver.cpp:106] Iteration 48306, lr = 0.0035
I0525 10:06:31.714247 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_48314.caffemodel
I0525 10:06:31.791421 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_48314.solverstate
I0525 10:06:40.237700 19426 solver.cpp:237] Iteration 48472, loss = 1.19933
I0525 10:06:40.237745 19426 solver.cpp:253]     Train net output #0: loss = 1.19933 (* 1 = 1.19933 loss)
I0525 10:06:40.237762 19426 sgd_solver.cpp:106] Iteration 48472, lr = 0.0035
I0525 10:06:49.058667 19426 solver.cpp:237] Iteration 48638, loss = 1.12967
I0525 10:06:49.058835 19426 solver.cpp:253]     Train net output #0: loss = 1.12967 (* 1 = 1.12967 loss)
I0525 10:06:49.058848 19426 sgd_solver.cpp:106] Iteration 48638, lr = 0.0035
I0525 10:06:57.884891 19426 solver.cpp:237] Iteration 48804, loss = 1.22457
I0525 10:06:57.884939 19426 solver.cpp:253]     Train net output #0: loss = 1.22457 (* 1 = 1.22457 loss)
I0525 10:06:57.884955 19426 sgd_solver.cpp:106] Iteration 48804, lr = 0.0035
I0525 10:07:27.523962 19426 solver.cpp:237] Iteration 48970, loss = 1.1328
I0525 10:07:27.524144 19426 solver.cpp:253]     Train net output #0: loss = 1.1328 (* 1 = 1.1328 loss)
I0525 10:07:27.524158 19426 sgd_solver.cpp:106] Iteration 48970, lr = 0.0035
I0525 10:07:36.341867 19426 solver.cpp:237] Iteration 49136, loss = 1.25217
I0525 10:07:36.341902 19426 solver.cpp:253]     Train net output #0: loss = 1.25217 (* 1 = 1.25217 loss)
I0525 10:07:36.341917 19426 sgd_solver.cpp:106] Iteration 49136, lr = 0.0035
I0525 10:07:45.170086 19426 solver.cpp:237] Iteration 49302, loss = 1.18768
I0525 10:07:45.170135 19426 solver.cpp:253]     Train net output #0: loss = 1.18768 (* 1 = 1.18768 loss)
I0525 10:07:45.170148 19426 sgd_solver.cpp:106] Iteration 49302, lr = 0.0035
I0525 10:07:53.992633 19426 solver.cpp:237] Iteration 49468, loss = 1.20279
I0525 10:07:53.992669 19426 solver.cpp:253]     Train net output #0: loss = 1.20279 (* 1 = 1.20279 loss)
I0525 10:07:53.992682 19426 sgd_solver.cpp:106] Iteration 49468, lr = 0.0035
I0525 10:08:02.811519 19426 solver.cpp:237] Iteration 49634, loss = 1.10491
I0525 10:08:02.811681 19426 solver.cpp:253]     Train net output #0: loss = 1.10491 (* 1 = 1.10491 loss)
I0525 10:08:02.811694 19426 sgd_solver.cpp:106] Iteration 49634, lr = 0.0035
I0525 10:08:11.638272 19426 solver.cpp:237] Iteration 49800, loss = 0.966272
I0525 10:08:11.638316 19426 solver.cpp:253]     Train net output #0: loss = 0.966272 (* 1 = 0.966272 loss)
I0525 10:08:11.638334 19426 sgd_solver.cpp:106] Iteration 49800, lr = 0.0035
I0525 10:08:20.455688 19426 solver.cpp:237] Iteration 49966, loss = 1.18132
I0525 10:08:20.455724 19426 solver.cpp:253]     Train net output #0: loss = 1.18132 (* 1 = 1.18132 loss)
I0525 10:08:20.455739 19426 sgd_solver.cpp:106] Iteration 49966, lr = 0.0035
I0525 10:08:21.147936 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_49980.caffemodel
I0525 10:08:21.224258 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_49980.solverstate
I0525 10:08:22.015763 19426 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 10:09:08.812155 19426 solver.cpp:409]     Test net output #0: accuracy = 0.889987
I0525 10:09:08.812364 19426 solver.cpp:409]     Test net output #1: loss = 0.362259 (* 1 = 0.362259 loss)
I0525 10:09:36.976490 19426 solver.cpp:237] Iteration 50132, loss = 1.27604
I0525 10:09:36.976541 19426 solver.cpp:253]     Train net output #0: loss = 1.27604 (* 1 = 1.27604 loss)
I0525 10:09:36.976555 19426 sgd_solver.cpp:106] Iteration 50132, lr = 0.0035
I0525 10:09:45.801002 19426 solver.cpp:237] Iteration 50298, loss = 1.04016
I0525 10:09:45.801177 19426 solver.cpp:253]     Train net output #0: loss = 1.04016 (* 1 = 1.04016 loss)
I0525 10:09:45.801190 19426 sgd_solver.cpp:106] Iteration 50298, lr = 0.0035
I0525 10:09:54.630147 19426 solver.cpp:237] Iteration 50464, loss = 1.23486
I0525 10:09:54.630192 19426 solver.cpp:253]     Train net output #0: loss = 1.23486 (* 1 = 1.23486 loss)
I0525 10:09:54.630208 19426 sgd_solver.cpp:106] Iteration 50464, lr = 0.0035
I0525 10:10:03.454494 19426 solver.cpp:237] Iteration 50630, loss = 1.18944
I0525 10:10:03.454530 19426 solver.cpp:253]     Train net output #0: loss = 1.18944 (* 1 = 1.18944 loss)
I0525 10:10:03.454545 19426 sgd_solver.cpp:106] Iteration 50630, lr = 0.0035
I0525 10:10:12.278688 19426 solver.cpp:237] Iteration 50796, loss = 1.34531
I0525 10:10:12.278723 19426 solver.cpp:253]     Train net output #0: loss = 1.34531 (* 1 = 1.34531 loss)
I0525 10:10:12.278738 19426 sgd_solver.cpp:106] Iteration 50796, lr = 0.0035
I0525 10:10:21.107447 19426 solver.cpp:237] Iteration 50962, loss = 1.0132
I0525 10:10:21.107623 19426 solver.cpp:253]     Train net output #0: loss = 1.0132 (* 1 = 1.0132 loss)
I0525 10:10:21.107637 19426 sgd_solver.cpp:106] Iteration 50962, lr = 0.0035
I0525 10:10:50.727605 19426 solver.cpp:237] Iteration 51128, loss = 1.14509
I0525 10:10:50.727654 19426 solver.cpp:253]     Train net output #0: loss = 1.14509 (* 1 = 1.14509 loss)
I0525 10:10:50.727670 19426 sgd_solver.cpp:106] Iteration 51128, lr = 0.0035
I0525 10:10:59.556143 19426 solver.cpp:237] Iteration 51294, loss = 1.28145
I0525 10:10:59.556310 19426 solver.cpp:253]     Train net output #0: loss = 1.28145 (* 1 = 1.28145 loss)
I0525 10:10:59.556324 19426 sgd_solver.cpp:106] Iteration 51294, lr = 0.0035
I0525 10:11:08.384166 19426 solver.cpp:237] Iteration 51460, loss = 1.20536
I0525 10:11:08.384212 19426 solver.cpp:253]     Train net output #0: loss = 1.20536 (* 1 = 1.20536 loss)
I0525 10:11:08.384227 19426 sgd_solver.cpp:106] Iteration 51460, lr = 0.0035
I0525 10:11:17.212286 19426 solver.cpp:237] Iteration 51626, loss = 1.11846
I0525 10:11:17.212322 19426 solver.cpp:253]     Train net output #0: loss = 1.11846 (* 1 = 1.11846 loss)
I0525 10:11:17.212335 19426 sgd_solver.cpp:106] Iteration 51626, lr = 0.0035
I0525 10:11:18.224941 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_51646.caffemodel
I0525 10:11:18.300155 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_51646.solverstate
I0525 10:11:26.103616 19426 solver.cpp:237] Iteration 51792, loss = 1.1933
I0525 10:11:26.103659 19426 solver.cpp:253]     Train net output #0: loss = 1.1933 (* 1 = 1.1933 loss)
I0525 10:11:26.103677 19426 sgd_solver.cpp:106] Iteration 51792, lr = 0.0035
I0525 10:11:34.926832 19426 solver.cpp:237] Iteration 51958, loss = 1.21273
I0525 10:11:34.927024 19426 solver.cpp:253]     Train net output #0: loss = 1.21273 (* 1 = 1.21273 loss)
I0525 10:11:34.927038 19426 sgd_solver.cpp:106] Iteration 51958, lr = 0.0035
I0525 10:11:43.756556 19426 solver.cpp:237] Iteration 52124, loss = 1.06615
I0525 10:11:43.756590 19426 solver.cpp:253]     Train net output #0: loss = 1.06615 (* 1 = 1.06615 loss)
I0525 10:11:43.756605 19426 sgd_solver.cpp:106] Iteration 52124, lr = 0.0035
I0525 10:12:13.490345 19426 solver.cpp:237] Iteration 52290, loss = 1.20952
I0525 10:12:13.490535 19426 solver.cpp:253]     Train net output #0: loss = 1.20952 (* 1 = 1.20952 loss)
I0525 10:12:13.490548 19426 sgd_solver.cpp:106] Iteration 52290, lr = 0.0035
I0525 10:12:22.319545 19426 solver.cpp:237] Iteration 52456, loss = 0.999044
I0525 10:12:22.319592 19426 solver.cpp:253]     Train net output #0: loss = 0.999044 (* 1 = 0.999044 loss)
I0525 10:12:22.319607 19426 sgd_solver.cpp:106] Iteration 52456, lr = 0.0035
I0525 10:12:31.144984 19426 solver.cpp:237] Iteration 52622, loss = 1.06064
I0525 10:12:31.145020 19426 solver.cpp:253]     Train net output #0: loss = 1.06064 (* 1 = 1.06064 loss)
I0525 10:12:31.145040 19426 sgd_solver.cpp:106] Iteration 52622, lr = 0.0035
I0525 10:12:39.974136 19426 solver.cpp:237] Iteration 52788, loss = 1.13283
I0525 10:12:39.974172 19426 solver.cpp:253]     Train net output #0: loss = 1.13283 (* 1 = 1.13283 loss)
I0525 10:12:39.974186 19426 sgd_solver.cpp:106] Iteration 52788, lr = 0.0035
I0525 10:12:48.803872 19426 solver.cpp:237] Iteration 52954, loss = 1.35611
I0525 10:12:48.804050 19426 solver.cpp:253]     Train net output #0: loss = 1.35611 (* 1 = 1.35611 loss)
I0525 10:12:48.804064 19426 sgd_solver.cpp:106] Iteration 52954, lr = 0.0035
I0525 10:12:57.636626 19426 solver.cpp:237] Iteration 53120, loss = 1.06451
I0525 10:12:57.636661 19426 solver.cpp:253]     Train net output #0: loss = 1.06451 (* 1 = 1.06451 loss)
I0525 10:12:57.636674 19426 sgd_solver.cpp:106] Iteration 53120, lr = 0.0035
I0525 10:13:06.462177 19426 solver.cpp:237] Iteration 53286, loss = 1.20262
I0525 10:13:06.462213 19426 solver.cpp:253]     Train net output #0: loss = 1.20262 (* 1 = 1.20262 loss)
I0525 10:13:06.462226 19426 sgd_solver.cpp:106] Iteration 53286, lr = 0.0035
I0525 10:13:07.792032 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_53312.caffemodel
I0525 10:13:07.867153 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_53312.solverstate
I0525 10:13:08.706264 19426 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 10:14:16.791610 19426 solver.cpp:409]     Test net output #0: accuracy = 0.889633
I0525 10:14:16.791805 19426 solver.cpp:409]     Test net output #1: loss = 0.340822 (* 1 = 0.340822 loss)
I0525 10:14:44.200156 19426 solver.cpp:237] Iteration 53452, loss = 1.13693
I0525 10:14:44.200206 19426 solver.cpp:253]     Train net output #0: loss = 1.13693 (* 1 = 1.13693 loss)
I0525 10:14:44.200220 19426 sgd_solver.cpp:106] Iteration 53452, lr = 0.0035
I0525 10:14:53.022220 19426 solver.cpp:237] Iteration 53618, loss = 1.22317
I0525 10:14:53.022404 19426 solver.cpp:253]     Train net output #0: loss = 1.22317 (* 1 = 1.22317 loss)
I0525 10:14:53.022419 19426 sgd_solver.cpp:106] Iteration 53618, lr = 0.0035
I0525 10:15:01.834220 19426 solver.cpp:237] Iteration 53784, loss = 1.14043
I0525 10:15:01.834255 19426 solver.cpp:253]     Train net output #0: loss = 1.14043 (* 1 = 1.14043 loss)
I0525 10:15:01.834270 19426 sgd_solver.cpp:106] Iteration 53784, lr = 0.0035
I0525 10:15:10.650907 19426 solver.cpp:237] Iteration 53950, loss = 1.01683
I0525 10:15:10.650943 19426 solver.cpp:253]     Train net output #0: loss = 1.01683 (* 1 = 1.01683 loss)
I0525 10:15:10.650957 19426 sgd_solver.cpp:106] Iteration 53950, lr = 0.0035
I0525 10:15:19.467943 19426 solver.cpp:237] Iteration 54116, loss = 1.17262
I0525 10:15:19.467990 19426 solver.cpp:253]     Train net output #0: loss = 1.17262 (* 1 = 1.17262 loss)
I0525 10:15:19.468004 19426 sgd_solver.cpp:106] Iteration 54116, lr = 0.0035
I0525 10:15:28.280820 19426 solver.cpp:237] Iteration 54282, loss = 1.16995
I0525 10:15:28.280997 19426 solver.cpp:253]     Train net output #0: loss = 1.16995 (* 1 = 1.16995 loss)
I0525 10:15:28.281011 19426 sgd_solver.cpp:106] Iteration 54282, lr = 0.0035
I0525 10:15:57.947417 19426 solver.cpp:237] Iteration 54448, loss = 1.0524
I0525 10:15:57.947468 19426 solver.cpp:253]     Train net output #0: loss = 1.0524 (* 1 = 1.0524 loss)
I0525 10:15:57.947480 19426 sgd_solver.cpp:106] Iteration 54448, lr = 0.0035
I0525 10:16:06.777817 19426 solver.cpp:237] Iteration 54614, loss = 1.23044
I0525 10:16:06.778000 19426 solver.cpp:253]     Train net output #0: loss = 1.23044 (* 1 = 1.23044 loss)
I0525 10:16:06.778014 19426 sgd_solver.cpp:106] Iteration 54614, lr = 0.0035
I0525 10:16:15.593825 19426 solver.cpp:237] Iteration 54780, loss = 1.28132
I0525 10:16:15.593860 19426 solver.cpp:253]     Train net output #0: loss = 1.28132 (* 1 = 1.28132 loss)
I0525 10:16:15.593875 19426 sgd_solver.cpp:106] Iteration 54780, lr = 0.0035
I0525 10:16:24.408769 19426 solver.cpp:237] Iteration 54946, loss = 1.08464
I0525 10:16:24.408805 19426 solver.cpp:253]     Train net output #0: loss = 1.08464 (* 1 = 1.08464 loss)
I0525 10:16:24.408818 19426 sgd_solver.cpp:106] Iteration 54946, lr = 0.0035
I0525 10:16:26.054602 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_54978.caffemodel
I0525 10:16:26.128760 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_54978.solverstate
I0525 10:16:33.288015 19426 solver.cpp:237] Iteration 55112, loss = 1.12068
I0525 10:16:33.288064 19426 solver.cpp:253]     Train net output #0: loss = 1.12068 (* 1 = 1.12068 loss)
I0525 10:16:33.288080 19426 sgd_solver.cpp:106] Iteration 55112, lr = 0.0035
I0525 10:16:42.111146 19426 solver.cpp:237] Iteration 55278, loss = 1.0197
I0525 10:16:42.111317 19426 solver.cpp:253]     Train net output #0: loss = 1.0197 (* 1 = 1.0197 loss)
I0525 10:16:42.111330 19426 sgd_solver.cpp:106] Iteration 55278, lr = 0.0035
I0525 10:16:50.923502 19426 solver.cpp:237] Iteration 55444, loss = 1.15911
I0525 10:16:50.923537 19426 solver.cpp:253]     Train net output #0: loss = 1.15911 (* 1 = 1.15911 loss)
I0525 10:16:50.923552 19426 sgd_solver.cpp:106] Iteration 55444, lr = 0.0035
I0525 10:17:20.594305 19426 solver.cpp:237] Iteration 55610, loss = 1.22567
I0525 10:17:20.594492 19426 solver.cpp:253]     Train net output #0: loss = 1.22567 (* 1 = 1.22567 loss)
I0525 10:17:20.594506 19426 sgd_solver.cpp:106] Iteration 55610, lr = 0.0035
I0525 10:17:29.415807 19426 solver.cpp:237] Iteration 55776, loss = 1.13162
I0525 10:17:29.415840 19426 solver.cpp:253]     Train net output #0: loss = 1.13162 (* 1 = 1.13162 loss)
I0525 10:17:29.415856 19426 sgd_solver.cpp:106] Iteration 55776, lr = 0.0035
I0525 10:17:38.238188 19426 solver.cpp:237] Iteration 55942, loss = 1.01364
I0525 10:17:38.238224 19426 solver.cpp:253]     Train net output #0: loss = 1.01364 (* 1 = 1.01364 loss)
I0525 10:17:38.238239 19426 sgd_solver.cpp:106] Iteration 55942, lr = 0.0035
I0525 10:17:47.063859 19426 solver.cpp:237] Iteration 56108, loss = 1.18302
I0525 10:17:47.063905 19426 solver.cpp:253]     Train net output #0: loss = 1.18302 (* 1 = 1.18302 loss)
I0525 10:17:47.063920 19426 sgd_solver.cpp:106] Iteration 56108, lr = 0.0035
I0525 10:17:55.879873 19426 solver.cpp:237] Iteration 56274, loss = 1.11526
I0525 10:17:55.880039 19426 solver.cpp:253]     Train net output #0: loss = 1.11526 (* 1 = 1.11526 loss)
I0525 10:17:55.880053 19426 sgd_solver.cpp:106] Iteration 56274, lr = 0.0035
I0525 10:18:04.702826 19426 solver.cpp:237] Iteration 56440, loss = 0.961036
I0525 10:18:04.702860 19426 solver.cpp:253]     Train net output #0: loss = 0.961036 (* 1 = 0.961036 loss)
I0525 10:18:04.702877 19426 sgd_solver.cpp:106] Iteration 56440, lr = 0.0035
I0525 10:18:13.518280 19426 solver.cpp:237] Iteration 56606, loss = 1.44879
I0525 10:18:13.518322 19426 solver.cpp:253]     Train net output #0: loss = 1.44879 (* 1 = 1.44879 loss)
I0525 10:18:13.518339 19426 sgd_solver.cpp:106] Iteration 56606, lr = 0.0035
I0525 10:18:15.484748 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_56644.caffemodel
I0525 10:18:15.561199 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_56644.solverstate
I0525 10:18:16.452965 19426 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 10:19:03.645066 19426 solver.cpp:409]     Test net output #0: accuracy = 0.892061
I0525 10:19:03.645262 19426 solver.cpp:409]     Test net output #1: loss = 0.364747 (* 1 = 0.364747 loss)
I0525 10:19:30.440237 19426 solver.cpp:237] Iteration 56772, loss = 1.06693
I0525 10:19:30.440289 19426 solver.cpp:253]     Train net output #0: loss = 1.06693 (* 1 = 1.06693 loss)
I0525 10:19:30.440302 19426 sgd_solver.cpp:106] Iteration 56772, lr = 0.0035
I0525 10:19:39.271674 19426 solver.cpp:237] Iteration 56938, loss = 1.21405
I0525 10:19:39.271847 19426 solver.cpp:253]     Train net output #0: loss = 1.21405 (* 1 = 1.21405 loss)
I0525 10:19:39.271860 19426 sgd_solver.cpp:106] Iteration 56938, lr = 0.0035
I0525 10:19:48.099217 19426 solver.cpp:237] Iteration 57104, loss = 1.01819
I0525 10:19:48.099252 19426 solver.cpp:253]     Train net output #0: loss = 1.01819 (* 1 = 1.01819 loss)
I0525 10:19:48.099267 19426 sgd_solver.cpp:106] Iteration 57104, lr = 0.0035
I0525 10:19:56.918696 19426 solver.cpp:237] Iteration 57270, loss = 1.05766
I0525 10:19:56.918740 19426 solver.cpp:253]     Train net output #0: loss = 1.05766 (* 1 = 1.05766 loss)
I0525 10:19:56.918756 19426 sgd_solver.cpp:106] Iteration 57270, lr = 0.0035
I0525 10:20:05.743717 19426 solver.cpp:237] Iteration 57436, loss = 1.33581
I0525 10:20:05.743753 19426 solver.cpp:253]     Train net output #0: loss = 1.33581 (* 1 = 1.33581 loss)
I0525 10:20:05.743767 19426 sgd_solver.cpp:106] Iteration 57436, lr = 0.0035
I0525 10:20:14.579795 19426 solver.cpp:237] Iteration 57602, loss = 1.32951
I0525 10:20:14.579975 19426 solver.cpp:253]     Train net output #0: loss = 1.32951 (* 1 = 1.32951 loss)
I0525 10:20:14.579989 19426 sgd_solver.cpp:106] Iteration 57602, lr = 0.0035
I0525 10:20:23.394104 19426 solver.cpp:237] Iteration 57768, loss = 1.14325
I0525 10:20:23.394134 19426 solver.cpp:253]     Train net output #0: loss = 1.14325 (* 1 = 1.14325 loss)
I0525 10:20:23.394155 19426 sgd_solver.cpp:106] Iteration 57768, lr = 0.0035
I0525 10:20:53.069555 19426 solver.cpp:237] Iteration 57934, loss = 1.02429
I0525 10:20:53.069744 19426 solver.cpp:253]     Train net output #0: loss = 1.02429 (* 1 = 1.02429 loss)
I0525 10:20:53.069759 19426 sgd_solver.cpp:106] Iteration 57934, lr = 0.0035
I0525 10:21:01.887152 19426 solver.cpp:237] Iteration 58100, loss = 1.35103
I0525 10:21:01.887187 19426 solver.cpp:253]     Train net output #0: loss = 1.35103 (* 1 = 1.35103 loss)
I0525 10:21:01.887202 19426 sgd_solver.cpp:106] Iteration 58100, lr = 0.0035
I0525 10:21:10.707461 19426 solver.cpp:237] Iteration 58266, loss = 1.08582
I0525 10:21:10.707502 19426 solver.cpp:253]     Train net output #0: loss = 1.08582 (* 1 = 1.08582 loss)
I0525 10:21:10.707521 19426 sgd_solver.cpp:106] Iteration 58266, lr = 0.0035
I0525 10:21:12.997313 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_58310.caffemodel
I0525 10:21:13.073318 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_58310.solverstate
I0525 10:21:19.609509 19426 solver.cpp:237] Iteration 58432, loss = 1.31893
I0525 10:21:19.609558 19426 solver.cpp:253]     Train net output #0: loss = 1.31893 (* 1 = 1.31893 loss)
I0525 10:21:19.609573 19426 sgd_solver.cpp:106] Iteration 58432, lr = 0.0035
I0525 10:21:28.442191 19426 solver.cpp:237] Iteration 58598, loss = 1.10242
I0525 10:21:28.442384 19426 solver.cpp:253]     Train net output #0: loss = 1.10242 (* 1 = 1.10242 loss)
I0525 10:21:28.442399 19426 sgd_solver.cpp:106] Iteration 58598, lr = 0.0035
I0525 10:21:37.265928 19426 solver.cpp:237] Iteration 58764, loss = 1.28306
I0525 10:21:37.265977 19426 solver.cpp:253]     Train net output #0: loss = 1.28306 (* 1 = 1.28306 loss)
I0525 10:21:37.265991 19426 sgd_solver.cpp:106] Iteration 58764, lr = 0.0035
I0525 10:22:06.972589 19426 solver.cpp:237] Iteration 58930, loss = 1.24031
I0525 10:22:06.972781 19426 solver.cpp:253]     Train net output #0: loss = 1.24031 (* 1 = 1.24031 loss)
I0525 10:22:06.972796 19426 sgd_solver.cpp:106] Iteration 58930, lr = 0.0035
I0525 10:22:15.804683 19426 solver.cpp:237] Iteration 59096, loss = 1.41206
I0525 10:22:15.804718 19426 solver.cpp:253]     Train net output #0: loss = 1.41206 (* 1 = 1.41206 loss)
I0525 10:22:15.804733 19426 sgd_solver.cpp:106] Iteration 59096, lr = 0.0035
I0525 10:22:24.641876 19426 solver.cpp:237] Iteration 59262, loss = 1.2691
I0525 10:22:24.641912 19426 solver.cpp:253]     Train net output #0: loss = 1.2691 (* 1 = 1.2691 loss)
I0525 10:22:24.641932 19426 sgd_solver.cpp:106] Iteration 59262, lr = 0.0035
I0525 10:22:33.469754 19426 solver.cpp:237] Iteration 59428, loss = 1.08687
I0525 10:22:33.469790 19426 solver.cpp:253]     Train net output #0: loss = 1.08687 (* 1 = 1.08687 loss)
I0525 10:22:33.469804 19426 sgd_solver.cpp:106] Iteration 59428, lr = 0.0035
I0525 10:22:42.296119 19426 solver.cpp:237] Iteration 59594, loss = 1.18999
I0525 10:22:42.296285 19426 solver.cpp:253]     Train net output #0: loss = 1.18999 (* 1 = 1.18999 loss)
I0525 10:22:42.296298 19426 sgd_solver.cpp:106] Iteration 59594, lr = 0.0035
I0525 10:22:51.120244 19426 solver.cpp:237] Iteration 59760, loss = 1.424
I0525 10:22:51.120278 19426 solver.cpp:253]     Train net output #0: loss = 1.424 (* 1 = 1.424 loss)
I0525 10:22:51.120299 19426 sgd_solver.cpp:106] Iteration 59760, lr = 0.0035
I0525 10:22:59.944407 19426 solver.cpp:237] Iteration 59926, loss = 0.955779
I0525 10:22:59.944443 19426 solver.cpp:253]     Train net output #0: loss = 0.955779 (* 1 = 0.955779 loss)
I0525 10:22:59.944456 19426 sgd_solver.cpp:106] Iteration 59926, lr = 0.0035
I0525 10:23:02.547662 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_59976.caffemodel
I0525 10:23:02.623565 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_59976.solverstate
I0525 10:23:03.571590 19426 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 10:24:11.621477 19426 solver.cpp:409]     Test net output #0: accuracy = 0.894943
I0525 10:24:11.621667 19426 solver.cpp:409]     Test net output #1: loss = 0.330479 (* 1 = 0.330479 loss)
I0525 10:24:37.686872 19426 solver.cpp:237] Iteration 60092, loss = 1.14063
I0525 10:24:37.686923 19426 solver.cpp:253]     Train net output #0: loss = 1.14063 (* 1 = 1.14063 loss)
I0525 10:24:37.686939 19426 sgd_solver.cpp:106] Iteration 60092, lr = 0.0035
I0525 10:24:46.512310 19426 solver.cpp:237] Iteration 60258, loss = 0.878745
I0525 10:24:46.512482 19426 solver.cpp:253]     Train net output #0: loss = 0.878745 (* 1 = 0.878745 loss)
I0525 10:24:46.512496 19426 sgd_solver.cpp:106] Iteration 60258, lr = 0.0035
I0525 10:24:55.335865 19426 solver.cpp:237] Iteration 60424, loss = 1.36492
I0525 10:24:55.335903 19426 solver.cpp:253]     Train net output #0: loss = 1.36492 (* 1 = 1.36492 loss)
I0525 10:24:55.335923 19426 sgd_solver.cpp:106] Iteration 60424, lr = 0.0035
I0525 10:25:04.170867 19426 solver.cpp:237] Iteration 60590, loss = 1.08847
I0525 10:25:04.170903 19426 solver.cpp:253]     Train net output #0: loss = 1.08847 (* 1 = 1.08847 loss)
I0525 10:25:04.170918 19426 sgd_solver.cpp:106] Iteration 60590, lr = 0.0035
I0525 10:25:13.000403 19426 solver.cpp:237] Iteration 60756, loss = 1.06733
I0525 10:25:13.000438 19426 solver.cpp:253]     Train net output #0: loss = 1.06733 (* 1 = 1.06733 loss)
I0525 10:25:13.000453 19426 sgd_solver.cpp:106] Iteration 60756, lr = 0.0035
I0525 10:25:21.830639 19426 solver.cpp:237] Iteration 60922, loss = 1.44039
I0525 10:25:21.830831 19426 solver.cpp:253]     Train net output #0: loss = 1.44039 (* 1 = 1.44039 loss)
I0525 10:25:21.830845 19426 sgd_solver.cpp:106] Iteration 60922, lr = 0.0035
I0525 10:25:30.652956 19426 solver.cpp:237] Iteration 61088, loss = 1.35676
I0525 10:25:30.652989 19426 solver.cpp:253]     Train net output #0: loss = 1.35676 (* 1 = 1.35676 loss)
I0525 10:25:30.653005 19426 sgd_solver.cpp:106] Iteration 61088, lr = 0.0035
I0525 10:26:00.358906 19426 solver.cpp:237] Iteration 61254, loss = 1.10783
I0525 10:26:00.359098 19426 solver.cpp:253]     Train net output #0: loss = 1.10783 (* 1 = 1.10783 loss)
I0525 10:26:00.359115 19426 sgd_solver.cpp:106] Iteration 61254, lr = 0.0035
I0525 10:26:09.182098 19426 solver.cpp:237] Iteration 61420, loss = 1.05667
I0525 10:26:09.182138 19426 solver.cpp:253]     Train net output #0: loss = 1.05667 (* 1 = 1.05667 loss)
I0525 10:26:09.182158 19426 sgd_solver.cpp:106] Iteration 61420, lr = 0.0035
I0525 10:26:18.005012 19426 solver.cpp:237] Iteration 61586, loss = 1.29208
I0525 10:26:18.005053 19426 solver.cpp:253]     Train net output #0: loss = 1.29208 (* 1 = 1.29208 loss)
I0525 10:26:18.005065 19426 sgd_solver.cpp:106] Iteration 61586, lr = 0.0035
I0525 10:26:20.926808 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_61642.caffemodel
I0525 10:26:21.002074 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_61642.solverstate
I0525 10:26:26.895725 19426 solver.cpp:237] Iteration 61752, loss = 1.21066
I0525 10:26:26.895771 19426 solver.cpp:253]     Train net output #0: loss = 1.21066 (* 1 = 1.21066 loss)
I0525 10:26:26.895786 19426 sgd_solver.cpp:106] Iteration 61752, lr = 0.0035
I0525 10:26:35.732121 19426 solver.cpp:237] Iteration 61918, loss = 1.2461
I0525 10:26:35.732311 19426 solver.cpp:253]     Train net output #0: loss = 1.2461 (* 1 = 1.2461 loss)
I0525 10:26:35.732326 19426 sgd_solver.cpp:106] Iteration 61918, lr = 0.0035
I0525 10:26:44.554522 19426 solver.cpp:237] Iteration 62084, loss = 1.01866
I0525 10:26:44.554555 19426 solver.cpp:253]     Train net output #0: loss = 1.01866 (* 1 = 1.01866 loss)
I0525 10:26:44.554572 19426 sgd_solver.cpp:106] Iteration 62084, lr = 0.0035
I0525 10:27:14.232398 19426 solver.cpp:237] Iteration 62250, loss = 1.18945
I0525 10:27:14.232589 19426 solver.cpp:253]     Train net output #0: loss = 1.18945 (* 1 = 1.18945 loss)
I0525 10:27:14.232604 19426 sgd_solver.cpp:106] Iteration 62250, lr = 0.0035
I0525 10:27:23.065137 19426 solver.cpp:237] Iteration 62416, loss = 1.12201
I0525 10:27:23.065179 19426 solver.cpp:253]     Train net output #0: loss = 1.12201 (* 1 = 1.12201 loss)
I0525 10:27:23.065198 19426 sgd_solver.cpp:106] Iteration 62416, lr = 0.0035
I0525 10:27:31.893463 19426 solver.cpp:237] Iteration 62582, loss = 1.19822
I0525 10:27:31.893498 19426 solver.cpp:253]     Train net output #0: loss = 1.19822 (* 1 = 1.19822 loss)
I0525 10:27:31.893512 19426 sgd_solver.cpp:106] Iteration 62582, lr = 0.0035
I0525 10:27:40.722242 19426 solver.cpp:237] Iteration 62748, loss = 1.15106
I0525 10:27:40.722278 19426 solver.cpp:253]     Train net output #0: loss = 1.15106 (* 1 = 1.15106 loss)
I0525 10:27:40.722291 19426 sgd_solver.cpp:106] Iteration 62748, lr = 0.0035
I0525 10:27:49.552855 19426 solver.cpp:237] Iteration 62914, loss = 1.2202
I0525 10:27:49.553055 19426 solver.cpp:253]     Train net output #0: loss = 1.2202 (* 1 = 1.2202 loss)
I0525 10:27:49.553068 19426 sgd_solver.cpp:106] Iteration 62914, lr = 0.0035
I0525 10:27:58.381999 19426 solver.cpp:237] Iteration 63080, loss = 1.47491
I0525 10:27:58.382035 19426 solver.cpp:253]     Train net output #0: loss = 1.47491 (* 1 = 1.47491 loss)
I0525 10:27:58.382050 19426 sgd_solver.cpp:106] Iteration 63080, lr = 0.0035
I0525 10:28:07.213340 19426 solver.cpp:237] Iteration 63246, loss = 1.03604
I0525 10:28:07.213374 19426 solver.cpp:253]     Train net output #0: loss = 1.03604 (* 1 = 1.03604 loss)
I0525 10:28:07.213388 19426 sgd_solver.cpp:106] Iteration 63246, lr = 0.0035
I0525 10:28:10.458608 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_63308.caffemodel
I0525 10:28:10.533201 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_63308.solverstate
I0525 10:28:11.536640 19426 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 10:28:58.392113 19426 solver.cpp:409]     Test net output #0: accuracy = 0.893336
I0525 10:28:58.392305 19426 solver.cpp:409]     Test net output #1: loss = 0.33818 (* 1 = 0.33818 loss)
I0525 10:29:23.730594 19426 solver.cpp:237] Iteration 63412, loss = 1.30417
I0525 10:29:23.730645 19426 solver.cpp:253]     Train net output #0: loss = 1.30417 (* 1 = 1.30417 loss)
I0525 10:29:23.730660 19426 sgd_solver.cpp:106] Iteration 63412, lr = 0.0035
I0525 10:29:32.570252 19426 solver.cpp:237] Iteration 63578, loss = 1.29291
I0525 10:29:32.570442 19426 solver.cpp:253]     Train net output #0: loss = 1.29291 (* 1 = 1.29291 loss)
I0525 10:29:32.570456 19426 sgd_solver.cpp:106] Iteration 63578, lr = 0.0035
I0525 10:29:41.408710 19426 solver.cpp:237] Iteration 63744, loss = 1.0138
I0525 10:29:41.408745 19426 solver.cpp:253]     Train net output #0: loss = 1.0138 (* 1 = 1.0138 loss)
I0525 10:29:41.408759 19426 sgd_solver.cpp:106] Iteration 63744, lr = 0.0035
I0525 10:29:50.252270 19426 solver.cpp:237] Iteration 63910, loss = 1.074
I0525 10:29:50.252318 19426 solver.cpp:253]     Train net output #0: loss = 1.074 (* 1 = 1.074 loss)
I0525 10:29:50.252331 19426 sgd_solver.cpp:106] Iteration 63910, lr = 0.0035
I0525 10:29:59.094547 19426 solver.cpp:237] Iteration 64076, loss = 1.30535
I0525 10:29:59.094583 19426 solver.cpp:253]     Train net output #0: loss = 1.30535 (* 1 = 1.30535 loss)
I0525 10:29:59.094597 19426 sgd_solver.cpp:106] Iteration 64076, lr = 0.0035
I0525 10:30:07.932528 19426 solver.cpp:237] Iteration 64242, loss = 1.13021
I0525 10:30:07.932698 19426 solver.cpp:253]     Train net output #0: loss = 1.13021 (* 1 = 1.13021 loss)
I0525 10:30:07.932711 19426 sgd_solver.cpp:106] Iteration 64242, lr = 0.0035
I0525 10:30:16.777945 19426 solver.cpp:237] Iteration 64408, loss = 1.34352
I0525 10:30:16.777987 19426 solver.cpp:253]     Train net output #0: loss = 1.34352 (* 1 = 1.34352 loss)
I0525 10:30:16.778005 19426 sgd_solver.cpp:106] Iteration 64408, lr = 0.0035
I0525 10:30:46.443979 19426 solver.cpp:237] Iteration 64574, loss = 1.21224
I0525 10:30:46.444171 19426 solver.cpp:253]     Train net output #0: loss = 1.21224 (* 1 = 1.21224 loss)
I0525 10:30:46.444185 19426 sgd_solver.cpp:106] Iteration 64574, lr = 0.0035
I0525 10:30:55.279259 19426 solver.cpp:237] Iteration 64740, loss = 1.05561
I0525 10:30:55.279294 19426 solver.cpp:253]     Train net output #0: loss = 1.05561 (* 1 = 1.05561 loss)
I0525 10:30:55.279309 19426 sgd_solver.cpp:106] Iteration 64740, lr = 0.0035
I0525 10:31:04.116950 19426 solver.cpp:237] Iteration 64906, loss = 1.15378
I0525 10:31:04.117000 19426 solver.cpp:253]     Train net output #0: loss = 1.15378 (* 1 = 1.15378 loss)
I0525 10:31:04.117013 19426 sgd_solver.cpp:106] Iteration 64906, lr = 0.0035
I0525 10:31:07.688791 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_64974.caffemodel
I0525 10:31:07.763777 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_64974.solverstate
I0525 10:31:13.024720 19426 solver.cpp:237] Iteration 65072, loss = 1.28823
I0525 10:31:13.024768 19426 solver.cpp:253]     Train net output #0: loss = 1.28823 (* 1 = 1.28823 loss)
I0525 10:31:13.024785 19426 sgd_solver.cpp:106] Iteration 65072, lr = 0.0035
I0525 10:31:21.872211 19426 solver.cpp:237] Iteration 65238, loss = 1.46381
I0525 10:31:21.872406 19426 solver.cpp:253]     Train net output #0: loss = 1.46381 (* 1 = 1.46381 loss)
I0525 10:31:21.872419 19426 sgd_solver.cpp:106] Iteration 65238, lr = 0.0035
I0525 10:31:30.701007 19426 solver.cpp:237] Iteration 65404, loss = 1.17173
I0525 10:31:30.701059 19426 solver.cpp:253]     Train net output #0: loss = 1.17173 (* 1 = 1.17173 loss)
I0525 10:31:30.701076 19426 sgd_solver.cpp:106] Iteration 65404, lr = 0.0035
I0525 10:32:00.354696 19426 solver.cpp:237] Iteration 65570, loss = 1.20971
I0525 10:32:00.354892 19426 solver.cpp:253]     Train net output #0: loss = 1.20971 (* 1 = 1.20971 loss)
I0525 10:32:00.354907 19426 sgd_solver.cpp:106] Iteration 65570, lr = 0.0035
I0525 10:32:09.189427 19426 solver.cpp:237] Iteration 65736, loss = 1.04463
I0525 10:32:09.189461 19426 solver.cpp:253]     Train net output #0: loss = 1.04463 (* 1 = 1.04463 loss)
I0525 10:32:09.189478 19426 sgd_solver.cpp:106] Iteration 65736, lr = 0.0035
I0525 10:32:18.028509 19426 solver.cpp:237] Iteration 65902, loss = 1.21703
I0525 10:32:18.028545 19426 solver.cpp:253]     Train net output #0: loss = 1.21703 (* 1 = 1.21703 loss)
I0525 10:32:18.028558 19426 sgd_solver.cpp:106] Iteration 65902, lr = 0.0035
I0525 10:32:26.865309 19426 solver.cpp:237] Iteration 66068, loss = 1.32317
I0525 10:32:26.865356 19426 solver.cpp:253]     Train net output #0: loss = 1.32317 (* 1 = 1.32317 loss)
I0525 10:32:26.865370 19426 sgd_solver.cpp:106] Iteration 66068, lr = 0.0035
I0525 10:32:35.701153 19426 solver.cpp:237] Iteration 66234, loss = 1.19896
I0525 10:32:35.701324 19426 solver.cpp:253]     Train net output #0: loss = 1.19896 (* 1 = 1.19896 loss)
I0525 10:32:35.701339 19426 sgd_solver.cpp:106] Iteration 66234, lr = 0.0035
I0525 10:32:44.533725 19426 solver.cpp:237] Iteration 66400, loss = 1.25857
I0525 10:32:44.533774 19426 solver.cpp:253]     Train net output #0: loss = 1.25857 (* 1 = 1.25857 loss)
I0525 10:32:44.533788 19426 sgd_solver.cpp:106] Iteration 66400, lr = 0.0035
I0525 10:32:53.364863 19426 solver.cpp:237] Iteration 66566, loss = 1.08141
I0525 10:32:53.364899 19426 solver.cpp:253]     Train net output #0: loss = 1.08141 (* 1 = 1.08141 loss)
I0525 10:32:53.364912 19426 sgd_solver.cpp:106] Iteration 66566, lr = 0.0035
I0525 10:32:57.253087 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_66640.caffemodel
I0525 10:32:57.328155 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_66640.solverstate
I0525 10:32:58.385839 19426 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 10:34:06.461333 19426 solver.cpp:409]     Test net output #0: accuracy = 0.894335
I0525 10:34:06.461524 19426 solver.cpp:409]     Test net output #1: loss = 0.340391 (* 1 = 0.340391 loss)
I0525 10:34:31.202853 19426 solver.cpp:237] Iteration 66732, loss = 1.05521
I0525 10:34:31.202903 19426 solver.cpp:253]     Train net output #0: loss = 1.05521 (* 1 = 1.05521 loss)
I0525 10:34:31.202919 19426 sgd_solver.cpp:106] Iteration 66732, lr = 0.0035
I0525 10:34:40.038447 19426 solver.cpp:237] Iteration 66898, loss = 1.24823
I0525 10:34:40.038645 19426 solver.cpp:253]     Train net output #0: loss = 1.24823 (* 1 = 1.24823 loss)
I0525 10:34:40.038657 19426 sgd_solver.cpp:106] Iteration 66898, lr = 0.0035
I0525 10:34:48.874219 19426 solver.cpp:237] Iteration 67064, loss = 1.19583
I0525 10:34:48.874267 19426 solver.cpp:253]     Train net output #0: loss = 1.19583 (* 1 = 1.19583 loss)
I0525 10:34:48.874281 19426 sgd_solver.cpp:106] Iteration 67064, lr = 0.0035
I0525 10:34:57.701195 19426 solver.cpp:237] Iteration 67230, loss = 1.27678
I0525 10:34:57.701231 19426 solver.cpp:253]     Train net output #0: loss = 1.27678 (* 1 = 1.27678 loss)
I0525 10:34:57.701246 19426 sgd_solver.cpp:106] Iteration 67230, lr = 0.0035
I0525 10:35:06.520445 19426 solver.cpp:237] Iteration 67396, loss = 1.20641
I0525 10:35:06.520480 19426 solver.cpp:253]     Train net output #0: loss = 1.20641 (* 1 = 1.20641 loss)
I0525 10:35:06.520495 19426 sgd_solver.cpp:106] Iteration 67396, lr = 0.0035
I0525 10:35:15.352936 19426 solver.cpp:237] Iteration 67562, loss = 1.03319
I0525 10:35:15.353121 19426 solver.cpp:253]     Train net output #0: loss = 1.03319 (* 1 = 1.03319 loss)
I0525 10:35:15.353135 19426 sgd_solver.cpp:106] Iteration 67562, lr = 0.0035
I0525 10:35:24.187696 19426 solver.cpp:237] Iteration 67728, loss = 1.28414
I0525 10:35:24.187731 19426 solver.cpp:253]     Train net output #0: loss = 1.28414 (* 1 = 1.28414 loss)
I0525 10:35:24.187747 19426 sgd_solver.cpp:106] Iteration 67728, lr = 0.0035
I0525 10:35:53.833900 19426 solver.cpp:237] Iteration 67894, loss = 1.15249
I0525 10:35:53.834095 19426 solver.cpp:253]     Train net output #0: loss = 1.15249 (* 1 = 1.15249 loss)
I0525 10:35:53.834110 19426 sgd_solver.cpp:106] Iteration 67894, lr = 0.0035
I0525 10:36:02.665236 19426 solver.cpp:237] Iteration 68060, loss = 1.07291
I0525 10:36:02.665271 19426 solver.cpp:253]     Train net output #0: loss = 1.07291 (* 1 = 1.07291 loss)
I0525 10:36:02.665285 19426 sgd_solver.cpp:106] Iteration 68060, lr = 0.0035
I0525 10:36:11.497203 19426 solver.cpp:237] Iteration 68226, loss = 1.2183
I0525 10:36:11.497241 19426 solver.cpp:253]     Train net output #0: loss = 1.2183 (* 1 = 1.2183 loss)
I0525 10:36:11.497254 19426 sgd_solver.cpp:106] Iteration 68226, lr = 0.0035
I0525 10:36:15.705054 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_68306.caffemodel
I0525 10:36:15.778931 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_68306.solverstate
I0525 10:36:20.393600 19426 solver.cpp:237] Iteration 68392, loss = 1.19061
I0525 10:36:20.393647 19426 solver.cpp:253]     Train net output #0: loss = 1.19061 (* 1 = 1.19061 loss)
I0525 10:36:20.393662 19426 sgd_solver.cpp:106] Iteration 68392, lr = 0.0035
I0525 10:36:29.233052 19426 solver.cpp:237] Iteration 68558, loss = 1.14324
I0525 10:36:29.233240 19426 solver.cpp:253]     Train net output #0: loss = 1.14324 (* 1 = 1.14324 loss)
I0525 10:36:29.233254 19426 sgd_solver.cpp:106] Iteration 68558, lr = 0.0035
I0525 10:36:38.063611 19426 solver.cpp:237] Iteration 68724, loss = 1.39181
I0525 10:36:38.063647 19426 solver.cpp:253]     Train net output #0: loss = 1.39181 (* 1 = 1.39181 loss)
I0525 10:36:38.063663 19426 sgd_solver.cpp:106] Iteration 68724, lr = 0.0035
I0525 10:37:07.763775 19426 solver.cpp:237] Iteration 68890, loss = 1.24925
I0525 10:37:07.763974 19426 solver.cpp:253]     Train net output #0: loss = 1.24925 (* 1 = 1.24925 loss)
I0525 10:37:07.763988 19426 sgd_solver.cpp:106] Iteration 68890, lr = 0.0035
I0525 10:37:16.598724 19426 solver.cpp:237] Iteration 69056, loss = 1.24915
I0525 10:37:16.598759 19426 solver.cpp:253]     Train net output #0: loss = 1.24915 (* 1 = 1.24915 loss)
I0525 10:37:16.598775 19426 sgd_solver.cpp:106] Iteration 69056, lr = 0.0035
I0525 10:37:25.419600 19426 solver.cpp:237] Iteration 69222, loss = 0.995249
I0525 10:37:25.419646 19426 solver.cpp:253]     Train net output #0: loss = 0.995249 (* 1 = 0.995249 loss)
I0525 10:37:25.419661 19426 sgd_solver.cpp:106] Iteration 69222, lr = 0.0035
I0525 10:37:34.249495 19426 solver.cpp:237] Iteration 69388, loss = 1.11789
I0525 10:37:34.249531 19426 solver.cpp:253]     Train net output #0: loss = 1.11789 (* 1 = 1.11789 loss)
I0525 10:37:34.249547 19426 sgd_solver.cpp:106] Iteration 69388, lr = 0.0035
I0525 10:37:43.066874 19426 solver.cpp:237] Iteration 69554, loss = 1.02179
I0525 10:37:43.067059 19426 solver.cpp:253]     Train net output #0: loss = 1.02179 (* 1 = 1.02179 loss)
I0525 10:37:43.067072 19426 sgd_solver.cpp:106] Iteration 69554, lr = 0.0035
I0525 10:37:51.902935 19426 solver.cpp:237] Iteration 69720, loss = 1.05121
I0525 10:37:51.902972 19426 solver.cpp:253]     Train net output #0: loss = 1.05121 (* 1 = 1.05121 loss)
I0525 10:37:51.902992 19426 sgd_solver.cpp:106] Iteration 69720, lr = 0.0035
I0525 10:38:00.730046 19426 solver.cpp:237] Iteration 69886, loss = 1.21323
I0525 10:38:00.730082 19426 solver.cpp:253]     Train net output #0: loss = 1.21323 (* 1 = 1.21323 loss)
I0525 10:38:00.730096 19426 sgd_solver.cpp:106] Iteration 69886, lr = 0.0035
I0525 10:38:05.247635 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_69972.caffemodel
I0525 10:38:05.321854 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_69972.solverstate
I0525 10:38:06.430305 19426 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 10:38:53.631969 19426 solver.cpp:409]     Test net output #0: accuracy = 0.894043
I0525 10:38:53.632164 19426 solver.cpp:409]     Test net output #1: loss = 0.325996 (* 1 = 0.325996 loss)
I0525 10:39:17.632724 19426 solver.cpp:237] Iteration 70052, loss = 1.01118
I0525 10:39:17.632773 19426 solver.cpp:253]     Train net output #0: loss = 1.01118 (* 1 = 1.01118 loss)
I0525 10:39:17.632788 19426 sgd_solver.cpp:106] Iteration 70052, lr = 0.0035
I0525 10:39:26.461933 19426 solver.cpp:237] Iteration 70218, loss = 1.21486
I0525 10:39:26.462124 19426 solver.cpp:253]     Train net output #0: loss = 1.21486 (* 1 = 1.21486 loss)
I0525 10:39:26.462139 19426 sgd_solver.cpp:106] Iteration 70218, lr = 0.0035
I0525 10:39:35.276510 19426 solver.cpp:237] Iteration 70384, loss = 1.28942
I0525 10:39:35.276545 19426 solver.cpp:253]     Train net output #0: loss = 1.28942 (* 1 = 1.28942 loss)
I0525 10:39:35.276559 19426 sgd_solver.cpp:106] Iteration 70384, lr = 0.0035
I0525 10:39:44.097317 19426 solver.cpp:237] Iteration 70550, loss = 1.19654
I0525 10:39:44.097353 19426 solver.cpp:253]     Train net output #0: loss = 1.19654 (* 1 = 1.19654 loss)
I0525 10:39:44.097368 19426 sgd_solver.cpp:106] Iteration 70550, lr = 0.0035
I0525 10:39:52.918985 19426 solver.cpp:237] Iteration 70716, loss = 1.03081
I0525 10:39:52.919031 19426 solver.cpp:253]     Train net output #0: loss = 1.03081 (* 1 = 1.03081 loss)
I0525 10:39:52.919045 19426 sgd_solver.cpp:106] Iteration 70716, lr = 0.0035
I0525 10:40:01.737251 19426 solver.cpp:237] Iteration 70882, loss = 1.12944
I0525 10:40:01.737422 19426 solver.cpp:253]     Train net output #0: loss = 1.12944 (* 1 = 1.12944 loss)
I0525 10:40:01.737437 19426 sgd_solver.cpp:106] Iteration 70882, lr = 0.0035
I0525 10:40:10.561252 19426 solver.cpp:237] Iteration 71048, loss = 1.32443
I0525 10:40:10.561286 19426 solver.cpp:253]     Train net output #0: loss = 1.32443 (* 1 = 1.32443 loss)
I0525 10:40:10.561302 19426 sgd_solver.cpp:106] Iteration 71048, lr = 0.0035
I0525 10:40:40.285857 19426 solver.cpp:237] Iteration 71214, loss = 0.88911
I0525 10:40:40.286052 19426 solver.cpp:253]     Train net output #0: loss = 0.88911 (* 1 = 0.88911 loss)
I0525 10:40:40.286067 19426 sgd_solver.cpp:106] Iteration 71214, lr = 0.0035
I0525 10:40:49.110488 19426 solver.cpp:237] Iteration 71380, loss = 1.31883
I0525 10:40:49.110522 19426 solver.cpp:253]     Train net output #0: loss = 1.31883 (* 1 = 1.31883 loss)
I0525 10:40:49.110538 19426 sgd_solver.cpp:106] Iteration 71380, lr = 0.0035
I0525 10:40:57.936602 19426 solver.cpp:237] Iteration 71546, loss = 0.985734
I0525 10:40:57.936640 19426 solver.cpp:253]     Train net output #0: loss = 0.985734 (* 1 = 0.985734 loss)
I0525 10:40:57.936653 19426 sgd_solver.cpp:106] Iteration 71546, lr = 0.0035
I0525 10:41:02.776512 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_71638.caffemodel
I0525 10:41:02.851696 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_71638.solverstate
I0525 10:41:06.833816 19426 solver.cpp:237] Iteration 71712, loss = 1.21703
I0525 10:41:06.833860 19426 solver.cpp:253]     Train net output #0: loss = 1.21703 (* 1 = 1.21703 loss)
I0525 10:41:06.833879 19426 sgd_solver.cpp:106] Iteration 71712, lr = 0.0035
I0525 10:41:15.651310 19426 solver.cpp:237] Iteration 71878, loss = 1.19558
I0525 10:41:15.651509 19426 solver.cpp:253]     Train net output #0: loss = 1.19558 (* 1 = 1.19558 loss)
I0525 10:41:15.651521 19426 sgd_solver.cpp:106] Iteration 71878, lr = 0.0035
I0525 10:41:24.463939 19426 solver.cpp:237] Iteration 72044, loss = 1.28918
I0525 10:41:24.463974 19426 solver.cpp:253]     Train net output #0: loss = 1.28918 (* 1 = 1.28918 loss)
I0525 10:41:24.463990 19426 sgd_solver.cpp:106] Iteration 72044, lr = 0.0035
I0525 10:41:33.283638 19426 solver.cpp:237] Iteration 72210, loss = 1.08373
I0525 10:41:33.283684 19426 solver.cpp:253]     Train net output #0: loss = 1.08373 (* 1 = 1.08373 loss)
I0525 10:41:33.283700 19426 sgd_solver.cpp:106] Iteration 72210, lr = 0.0035
I0525 10:42:02.981262 19426 solver.cpp:237] Iteration 72376, loss = 1.20903
I0525 10:42:02.981461 19426 solver.cpp:253]     Train net output #0: loss = 1.20903 (* 1 = 1.20903 loss)
I0525 10:42:02.981474 19426 sgd_solver.cpp:106] Iteration 72376, lr = 0.0035
I0525 10:42:11.808715 19426 solver.cpp:237] Iteration 72542, loss = 0.997065
I0525 10:42:11.808751 19426 solver.cpp:253]     Train net output #0: loss = 0.997065 (* 1 = 0.997065 loss)
I0525 10:42:11.808768 19426 sgd_solver.cpp:106] Iteration 72542, lr = 0.0035
I0525 10:42:20.628691 19426 solver.cpp:237] Iteration 72708, loss = 1.13139
I0525 10:42:20.628736 19426 solver.cpp:253]     Train net output #0: loss = 1.13139 (* 1 = 1.13139 loss)
I0525 10:42:20.628751 19426 sgd_solver.cpp:106] Iteration 72708, lr = 0.0035
I0525 10:42:29.457438 19426 solver.cpp:237] Iteration 72874, loss = 1.16465
I0525 10:42:29.457473 19426 solver.cpp:253]     Train net output #0: loss = 1.16465 (* 1 = 1.16465 loss)
I0525 10:42:29.457489 19426 sgd_solver.cpp:106] Iteration 72874, lr = 0.0035
I0525 10:42:38.279788 19426 solver.cpp:237] Iteration 73040, loss = 1.15104
I0525 10:42:38.279973 19426 solver.cpp:253]     Train net output #0: loss = 1.15104 (* 1 = 1.15104 loss)
I0525 10:42:38.279985 19426 sgd_solver.cpp:106] Iteration 73040, lr = 0.0035
I0525 10:42:47.089762 19426 solver.cpp:237] Iteration 73206, loss = 1.02323
I0525 10:42:47.089810 19426 solver.cpp:253]     Train net output #0: loss = 1.02323 (* 1 = 1.02323 loss)
I0525 10:42:47.089825 19426 sgd_solver.cpp:106] Iteration 73206, lr = 0.0035
I0525 10:42:52.244988 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_73304.caffemodel
I0525 10:42:52.320338 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_73304.solverstate
I0525 10:42:53.479112 19426 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 10:44:01.554141 19426 solver.cpp:409]     Test net output #0: accuracy = 0.894716
I0525 10:44:01.554352 19426 solver.cpp:409]     Test net output #1: loss = 0.34404 (* 1 = 0.34404 loss)
I0525 10:44:24.877709 19426 solver.cpp:237] Iteration 73372, loss = 1.28307
I0525 10:44:24.877758 19426 solver.cpp:253]     Train net output #0: loss = 1.28307 (* 1 = 1.28307 loss)
I0525 10:44:24.877773 19426 sgd_solver.cpp:106] Iteration 73372, lr = 0.0035
I0525 10:44:33.700379 19426 solver.cpp:237] Iteration 73538, loss = 0.867458
I0525 10:44:33.700563 19426 solver.cpp:253]     Train net output #0: loss = 0.867458 (* 1 = 0.867458 loss)
I0525 10:44:33.700578 19426 sgd_solver.cpp:106] Iteration 73538, lr = 0.0035
I0525 10:44:42.526842 19426 solver.cpp:237] Iteration 73704, loss = 0.980398
I0525 10:44:42.526877 19426 solver.cpp:253]     Train net output #0: loss = 0.980398 (* 1 = 0.980398 loss)
I0525 10:44:42.526895 19426 sgd_solver.cpp:106] Iteration 73704, lr = 0.0035
I0525 10:44:51.355931 19426 solver.cpp:237] Iteration 73870, loss = 1.31531
I0525 10:44:51.355975 19426 solver.cpp:253]     Train net output #0: loss = 1.31531 (* 1 = 1.31531 loss)
I0525 10:44:51.355994 19426 sgd_solver.cpp:106] Iteration 73870, lr = 0.0035
I0525 10:45:00.185189 19426 solver.cpp:237] Iteration 74036, loss = 1.17329
I0525 10:45:00.185223 19426 solver.cpp:253]     Train net output #0: loss = 1.17329 (* 1 = 1.17329 loss)
I0525 10:45:00.185240 19426 sgd_solver.cpp:106] Iteration 74036, lr = 0.0035
I0525 10:45:09.009474 19426 solver.cpp:237] Iteration 74202, loss = 1.07726
I0525 10:45:09.009650 19426 solver.cpp:253]     Train net output #0: loss = 1.07726 (* 1 = 1.07726 loss)
I0525 10:45:09.009665 19426 sgd_solver.cpp:106] Iteration 74202, lr = 0.0035
I0525 10:45:17.845952 19426 solver.cpp:237] Iteration 74368, loss = 1.04965
I0525 10:45:17.845998 19426 solver.cpp:253]     Train net output #0: loss = 1.04965 (* 1 = 1.04965 loss)
I0525 10:45:17.846015 19426 sgd_solver.cpp:106] Iteration 74368, lr = 0.0035
I0525 10:45:47.534481 19426 solver.cpp:237] Iteration 74534, loss = 1.23372
I0525 10:45:47.534682 19426 solver.cpp:253]     Train net output #0: loss = 1.23372 (* 1 = 1.23372 loss)
I0525 10:45:47.534695 19426 sgd_solver.cpp:106] Iteration 74534, lr = 0.0035
I0525 10:45:56.362790 19426 solver.cpp:237] Iteration 74700, loss = 0.927037
I0525 10:45:56.362825 19426 solver.cpp:253]     Train net output #0: loss = 0.927037 (* 1 = 0.927037 loss)
I0525 10:45:56.362843 19426 sgd_solver.cpp:106] Iteration 74700, lr = 0.0035
I0525 10:46:05.181934 19426 solver.cpp:237] Iteration 74866, loss = 1.16187
I0525 10:46:05.181982 19426 solver.cpp:253]     Train net output #0: loss = 1.16187 (* 1 = 1.16187 loss)
I0525 10:46:05.181995 19426 sgd_solver.cpp:106] Iteration 74866, lr = 0.0035
I0525 10:46:10.658318 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_74970.caffemodel
I0525 10:46:10.735208 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_74970.solverstate
I0525 10:46:14.073228 19426 solver.cpp:237] Iteration 75032, loss = 1.09253
I0525 10:46:14.073277 19426 solver.cpp:253]     Train net output #0: loss = 1.09253 (* 1 = 1.09253 loss)
I0525 10:46:14.073293 19426 sgd_solver.cpp:106] Iteration 75032, lr = 0.0035
I0525 10:46:22.898147 19426 solver.cpp:237] Iteration 75198, loss = 1.01347
I0525 10:46:22.898330 19426 solver.cpp:253]     Train net output #0: loss = 1.01347 (* 1 = 1.01347 loss)
I0525 10:46:22.898345 19426 sgd_solver.cpp:106] Iteration 75198, lr = 0.0035
I0525 10:46:31.726060 19426 solver.cpp:237] Iteration 75364, loss = 1.23473
I0525 10:46:31.726109 19426 solver.cpp:253]     Train net output #0: loss = 1.23473 (* 1 = 1.23473 loss)
I0525 10:46:31.726126 19426 sgd_solver.cpp:106] Iteration 75364, lr = 0.0035
I0525 10:46:40.556105 19426 solver.cpp:237] Iteration 75530, loss = 1.18608
I0525 10:46:40.556139 19426 solver.cpp:253]     Train net output #0: loss = 1.18608 (* 1 = 1.18608 loss)
I0525 10:46:40.556157 19426 sgd_solver.cpp:106] Iteration 75530, lr = 0.0035
I0525 10:47:10.247462 19426 solver.cpp:237] Iteration 75696, loss = 1.14124
I0525 10:47:10.247680 19426 solver.cpp:253]     Train net output #0: loss = 1.14124 (* 1 = 1.14124 loss)
I0525 10:47:10.247696 19426 sgd_solver.cpp:106] Iteration 75696, lr = 0.0035
I0525 10:47:19.073663 19426 solver.cpp:237] Iteration 75862, loss = 1.32042
I0525 10:47:19.073712 19426 solver.cpp:253]     Train net output #0: loss = 1.32042 (* 1 = 1.32042 loss)
I0525 10:47:19.073729 19426 sgd_solver.cpp:106] Iteration 75862, lr = 0.0035
I0525 10:47:27.904911 19426 solver.cpp:237] Iteration 76028, loss = 1.10595
I0525 10:47:27.904947 19426 solver.cpp:253]     Train net output #0: loss = 1.10595 (* 1 = 1.10595 loss)
I0525 10:47:27.904963 19426 sgd_solver.cpp:106] Iteration 76028, lr = 0.0035
I0525 10:47:36.733592 19426 solver.cpp:237] Iteration 76194, loss = 0.979133
I0525 10:47:36.733628 19426 solver.cpp:253]     Train net output #0: loss = 0.979133 (* 1 = 0.979133 loss)
I0525 10:47:36.733644 19426 sgd_solver.cpp:106] Iteration 76194, lr = 0.0035
I0525 10:47:45.564399 19426 solver.cpp:237] Iteration 76360, loss = 1.08135
I0525 10:47:45.564596 19426 solver.cpp:253]     Train net output #0: loss = 1.08135 (* 1 = 1.08135 loss)
I0525 10:47:45.564610 19426 sgd_solver.cpp:106] Iteration 76360, lr = 0.0035
I0525 10:47:54.383895 19426 solver.cpp:237] Iteration 76526, loss = 1.19523
I0525 10:47:54.383930 19426 solver.cpp:253]     Train net output #0: loss = 1.19523 (* 1 = 1.19523 loss)
I0525 10:47:54.383949 19426 sgd_solver.cpp:106] Iteration 76526, lr = 0.0035
I0525 10:48:00.174572 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_76636.caffemodel
I0525 10:48:00.249846 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_76636.solverstate
I0525 10:48:01.462291 19426 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 10:48:48.308153 19426 solver.cpp:409]     Test net output #0: accuracy = 0.898517
I0525 10:48:48.308351 19426 solver.cpp:409]     Test net output #1: loss = 0.329576 (* 1 = 0.329576 loss)
I0525 10:49:10.991296 19426 solver.cpp:237] Iteration 76692, loss = 0.942714
I0525 10:49:10.991346 19426 solver.cpp:253]     Train net output #0: loss = 0.942714 (* 1 = 0.942714 loss)
I0525 10:49:10.991360 19426 sgd_solver.cpp:106] Iteration 76692, lr = 0.0035
I0525 10:49:19.819936 19426 solver.cpp:237] Iteration 76858, loss = 1.34177
I0525 10:49:19.820121 19426 solver.cpp:253]     Train net output #0: loss = 1.34177 (* 1 = 1.34177 loss)
I0525 10:49:19.820133 19426 sgd_solver.cpp:106] Iteration 76858, lr = 0.0035
I0525 10:49:28.637441 19426 solver.cpp:237] Iteration 77024, loss = 1.0363
I0525 10:49:28.637485 19426 solver.cpp:253]     Train net output #0: loss = 1.0363 (* 1 = 1.0363 loss)
I0525 10:49:28.637502 19426 sgd_solver.cpp:106] Iteration 77024, lr = 0.0035
I0525 10:49:37.461937 19426 solver.cpp:237] Iteration 77190, loss = 1.1134
I0525 10:49:37.461972 19426 solver.cpp:253]     Train net output #0: loss = 1.1134 (* 1 = 1.1134 loss)
I0525 10:49:37.461988 19426 sgd_solver.cpp:106] Iteration 77190, lr = 0.0035
I0525 10:49:46.277817 19426 solver.cpp:237] Iteration 77356, loss = 0.937727
I0525 10:49:46.277853 19426 solver.cpp:253]     Train net output #0: loss = 0.937727 (* 1 = 0.937727 loss)
I0525 10:49:46.277869 19426 sgd_solver.cpp:106] Iteration 77356, lr = 0.0035
I0525 10:49:55.089462 19426 solver.cpp:237] Iteration 77522, loss = 1.27951
I0525 10:49:55.089653 19426 solver.cpp:253]     Train net output #0: loss = 1.27951 (* 1 = 1.27951 loss)
I0525 10:49:55.089668 19426 sgd_solver.cpp:106] Iteration 77522, lr = 0.0035
I0525 10:50:03.908478 19426 solver.cpp:237] Iteration 77688, loss = 1.128
I0525 10:50:03.908511 19426 solver.cpp:253]     Train net output #0: loss = 1.128 (* 1 = 1.128 loss)
I0525 10:50:03.908527 19426 sgd_solver.cpp:106] Iteration 77688, lr = 0.0035
I0525 10:50:33.547755 19426 solver.cpp:237] Iteration 77854, loss = 1.05795
I0525 10:50:33.547961 19426 solver.cpp:253]     Train net output #0: loss = 1.05795 (* 1 = 1.05795 loss)
I0525 10:50:33.547977 19426 sgd_solver.cpp:106] Iteration 77854, lr = 0.0035
I0525 10:50:42.372390 19426 solver.cpp:237] Iteration 78020, loss = 0.993505
I0525 10:50:42.372433 19426 solver.cpp:253]     Train net output #0: loss = 0.993505 (* 1 = 0.993505 loss)
I0525 10:50:42.372450 19426 sgd_solver.cpp:106] Iteration 78020, lr = 0.0035
I0525 10:50:51.188272 19426 solver.cpp:237] Iteration 78186, loss = 1.00835
I0525 10:50:51.188308 19426 solver.cpp:253]     Train net output #0: loss = 1.00835 (* 1 = 1.00835 loss)
I0525 10:50:51.188323 19426 sgd_solver.cpp:106] Iteration 78186, lr = 0.0035
I0525 10:50:57.299075 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_78302.caffemodel
I0525 10:50:57.374482 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_78302.solverstate
I0525 10:51:00.076616 19426 solver.cpp:237] Iteration 78352, loss = 1.37159
I0525 10:51:00.076661 19426 solver.cpp:253]     Train net output #0: loss = 1.37159 (* 1 = 1.37159 loss)
I0525 10:51:00.076678 19426 sgd_solver.cpp:106] Iteration 78352, lr = 0.0035
I0525 10:51:08.898613 19426 solver.cpp:237] Iteration 78518, loss = 1.05758
I0525 10:51:08.898804 19426 solver.cpp:253]     Train net output #0: loss = 1.05758 (* 1 = 1.05758 loss)
I0525 10:51:08.898818 19426 sgd_solver.cpp:106] Iteration 78518, lr = 0.0035
I0525 10:51:17.713601 19426 solver.cpp:237] Iteration 78684, loss = 1.07737
I0525 10:51:17.713636 19426 solver.cpp:253]     Train net output #0: loss = 1.07737 (* 1 = 1.07737 loss)
I0525 10:51:17.713652 19426 sgd_solver.cpp:106] Iteration 78684, lr = 0.0035
I0525 10:51:26.527539 19426 solver.cpp:237] Iteration 78850, loss = 1.3712
I0525 10:51:26.527575 19426 solver.cpp:253]     Train net output #0: loss = 1.3712 (* 1 = 1.3712 loss)
I0525 10:51:26.527590 19426 sgd_solver.cpp:106] Iteration 78850, lr = 0.0035
I0525 10:51:56.228379 19426 solver.cpp:237] Iteration 79016, loss = 1.22995
I0525 10:51:56.228577 19426 solver.cpp:253]     Train net output #0: loss = 1.22995 (* 1 = 1.22995 loss)
I0525 10:51:56.228591 19426 sgd_solver.cpp:106] Iteration 79016, lr = 0.0035
I0525 10:52:05.052608 19426 solver.cpp:237] Iteration 79182, loss = 1.15373
I0525 10:52:05.052644 19426 solver.cpp:253]     Train net output #0: loss = 1.15373 (* 1 = 1.15373 loss)
I0525 10:52:05.052660 19426 sgd_solver.cpp:106] Iteration 79182, lr = 0.0035
I0525 10:52:13.877562 19426 solver.cpp:237] Iteration 79348, loss = 1.09797
I0525 10:52:13.877599 19426 solver.cpp:253]     Train net output #0: loss = 1.09797 (* 1 = 1.09797 loss)
I0525 10:52:13.877614 19426 sgd_solver.cpp:106] Iteration 79348, lr = 0.0035
I0525 10:52:22.702062 19426 solver.cpp:237] Iteration 79514, loss = 0.915622
I0525 10:52:22.702112 19426 solver.cpp:253]     Train net output #0: loss = 0.915622 (* 1 = 0.915622 loss)
I0525 10:52:22.702126 19426 sgd_solver.cpp:106] Iteration 79514, lr = 0.0035
I0525 10:52:31.519414 19426 solver.cpp:237] Iteration 79680, loss = 1.27595
I0525 10:52:31.519596 19426 solver.cpp:253]     Train net output #0: loss = 1.27595 (* 1 = 1.27595 loss)
I0525 10:52:31.519610 19426 sgd_solver.cpp:106] Iteration 79680, lr = 0.0035
I0525 10:52:40.332844 19426 solver.cpp:237] Iteration 79846, loss = 1.05123
I0525 10:52:40.332877 19426 solver.cpp:253]     Train net output #0: loss = 1.05123 (* 1 = 1.05123 loss)
I0525 10:52:40.332892 19426 sgd_solver.cpp:106] Iteration 79846, lr = 0.0035
I0525 10:52:46.759449 19426 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_79968.caffemodel
I0525 10:52:46.834213 19426 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0035_2016-05-20T15.49.22.429442_iter_79968.solverstate
I0525 10:52:48.098733 19426 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11263117: Caught signal Terminated, sending to application
aprun: Apid 11263117: Caught signal Terminated, sending to application
*** Aborted at 1464188026 (unix time) try "date -d @1464188026" if you are using GNU date ***
aprun: Apid 11263117: Caught signal Terminated, sending to application
aprun: Apid 11263117: Caught signal Terminated, sending to application
PC: @     0x2aaac5e965e5 adler32
*** SIGTERM (@0x4bdf) received by PID 19426 (TID 0x2aaac746f900) from PID 19423; stack trace: ***
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11263117: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7228 exceeded limit 7200
    @     0x2aaac5e965e5 adler32
aprun: Apid 11263117: Caught signal Terminated, sending to application
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaac5e9db3a inflate
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11263117: Caught signal Terminated, sending to application
aprun: Apid 11263117: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 03789] [c8-1c0s6n1] [Wed May 25 10:53:48 2016] PE RANK 0 exit signal Terminated
Application 11263117 exit codes: 143
Application 11263117 resources: utime ~6230s, stime ~988s, Rss ~5332588, inblocks ~16411684, outblocks ~740498
