2811912
I0526 13:34:19.515887 32260 caffe.cpp:184] Using GPUs 0
I0526 13:34:19.957084 32260 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0015
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639.prototxt"
I0526 13:34:19.958793 32260 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639.prototxt
I0526 13:34:19.975054 32260 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 13:34:19.975111 32260 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 13:34:19.975458 32260 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 13:34:19.975641 32260 layer_factory.hpp:77] Creating layer data_hdf5
I0526 13:34:19.975666 32260 net.cpp:106] Creating Layer data_hdf5
I0526 13:34:19.975679 32260 net.cpp:411] data_hdf5 -> data
I0526 13:34:19.975714 32260 net.cpp:411] data_hdf5 -> label
I0526 13:34:19.975746 32260 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 13:34:19.991614 32260 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 13:34:20.007470 32260 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 13:34:41.598690 32260 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 13:34:41.603808 32260 net.cpp:150] Setting up data_hdf5
I0526 13:34:41.603849 32260 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 13:34:41.603863 32260 net.cpp:157] Top shape: 20 (20)
I0526 13:34:41.603873 32260 net.cpp:165] Memory required for data: 508080
I0526 13:34:41.603886 32260 layer_factory.hpp:77] Creating layer conv1
I0526 13:34:41.603921 32260 net.cpp:106] Creating Layer conv1
I0526 13:34:41.603932 32260 net.cpp:454] conv1 <- data
I0526 13:34:41.603955 32260 net.cpp:411] conv1 -> conv1
I0526 13:34:44.365991 32260 net.cpp:150] Setting up conv1
I0526 13:34:44.366039 32260 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:34:44.366050 32260 net.cpp:165] Memory required for data: 6037680
I0526 13:34:44.366080 32260 layer_factory.hpp:77] Creating layer relu1
I0526 13:34:44.366101 32260 net.cpp:106] Creating Layer relu1
I0526 13:34:44.366112 32260 net.cpp:454] relu1 <- conv1
I0526 13:34:44.366127 32260 net.cpp:397] relu1 -> conv1 (in-place)
I0526 13:34:44.366643 32260 net.cpp:150] Setting up relu1
I0526 13:34:44.366659 32260 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:34:44.366669 32260 net.cpp:165] Memory required for data: 11567280
I0526 13:34:44.366680 32260 layer_factory.hpp:77] Creating layer pool1
I0526 13:34:44.366698 32260 net.cpp:106] Creating Layer pool1
I0526 13:34:44.366708 32260 net.cpp:454] pool1 <- conv1
I0526 13:34:44.366721 32260 net.cpp:411] pool1 -> pool1
I0526 13:34:44.366801 32260 net.cpp:150] Setting up pool1
I0526 13:34:44.366816 32260 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 13:34:44.366825 32260 net.cpp:165] Memory required for data: 14332080
I0526 13:34:44.366837 32260 layer_factory.hpp:77] Creating layer conv2
I0526 13:34:44.366858 32260 net.cpp:106] Creating Layer conv2
I0526 13:34:44.366869 32260 net.cpp:454] conv2 <- pool1
I0526 13:34:44.366883 32260 net.cpp:411] conv2 -> conv2
I0526 13:34:44.369604 32260 net.cpp:150] Setting up conv2
I0526 13:34:44.369632 32260 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:34:44.369642 32260 net.cpp:165] Memory required for data: 18306480
I0526 13:34:44.369662 32260 layer_factory.hpp:77] Creating layer relu2
I0526 13:34:44.369676 32260 net.cpp:106] Creating Layer relu2
I0526 13:34:44.369685 32260 net.cpp:454] relu2 <- conv2
I0526 13:34:44.369699 32260 net.cpp:397] relu2 -> conv2 (in-place)
I0526 13:34:44.370041 32260 net.cpp:150] Setting up relu2
I0526 13:34:44.370055 32260 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:34:44.370065 32260 net.cpp:165] Memory required for data: 22280880
I0526 13:34:44.370075 32260 layer_factory.hpp:77] Creating layer pool2
I0526 13:34:44.370088 32260 net.cpp:106] Creating Layer pool2
I0526 13:34:44.370098 32260 net.cpp:454] pool2 <- conv2
I0526 13:34:44.370111 32260 net.cpp:411] pool2 -> pool2
I0526 13:34:44.370193 32260 net.cpp:150] Setting up pool2
I0526 13:34:44.370206 32260 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 13:34:44.370216 32260 net.cpp:165] Memory required for data: 24268080
I0526 13:34:44.370224 32260 layer_factory.hpp:77] Creating layer conv3
I0526 13:34:44.370244 32260 net.cpp:106] Creating Layer conv3
I0526 13:34:44.370254 32260 net.cpp:454] conv3 <- pool2
I0526 13:34:44.370267 32260 net.cpp:411] conv3 -> conv3
I0526 13:34:44.372210 32260 net.cpp:150] Setting up conv3
I0526 13:34:44.372227 32260 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:34:44.372241 32260 net.cpp:165] Memory required for data: 26436400
I0526 13:34:44.372258 32260 layer_factory.hpp:77] Creating layer relu3
I0526 13:34:44.372275 32260 net.cpp:106] Creating Layer relu3
I0526 13:34:44.372285 32260 net.cpp:454] relu3 <- conv3
I0526 13:34:44.372298 32260 net.cpp:397] relu3 -> conv3 (in-place)
I0526 13:34:44.372766 32260 net.cpp:150] Setting up relu3
I0526 13:34:44.372782 32260 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:34:44.372792 32260 net.cpp:165] Memory required for data: 28604720
I0526 13:34:44.372803 32260 layer_factory.hpp:77] Creating layer pool3
I0526 13:34:44.372817 32260 net.cpp:106] Creating Layer pool3
I0526 13:34:44.372825 32260 net.cpp:454] pool3 <- conv3
I0526 13:34:44.372838 32260 net.cpp:411] pool3 -> pool3
I0526 13:34:44.372906 32260 net.cpp:150] Setting up pool3
I0526 13:34:44.372920 32260 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 13:34:44.372930 32260 net.cpp:165] Memory required for data: 29688880
I0526 13:34:44.372936 32260 layer_factory.hpp:77] Creating layer conv4
I0526 13:34:44.372954 32260 net.cpp:106] Creating Layer conv4
I0526 13:34:44.372966 32260 net.cpp:454] conv4 <- pool3
I0526 13:34:44.372979 32260 net.cpp:411] conv4 -> conv4
I0526 13:34:44.375716 32260 net.cpp:150] Setting up conv4
I0526 13:34:44.375744 32260 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:34:44.375756 32260 net.cpp:165] Memory required for data: 30414640
I0526 13:34:44.375771 32260 layer_factory.hpp:77] Creating layer relu4
I0526 13:34:44.375784 32260 net.cpp:106] Creating Layer relu4
I0526 13:34:44.375795 32260 net.cpp:454] relu4 <- conv4
I0526 13:34:44.375808 32260 net.cpp:397] relu4 -> conv4 (in-place)
I0526 13:34:44.376271 32260 net.cpp:150] Setting up relu4
I0526 13:34:44.376286 32260 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:34:44.376296 32260 net.cpp:165] Memory required for data: 31140400
I0526 13:34:44.376307 32260 layer_factory.hpp:77] Creating layer pool4
I0526 13:34:44.376320 32260 net.cpp:106] Creating Layer pool4
I0526 13:34:44.376330 32260 net.cpp:454] pool4 <- conv4
I0526 13:34:44.376343 32260 net.cpp:411] pool4 -> pool4
I0526 13:34:44.376411 32260 net.cpp:150] Setting up pool4
I0526 13:34:44.376425 32260 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 13:34:44.376435 32260 net.cpp:165] Memory required for data: 31503280
I0526 13:34:44.376446 32260 layer_factory.hpp:77] Creating layer ip1
I0526 13:34:44.376463 32260 net.cpp:106] Creating Layer ip1
I0526 13:34:44.376473 32260 net.cpp:454] ip1 <- pool4
I0526 13:34:44.376488 32260 net.cpp:411] ip1 -> ip1
I0526 13:34:44.391978 32260 net.cpp:150] Setting up ip1
I0526 13:34:44.392002 32260 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:34:44.392015 32260 net.cpp:165] Memory required for data: 31518960
I0526 13:34:44.392041 32260 layer_factory.hpp:77] Creating layer relu5
I0526 13:34:44.392056 32260 net.cpp:106] Creating Layer relu5
I0526 13:34:44.392066 32260 net.cpp:454] relu5 <- ip1
I0526 13:34:44.392081 32260 net.cpp:397] relu5 -> ip1 (in-place)
I0526 13:34:44.392421 32260 net.cpp:150] Setting up relu5
I0526 13:34:44.392436 32260 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:34:44.392446 32260 net.cpp:165] Memory required for data: 31534640
I0526 13:34:44.392457 32260 layer_factory.hpp:77] Creating layer drop1
I0526 13:34:44.392479 32260 net.cpp:106] Creating Layer drop1
I0526 13:34:44.392489 32260 net.cpp:454] drop1 <- ip1
I0526 13:34:44.392503 32260 net.cpp:397] drop1 -> ip1 (in-place)
I0526 13:34:44.392561 32260 net.cpp:150] Setting up drop1
I0526 13:34:44.392575 32260 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:34:44.392585 32260 net.cpp:165] Memory required for data: 31550320
I0526 13:34:44.392596 32260 layer_factory.hpp:77] Creating layer ip2
I0526 13:34:44.392613 32260 net.cpp:106] Creating Layer ip2
I0526 13:34:44.392624 32260 net.cpp:454] ip2 <- ip1
I0526 13:34:44.392637 32260 net.cpp:411] ip2 -> ip2
I0526 13:34:44.393100 32260 net.cpp:150] Setting up ip2
I0526 13:34:44.393113 32260 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:34:44.393123 32260 net.cpp:165] Memory required for data: 31558160
I0526 13:34:44.393138 32260 layer_factory.hpp:77] Creating layer relu6
I0526 13:34:44.393151 32260 net.cpp:106] Creating Layer relu6
I0526 13:34:44.393160 32260 net.cpp:454] relu6 <- ip2
I0526 13:34:44.393173 32260 net.cpp:397] relu6 -> ip2 (in-place)
I0526 13:34:44.393689 32260 net.cpp:150] Setting up relu6
I0526 13:34:44.393705 32260 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:34:44.393717 32260 net.cpp:165] Memory required for data: 31566000
I0526 13:34:44.393726 32260 layer_factory.hpp:77] Creating layer drop2
I0526 13:34:44.393739 32260 net.cpp:106] Creating Layer drop2
I0526 13:34:44.393749 32260 net.cpp:454] drop2 <- ip2
I0526 13:34:44.393761 32260 net.cpp:397] drop2 -> ip2 (in-place)
I0526 13:34:44.393803 32260 net.cpp:150] Setting up drop2
I0526 13:34:44.393817 32260 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:34:44.393827 32260 net.cpp:165] Memory required for data: 31573840
I0526 13:34:44.393837 32260 layer_factory.hpp:77] Creating layer ip3
I0526 13:34:44.393851 32260 net.cpp:106] Creating Layer ip3
I0526 13:34:44.393859 32260 net.cpp:454] ip3 <- ip2
I0526 13:34:44.393872 32260 net.cpp:411] ip3 -> ip3
I0526 13:34:44.394093 32260 net.cpp:150] Setting up ip3
I0526 13:34:44.394105 32260 net.cpp:157] Top shape: 20 11 (220)
I0526 13:34:44.394115 32260 net.cpp:165] Memory required for data: 31574720
I0526 13:34:44.394130 32260 layer_factory.hpp:77] Creating layer drop3
I0526 13:34:44.394143 32260 net.cpp:106] Creating Layer drop3
I0526 13:34:44.394153 32260 net.cpp:454] drop3 <- ip3
I0526 13:34:44.394165 32260 net.cpp:397] drop3 -> ip3 (in-place)
I0526 13:34:44.394206 32260 net.cpp:150] Setting up drop3
I0526 13:34:44.394218 32260 net.cpp:157] Top shape: 20 11 (220)
I0526 13:34:44.394228 32260 net.cpp:165] Memory required for data: 31575600
I0526 13:34:44.394237 32260 layer_factory.hpp:77] Creating layer loss
I0526 13:34:44.394258 32260 net.cpp:106] Creating Layer loss
I0526 13:34:44.394268 32260 net.cpp:454] loss <- ip3
I0526 13:34:44.394279 32260 net.cpp:454] loss <- label
I0526 13:34:44.394290 32260 net.cpp:411] loss -> loss
I0526 13:34:44.394309 32260 layer_factory.hpp:77] Creating layer loss
I0526 13:34:44.394943 32260 net.cpp:150] Setting up loss
I0526 13:34:44.394964 32260 net.cpp:157] Top shape: (1)
I0526 13:34:44.394978 32260 net.cpp:160]     with loss weight 1
I0526 13:34:44.395020 32260 net.cpp:165] Memory required for data: 31575604
I0526 13:34:44.395030 32260 net.cpp:226] loss needs backward computation.
I0526 13:34:44.395041 32260 net.cpp:226] drop3 needs backward computation.
I0526 13:34:44.395051 32260 net.cpp:226] ip3 needs backward computation.
I0526 13:34:44.395061 32260 net.cpp:226] drop2 needs backward computation.
I0526 13:34:44.395071 32260 net.cpp:226] relu6 needs backward computation.
I0526 13:34:44.395081 32260 net.cpp:226] ip2 needs backward computation.
I0526 13:34:44.395092 32260 net.cpp:226] drop1 needs backward computation.
I0526 13:34:44.395102 32260 net.cpp:226] relu5 needs backward computation.
I0526 13:34:44.395112 32260 net.cpp:226] ip1 needs backward computation.
I0526 13:34:44.395122 32260 net.cpp:226] pool4 needs backward computation.
I0526 13:34:44.395131 32260 net.cpp:226] relu4 needs backward computation.
I0526 13:34:44.395141 32260 net.cpp:226] conv4 needs backward computation.
I0526 13:34:44.395153 32260 net.cpp:226] pool3 needs backward computation.
I0526 13:34:44.395162 32260 net.cpp:226] relu3 needs backward computation.
I0526 13:34:44.395172 32260 net.cpp:226] conv3 needs backward computation.
I0526 13:34:44.395191 32260 net.cpp:226] pool2 needs backward computation.
I0526 13:34:44.395203 32260 net.cpp:226] relu2 needs backward computation.
I0526 13:34:44.395213 32260 net.cpp:226] conv2 needs backward computation.
I0526 13:34:44.395223 32260 net.cpp:226] pool1 needs backward computation.
I0526 13:34:44.395233 32260 net.cpp:226] relu1 needs backward computation.
I0526 13:34:44.395243 32260 net.cpp:226] conv1 needs backward computation.
I0526 13:34:44.395254 32260 net.cpp:228] data_hdf5 does not need backward computation.
I0526 13:34:44.395264 32260 net.cpp:270] This network produces output loss
I0526 13:34:44.395287 32260 net.cpp:283] Network initialization done.
I0526 13:34:44.397070 32260 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639.prototxt
I0526 13:34:44.397141 32260 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 13:34:44.397496 32260 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 13:34:44.397686 32260 layer_factory.hpp:77] Creating layer data_hdf5
I0526 13:34:44.397701 32260 net.cpp:106] Creating Layer data_hdf5
I0526 13:34:44.397712 32260 net.cpp:411] data_hdf5 -> data
I0526 13:34:44.397729 32260 net.cpp:411] data_hdf5 -> label
I0526 13:34:44.397745 32260 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 13:34:44.414448 32260 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 13:35:05.870445 32260 net.cpp:150] Setting up data_hdf5
I0526 13:35:05.870610 32260 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 13:35:05.870625 32260 net.cpp:157] Top shape: 20 (20)
I0526 13:35:05.870635 32260 net.cpp:165] Memory required for data: 508080
I0526 13:35:05.870649 32260 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 13:35:05.870676 32260 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 13:35:05.870687 32260 net.cpp:454] label_data_hdf5_1_split <- label
I0526 13:35:05.870702 32260 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 13:35:05.870723 32260 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 13:35:05.870798 32260 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 13:35:05.870812 32260 net.cpp:157] Top shape: 20 (20)
I0526 13:35:05.870825 32260 net.cpp:157] Top shape: 20 (20)
I0526 13:35:05.870834 32260 net.cpp:165] Memory required for data: 508240
I0526 13:35:05.870844 32260 layer_factory.hpp:77] Creating layer conv1
I0526 13:35:05.870867 32260 net.cpp:106] Creating Layer conv1
I0526 13:35:05.870877 32260 net.cpp:454] conv1 <- data
I0526 13:35:05.870892 32260 net.cpp:411] conv1 -> conv1
I0526 13:35:05.872817 32260 net.cpp:150] Setting up conv1
I0526 13:35:05.872841 32260 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:35:05.872853 32260 net.cpp:165] Memory required for data: 6037840
I0526 13:35:05.872874 32260 layer_factory.hpp:77] Creating layer relu1
I0526 13:35:05.872889 32260 net.cpp:106] Creating Layer relu1
I0526 13:35:05.872898 32260 net.cpp:454] relu1 <- conv1
I0526 13:35:05.872911 32260 net.cpp:397] relu1 -> conv1 (in-place)
I0526 13:35:05.873407 32260 net.cpp:150] Setting up relu1
I0526 13:35:05.873425 32260 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:35:05.873435 32260 net.cpp:165] Memory required for data: 11567440
I0526 13:35:05.873445 32260 layer_factory.hpp:77] Creating layer pool1
I0526 13:35:05.873461 32260 net.cpp:106] Creating Layer pool1
I0526 13:35:05.873471 32260 net.cpp:454] pool1 <- conv1
I0526 13:35:05.873484 32260 net.cpp:411] pool1 -> pool1
I0526 13:35:05.873559 32260 net.cpp:150] Setting up pool1
I0526 13:35:05.873572 32260 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 13:35:05.873581 32260 net.cpp:165] Memory required for data: 14332240
I0526 13:35:05.873592 32260 layer_factory.hpp:77] Creating layer conv2
I0526 13:35:05.873610 32260 net.cpp:106] Creating Layer conv2
I0526 13:35:05.873620 32260 net.cpp:454] conv2 <- pool1
I0526 13:35:05.873636 32260 net.cpp:411] conv2 -> conv2
I0526 13:35:05.875562 32260 net.cpp:150] Setting up conv2
I0526 13:35:05.875586 32260 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:35:05.875596 32260 net.cpp:165] Memory required for data: 18306640
I0526 13:35:05.875614 32260 layer_factory.hpp:77] Creating layer relu2
I0526 13:35:05.875627 32260 net.cpp:106] Creating Layer relu2
I0526 13:35:05.875638 32260 net.cpp:454] relu2 <- conv2
I0526 13:35:05.875649 32260 net.cpp:397] relu2 -> conv2 (in-place)
I0526 13:35:05.875983 32260 net.cpp:150] Setting up relu2
I0526 13:35:05.875998 32260 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:35:05.876008 32260 net.cpp:165] Memory required for data: 22281040
I0526 13:35:05.876018 32260 layer_factory.hpp:77] Creating layer pool2
I0526 13:35:05.876030 32260 net.cpp:106] Creating Layer pool2
I0526 13:35:05.876039 32260 net.cpp:454] pool2 <- conv2
I0526 13:35:05.876051 32260 net.cpp:411] pool2 -> pool2
I0526 13:35:05.876123 32260 net.cpp:150] Setting up pool2
I0526 13:35:05.876137 32260 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 13:35:05.876147 32260 net.cpp:165] Memory required for data: 24268240
I0526 13:35:05.876157 32260 layer_factory.hpp:77] Creating layer conv3
I0526 13:35:05.876173 32260 net.cpp:106] Creating Layer conv3
I0526 13:35:05.876184 32260 net.cpp:454] conv3 <- pool2
I0526 13:35:05.876199 32260 net.cpp:411] conv3 -> conv3
I0526 13:35:05.878177 32260 net.cpp:150] Setting up conv3
I0526 13:35:05.878201 32260 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:35:05.878212 32260 net.cpp:165] Memory required for data: 26436560
I0526 13:35:05.878231 32260 layer_factory.hpp:77] Creating layer relu3
I0526 13:35:05.878257 32260 net.cpp:106] Creating Layer relu3
I0526 13:35:05.878267 32260 net.cpp:454] relu3 <- conv3
I0526 13:35:05.878279 32260 net.cpp:397] relu3 -> conv3 (in-place)
I0526 13:35:05.878751 32260 net.cpp:150] Setting up relu3
I0526 13:35:05.878767 32260 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:35:05.878777 32260 net.cpp:165] Memory required for data: 28604880
I0526 13:35:05.878787 32260 layer_factory.hpp:77] Creating layer pool3
I0526 13:35:05.878799 32260 net.cpp:106] Creating Layer pool3
I0526 13:35:05.878809 32260 net.cpp:454] pool3 <- conv3
I0526 13:35:05.878823 32260 net.cpp:411] pool3 -> pool3
I0526 13:35:05.878895 32260 net.cpp:150] Setting up pool3
I0526 13:35:05.878907 32260 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 13:35:05.878917 32260 net.cpp:165] Memory required for data: 29689040
I0526 13:35:05.878927 32260 layer_factory.hpp:77] Creating layer conv4
I0526 13:35:05.878947 32260 net.cpp:106] Creating Layer conv4
I0526 13:35:05.878957 32260 net.cpp:454] conv4 <- pool3
I0526 13:35:05.878971 32260 net.cpp:411] conv4 -> conv4
I0526 13:35:05.881019 32260 net.cpp:150] Setting up conv4
I0526 13:35:05.881042 32260 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:35:05.881054 32260 net.cpp:165] Memory required for data: 30414800
I0526 13:35:05.881069 32260 layer_factory.hpp:77] Creating layer relu4
I0526 13:35:05.881083 32260 net.cpp:106] Creating Layer relu4
I0526 13:35:05.881093 32260 net.cpp:454] relu4 <- conv4
I0526 13:35:05.881106 32260 net.cpp:397] relu4 -> conv4 (in-place)
I0526 13:35:05.881575 32260 net.cpp:150] Setting up relu4
I0526 13:35:05.881592 32260 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:35:05.881603 32260 net.cpp:165] Memory required for data: 31140560
I0526 13:35:05.881613 32260 layer_factory.hpp:77] Creating layer pool4
I0526 13:35:05.881625 32260 net.cpp:106] Creating Layer pool4
I0526 13:35:05.881635 32260 net.cpp:454] pool4 <- conv4
I0526 13:35:05.881649 32260 net.cpp:411] pool4 -> pool4
I0526 13:35:05.881721 32260 net.cpp:150] Setting up pool4
I0526 13:35:05.881734 32260 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 13:35:05.881744 32260 net.cpp:165] Memory required for data: 31503440
I0526 13:35:05.881757 32260 layer_factory.hpp:77] Creating layer ip1
I0526 13:35:05.881770 32260 net.cpp:106] Creating Layer ip1
I0526 13:35:05.881780 32260 net.cpp:454] ip1 <- pool4
I0526 13:35:05.881795 32260 net.cpp:411] ip1 -> ip1
I0526 13:35:05.897189 32260 net.cpp:150] Setting up ip1
I0526 13:35:05.897217 32260 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:35:05.897228 32260 net.cpp:165] Memory required for data: 31519120
I0526 13:35:05.897251 32260 layer_factory.hpp:77] Creating layer relu5
I0526 13:35:05.897266 32260 net.cpp:106] Creating Layer relu5
I0526 13:35:05.897276 32260 net.cpp:454] relu5 <- ip1
I0526 13:35:05.897290 32260 net.cpp:397] relu5 -> ip1 (in-place)
I0526 13:35:05.897639 32260 net.cpp:150] Setting up relu5
I0526 13:35:05.897653 32260 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:35:05.897663 32260 net.cpp:165] Memory required for data: 31534800
I0526 13:35:05.897675 32260 layer_factory.hpp:77] Creating layer drop1
I0526 13:35:05.897692 32260 net.cpp:106] Creating Layer drop1
I0526 13:35:05.897702 32260 net.cpp:454] drop1 <- ip1
I0526 13:35:05.897716 32260 net.cpp:397] drop1 -> ip1 (in-place)
I0526 13:35:05.897761 32260 net.cpp:150] Setting up drop1
I0526 13:35:05.897774 32260 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:35:05.897784 32260 net.cpp:165] Memory required for data: 31550480
I0526 13:35:05.897795 32260 layer_factory.hpp:77] Creating layer ip2
I0526 13:35:05.897809 32260 net.cpp:106] Creating Layer ip2
I0526 13:35:05.897819 32260 net.cpp:454] ip2 <- ip1
I0526 13:35:05.897832 32260 net.cpp:411] ip2 -> ip2
I0526 13:35:05.898316 32260 net.cpp:150] Setting up ip2
I0526 13:35:05.898329 32260 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:35:05.898340 32260 net.cpp:165] Memory required for data: 31558320
I0526 13:35:05.898355 32260 layer_factory.hpp:77] Creating layer relu6
I0526 13:35:05.898380 32260 net.cpp:106] Creating Layer relu6
I0526 13:35:05.898391 32260 net.cpp:454] relu6 <- ip2
I0526 13:35:05.898403 32260 net.cpp:397] relu6 -> ip2 (in-place)
I0526 13:35:05.898933 32260 net.cpp:150] Setting up relu6
I0526 13:35:05.898954 32260 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:35:05.898964 32260 net.cpp:165] Memory required for data: 31566160
I0526 13:35:05.898974 32260 layer_factory.hpp:77] Creating layer drop2
I0526 13:35:05.898988 32260 net.cpp:106] Creating Layer drop2
I0526 13:35:05.898998 32260 net.cpp:454] drop2 <- ip2
I0526 13:35:05.899011 32260 net.cpp:397] drop2 -> ip2 (in-place)
I0526 13:35:05.899055 32260 net.cpp:150] Setting up drop2
I0526 13:35:05.899068 32260 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:35:05.899078 32260 net.cpp:165] Memory required for data: 31574000
I0526 13:35:05.899088 32260 layer_factory.hpp:77] Creating layer ip3
I0526 13:35:05.899102 32260 net.cpp:106] Creating Layer ip3
I0526 13:35:05.899112 32260 net.cpp:454] ip3 <- ip2
I0526 13:35:05.899127 32260 net.cpp:411] ip3 -> ip3
I0526 13:35:05.899350 32260 net.cpp:150] Setting up ip3
I0526 13:35:05.899363 32260 net.cpp:157] Top shape: 20 11 (220)
I0526 13:35:05.899374 32260 net.cpp:165] Memory required for data: 31574880
I0526 13:35:05.899389 32260 layer_factory.hpp:77] Creating layer drop3
I0526 13:35:05.899401 32260 net.cpp:106] Creating Layer drop3
I0526 13:35:05.899411 32260 net.cpp:454] drop3 <- ip3
I0526 13:35:05.899425 32260 net.cpp:397] drop3 -> ip3 (in-place)
I0526 13:35:05.899466 32260 net.cpp:150] Setting up drop3
I0526 13:35:05.899478 32260 net.cpp:157] Top shape: 20 11 (220)
I0526 13:35:05.899488 32260 net.cpp:165] Memory required for data: 31575760
I0526 13:35:05.899497 32260 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 13:35:05.899512 32260 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 13:35:05.899520 32260 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 13:35:05.899533 32260 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 13:35:05.899549 32260 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 13:35:05.899622 32260 net.cpp:150] Setting up ip3_drop3_0_split
I0526 13:35:05.899636 32260 net.cpp:157] Top shape: 20 11 (220)
I0526 13:35:05.899647 32260 net.cpp:157] Top shape: 20 11 (220)
I0526 13:35:05.899657 32260 net.cpp:165] Memory required for data: 31577520
I0526 13:35:05.899668 32260 layer_factory.hpp:77] Creating layer accuracy
I0526 13:35:05.899689 32260 net.cpp:106] Creating Layer accuracy
I0526 13:35:05.899698 32260 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 13:35:05.899709 32260 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 13:35:05.899724 32260 net.cpp:411] accuracy -> accuracy
I0526 13:35:05.899747 32260 net.cpp:150] Setting up accuracy
I0526 13:35:05.899760 32260 net.cpp:157] Top shape: (1)
I0526 13:35:05.899770 32260 net.cpp:165] Memory required for data: 31577524
I0526 13:35:05.899780 32260 layer_factory.hpp:77] Creating layer loss
I0526 13:35:05.899792 32260 net.cpp:106] Creating Layer loss
I0526 13:35:05.899803 32260 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 13:35:05.899814 32260 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 13:35:05.899827 32260 net.cpp:411] loss -> loss
I0526 13:35:05.899845 32260 layer_factory.hpp:77] Creating layer loss
I0526 13:35:05.900326 32260 net.cpp:150] Setting up loss
I0526 13:35:05.900339 32260 net.cpp:157] Top shape: (1)
I0526 13:35:05.900349 32260 net.cpp:160]     with loss weight 1
I0526 13:35:05.900367 32260 net.cpp:165] Memory required for data: 31577528
I0526 13:35:05.900377 32260 net.cpp:226] loss needs backward computation.
I0526 13:35:05.900388 32260 net.cpp:228] accuracy does not need backward computation.
I0526 13:35:05.900400 32260 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 13:35:05.900410 32260 net.cpp:226] drop3 needs backward computation.
I0526 13:35:05.900420 32260 net.cpp:226] ip3 needs backward computation.
I0526 13:35:05.900431 32260 net.cpp:226] drop2 needs backward computation.
I0526 13:35:05.900441 32260 net.cpp:226] relu6 needs backward computation.
I0526 13:35:05.900460 32260 net.cpp:226] ip2 needs backward computation.
I0526 13:35:05.900470 32260 net.cpp:226] drop1 needs backward computation.
I0526 13:35:05.900480 32260 net.cpp:226] relu5 needs backward computation.
I0526 13:35:05.900488 32260 net.cpp:226] ip1 needs backward computation.
I0526 13:35:05.900498 32260 net.cpp:226] pool4 needs backward computation.
I0526 13:35:05.900509 32260 net.cpp:226] relu4 needs backward computation.
I0526 13:35:05.900519 32260 net.cpp:226] conv4 needs backward computation.
I0526 13:35:05.900528 32260 net.cpp:226] pool3 needs backward computation.
I0526 13:35:05.900539 32260 net.cpp:226] relu3 needs backward computation.
I0526 13:35:05.900550 32260 net.cpp:226] conv3 needs backward computation.
I0526 13:35:05.900560 32260 net.cpp:226] pool2 needs backward computation.
I0526 13:35:05.900570 32260 net.cpp:226] relu2 needs backward computation.
I0526 13:35:05.900581 32260 net.cpp:226] conv2 needs backward computation.
I0526 13:35:05.900591 32260 net.cpp:226] pool1 needs backward computation.
I0526 13:35:05.900601 32260 net.cpp:226] relu1 needs backward computation.
I0526 13:35:05.900611 32260 net.cpp:226] conv1 needs backward computation.
I0526 13:35:05.900622 32260 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 13:35:05.900635 32260 net.cpp:228] data_hdf5 does not need backward computation.
I0526 13:35:05.900645 32260 net.cpp:270] This network produces output accuracy
I0526 13:35:05.900656 32260 net.cpp:270] This network produces output loss
I0526 13:35:05.900684 32260 net.cpp:283] Network initialization done.
I0526 13:35:05.900816 32260 solver.cpp:60] Solver scaffolding done.
I0526 13:35:05.901963 32260 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_285000.solverstate
I0526 13:35:06.123040 32260 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 13:35:06.128514 32260 caffe.cpp:212] Starting Optimization
I0526 13:35:06.128553 32260 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 13:35:06.128564 32260 solver.cpp:289] Learning Rate Policy: fixed
I0526 13:35:06.129927 32260 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 13:35:59.078583 32260 solver.cpp:409]     Test net output #0: accuracy = 0.896837
I0526 13:35:59.078737 32260 solver.cpp:409]     Test net output #1: loss = 0.324479 (* 1 = 0.324479 loss)
I0526 13:35:59.097877 32260 solver.cpp:237] Iteration 285000, loss = 1.37478
I0526 13:35:59.097924 32260 solver.cpp:253]     Train net output #0: loss = 1.37478 (* 1 = 1.37478 loss)
I0526 13:35:59.097944 32260 sgd_solver.cpp:106] Iteration 285000, lr = 0.0015
I0526 13:36:11.259302 32260 solver.cpp:237] Iteration 285750, loss = 1.21951
I0526 13:36:11.259338 32260 solver.cpp:253]     Train net output #0: loss = 1.21951 (* 1 = 1.21951 loss)
I0526 13:36:11.259351 32260 sgd_solver.cpp:106] Iteration 285750, lr = 0.0015
I0526 13:36:23.454609 32260 solver.cpp:237] Iteration 286500, loss = 0.710464
I0526 13:36:23.454649 32260 solver.cpp:253]     Train net output #0: loss = 0.710464 (* 1 = 0.710464 loss)
I0526 13:36:23.454665 32260 sgd_solver.cpp:106] Iteration 286500, lr = 0.0015
I0526 13:36:35.639575 32260 solver.cpp:237] Iteration 287250, loss = 1.13414
I0526 13:36:35.639720 32260 solver.cpp:253]     Train net output #0: loss = 1.13414 (* 1 = 1.13414 loss)
I0526 13:36:35.639734 32260 sgd_solver.cpp:106] Iteration 287250, lr = 0.0015
I0526 13:36:47.791338 32260 solver.cpp:237] Iteration 288000, loss = 1.23696
I0526 13:36:47.791378 32260 solver.cpp:253]     Train net output #0: loss = 1.23696 (* 1 = 1.23696 loss)
I0526 13:36:47.791393 32260 sgd_solver.cpp:106] Iteration 288000, lr = 0.0015
I0526 13:36:59.950084 32260 solver.cpp:237] Iteration 288750, loss = 1.50575
I0526 13:36:59.950119 32260 solver.cpp:253]     Train net output #0: loss = 1.50575 (* 1 = 1.50575 loss)
I0526 13:36:59.950134 32260 sgd_solver.cpp:106] Iteration 288750, lr = 0.0015
I0526 13:37:12.116624 32260 solver.cpp:237] Iteration 289500, loss = 1.48501
I0526 13:37:12.116766 32260 solver.cpp:253]     Train net output #0: loss = 1.48501 (* 1 = 1.48501 loss)
I0526 13:37:12.116780 32260 sgd_solver.cpp:106] Iteration 289500, lr = 0.0015
I0526 13:37:46.529803 32260 solver.cpp:237] Iteration 290250, loss = 1.24651
I0526 13:37:46.529973 32260 solver.cpp:253]     Train net output #0: loss = 1.24651 (* 1 = 1.24651 loss)
I0526 13:37:46.529989 32260 sgd_solver.cpp:106] Iteration 290250, lr = 0.0015
I0526 13:37:58.709805 32260 solver.cpp:237] Iteration 291000, loss = 1.09759
I0526 13:37:58.709851 32260 solver.cpp:253]     Train net output #0: loss = 1.09759 (* 1 = 1.09759 loss)
I0526 13:37:58.709864 32260 sgd_solver.cpp:106] Iteration 291000, lr = 0.0015
I0526 13:38:10.890542 32260 solver.cpp:237] Iteration 291750, loss = 2.13359
I0526 13:38:10.890578 32260 solver.cpp:253]     Train net output #0: loss = 2.13359 (* 1 = 2.13359 loss)
I0526 13:38:10.890593 32260 sgd_solver.cpp:106] Iteration 291750, lr = 0.0015
I0526 13:38:23.031714 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_292500.caffemodel
I0526 13:38:23.083794 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_292500.solverstate
I0526 13:38:23.115986 32260 solver.cpp:237] Iteration 292500, loss = 0.780342
I0526 13:38:23.116037 32260 solver.cpp:253]     Train net output #0: loss = 0.780342 (* 1 = 0.780342 loss)
I0526 13:38:23.116053 32260 sgd_solver.cpp:106] Iteration 292500, lr = 0.0015
I0526 13:38:35.262542 32260 solver.cpp:237] Iteration 293250, loss = 1.60628
I0526 13:38:35.262579 32260 solver.cpp:253]     Train net output #0: loss = 1.60628 (* 1 = 1.60628 loss)
I0526 13:38:35.262593 32260 sgd_solver.cpp:106] Iteration 293250, lr = 0.0015
I0526 13:38:47.448725 32260 solver.cpp:237] Iteration 294000, loss = 0.854737
I0526 13:38:47.448770 32260 solver.cpp:253]     Train net output #0: loss = 0.854737 (* 1 = 0.854737 loss)
I0526 13:38:47.448784 32260 sgd_solver.cpp:106] Iteration 294000, lr = 0.0015
I0526 13:38:59.649844 32260 solver.cpp:237] Iteration 294750, loss = 0.887204
I0526 13:38:59.649994 32260 solver.cpp:253]     Train net output #0: loss = 0.887204 (* 1 = 0.887204 loss)
I0526 13:38:59.650009 32260 sgd_solver.cpp:106] Iteration 294750, lr = 0.0015
I0526 13:39:34.023162 32260 solver.cpp:237] Iteration 295500, loss = 0.979976
I0526 13:39:34.023334 32260 solver.cpp:253]     Train net output #0: loss = 0.979976 (* 1 = 0.979976 loss)
I0526 13:39:34.023349 32260 sgd_solver.cpp:106] Iteration 295500, lr = 0.0015
I0526 13:39:46.230339 32260 solver.cpp:237] Iteration 296250, loss = 1.07951
I0526 13:39:46.230373 32260 solver.cpp:253]     Train net output #0: loss = 1.07951 (* 1 = 1.07951 loss)
I0526 13:39:46.230386 32260 sgd_solver.cpp:106] Iteration 296250, lr = 0.0015
I0526 13:39:58.434916 32260 solver.cpp:237] Iteration 297000, loss = 1.12359
I0526 13:39:58.434952 32260 solver.cpp:253]     Train net output #0: loss = 1.12359 (* 1 = 1.12359 loss)
I0526 13:39:58.434969 32260 sgd_solver.cpp:106] Iteration 297000, lr = 0.0015
I0526 13:40:10.657634 32260 solver.cpp:237] Iteration 297750, loss = 1.54339
I0526 13:40:10.657769 32260 solver.cpp:253]     Train net output #0: loss = 1.54339 (* 1 = 1.54339 loss)
I0526 13:40:10.657785 32260 sgd_solver.cpp:106] Iteration 297750, lr = 0.0015
I0526 13:40:22.831589 32260 solver.cpp:237] Iteration 298500, loss = 1.21852
I0526 13:40:22.831626 32260 solver.cpp:253]     Train net output #0: loss = 1.21852 (* 1 = 1.21852 loss)
I0526 13:40:22.831642 32260 sgd_solver.cpp:106] Iteration 298500, lr = 0.0015
I0526 13:40:34.994722 32260 solver.cpp:237] Iteration 299250, loss = 1.30049
I0526 13:40:34.994758 32260 solver.cpp:253]     Train net output #0: loss = 1.30049 (* 1 = 1.30049 loss)
I0526 13:40:34.994771 32260 sgd_solver.cpp:106] Iteration 299250, lr = 0.0015
I0526 13:40:47.173458 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_300000.caffemodel
I0526 13:40:47.224067 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_300000.solverstate
I0526 13:40:47.250733 32260 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 13:41:39.236400 32260 solver.cpp:409]     Test net output #0: accuracy = 0.896825
I0526 13:41:39.236559 32260 solver.cpp:409]     Test net output #1: loss = 0.327817 (* 1 = 0.327817 loss)
I0526 13:42:01.423910 32260 solver.cpp:237] Iteration 300000, loss = 0.785462
I0526 13:42:01.423965 32260 solver.cpp:253]     Train net output #0: loss = 0.785462 (* 1 = 0.785462 loss)
I0526 13:42:01.423980 32260 sgd_solver.cpp:106] Iteration 300000, lr = 0.0015
I0526 13:42:13.550890 32260 solver.cpp:237] Iteration 300750, loss = 1.30607
I0526 13:42:13.551055 32260 solver.cpp:253]     Train net output #0: loss = 1.30607 (* 1 = 1.30607 loss)
I0526 13:42:13.551069 32260 sgd_solver.cpp:106] Iteration 300750, lr = 0.0015
I0526 13:42:25.688611 32260 solver.cpp:237] Iteration 301500, loss = 0.701565
I0526 13:42:25.688647 32260 solver.cpp:253]     Train net output #0: loss = 0.701565 (* 1 = 0.701565 loss)
I0526 13:42:25.688659 32260 sgd_solver.cpp:106] Iteration 301500, lr = 0.0015
I0526 13:42:37.828783 32260 solver.cpp:237] Iteration 302250, loss = 1.27921
I0526 13:42:37.828830 32260 solver.cpp:253]     Train net output #0: loss = 1.27921 (* 1 = 1.27921 loss)
I0526 13:42:37.828845 32260 sgd_solver.cpp:106] Iteration 302250, lr = 0.0015
I0526 13:42:49.991153 32260 solver.cpp:237] Iteration 303000, loss = 0.949809
I0526 13:42:49.991293 32260 solver.cpp:253]     Train net output #0: loss = 0.949808 (* 1 = 0.949808 loss)
I0526 13:42:49.991308 32260 sgd_solver.cpp:106] Iteration 303000, lr = 0.0015
I0526 13:43:02.153985 32260 solver.cpp:237] Iteration 303750, loss = 1.75827
I0526 13:43:02.154029 32260 solver.cpp:253]     Train net output #0: loss = 1.75827 (* 1 = 1.75827 loss)
I0526 13:43:02.154042 32260 sgd_solver.cpp:106] Iteration 303750, lr = 0.0015
I0526 13:43:14.313884 32260 solver.cpp:237] Iteration 304500, loss = 0.954953
I0526 13:43:14.313930 32260 solver.cpp:253]     Train net output #0: loss = 0.954953 (* 1 = 0.954953 loss)
I0526 13:43:14.313944 32260 sgd_solver.cpp:106] Iteration 304500, lr = 0.0015
I0526 13:43:48.687726 32260 solver.cpp:237] Iteration 305250, loss = 1.007
I0526 13:43:48.687896 32260 solver.cpp:253]     Train net output #0: loss = 1.007 (* 1 = 1.007 loss)
I0526 13:43:48.687911 32260 sgd_solver.cpp:106] Iteration 305250, lr = 0.0015
I0526 13:44:00.851500 32260 solver.cpp:237] Iteration 306000, loss = 1.02886
I0526 13:44:00.851536 32260 solver.cpp:253]     Train net output #0: loss = 1.02886 (* 1 = 1.02886 loss)
I0526 13:44:00.851549 32260 sgd_solver.cpp:106] Iteration 306000, lr = 0.0015
I0526 13:44:12.994264 32260 solver.cpp:237] Iteration 306750, loss = 1.68191
I0526 13:44:12.994313 32260 solver.cpp:253]     Train net output #0: loss = 1.68192 (* 1 = 1.68192 loss)
I0526 13:44:12.994326 32260 sgd_solver.cpp:106] Iteration 306750, lr = 0.0015
I0526 13:44:25.098958 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_307500.caffemodel
I0526 13:44:25.150916 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_307500.solverstate
I0526 13:44:25.183445 32260 solver.cpp:237] Iteration 307500, loss = 1.14057
I0526 13:44:25.183496 32260 solver.cpp:253]     Train net output #0: loss = 1.14057 (* 1 = 1.14057 loss)
I0526 13:44:25.183511 32260 sgd_solver.cpp:106] Iteration 307500, lr = 0.0015
I0526 13:44:37.275492 32260 solver.cpp:237] Iteration 308250, loss = 1.0026
I0526 13:44:37.275537 32260 solver.cpp:253]     Train net output #0: loss = 1.0026 (* 1 = 1.0026 loss)
I0526 13:44:37.275549 32260 sgd_solver.cpp:106] Iteration 308250, lr = 0.0015
I0526 13:44:49.403105 32260 solver.cpp:237] Iteration 309000, loss = 1.10215
I0526 13:44:49.403141 32260 solver.cpp:253]     Train net output #0: loss = 1.10215 (* 1 = 1.10215 loss)
I0526 13:44:49.403153 32260 sgd_solver.cpp:106] Iteration 309000, lr = 0.0015
I0526 13:45:01.526087 32260 solver.cpp:237] Iteration 309750, loss = 1.29572
I0526 13:45:01.526242 32260 solver.cpp:253]     Train net output #0: loss = 1.29572 (* 1 = 1.29572 loss)
I0526 13:45:01.526255 32260 sgd_solver.cpp:106] Iteration 309750, lr = 0.0015
I0526 13:45:35.858494 32260 solver.cpp:237] Iteration 310500, loss = 0.497774
I0526 13:45:35.858657 32260 solver.cpp:253]     Train net output #0: loss = 0.497775 (* 1 = 0.497775 loss)
I0526 13:45:35.858674 32260 sgd_solver.cpp:106] Iteration 310500, lr = 0.0015
I0526 13:45:47.983518 32260 solver.cpp:237] Iteration 311250, loss = 1.20563
I0526 13:45:47.983561 32260 solver.cpp:253]     Train net output #0: loss = 1.20563 (* 1 = 1.20563 loss)
I0526 13:45:47.983574 32260 sgd_solver.cpp:106] Iteration 311250, lr = 0.0015
I0526 13:46:00.097205 32260 solver.cpp:237] Iteration 312000, loss = 0.986288
I0526 13:46:00.097241 32260 solver.cpp:253]     Train net output #0: loss = 0.986289 (* 1 = 0.986289 loss)
I0526 13:46:00.097255 32260 sgd_solver.cpp:106] Iteration 312000, lr = 0.0015
I0526 13:46:12.209823 32260 solver.cpp:237] Iteration 312750, loss = 1.00107
I0526 13:46:12.209972 32260 solver.cpp:253]     Train net output #0: loss = 1.00107 (* 1 = 1.00107 loss)
I0526 13:46:12.209987 32260 sgd_solver.cpp:106] Iteration 312750, lr = 0.0015
I0526 13:46:24.364753 32260 solver.cpp:237] Iteration 313500, loss = 1.11875
I0526 13:46:24.364789 32260 solver.cpp:253]     Train net output #0: loss = 1.11875 (* 1 = 1.11875 loss)
I0526 13:46:24.364804 32260 sgd_solver.cpp:106] Iteration 313500, lr = 0.0015
I0526 13:46:36.489739 32260 solver.cpp:237] Iteration 314250, loss = 0.82574
I0526 13:46:36.489774 32260 solver.cpp:253]     Train net output #0: loss = 0.825741 (* 1 = 0.825741 loss)
I0526 13:46:36.489789 32260 sgd_solver.cpp:106] Iteration 314250, lr = 0.0015
I0526 13:46:48.566227 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_315000.caffemodel
I0526 13:46:48.628283 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_315000.solverstate
I0526 13:46:48.656167 32260 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 13:48:01.558279 32260 solver.cpp:409]     Test net output #0: accuracy = 0.899644
I0526 13:48:01.558439 32260 solver.cpp:409]     Test net output #1: loss = 0.343244 (* 1 = 0.343244 loss)
I0526 13:48:23.900961 32260 solver.cpp:237] Iteration 315000, loss = 0.765487
I0526 13:48:23.901011 32260 solver.cpp:253]     Train net output #0: loss = 0.765488 (* 1 = 0.765488 loss)
I0526 13:48:23.901031 32260 sgd_solver.cpp:106] Iteration 315000, lr = 0.0015
I0526 13:48:36.017997 32260 solver.cpp:237] Iteration 315750, loss = 0.92197
I0526 13:48:36.018139 32260 solver.cpp:253]     Train net output #0: loss = 0.92197 (* 1 = 0.92197 loss)
I0526 13:48:36.018154 32260 sgd_solver.cpp:106] Iteration 315750, lr = 0.0015
I0526 13:48:48.099264 32260 solver.cpp:237] Iteration 316500, loss = 0.969753
I0526 13:48:48.099308 32260 solver.cpp:253]     Train net output #0: loss = 0.969753 (* 1 = 0.969753 loss)
I0526 13:48:48.099321 32260 sgd_solver.cpp:106] Iteration 316500, lr = 0.0015
I0526 13:49:00.185755 32260 solver.cpp:237] Iteration 317250, loss = 1.1208
I0526 13:49:00.185791 32260 solver.cpp:253]     Train net output #0: loss = 1.1208 (* 1 = 1.1208 loss)
I0526 13:49:00.185804 32260 sgd_solver.cpp:106] Iteration 317250, lr = 0.0015
I0526 13:49:12.270411 32260 solver.cpp:237] Iteration 318000, loss = 1.22021
I0526 13:49:12.270560 32260 solver.cpp:253]     Train net output #0: loss = 1.22021 (* 1 = 1.22021 loss)
I0526 13:49:12.270573 32260 sgd_solver.cpp:106] Iteration 318000, lr = 0.0015
I0526 13:49:24.346240 32260 solver.cpp:237] Iteration 318750, loss = 1.00602
I0526 13:49:24.346276 32260 solver.cpp:253]     Train net output #0: loss = 1.00602 (* 1 = 1.00602 loss)
I0526 13:49:24.346289 32260 sgd_solver.cpp:106] Iteration 318750, lr = 0.0015
I0526 13:49:36.426046 32260 solver.cpp:237] Iteration 319500, loss = 1.49335
I0526 13:49:36.426085 32260 solver.cpp:253]     Train net output #0: loss = 1.49335 (* 1 = 1.49335 loss)
I0526 13:49:36.426100 32260 sgd_solver.cpp:106] Iteration 319500, lr = 0.0015
I0526 13:50:10.879662 32260 solver.cpp:237] Iteration 320250, loss = 1.10884
I0526 13:50:10.879822 32260 solver.cpp:253]     Train net output #0: loss = 1.10884 (* 1 = 1.10884 loss)
I0526 13:50:10.879835 32260 sgd_solver.cpp:106] Iteration 320250, lr = 0.0015
I0526 13:50:23.051745 32260 solver.cpp:237] Iteration 321000, loss = 0.902868
I0526 13:50:23.051789 32260 solver.cpp:253]     Train net output #0: loss = 0.902868 (* 1 = 0.902868 loss)
I0526 13:50:23.051810 32260 sgd_solver.cpp:106] Iteration 321000, lr = 0.0015
I0526 13:50:35.217164 32260 solver.cpp:237] Iteration 321750, loss = 1.22003
I0526 13:50:35.217200 32260 solver.cpp:253]     Train net output #0: loss = 1.22003 (* 1 = 1.22003 loss)
I0526 13:50:35.217213 32260 sgd_solver.cpp:106] Iteration 321750, lr = 0.0015
I0526 13:50:47.381254 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_322500.caffemodel
I0526 13:50:47.432703 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_322500.solverstate
I0526 13:50:47.465170 32260 solver.cpp:237] Iteration 322500, loss = 0.997374
I0526 13:50:47.465219 32260 solver.cpp:253]     Train net output #0: loss = 0.997374 (* 1 = 0.997374 loss)
I0526 13:50:47.465239 32260 sgd_solver.cpp:106] Iteration 322500, lr = 0.0015
I0526 13:50:59.598604 32260 solver.cpp:237] Iteration 323250, loss = 0.995266
I0526 13:50:59.598639 32260 solver.cpp:253]     Train net output #0: loss = 0.995266 (* 1 = 0.995266 loss)
I0526 13:50:59.598654 32260 sgd_solver.cpp:106] Iteration 323250, lr = 0.0015
I0526 13:51:11.707944 32260 solver.cpp:237] Iteration 324000, loss = 1.40567
I0526 13:51:11.707979 32260 solver.cpp:253]     Train net output #0: loss = 1.40567 (* 1 = 1.40567 loss)
I0526 13:51:11.707993 32260 sgd_solver.cpp:106] Iteration 324000, lr = 0.0015
I0526 13:51:23.830922 32260 solver.cpp:237] Iteration 324750, loss = 0.927954
I0526 13:51:23.831095 32260 solver.cpp:253]     Train net output #0: loss = 0.927954 (* 1 = 0.927954 loss)
I0526 13:51:23.831111 32260 sgd_solver.cpp:106] Iteration 324750, lr = 0.0015
I0526 13:51:58.114073 32260 solver.cpp:237] Iteration 325500, loss = 0.78146
I0526 13:51:58.114243 32260 solver.cpp:253]     Train net output #0: loss = 0.78146 (* 1 = 0.78146 loss)
I0526 13:51:58.114259 32260 sgd_solver.cpp:106] Iteration 325500, lr = 0.0015
I0526 13:52:10.222723 32260 solver.cpp:237] Iteration 326250, loss = 1.43727
I0526 13:52:10.222765 32260 solver.cpp:253]     Train net output #0: loss = 1.43727 (* 1 = 1.43727 loss)
I0526 13:52:10.222784 32260 sgd_solver.cpp:106] Iteration 326250, lr = 0.0015
I0526 13:52:22.359730 32260 solver.cpp:237] Iteration 327000, loss = 1.50131
I0526 13:52:22.359766 32260 solver.cpp:253]     Train net output #0: loss = 1.50131 (* 1 = 1.50131 loss)
I0526 13:52:22.359778 32260 sgd_solver.cpp:106] Iteration 327000, lr = 0.0015
I0526 13:52:34.470799 32260 solver.cpp:237] Iteration 327750, loss = 0.922563
I0526 13:52:34.470945 32260 solver.cpp:253]     Train net output #0: loss = 0.922563 (* 1 = 0.922563 loss)
I0526 13:52:34.470959 32260 sgd_solver.cpp:106] Iteration 327750, lr = 0.0015
I0526 13:52:46.602771 32260 solver.cpp:237] Iteration 328500, loss = 0.726796
I0526 13:52:46.602807 32260 solver.cpp:253]     Train net output #0: loss = 0.726796 (* 1 = 0.726796 loss)
I0526 13:52:46.602820 32260 sgd_solver.cpp:106] Iteration 328500, lr = 0.0015
I0526 13:52:58.749999 32260 solver.cpp:237] Iteration 329250, loss = 0.68394
I0526 13:52:58.750047 32260 solver.cpp:253]     Train net output #0: loss = 0.68394 (* 1 = 0.68394 loss)
I0526 13:52:58.750062 32260 sgd_solver.cpp:106] Iteration 329250, lr = 0.0015
I0526 13:53:10.847470 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_330000.caffemodel
I0526 13:53:10.897202 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_330000.solverstate
I0526 13:53:10.922866 32260 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 13:54:02.544327 32260 solver.cpp:409]     Test net output #0: accuracy = 0.902285
I0526 13:54:02.544497 32260 solver.cpp:409]     Test net output #1: loss = 0.320783 (* 1 = 0.320783 loss)
I0526 13:54:24.735914 32260 solver.cpp:237] Iteration 330000, loss = 1.42898
I0526 13:54:24.735965 32260 solver.cpp:253]     Train net output #0: loss = 1.42898 (* 1 = 1.42898 loss)
I0526 13:54:24.735983 32260 sgd_solver.cpp:106] Iteration 330000, lr = 0.0015
I0526 13:54:36.842831 32260 solver.cpp:237] Iteration 330750, loss = 0.990182
I0526 13:54:36.842996 32260 solver.cpp:253]     Train net output #0: loss = 0.990182 (* 1 = 0.990182 loss)
I0526 13:54:36.843011 32260 sgd_solver.cpp:106] Iteration 330750, lr = 0.0015
I0526 13:54:48.906738 32260 solver.cpp:237] Iteration 331500, loss = 1.5542
I0526 13:54:48.906774 32260 solver.cpp:253]     Train net output #0: loss = 1.5542 (* 1 = 1.5542 loss)
I0526 13:54:48.906786 32260 sgd_solver.cpp:106] Iteration 331500, lr = 0.0015
I0526 13:55:00.955996 32260 solver.cpp:237] Iteration 332250, loss = 1.41121
I0526 13:55:00.956040 32260 solver.cpp:253]     Train net output #0: loss = 1.41121 (* 1 = 1.41121 loss)
I0526 13:55:00.956054 32260 sgd_solver.cpp:106] Iteration 332250, lr = 0.0015
I0526 13:55:12.998810 32260 solver.cpp:237] Iteration 333000, loss = 1.72071
I0526 13:55:12.998950 32260 solver.cpp:253]     Train net output #0: loss = 1.72071 (* 1 = 1.72071 loss)
I0526 13:55:12.998965 32260 sgd_solver.cpp:106] Iteration 333000, lr = 0.0015
I0526 13:55:25.044529 32260 solver.cpp:237] Iteration 333750, loss = 0.978167
I0526 13:55:25.044577 32260 solver.cpp:253]     Train net output #0: loss = 0.978167 (* 1 = 0.978167 loss)
I0526 13:55:25.044592 32260 sgd_solver.cpp:106] Iteration 333750, lr = 0.0015
I0526 13:55:37.086515 32260 solver.cpp:237] Iteration 334500, loss = 0.976883
I0526 13:55:37.086552 32260 solver.cpp:253]     Train net output #0: loss = 0.976883 (* 1 = 0.976883 loss)
I0526 13:55:37.086565 32260 sgd_solver.cpp:106] Iteration 334500, lr = 0.0015
I0526 13:56:11.335479 32260 solver.cpp:237] Iteration 335250, loss = 0.943754
I0526 13:56:11.335654 32260 solver.cpp:253]     Train net output #0: loss = 0.943754 (* 1 = 0.943754 loss)
I0526 13:56:11.335669 32260 sgd_solver.cpp:106] Iteration 335250, lr = 0.0015
I0526 13:56:23.382916 32260 solver.cpp:237] Iteration 336000, loss = 0.922561
I0526 13:56:23.382957 32260 solver.cpp:253]     Train net output #0: loss = 0.922561 (* 1 = 0.922561 loss)
I0526 13:56:23.382972 32260 sgd_solver.cpp:106] Iteration 336000, lr = 0.0015
I0526 13:56:35.430660 32260 solver.cpp:237] Iteration 336750, loss = 1.23011
I0526 13:56:35.430694 32260 solver.cpp:253]     Train net output #0: loss = 1.23011 (* 1 = 1.23011 loss)
I0526 13:56:35.430707 32260 sgd_solver.cpp:106] Iteration 336750, lr = 0.0015
I0526 13:56:47.532188 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_337500.caffemodel
I0526 13:56:47.581365 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_337500.solverstate
I0526 13:56:47.611379 32260 solver.cpp:237] Iteration 337500, loss = 0.822099
I0526 13:56:47.611430 32260 solver.cpp:253]     Train net output #0: loss = 0.822099 (* 1 = 0.822099 loss)
I0526 13:56:47.611444 32260 sgd_solver.cpp:106] Iteration 337500, lr = 0.0015
I0526 13:56:59.756548 32260 solver.cpp:237] Iteration 338250, loss = 1.18917
I0526 13:56:59.756585 32260 solver.cpp:253]     Train net output #0: loss = 1.18917 (* 1 = 1.18917 loss)
I0526 13:56:59.756599 32260 sgd_solver.cpp:106] Iteration 338250, lr = 0.0015
I0526 13:57:11.864123 32260 solver.cpp:237] Iteration 339000, loss = 1.0413
I0526 13:57:11.864169 32260 solver.cpp:253]     Train net output #0: loss = 1.0413 (* 1 = 1.0413 loss)
I0526 13:57:11.864183 32260 sgd_solver.cpp:106] Iteration 339000, lr = 0.0015
I0526 13:57:23.936576 32260 solver.cpp:237] Iteration 339750, loss = 1.18974
I0526 13:57:23.936723 32260 solver.cpp:253]     Train net output #0: loss = 1.18974 (* 1 = 1.18974 loss)
I0526 13:57:23.936738 32260 sgd_solver.cpp:106] Iteration 339750, lr = 0.0015
I0526 13:57:58.261822 32260 solver.cpp:237] Iteration 340500, loss = 1.15589
I0526 13:57:58.261993 32260 solver.cpp:253]     Train net output #0: loss = 1.15589 (* 1 = 1.15589 loss)
I0526 13:57:58.262008 32260 sgd_solver.cpp:106] Iteration 340500, lr = 0.0015
I0526 13:58:10.299799 32260 solver.cpp:237] Iteration 341250, loss = 2.28591
I0526 13:58:10.299836 32260 solver.cpp:253]     Train net output #0: loss = 2.28591 (* 1 = 2.28591 loss)
I0526 13:58:10.299849 32260 sgd_solver.cpp:106] Iteration 341250, lr = 0.0015
I0526 13:58:22.390928 32260 solver.cpp:237] Iteration 342000, loss = 1.21909
I0526 13:58:22.390970 32260 solver.cpp:253]     Train net output #0: loss = 1.21909 (* 1 = 1.21909 loss)
I0526 13:58:22.390983 32260 sgd_solver.cpp:106] Iteration 342000, lr = 0.0015
I0526 13:58:34.572340 32260 solver.cpp:237] Iteration 342750, loss = 0.8435
I0526 13:58:34.572480 32260 solver.cpp:253]     Train net output #0: loss = 0.843499 (* 1 = 0.843499 loss)
I0526 13:58:34.572495 32260 sgd_solver.cpp:106] Iteration 342750, lr = 0.0015
I0526 13:58:46.760504 32260 solver.cpp:237] Iteration 343500, loss = 0.820449
I0526 13:58:46.760550 32260 solver.cpp:253]     Train net output #0: loss = 0.820449 (* 1 = 0.820449 loss)
I0526 13:58:46.760563 32260 sgd_solver.cpp:106] Iteration 343500, lr = 0.0015
I0526 13:58:58.945130 32260 solver.cpp:237] Iteration 344250, loss = 1.07563
I0526 13:58:58.945166 32260 solver.cpp:253]     Train net output #0: loss = 1.07563 (* 1 = 1.07563 loss)
I0526 13:58:58.945179 32260 sgd_solver.cpp:106] Iteration 344250, lr = 0.0015
I0526 13:59:11.139667 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_345000.caffemodel
I0526 13:59:11.188750 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_345000.solverstate
I0526 13:59:11.214280 32260 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 14:00:24.002996 32260 solver.cpp:409]     Test net output #0: accuracy = 0.899905
I0526 14:00:24.003160 32260 solver.cpp:409]     Test net output #1: loss = 0.312179 (* 1 = 0.312179 loss)
I0526 14:00:58.006608 32260 solver.cpp:237] Iteration 345000, loss = 1.81437
I0526 14:00:58.006788 32260 solver.cpp:253]     Train net output #0: loss = 1.81437 (* 1 = 1.81437 loss)
I0526 14:00:58.006803 32260 sgd_solver.cpp:106] Iteration 345000, lr = 0.0015
I0526 14:01:10.125980 32260 solver.cpp:237] Iteration 345750, loss = 1.08815
I0526 14:01:10.126016 32260 solver.cpp:253]     Train net output #0: loss = 1.08815 (* 1 = 1.08815 loss)
I0526 14:01:10.126030 32260 sgd_solver.cpp:106] Iteration 345750, lr = 0.0015
I0526 14:01:22.252862 32260 solver.cpp:237] Iteration 346500, loss = 1.00659
I0526 14:01:22.252903 32260 solver.cpp:253]     Train net output #0: loss = 1.00659 (* 1 = 1.00659 loss)
I0526 14:01:22.252918 32260 sgd_solver.cpp:106] Iteration 346500, lr = 0.0015
I0526 14:01:34.405705 32260 solver.cpp:237] Iteration 347250, loss = 0.991851
I0526 14:01:34.405849 32260 solver.cpp:253]     Train net output #0: loss = 0.99185 (* 1 = 0.99185 loss)
I0526 14:01:34.405864 32260 sgd_solver.cpp:106] Iteration 347250, lr = 0.0015
I0526 14:01:46.612352 32260 solver.cpp:237] Iteration 348000, loss = 1.19234
I0526 14:01:46.612399 32260 solver.cpp:253]     Train net output #0: loss = 1.19234 (* 1 = 1.19234 loss)
I0526 14:01:46.612413 32260 sgd_solver.cpp:106] Iteration 348000, lr = 0.0015
I0526 14:01:58.762156 32260 solver.cpp:237] Iteration 348750, loss = 1.08861
I0526 14:01:58.762192 32260 solver.cpp:253]     Train net output #0: loss = 1.08861 (* 1 = 1.08861 loss)
I0526 14:01:58.762204 32260 sgd_solver.cpp:106] Iteration 348750, lr = 0.0015
I0526 14:02:10.897821 32260 solver.cpp:237] Iteration 349500, loss = 0.795979
I0526 14:02:10.898002 32260 solver.cpp:253]     Train net output #0: loss = 0.795978 (* 1 = 0.795978 loss)
I0526 14:02:10.898018 32260 sgd_solver.cpp:106] Iteration 349500, lr = 0.0015
I0526 14:04:01.722800 32260 solver.cpp:237] Iteration 350250, loss = 1.00763
I0526 14:04:01.722972 32260 solver.cpp:253]     Train net output #0: loss = 1.00763 (* 1 = 1.00763 loss)
I0526 14:04:01.722988 32260 sgd_solver.cpp:106] Iteration 350250, lr = 0.0015
I0526 14:04:13.859104 32260 solver.cpp:237] Iteration 351000, loss = 0.613042
I0526 14:04:13.859153 32260 solver.cpp:253]     Train net output #0: loss = 0.61304 (* 1 = 0.61304 loss)
I0526 14:04:13.859166 32260 sgd_solver.cpp:106] Iteration 351000, lr = 0.0015
I0526 14:04:26.003271 32260 solver.cpp:237] Iteration 351750, loss = 1.33034
I0526 14:04:26.003307 32260 solver.cpp:253]     Train net output #0: loss = 1.33033 (* 1 = 1.33033 loss)
I0526 14:04:26.003320 32260 sgd_solver.cpp:106] Iteration 351750, lr = 0.0015
I0526 14:04:38.130950 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_352500.caffemodel
I0526 14:04:38.182669 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_352500.solverstate
I0526 14:04:38.215315 32260 solver.cpp:237] Iteration 352500, loss = 1.64404
I0526 14:04:38.215365 32260 solver.cpp:253]     Train net output #0: loss = 1.64404 (* 1 = 1.64404 loss)
I0526 14:04:38.215380 32260 sgd_solver.cpp:106] Iteration 352500, lr = 0.0015
I0526 14:04:50.337975 32260 solver.cpp:237] Iteration 353250, loss = 0.946069
I0526 14:04:50.338011 32260 solver.cpp:253]     Train net output #0: loss = 0.946067 (* 1 = 0.946067 loss)
I0526 14:04:50.338026 32260 sgd_solver.cpp:106] Iteration 353250, lr = 0.0015
I0526 14:05:02.486615 32260 solver.cpp:237] Iteration 354000, loss = 1.63051
I0526 14:05:02.486665 32260 solver.cpp:253]     Train net output #0: loss = 1.63051 (* 1 = 1.63051 loss)
I0526 14:05:02.486681 32260 sgd_solver.cpp:106] Iteration 354000, lr = 0.0015
I0526 14:05:14.597659 32260 solver.cpp:237] Iteration 354750, loss = 1.01461
I0526 14:05:14.597831 32260 solver.cpp:253]     Train net output #0: loss = 1.01461 (* 1 = 1.01461 loss)
I0526 14:05:14.597846 32260 sgd_solver.cpp:106] Iteration 354750, lr = 0.0015
I0526 14:05:48.923399 32260 solver.cpp:237] Iteration 355500, loss = 1.26739
I0526 14:05:48.923585 32260 solver.cpp:253]     Train net output #0: loss = 1.26739 (* 1 = 1.26739 loss)
I0526 14:05:48.923599 32260 sgd_solver.cpp:106] Iteration 355500, lr = 0.0015
I0526 14:06:01.076138 32260 solver.cpp:237] Iteration 356250, loss = 1.13772
I0526 14:06:01.076169 32260 solver.cpp:253]     Train net output #0: loss = 1.13772 (* 1 = 1.13772 loss)
I0526 14:06:01.076181 32260 sgd_solver.cpp:106] Iteration 356250, lr = 0.0015
I0526 14:06:13.215672 32260 solver.cpp:237] Iteration 357000, loss = 0.971943
I0526 14:06:13.215714 32260 solver.cpp:253]     Train net output #0: loss = 0.971941 (* 1 = 0.971941 loss)
I0526 14:06:13.215730 32260 sgd_solver.cpp:106] Iteration 357000, lr = 0.0015
I0526 14:06:25.427644 32260 solver.cpp:237] Iteration 357750, loss = 0.987691
I0526 14:06:25.427788 32260 solver.cpp:253]     Train net output #0: loss = 0.987689 (* 1 = 0.987689 loss)
I0526 14:06:25.427803 32260 sgd_solver.cpp:106] Iteration 357750, lr = 0.0015
I0526 14:06:37.638231 32260 solver.cpp:237] Iteration 358500, loss = 1.26008
I0526 14:06:37.638279 32260 solver.cpp:253]     Train net output #0: loss = 1.26008 (* 1 = 1.26008 loss)
I0526 14:06:37.638293 32260 sgd_solver.cpp:106] Iteration 358500, lr = 0.0015
I0526 14:06:49.787858 32260 solver.cpp:237] Iteration 359250, loss = 1.11299
I0526 14:06:49.787894 32260 solver.cpp:253]     Train net output #0: loss = 1.11298 (* 1 = 1.11298 loss)
I0526 14:06:49.787907 32260 sgd_solver.cpp:106] Iteration 359250, lr = 0.0015
I0526 14:07:01.919003 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_360000.caffemodel
I0526 14:07:01.970970 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_360000.solverstate
I0526 14:07:01.998708 32260 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 14:07:54.045186 32260 solver.cpp:409]     Test net output #0: accuracy = 0.901576
I0526 14:07:54.045359 32260 solver.cpp:409]     Test net output #1: loss = 0.30666 (* 1 = 0.30666 loss)
I0526 14:08:14.952780 32260 solver.cpp:237] Iteration 360000, loss = 1.09883
I0526 14:08:14.952831 32260 solver.cpp:253]     Train net output #0: loss = 1.09882 (* 1 = 1.09882 loss)
I0526 14:08:14.952847 32260 sgd_solver.cpp:106] Iteration 360000, lr = 0.0015
I0526 14:08:27.205122 32260 solver.cpp:237] Iteration 360750, loss = 1.0582
I0526 14:08:27.205287 32260 solver.cpp:253]     Train net output #0: loss = 1.0582 (* 1 = 1.0582 loss)
I0526 14:08:27.205302 32260 sgd_solver.cpp:106] Iteration 360750, lr = 0.0015
I0526 14:08:39.452523 32260 solver.cpp:237] Iteration 361500, loss = 0.839407
I0526 14:08:39.452559 32260 solver.cpp:253]     Train net output #0: loss = 0.839405 (* 1 = 0.839405 loss)
I0526 14:08:39.452575 32260 sgd_solver.cpp:106] Iteration 361500, lr = 0.0015
I0526 14:08:51.718303 32260 solver.cpp:237] Iteration 362250, loss = 1.30284
I0526 14:08:51.718350 32260 solver.cpp:253]     Train net output #0: loss = 1.30284 (* 1 = 1.30284 loss)
I0526 14:08:51.718364 32260 sgd_solver.cpp:106] Iteration 362250, lr = 0.0015
I0526 14:09:03.967766 32260 solver.cpp:237] Iteration 363000, loss = 1.09637
I0526 14:09:03.967921 32260 solver.cpp:253]     Train net output #0: loss = 1.09637 (* 1 = 1.09637 loss)
I0526 14:09:03.967936 32260 sgd_solver.cpp:106] Iteration 363000, lr = 0.0015
I0526 14:09:16.189105 32260 solver.cpp:237] Iteration 363750, loss = 1.0008
I0526 14:09:16.189151 32260 solver.cpp:253]     Train net output #0: loss = 1.00079 (* 1 = 1.00079 loss)
I0526 14:09:16.189164 32260 sgd_solver.cpp:106] Iteration 363750, lr = 0.0015
I0526 14:09:28.354547 32260 solver.cpp:237] Iteration 364500, loss = 1.23671
I0526 14:09:28.354584 32260 solver.cpp:253]     Train net output #0: loss = 1.23671 (* 1 = 1.23671 loss)
I0526 14:09:28.354598 32260 sgd_solver.cpp:106] Iteration 364500, lr = 0.0015
I0526 14:10:01.393436 32260 solver.cpp:237] Iteration 365250, loss = 0.953653
I0526 14:10:01.393607 32260 solver.cpp:253]     Train net output #0: loss = 0.953652 (* 1 = 0.953652 loss)
I0526 14:10:01.393622 32260 sgd_solver.cpp:106] Iteration 365250, lr = 0.0015
I0526 14:10:13.562320 32260 solver.cpp:237] Iteration 366000, loss = 1.0797
I0526 14:10:13.562356 32260 solver.cpp:253]     Train net output #0: loss = 1.0797 (* 1 = 1.0797 loss)
I0526 14:10:13.562369 32260 sgd_solver.cpp:106] Iteration 366000, lr = 0.0015
I0526 14:10:25.762665 32260 solver.cpp:237] Iteration 366750, loss = 1.29162
I0526 14:10:25.762712 32260 solver.cpp:253]     Train net output #0: loss = 1.29162 (* 1 = 1.29162 loss)
I0526 14:10:25.762727 32260 sgd_solver.cpp:106] Iteration 366750, lr = 0.0015
I0526 14:10:37.968152 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_367500.caffemodel
I0526 14:10:38.017945 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_367500.solverstate
I0526 14:10:38.048498 32260 solver.cpp:237] Iteration 367500, loss = 1.08644
I0526 14:10:38.048544 32260 solver.cpp:253]     Train net output #0: loss = 1.08644 (* 1 = 1.08644 loss)
I0526 14:10:38.048558 32260 sgd_solver.cpp:106] Iteration 367500, lr = 0.0015
I0526 14:10:50.225975 32260 solver.cpp:237] Iteration 368250, loss = 1.61176
I0526 14:10:50.226017 32260 solver.cpp:253]     Train net output #0: loss = 1.61176 (* 1 = 1.61176 loss)
I0526 14:10:50.226033 32260 sgd_solver.cpp:106] Iteration 368250, lr = 0.0015
I0526 14:11:02.430699 32260 solver.cpp:237] Iteration 369000, loss = 0.850434
I0526 14:11:02.430737 32260 solver.cpp:253]     Train net output #0: loss = 0.850432 (* 1 = 0.850432 loss)
I0526 14:11:02.430749 32260 sgd_solver.cpp:106] Iteration 369000, lr = 0.0015
I0526 14:11:14.677050 32260 solver.cpp:237] Iteration 369750, loss = 1.09291
I0526 14:11:14.677212 32260 solver.cpp:253]     Train net output #0: loss = 1.09291 (* 1 = 1.09291 loss)
I0526 14:11:14.677227 32260 sgd_solver.cpp:106] Iteration 369750, lr = 0.0015
I0526 14:11:47.777815 32260 solver.cpp:237] Iteration 370500, loss = 0.982791
I0526 14:11:47.777979 32260 solver.cpp:253]     Train net output #0: loss = 0.982789 (* 1 = 0.982789 loss)
I0526 14:11:47.777994 32260 sgd_solver.cpp:106] Iteration 370500, lr = 0.0015
I0526 14:12:00.003968 32260 solver.cpp:237] Iteration 371250, loss = 0.958978
I0526 14:12:00.004005 32260 solver.cpp:253]     Train net output #0: loss = 0.958977 (* 1 = 0.958977 loss)
I0526 14:12:00.004021 32260 sgd_solver.cpp:106] Iteration 371250, lr = 0.0015
I0526 14:12:12.221078 32260 solver.cpp:237] Iteration 372000, loss = 0.653804
I0526 14:12:12.221122 32260 solver.cpp:253]     Train net output #0: loss = 0.653803 (* 1 = 0.653803 loss)
I0526 14:12:12.221137 32260 sgd_solver.cpp:106] Iteration 372000, lr = 0.0015
I0526 14:12:24.394861 32260 solver.cpp:237] Iteration 372750, loss = 0.930328
I0526 14:12:24.395018 32260 solver.cpp:253]     Train net output #0: loss = 0.930326 (* 1 = 0.930326 loss)
I0526 14:12:24.395033 32260 sgd_solver.cpp:106] Iteration 372750, lr = 0.0015
I0526 14:12:36.611307 32260 solver.cpp:237] Iteration 373500, loss = 0.974386
I0526 14:12:36.611352 32260 solver.cpp:253]     Train net output #0: loss = 0.974385 (* 1 = 0.974385 loss)
I0526 14:12:36.611366 32260 sgd_solver.cpp:106] Iteration 373500, lr = 0.0015
I0526 14:12:48.821727 32260 solver.cpp:237] Iteration 374250, loss = 0.790885
I0526 14:12:48.821763 32260 solver.cpp:253]     Train net output #0: loss = 0.790884 (* 1 = 0.790884 loss)
I0526 14:12:48.821776 32260 sgd_solver.cpp:106] Iteration 374250, lr = 0.0015
I0526 14:13:01.018049 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_375000.caffemodel
I0526 14:13:01.067482 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_375000.solverstate
I0526 14:13:01.092701 32260 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 14:14:14.006175 32260 solver.cpp:409]     Test net output #0: accuracy = 0.902478
I0526 14:14:14.006338 32260 solver.cpp:409]     Test net output #1: loss = 0.314726 (* 1 = 0.314726 loss)
I0526 14:14:34.880529 32260 solver.cpp:237] Iteration 375000, loss = 0.998923
I0526 14:14:34.880583 32260 solver.cpp:253]     Train net output #0: loss = 0.998922 (* 1 = 0.998922 loss)
I0526 14:14:34.880597 32260 sgd_solver.cpp:106] Iteration 375000, lr = 0.0015
I0526 14:14:47.015450 32260 solver.cpp:237] Iteration 375750, loss = 1.08944
I0526 14:14:47.015600 32260 solver.cpp:253]     Train net output #0: loss = 1.08944 (* 1 = 1.08944 loss)
I0526 14:14:47.015614 32260 sgd_solver.cpp:106] Iteration 375750, lr = 0.0015
I0526 14:14:59.132884 32260 solver.cpp:237] Iteration 376500, loss = 1.17801
I0526 14:14:59.132930 32260 solver.cpp:253]     Train net output #0: loss = 1.17801 (* 1 = 1.17801 loss)
I0526 14:14:59.132946 32260 sgd_solver.cpp:106] Iteration 376500, lr = 0.0015
I0526 14:15:11.229296 32260 solver.cpp:237] Iteration 377250, loss = 1.409
I0526 14:15:11.229332 32260 solver.cpp:253]     Train net output #0: loss = 1.409 (* 1 = 1.409 loss)
I0526 14:15:11.229346 32260 sgd_solver.cpp:106] Iteration 377250, lr = 0.0015
I0526 14:15:23.350602 32260 solver.cpp:237] Iteration 378000, loss = 0.689864
I0526 14:15:23.350772 32260 solver.cpp:253]     Train net output #0: loss = 0.689863 (* 1 = 0.689863 loss)
I0526 14:15:23.350787 32260 sgd_solver.cpp:106] Iteration 378000, lr = 0.0015
I0526 14:15:35.475397 32260 solver.cpp:237] Iteration 378750, loss = 1.3311
I0526 14:15:35.475432 32260 solver.cpp:253]     Train net output #0: loss = 1.3311 (* 1 = 1.3311 loss)
I0526 14:15:35.475448 32260 sgd_solver.cpp:106] Iteration 378750, lr = 0.0015
I0526 14:15:47.612746 32260 solver.cpp:237] Iteration 379500, loss = 1.11812
I0526 14:15:47.612795 32260 solver.cpp:253]     Train net output #0: loss = 1.11812 (* 1 = 1.11812 loss)
I0526 14:15:47.612809 32260 sgd_solver.cpp:106] Iteration 379500, lr = 0.0015
I0526 14:16:20.683176 32260 solver.cpp:237] Iteration 380250, loss = 0.74331
I0526 14:16:20.683351 32260 solver.cpp:253]     Train net output #0: loss = 0.743309 (* 1 = 0.743309 loss)
I0526 14:16:20.683367 32260 sgd_solver.cpp:106] Iteration 380250, lr = 0.0015
I0526 14:16:32.806617 32260 solver.cpp:237] Iteration 381000, loss = 0.986279
I0526 14:16:32.806653 32260 solver.cpp:253]     Train net output #0: loss = 0.986278 (* 1 = 0.986278 loss)
I0526 14:16:32.806665 32260 sgd_solver.cpp:106] Iteration 381000, lr = 0.0015
I0526 14:16:44.956274 32260 solver.cpp:237] Iteration 381750, loss = 1.36735
I0526 14:16:44.956320 32260 solver.cpp:253]     Train net output #0: loss = 1.36735 (* 1 = 1.36735 loss)
I0526 14:16:44.956333 32260 sgd_solver.cpp:106] Iteration 381750, lr = 0.0015
I0526 14:16:57.112030 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_382500.caffemodel
I0526 14:16:57.161201 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_382500.solverstate
I0526 14:16:57.194761 32260 solver.cpp:237] Iteration 382500, loss = 0.784973
I0526 14:16:57.194813 32260 solver.cpp:253]     Train net output #0: loss = 0.784972 (* 1 = 0.784972 loss)
I0526 14:16:57.194828 32260 sgd_solver.cpp:106] Iteration 382500, lr = 0.0015
I0526 14:17:09.352114 32260 solver.cpp:237] Iteration 383250, loss = 0.951935
I0526 14:17:09.352164 32260 solver.cpp:253]     Train net output #0: loss = 0.951934 (* 1 = 0.951934 loss)
I0526 14:17:09.352179 32260 sgd_solver.cpp:106] Iteration 383250, lr = 0.0015
I0526 14:17:21.493505 32260 solver.cpp:237] Iteration 384000, loss = 0.894469
I0526 14:17:21.493541 32260 solver.cpp:253]     Train net output #0: loss = 0.894467 (* 1 = 0.894467 loss)
I0526 14:17:21.493556 32260 sgd_solver.cpp:106] Iteration 384000, lr = 0.0015
I0526 14:17:33.611937 32260 solver.cpp:237] Iteration 384750, loss = 1.28765
I0526 14:17:33.612104 32260 solver.cpp:253]     Train net output #0: loss = 1.28765 (* 1 = 1.28765 loss)
I0526 14:17:33.612119 32260 sgd_solver.cpp:106] Iteration 384750, lr = 0.0015
I0526 14:18:06.672035 32260 solver.cpp:237] Iteration 385500, loss = 1.18356
I0526 14:18:06.672206 32260 solver.cpp:253]     Train net output #0: loss = 1.18356 (* 1 = 1.18356 loss)
I0526 14:18:06.672220 32260 sgd_solver.cpp:106] Iteration 385500, lr = 0.0015
I0526 14:18:18.828630 32260 solver.cpp:237] Iteration 386250, loss = 1.04639
I0526 14:18:18.828675 32260 solver.cpp:253]     Train net output #0: loss = 1.04639 (* 1 = 1.04639 loss)
I0526 14:18:18.828694 32260 sgd_solver.cpp:106] Iteration 386250, lr = 0.0015
I0526 14:18:30.963945 32260 solver.cpp:237] Iteration 387000, loss = 1.1431
I0526 14:18:30.963980 32260 solver.cpp:253]     Train net output #0: loss = 1.14309 (* 1 = 1.14309 loss)
I0526 14:18:30.963997 32260 sgd_solver.cpp:106] Iteration 387000, lr = 0.0015
I0526 14:18:43.049571 32260 solver.cpp:237] Iteration 387750, loss = 0.824458
I0526 14:18:43.049723 32260 solver.cpp:253]     Train net output #0: loss = 0.824457 (* 1 = 0.824457 loss)
I0526 14:18:43.049737 32260 sgd_solver.cpp:106] Iteration 387750, lr = 0.0015
I0526 14:18:55.129549 32260 solver.cpp:237] Iteration 388500, loss = 0.841042
I0526 14:18:55.129585 32260 solver.cpp:253]     Train net output #0: loss = 0.841041 (* 1 = 0.841041 loss)
I0526 14:18:55.129602 32260 sgd_solver.cpp:106] Iteration 388500, lr = 0.0015
I0526 14:19:07.306865 32260 solver.cpp:237] Iteration 389250, loss = 0.883576
I0526 14:19:07.306903 32260 solver.cpp:253]     Train net output #0: loss = 0.883575 (* 1 = 0.883575 loss)
I0526 14:19:07.306915 32260 sgd_solver.cpp:106] Iteration 389250, lr = 0.0015
I0526 14:19:19.474227 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_390000.caffemodel
I0526 14:19:19.525476 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_390000.solverstate
I0526 14:19:19.552933 32260 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 14:20:11.262261 32260 solver.cpp:409]     Test net output #0: accuracy = 0.902585
I0526 14:20:11.262428 32260 solver.cpp:409]     Test net output #1: loss = 0.336975 (* 1 = 0.336975 loss)
I0526 14:20:32.168145 32260 solver.cpp:237] Iteration 390000, loss = 1.07775
I0526 14:20:32.168200 32260 solver.cpp:253]     Train net output #0: loss = 1.07775 (* 1 = 1.07775 loss)
I0526 14:20:32.168215 32260 sgd_solver.cpp:106] Iteration 390000, lr = 0.0015
I0526 14:20:44.250588 32260 solver.cpp:237] Iteration 390750, loss = 1.04942
I0526 14:20:44.250759 32260 solver.cpp:253]     Train net output #0: loss = 1.04942 (* 1 = 1.04942 loss)
I0526 14:20:44.250773 32260 sgd_solver.cpp:106] Iteration 390750, lr = 0.0015
I0526 14:20:56.334942 32260 solver.cpp:237] Iteration 391500, loss = 0.889768
I0526 14:20:56.334986 32260 solver.cpp:253]     Train net output #0: loss = 0.889767 (* 1 = 0.889767 loss)
I0526 14:20:56.335000 32260 sgd_solver.cpp:106] Iteration 391500, lr = 0.0015
I0526 14:21:08.487424 32260 solver.cpp:237] Iteration 392250, loss = 1.60552
I0526 14:21:08.487460 32260 solver.cpp:253]     Train net output #0: loss = 1.60552 (* 1 = 1.60552 loss)
I0526 14:21:08.487473 32260 sgd_solver.cpp:106] Iteration 392250, lr = 0.0015
I0526 14:21:20.638211 32260 solver.cpp:237] Iteration 393000, loss = 0.790821
I0526 14:21:20.638378 32260 solver.cpp:253]     Train net output #0: loss = 0.790819 (* 1 = 0.790819 loss)
I0526 14:21:20.638393 32260 sgd_solver.cpp:106] Iteration 393000, lr = 0.0015
I0526 14:21:32.799646 32260 solver.cpp:237] Iteration 393750, loss = 1.5319
I0526 14:21:32.799682 32260 solver.cpp:253]     Train net output #0: loss = 1.5319 (* 1 = 1.5319 loss)
I0526 14:21:32.799695 32260 sgd_solver.cpp:106] Iteration 393750, lr = 0.0015
I0526 14:21:44.926671 32260 solver.cpp:237] Iteration 394500, loss = 1.78382
I0526 14:21:44.926717 32260 solver.cpp:253]     Train net output #0: loss = 1.78382 (* 1 = 1.78382 loss)
I0526 14:21:44.926733 32260 sgd_solver.cpp:106] Iteration 394500, lr = 0.0015
I0526 14:22:17.985038 32260 solver.cpp:237] Iteration 395250, loss = 1.46129
I0526 14:22:17.985214 32260 solver.cpp:253]     Train net output #0: loss = 1.46128 (* 1 = 1.46128 loss)
I0526 14:22:17.985229 32260 sgd_solver.cpp:106] Iteration 395250, lr = 0.0015
I0526 14:22:30.196817 32260 solver.cpp:237] Iteration 396000, loss = 1.09527
I0526 14:22:30.196863 32260 solver.cpp:253]     Train net output #0: loss = 1.09527 (* 1 = 1.09527 loss)
I0526 14:22:30.196877 32260 sgd_solver.cpp:106] Iteration 396000, lr = 0.0015
I0526 14:22:42.364629 32260 solver.cpp:237] Iteration 396750, loss = 1.04241
I0526 14:22:42.364665 32260 solver.cpp:253]     Train net output #0: loss = 1.0424 (* 1 = 1.0424 loss)
I0526 14:22:42.364682 32260 sgd_solver.cpp:106] Iteration 396750, lr = 0.0015
I0526 14:22:54.506853 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_397500.caffemodel
I0526 14:22:54.558497 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_397500.solverstate
I0526 14:22:54.591155 32260 solver.cpp:237] Iteration 397500, loss = 0.841136
I0526 14:22:54.591207 32260 solver.cpp:253]     Train net output #0: loss = 0.841134 (* 1 = 0.841134 loss)
I0526 14:22:54.591222 32260 sgd_solver.cpp:106] Iteration 397500, lr = 0.0015
I0526 14:23:06.787566 32260 solver.cpp:237] Iteration 398250, loss = 1.3079
I0526 14:23:06.787601 32260 solver.cpp:253]     Train net output #0: loss = 1.3079 (* 1 = 1.3079 loss)
I0526 14:23:06.787617 32260 sgd_solver.cpp:106] Iteration 398250, lr = 0.0015
I0526 14:23:18.925565 32260 solver.cpp:237] Iteration 399000, loss = 0.969669
I0526 14:23:18.925607 32260 solver.cpp:253]     Train net output #0: loss = 0.969668 (* 1 = 0.969668 loss)
I0526 14:23:18.925624 32260 sgd_solver.cpp:106] Iteration 399000, lr = 0.0015
I0526 14:23:31.089089 32260 solver.cpp:237] Iteration 399750, loss = 1.06405
I0526 14:23:31.089243 32260 solver.cpp:253]     Train net output #0: loss = 1.06405 (* 1 = 1.06405 loss)
I0526 14:23:31.089257 32260 sgd_solver.cpp:106] Iteration 399750, lr = 0.0015
I0526 14:24:04.160605 32260 solver.cpp:237] Iteration 400500, loss = 1.19725
I0526 14:24:04.160774 32260 solver.cpp:253]     Train net output #0: loss = 1.19725 (* 1 = 1.19725 loss)
I0526 14:24:04.160790 32260 sgd_solver.cpp:106] Iteration 400500, lr = 0.0015
I0526 14:24:16.285147 32260 solver.cpp:237] Iteration 401250, loss = 1.14947
I0526 14:24:16.285195 32260 solver.cpp:253]     Train net output #0: loss = 1.14947 (* 1 = 1.14947 loss)
I0526 14:24:16.285209 32260 sgd_solver.cpp:106] Iteration 401250, lr = 0.0015
I0526 14:24:28.375059 32260 solver.cpp:237] Iteration 402000, loss = 0.796542
I0526 14:24:28.375095 32260 solver.cpp:253]     Train net output #0: loss = 0.796541 (* 1 = 0.796541 loss)
I0526 14:24:28.375109 32260 sgd_solver.cpp:106] Iteration 402000, lr = 0.0015
I0526 14:24:40.478062 32260 solver.cpp:237] Iteration 402750, loss = 1.29051
I0526 14:24:40.478232 32260 solver.cpp:253]     Train net output #0: loss = 1.29051 (* 1 = 1.29051 loss)
I0526 14:24:40.478246 32260 sgd_solver.cpp:106] Iteration 402750, lr = 0.0015
I0526 14:24:52.633280 32260 solver.cpp:237] Iteration 403500, loss = 1.08674
I0526 14:24:52.633313 32260 solver.cpp:253]     Train net output #0: loss = 1.08674 (* 1 = 1.08674 loss)
I0526 14:24:52.633332 32260 sgd_solver.cpp:106] Iteration 403500, lr = 0.0015
I0526 14:25:04.745764 32260 solver.cpp:237] Iteration 404250, loss = 0.714855
I0526 14:25:04.745807 32260 solver.cpp:253]     Train net output #0: loss = 0.714854 (* 1 = 0.714854 loss)
I0526 14:25:04.745821 32260 sgd_solver.cpp:106] Iteration 404250, lr = 0.0015
I0526 14:25:16.824172 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_405000.caffemodel
I0526 14:25:16.881788 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_405000.solverstate
I0526 14:25:16.915719 32260 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 14:26:29.650193 32260 solver.cpp:409]     Test net output #0: accuracy = 0.901284
I0526 14:26:29.650359 32260 solver.cpp:409]     Test net output #1: loss = 0.318086 (* 1 = 0.318086 loss)
I0526 14:26:50.515687 32260 solver.cpp:237] Iteration 405000, loss = 0.886987
I0526 14:26:50.515740 32260 solver.cpp:253]     Train net output #0: loss = 0.886986 (* 1 = 0.886986 loss)
I0526 14:26:50.515756 32260 sgd_solver.cpp:106] Iteration 405000, lr = 0.0015
I0526 14:27:02.649209 32260 solver.cpp:237] Iteration 405750, loss = 1.11692
I0526 14:27:02.649374 32260 solver.cpp:253]     Train net output #0: loss = 1.11692 (* 1 = 1.11692 loss)
I0526 14:27:02.649389 32260 sgd_solver.cpp:106] Iteration 405750, lr = 0.0015
I0526 14:27:14.791590 32260 solver.cpp:237] Iteration 406500, loss = 1.64428
I0526 14:27:14.791626 32260 solver.cpp:253]     Train net output #0: loss = 1.64428 (* 1 = 1.64428 loss)
I0526 14:27:14.791643 32260 sgd_solver.cpp:106] Iteration 406500, lr = 0.0015
I0526 14:27:26.917326 32260 solver.cpp:237] Iteration 407250, loss = 1.29816
I0526 14:27:26.917361 32260 solver.cpp:253]     Train net output #0: loss = 1.29816 (* 1 = 1.29816 loss)
I0526 14:27:26.917374 32260 sgd_solver.cpp:106] Iteration 407250, lr = 0.0015
I0526 14:27:39.142588 32260 solver.cpp:237] Iteration 408000, loss = 1.0143
I0526 14:27:39.142752 32260 solver.cpp:253]     Train net output #0: loss = 1.0143 (* 1 = 1.0143 loss)
I0526 14:27:39.142768 32260 sgd_solver.cpp:106] Iteration 408000, lr = 0.0015
I0526 14:27:51.315016 32260 solver.cpp:237] Iteration 408750, loss = 0.972631
I0526 14:27:51.315052 32260 solver.cpp:253]     Train net output #0: loss = 0.97263 (* 1 = 0.97263 loss)
I0526 14:27:51.315064 32260 sgd_solver.cpp:106] Iteration 408750, lr = 0.0015
I0526 14:28:03.482080 32260 solver.cpp:237] Iteration 409500, loss = 1.42433
I0526 14:28:03.482125 32260 solver.cpp:253]     Train net output #0: loss = 1.42433 (* 1 = 1.42433 loss)
I0526 14:28:03.482141 32260 sgd_solver.cpp:106] Iteration 409500, lr = 0.0015
I0526 14:28:36.563830 32260 solver.cpp:237] Iteration 410250, loss = 1.40348
I0526 14:28:36.564007 32260 solver.cpp:253]     Train net output #0: loss = 1.40348 (* 1 = 1.40348 loss)
I0526 14:28:36.564021 32260 sgd_solver.cpp:106] Iteration 410250, lr = 0.0015
I0526 14:28:48.739368 32260 solver.cpp:237] Iteration 411000, loss = 0.650099
I0526 14:28:48.739418 32260 solver.cpp:253]     Train net output #0: loss = 0.650097 (* 1 = 0.650097 loss)
I0526 14:28:48.739433 32260 sgd_solver.cpp:106] Iteration 411000, lr = 0.0015
I0526 14:29:00.864341 32260 solver.cpp:237] Iteration 411750, loss = 1.19424
I0526 14:29:00.864377 32260 solver.cpp:253]     Train net output #0: loss = 1.19424 (* 1 = 1.19424 loss)
I0526 14:29:00.864389 32260 sgd_solver.cpp:106] Iteration 411750, lr = 0.0015
I0526 14:29:12.960959 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_412500.caffemodel
I0526 14:29:13.016865 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_412500.solverstate
I0526 14:29:13.056627 32260 solver.cpp:237] Iteration 412500, loss = 1.20784
I0526 14:29:13.056673 32260 solver.cpp:253]     Train net output #0: loss = 1.20784 (* 1 = 1.20784 loss)
I0526 14:29:13.056686 32260 sgd_solver.cpp:106] Iteration 412500, lr = 0.0015
I0526 14:29:25.177443 32260 solver.cpp:237] Iteration 413250, loss = 1.34178
I0526 14:29:25.177479 32260 solver.cpp:253]     Train net output #0: loss = 1.34178 (* 1 = 1.34178 loss)
I0526 14:29:25.177491 32260 sgd_solver.cpp:106] Iteration 413250, lr = 0.0015
I0526 14:29:37.317531 32260 solver.cpp:237] Iteration 414000, loss = 0.694528
I0526 14:29:37.317580 32260 solver.cpp:253]     Train net output #0: loss = 0.694527 (* 1 = 0.694527 loss)
I0526 14:29:37.317594 32260 sgd_solver.cpp:106] Iteration 414000, lr = 0.0015
I0526 14:29:49.473443 32260 solver.cpp:237] Iteration 414750, loss = 1.2774
I0526 14:29:49.473599 32260 solver.cpp:253]     Train net output #0: loss = 1.2774 (* 1 = 1.2774 loss)
I0526 14:29:49.473613 32260 sgd_solver.cpp:106] Iteration 414750, lr = 0.0015
I0526 14:30:22.503123 32260 solver.cpp:237] Iteration 415500, loss = 1.61267
I0526 14:30:22.503288 32260 solver.cpp:253]     Train net output #0: loss = 1.61267 (* 1 = 1.61267 loss)
I0526 14:30:22.503301 32260 sgd_solver.cpp:106] Iteration 415500, lr = 0.0015
I0526 14:30:34.667403 32260 solver.cpp:237] Iteration 416250, loss = 1.3019
I0526 14:30:34.667438 32260 solver.cpp:253]     Train net output #0: loss = 1.3019 (* 1 = 1.3019 loss)
I0526 14:30:34.667453 32260 sgd_solver.cpp:106] Iteration 416250, lr = 0.0015
I0526 14:30:46.865694 32260 solver.cpp:237] Iteration 417000, loss = 1.00631
I0526 14:30:46.865728 32260 solver.cpp:253]     Train net output #0: loss = 1.00631 (* 1 = 1.00631 loss)
I0526 14:30:46.865746 32260 sgd_solver.cpp:106] Iteration 417000, lr = 0.0015
I0526 14:30:59.044637 32260 solver.cpp:237] Iteration 417750, loss = 1.00902
I0526 14:30:59.044813 32260 solver.cpp:253]     Train net output #0: loss = 1.00902 (* 1 = 1.00902 loss)
I0526 14:30:59.044829 32260 sgd_solver.cpp:106] Iteration 417750, lr = 0.0015
I0526 14:31:11.212183 32260 solver.cpp:237] Iteration 418500, loss = 1.03968
I0526 14:31:11.212218 32260 solver.cpp:253]     Train net output #0: loss = 1.03968 (* 1 = 1.03968 loss)
I0526 14:31:11.212232 32260 sgd_solver.cpp:106] Iteration 418500, lr = 0.0015
I0526 14:31:23.384166 32260 solver.cpp:237] Iteration 419250, loss = 1.6836
I0526 14:31:23.384209 32260 solver.cpp:253]     Train net output #0: loss = 1.6836 (* 1 = 1.6836 loss)
I0526 14:31:23.384227 32260 sgd_solver.cpp:106] Iteration 419250, lr = 0.0015
I0526 14:31:35.532579 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_420000.caffemodel
I0526 14:31:35.591190 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_420000.solverstate
I0526 14:31:35.628974 32260 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 14:32:27.595935 32260 solver.cpp:409]     Test net output #0: accuracy = 0.903393
I0526 14:32:27.596112 32260 solver.cpp:409]     Test net output #1: loss = 0.309917 (* 1 = 0.309917 loss)
I0526 14:32:48.456800 32260 solver.cpp:237] Iteration 420000, loss = 1.30367
I0526 14:32:48.456852 32260 solver.cpp:253]     Train net output #0: loss = 1.30367 (* 1 = 1.30367 loss)
I0526 14:32:48.456867 32260 sgd_solver.cpp:106] Iteration 420000, lr = 0.0015
I0526 14:33:00.560119 32260 solver.cpp:237] Iteration 420750, loss = 1.15674
I0526 14:33:00.560295 32260 solver.cpp:253]     Train net output #0: loss = 1.15674 (* 1 = 1.15674 loss)
I0526 14:33:00.560312 32260 sgd_solver.cpp:106] Iteration 420750, lr = 0.0015
I0526 14:33:12.639837 32260 solver.cpp:237] Iteration 421500, loss = 1.23767
I0526 14:33:12.639873 32260 solver.cpp:253]     Train net output #0: loss = 1.23767 (* 1 = 1.23767 loss)
I0526 14:33:12.639885 32260 sgd_solver.cpp:106] Iteration 421500, lr = 0.0015
I0526 14:33:24.792979 32260 solver.cpp:237] Iteration 422250, loss = 1.37515
I0526 14:33:24.793025 32260 solver.cpp:253]     Train net output #0: loss = 1.37515 (* 1 = 1.37515 loss)
I0526 14:33:24.793040 32260 sgd_solver.cpp:106] Iteration 422250, lr = 0.0015
I0526 14:33:36.923833 32260 solver.cpp:237] Iteration 423000, loss = 1.05364
I0526 14:33:36.923986 32260 solver.cpp:253]     Train net output #0: loss = 1.05364 (* 1 = 1.05364 loss)
I0526 14:33:36.924001 32260 sgd_solver.cpp:106] Iteration 423000, lr = 0.0015
I0526 14:33:49.059435 32260 solver.cpp:237] Iteration 423750, loss = 1.14622
I0526 14:33:49.059480 32260 solver.cpp:253]     Train net output #0: loss = 1.14622 (* 1 = 1.14622 loss)
I0526 14:33:49.059494 32260 sgd_solver.cpp:106] Iteration 423750, lr = 0.0015
I0526 14:34:01.205267 32260 solver.cpp:237] Iteration 424500, loss = 1.0024
I0526 14:34:01.205302 32260 solver.cpp:253]     Train net output #0: loss = 1.0024 (* 1 = 1.0024 loss)
I0526 14:34:01.205315 32260 sgd_solver.cpp:106] Iteration 424500, lr = 0.0015
I0526 14:34:34.268525 32260 solver.cpp:237] Iteration 425250, loss = 1.46738
I0526 14:34:34.268698 32260 solver.cpp:253]     Train net output #0: loss = 1.46738 (* 1 = 1.46738 loss)
I0526 14:34:34.268712 32260 sgd_solver.cpp:106] Iteration 425250, lr = 0.0015
I0526 14:34:46.492043 32260 solver.cpp:237] Iteration 426000, loss = 1.12344
I0526 14:34:46.492079 32260 solver.cpp:253]     Train net output #0: loss = 1.12344 (* 1 = 1.12344 loss)
I0526 14:34:46.492094 32260 sgd_solver.cpp:106] Iteration 426000, lr = 0.0015
I0526 14:34:58.627151 32260 solver.cpp:237] Iteration 426750, loss = 0.915992
I0526 14:34:58.627190 32260 solver.cpp:253]     Train net output #0: loss = 0.91599 (* 1 = 0.91599 loss)
I0526 14:34:58.627208 32260 sgd_solver.cpp:106] Iteration 426750, lr = 0.0015
I0526 14:35:10.744184 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_427500.caffemodel
I0526 14:35:10.810858 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_427500.solverstate
I0526 14:35:10.853832 32260 solver.cpp:237] Iteration 427500, loss = 1.37505
I0526 14:35:10.853878 32260 solver.cpp:253]     Train net output #0: loss = 1.37505 (* 1 = 1.37505 loss)
I0526 14:35:10.853899 32260 sgd_solver.cpp:106] Iteration 427500, lr = 0.0015
I0526 14:35:23.032769 32260 solver.cpp:237] Iteration 428250, loss = 0.649203
I0526 14:35:23.032821 32260 solver.cpp:253]     Train net output #0: loss = 0.649201 (* 1 = 0.649201 loss)
I0526 14:35:23.032837 32260 sgd_solver.cpp:106] Iteration 428250, lr = 0.0015
I0526 14:35:35.196466 32260 solver.cpp:237] Iteration 429000, loss = 2.20763
I0526 14:35:35.196502 32260 solver.cpp:253]     Train net output #0: loss = 2.20763 (* 1 = 2.20763 loss)
I0526 14:35:35.196516 32260 sgd_solver.cpp:106] Iteration 429000, lr = 0.0015
I0526 14:35:47.349886 32260 solver.cpp:237] Iteration 429750, loss = 0.963182
I0526 14:35:47.350069 32260 solver.cpp:253]     Train net output #0: loss = 0.96318 (* 1 = 0.96318 loss)
I0526 14:35:47.350085 32260 sgd_solver.cpp:106] Iteration 429750, lr = 0.0015
I0526 14:36:20.417503 32260 solver.cpp:237] Iteration 430500, loss = 1.27231
I0526 14:36:20.417681 32260 solver.cpp:253]     Train net output #0: loss = 1.27231 (* 1 = 1.27231 loss)
I0526 14:36:20.417696 32260 sgd_solver.cpp:106] Iteration 430500, lr = 0.0015
I0526 14:36:32.621881 32260 solver.cpp:237] Iteration 431250, loss = 1.23959
I0526 14:36:32.621923 32260 solver.cpp:253]     Train net output #0: loss = 1.23959 (* 1 = 1.23959 loss)
I0526 14:36:32.621937 32260 sgd_solver.cpp:106] Iteration 431250, lr = 0.0015
I0526 14:36:44.790987 32260 solver.cpp:237] Iteration 432000, loss = 0.960428
I0526 14:36:44.791038 32260 solver.cpp:253]     Train net output #0: loss = 0.960426 (* 1 = 0.960426 loss)
I0526 14:36:44.791052 32260 sgd_solver.cpp:106] Iteration 432000, lr = 0.0015
I0526 14:36:56.926452 32260 solver.cpp:237] Iteration 432750, loss = 1.21579
I0526 14:36:56.926604 32260 solver.cpp:253]     Train net output #0: loss = 1.21579 (* 1 = 1.21579 loss)
I0526 14:36:56.926619 32260 sgd_solver.cpp:106] Iteration 432750, lr = 0.0015
I0526 14:37:08.998769 32260 solver.cpp:237] Iteration 433500, loss = 0.954994
I0526 14:37:08.998816 32260 solver.cpp:253]     Train net output #0: loss = 0.954991 (* 1 = 0.954991 loss)
I0526 14:37:08.998831 32260 sgd_solver.cpp:106] Iteration 433500, lr = 0.0015
I0526 14:37:21.069136 32260 solver.cpp:237] Iteration 434250, loss = 1.44123
I0526 14:37:21.069171 32260 solver.cpp:253]     Train net output #0: loss = 1.44122 (* 1 = 1.44122 loss)
I0526 14:37:21.069185 32260 sgd_solver.cpp:106] Iteration 434250, lr = 0.0015
I0526 14:37:33.174350 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_435000.caffemodel
I0526 14:37:33.234025 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_435000.solverstate
I0526 14:37:33.267930 32260 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 14:38:46.215028 32260 solver.cpp:409]     Test net output #0: accuracy = 0.903526
I0526 14:38:46.215198 32260 solver.cpp:409]     Test net output #1: loss = 0.29334 (* 1 = 0.29334 loss)
I0526 14:39:07.089817 32260 solver.cpp:237] Iteration 435000, loss = 0.953282
I0526 14:39:07.089867 32260 solver.cpp:253]     Train net output #0: loss = 0.953279 (* 1 = 0.953279 loss)
I0526 14:39:07.089884 32260 sgd_solver.cpp:106] Iteration 435000, lr = 0.0015
I0526 14:39:19.224014 32260 solver.cpp:237] Iteration 435750, loss = 1.06724
I0526 14:39:19.224182 32260 solver.cpp:253]     Train net output #0: loss = 1.06724 (* 1 = 1.06724 loss)
I0526 14:39:19.224197 32260 sgd_solver.cpp:106] Iteration 435750, lr = 0.0015
I0526 14:39:31.359593 32260 solver.cpp:237] Iteration 436500, loss = 0.900563
I0526 14:39:31.359630 32260 solver.cpp:253]     Train net output #0: loss = 0.900561 (* 1 = 0.900561 loss)
I0526 14:39:31.359644 32260 sgd_solver.cpp:106] Iteration 436500, lr = 0.0015
I0526 14:39:43.470253 32260 solver.cpp:237] Iteration 437250, loss = 1.1169
I0526 14:39:43.470296 32260 solver.cpp:253]     Train net output #0: loss = 1.11689 (* 1 = 1.11689 loss)
I0526 14:39:43.470309 32260 sgd_solver.cpp:106] Iteration 437250, lr = 0.0015
I0526 14:39:55.564035 32260 solver.cpp:237] Iteration 438000, loss = 0.873491
I0526 14:39:55.564187 32260 solver.cpp:253]     Train net output #0: loss = 0.873488 (* 1 = 0.873488 loss)
I0526 14:39:55.564201 32260 sgd_solver.cpp:106] Iteration 438000, lr = 0.0015
I0526 14:40:07.709406 32260 solver.cpp:237] Iteration 438750, loss = 1.25368
I0526 14:40:07.709450 32260 solver.cpp:253]     Train net output #0: loss = 1.25368 (* 1 = 1.25368 loss)
I0526 14:40:07.709463 32260 sgd_solver.cpp:106] Iteration 438750, lr = 0.0015
I0526 14:40:19.917887 32260 solver.cpp:237] Iteration 439500, loss = 1.59728
I0526 14:40:19.917923 32260 solver.cpp:253]     Train net output #0: loss = 1.59728 (* 1 = 1.59728 loss)
I0526 14:40:19.917937 32260 sgd_solver.cpp:106] Iteration 439500, lr = 0.0015
I0526 14:40:52.916185 32260 solver.cpp:237] Iteration 440250, loss = 1.06544
I0526 14:40:52.916373 32260 solver.cpp:253]     Train net output #0: loss = 1.06544 (* 1 = 1.06544 loss)
I0526 14:40:52.916388 32260 sgd_solver.cpp:106] Iteration 440250, lr = 0.0015
I0526 14:41:05.045549 32260 solver.cpp:237] Iteration 441000, loss = 1.41646
I0526 14:41:05.045584 32260 solver.cpp:253]     Train net output #0: loss = 1.41646 (* 1 = 1.41646 loss)
I0526 14:41:05.045600 32260 sgd_solver.cpp:106] Iteration 441000, lr = 0.0015
I0526 14:41:17.167268 32260 solver.cpp:237] Iteration 441750, loss = 2.08503
I0526 14:41:17.167316 32260 solver.cpp:253]     Train net output #0: loss = 2.08503 (* 1 = 2.08503 loss)
I0526 14:41:17.167330 32260 sgd_solver.cpp:106] Iteration 441750, lr = 0.0015
I0526 14:41:29.263749 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_442500.caffemodel
I0526 14:41:29.320785 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_442500.solverstate
I0526 14:41:29.359184 32260 solver.cpp:237] Iteration 442500, loss = 0.81153
I0526 14:41:29.359230 32260 solver.cpp:253]     Train net output #0: loss = 0.811527 (* 1 = 0.811527 loss)
I0526 14:41:29.359247 32260 sgd_solver.cpp:106] Iteration 442500, lr = 0.0015
I0526 14:41:41.492249 32260 solver.cpp:237] Iteration 443250, loss = 1.41866
I0526 14:41:41.492297 32260 solver.cpp:253]     Train net output #0: loss = 1.41866 (* 1 = 1.41866 loss)
I0526 14:41:41.492311 32260 sgd_solver.cpp:106] Iteration 443250, lr = 0.0015
I0526 14:41:53.642712 32260 solver.cpp:237] Iteration 444000, loss = 1.06253
I0526 14:41:53.642748 32260 solver.cpp:253]     Train net output #0: loss = 1.06253 (* 1 = 1.06253 loss)
I0526 14:41:53.642761 32260 sgd_solver.cpp:106] Iteration 444000, lr = 0.0015
I0526 14:42:05.789597 32260 solver.cpp:237] Iteration 444750, loss = 0.958285
I0526 14:42:05.789767 32260 solver.cpp:253]     Train net output #0: loss = 0.958282 (* 1 = 0.958282 loss)
I0526 14:42:05.789783 32260 sgd_solver.cpp:106] Iteration 444750, lr = 0.0015
I0526 14:42:38.810715 32260 solver.cpp:237] Iteration 445500, loss = 0.950539
I0526 14:42:38.810891 32260 solver.cpp:253]     Train net output #0: loss = 0.950537 (* 1 = 0.950537 loss)
I0526 14:42:38.810906 32260 sgd_solver.cpp:106] Iteration 445500, lr = 0.0015
I0526 14:42:50.968099 32260 solver.cpp:237] Iteration 446250, loss = 0.884445
I0526 14:42:50.968137 32260 solver.cpp:253]     Train net output #0: loss = 0.884443 (* 1 = 0.884443 loss)
I0526 14:42:50.968149 32260 sgd_solver.cpp:106] Iteration 446250, lr = 0.0015
I0526 14:43:03.051955 32260 solver.cpp:237] Iteration 447000, loss = 1.21052
I0526 14:43:03.052000 32260 solver.cpp:253]     Train net output #0: loss = 1.21052 (* 1 = 1.21052 loss)
I0526 14:43:03.052014 32260 sgd_solver.cpp:106] Iteration 447000, lr = 0.0015
I0526 14:43:15.117642 32260 solver.cpp:237] Iteration 447750, loss = 1.01997
I0526 14:43:15.117796 32260 solver.cpp:253]     Train net output #0: loss = 1.01997 (* 1 = 1.01997 loss)
I0526 14:43:15.117810 32260 sgd_solver.cpp:106] Iteration 447750, lr = 0.0015
I0526 14:43:27.200575 32260 solver.cpp:237] Iteration 448500, loss = 1.11967
I0526 14:43:27.200620 32260 solver.cpp:253]     Train net output #0: loss = 1.11967 (* 1 = 1.11967 loss)
I0526 14:43:27.200634 32260 sgd_solver.cpp:106] Iteration 448500, lr = 0.0015
I0526 14:43:39.329078 32260 solver.cpp:237] Iteration 449250, loss = 0.808861
I0526 14:43:39.329115 32260 solver.cpp:253]     Train net output #0: loss = 0.808859 (* 1 = 0.808859 loss)
I0526 14:43:39.329131 32260 sgd_solver.cpp:106] Iteration 449250, lr = 0.0015
I0526 14:43:51.454603 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_450000.caffemodel
I0526 14:43:51.515162 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_450000.solverstate
I0526 14:43:51.546602 32260 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 14:44:43.217056 32260 solver.cpp:409]     Test net output #0: accuracy = 0.90371
I0526 14:44:43.217249 32260 solver.cpp:409]     Test net output #1: loss = 0.302725 (* 1 = 0.302725 loss)
I0526 14:45:04.081943 32260 solver.cpp:237] Iteration 450000, loss = 1.10161
I0526 14:45:04.081995 32260 solver.cpp:253]     Train net output #0: loss = 1.10161 (* 1 = 1.10161 loss)
I0526 14:45:04.082010 32260 sgd_solver.cpp:106] Iteration 450000, lr = 0.0015
I0526 14:45:16.235287 32260 solver.cpp:237] Iteration 450750, loss = 0.496902
I0526 14:45:16.235450 32260 solver.cpp:253]     Train net output #0: loss = 0.4969 (* 1 = 0.4969 loss)
I0526 14:45:16.235466 32260 sgd_solver.cpp:106] Iteration 450750, lr = 0.0015
I0526 14:45:28.396189 32260 solver.cpp:237] Iteration 451500, loss = 1.05925
I0526 14:45:28.396239 32260 solver.cpp:253]     Train net output #0: loss = 1.05925 (* 1 = 1.05925 loss)
I0526 14:45:28.396253 32260 sgd_solver.cpp:106] Iteration 451500, lr = 0.0015
I0526 14:45:40.559240 32260 solver.cpp:237] Iteration 452250, loss = 1.41802
I0526 14:45:40.559275 32260 solver.cpp:253]     Train net output #0: loss = 1.41801 (* 1 = 1.41801 loss)
I0526 14:45:40.559289 32260 sgd_solver.cpp:106] Iteration 452250, lr = 0.0015
I0526 14:45:52.716317 32260 solver.cpp:237] Iteration 453000, loss = 1.2157
I0526 14:45:52.716491 32260 solver.cpp:253]     Train net output #0: loss = 1.2157 (* 1 = 1.2157 loss)
I0526 14:45:52.716506 32260 sgd_solver.cpp:106] Iteration 453000, lr = 0.0015
I0526 14:46:04.920605 32260 solver.cpp:237] Iteration 453750, loss = 1.50221
I0526 14:46:04.920641 32260 solver.cpp:253]     Train net output #0: loss = 1.50221 (* 1 = 1.50221 loss)
I0526 14:46:04.920655 32260 sgd_solver.cpp:106] Iteration 453750, lr = 0.0015
I0526 14:46:17.121476 32260 solver.cpp:237] Iteration 454500, loss = 0.997051
I0526 14:46:17.121526 32260 solver.cpp:253]     Train net output #0: loss = 0.997048 (* 1 = 0.997048 loss)
I0526 14:46:17.121539 32260 sgd_solver.cpp:106] Iteration 454500, lr = 0.0015
I0526 14:46:50.224361 32260 solver.cpp:237] Iteration 455250, loss = 0.990766
I0526 14:46:50.224541 32260 solver.cpp:253]     Train net output #0: loss = 0.990764 (* 1 = 0.990764 loss)
I0526 14:46:50.224557 32260 sgd_solver.cpp:106] Iteration 455250, lr = 0.0015
I0526 14:47:02.422955 32260 solver.cpp:237] Iteration 456000, loss = 0.928342
I0526 14:47:02.422996 32260 solver.cpp:253]     Train net output #0: loss = 0.928339 (* 1 = 0.928339 loss)
I0526 14:47:02.423015 32260 sgd_solver.cpp:106] Iteration 456000, lr = 0.0015
I0526 14:47:14.591537 32260 solver.cpp:237] Iteration 456750, loss = 1.56103
I0526 14:47:14.591573 32260 solver.cpp:253]     Train net output #0: loss = 1.56103 (* 1 = 1.56103 loss)
I0526 14:47:14.591590 32260 sgd_solver.cpp:106] Iteration 456750, lr = 0.0015
I0526 14:47:26.737972 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_457500.caffemodel
I0526 14:47:26.802611 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_457500.solverstate
I0526 14:47:26.841888 32260 solver.cpp:237] Iteration 457500, loss = 1.58918
I0526 14:47:26.841940 32260 solver.cpp:253]     Train net output #0: loss = 1.58918 (* 1 = 1.58918 loss)
I0526 14:47:26.841954 32260 sgd_solver.cpp:106] Iteration 457500, lr = 0.0015
I0526 14:47:39.008810 32260 solver.cpp:237] Iteration 458250, loss = 1.26832
I0526 14:47:39.008851 32260 solver.cpp:253]     Train net output #0: loss = 1.26832 (* 1 = 1.26832 loss)
I0526 14:47:39.008865 32260 sgd_solver.cpp:106] Iteration 458250, lr = 0.0015
I0526 14:47:51.235826 32260 solver.cpp:237] Iteration 459000, loss = 1.00362
I0526 14:47:51.235862 32260 solver.cpp:253]     Train net output #0: loss = 1.00362 (* 1 = 1.00362 loss)
I0526 14:47:51.235874 32260 sgd_solver.cpp:106] Iteration 459000, lr = 0.0015
I0526 14:48:03.411065 32260 solver.cpp:237] Iteration 459750, loss = 0.917851
I0526 14:48:03.411253 32260 solver.cpp:253]     Train net output #0: loss = 0.917849 (* 1 = 0.917849 loss)
I0526 14:48:03.411268 32260 sgd_solver.cpp:106] Iteration 459750, lr = 0.0015
I0526 14:48:36.469413 32260 solver.cpp:237] Iteration 460500, loss = 0.871695
I0526 14:48:36.469595 32260 solver.cpp:253]     Train net output #0: loss = 0.871692 (* 1 = 0.871692 loss)
I0526 14:48:36.469611 32260 sgd_solver.cpp:106] Iteration 460500, lr = 0.0015
I0526 14:48:48.643827 32260 solver.cpp:237] Iteration 461250, loss = 1.31906
I0526 14:48:48.643874 32260 solver.cpp:253]     Train net output #0: loss = 1.31906 (* 1 = 1.31906 loss)
I0526 14:48:48.643888 32260 sgd_solver.cpp:106] Iteration 461250, lr = 0.0015
I0526 14:49:00.834559 32260 solver.cpp:237] Iteration 462000, loss = 1.00318
I0526 14:49:00.834595 32260 solver.cpp:253]     Train net output #0: loss = 1.00318 (* 1 = 1.00318 loss)
I0526 14:49:00.834609 32260 sgd_solver.cpp:106] Iteration 462000, lr = 0.0015
I0526 14:49:13.033188 32260 solver.cpp:237] Iteration 462750, loss = 1.07702
I0526 14:49:13.033360 32260 solver.cpp:253]     Train net output #0: loss = 1.07702 (* 1 = 1.07702 loss)
I0526 14:49:13.033376 32260 sgd_solver.cpp:106] Iteration 462750, lr = 0.0015
I0526 14:49:25.187023 32260 solver.cpp:237] Iteration 463500, loss = 1.4018
I0526 14:49:25.187059 32260 solver.cpp:253]     Train net output #0: loss = 1.4018 (* 1 = 1.4018 loss)
I0526 14:49:25.187073 32260 sgd_solver.cpp:106] Iteration 463500, lr = 0.0015
I0526 14:49:37.340483 32260 solver.cpp:237] Iteration 464250, loss = 1.03564
I0526 14:49:37.340528 32260 solver.cpp:253]     Train net output #0: loss = 1.03564 (* 1 = 1.03564 loss)
I0526 14:49:37.340541 32260 sgd_solver.cpp:106] Iteration 464250, lr = 0.0015
I0526 14:49:49.497285 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_465000.caffemodel
I0526 14:49:49.560740 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_465000.solverstate
I0526 14:49:49.594061 32260 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 14:51:02.453397 32260 solver.cpp:409]     Test net output #0: accuracy = 0.902599
I0526 14:51:02.453575 32260 solver.cpp:409]     Test net output #1: loss = 0.320368 (* 1 = 0.320368 loss)
I0526 14:51:23.348656 32260 solver.cpp:237] Iteration 465000, loss = 0.836688
I0526 14:51:23.348709 32260 solver.cpp:253]     Train net output #0: loss = 0.836685 (* 1 = 0.836685 loss)
I0526 14:51:23.348724 32260 sgd_solver.cpp:106] Iteration 465000, lr = 0.0015
I0526 14:51:35.417120 32260 solver.cpp:237] Iteration 465750, loss = 0.808769
I0526 14:51:35.417284 32260 solver.cpp:253]     Train net output #0: loss = 0.808767 (* 1 = 0.808767 loss)
I0526 14:51:35.417299 32260 sgd_solver.cpp:106] Iteration 465750, lr = 0.0015
I0526 14:51:47.529430 32260 solver.cpp:237] Iteration 466500, loss = 0.656325
I0526 14:51:47.529476 32260 solver.cpp:253]     Train net output #0: loss = 0.656323 (* 1 = 0.656323 loss)
I0526 14:51:47.529491 32260 sgd_solver.cpp:106] Iteration 466500, lr = 0.0015
I0526 14:51:59.643970 32260 solver.cpp:237] Iteration 467250, loss = 1.06365
I0526 14:51:59.644006 32260 solver.cpp:253]     Train net output #0: loss = 1.06365 (* 1 = 1.06365 loss)
I0526 14:51:59.644019 32260 sgd_solver.cpp:106] Iteration 467250, lr = 0.0015
I0526 14:52:11.741667 32260 solver.cpp:237] Iteration 468000, loss = 0.951233
I0526 14:52:11.741849 32260 solver.cpp:253]     Train net output #0: loss = 0.951231 (* 1 = 0.951231 loss)
I0526 14:52:11.741864 32260 sgd_solver.cpp:106] Iteration 468000, lr = 0.0015
I0526 14:52:23.821538 32260 solver.cpp:237] Iteration 468750, loss = 1.16446
I0526 14:52:23.821574 32260 solver.cpp:253]     Train net output #0: loss = 1.16446 (* 1 = 1.16446 loss)
I0526 14:52:23.821588 32260 sgd_solver.cpp:106] Iteration 468750, lr = 0.0015
I0526 14:52:35.904600 32260 solver.cpp:237] Iteration 469500, loss = 1.91637
I0526 14:52:35.904650 32260 solver.cpp:253]     Train net output #0: loss = 1.91637 (* 1 = 1.91637 loss)
I0526 14:52:35.904664 32260 sgd_solver.cpp:106] Iteration 469500, lr = 0.0015
I0526 14:53:08.860090 32260 solver.cpp:237] Iteration 470250, loss = 1.62259
I0526 14:53:08.860273 32260 solver.cpp:253]     Train net output #0: loss = 1.62259 (* 1 = 1.62259 loss)
I0526 14:53:08.860288 32260 sgd_solver.cpp:106] Iteration 470250, lr = 0.0015
I0526 14:53:20.971640 32260 solver.cpp:237] Iteration 471000, loss = 1.13255
I0526 14:53:20.971688 32260 solver.cpp:253]     Train net output #0: loss = 1.13255 (* 1 = 1.13255 loss)
I0526 14:53:20.971703 32260 sgd_solver.cpp:106] Iteration 471000, lr = 0.0015
I0526 14:53:33.095603 32260 solver.cpp:237] Iteration 471750, loss = 1.47631
I0526 14:53:33.095638 32260 solver.cpp:253]     Train net output #0: loss = 1.47631 (* 1 = 1.47631 loss)
I0526 14:53:33.095651 32260 sgd_solver.cpp:106] Iteration 471750, lr = 0.0015
I0526 14:53:45.213625 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_472500.caffemodel
I0526 14:53:45.274966 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_472500.solverstate
I0526 14:53:45.318624 32260 solver.cpp:237] Iteration 472500, loss = 1.31602
I0526 14:53:45.318670 32260 solver.cpp:253]     Train net output #0: loss = 1.31602 (* 1 = 1.31602 loss)
I0526 14:53:45.318691 32260 sgd_solver.cpp:106] Iteration 472500, lr = 0.0015
I0526 14:53:57.468230 32260 solver.cpp:237] Iteration 473250, loss = 1.39616
I0526 14:53:57.468266 32260 solver.cpp:253]     Train net output #0: loss = 1.39615 (* 1 = 1.39615 loss)
I0526 14:53:57.468279 32260 sgd_solver.cpp:106] Iteration 473250, lr = 0.0015
I0526 14:54:09.613796 32260 solver.cpp:237] Iteration 474000, loss = 0.740786
I0526 14:54:09.613848 32260 solver.cpp:253]     Train net output #0: loss = 0.740784 (* 1 = 0.740784 loss)
I0526 14:54:09.613862 32260 sgd_solver.cpp:106] Iteration 474000, lr = 0.0015
I0526 14:54:21.736217 32260 solver.cpp:237] Iteration 474750, loss = 1.13843
I0526 14:54:21.736395 32260 solver.cpp:253]     Train net output #0: loss = 1.13843 (* 1 = 1.13843 loss)
I0526 14:54:21.736409 32260 sgd_solver.cpp:106] Iteration 474750, lr = 0.0015
I0526 14:54:54.719187 32260 solver.cpp:237] Iteration 475500, loss = 1.74347
I0526 14:54:54.719363 32260 solver.cpp:253]     Train net output #0: loss = 1.74347 (* 1 = 1.74347 loss)
I0526 14:54:54.719378 32260 sgd_solver.cpp:106] Iteration 475500, lr = 0.0015
I0526 14:55:06.839051 32260 solver.cpp:237] Iteration 476250, loss = 0.80858
I0526 14:55:06.839095 32260 solver.cpp:253]     Train net output #0: loss = 0.808577 (* 1 = 0.808577 loss)
I0526 14:55:06.839110 32260 sgd_solver.cpp:106] Iteration 476250, lr = 0.0015
I0526 14:55:18.993650 32260 solver.cpp:237] Iteration 477000, loss = 1.60998
I0526 14:55:18.993686 32260 solver.cpp:253]     Train net output #0: loss = 1.60998 (* 1 = 1.60998 loss)
I0526 14:55:18.993700 32260 sgd_solver.cpp:106] Iteration 477000, lr = 0.0015
I0526 14:55:31.142684 32260 solver.cpp:237] Iteration 477750, loss = 1.15614
I0526 14:55:31.142850 32260 solver.cpp:253]     Train net output #0: loss = 1.15614 (* 1 = 1.15614 loss)
I0526 14:55:31.142864 32260 sgd_solver.cpp:106] Iteration 477750, lr = 0.0015
I0526 14:55:43.305594 32260 solver.cpp:237] Iteration 478500, loss = 1.29973
I0526 14:55:43.305629 32260 solver.cpp:253]     Train net output #0: loss = 1.29973 (* 1 = 1.29973 loss)
I0526 14:55:43.305644 32260 sgd_solver.cpp:106] Iteration 478500, lr = 0.0015
I0526 14:55:55.426970 32260 solver.cpp:237] Iteration 479250, loss = 1.12787
I0526 14:55:55.427019 32260 solver.cpp:253]     Train net output #0: loss = 1.12786 (* 1 = 1.12786 loss)
I0526 14:55:55.427033 32260 sgd_solver.cpp:106] Iteration 479250, lr = 0.0015
I0526 14:56:07.528825 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_480000.caffemodel
I0526 14:56:07.587656 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_480000.solverstate
I0526 14:56:07.621865 32260 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 14:56:59.577688 32260 solver.cpp:409]     Test net output #0: accuracy = 0.900792
I0526 14:56:59.577872 32260 solver.cpp:409]     Test net output #1: loss = 0.329428 (* 1 = 0.329428 loss)
I0526 14:57:20.428302 32260 solver.cpp:237] Iteration 480000, loss = 1.33228
I0526 14:57:20.428352 32260 solver.cpp:253]     Train net output #0: loss = 1.33228 (* 1 = 1.33228 loss)
I0526 14:57:20.428369 32260 sgd_solver.cpp:106] Iteration 480000, lr = 0.0015
I0526 14:57:32.588124 32260 solver.cpp:237] Iteration 480750, loss = 0.752325
I0526 14:57:32.588304 32260 solver.cpp:253]     Train net output #0: loss = 0.752323 (* 1 = 0.752323 loss)
I0526 14:57:32.588318 32260 sgd_solver.cpp:106] Iteration 480750, lr = 0.0015
I0526 14:57:44.751385 32260 solver.cpp:237] Iteration 481500, loss = 1.36697
I0526 14:57:44.751421 32260 solver.cpp:253]     Train net output #0: loss = 1.36697 (* 1 = 1.36697 loss)
I0526 14:57:44.751437 32260 sgd_solver.cpp:106] Iteration 481500, lr = 0.0015
I0526 14:57:56.905177 32260 solver.cpp:237] Iteration 482250, loss = 1.26724
I0526 14:57:56.905227 32260 solver.cpp:253]     Train net output #0: loss = 1.26724 (* 1 = 1.26724 loss)
I0526 14:57:56.905241 32260 sgd_solver.cpp:106] Iteration 482250, lr = 0.0015
I0526 14:58:09.069653 32260 solver.cpp:237] Iteration 483000, loss = 0.790997
I0526 14:58:09.069814 32260 solver.cpp:253]     Train net output #0: loss = 0.790994 (* 1 = 0.790994 loss)
I0526 14:58:09.069829 32260 sgd_solver.cpp:106] Iteration 483000, lr = 0.0015
I0526 14:58:21.319241 32260 solver.cpp:237] Iteration 483750, loss = 1.12188
I0526 14:58:21.319286 32260 solver.cpp:253]     Train net output #0: loss = 1.12188 (* 1 = 1.12188 loss)
I0526 14:58:21.319299 32260 sgd_solver.cpp:106] Iteration 483750, lr = 0.0015
I0526 14:58:33.522073 32260 solver.cpp:237] Iteration 484500, loss = 0.9901
I0526 14:58:33.522110 32260 solver.cpp:253]     Train net output #0: loss = 0.990097 (* 1 = 0.990097 loss)
I0526 14:58:33.522124 32260 sgd_solver.cpp:106] Iteration 484500, lr = 0.0015
I0526 14:59:06.640625 32260 solver.cpp:237] Iteration 485250, loss = 1.09206
I0526 14:59:06.640805 32260 solver.cpp:253]     Train net output #0: loss = 1.09206 (* 1 = 1.09206 loss)
I0526 14:59:06.640821 32260 sgd_solver.cpp:106] Iteration 485250, lr = 0.0015
I0526 14:59:18.884763 32260 solver.cpp:237] Iteration 486000, loss = 0.788686
I0526 14:59:18.884807 32260 solver.cpp:253]     Train net output #0: loss = 0.788684 (* 1 = 0.788684 loss)
I0526 14:59:18.884824 32260 sgd_solver.cpp:106] Iteration 486000, lr = 0.0015
I0526 14:59:31.148011 32260 solver.cpp:237] Iteration 486750, loss = 1.30236
I0526 14:59:31.148047 32260 solver.cpp:253]     Train net output #0: loss = 1.30236 (* 1 = 1.30236 loss)
I0526 14:59:31.148064 32260 sgd_solver.cpp:106] Iteration 486750, lr = 0.0015
I0526 14:59:43.330284 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_487500.caffemodel
I0526 14:59:43.387591 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_487500.solverstate
I0526 14:59:43.426983 32260 solver.cpp:237] Iteration 487500, loss = 1.11371
I0526 14:59:43.427026 32260 solver.cpp:253]     Train net output #0: loss = 1.11371 (* 1 = 1.11371 loss)
I0526 14:59:43.427048 32260 sgd_solver.cpp:106] Iteration 487500, lr = 0.0015
I0526 14:59:55.633482 32260 solver.cpp:237] Iteration 488250, loss = 1.32182
I0526 14:59:55.633518 32260 solver.cpp:253]     Train net output #0: loss = 1.32182 (* 1 = 1.32182 loss)
I0526 14:59:55.633532 32260 sgd_solver.cpp:106] Iteration 488250, lr = 0.0015
I0526 15:00:07.797904 32260 solver.cpp:237] Iteration 489000, loss = 1.11232
I0526 15:00:07.797955 32260 solver.cpp:253]     Train net output #0: loss = 1.11232 (* 1 = 1.11232 loss)
I0526 15:00:07.797968 32260 sgd_solver.cpp:106] Iteration 489000, lr = 0.0015
I0526 15:00:19.952550 32260 solver.cpp:237] Iteration 489750, loss = 1.04614
I0526 15:00:19.952720 32260 solver.cpp:253]     Train net output #0: loss = 1.04614 (* 1 = 1.04614 loss)
I0526 15:00:19.952734 32260 sgd_solver.cpp:106] Iteration 489750, lr = 0.0015
I0526 15:00:52.968233 32260 solver.cpp:237] Iteration 490500, loss = 0.835939
I0526 15:00:52.968415 32260 solver.cpp:253]     Train net output #0: loss = 0.835937 (* 1 = 0.835937 loss)
I0526 15:00:52.968431 32260 sgd_solver.cpp:106] Iteration 490500, lr = 0.0015
I0526 15:01:05.156440 32260 solver.cpp:237] Iteration 491250, loss = 1.62875
I0526 15:01:05.156476 32260 solver.cpp:253]     Train net output #0: loss = 1.62875 (* 1 = 1.62875 loss)
I0526 15:01:05.156491 32260 sgd_solver.cpp:106] Iteration 491250, lr = 0.0015
I0526 15:01:17.330801 32260 solver.cpp:237] Iteration 492000, loss = 1.20736
I0526 15:01:17.330848 32260 solver.cpp:253]     Train net output #0: loss = 1.20735 (* 1 = 1.20735 loss)
I0526 15:01:17.330864 32260 sgd_solver.cpp:106] Iteration 492000, lr = 0.0015
I0526 15:01:29.503950 32260 solver.cpp:237] Iteration 492750, loss = 0.940838
I0526 15:01:29.504113 32260 solver.cpp:253]     Train net output #0: loss = 0.940836 (* 1 = 0.940836 loss)
I0526 15:01:29.504128 32260 sgd_solver.cpp:106] Iteration 492750, lr = 0.0015
I0526 15:01:41.688601 32260 solver.cpp:237] Iteration 493500, loss = 1.06362
I0526 15:01:41.688644 32260 solver.cpp:253]     Train net output #0: loss = 1.06362 (* 1 = 1.06362 loss)
I0526 15:01:41.688658 32260 sgd_solver.cpp:106] Iteration 493500, lr = 0.0015
I0526 15:01:53.848229 32260 solver.cpp:237] Iteration 494250, loss = 0.864216
I0526 15:01:53.848265 32260 solver.cpp:253]     Train net output #0: loss = 0.864214 (* 1 = 0.864214 loss)
I0526 15:01:53.848279 32260 sgd_solver.cpp:106] Iteration 494250, lr = 0.0015
I0526 15:02:06.036921 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_495000.caffemodel
I0526 15:02:06.099337 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_495000.solverstate
I0526 15:02:06.133371 32260 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 15:03:19.044649 32260 solver.cpp:409]     Test net output #0: accuracy = 0.905178
I0526 15:03:19.044829 32260 solver.cpp:409]     Test net output #1: loss = 0.304049 (* 1 = 0.304049 loss)
I0526 15:03:39.916996 32260 solver.cpp:237] Iteration 495000, loss = 0.988021
I0526 15:03:39.917049 32260 solver.cpp:253]     Train net output #0: loss = 0.988018 (* 1 = 0.988018 loss)
I0526 15:03:39.917065 32260 sgd_solver.cpp:106] Iteration 495000, lr = 0.0015
I0526 15:03:52.065320 32260 solver.cpp:237] Iteration 495750, loss = 0.795675
I0526 15:03:52.065496 32260 solver.cpp:253]     Train net output #0: loss = 0.795673 (* 1 = 0.795673 loss)
I0526 15:03:52.065510 32260 sgd_solver.cpp:106] Iteration 495750, lr = 0.0015
I0526 15:04:04.183969 32260 solver.cpp:237] Iteration 496500, loss = 1.11314
I0526 15:04:04.184005 32260 solver.cpp:253]     Train net output #0: loss = 1.11314 (* 1 = 1.11314 loss)
I0526 15:04:04.184018 32260 sgd_solver.cpp:106] Iteration 496500, lr = 0.0015
I0526 15:04:16.339838 32260 solver.cpp:237] Iteration 497250, loss = 0.970512
I0526 15:04:16.339887 32260 solver.cpp:253]     Train net output #0: loss = 0.97051 (* 1 = 0.97051 loss)
I0526 15:04:16.339900 32260 sgd_solver.cpp:106] Iteration 497250, lr = 0.0015
I0526 15:04:28.511276 32260 solver.cpp:237] Iteration 498000, loss = 1.22727
I0526 15:04:28.511466 32260 solver.cpp:253]     Train net output #0: loss = 1.22727 (* 1 = 1.22727 loss)
I0526 15:04:28.511481 32260 sgd_solver.cpp:106] Iteration 498000, lr = 0.0015
I0526 15:04:40.709111 32260 solver.cpp:237] Iteration 498750, loss = 1.01652
I0526 15:04:40.709156 32260 solver.cpp:253]     Train net output #0: loss = 1.01652 (* 1 = 1.01652 loss)
I0526 15:04:40.709172 32260 sgd_solver.cpp:106] Iteration 498750, lr = 0.0015
I0526 15:04:52.832247 32260 solver.cpp:237] Iteration 499500, loss = 0.966906
I0526 15:04:52.832283 32260 solver.cpp:253]     Train net output #0: loss = 0.966903 (* 1 = 0.966903 loss)
I0526 15:04:52.832299 32260 sgd_solver.cpp:106] Iteration 499500, lr = 0.0015
I0526 15:05:25.893527 32260 solver.cpp:237] Iteration 500250, loss = 1.17442
I0526 15:05:25.893707 32260 solver.cpp:253]     Train net output #0: loss = 1.17442 (* 1 = 1.17442 loss)
I0526 15:05:25.893723 32260 sgd_solver.cpp:106] Iteration 500250, lr = 0.0015
I0526 15:05:38.074082 32260 solver.cpp:237] Iteration 501000, loss = 0.792304
I0526 15:05:38.074115 32260 solver.cpp:253]     Train net output #0: loss = 0.792302 (* 1 = 0.792302 loss)
I0526 15:05:38.074127 32260 sgd_solver.cpp:106] Iteration 501000, lr = 0.0015
I0526 15:05:50.242916 32260 solver.cpp:237] Iteration 501750, loss = 1.01127
I0526 15:05:50.242966 32260 solver.cpp:253]     Train net output #0: loss = 1.01126 (* 1 = 1.01126 loss)
I0526 15:05:50.242980 32260 sgd_solver.cpp:106] Iteration 501750, lr = 0.0015
I0526 15:06:02.367143 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_502500.caffemodel
I0526 15:06:02.427758 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_502500.solverstate
I0526 15:06:02.464995 32260 solver.cpp:237] Iteration 502500, loss = 1.80037
I0526 15:06:02.465041 32260 solver.cpp:253]     Train net output #0: loss = 1.80037 (* 1 = 1.80037 loss)
I0526 15:06:02.465062 32260 sgd_solver.cpp:106] Iteration 502500, lr = 0.0015
I0526 15:06:14.602288 32260 solver.cpp:237] Iteration 503250, loss = 0.893662
I0526 15:06:14.602336 32260 solver.cpp:253]     Train net output #0: loss = 0.893661 (* 1 = 0.893661 loss)
I0526 15:06:14.602352 32260 sgd_solver.cpp:106] Iteration 503250, lr = 0.0015
I0526 15:06:26.736657 32260 solver.cpp:237] Iteration 504000, loss = 1.36006
I0526 15:06:26.736693 32260 solver.cpp:253]     Train net output #0: loss = 1.36006 (* 1 = 1.36006 loss)
I0526 15:06:26.736706 32260 sgd_solver.cpp:106] Iteration 504000, lr = 0.0015
I0526 15:06:38.896056 32260 solver.cpp:237] Iteration 504750, loss = 1.15584
I0526 15:06:38.896235 32260 solver.cpp:253]     Train net output #0: loss = 1.15584 (* 1 = 1.15584 loss)
I0526 15:06:38.896250 32260 sgd_solver.cpp:106] Iteration 504750, lr = 0.0015
I0526 15:07:11.965032 32260 solver.cpp:237] Iteration 505500, loss = 1.39071
I0526 15:07:11.965216 32260 solver.cpp:253]     Train net output #0: loss = 1.39071 (* 1 = 1.39071 loss)
I0526 15:07:11.965232 32260 sgd_solver.cpp:106] Iteration 505500, lr = 0.0015
I0526 15:07:24.109314 32260 solver.cpp:237] Iteration 506250, loss = 1.27125
I0526 15:07:24.109349 32260 solver.cpp:253]     Train net output #0: loss = 1.27125 (* 1 = 1.27125 loss)
I0526 15:07:24.109366 32260 sgd_solver.cpp:106] Iteration 506250, lr = 0.0015
I0526 15:07:36.292629 32260 solver.cpp:237] Iteration 507000, loss = 1.41297
I0526 15:07:36.292675 32260 solver.cpp:253]     Train net output #0: loss = 1.41296 (* 1 = 1.41296 loss)
I0526 15:07:36.292687 32260 sgd_solver.cpp:106] Iteration 507000, lr = 0.0015
I0526 15:07:48.471807 32260 solver.cpp:237] Iteration 507750, loss = 1.45033
I0526 15:07:48.471981 32260 solver.cpp:253]     Train net output #0: loss = 1.45033 (* 1 = 1.45033 loss)
I0526 15:07:48.471995 32260 sgd_solver.cpp:106] Iteration 507750, lr = 0.0015
I0526 15:08:00.682736 32260 solver.cpp:237] Iteration 508500, loss = 1.7391
I0526 15:08:00.682785 32260 solver.cpp:253]     Train net output #0: loss = 1.7391 (* 1 = 1.7391 loss)
I0526 15:08:00.682798 32260 sgd_solver.cpp:106] Iteration 508500, lr = 0.0015
I0526 15:08:12.872203 32260 solver.cpp:237] Iteration 509250, loss = 1.62104
I0526 15:08:12.872239 32260 solver.cpp:253]     Train net output #0: loss = 1.62104 (* 1 = 1.62104 loss)
I0526 15:08:12.872252 32260 sgd_solver.cpp:106] Iteration 509250, lr = 0.0015
I0526 15:08:25.031472 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_510000.caffemodel
I0526 15:08:25.090946 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_510000.solverstate
I0526 15:08:25.127228 32260 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 15:09:16.772773 32260 solver.cpp:409]     Test net output #0: accuracy = 0.903379
I0526 15:09:16.772974 32260 solver.cpp:409]     Test net output #1: loss = 0.305113 (* 1 = 0.305113 loss)
I0526 15:09:37.628916 32260 solver.cpp:237] Iteration 510000, loss = 1.02299
I0526 15:09:37.628968 32260 solver.cpp:253]     Train net output #0: loss = 1.02298 (* 1 = 1.02298 loss)
I0526 15:09:37.628983 32260 sgd_solver.cpp:106] Iteration 510000, lr = 0.0015
I0526 15:09:49.765139 32260 solver.cpp:237] Iteration 510750, loss = 0.804341
I0526 15:09:49.765305 32260 solver.cpp:253]     Train net output #0: loss = 0.804339 (* 1 = 0.804339 loss)
I0526 15:09:49.765321 32260 sgd_solver.cpp:106] Iteration 510750, lr = 0.0015
I0526 15:10:01.919668 32260 solver.cpp:237] Iteration 511500, loss = 1.01374
I0526 15:10:01.919713 32260 solver.cpp:253]     Train net output #0: loss = 1.01373 (* 1 = 1.01373 loss)
I0526 15:10:01.919726 32260 sgd_solver.cpp:106] Iteration 511500, lr = 0.0015
I0526 15:10:14.033623 32260 solver.cpp:237] Iteration 512250, loss = 1.10712
I0526 15:10:14.033659 32260 solver.cpp:253]     Train net output #0: loss = 1.10712 (* 1 = 1.10712 loss)
I0526 15:10:14.033673 32260 sgd_solver.cpp:106] Iteration 512250, lr = 0.0015
I0526 15:10:26.138739 32260 solver.cpp:237] Iteration 513000, loss = 1.37968
I0526 15:10:26.138917 32260 solver.cpp:253]     Train net output #0: loss = 1.37968 (* 1 = 1.37968 loss)
I0526 15:10:26.138933 32260 sgd_solver.cpp:106] Iteration 513000, lr = 0.0015
I0526 15:10:38.261863 32260 solver.cpp:237] Iteration 513750, loss = 1.1629
I0526 15:10:38.261900 32260 solver.cpp:253]     Train net output #0: loss = 1.1629 (* 1 = 1.1629 loss)
I0526 15:10:38.261920 32260 sgd_solver.cpp:106] Iteration 513750, lr = 0.0015
I0526 15:10:50.460886 32260 solver.cpp:237] Iteration 514500, loss = 1.10685
I0526 15:10:50.460932 32260 solver.cpp:253]     Train net output #0: loss = 1.10684 (* 1 = 1.10684 loss)
I0526 15:10:50.460947 32260 sgd_solver.cpp:106] Iteration 514500, lr = 0.0015
I0526 15:11:23.577272 32260 solver.cpp:237] Iteration 515250, loss = 1.13852
I0526 15:11:23.577476 32260 solver.cpp:253]     Train net output #0: loss = 1.13851 (* 1 = 1.13851 loss)
I0526 15:11:23.577491 32260 sgd_solver.cpp:106] Iteration 515250, lr = 0.0015
I0526 15:11:35.773416 32260 solver.cpp:237] Iteration 516000, loss = 0.827393
I0526 15:11:35.773452 32260 solver.cpp:253]     Train net output #0: loss = 0.827391 (* 1 = 0.827391 loss)
I0526 15:11:35.773470 32260 sgd_solver.cpp:106] Iteration 516000, lr = 0.0015
I0526 15:11:47.919200 32260 solver.cpp:237] Iteration 516750, loss = 1.42549
I0526 15:11:47.919248 32260 solver.cpp:253]     Train net output #0: loss = 1.42549 (* 1 = 1.42549 loss)
I0526 15:11:47.919261 32260 sgd_solver.cpp:106] Iteration 516750, lr = 0.0015
I0526 15:12:00.048524 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_517500.caffemodel
I0526 15:12:00.101052 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_517500.solverstate
I0526 15:12:00.136054 32260 solver.cpp:237] Iteration 517500, loss = 0.600842
I0526 15:12:00.136101 32260 solver.cpp:253]     Train net output #0: loss = 0.60084 (* 1 = 0.60084 loss)
I0526 15:12:00.136116 32260 sgd_solver.cpp:106] Iteration 517500, lr = 0.0015
I0526 15:12:12.272513 32260 solver.cpp:237] Iteration 518250, loss = 1.22501
I0526 15:12:12.272557 32260 solver.cpp:253]     Train net output #0: loss = 1.22501 (* 1 = 1.22501 loss)
I0526 15:12:12.272572 32260 sgd_solver.cpp:106] Iteration 518250, lr = 0.0015
I0526 15:12:24.370460 32260 solver.cpp:237] Iteration 519000, loss = 0.904739
I0526 15:12:24.370497 32260 solver.cpp:253]     Train net output #0: loss = 0.904738 (* 1 = 0.904738 loss)
I0526 15:12:24.370512 32260 sgd_solver.cpp:106] Iteration 519000, lr = 0.0015
I0526 15:12:36.450063 32260 solver.cpp:237] Iteration 519750, loss = 1.16406
I0526 15:12:36.450245 32260 solver.cpp:253]     Train net output #0: loss = 1.16406 (* 1 = 1.16406 loss)
I0526 15:12:36.450261 32260 sgd_solver.cpp:106] Iteration 519750, lr = 0.0015
I0526 15:13:09.391515 32260 solver.cpp:237] Iteration 520500, loss = 1.23874
I0526 15:13:09.391718 32260 solver.cpp:253]     Train net output #0: loss = 1.23874 (* 1 = 1.23874 loss)
I0526 15:13:09.391733 32260 sgd_solver.cpp:106] Iteration 520500, lr = 0.0015
I0526 15:13:21.477071 32260 solver.cpp:237] Iteration 521250, loss = 0.651862
I0526 15:13:21.477116 32260 solver.cpp:253]     Train net output #0: loss = 0.65186 (* 1 = 0.65186 loss)
I0526 15:13:21.477130 32260 sgd_solver.cpp:106] Iteration 521250, lr = 0.0015
I0526 15:13:33.598863 32260 solver.cpp:237] Iteration 522000, loss = 1.06973
I0526 15:13:33.598899 32260 solver.cpp:253]     Train net output #0: loss = 1.06973 (* 1 = 1.06973 loss)
I0526 15:13:33.598912 32260 sgd_solver.cpp:106] Iteration 522000, lr = 0.0015
I0526 15:13:45.745076 32260 solver.cpp:237] Iteration 522750, loss = 1.15887
I0526 15:13:45.745256 32260 solver.cpp:253]     Train net output #0: loss = 1.15887 (* 1 = 1.15887 loss)
I0526 15:13:45.745271 32260 sgd_solver.cpp:106] Iteration 522750, lr = 0.0015
I0526 15:13:57.895515 32260 solver.cpp:237] Iteration 523500, loss = 1.19727
I0526 15:13:57.895551 32260 solver.cpp:253]     Train net output #0: loss = 1.19727 (* 1 = 1.19727 loss)
I0526 15:13:57.895565 32260 sgd_solver.cpp:106] Iteration 523500, lr = 0.0015
I0526 15:14:10.027698 32260 solver.cpp:237] Iteration 524250, loss = 0.868127
I0526 15:14:10.027746 32260 solver.cpp:253]     Train net output #0: loss = 0.868125 (* 1 = 0.868125 loss)
I0526 15:14:10.027760 32260 sgd_solver.cpp:106] Iteration 524250, lr = 0.0015
I0526 15:14:22.151330 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_525000.caffemodel
I0526 15:14:22.199707 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_525000.solverstate
I0526 15:14:22.224768 32260 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 15:15:35.015751 32260 solver.cpp:409]     Test net output #0: accuracy = 0.90718
I0526 15:15:35.015935 32260 solver.cpp:409]     Test net output #1: loss = 0.302941 (* 1 = 0.302941 loss)
I0526 15:15:55.848440 32260 solver.cpp:237] Iteration 525000, loss = 1.07506
I0526 15:15:55.848494 32260 solver.cpp:253]     Train net output #0: loss = 1.07505 (* 1 = 1.07505 loss)
I0526 15:15:55.848507 32260 sgd_solver.cpp:106] Iteration 525000, lr = 0.0015
I0526 15:16:07.965256 32260 solver.cpp:237] Iteration 525750, loss = 1.21764
I0526 15:16:07.965446 32260 solver.cpp:253]     Train net output #0: loss = 1.21763 (* 1 = 1.21763 loss)
I0526 15:16:07.965461 32260 sgd_solver.cpp:106] Iteration 525750, lr = 0.0015
I0526 15:16:20.083076 32260 solver.cpp:237] Iteration 526500, loss = 1.09238
I0526 15:16:20.083119 32260 solver.cpp:253]     Train net output #0: loss = 1.09238 (* 1 = 1.09238 loss)
I0526 15:16:20.083135 32260 sgd_solver.cpp:106] Iteration 526500, lr = 0.0015
I0526 15:16:32.193940 32260 solver.cpp:237] Iteration 527250, loss = 1.55967
I0526 15:16:32.193976 32260 solver.cpp:253]     Train net output #0: loss = 1.55967 (* 1 = 1.55967 loss)
I0526 15:16:32.193989 32260 sgd_solver.cpp:106] Iteration 527250, lr = 0.0015
I0526 15:16:44.286491 32260 solver.cpp:237] Iteration 528000, loss = 0.762872
I0526 15:16:44.286674 32260 solver.cpp:253]     Train net output #0: loss = 0.76287 (* 1 = 0.76287 loss)
I0526 15:16:44.286689 32260 sgd_solver.cpp:106] Iteration 528000, lr = 0.0015
I0526 15:16:56.399839 32260 solver.cpp:237] Iteration 528750, loss = 1.67316
I0526 15:16:56.399875 32260 solver.cpp:253]     Train net output #0: loss = 1.67316 (* 1 = 1.67316 loss)
I0526 15:16:56.399888 32260 sgd_solver.cpp:106] Iteration 528750, lr = 0.0015
I0526 15:17:08.510851 32260 solver.cpp:237] Iteration 529500, loss = 1.04477
I0526 15:17:08.510900 32260 solver.cpp:253]     Train net output #0: loss = 1.04477 (* 1 = 1.04477 loss)
I0526 15:17:08.510915 32260 sgd_solver.cpp:106] Iteration 529500, lr = 0.0015
I0526 15:17:41.453645 32260 solver.cpp:237] Iteration 530250, loss = 1.10238
I0526 15:17:41.453831 32260 solver.cpp:253]     Train net output #0: loss = 1.10238 (* 1 = 1.10238 loss)
I0526 15:17:41.453846 32260 sgd_solver.cpp:106] Iteration 530250, lr = 0.0015
I0526 15:17:53.554091 32260 solver.cpp:237] Iteration 531000, loss = 0.960248
I0526 15:17:53.554141 32260 solver.cpp:253]     Train net output #0: loss = 0.960246 (* 1 = 0.960246 loss)
I0526 15:17:53.554155 32260 sgd_solver.cpp:106] Iteration 531000, lr = 0.0015
I0526 15:18:05.661592 32260 solver.cpp:237] Iteration 531750, loss = 0.881467
I0526 15:18:05.661629 32260 solver.cpp:253]     Train net output #0: loss = 0.881465 (* 1 = 0.881465 loss)
I0526 15:18:05.661643 32260 sgd_solver.cpp:106] Iteration 531750, lr = 0.0015
I0526 15:18:17.749965 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_532500.caffemodel
I0526 15:18:17.798969 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_532500.solverstate
I0526 15:18:17.832347 32260 solver.cpp:237] Iteration 532500, loss = 0.875196
I0526 15:18:17.832394 32260 solver.cpp:253]     Train net output #0: loss = 0.875194 (* 1 = 0.875194 loss)
I0526 15:18:17.832409 32260 sgd_solver.cpp:106] Iteration 532500, lr = 0.0015
I0526 15:18:30.004359 32260 solver.cpp:237] Iteration 533250, loss = 1.06943
I0526 15:18:30.004395 32260 solver.cpp:253]     Train net output #0: loss = 1.06943 (* 1 = 1.06943 loss)
I0526 15:18:30.004410 32260 sgd_solver.cpp:106] Iteration 533250, lr = 0.0015
I0526 15:18:42.175796 32260 solver.cpp:237] Iteration 534000, loss = 0.940194
I0526 15:18:42.175832 32260 solver.cpp:253]     Train net output #0: loss = 0.940192 (* 1 = 0.940192 loss)
I0526 15:18:42.175845 32260 sgd_solver.cpp:106] Iteration 534000, lr = 0.0015
I0526 15:18:54.324594 32260 solver.cpp:237] Iteration 534750, loss = 0.993649
I0526 15:18:54.324765 32260 solver.cpp:253]     Train net output #0: loss = 0.993647 (* 1 = 0.993647 loss)
I0526 15:18:54.324779 32260 sgd_solver.cpp:106] Iteration 534750, lr = 0.0015
I0526 15:19:27.313477 32260 solver.cpp:237] Iteration 535500, loss = 0.834815
I0526 15:19:27.313679 32260 solver.cpp:253]     Train net output #0: loss = 0.834813 (* 1 = 0.834813 loss)
I0526 15:19:27.313694 32260 sgd_solver.cpp:106] Iteration 535500, lr = 0.0015
I0526 15:19:39.390552 32260 solver.cpp:237] Iteration 536250, loss = 0.986864
I0526 15:19:39.390594 32260 solver.cpp:253]     Train net output #0: loss = 0.986862 (* 1 = 0.986862 loss)
I0526 15:19:39.390609 32260 sgd_solver.cpp:106] Iteration 536250, lr = 0.0015
I0526 15:19:51.485019 32260 solver.cpp:237] Iteration 537000, loss = 1.21159
I0526 15:19:51.485054 32260 solver.cpp:253]     Train net output #0: loss = 1.21159 (* 1 = 1.21159 loss)
I0526 15:19:51.485067 32260 sgd_solver.cpp:106] Iteration 537000, lr = 0.0015
I0526 15:20:03.621131 32260 solver.cpp:237] Iteration 537750, loss = 0.793284
I0526 15:20:03.621310 32260 solver.cpp:253]     Train net output #0: loss = 0.793282 (* 1 = 0.793282 loss)
I0526 15:20:03.621326 32260 sgd_solver.cpp:106] Iteration 537750, lr = 0.0015
I0526 15:20:15.765668 32260 solver.cpp:237] Iteration 538500, loss = 0.913523
I0526 15:20:15.765704 32260 solver.cpp:253]     Train net output #0: loss = 0.913521 (* 1 = 0.913521 loss)
I0526 15:20:15.765717 32260 sgd_solver.cpp:106] Iteration 538500, lr = 0.0015
I0526 15:20:27.906306 32260 solver.cpp:237] Iteration 539250, loss = 1.10459
I0526 15:20:27.906349 32260 solver.cpp:253]     Train net output #0: loss = 1.10459 (* 1 = 1.10459 loss)
I0526 15:20:27.906363 32260 sgd_solver.cpp:106] Iteration 539250, lr = 0.0015
I0526 15:20:40.026970 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_540000.caffemodel
I0526 15:20:40.078223 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_540000.solverstate
I0526 15:20:40.104977 32260 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 15:21:32.062847 32260 solver.cpp:409]     Test net output #0: accuracy = 0.903347
I0526 15:21:32.063032 32260 solver.cpp:409]     Test net output #1: loss = 0.318468 (* 1 = 0.318468 loss)
I0526 15:21:52.917067 32260 solver.cpp:237] Iteration 540000, loss = 0.930482
I0526 15:21:52.917121 32260 solver.cpp:253]     Train net output #0: loss = 0.93048 (* 1 = 0.93048 loss)
I0526 15:21:52.917136 32260 sgd_solver.cpp:106] Iteration 540000, lr = 0.0015
I0526 15:22:05.170578 32260 solver.cpp:237] Iteration 540750, loss = 0.974639
I0526 15:22:05.170774 32260 solver.cpp:253]     Train net output #0: loss = 0.974637 (* 1 = 0.974637 loss)
I0526 15:22:05.170789 32260 sgd_solver.cpp:106] Iteration 540750, lr = 0.0015
I0526 15:22:17.404244 32260 solver.cpp:237] Iteration 541500, loss = 0.891752
I0526 15:22:17.404281 32260 solver.cpp:253]     Train net output #0: loss = 0.89175 (* 1 = 0.89175 loss)
I0526 15:22:17.404297 32260 sgd_solver.cpp:106] Iteration 541500, lr = 0.0015
I0526 15:22:29.642957 32260 solver.cpp:237] Iteration 542250, loss = 1.34174
I0526 15:22:29.643003 32260 solver.cpp:253]     Train net output #0: loss = 1.34174 (* 1 = 1.34174 loss)
I0526 15:22:29.643020 32260 sgd_solver.cpp:106] Iteration 542250, lr = 0.0015
I0526 15:22:41.884599 32260 solver.cpp:237] Iteration 543000, loss = 0.808762
I0526 15:22:41.884768 32260 solver.cpp:253]     Train net output #0: loss = 0.80876 (* 1 = 0.80876 loss)
I0526 15:22:41.884783 32260 sgd_solver.cpp:106] Iteration 543000, lr = 0.0015
I0526 15:22:54.099453 32260 solver.cpp:237] Iteration 543750, loss = 1.01026
I0526 15:22:54.099503 32260 solver.cpp:253]     Train net output #0: loss = 1.01025 (* 1 = 1.01025 loss)
I0526 15:22:54.099519 32260 sgd_solver.cpp:106] Iteration 543750, lr = 0.0015
I0526 15:23:06.318909 32260 solver.cpp:237] Iteration 544500, loss = 1.37876
I0526 15:23:06.318946 32260 solver.cpp:253]     Train net output #0: loss = 1.37876 (* 1 = 1.37876 loss)
I0526 15:23:06.318960 32260 sgd_solver.cpp:106] Iteration 544500, lr = 0.0015
I0526 15:23:39.420285 32260 solver.cpp:237] Iteration 545250, loss = 1.27714
I0526 15:23:39.420486 32260 solver.cpp:253]     Train net output #0: loss = 1.27714 (* 1 = 1.27714 loss)
I0526 15:23:39.420501 32260 sgd_solver.cpp:106] Iteration 545250, lr = 0.0015
I0526 15:23:51.617602 32260 solver.cpp:237] Iteration 546000, loss = 1.41115
I0526 15:23:51.617646 32260 solver.cpp:253]     Train net output #0: loss = 1.41115 (* 1 = 1.41115 loss)
I0526 15:23:51.617660 32260 sgd_solver.cpp:106] Iteration 546000, lr = 0.0015
I0526 15:24:03.819284 32260 solver.cpp:237] Iteration 546750, loss = 0.888829
I0526 15:24:03.819321 32260 solver.cpp:253]     Train net output #0: loss = 0.888827 (* 1 = 0.888827 loss)
I0526 15:24:03.819337 32260 sgd_solver.cpp:106] Iteration 546750, lr = 0.0015
I0526 15:24:16.041651 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_547500.caffemodel
I0526 15:24:16.093653 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_547500.solverstate
I0526 15:24:16.126791 32260 solver.cpp:237] Iteration 547500, loss = 0.968584
I0526 15:24:16.126842 32260 solver.cpp:253]     Train net output #0: loss = 0.968583 (* 1 = 0.968583 loss)
I0526 15:24:16.126859 32260 sgd_solver.cpp:106] Iteration 547500, lr = 0.0015
I0526 15:24:28.284039 32260 solver.cpp:237] Iteration 548250, loss = 1.10096
I0526 15:24:28.284075 32260 solver.cpp:253]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0526 15:24:28.284090 32260 sgd_solver.cpp:106] Iteration 548250, lr = 0.0015
I0526 15:24:40.439245 32260 solver.cpp:237] Iteration 549000, loss = 1.16752
I0526 15:24:40.439296 32260 solver.cpp:253]     Train net output #0: loss = 1.16752 (* 1 = 1.16752 loss)
I0526 15:24:40.439311 32260 sgd_solver.cpp:106] Iteration 549000, lr = 0.0015
I0526 15:24:52.599120 32260 solver.cpp:237] Iteration 549750, loss = 1.24836
I0526 15:24:52.599303 32260 solver.cpp:253]     Train net output #0: loss = 1.24836 (* 1 = 1.24836 loss)
I0526 15:24:52.599316 32260 sgd_solver.cpp:106] Iteration 549750, lr = 0.0015
I0526 15:25:25.656325 32260 solver.cpp:237] Iteration 550500, loss = 1.02098
I0526 15:25:25.656517 32260 solver.cpp:253]     Train net output #0: loss = 1.02098 (* 1 = 1.02098 loss)
I0526 15:25:25.656530 32260 sgd_solver.cpp:106] Iteration 550500, lr = 0.0015
I0526 15:25:37.835785 32260 solver.cpp:237] Iteration 551250, loss = 0.925798
I0526 15:25:37.835821 32260 solver.cpp:253]     Train net output #0: loss = 0.925796 (* 1 = 0.925796 loss)
I0526 15:25:37.835835 32260 sgd_solver.cpp:106] Iteration 551250, lr = 0.0015
I0526 15:25:50.051507 32260 solver.cpp:237] Iteration 552000, loss = 1.40389
I0526 15:25:50.051553 32260 solver.cpp:253]     Train net output #0: loss = 1.40388 (* 1 = 1.40388 loss)
I0526 15:25:50.051566 32260 sgd_solver.cpp:106] Iteration 552000, lr = 0.0015
I0526 15:26:02.289638 32260 solver.cpp:237] Iteration 552750, loss = 1.46437
I0526 15:26:02.289808 32260 solver.cpp:253]     Train net output #0: loss = 1.46437 (* 1 = 1.46437 loss)
I0526 15:26:02.289822 32260 sgd_solver.cpp:106] Iteration 552750, lr = 0.0015
I0526 15:26:14.529929 32260 solver.cpp:237] Iteration 553500, loss = 1.08582
I0526 15:26:14.529971 32260 solver.cpp:253]     Train net output #0: loss = 1.08582 (* 1 = 1.08582 loss)
I0526 15:26:14.529989 32260 sgd_solver.cpp:106] Iteration 553500, lr = 0.0015
I0526 15:26:26.761180 32260 solver.cpp:237] Iteration 554250, loss = 1.16961
I0526 15:26:26.761216 32260 solver.cpp:253]     Train net output #0: loss = 1.16961 (* 1 = 1.16961 loss)
I0526 15:26:26.761229 32260 sgd_solver.cpp:106] Iteration 554250, lr = 0.0015
I0526 15:26:38.964598 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_555000.caffemodel
I0526 15:26:39.020386 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_555000.solverstate
I0526 15:26:39.051633 32260 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 15:27:51.811311 32260 solver.cpp:409]     Test net output #0: accuracy = 0.901844
I0526 15:27:51.811499 32260 solver.cpp:409]     Test net output #1: loss = 0.316811 (* 1 = 0.316811 loss)
I0526 15:28:12.681578 32260 solver.cpp:237] Iteration 555000, loss = 1.15765
I0526 15:28:12.681630 32260 solver.cpp:253]     Train net output #0: loss = 1.15765 (* 1 = 1.15765 loss)
I0526 15:28:12.681645 32260 sgd_solver.cpp:106] Iteration 555000, lr = 0.0015
I0526 15:28:24.868505 32260 solver.cpp:237] Iteration 555750, loss = 1.15531
I0526 15:28:24.868703 32260 solver.cpp:253]     Train net output #0: loss = 1.1553 (* 1 = 1.1553 loss)
I0526 15:28:24.868717 32260 sgd_solver.cpp:106] Iteration 555750, lr = 0.0015
I0526 15:28:37.059134 32260 solver.cpp:237] Iteration 556500, loss = 1.64089
I0526 15:28:37.059168 32260 solver.cpp:253]     Train net output #0: loss = 1.64089 (* 1 = 1.64089 loss)
I0526 15:28:37.059187 32260 sgd_solver.cpp:106] Iteration 556500, lr = 0.0015
I0526 15:28:49.220981 32260 solver.cpp:237] Iteration 557250, loss = 1.06175
I0526 15:28:49.221029 32260 solver.cpp:253]     Train net output #0: loss = 1.06175 (* 1 = 1.06175 loss)
I0526 15:28:49.221042 32260 sgd_solver.cpp:106] Iteration 557250, lr = 0.0015
I0526 15:29:01.341974 32260 solver.cpp:237] Iteration 558000, loss = 1.13301
I0526 15:29:01.342144 32260 solver.cpp:253]     Train net output #0: loss = 1.13301 (* 1 = 1.13301 loss)
I0526 15:29:01.342157 32260 sgd_solver.cpp:106] Iteration 558000, lr = 0.0015
I0526 15:29:13.461611 32260 solver.cpp:237] Iteration 558750, loss = 1.1292
I0526 15:29:13.461657 32260 solver.cpp:253]     Train net output #0: loss = 1.1292 (* 1 = 1.1292 loss)
I0526 15:29:13.461670 32260 sgd_solver.cpp:106] Iteration 558750, lr = 0.0015
I0526 15:29:25.566730 32260 solver.cpp:237] Iteration 559500, loss = 0.722866
I0526 15:29:25.566766 32260 solver.cpp:253]     Train net output #0: loss = 0.722864 (* 1 = 0.722864 loss)
I0526 15:29:25.566781 32260 sgd_solver.cpp:106] Iteration 559500, lr = 0.0015
I0526 15:29:58.497098 32260 solver.cpp:237] Iteration 560250, loss = 0.974448
I0526 15:29:58.497287 32260 solver.cpp:253]     Train net output #0: loss = 0.974446 (* 1 = 0.974446 loss)
I0526 15:29:58.497303 32260 sgd_solver.cpp:106] Iteration 560250, lr = 0.0015
I0526 15:30:10.643301 32260 solver.cpp:237] Iteration 561000, loss = 0.995926
I0526 15:30:10.643337 32260 solver.cpp:253]     Train net output #0: loss = 0.995924 (* 1 = 0.995924 loss)
I0526 15:30:10.643352 32260 sgd_solver.cpp:106] Iteration 561000, lr = 0.0015
I0526 15:30:22.792495 32260 solver.cpp:237] Iteration 561750, loss = 1.03885
I0526 15:30:22.792541 32260 solver.cpp:253]     Train net output #0: loss = 1.03885 (* 1 = 1.03885 loss)
I0526 15:30:22.792556 32260 sgd_solver.cpp:106] Iteration 561750, lr = 0.0015
I0526 15:30:34.930090 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_562500.caffemodel
I0526 15:30:34.979228 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_562500.solverstate
I0526 15:30:35.009567 32260 solver.cpp:237] Iteration 562500, loss = 1.60928
I0526 15:30:35.009608 32260 solver.cpp:253]     Train net output #0: loss = 1.60928 (* 1 = 1.60928 loss)
I0526 15:30:35.009624 32260 sgd_solver.cpp:106] Iteration 562500, lr = 0.0015
I0526 15:30:47.150459 32260 solver.cpp:237] Iteration 563250, loss = 1.08196
I0526 15:30:47.150495 32260 solver.cpp:253]     Train net output #0: loss = 1.08196 (* 1 = 1.08196 loss)
I0526 15:30:47.150507 32260 sgd_solver.cpp:106] Iteration 563250, lr = 0.0015
I0526 15:30:59.323596 32260 solver.cpp:237] Iteration 564000, loss = 1.26802
I0526 15:30:59.323642 32260 solver.cpp:253]     Train net output #0: loss = 1.26802 (* 1 = 1.26802 loss)
I0526 15:30:59.323654 32260 sgd_solver.cpp:106] Iteration 564000, lr = 0.0015
I0526 15:31:11.477088 32260 solver.cpp:237] Iteration 564750, loss = 1.18024
I0526 15:31:11.477273 32260 solver.cpp:253]     Train net output #0: loss = 1.18024 (* 1 = 1.18024 loss)
I0526 15:31:11.477288 32260 sgd_solver.cpp:106] Iteration 564750, lr = 0.0015
I0526 15:31:44.466559 32260 solver.cpp:237] Iteration 565500, loss = 1.32825
I0526 15:31:44.466753 32260 solver.cpp:253]     Train net output #0: loss = 1.32825 (* 1 = 1.32825 loss)
I0526 15:31:44.466769 32260 sgd_solver.cpp:106] Iteration 565500, lr = 0.0015
I0526 15:31:56.617074 32260 solver.cpp:237] Iteration 566250, loss = 1.60362
I0526 15:31:56.617110 32260 solver.cpp:253]     Train net output #0: loss = 1.60361 (* 1 = 1.60361 loss)
I0526 15:31:56.617122 32260 sgd_solver.cpp:106] Iteration 566250, lr = 0.0015
I0526 15:32:08.771757 32260 solver.cpp:237] Iteration 567000, loss = 0.971712
I0526 15:32:08.771808 32260 solver.cpp:253]     Train net output #0: loss = 0.97171 (* 1 = 0.97171 loss)
I0526 15:32:08.771822 32260 sgd_solver.cpp:106] Iteration 567000, lr = 0.0015
I0526 15:32:20.965226 32260 solver.cpp:237] Iteration 567750, loss = 1.08107
I0526 15:32:20.965401 32260 solver.cpp:253]     Train net output #0: loss = 1.08107 (* 1 = 1.08107 loss)
I0526 15:32:20.965416 32260 sgd_solver.cpp:106] Iteration 567750, lr = 0.0015
I0526 15:32:33.158133 32260 solver.cpp:237] Iteration 568500, loss = 0.763927
I0526 15:32:33.158184 32260 solver.cpp:253]     Train net output #0: loss = 0.763925 (* 1 = 0.763925 loss)
I0526 15:32:33.158200 32260 sgd_solver.cpp:106] Iteration 568500, lr = 0.0015
I0526 15:32:45.307819 32260 solver.cpp:237] Iteration 569250, loss = 1.53132
I0526 15:32:45.307854 32260 solver.cpp:253]     Train net output #0: loss = 1.53132 (* 1 = 1.53132 loss)
I0526 15:32:45.307870 32260 sgd_solver.cpp:106] Iteration 569250, lr = 0.0015
I0526 15:32:57.442764 32260 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_570000.caffemodel
I0526 15:32:57.491711 32260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0015_2016-05-20T15.48.54.123639_iter_570000.solverstate
I0526 15:32:57.516846 32260 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 15:33:49.038221 32260 solver.cpp:409]     Test net output #0: accuracy = 0.904513
I0526 15:33:49.038419 32260 solver.cpp:409]     Test net output #1: loss = 0.301386 (* 1 = 0.301386 loss)
I0526 15:34:09.923341 32260 solver.cpp:237] Iteration 570000, loss = 1.61814
I0526 15:34:09.923393 32260 solver.cpp:253]     Train net output #0: loss = 1.61814 (* 1 = 1.61814 loss)
I0526 15:34:09.923408 32260 sgd_solver.cpp:106] Iteration 570000, lr = 0.0015
I0526 15:34:22.082587 32260 solver.cpp:237] Iteration 570750, loss = 1.08013
I0526 15:34:22.082758 32260 solver.cpp:253]     Train net output #0: loss = 1.08013 (* 1 = 1.08013 loss)
I0526 15:34:22.082772 32260 sgd_solver.cpp:106] Iteration 570750, lr = 0.0015
I0526 15:34:34.207489 32260 solver.cpp:237] Iteration 571500, loss = 0.881561
I0526 15:34:34.207540 32260 solver.cpp:253]     Train net output #0: loss = 0.881559 (* 1 = 0.881559 loss)
I0526 15:34:34.207554 32260 sgd_solver.cpp:106] Iteration 571500, lr = 0.0015
aprun: Apid 11268959: Caught signal Terminated, sending to application
*** Aborted at 1464291274 (unix time) try "date -d @1464291274" if you are using GNU date ***
aprun: Apid 11268959: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x7e01) received by PID 32260 (TID 0x2aaac746f900) from PID 32257; stack trace: ***
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
=>> PBS: job killed: walltime 7226 exceeded limit 7200
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11268959: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
aprun: Apid 11268959: Caught signal Terminated, sending to application
