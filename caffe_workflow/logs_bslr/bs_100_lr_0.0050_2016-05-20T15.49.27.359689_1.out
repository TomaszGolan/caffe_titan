2811067
I0525 22:55:46.553346 20705 caffe.cpp:184] Using GPUs 0
I0525 22:55:46.978384 20705 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.005
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689.prototxt"
I0525 22:55:46.980448 20705 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689.prototxt
I0525 22:55:46.997166 20705 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 22:55:46.997231 20705 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 22:55:46.997606 20705 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 22:55:46.997810 20705 layer_factory.hpp:77] Creating layer data_hdf5
I0525 22:55:46.997848 20705 net.cpp:106] Creating Layer data_hdf5
I0525 22:55:46.997864 20705 net.cpp:411] data_hdf5 -> data
I0525 22:55:46.997897 20705 net.cpp:411] data_hdf5 -> label
I0525 22:55:46.997941 20705 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 22:55:47.012202 20705 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 22:55:47.034795 20705 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 22:56:08.543777 20705 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 22:56:08.548954 20705 net.cpp:150] Setting up data_hdf5
I0525 22:56:08.548995 20705 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 22:56:08.549012 20705 net.cpp:157] Top shape: 100 (100)
I0525 22:56:08.549024 20705 net.cpp:165] Memory required for data: 2540400
I0525 22:56:08.549044 20705 layer_factory.hpp:77] Creating layer conv1
I0525 22:56:08.549091 20705 net.cpp:106] Creating Layer conv1
I0525 22:56:08.549114 20705 net.cpp:454] conv1 <- data
I0525 22:56:08.549139 20705 net.cpp:411] conv1 -> conv1
I0525 22:56:11.832972 20705 net.cpp:150] Setting up conv1
I0525 22:56:11.833026 20705 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 22:56:11.833050 20705 net.cpp:165] Memory required for data: 30188400
I0525 22:56:11.833081 20705 layer_factory.hpp:77] Creating layer relu1
I0525 22:56:11.833101 20705 net.cpp:106] Creating Layer relu1
I0525 22:56:11.833114 20705 net.cpp:454] relu1 <- conv1
I0525 22:56:11.833137 20705 net.cpp:397] relu1 -> conv1 (in-place)
I0525 22:56:11.833685 20705 net.cpp:150] Setting up relu1
I0525 22:56:11.833709 20705 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 22:56:11.833721 20705 net.cpp:165] Memory required for data: 57836400
I0525 22:56:11.833737 20705 layer_factory.hpp:77] Creating layer pool1
I0525 22:56:11.833756 20705 net.cpp:106] Creating Layer pool1
I0525 22:56:11.833778 20705 net.cpp:454] pool1 <- conv1
I0525 22:56:11.833794 20705 net.cpp:411] pool1 -> pool1
I0525 22:56:11.833889 20705 net.cpp:150] Setting up pool1
I0525 22:56:11.833907 20705 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 22:56:11.833922 20705 net.cpp:165] Memory required for data: 71660400
I0525 22:56:11.833942 20705 layer_factory.hpp:77] Creating layer conv2
I0525 22:56:11.833967 20705 net.cpp:106] Creating Layer conv2
I0525 22:56:11.833981 20705 net.cpp:454] conv2 <- pool1
I0525 22:56:11.833997 20705 net.cpp:411] conv2 -> conv2
I0525 22:56:11.836743 20705 net.cpp:150] Setting up conv2
I0525 22:56:11.836774 20705 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 22:56:11.836788 20705 net.cpp:165] Memory required for data: 91532400
I0525 22:56:11.836815 20705 layer_factory.hpp:77] Creating layer relu2
I0525 22:56:11.836843 20705 net.cpp:106] Creating Layer relu2
I0525 22:56:11.836858 20705 net.cpp:454] relu2 <- conv2
I0525 22:56:11.836874 20705 net.cpp:397] relu2 -> conv2 (in-place)
I0525 22:56:11.837232 20705 net.cpp:150] Setting up relu2
I0525 22:56:11.837252 20705 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 22:56:11.837266 20705 net.cpp:165] Memory required for data: 111404400
I0525 22:56:11.837281 20705 layer_factory.hpp:77] Creating layer pool2
I0525 22:56:11.837296 20705 net.cpp:106] Creating Layer pool2
I0525 22:56:11.837318 20705 net.cpp:454] pool2 <- conv2
I0525 22:56:11.837334 20705 net.cpp:411] pool2 -> pool2
I0525 22:56:11.837429 20705 net.cpp:150] Setting up pool2
I0525 22:56:11.837446 20705 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 22:56:11.837462 20705 net.cpp:165] Memory required for data: 121340400
I0525 22:56:11.837482 20705 layer_factory.hpp:77] Creating layer conv3
I0525 22:56:11.837503 20705 net.cpp:106] Creating Layer conv3
I0525 22:56:11.837518 20705 net.cpp:454] conv3 <- pool2
I0525 22:56:11.837534 20705 net.cpp:411] conv3 -> conv3
I0525 22:56:11.839473 20705 net.cpp:150] Setting up conv3
I0525 22:56:11.839503 20705 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 22:56:11.839515 20705 net.cpp:165] Memory required for data: 132182000
I0525 22:56:11.839537 20705 layer_factory.hpp:77] Creating layer relu3
I0525 22:56:11.839570 20705 net.cpp:106] Creating Layer relu3
I0525 22:56:11.839583 20705 net.cpp:454] relu3 <- conv3
I0525 22:56:11.839599 20705 net.cpp:397] relu3 -> conv3 (in-place)
I0525 22:56:11.840092 20705 net.cpp:150] Setting up relu3
I0525 22:56:11.840116 20705 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 22:56:11.840129 20705 net.cpp:165] Memory required for data: 143023600
I0525 22:56:11.840147 20705 layer_factory.hpp:77] Creating layer pool3
I0525 22:56:11.840162 20705 net.cpp:106] Creating Layer pool3
I0525 22:56:11.840183 20705 net.cpp:454] pool3 <- conv3
I0525 22:56:11.840199 20705 net.cpp:411] pool3 -> pool3
I0525 22:56:11.840281 20705 net.cpp:150] Setting up pool3
I0525 22:56:11.840301 20705 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 22:56:11.840315 20705 net.cpp:165] Memory required for data: 148444400
I0525 22:56:11.840327 20705 layer_factory.hpp:77] Creating layer conv4
I0525 22:56:11.840361 20705 net.cpp:106] Creating Layer conv4
I0525 22:56:11.840381 20705 net.cpp:454] conv4 <- pool3
I0525 22:56:11.840399 20705 net.cpp:411] conv4 -> conv4
I0525 22:56:11.843344 20705 net.cpp:150] Setting up conv4
I0525 22:56:11.843376 20705 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 22:56:11.843396 20705 net.cpp:165] Memory required for data: 152073200
I0525 22:56:11.843416 20705 layer_factory.hpp:77] Creating layer relu4
I0525 22:56:11.843437 20705 net.cpp:106] Creating Layer relu4
I0525 22:56:11.843451 20705 net.cpp:454] relu4 <- conv4
I0525 22:56:11.843466 20705 net.cpp:397] relu4 -> conv4 (in-place)
I0525 22:56:11.843961 20705 net.cpp:150] Setting up relu4
I0525 22:56:11.843983 20705 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 22:56:11.843997 20705 net.cpp:165] Memory required for data: 155702000
I0525 22:56:11.844013 20705 layer_factory.hpp:77] Creating layer pool4
I0525 22:56:11.844028 20705 net.cpp:106] Creating Layer pool4
I0525 22:56:11.844043 20705 net.cpp:454] pool4 <- conv4
I0525 22:56:11.844068 20705 net.cpp:411] pool4 -> pool4
I0525 22:56:11.844151 20705 net.cpp:150] Setting up pool4
I0525 22:56:11.844167 20705 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 22:56:11.844182 20705 net.cpp:165] Memory required for data: 157516400
I0525 22:56:11.844194 20705 layer_factory.hpp:77] Creating layer ip1
I0525 22:56:11.844216 20705 net.cpp:106] Creating Layer ip1
I0525 22:56:11.844235 20705 net.cpp:454] ip1 <- pool4
I0525 22:56:11.844251 20705 net.cpp:411] ip1 -> ip1
I0525 22:56:11.859586 20705 net.cpp:150] Setting up ip1
I0525 22:56:11.859622 20705 net.cpp:157] Top shape: 100 196 (19600)
I0525 22:56:11.859635 20705 net.cpp:165] Memory required for data: 157594800
I0525 22:56:11.859665 20705 layer_factory.hpp:77] Creating layer relu5
I0525 22:56:11.859694 20705 net.cpp:106] Creating Layer relu5
I0525 22:56:11.859709 20705 net.cpp:454] relu5 <- ip1
I0525 22:56:11.859724 20705 net.cpp:397] relu5 -> ip1 (in-place)
I0525 22:56:11.860090 20705 net.cpp:150] Setting up relu5
I0525 22:56:11.860110 20705 net.cpp:157] Top shape: 100 196 (19600)
I0525 22:56:11.860122 20705 net.cpp:165] Memory required for data: 157673200
I0525 22:56:11.860137 20705 layer_factory.hpp:77] Creating layer drop1
I0525 22:56:11.860160 20705 net.cpp:106] Creating Layer drop1
I0525 22:56:11.860182 20705 net.cpp:454] drop1 <- ip1
I0525 22:56:11.860196 20705 net.cpp:397] drop1 -> ip1 (in-place)
I0525 22:56:11.860267 20705 net.cpp:150] Setting up drop1
I0525 22:56:11.860283 20705 net.cpp:157] Top shape: 100 196 (19600)
I0525 22:56:11.860296 20705 net.cpp:165] Memory required for data: 157751600
I0525 22:56:11.860311 20705 layer_factory.hpp:77] Creating layer ip2
I0525 22:56:11.860333 20705 net.cpp:106] Creating Layer ip2
I0525 22:56:11.860352 20705 net.cpp:454] ip2 <- ip1
I0525 22:56:11.860381 20705 net.cpp:411] ip2 -> ip2
I0525 22:56:11.860872 20705 net.cpp:150] Setting up ip2
I0525 22:56:11.860891 20705 net.cpp:157] Top shape: 100 98 (9800)
I0525 22:56:11.860904 20705 net.cpp:165] Memory required for data: 157790800
I0525 22:56:11.860924 20705 layer_factory.hpp:77] Creating layer relu6
I0525 22:56:11.860946 20705 net.cpp:106] Creating Layer relu6
I0525 22:56:11.860960 20705 net.cpp:454] relu6 <- ip2
I0525 22:56:11.860975 20705 net.cpp:397] relu6 -> ip2 (in-place)
I0525 22:56:11.861522 20705 net.cpp:150] Setting up relu6
I0525 22:56:11.861546 20705 net.cpp:157] Top shape: 100 98 (9800)
I0525 22:56:11.861559 20705 net.cpp:165] Memory required for data: 157830000
I0525 22:56:11.861575 20705 layer_factory.hpp:77] Creating layer drop2
I0525 22:56:11.861590 20705 net.cpp:106] Creating Layer drop2
I0525 22:56:11.861604 20705 net.cpp:454] drop2 <- ip2
I0525 22:56:11.861627 20705 net.cpp:397] drop2 -> ip2 (in-place)
I0525 22:56:11.861677 20705 net.cpp:150] Setting up drop2
I0525 22:56:11.861699 20705 net.cpp:157] Top shape: 100 98 (9800)
I0525 22:56:11.861712 20705 net.cpp:165] Memory required for data: 157869200
I0525 22:56:11.861726 20705 layer_factory.hpp:77] Creating layer ip3
I0525 22:56:11.861744 20705 net.cpp:106] Creating Layer ip3
I0525 22:56:11.861757 20705 net.cpp:454] ip3 <- ip2
I0525 22:56:11.861773 20705 net.cpp:411] ip3 -> ip3
I0525 22:56:11.862001 20705 net.cpp:150] Setting up ip3
I0525 22:56:11.862020 20705 net.cpp:157] Top shape: 100 11 (1100)
I0525 22:56:11.862033 20705 net.cpp:165] Memory required for data: 157873600
I0525 22:56:11.862054 20705 layer_factory.hpp:77] Creating layer drop3
I0525 22:56:11.862069 20705 net.cpp:106] Creating Layer drop3
I0525 22:56:11.862082 20705 net.cpp:454] drop3 <- ip3
I0525 22:56:11.862104 20705 net.cpp:397] drop3 -> ip3 (in-place)
I0525 22:56:11.862151 20705 net.cpp:150] Setting up drop3
I0525 22:56:11.862167 20705 net.cpp:157] Top shape: 100 11 (1100)
I0525 22:56:11.862180 20705 net.cpp:165] Memory required for data: 157878000
I0525 22:56:11.862193 20705 layer_factory.hpp:77] Creating layer loss
I0525 22:56:11.862215 20705 net.cpp:106] Creating Layer loss
I0525 22:56:11.862226 20705 net.cpp:454] loss <- ip3
I0525 22:56:11.862241 20705 net.cpp:454] loss <- label
I0525 22:56:11.862272 20705 net.cpp:411] loss -> loss
I0525 22:56:11.862293 20705 layer_factory.hpp:77] Creating layer loss
I0525 22:56:11.862970 20705 net.cpp:150] Setting up loss
I0525 22:56:11.862993 20705 net.cpp:157] Top shape: (1)
I0525 22:56:11.863014 20705 net.cpp:160]     with loss weight 1
I0525 22:56:11.863064 20705 net.cpp:165] Memory required for data: 157878004
I0525 22:56:11.863085 20705 net.cpp:226] loss needs backward computation.
I0525 22:56:11.863100 20705 net.cpp:226] drop3 needs backward computation.
I0525 22:56:11.863112 20705 net.cpp:226] ip3 needs backward computation.
I0525 22:56:11.863126 20705 net.cpp:226] drop2 needs backward computation.
I0525 22:56:11.863138 20705 net.cpp:226] relu6 needs backward computation.
I0525 22:56:11.863152 20705 net.cpp:226] ip2 needs backward computation.
I0525 22:56:11.863164 20705 net.cpp:226] drop1 needs backward computation.
I0525 22:56:11.863183 20705 net.cpp:226] relu5 needs backward computation.
I0525 22:56:11.863196 20705 net.cpp:226] ip1 needs backward computation.
I0525 22:56:11.863214 20705 net.cpp:226] pool4 needs backward computation.
I0525 22:56:11.863227 20705 net.cpp:226] relu4 needs backward computation.
I0525 22:56:11.863240 20705 net.cpp:226] conv4 needs backward computation.
I0525 22:56:11.863252 20705 net.cpp:226] pool3 needs backward computation.
I0525 22:56:11.863267 20705 net.cpp:226] relu3 needs backward computation.
I0525 22:56:11.863296 20705 net.cpp:226] conv3 needs backward computation.
I0525 22:56:11.863311 20705 net.cpp:226] pool2 needs backward computation.
I0525 22:56:11.863324 20705 net.cpp:226] relu2 needs backward computation.
I0525 22:56:11.863337 20705 net.cpp:226] conv2 needs backward computation.
I0525 22:56:11.863353 20705 net.cpp:226] pool1 needs backward computation.
I0525 22:56:11.863364 20705 net.cpp:226] relu1 needs backward computation.
I0525 22:56:11.863385 20705 net.cpp:226] conv1 needs backward computation.
I0525 22:56:11.863399 20705 net.cpp:228] data_hdf5 does not need backward computation.
I0525 22:56:11.863416 20705 net.cpp:270] This network produces output loss
I0525 22:56:11.863442 20705 net.cpp:283] Network initialization done.
I0525 22:56:11.865167 20705 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689.prototxt
I0525 22:56:11.865247 20705 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 22:56:11.865628 20705 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 22:56:11.865849 20705 layer_factory.hpp:77] Creating layer data_hdf5
I0525 22:56:11.865875 20705 net.cpp:106] Creating Layer data_hdf5
I0525 22:56:11.865890 20705 net.cpp:411] data_hdf5 -> data
I0525 22:56:11.865911 20705 net.cpp:411] data_hdf5 -> label
I0525 22:56:11.865929 20705 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 22:56:11.886209 20705 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 22:56:33.250546 20705 net.cpp:150] Setting up data_hdf5
I0525 22:56:33.250715 20705 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 22:56:33.250732 20705 net.cpp:157] Top shape: 100 (100)
I0525 22:56:33.250746 20705 net.cpp:165] Memory required for data: 2540400
I0525 22:56:33.250759 20705 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 22:56:33.250788 20705 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 22:56:33.250808 20705 net.cpp:454] label_data_hdf5_1_split <- label
I0525 22:56:33.250843 20705 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 22:56:33.250867 20705 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 22:56:33.250946 20705 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 22:56:33.250972 20705 net.cpp:157] Top shape: 100 (100)
I0525 22:56:33.250987 20705 net.cpp:157] Top shape: 100 (100)
I0525 22:56:33.251001 20705 net.cpp:165] Memory required for data: 2541200
I0525 22:56:33.251014 20705 layer_factory.hpp:77] Creating layer conv1
I0525 22:56:33.251046 20705 net.cpp:106] Creating Layer conv1
I0525 22:56:33.251060 20705 net.cpp:454] conv1 <- data
I0525 22:56:33.251078 20705 net.cpp:411] conv1 -> conv1
I0525 22:56:33.253043 20705 net.cpp:150] Setting up conv1
I0525 22:56:33.253069 20705 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 22:56:33.253090 20705 net.cpp:165] Memory required for data: 30189200
I0525 22:56:33.253114 20705 layer_factory.hpp:77] Creating layer relu1
I0525 22:56:33.253135 20705 net.cpp:106] Creating Layer relu1
I0525 22:56:33.253147 20705 net.cpp:454] relu1 <- conv1
I0525 22:56:33.253173 20705 net.cpp:397] relu1 -> conv1 (in-place)
I0525 22:56:33.253690 20705 net.cpp:150] Setting up relu1
I0525 22:56:33.253712 20705 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 22:56:33.253726 20705 net.cpp:165] Memory required for data: 57837200
I0525 22:56:33.253737 20705 layer_factory.hpp:77] Creating layer pool1
I0525 22:56:33.253767 20705 net.cpp:106] Creating Layer pool1
I0525 22:56:33.253782 20705 net.cpp:454] pool1 <- conv1
I0525 22:56:33.253798 20705 net.cpp:411] pool1 -> pool1
I0525 22:56:33.253888 20705 net.cpp:150] Setting up pool1
I0525 22:56:33.253906 20705 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 22:56:33.253921 20705 net.cpp:165] Memory required for data: 71661200
I0525 22:56:33.253939 20705 layer_factory.hpp:77] Creating layer conv2
I0525 22:56:33.253962 20705 net.cpp:106] Creating Layer conv2
I0525 22:56:33.253981 20705 net.cpp:454] conv2 <- pool1
I0525 22:56:33.253998 20705 net.cpp:411] conv2 -> conv2
I0525 22:56:33.255944 20705 net.cpp:150] Setting up conv2
I0525 22:56:33.255967 20705 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 22:56:33.255988 20705 net.cpp:165] Memory required for data: 91533200
I0525 22:56:33.256009 20705 layer_factory.hpp:77] Creating layer relu2
I0525 22:56:33.256029 20705 net.cpp:106] Creating Layer relu2
I0525 22:56:33.256052 20705 net.cpp:454] relu2 <- conv2
I0525 22:56:33.256067 20705 net.cpp:397] relu2 -> conv2 (in-place)
I0525 22:56:33.256425 20705 net.cpp:150] Setting up relu2
I0525 22:56:33.256445 20705 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 22:56:33.256458 20705 net.cpp:165] Memory required for data: 111405200
I0525 22:56:33.256474 20705 layer_factory.hpp:77] Creating layer pool2
I0525 22:56:33.256489 20705 net.cpp:106] Creating Layer pool2
I0525 22:56:33.256510 20705 net.cpp:454] pool2 <- conv2
I0525 22:56:33.256525 20705 net.cpp:411] pool2 -> pool2
I0525 22:56:33.256618 20705 net.cpp:150] Setting up pool2
I0525 22:56:33.256636 20705 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 22:56:33.256656 20705 net.cpp:165] Memory required for data: 121341200
I0525 22:56:33.256669 20705 layer_factory.hpp:77] Creating layer conv3
I0525 22:56:33.256695 20705 net.cpp:106] Creating Layer conv3
I0525 22:56:33.256706 20705 net.cpp:454] conv3 <- pool2
I0525 22:56:33.256731 20705 net.cpp:411] conv3 -> conv3
I0525 22:56:33.258738 20705 net.cpp:150] Setting up conv3
I0525 22:56:33.258762 20705 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 22:56:33.258781 20705 net.cpp:165] Memory required for data: 132182800
I0525 22:56:33.258821 20705 layer_factory.hpp:77] Creating layer relu3
I0525 22:56:33.258846 20705 net.cpp:106] Creating Layer relu3
I0525 22:56:33.258860 20705 net.cpp:454] relu3 <- conv3
I0525 22:56:33.258877 20705 net.cpp:397] relu3 -> conv3 (in-place)
I0525 22:56:33.259373 20705 net.cpp:150] Setting up relu3
I0525 22:56:33.259397 20705 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 22:56:33.259409 20705 net.cpp:165] Memory required for data: 143024400
I0525 22:56:33.259421 20705 layer_factory.hpp:77] Creating layer pool3
I0525 22:56:33.259441 20705 net.cpp:106] Creating Layer pool3
I0525 22:56:33.259462 20705 net.cpp:454] pool3 <- conv3
I0525 22:56:33.259479 20705 net.cpp:411] pool3 -> pool3
I0525 22:56:33.259565 20705 net.cpp:150] Setting up pool3
I0525 22:56:33.259583 20705 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 22:56:33.259595 20705 net.cpp:165] Memory required for data: 148445200
I0525 22:56:33.259611 20705 layer_factory.hpp:77] Creating layer conv4
I0525 22:56:33.259639 20705 net.cpp:106] Creating Layer conv4
I0525 22:56:33.259651 20705 net.cpp:454] conv4 <- pool3
I0525 22:56:33.259670 20705 net.cpp:411] conv4 -> conv4
I0525 22:56:33.261795 20705 net.cpp:150] Setting up conv4
I0525 22:56:33.261824 20705 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 22:56:33.261837 20705 net.cpp:165] Memory required for data: 152074000
I0525 22:56:33.261857 20705 layer_factory.hpp:77] Creating layer relu4
I0525 22:56:33.261876 20705 net.cpp:106] Creating Layer relu4
I0525 22:56:33.261899 20705 net.cpp:454] relu4 <- conv4
I0525 22:56:33.261915 20705 net.cpp:397] relu4 -> conv4 (in-place)
I0525 22:56:33.262415 20705 net.cpp:150] Setting up relu4
I0525 22:56:33.262439 20705 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 22:56:33.262452 20705 net.cpp:165] Memory required for data: 155702800
I0525 22:56:33.262465 20705 layer_factory.hpp:77] Creating layer pool4
I0525 22:56:33.262485 20705 net.cpp:106] Creating Layer pool4
I0525 22:56:33.262506 20705 net.cpp:454] pool4 <- conv4
I0525 22:56:33.262522 20705 net.cpp:411] pool4 -> pool4
I0525 22:56:33.262609 20705 net.cpp:150] Setting up pool4
I0525 22:56:33.262625 20705 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 22:56:33.262640 20705 net.cpp:165] Memory required for data: 157517200
I0525 22:56:33.262653 20705 layer_factory.hpp:77] Creating layer ip1
I0525 22:56:33.262677 20705 net.cpp:106] Creating Layer ip1
I0525 22:56:33.262691 20705 net.cpp:454] ip1 <- pool4
I0525 22:56:33.262713 20705 net.cpp:411] ip1 -> ip1
I0525 22:56:33.278136 20705 net.cpp:150] Setting up ip1
I0525 22:56:33.278167 20705 net.cpp:157] Top shape: 100 196 (19600)
I0525 22:56:33.278189 20705 net.cpp:165] Memory required for data: 157595600
I0525 22:56:33.278216 20705 layer_factory.hpp:77] Creating layer relu5
I0525 22:56:33.278237 20705 net.cpp:106] Creating Layer relu5
I0525 22:56:33.278262 20705 net.cpp:454] relu5 <- ip1
I0525 22:56:33.278280 20705 net.cpp:397] relu5 -> ip1 (in-place)
I0525 22:56:33.278645 20705 net.cpp:150] Setting up relu5
I0525 22:56:33.278666 20705 net.cpp:157] Top shape: 100 196 (19600)
I0525 22:56:33.278678 20705 net.cpp:165] Memory required for data: 157674000
I0525 22:56:33.278693 20705 layer_factory.hpp:77] Creating layer drop1
I0525 22:56:33.278714 20705 net.cpp:106] Creating Layer drop1
I0525 22:56:33.278734 20705 net.cpp:454] drop1 <- ip1
I0525 22:56:33.278750 20705 net.cpp:397] drop1 -> ip1 (in-place)
I0525 22:56:33.278801 20705 net.cpp:150] Setting up drop1
I0525 22:56:33.278826 20705 net.cpp:157] Top shape: 100 196 (19600)
I0525 22:56:33.278839 20705 net.cpp:165] Memory required for data: 157752400
I0525 22:56:33.278851 20705 layer_factory.hpp:77] Creating layer ip2
I0525 22:56:33.278872 20705 net.cpp:106] Creating Layer ip2
I0525 22:56:33.278884 20705 net.cpp:454] ip2 <- ip1
I0525 22:56:33.278908 20705 net.cpp:411] ip2 -> ip2
I0525 22:56:33.279403 20705 net.cpp:150] Setting up ip2
I0525 22:56:33.279423 20705 net.cpp:157] Top shape: 100 98 (9800)
I0525 22:56:33.279438 20705 net.cpp:165] Memory required for data: 157791600
I0525 22:56:33.279458 20705 layer_factory.hpp:77] Creating layer relu6
I0525 22:56:33.279496 20705 net.cpp:106] Creating Layer relu6
I0525 22:56:33.279517 20705 net.cpp:454] relu6 <- ip2
I0525 22:56:33.279534 20705 net.cpp:397] relu6 -> ip2 (in-place)
I0525 22:56:33.280095 20705 net.cpp:150] Setting up relu6
I0525 22:56:33.280118 20705 net.cpp:157] Top shape: 100 98 (9800)
I0525 22:56:33.280131 20705 net.cpp:165] Memory required for data: 157830800
I0525 22:56:33.280143 20705 layer_factory.hpp:77] Creating layer drop2
I0525 22:56:33.280164 20705 net.cpp:106] Creating Layer drop2
I0525 22:56:33.280185 20705 net.cpp:454] drop2 <- ip2
I0525 22:56:33.280202 20705 net.cpp:397] drop2 -> ip2 (in-place)
I0525 22:56:33.280253 20705 net.cpp:150] Setting up drop2
I0525 22:56:33.280277 20705 net.cpp:157] Top shape: 100 98 (9800)
I0525 22:56:33.280289 20705 net.cpp:165] Memory required for data: 157870000
I0525 22:56:33.280308 20705 layer_factory.hpp:77] Creating layer ip3
I0525 22:56:33.280324 20705 net.cpp:106] Creating Layer ip3
I0525 22:56:33.280349 20705 net.cpp:454] ip3 <- ip2
I0525 22:56:33.280374 20705 net.cpp:411] ip3 -> ip3
I0525 22:56:33.280613 20705 net.cpp:150] Setting up ip3
I0525 22:56:33.280633 20705 net.cpp:157] Top shape: 100 11 (1100)
I0525 22:56:33.280647 20705 net.cpp:165] Memory required for data: 157874400
I0525 22:56:33.280668 20705 layer_factory.hpp:77] Creating layer drop3
I0525 22:56:33.280690 20705 net.cpp:106] Creating Layer drop3
I0525 22:56:33.280704 20705 net.cpp:454] drop3 <- ip3
I0525 22:56:33.280719 20705 net.cpp:397] drop3 -> ip3 (in-place)
I0525 22:56:33.280767 20705 net.cpp:150] Setting up drop3
I0525 22:56:33.280791 20705 net.cpp:157] Top shape: 100 11 (1100)
I0525 22:56:33.280802 20705 net.cpp:165] Memory required for data: 157878800
I0525 22:56:33.280817 20705 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 22:56:33.280833 20705 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 22:56:33.280848 20705 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 22:56:33.280869 20705 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 22:56:33.280889 20705 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 22:56:33.280978 20705 net.cpp:150] Setting up ip3_drop3_0_split
I0525 22:56:33.280995 20705 net.cpp:157] Top shape: 100 11 (1100)
I0525 22:56:33.281011 20705 net.cpp:157] Top shape: 100 11 (1100)
I0525 22:56:33.281023 20705 net.cpp:165] Memory required for data: 157887600
I0525 22:56:33.281038 20705 layer_factory.hpp:77] Creating layer accuracy
I0525 22:56:33.281066 20705 net.cpp:106] Creating Layer accuracy
I0525 22:56:33.281080 20705 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 22:56:33.281095 20705 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 22:56:33.281111 20705 net.cpp:411] accuracy -> accuracy
I0525 22:56:33.281144 20705 net.cpp:150] Setting up accuracy
I0525 22:56:33.281160 20705 net.cpp:157] Top shape: (1)
I0525 22:56:33.281172 20705 net.cpp:165] Memory required for data: 157887604
I0525 22:56:33.281184 20705 layer_factory.hpp:77] Creating layer loss
I0525 22:56:33.281200 20705 net.cpp:106] Creating Layer loss
I0525 22:56:33.281215 20705 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 22:56:33.281229 20705 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 22:56:33.281252 20705 net.cpp:411] loss -> loss
I0525 22:56:33.281277 20705 layer_factory.hpp:77] Creating layer loss
I0525 22:56:33.281792 20705 net.cpp:150] Setting up loss
I0525 22:56:33.281812 20705 net.cpp:157] Top shape: (1)
I0525 22:56:33.281826 20705 net.cpp:160]     with loss weight 1
I0525 22:56:33.281852 20705 net.cpp:165] Memory required for data: 157887608
I0525 22:56:33.281872 20705 net.cpp:226] loss needs backward computation.
I0525 22:56:33.281888 20705 net.cpp:228] accuracy does not need backward computation.
I0525 22:56:33.281904 20705 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 22:56:33.281919 20705 net.cpp:226] drop3 needs backward computation.
I0525 22:56:33.281930 20705 net.cpp:226] ip3 needs backward computation.
I0525 22:56:33.281945 20705 net.cpp:226] drop2 needs backward computation.
I0525 22:56:33.281973 20705 net.cpp:226] relu6 needs backward computation.
I0525 22:56:33.281986 20705 net.cpp:226] ip2 needs backward computation.
I0525 22:56:33.282001 20705 net.cpp:226] drop1 needs backward computation.
I0525 22:56:33.282014 20705 net.cpp:226] relu5 needs backward computation.
I0525 22:56:33.282027 20705 net.cpp:226] ip1 needs backward computation.
I0525 22:56:33.282042 20705 net.cpp:226] pool4 needs backward computation.
I0525 22:56:33.282054 20705 net.cpp:226] relu4 needs backward computation.
I0525 22:56:33.282074 20705 net.cpp:226] conv4 needs backward computation.
I0525 22:56:33.282088 20705 net.cpp:226] pool3 needs backward computation.
I0525 22:56:33.282104 20705 net.cpp:226] relu3 needs backward computation.
I0525 22:56:33.282116 20705 net.cpp:226] conv3 needs backward computation.
I0525 22:56:33.282129 20705 net.cpp:226] pool2 needs backward computation.
I0525 22:56:33.282145 20705 net.cpp:226] relu2 needs backward computation.
I0525 22:56:33.282156 20705 net.cpp:226] conv2 needs backward computation.
I0525 22:56:33.282176 20705 net.cpp:226] pool1 needs backward computation.
I0525 22:56:33.282189 20705 net.cpp:226] relu1 needs backward computation.
I0525 22:56:33.282205 20705 net.cpp:226] conv1 needs backward computation.
I0525 22:56:33.282220 20705 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 22:56:33.282233 20705 net.cpp:228] data_hdf5 does not need backward computation.
I0525 22:56:33.282248 20705 net.cpp:270] This network produces output accuracy
I0525 22:56:33.282260 20705 net.cpp:270] This network produces output loss
I0525 22:56:33.282292 20705 net.cpp:283] Network initialization done.
I0525 22:56:33.282431 20705 solver.cpp:60] Solver scaffolding done.
I0525 22:56:33.283572 20705 caffe.cpp:212] Starting Optimization
I0525 22:56:33.283588 20705 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 22:56:33.283603 20705 solver.cpp:289] Learning Rate Policy: fixed
I0525 22:56:33.284696 20705 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 22:57:21.060307 20705 solver.cpp:409]     Test net output #0: accuracy = 0.0874866
I0525 22:57:21.060477 20705 solver.cpp:409]     Test net output #1: loss = 2.39761 (* 1 = 2.39761 loss)
I0525 22:57:21.093371 20705 solver.cpp:237] Iteration 0, loss = 2.39849
I0525 22:57:21.093410 20705 solver.cpp:253]     Train net output #0: loss = 2.39849 (* 1 = 2.39849 loss)
I0525 22:57:21.093432 20705 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0525 22:57:29.812445 20705 solver.cpp:237] Iteration 150, loss = 2.22034
I0525 22:57:29.812484 20705 solver.cpp:253]     Train net output #0: loss = 2.22034 (* 1 = 2.22034 loss)
I0525 22:57:29.812507 20705 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0525 22:57:38.530282 20705 solver.cpp:237] Iteration 300, loss = 2.05592
I0525 22:57:38.530341 20705 solver.cpp:253]     Train net output #0: loss = 2.05592 (* 1 = 2.05592 loss)
I0525 22:57:38.530367 20705 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0525 22:57:47.257664 20705 solver.cpp:237] Iteration 450, loss = 2.00073
I0525 22:57:47.257702 20705 solver.cpp:253]     Train net output #0: loss = 2.00073 (* 1 = 2.00073 loss)
I0525 22:57:47.257726 20705 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0525 22:57:55.979696 20705 solver.cpp:237] Iteration 600, loss = 1.75122
I0525 22:57:55.979848 20705 solver.cpp:253]     Train net output #0: loss = 1.75122 (* 1 = 1.75122 loss)
I0525 22:57:55.979866 20705 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0525 22:58:04.704840 20705 solver.cpp:237] Iteration 750, loss = 1.91249
I0525 22:58:04.704898 20705 solver.cpp:253]     Train net output #0: loss = 1.91249 (* 1 = 1.91249 loss)
I0525 22:58:04.704924 20705 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0525 22:58:13.426882 20705 solver.cpp:237] Iteration 900, loss = 1.78365
I0525 22:58:13.426924 20705 solver.cpp:253]     Train net output #0: loss = 1.78365 (* 1 = 1.78365 loss)
I0525 22:58:13.426940 20705 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0525 22:58:44.264529 20705 solver.cpp:237] Iteration 1050, loss = 1.78377
I0525 22:58:44.264694 20705 solver.cpp:253]     Train net output #0: loss = 1.78377 (* 1 = 1.78377 loss)
I0525 22:58:44.264713 20705 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0525 22:58:52.988592 20705 solver.cpp:237] Iteration 1200, loss = 1.62352
I0525 22:58:52.988648 20705 solver.cpp:253]     Train net output #0: loss = 1.62352 (* 1 = 1.62352 loss)
I0525 22:58:52.988665 20705 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0525 22:59:01.715859 20705 solver.cpp:237] Iteration 1350, loss = 1.5639
I0525 22:59:01.715896 20705 solver.cpp:253]     Train net output #0: loss = 1.5639 (* 1 = 1.5639 loss)
I0525 22:59:01.715914 20705 sgd_solver.cpp:106] Iteration 1350, lr = 0.005
I0525 22:59:10.380928 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_1500.caffemodel
I0525 22:59:10.465281 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_1500.solverstate
I0525 22:59:10.508939 20705 solver.cpp:237] Iteration 1500, loss = 1.84946
I0525 22:59:10.508996 20705 solver.cpp:253]     Train net output #0: loss = 1.84946 (* 1 = 1.84946 loss)
I0525 22:59:10.509013 20705 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0525 22:59:19.245096 20705 solver.cpp:237] Iteration 1650, loss = 1.72338
I0525 22:59:19.245261 20705 solver.cpp:253]     Train net output #0: loss = 1.72338 (* 1 = 1.72338 loss)
I0525 22:59:19.245286 20705 sgd_solver.cpp:106] Iteration 1650, lr = 0.005
I0525 22:59:27.975314 20705 solver.cpp:237] Iteration 1800, loss = 1.54144
I0525 22:59:27.975350 20705 solver.cpp:253]     Train net output #0: loss = 1.54144 (* 1 = 1.54144 loss)
I0525 22:59:27.975373 20705 sgd_solver.cpp:106] Iteration 1800, lr = 0.005
I0525 22:59:36.700239 20705 solver.cpp:237] Iteration 1950, loss = 1.68075
I0525 22:59:36.700278 20705 solver.cpp:253]     Train net output #0: loss = 1.68075 (* 1 = 1.68075 loss)
I0525 22:59:36.700304 20705 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0525 23:00:07.773206 20705 solver.cpp:237] Iteration 2100, loss = 1.48179
I0525 23:00:07.773365 20705 solver.cpp:253]     Train net output #0: loss = 1.48179 (* 1 = 1.48179 loss)
I0525 23:00:07.773382 20705 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0525 23:00:16.498657 20705 solver.cpp:237] Iteration 2250, loss = 1.51472
I0525 23:00:16.498695 20705 solver.cpp:253]     Train net output #0: loss = 1.51472 (* 1 = 1.51472 loss)
I0525 23:00:16.498714 20705 sgd_solver.cpp:106] Iteration 2250, lr = 0.005
I0525 23:00:25.224391 20705 solver.cpp:237] Iteration 2400, loss = 1.62869
I0525 23:00:25.224428 20705 solver.cpp:253]     Train net output #0: loss = 1.62869 (* 1 = 1.62869 loss)
I0525 23:00:25.224452 20705 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0525 23:00:33.950817 20705 solver.cpp:237] Iteration 2550, loss = 1.46504
I0525 23:00:33.950873 20705 solver.cpp:253]     Train net output #0: loss = 1.46504 (* 1 = 1.46504 loss)
I0525 23:00:33.950891 20705 sgd_solver.cpp:106] Iteration 2550, lr = 0.005
I0525 23:00:42.680356 20705 solver.cpp:237] Iteration 2700, loss = 1.51718
I0525 23:00:42.680508 20705 solver.cpp:253]     Train net output #0: loss = 1.51718 (* 1 = 1.51718 loss)
I0525 23:00:42.680526 20705 sgd_solver.cpp:106] Iteration 2700, lr = 0.005
I0525 23:00:51.407611 20705 solver.cpp:237] Iteration 2850, loss = 1.42194
I0525 23:00:51.407647 20705 solver.cpp:253]     Train net output #0: loss = 1.42194 (* 1 = 1.42194 loss)
I0525 23:00:51.407666 20705 sgd_solver.cpp:106] Iteration 2850, lr = 0.005
I0525 23:01:00.078490 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_3000.caffemodel
I0525 23:01:00.159201 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_3000.solverstate
I0525 23:01:00.185381 20705 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 23:01:47.052918 20705 solver.cpp:409]     Test net output #0: accuracy = 0.779269
I0525 23:01:47.053082 20705 solver.cpp:409]     Test net output #1: loss = 0.794537 (* 1 = 0.794537 loss)
I0525 23:02:09.226723 20705 solver.cpp:237] Iteration 3000, loss = 1.28973
I0525 23:02:09.226788 20705 solver.cpp:253]     Train net output #0: loss = 1.28973 (* 1 = 1.28973 loss)
I0525 23:02:09.226815 20705 sgd_solver.cpp:106] Iteration 3000, lr = 0.005
I0525 23:02:17.970144 20705 solver.cpp:237] Iteration 3150, loss = 1.56785
I0525 23:02:17.970299 20705 solver.cpp:253]     Train net output #0: loss = 1.56785 (* 1 = 1.56785 loss)
I0525 23:02:17.970316 20705 sgd_solver.cpp:106] Iteration 3150, lr = 0.005
I0525 23:02:26.712443 20705 solver.cpp:237] Iteration 3300, loss = 1.73021
I0525 23:02:26.712481 20705 solver.cpp:253]     Train net output #0: loss = 1.73021 (* 1 = 1.73021 loss)
I0525 23:02:26.712499 20705 sgd_solver.cpp:106] Iteration 3300, lr = 0.005
I0525 23:02:35.460319 20705 solver.cpp:237] Iteration 3450, loss = 1.49661
I0525 23:02:35.460368 20705 solver.cpp:253]     Train net output #0: loss = 1.49661 (* 1 = 1.49661 loss)
I0525 23:02:35.460386 20705 sgd_solver.cpp:106] Iteration 3450, lr = 0.005
I0525 23:02:44.201860 20705 solver.cpp:237] Iteration 3600, loss = 1.48756
I0525 23:02:44.201910 20705 solver.cpp:253]     Train net output #0: loss = 1.48756 (* 1 = 1.48756 loss)
I0525 23:02:44.201935 20705 sgd_solver.cpp:106] Iteration 3600, lr = 0.005
I0525 23:02:52.946166 20705 solver.cpp:237] Iteration 3750, loss = 1.46475
I0525 23:02:52.946310 20705 solver.cpp:253]     Train net output #0: loss = 1.46475 (* 1 = 1.46475 loss)
I0525 23:02:52.946326 20705 sgd_solver.cpp:106] Iteration 3750, lr = 0.005
I0525 23:03:01.690433 20705 solver.cpp:237] Iteration 3900, loss = 1.34111
I0525 23:03:01.690470 20705 solver.cpp:253]     Train net output #0: loss = 1.34111 (* 1 = 1.34111 loss)
I0525 23:03:01.690490 20705 sgd_solver.cpp:106] Iteration 3900, lr = 0.005
I0525 23:03:32.634186 20705 solver.cpp:237] Iteration 4050, loss = 1.60017
I0525 23:03:32.634356 20705 solver.cpp:253]     Train net output #0: loss = 1.60017 (* 1 = 1.60017 loss)
I0525 23:03:32.634374 20705 sgd_solver.cpp:106] Iteration 4050, lr = 0.005
I0525 23:03:41.370630 20705 solver.cpp:237] Iteration 4200, loss = 1.28363
I0525 23:03:41.370667 20705 solver.cpp:253]     Train net output #0: loss = 1.28363 (* 1 = 1.28363 loss)
I0525 23:03:41.370687 20705 sgd_solver.cpp:106] Iteration 4200, lr = 0.005
I0525 23:03:50.109962 20705 solver.cpp:237] Iteration 4350, loss = 1.17896
I0525 23:03:50.109999 20705 solver.cpp:253]     Train net output #0: loss = 1.17896 (* 1 = 1.17896 loss)
I0525 23:03:50.110018 20705 sgd_solver.cpp:106] Iteration 4350, lr = 0.005
I0525 23:03:58.788444 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_4500.caffemodel
I0525 23:03:58.871795 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_4500.solverstate
I0525 23:03:58.918275 20705 solver.cpp:237] Iteration 4500, loss = 1.44506
I0525 23:03:58.918337 20705 solver.cpp:253]     Train net output #0: loss = 1.44506 (* 1 = 1.44506 loss)
I0525 23:03:58.918356 20705 sgd_solver.cpp:106] Iteration 4500, lr = 0.005
I0525 23:04:07.652741 20705 solver.cpp:237] Iteration 4650, loss = 1.51431
I0525 23:04:07.652897 20705 solver.cpp:253]     Train net output #0: loss = 1.51431 (* 1 = 1.51431 loss)
I0525 23:04:07.652915 20705 sgd_solver.cpp:106] Iteration 4650, lr = 0.005
I0525 23:04:16.393877 20705 solver.cpp:237] Iteration 4800, loss = 1.47739
I0525 23:04:16.393913 20705 solver.cpp:253]     Train net output #0: loss = 1.47739 (* 1 = 1.47739 loss)
I0525 23:04:16.393932 20705 sgd_solver.cpp:106] Iteration 4800, lr = 0.005
I0525 23:04:25.140166 20705 solver.cpp:237] Iteration 4950, loss = 1.39026
I0525 23:04:25.140225 20705 solver.cpp:253]     Train net output #0: loss = 1.39026 (* 1 = 1.39026 loss)
I0525 23:04:25.140249 20705 sgd_solver.cpp:106] Iteration 4950, lr = 0.005
I0525 23:04:56.057566 20705 solver.cpp:237] Iteration 5100, loss = 1.35761
I0525 23:04:56.057735 20705 solver.cpp:253]     Train net output #0: loss = 1.35761 (* 1 = 1.35761 loss)
I0525 23:04:56.057754 20705 sgd_solver.cpp:106] Iteration 5100, lr = 0.005
I0525 23:05:04.809373 20705 solver.cpp:237] Iteration 5250, loss = 1.33513
I0525 23:05:04.809411 20705 solver.cpp:253]     Train net output #0: loss = 1.33513 (* 1 = 1.33513 loss)
I0525 23:05:04.809429 20705 sgd_solver.cpp:106] Iteration 5250, lr = 0.005
I0525 23:05:13.559213 20705 solver.cpp:237] Iteration 5400, loss = 1.14087
I0525 23:05:13.559264 20705 solver.cpp:253]     Train net output #0: loss = 1.14087 (* 1 = 1.14087 loss)
I0525 23:05:13.559289 20705 sgd_solver.cpp:106] Iteration 5400, lr = 0.005
I0525 23:05:22.310667 20705 solver.cpp:237] Iteration 5550, loss = 1.37123
I0525 23:05:22.310703 20705 solver.cpp:253]     Train net output #0: loss = 1.37123 (* 1 = 1.37123 loss)
I0525 23:05:22.310722 20705 sgd_solver.cpp:106] Iteration 5550, lr = 0.005
I0525 23:05:31.058454 20705 solver.cpp:237] Iteration 5700, loss = 1.33954
I0525 23:05:31.058598 20705 solver.cpp:253]     Train net output #0: loss = 1.33954 (* 1 = 1.33954 loss)
I0525 23:05:31.058615 20705 sgd_solver.cpp:106] Iteration 5700, lr = 0.005
I0525 23:05:39.808456 20705 solver.cpp:237] Iteration 5850, loss = 1.31565
I0525 23:05:39.808506 20705 solver.cpp:253]     Train net output #0: loss = 1.31565 (* 1 = 1.31565 loss)
I0525 23:05:39.808531 20705 sgd_solver.cpp:106] Iteration 5850, lr = 0.005
I0525 23:05:48.502159 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_6000.caffemodel
I0525 23:05:48.585589 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_6000.solverstate
I0525 23:05:48.613382 20705 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 23:06:56.278931 20705 solver.cpp:409]     Test net output #0: accuracy = 0.827052
I0525 23:06:56.279119 20705 solver.cpp:409]     Test net output #1: loss = 0.605034 (* 1 = 0.605034 loss)
I0525 23:07:18.443280 20705 solver.cpp:237] Iteration 6000, loss = 1.47617
I0525 23:07:18.443344 20705 solver.cpp:253]     Train net output #0: loss = 1.47617 (* 1 = 1.47617 loss)
I0525 23:07:18.443374 20705 sgd_solver.cpp:106] Iteration 6000, lr = 0.005
I0525 23:07:27.181007 20705 solver.cpp:237] Iteration 6150, loss = 1.29944
I0525 23:07:27.181160 20705 solver.cpp:253]     Train net output #0: loss = 1.29944 (* 1 = 1.29944 loss)
I0525 23:07:27.181177 20705 sgd_solver.cpp:106] Iteration 6150, lr = 0.005
I0525 23:07:35.918664 20705 solver.cpp:237] Iteration 6300, loss = 1.33557
I0525 23:07:35.918701 20705 solver.cpp:253]     Train net output #0: loss = 1.33557 (* 1 = 1.33557 loss)
I0525 23:07:35.918718 20705 sgd_solver.cpp:106] Iteration 6300, lr = 0.005
I0525 23:07:44.658802 20705 solver.cpp:237] Iteration 6450, loss = 1.4058
I0525 23:07:44.658849 20705 solver.cpp:253]     Train net output #0: loss = 1.4058 (* 1 = 1.4058 loss)
I0525 23:07:44.658869 20705 sgd_solver.cpp:106] Iteration 6450, lr = 0.005
I0525 23:07:53.399431 20705 solver.cpp:237] Iteration 6600, loss = 1.49457
I0525 23:07:53.399468 20705 solver.cpp:253]     Train net output #0: loss = 1.49457 (* 1 = 1.49457 loss)
I0525 23:07:53.399487 20705 sgd_solver.cpp:106] Iteration 6600, lr = 0.005
I0525 23:08:02.133934 20705 solver.cpp:237] Iteration 6750, loss = 1.21687
I0525 23:08:02.134078 20705 solver.cpp:253]     Train net output #0: loss = 1.21687 (* 1 = 1.21687 loss)
I0525 23:08:02.134094 20705 sgd_solver.cpp:106] Iteration 6750, lr = 0.005
I0525 23:08:10.876782 20705 solver.cpp:237] Iteration 6900, loss = 1.33697
I0525 23:08:10.876823 20705 solver.cpp:253]     Train net output #0: loss = 1.33697 (* 1 = 1.33697 loss)
I0525 23:08:10.876843 20705 sgd_solver.cpp:106] Iteration 6900, lr = 0.005
I0525 23:08:41.822376 20705 solver.cpp:237] Iteration 7050, loss = 1.11918
I0525 23:08:41.822543 20705 solver.cpp:253]     Train net output #0: loss = 1.11918 (* 1 = 1.11918 loss)
I0525 23:08:41.822561 20705 sgd_solver.cpp:106] Iteration 7050, lr = 0.005
I0525 23:08:50.558320 20705 solver.cpp:237] Iteration 7200, loss = 1.34568
I0525 23:08:50.558356 20705 solver.cpp:253]     Train net output #0: loss = 1.34568 (* 1 = 1.34568 loss)
I0525 23:08:50.558374 20705 sgd_solver.cpp:106] Iteration 7200, lr = 0.005
I0525 23:08:59.294245 20705 solver.cpp:237] Iteration 7350, loss = 1.47657
I0525 23:08:59.294289 20705 solver.cpp:253]     Train net output #0: loss = 1.47657 (* 1 = 1.47657 loss)
I0525 23:08:59.294309 20705 sgd_solver.cpp:106] Iteration 7350, lr = 0.005
I0525 23:09:07.979115 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_7500.caffemodel
I0525 23:09:08.061383 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_7500.solverstate
I0525 23:09:08.107249 20705 solver.cpp:237] Iteration 7500, loss = 1.39199
I0525 23:09:08.107308 20705 solver.cpp:253]     Train net output #0: loss = 1.39199 (* 1 = 1.39199 loss)
I0525 23:09:08.107336 20705 sgd_solver.cpp:106] Iteration 7500, lr = 0.005
I0525 23:09:16.848891 20705 solver.cpp:237] Iteration 7650, loss = 1.13029
I0525 23:09:16.849040 20705 solver.cpp:253]     Train net output #0: loss = 1.13029 (* 1 = 1.13029 loss)
I0525 23:09:16.849056 20705 sgd_solver.cpp:106] Iteration 7650, lr = 0.005
I0525 23:09:25.591758 20705 solver.cpp:237] Iteration 7800, loss = 1.33422
I0525 23:09:25.591811 20705 solver.cpp:253]     Train net output #0: loss = 1.33422 (* 1 = 1.33422 loss)
I0525 23:09:25.591838 20705 sgd_solver.cpp:106] Iteration 7800, lr = 0.005
I0525 23:09:34.326131 20705 solver.cpp:237] Iteration 7950, loss = 1.27184
I0525 23:09:34.326169 20705 solver.cpp:253]     Train net output #0: loss = 1.27184 (* 1 = 1.27184 loss)
I0525 23:09:34.326187 20705 sgd_solver.cpp:106] Iteration 7950, lr = 0.005
I0525 23:10:05.238926 20705 solver.cpp:237] Iteration 8100, loss = 1.37729
I0525 23:10:05.239100 20705 solver.cpp:253]     Train net output #0: loss = 1.37729 (* 1 = 1.37729 loss)
I0525 23:10:05.239117 20705 sgd_solver.cpp:106] Iteration 8100, lr = 0.005
I0525 23:10:13.975849 20705 solver.cpp:237] Iteration 8250, loss = 1.19145
I0525 23:10:13.975898 20705 solver.cpp:253]     Train net output #0: loss = 1.19145 (* 1 = 1.19145 loss)
I0525 23:10:13.975926 20705 sgd_solver.cpp:106] Iteration 8250, lr = 0.005
I0525 23:10:22.712853 20705 solver.cpp:237] Iteration 8400, loss = 1.2862
I0525 23:10:22.712889 20705 solver.cpp:253]     Train net output #0: loss = 1.2862 (* 1 = 1.2862 loss)
I0525 23:10:22.712908 20705 sgd_solver.cpp:106] Iteration 8400, lr = 0.005
I0525 23:10:31.446842 20705 solver.cpp:237] Iteration 8550, loss = 1.24993
I0525 23:10:31.446878 20705 solver.cpp:253]     Train net output #0: loss = 1.24993 (* 1 = 1.24993 loss)
I0525 23:10:31.446897 20705 sgd_solver.cpp:106] Iteration 8550, lr = 0.005
I0525 23:10:40.184532 20705 solver.cpp:237] Iteration 8700, loss = 1.12571
I0525 23:10:40.184684 20705 solver.cpp:253]     Train net output #0: loss = 1.12571 (* 1 = 1.12571 loss)
I0525 23:10:40.184702 20705 sgd_solver.cpp:106] Iteration 8700, lr = 0.005
I0525 23:10:48.913794 20705 solver.cpp:237] Iteration 8850, loss = 1.07901
I0525 23:10:48.913836 20705 solver.cpp:253]     Train net output #0: loss = 1.07901 (* 1 = 1.07901 loss)
I0525 23:10:48.913852 20705 sgd_solver.cpp:106] Iteration 8850, lr = 0.005
I0525 23:10:57.595808 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_9000.caffemodel
I0525 23:10:57.676785 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_9000.solverstate
I0525 23:10:57.702567 20705 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 23:11:44.202877 20705 solver.cpp:409]     Test net output #0: accuracy = 0.843638
I0525 23:11:44.203058 20705 solver.cpp:409]     Test net output #1: loss = 0.510731 (* 1 = 0.510731 loss)
I0525 23:12:06.435922 20705 solver.cpp:237] Iteration 9000, loss = 1.21931
I0525 23:12:06.435982 20705 solver.cpp:253]     Train net output #0: loss = 1.21931 (* 1 = 1.21931 loss)
I0525 23:12:06.436009 20705 sgd_solver.cpp:106] Iteration 9000, lr = 0.005
I0525 23:12:15.157039 20705 solver.cpp:237] Iteration 9150, loss = 1.04193
I0525 23:12:15.157215 20705 solver.cpp:253]     Train net output #0: loss = 1.04193 (* 1 = 1.04193 loss)
I0525 23:12:15.157233 20705 sgd_solver.cpp:106] Iteration 9150, lr = 0.005
I0525 23:12:23.891927 20705 solver.cpp:237] Iteration 9300, loss = 1.15979
I0525 23:12:23.891965 20705 solver.cpp:253]     Train net output #0: loss = 1.15979 (* 1 = 1.15979 loss)
I0525 23:12:23.891983 20705 sgd_solver.cpp:106] Iteration 9300, lr = 0.005
I0525 23:12:32.615334 20705 solver.cpp:237] Iteration 9450, loss = 1.43978
I0525 23:12:32.615371 20705 solver.cpp:253]     Train net output #0: loss = 1.43978 (* 1 = 1.43978 loss)
I0525 23:12:32.615391 20705 sgd_solver.cpp:106] Iteration 9450, lr = 0.005
I0525 23:12:41.345444 20705 solver.cpp:237] Iteration 9600, loss = 1.38694
I0525 23:12:41.345504 20705 solver.cpp:253]     Train net output #0: loss = 1.38694 (* 1 = 1.38694 loss)
I0525 23:12:41.345527 20705 sgd_solver.cpp:106] Iteration 9600, lr = 0.005
I0525 23:12:50.070969 20705 solver.cpp:237] Iteration 9750, loss = 1.50125
I0525 23:12:50.071132 20705 solver.cpp:253]     Train net output #0: loss = 1.50125 (* 1 = 1.50125 loss)
I0525 23:12:50.071149 20705 sgd_solver.cpp:106] Iteration 9750, lr = 0.005
I0525 23:12:58.805053 20705 solver.cpp:237] Iteration 9900, loss = 1.37715
I0525 23:12:58.805089 20705 solver.cpp:253]     Train net output #0: loss = 1.37715 (* 1 = 1.37715 loss)
I0525 23:12:58.805107 20705 sgd_solver.cpp:106] Iteration 9900, lr = 0.005
I0525 23:13:29.742920 20705 solver.cpp:237] Iteration 10050, loss = 1.38041
I0525 23:13:29.743100 20705 solver.cpp:253]     Train net output #0: loss = 1.38041 (* 1 = 1.38041 loss)
I0525 23:13:29.743119 20705 sgd_solver.cpp:106] Iteration 10050, lr = 0.005
I0525 23:13:38.472332 20705 solver.cpp:237] Iteration 10200, loss = 1.20983
I0525 23:13:38.472373 20705 solver.cpp:253]     Train net output #0: loss = 1.20983 (* 1 = 1.20983 loss)
I0525 23:13:38.472393 20705 sgd_solver.cpp:106] Iteration 10200, lr = 0.005
I0525 23:13:47.201095 20705 solver.cpp:237] Iteration 10350, loss = 1.16798
I0525 23:13:47.201133 20705 solver.cpp:253]     Train net output #0: loss = 1.16798 (* 1 = 1.16798 loss)
I0525 23:13:47.201150 20705 sgd_solver.cpp:106] Iteration 10350, lr = 0.005
I0525 23:13:55.873235 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_10500.caffemodel
I0525 23:13:55.954481 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_10500.solverstate
I0525 23:13:55.998921 20705 solver.cpp:237] Iteration 10500, loss = 1.20841
I0525 23:13:55.998976 20705 solver.cpp:253]     Train net output #0: loss = 1.20841 (* 1 = 1.20841 loss)
I0525 23:13:55.999001 20705 sgd_solver.cpp:106] Iteration 10500, lr = 0.005
I0525 23:14:04.732388 20705 solver.cpp:237] Iteration 10650, loss = 1.07157
I0525 23:14:04.732540 20705 solver.cpp:253]     Train net output #0: loss = 1.07157 (* 1 = 1.07157 loss)
I0525 23:14:04.732556 20705 sgd_solver.cpp:106] Iteration 10650, lr = 0.005
I0525 23:14:13.461884 20705 solver.cpp:237] Iteration 10800, loss = 1.14925
I0525 23:14:13.461922 20705 solver.cpp:253]     Train net output #0: loss = 1.14925 (* 1 = 1.14925 loss)
I0525 23:14:13.461938 20705 sgd_solver.cpp:106] Iteration 10800, lr = 0.005
I0525 23:14:22.197306 20705 solver.cpp:237] Iteration 10950, loss = 1.25915
I0525 23:14:22.197363 20705 solver.cpp:253]     Train net output #0: loss = 1.25915 (* 1 = 1.25915 loss)
I0525 23:14:22.197388 20705 sgd_solver.cpp:106] Iteration 10950, lr = 0.005
I0525 23:14:53.107105 20705 solver.cpp:237] Iteration 11100, loss = 1.20864
I0525 23:14:53.107282 20705 solver.cpp:253]     Train net output #0: loss = 1.20864 (* 1 = 1.20864 loss)
I0525 23:14:53.107300 20705 sgd_solver.cpp:106] Iteration 11100, lr = 0.005
I0525 23:15:01.837834 20705 solver.cpp:237] Iteration 11250, loss = 1.25537
I0525 23:15:01.837870 20705 solver.cpp:253]     Train net output #0: loss = 1.25537 (* 1 = 1.25537 loss)
I0525 23:15:01.837889 20705 sgd_solver.cpp:106] Iteration 11250, lr = 0.005
I0525 23:15:10.575037 20705 solver.cpp:237] Iteration 11400, loss = 1.15811
I0525 23:15:10.575088 20705 solver.cpp:253]     Train net output #0: loss = 1.15811 (* 1 = 1.15811 loss)
I0525 23:15:10.575114 20705 sgd_solver.cpp:106] Iteration 11400, lr = 0.005
I0525 23:15:19.299810 20705 solver.cpp:237] Iteration 11550, loss = 1.03514
I0525 23:15:19.299846 20705 solver.cpp:253]     Train net output #0: loss = 1.03514 (* 1 = 1.03514 loss)
I0525 23:15:19.299865 20705 sgd_solver.cpp:106] Iteration 11550, lr = 0.005
I0525 23:15:28.032963 20705 solver.cpp:237] Iteration 11700, loss = 1.33898
I0525 23:15:28.033112 20705 solver.cpp:253]     Train net output #0: loss = 1.33898 (* 1 = 1.33898 loss)
I0525 23:15:28.033128 20705 sgd_solver.cpp:106] Iteration 11700, lr = 0.005
I0525 23:15:36.764111 20705 solver.cpp:237] Iteration 11850, loss = 1.41923
I0525 23:15:36.764165 20705 solver.cpp:253]     Train net output #0: loss = 1.41923 (* 1 = 1.41923 loss)
I0525 23:15:36.764190 20705 sgd_solver.cpp:106] Iteration 11850, lr = 0.005
I0525 23:15:45.435223 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_12000.caffemodel
I0525 23:15:45.516384 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_12000.solverstate
I0525 23:15:45.542949 20705 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 23:16:53.248133 20705 solver.cpp:409]     Test net output #0: accuracy = 0.863327
I0525 23:16:53.248316 20705 solver.cpp:409]     Test net output #1: loss = 0.449797 (* 1 = 0.449797 loss)
I0525 23:17:15.399969 20705 solver.cpp:237] Iteration 12000, loss = 1.38206
I0525 23:17:15.400033 20705 solver.cpp:253]     Train net output #0: loss = 1.38206 (* 1 = 1.38206 loss)
I0525 23:17:15.400051 20705 sgd_solver.cpp:106] Iteration 12000, lr = 0.005
I0525 23:17:24.129227 20705 solver.cpp:237] Iteration 12150, loss = 1.14954
I0525 23:17:24.129400 20705 solver.cpp:253]     Train net output #0: loss = 1.14954 (* 1 = 1.14954 loss)
I0525 23:17:24.129416 20705 sgd_solver.cpp:106] Iteration 12150, lr = 0.005
I0525 23:17:32.858677 20705 solver.cpp:237] Iteration 12300, loss = 1.16232
I0525 23:17:32.858714 20705 solver.cpp:253]     Train net output #0: loss = 1.16232 (* 1 = 1.16232 loss)
I0525 23:17:32.858733 20705 sgd_solver.cpp:106] Iteration 12300, lr = 0.005
I0525 23:17:41.587057 20705 solver.cpp:237] Iteration 12450, loss = 1.43221
I0525 23:17:41.587107 20705 solver.cpp:253]     Train net output #0: loss = 1.43221 (* 1 = 1.43221 loss)
I0525 23:17:41.587133 20705 sgd_solver.cpp:106] Iteration 12450, lr = 0.005
I0525 23:17:50.312232 20705 solver.cpp:237] Iteration 12600, loss = 1.28092
I0525 23:17:50.312268 20705 solver.cpp:253]     Train net output #0: loss = 1.28092 (* 1 = 1.28092 loss)
I0525 23:17:50.312288 20705 sgd_solver.cpp:106] Iteration 12600, lr = 0.005
I0525 23:17:59.042909 20705 solver.cpp:237] Iteration 12750, loss = 1.30882
I0525 23:17:59.043058 20705 solver.cpp:253]     Train net output #0: loss = 1.30882 (* 1 = 1.30882 loss)
I0525 23:17:59.043076 20705 sgd_solver.cpp:106] Iteration 12750, lr = 0.005
I0525 23:18:07.771812 20705 solver.cpp:237] Iteration 12900, loss = 1.21806
I0525 23:18:07.771863 20705 solver.cpp:253]     Train net output #0: loss = 1.21806 (* 1 = 1.21806 loss)
I0525 23:18:07.771888 20705 sgd_solver.cpp:106] Iteration 12900, lr = 0.005
I0525 23:18:38.691182 20705 solver.cpp:237] Iteration 13050, loss = 1.28281
I0525 23:18:38.691357 20705 solver.cpp:253]     Train net output #0: loss = 1.28281 (* 1 = 1.28281 loss)
I0525 23:18:38.691375 20705 sgd_solver.cpp:106] Iteration 13050, lr = 0.005
I0525 23:18:47.417259 20705 solver.cpp:237] Iteration 13200, loss = 1.07069
I0525 23:18:47.417295 20705 solver.cpp:253]     Train net output #0: loss = 1.07069 (* 1 = 1.07069 loss)
I0525 23:18:47.417315 20705 sgd_solver.cpp:106] Iteration 13200, lr = 0.005
I0525 23:18:56.145635 20705 solver.cpp:237] Iteration 13350, loss = 1.19761
I0525 23:18:56.145694 20705 solver.cpp:253]     Train net output #0: loss = 1.19761 (* 1 = 1.19761 loss)
I0525 23:18:56.145720 20705 sgd_solver.cpp:106] Iteration 13350, lr = 0.005
I0525 23:19:04.815229 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_13500.caffemodel
I0525 23:19:04.899014 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_13500.solverstate
I0525 23:19:04.945264 20705 solver.cpp:237] Iteration 13500, loss = 1.27191
I0525 23:19:04.945322 20705 solver.cpp:253]     Train net output #0: loss = 1.27191 (* 1 = 1.27191 loss)
I0525 23:19:04.945346 20705 sgd_solver.cpp:106] Iteration 13500, lr = 0.005
I0525 23:19:13.673612 20705 solver.cpp:237] Iteration 13650, loss = 1.12913
I0525 23:19:13.673765 20705 solver.cpp:253]     Train net output #0: loss = 1.12913 (* 1 = 1.12913 loss)
I0525 23:19:13.673781 20705 sgd_solver.cpp:106] Iteration 13650, lr = 0.005
I0525 23:19:22.404582 20705 solver.cpp:237] Iteration 13800, loss = 1.36823
I0525 23:19:22.404636 20705 solver.cpp:253]     Train net output #0: loss = 1.36823 (* 1 = 1.36823 loss)
I0525 23:19:22.404654 20705 sgd_solver.cpp:106] Iteration 13800, lr = 0.005
I0525 23:19:31.131026 20705 solver.cpp:237] Iteration 13950, loss = 1.20759
I0525 23:19:31.131063 20705 solver.cpp:253]     Train net output #0: loss = 1.20759 (* 1 = 1.20759 loss)
I0525 23:19:31.131080 20705 sgd_solver.cpp:106] Iteration 13950, lr = 0.005
I0525 23:20:02.011636 20705 solver.cpp:237] Iteration 14100, loss = 1.17601
I0525 23:20:02.011823 20705 solver.cpp:253]     Train net output #0: loss = 1.17601 (* 1 = 1.17601 loss)
I0525 23:20:02.011842 20705 sgd_solver.cpp:106] Iteration 14100, lr = 0.005
I0525 23:20:10.742888 20705 solver.cpp:237] Iteration 14250, loss = 1.16255
I0525 23:20:10.742940 20705 solver.cpp:253]     Train net output #0: loss = 1.16255 (* 1 = 1.16255 loss)
I0525 23:20:10.742967 20705 sgd_solver.cpp:106] Iteration 14250, lr = 0.005
I0525 23:20:19.466378 20705 solver.cpp:237] Iteration 14400, loss = 1.10225
I0525 23:20:19.466415 20705 solver.cpp:253]     Train net output #0: loss = 1.10225 (* 1 = 1.10225 loss)
I0525 23:20:19.466434 20705 sgd_solver.cpp:106] Iteration 14400, lr = 0.005
I0525 23:20:28.195062 20705 solver.cpp:237] Iteration 14550, loss = 1.36485
I0525 23:20:28.195101 20705 solver.cpp:253]     Train net output #0: loss = 1.36485 (* 1 = 1.36485 loss)
I0525 23:20:28.195117 20705 sgd_solver.cpp:106] Iteration 14550, lr = 0.005
I0525 23:20:36.924114 20705 solver.cpp:237] Iteration 14700, loss = 1.29635
I0525 23:20:36.924283 20705 solver.cpp:253]     Train net output #0: loss = 1.29635 (* 1 = 1.29635 loss)
I0525 23:20:36.924299 20705 sgd_solver.cpp:106] Iteration 14700, lr = 0.005
I0525 23:20:45.651684 20705 solver.cpp:237] Iteration 14850, loss = 1.25733
I0525 23:20:45.651721 20705 solver.cpp:253]     Train net output #0: loss = 1.25733 (* 1 = 1.25733 loss)
I0525 23:20:45.651739 20705 sgd_solver.cpp:106] Iteration 14850, lr = 0.005
I0525 23:20:54.322782 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_15000.caffemodel
I0525 23:20:54.406450 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_15000.solverstate
I0525 23:20:54.434988 20705 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 23:21:41.273686 20705 solver.cpp:409]     Test net output #0: accuracy = 0.868793
I0525 23:21:41.273857 20705 solver.cpp:409]     Test net output #1: loss = 0.425889 (* 1 = 0.425889 loss)
I0525 23:22:02.093014 20705 solver.cpp:237] Iteration 15000, loss = 1.16355
I0525 23:22:02.093076 20705 solver.cpp:253]     Train net output #0: loss = 1.16355 (* 1 = 1.16355 loss)
I0525 23:22:02.093096 20705 sgd_solver.cpp:106] Iteration 15000, lr = 0.005
I0525 23:22:10.832057 20705 solver.cpp:237] Iteration 15150, loss = 1.13505
I0525 23:22:10.832099 20705 solver.cpp:253]     Train net output #0: loss = 1.13505 (* 1 = 1.13505 loss)
I0525 23:22:10.832116 20705 sgd_solver.cpp:106] Iteration 15150, lr = 0.005
I0525 23:22:19.575361 20705 solver.cpp:237] Iteration 15300, loss = 1.10773
I0525 23:22:19.575536 20705 solver.cpp:253]     Train net output #0: loss = 1.10773 (* 1 = 1.10773 loss)
I0525 23:22:19.575554 20705 sgd_solver.cpp:106] Iteration 15300, lr = 0.005
I0525 23:22:28.305958 20705 solver.cpp:237] Iteration 15450, loss = 1.15987
I0525 23:22:28.305995 20705 solver.cpp:253]     Train net output #0: loss = 1.15987 (* 1 = 1.15987 loss)
I0525 23:22:28.306015 20705 sgd_solver.cpp:106] Iteration 15450, lr = 0.005
I0525 23:22:37.035989 20705 solver.cpp:237] Iteration 15600, loss = 1.03863
I0525 23:22:37.036026 20705 solver.cpp:253]     Train net output #0: loss = 1.03863 (* 1 = 1.03863 loss)
I0525 23:22:37.036042 20705 sgd_solver.cpp:106] Iteration 15600, lr = 0.005
I0525 23:22:45.763811 20705 solver.cpp:237] Iteration 15750, loss = 1.10209
I0525 23:22:45.763867 20705 solver.cpp:253]     Train net output #0: loss = 1.10209 (* 1 = 1.10209 loss)
I0525 23:22:45.763892 20705 sgd_solver.cpp:106] Iteration 15750, lr = 0.005
I0525 23:22:54.491511 20705 solver.cpp:237] Iteration 15900, loss = 1.11944
I0525 23:22:54.491673 20705 solver.cpp:253]     Train net output #0: loss = 1.11944 (* 1 = 1.11944 loss)
I0525 23:22:54.491690 20705 sgd_solver.cpp:106] Iteration 15900, lr = 0.005
I0525 23:23:24.008244 20705 solver.cpp:237] Iteration 16050, loss = 1.43573
I0525 23:23:24.008303 20705 solver.cpp:253]     Train net output #0: loss = 1.43573 (* 1 = 1.43573 loss)
I0525 23:23:24.008328 20705 sgd_solver.cpp:106] Iteration 16050, lr = 0.005
I0525 23:23:32.737426 20705 solver.cpp:237] Iteration 16200, loss = 1.10353
I0525 23:23:32.737602 20705 solver.cpp:253]     Train net output #0: loss = 1.10353 (* 1 = 1.10353 loss)
I0525 23:23:32.737622 20705 sgd_solver.cpp:106] Iteration 16200, lr = 0.005
I0525 23:23:41.471542 20705 solver.cpp:237] Iteration 16350, loss = 1.31028
I0525 23:23:41.471580 20705 solver.cpp:253]     Train net output #0: loss = 1.31028 (* 1 = 1.31028 loss)
I0525 23:23:41.471598 20705 sgd_solver.cpp:106] Iteration 16350, lr = 0.005
I0525 23:23:50.141644 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_16500.caffemodel
I0525 23:23:50.222705 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_16500.solverstate
I0525 23:23:50.266412 20705 solver.cpp:237] Iteration 16500, loss = 1.13107
I0525 23:23:50.266471 20705 solver.cpp:253]     Train net output #0: loss = 1.13107 (* 1 = 1.13107 loss)
I0525 23:23:50.266489 20705 sgd_solver.cpp:106] Iteration 16500, lr = 0.005
I0525 23:23:58.996261 20705 solver.cpp:237] Iteration 16650, loss = 1.26784
I0525 23:23:58.996320 20705 solver.cpp:253]     Train net output #0: loss = 1.26784 (* 1 = 1.26784 loss)
I0525 23:23:58.996356 20705 sgd_solver.cpp:106] Iteration 16650, lr = 0.005
I0525 23:24:07.719771 20705 solver.cpp:237] Iteration 16800, loss = 1.30949
I0525 23:24:07.719926 20705 solver.cpp:253]     Train net output #0: loss = 1.30949 (* 1 = 1.30949 loss)
I0525 23:24:07.719944 20705 sgd_solver.cpp:106] Iteration 16800, lr = 0.005
I0525 23:24:16.449054 20705 solver.cpp:237] Iteration 16950, loss = 1.26944
I0525 23:24:16.449093 20705 solver.cpp:253]     Train net output #0: loss = 1.26944 (* 1 = 1.26944 loss)
I0525 23:24:16.449117 20705 sgd_solver.cpp:106] Iteration 16950, lr = 0.005
I0525 23:24:45.973147 20705 solver.cpp:237] Iteration 17100, loss = 1.03652
I0525 23:24:45.973325 20705 solver.cpp:253]     Train net output #0: loss = 1.03652 (* 1 = 1.03652 loss)
I0525 23:24:45.973342 20705 sgd_solver.cpp:106] Iteration 17100, lr = 0.005
I0525 23:24:54.703160 20705 solver.cpp:237] Iteration 17250, loss = 1.19462
I0525 23:24:54.703200 20705 solver.cpp:253]     Train net output #0: loss = 1.19462 (* 1 = 1.19462 loss)
I0525 23:24:54.703217 20705 sgd_solver.cpp:106] Iteration 17250, lr = 0.005
I0525 23:25:03.434789 20705 solver.cpp:237] Iteration 17400, loss = 1.44899
I0525 23:25:03.434826 20705 solver.cpp:253]     Train net output #0: loss = 1.44899 (* 1 = 1.44899 loss)
I0525 23:25:03.434844 20705 sgd_solver.cpp:106] Iteration 17400, lr = 0.005
I0525 23:25:12.158663 20705 solver.cpp:237] Iteration 17550, loss = 1.20681
I0525 23:25:12.158720 20705 solver.cpp:253]     Train net output #0: loss = 1.20681 (* 1 = 1.20681 loss)
I0525 23:25:12.158746 20705 sgd_solver.cpp:106] Iteration 17550, lr = 0.005
I0525 23:25:20.882508 20705 solver.cpp:237] Iteration 17700, loss = 1.08794
I0525 23:25:20.882659 20705 solver.cpp:253]     Train net output #0: loss = 1.08794 (* 1 = 1.08794 loss)
I0525 23:25:20.882676 20705 sgd_solver.cpp:106] Iteration 17700, lr = 0.005
I0525 23:25:29.607786 20705 solver.cpp:237] Iteration 17850, loss = 1.19732
I0525 23:25:29.607822 20705 solver.cpp:253]     Train net output #0: loss = 1.19732 (* 1 = 1.19732 loss)
I0525 23:25:29.607841 20705 sgd_solver.cpp:106] Iteration 17850, lr = 0.005
I0525 23:25:38.282433 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_18000.caffemodel
I0525 23:25:38.363225 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_18000.solverstate
I0525 23:25:38.388833 20705 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 23:26:46.091598 20705 solver.cpp:409]     Test net output #0: accuracy = 0.870607
I0525 23:26:46.091789 20705 solver.cpp:409]     Test net output #1: loss = 0.39527 (* 1 = 0.39527 loss)
I0525 23:27:06.952639 20705 solver.cpp:237] Iteration 18000, loss = 1.26911
I0525 23:27:06.952702 20705 solver.cpp:253]     Train net output #0: loss = 1.26911 (* 1 = 1.26911 loss)
I0525 23:27:06.952731 20705 sgd_solver.cpp:106] Iteration 18000, lr = 0.005
I0525 23:27:15.691140 20705 solver.cpp:237] Iteration 18150, loss = 1.23813
I0525 23:27:15.691190 20705 solver.cpp:253]     Train net output #0: loss = 1.23813 (* 1 = 1.23813 loss)
I0525 23:27:15.691220 20705 sgd_solver.cpp:106] Iteration 18150, lr = 0.005
I0525 23:27:24.433709 20705 solver.cpp:237] Iteration 18300, loss = 1.15361
I0525 23:27:24.433866 20705 solver.cpp:253]     Train net output #0: loss = 1.15361 (* 1 = 1.15361 loss)
I0525 23:27:24.433881 20705 sgd_solver.cpp:106] Iteration 18300, lr = 0.005
I0525 23:27:33.176410 20705 solver.cpp:237] Iteration 18450, loss = 1.0633
I0525 23:27:33.176446 20705 solver.cpp:253]     Train net output #0: loss = 1.0633 (* 1 = 1.0633 loss)
I0525 23:27:33.176465 20705 sgd_solver.cpp:106] Iteration 18450, lr = 0.005
I0525 23:27:41.919592 20705 solver.cpp:237] Iteration 18600, loss = 1.22636
I0525 23:27:41.919651 20705 solver.cpp:253]     Train net output #0: loss = 1.22636 (* 1 = 1.22636 loss)
I0525 23:27:41.919677 20705 sgd_solver.cpp:106] Iteration 18600, lr = 0.005
I0525 23:27:50.657979 20705 solver.cpp:237] Iteration 18750, loss = 1.18505
I0525 23:27:50.658016 20705 solver.cpp:253]     Train net output #0: loss = 1.18505 (* 1 = 1.18505 loss)
I0525 23:27:50.658035 20705 sgd_solver.cpp:106] Iteration 18750, lr = 0.005
I0525 23:27:59.395418 20705 solver.cpp:237] Iteration 18900, loss = 1.22326
I0525 23:27:59.395572 20705 solver.cpp:253]     Train net output #0: loss = 1.22326 (* 1 = 1.22326 loss)
I0525 23:27:59.395588 20705 sgd_solver.cpp:106] Iteration 18900, lr = 0.005
I0525 23:28:28.991744 20705 solver.cpp:237] Iteration 19050, loss = 1.16131
I0525 23:28:28.991802 20705 solver.cpp:253]     Train net output #0: loss = 1.16131 (* 1 = 1.16131 loss)
I0525 23:28:28.991821 20705 sgd_solver.cpp:106] Iteration 19050, lr = 0.005
I0525 23:28:37.725219 20705 solver.cpp:237] Iteration 19200, loss = 1.08096
I0525 23:28:37.725376 20705 solver.cpp:253]     Train net output #0: loss = 1.08096 (* 1 = 1.08096 loss)
I0525 23:28:37.725394 20705 sgd_solver.cpp:106] Iteration 19200, lr = 0.005
I0525 23:28:46.458411 20705 solver.cpp:237] Iteration 19350, loss = 1.11338
I0525 23:28:46.458447 20705 solver.cpp:253]     Train net output #0: loss = 1.11338 (* 1 = 1.11338 loss)
I0525 23:28:46.458467 20705 sgd_solver.cpp:106] Iteration 19350, lr = 0.005
I0525 23:28:55.144273 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_19500.caffemodel
I0525 23:28:55.224402 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_19500.solverstate
I0525 23:28:55.268472 20705 solver.cpp:237] Iteration 19500, loss = 1.10581
I0525 23:28:55.268529 20705 solver.cpp:253]     Train net output #0: loss = 1.10581 (* 1 = 1.10581 loss)
I0525 23:28:55.268553 20705 sgd_solver.cpp:106] Iteration 19500, lr = 0.005
I0525 23:29:04.002876 20705 solver.cpp:237] Iteration 19650, loss = 1.39655
I0525 23:29:04.002915 20705 solver.cpp:253]     Train net output #0: loss = 1.39655 (* 1 = 1.39655 loss)
I0525 23:29:04.002934 20705 sgd_solver.cpp:106] Iteration 19650, lr = 0.005
I0525 23:29:12.740504 20705 solver.cpp:237] Iteration 19800, loss = 1.16706
I0525 23:29:12.740666 20705 solver.cpp:253]     Train net output #0: loss = 1.16706 (* 1 = 1.16706 loss)
I0525 23:29:12.740684 20705 sgd_solver.cpp:106] Iteration 19800, lr = 0.005
I0525 23:29:21.472530 20705 solver.cpp:237] Iteration 19950, loss = 1.1236
I0525 23:29:21.472581 20705 solver.cpp:253]     Train net output #0: loss = 1.1236 (* 1 = 1.1236 loss)
I0525 23:29:21.472599 20705 sgd_solver.cpp:106] Iteration 19950, lr = 0.005
I0525 23:29:50.999311 20705 solver.cpp:237] Iteration 20100, loss = 1.30544
I0525 23:29:50.999495 20705 solver.cpp:253]     Train net output #0: loss = 1.30544 (* 1 = 1.30544 loss)
I0525 23:29:50.999514 20705 sgd_solver.cpp:106] Iteration 20100, lr = 0.005
I0525 23:29:59.739460 20705 solver.cpp:237] Iteration 20250, loss = 1.04664
I0525 23:29:59.739497 20705 solver.cpp:253]     Train net output #0: loss = 1.04664 (* 1 = 1.04664 loss)
I0525 23:29:59.739516 20705 sgd_solver.cpp:106] Iteration 20250, lr = 0.005
I0525 23:30:08.477258 20705 solver.cpp:237] Iteration 20400, loss = 1.2246
I0525 23:30:08.477316 20705 solver.cpp:253]     Train net output #0: loss = 1.2246 (* 1 = 1.2246 loss)
I0525 23:30:08.477342 20705 sgd_solver.cpp:106] Iteration 20400, lr = 0.005
I0525 23:30:17.210748 20705 solver.cpp:237] Iteration 20550, loss = 1.34788
I0525 23:30:17.210788 20705 solver.cpp:253]     Train net output #0: loss = 1.34788 (* 1 = 1.34788 loss)
I0525 23:30:17.210804 20705 sgd_solver.cpp:106] Iteration 20550, lr = 0.005
I0525 23:30:25.947257 20705 solver.cpp:237] Iteration 20700, loss = 1.13905
I0525 23:30:25.947409 20705 solver.cpp:253]     Train net output #0: loss = 1.13905 (* 1 = 1.13905 loss)
I0525 23:30:25.947427 20705 sgd_solver.cpp:106] Iteration 20700, lr = 0.005
I0525 23:30:34.685701 20705 solver.cpp:237] Iteration 20850, loss = 1.16917
I0525 23:30:34.685755 20705 solver.cpp:253]     Train net output #0: loss = 1.16917 (* 1 = 1.16917 loss)
I0525 23:30:34.685782 20705 sgd_solver.cpp:106] Iteration 20850, lr = 0.005
I0525 23:30:43.366858 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_21000.caffemodel
I0525 23:30:43.445451 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_21000.solverstate
I0525 23:30:43.471541 20705 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 23:31:29.982461 20705 solver.cpp:409]     Test net output #0: accuracy = 0.8756
I0525 23:31:29.982636 20705 solver.cpp:409]     Test net output #1: loss = 0.419316 (* 1 = 0.419316 loss)
I0525 23:31:50.828383 20705 solver.cpp:237] Iteration 21000, loss = 1.14475
I0525 23:31:50.828450 20705 solver.cpp:253]     Train net output #0: loss = 1.14475 (* 1 = 1.14475 loss)
I0525 23:31:50.828469 20705 sgd_solver.cpp:106] Iteration 21000, lr = 0.005
I0525 23:31:59.576889 20705 solver.cpp:237] Iteration 21150, loss = 1.06502
I0525 23:31:59.576927 20705 solver.cpp:253]     Train net output #0: loss = 1.06502 (* 1 = 1.06502 loss)
I0525 23:31:59.576944 20705 sgd_solver.cpp:106] Iteration 21150, lr = 0.005
I0525 23:32:08.330153 20705 solver.cpp:237] Iteration 21300, loss = 1.26897
I0525 23:32:08.330310 20705 solver.cpp:253]     Train net output #0: loss = 1.26897 (* 1 = 1.26897 loss)
I0525 23:32:08.330327 20705 sgd_solver.cpp:106] Iteration 21300, lr = 0.005
I0525 23:32:17.087239 20705 solver.cpp:237] Iteration 21450, loss = 1.3822
I0525 23:32:17.087292 20705 solver.cpp:253]     Train net output #0: loss = 1.3822 (* 1 = 1.3822 loss)
I0525 23:32:17.087312 20705 sgd_solver.cpp:106] Iteration 21450, lr = 0.005
I0525 23:32:25.839869 20705 solver.cpp:237] Iteration 21600, loss = 1.20624
I0525 23:32:25.839905 20705 solver.cpp:253]     Train net output #0: loss = 1.20624 (* 1 = 1.20624 loss)
I0525 23:32:25.839925 20705 sgd_solver.cpp:106] Iteration 21600, lr = 0.005
I0525 23:32:34.582690 20705 solver.cpp:237] Iteration 21750, loss = 1.21993
I0525 23:32:34.582727 20705 solver.cpp:253]     Train net output #0: loss = 1.21993 (* 1 = 1.21993 loss)
I0525 23:32:34.582746 20705 sgd_solver.cpp:106] Iteration 21750, lr = 0.005
I0525 23:32:43.325711 20705 solver.cpp:237] Iteration 21900, loss = 1.13824
I0525 23:32:43.325896 20705 solver.cpp:253]     Train net output #0: loss = 1.13824 (* 1 = 1.13824 loss)
I0525 23:32:43.325912 20705 sgd_solver.cpp:106] Iteration 21900, lr = 0.005
I0525 23:33:12.914520 20705 solver.cpp:237] Iteration 22050, loss = 1.26841
I0525 23:33:12.914579 20705 solver.cpp:253]     Train net output #0: loss = 1.26841 (* 1 = 1.26841 loss)
I0525 23:33:12.914603 20705 sgd_solver.cpp:106] Iteration 22050, lr = 0.005
I0525 23:33:21.648177 20705 solver.cpp:237] Iteration 22200, loss = 1.26167
I0525 23:33:21.648360 20705 solver.cpp:253]     Train net output #0: loss = 1.26167 (* 1 = 1.26167 loss)
I0525 23:33:21.648376 20705 sgd_solver.cpp:106] Iteration 22200, lr = 0.005
I0525 23:33:30.384773 20705 solver.cpp:237] Iteration 22350, loss = 1.14563
I0525 23:33:30.384831 20705 solver.cpp:253]     Train net output #0: loss = 1.14563 (* 1 = 1.14563 loss)
I0525 23:33:30.384855 20705 sgd_solver.cpp:106] Iteration 22350, lr = 0.005
I0525 23:33:39.063134 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_22500.caffemodel
I0525 23:33:39.143535 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_22500.solverstate
I0525 23:33:39.189106 20705 solver.cpp:237] Iteration 22500, loss = 1.21362
I0525 23:33:39.189169 20705 solver.cpp:253]     Train net output #0: loss = 1.21362 (* 1 = 1.21362 loss)
I0525 23:33:39.189187 20705 sgd_solver.cpp:106] Iteration 22500, lr = 0.005
I0525 23:33:47.931684 20705 solver.cpp:237] Iteration 22650, loss = 1.21326
I0525 23:33:47.931718 20705 solver.cpp:253]     Train net output #0: loss = 1.21326 (* 1 = 1.21326 loss)
I0525 23:33:47.931742 20705 sgd_solver.cpp:106] Iteration 22650, lr = 0.005
I0525 23:33:56.673069 20705 solver.cpp:237] Iteration 22800, loss = 1.24061
I0525 23:33:56.673249 20705 solver.cpp:253]     Train net output #0: loss = 1.24061 (* 1 = 1.24061 loss)
I0525 23:33:56.673265 20705 sgd_solver.cpp:106] Iteration 22800, lr = 0.005
I0525 23:34:05.403311 20705 solver.cpp:237] Iteration 22950, loss = 1.29425
I0525 23:34:05.403347 20705 solver.cpp:253]     Train net output #0: loss = 1.29425 (* 1 = 1.29425 loss)
I0525 23:34:05.403365 20705 sgd_solver.cpp:106] Iteration 22950, lr = 0.005
I0525 23:34:34.937369 20705 solver.cpp:237] Iteration 23100, loss = 1.08176
I0525 23:34:34.937551 20705 solver.cpp:253]     Train net output #0: loss = 1.08176 (* 1 = 1.08176 loss)
I0525 23:34:34.937569 20705 sgd_solver.cpp:106] Iteration 23100, lr = 0.005
I0525 23:34:43.677289 20705 solver.cpp:237] Iteration 23250, loss = 1.10786
I0525 23:34:43.677345 20705 solver.cpp:253]     Train net output #0: loss = 1.10786 (* 1 = 1.10786 loss)
I0525 23:34:43.677371 20705 sgd_solver.cpp:106] Iteration 23250, lr = 0.005
I0525 23:34:52.412488 20705 solver.cpp:237] Iteration 23400, loss = 1.35017
I0525 23:34:52.412524 20705 solver.cpp:253]     Train net output #0: loss = 1.35017 (* 1 = 1.35017 loss)
I0525 23:34:52.412544 20705 sgd_solver.cpp:106] Iteration 23400, lr = 0.005
I0525 23:35:01.148772 20705 solver.cpp:237] Iteration 23550, loss = 1.35883
I0525 23:35:01.148808 20705 solver.cpp:253]     Train net output #0: loss = 1.35883 (* 1 = 1.35883 loss)
I0525 23:35:01.148825 20705 sgd_solver.cpp:106] Iteration 23550, lr = 0.005
I0525 23:35:09.877490 20705 solver.cpp:237] Iteration 23700, loss = 1.33241
I0525 23:35:09.877663 20705 solver.cpp:253]     Train net output #0: loss = 1.33241 (* 1 = 1.33241 loss)
I0525 23:35:09.877681 20705 sgd_solver.cpp:106] Iteration 23700, lr = 0.005
I0525 23:35:18.614117 20705 solver.cpp:237] Iteration 23850, loss = 1.0538
I0525 23:35:18.614153 20705 solver.cpp:253]     Train net output #0: loss = 1.0538 (* 1 = 1.0538 loss)
I0525 23:35:18.614172 20705 sgd_solver.cpp:106] Iteration 23850, lr = 0.005
I0525 23:35:27.289496 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_24000.caffemodel
I0525 23:35:27.377627 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_24000.solverstate
I0525 23:35:27.403353 20705 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 23:36:35.016425 20705 solver.cpp:409]     Test net output #0: accuracy = 0.880381
I0525 23:36:35.016609 20705 solver.cpp:409]     Test net output #1: loss = 0.382137 (* 1 = 0.382137 loss)
I0525 23:36:55.854432 20705 solver.cpp:237] Iteration 24000, loss = 1.06851
I0525 23:36:55.854496 20705 solver.cpp:253]     Train net output #0: loss = 1.06851 (* 1 = 1.06851 loss)
I0525 23:36:55.854526 20705 sgd_solver.cpp:106] Iteration 24000, lr = 0.005
I0525 23:37:04.584529 20705 solver.cpp:237] Iteration 24150, loss = 0.932022
I0525 23:37:04.584568 20705 solver.cpp:253]     Train net output #0: loss = 0.932022 (* 1 = 0.932022 loss)
I0525 23:37:04.584585 20705 sgd_solver.cpp:106] Iteration 24150, lr = 0.005
I0525 23:37:13.317878 20705 solver.cpp:237] Iteration 24300, loss = 1.2088
I0525 23:37:13.318044 20705 solver.cpp:253]     Train net output #0: loss = 1.2088 (* 1 = 1.2088 loss)
I0525 23:37:13.318063 20705 sgd_solver.cpp:106] Iteration 24300, lr = 0.005
I0525 23:37:22.058969 20705 solver.cpp:237] Iteration 24450, loss = 1.19155
I0525 23:37:22.059007 20705 solver.cpp:253]     Train net output #0: loss = 1.19155 (* 1 = 1.19155 loss)
I0525 23:37:22.059025 20705 sgd_solver.cpp:106] Iteration 24450, lr = 0.005
I0525 23:37:30.799526 20705 solver.cpp:237] Iteration 24600, loss = 1.08615
I0525 23:37:30.799562 20705 solver.cpp:253]     Train net output #0: loss = 1.08615 (* 1 = 1.08615 loss)
I0525 23:37:30.799587 20705 sgd_solver.cpp:106] Iteration 24600, lr = 0.005
I0525 23:37:39.539170 20705 solver.cpp:237] Iteration 24750, loss = 1.27349
I0525 23:37:39.539227 20705 solver.cpp:253]     Train net output #0: loss = 1.27349 (* 1 = 1.27349 loss)
I0525 23:37:39.539253 20705 sgd_solver.cpp:106] Iteration 24750, lr = 0.005
I0525 23:37:48.279876 20705 solver.cpp:237] Iteration 24900, loss = 1.07134
I0525 23:37:48.280043 20705 solver.cpp:253]     Train net output #0: loss = 1.07134 (* 1 = 1.07134 loss)
I0525 23:37:48.280061 20705 sgd_solver.cpp:106] Iteration 24900, lr = 0.005
I0525 23:38:17.834396 20705 solver.cpp:237] Iteration 25050, loss = 1.19836
I0525 23:38:17.834455 20705 solver.cpp:253]     Train net output #0: loss = 1.19836 (* 1 = 1.19836 loss)
I0525 23:38:17.834473 20705 sgd_solver.cpp:106] Iteration 25050, lr = 0.005
I0525 23:38:26.574795 20705 solver.cpp:237] Iteration 25200, loss = 1.26592
I0525 23:38:26.574957 20705 solver.cpp:253]     Train net output #0: loss = 1.26592 (* 1 = 1.26592 loss)
I0525 23:38:26.574973 20705 sgd_solver.cpp:106] Iteration 25200, lr = 0.005
I0525 23:38:35.311050 20705 solver.cpp:237] Iteration 25350, loss = 1.24928
I0525 23:38:35.311100 20705 solver.cpp:253]     Train net output #0: loss = 1.24928 (* 1 = 1.24928 loss)
I0525 23:38:35.311126 20705 sgd_solver.cpp:106] Iteration 25350, lr = 0.005
I0525 23:38:43.990994 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_25500.caffemodel
I0525 23:38:44.069937 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_25500.solverstate
I0525 23:38:44.114122 20705 solver.cpp:237] Iteration 25500, loss = 1.05489
I0525 23:38:44.114179 20705 solver.cpp:253]     Train net output #0: loss = 1.05489 (* 1 = 1.05489 loss)
I0525 23:38:44.114205 20705 sgd_solver.cpp:106] Iteration 25500, lr = 0.005
I0525 23:38:52.855921 20705 solver.cpp:237] Iteration 25650, loss = 0.986216
I0525 23:38:52.855975 20705 solver.cpp:253]     Train net output #0: loss = 0.986216 (* 1 = 0.986216 loss)
I0525 23:38:52.856001 20705 sgd_solver.cpp:106] Iteration 25650, lr = 0.005
I0525 23:39:01.596876 20705 solver.cpp:237] Iteration 25800, loss = 1.23778
I0525 23:39:01.597056 20705 solver.cpp:253]     Train net output #0: loss = 1.23778 (* 1 = 1.23778 loss)
I0525 23:39:01.597074 20705 sgd_solver.cpp:106] Iteration 25800, lr = 0.005
I0525 23:39:10.336257 20705 solver.cpp:237] Iteration 25950, loss = 1.27974
I0525 23:39:10.336295 20705 solver.cpp:253]     Train net output #0: loss = 1.27974 (* 1 = 1.27974 loss)
I0525 23:39:10.336311 20705 sgd_solver.cpp:106] Iteration 25950, lr = 0.005
I0525 23:39:39.934089 20705 solver.cpp:237] Iteration 26100, loss = 1.16204
I0525 23:39:39.934275 20705 solver.cpp:253]     Train net output #0: loss = 1.16204 (* 1 = 1.16204 loss)
I0525 23:39:39.934293 20705 sgd_solver.cpp:106] Iteration 26100, lr = 0.005
I0525 23:39:48.673369 20705 solver.cpp:237] Iteration 26250, loss = 1.29581
I0525 23:39:48.673427 20705 solver.cpp:253]     Train net output #0: loss = 1.29581 (* 1 = 1.29581 loss)
I0525 23:39:48.673447 20705 sgd_solver.cpp:106] Iteration 26250, lr = 0.005
I0525 23:39:57.416066 20705 solver.cpp:237] Iteration 26400, loss = 1.10683
I0525 23:39:57.416105 20705 solver.cpp:253]     Train net output #0: loss = 1.10683 (* 1 = 1.10683 loss)
I0525 23:39:57.416122 20705 sgd_solver.cpp:106] Iteration 26400, lr = 0.005
I0525 23:40:06.158154 20705 solver.cpp:237] Iteration 26550, loss = 1.1604
I0525 23:40:06.158195 20705 solver.cpp:253]     Train net output #0: loss = 1.1604 (* 1 = 1.1604 loss)
I0525 23:40:06.158212 20705 sgd_solver.cpp:106] Iteration 26550, lr = 0.005
I0525 23:40:14.898277 20705 solver.cpp:237] Iteration 26700, loss = 1.28546
I0525 23:40:14.898454 20705 solver.cpp:253]     Train net output #0: loss = 1.28546 (* 1 = 1.28546 loss)
I0525 23:40:14.898473 20705 sgd_solver.cpp:106] Iteration 26700, lr = 0.005
I0525 23:40:23.637346 20705 solver.cpp:237] Iteration 26850, loss = 1.13644
I0525 23:40:23.637383 20705 solver.cpp:253]     Train net output #0: loss = 1.13644 (* 1 = 1.13644 loss)
I0525 23:40:23.637400 20705 sgd_solver.cpp:106] Iteration 26850, lr = 0.005
I0525 23:40:32.319775 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_27000.caffemodel
I0525 23:40:32.398634 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_27000.solverstate
I0525 23:40:32.424762 20705 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 23:41:19.320958 20705 solver.cpp:409]     Test net output #0: accuracy = 0.881767
I0525 23:41:19.321136 20705 solver.cpp:409]     Test net output #1: loss = 0.370595 (* 1 = 0.370595 loss)
I0525 23:41:40.165452 20705 solver.cpp:237] Iteration 27000, loss = 1.3924
I0525 23:41:40.165511 20705 solver.cpp:253]     Train net output #0: loss = 1.3924 (* 1 = 1.3924 loss)
I0525 23:41:40.165537 20705 sgd_solver.cpp:106] Iteration 27000, lr = 0.005
I0525 23:41:48.903290 20705 solver.cpp:237] Iteration 27150, loss = 1.17572
I0525 23:41:48.903349 20705 solver.cpp:253]     Train net output #0: loss = 1.17572 (* 1 = 1.17572 loss)
I0525 23:41:48.903375 20705 sgd_solver.cpp:106] Iteration 27150, lr = 0.005
I0525 23:41:57.642395 20705 solver.cpp:237] Iteration 27300, loss = 1.20578
I0525 23:41:57.642560 20705 solver.cpp:253]     Train net output #0: loss = 1.20578 (* 1 = 1.20578 loss)
I0525 23:41:57.642576 20705 sgd_solver.cpp:106] Iteration 27300, lr = 0.005
I0525 23:42:06.386077 20705 solver.cpp:237] Iteration 27450, loss = 1.12204
I0525 23:42:06.386114 20705 solver.cpp:253]     Train net output #0: loss = 1.12204 (* 1 = 1.12204 loss)
I0525 23:42:06.386132 20705 sgd_solver.cpp:106] Iteration 27450, lr = 0.005
I0525 23:42:15.129137 20705 solver.cpp:237] Iteration 27600, loss = 1.28707
I0525 23:42:15.129189 20705 solver.cpp:253]     Train net output #0: loss = 1.28707 (* 1 = 1.28707 loss)
I0525 23:42:15.129216 20705 sgd_solver.cpp:106] Iteration 27600, lr = 0.005
I0525 23:42:23.874032 20705 solver.cpp:237] Iteration 27750, loss = 1.21475
I0525 23:42:23.874068 20705 solver.cpp:253]     Train net output #0: loss = 1.21475 (* 1 = 1.21475 loss)
I0525 23:42:23.874085 20705 sgd_solver.cpp:106] Iteration 27750, lr = 0.005
I0525 23:42:32.615124 20705 solver.cpp:237] Iteration 27900, loss = 1.11655
I0525 23:42:32.615303 20705 solver.cpp:253]     Train net output #0: loss = 1.11655 (* 1 = 1.11655 loss)
I0525 23:42:32.615319 20705 sgd_solver.cpp:106] Iteration 27900, lr = 0.005
I0525 23:43:02.222328 20705 solver.cpp:237] Iteration 28050, loss = 1.17391
I0525 23:43:02.222388 20705 solver.cpp:253]     Train net output #0: loss = 1.17391 (* 1 = 1.17391 loss)
I0525 23:43:02.222406 20705 sgd_solver.cpp:106] Iteration 28050, lr = 0.005
I0525 23:43:10.961289 20705 solver.cpp:237] Iteration 28200, loss = 1.15668
I0525 23:43:10.961472 20705 solver.cpp:253]     Train net output #0: loss = 1.15668 (* 1 = 1.15668 loss)
I0525 23:43:10.961488 20705 sgd_solver.cpp:106] Iteration 28200, lr = 0.005
I0525 23:43:19.697635 20705 solver.cpp:237] Iteration 28350, loss = 1.20154
I0525 23:43:19.697671 20705 solver.cpp:253]     Train net output #0: loss = 1.20154 (* 1 = 1.20154 loss)
I0525 23:43:19.697690 20705 sgd_solver.cpp:106] Iteration 28350, lr = 0.005
I0525 23:43:28.377532 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_28500.caffemodel
I0525 23:43:28.458964 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_28500.solverstate
I0525 23:43:28.504954 20705 solver.cpp:237] Iteration 28500, loss = 1.26261
I0525 23:43:28.505012 20705 solver.cpp:253]     Train net output #0: loss = 1.26261 (* 1 = 1.26261 loss)
I0525 23:43:28.505030 20705 sgd_solver.cpp:106] Iteration 28500, lr = 0.005
I0525 23:43:37.246476 20705 solver.cpp:237] Iteration 28650, loss = 1.04496
I0525 23:43:37.246513 20705 solver.cpp:253]     Train net output #0: loss = 1.04496 (* 1 = 1.04496 loss)
I0525 23:43:37.246532 20705 sgd_solver.cpp:106] Iteration 28650, lr = 0.005
I0525 23:43:45.989908 20705 solver.cpp:237] Iteration 28800, loss = 1.5606
I0525 23:43:45.990082 20705 solver.cpp:253]     Train net output #0: loss = 1.5606 (* 1 = 1.5606 loss)
I0525 23:43:45.990098 20705 sgd_solver.cpp:106] Iteration 28800, lr = 0.005
I0525 23:43:54.732498 20705 solver.cpp:237] Iteration 28950, loss = 1.12323
I0525 23:43:54.732553 20705 solver.cpp:253]     Train net output #0: loss = 1.12323 (* 1 = 1.12323 loss)
I0525 23:43:54.732580 20705 sgd_solver.cpp:106] Iteration 28950, lr = 0.005
I0525 23:44:24.327332 20705 solver.cpp:237] Iteration 29100, loss = 1.23712
I0525 23:44:24.327515 20705 solver.cpp:253]     Train net output #0: loss = 1.23712 (* 1 = 1.23712 loss)
I0525 23:44:24.327535 20705 sgd_solver.cpp:106] Iteration 29100, lr = 0.005
I0525 23:44:33.067740 20705 solver.cpp:237] Iteration 29250, loss = 1.29862
I0525 23:44:33.067778 20705 solver.cpp:253]     Train net output #0: loss = 1.29862 (* 1 = 1.29862 loss)
I0525 23:44:33.067795 20705 sgd_solver.cpp:106] Iteration 29250, lr = 0.005
I0525 23:44:41.806668 20705 solver.cpp:237] Iteration 29400, loss = 1.13974
I0525 23:44:41.806704 20705 solver.cpp:253]     Train net output #0: loss = 1.13974 (* 1 = 1.13974 loss)
I0525 23:44:41.806721 20705 sgd_solver.cpp:106] Iteration 29400, lr = 0.005
I0525 23:44:50.545670 20705 solver.cpp:237] Iteration 29550, loss = 1.25916
I0525 23:44:50.545724 20705 solver.cpp:253]     Train net output #0: loss = 1.25916 (* 1 = 1.25916 loss)
I0525 23:44:50.545750 20705 sgd_solver.cpp:106] Iteration 29550, lr = 0.005
I0525 23:44:59.284569 20705 solver.cpp:237] Iteration 29700, loss = 1.19073
I0525 23:44:59.284737 20705 solver.cpp:253]     Train net output #0: loss = 1.19073 (* 1 = 1.19073 loss)
I0525 23:44:59.284754 20705 sgd_solver.cpp:106] Iteration 29700, lr = 0.005
I0525 23:45:08.022147 20705 solver.cpp:237] Iteration 29850, loss = 1.23034
I0525 23:45:08.022207 20705 solver.cpp:253]     Train net output #0: loss = 1.23034 (* 1 = 1.23034 loss)
I0525 23:45:08.022239 20705 sgd_solver.cpp:106] Iteration 29850, lr = 0.005
I0525 23:45:16.706526 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_30000.caffemodel
I0525 23:45:16.787690 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_30000.solverstate
I0525 23:45:16.815358 20705 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 23:46:24.598207 20705 solver.cpp:409]     Test net output #0: accuracy = 0.885588
I0525 23:46:24.598392 20705 solver.cpp:409]     Test net output #1: loss = 0.374615 (* 1 = 0.374615 loss)
I0525 23:46:45.463865 20705 solver.cpp:237] Iteration 30000, loss = 1.25261
I0525 23:46:45.463929 20705 solver.cpp:253]     Train net output #0: loss = 1.25261 (* 1 = 1.25261 loss)
I0525 23:46:45.463949 20705 sgd_solver.cpp:106] Iteration 30000, lr = 0.005
I0525 23:46:54.230036 20705 solver.cpp:237] Iteration 30150, loss = 1.15683
I0525 23:46:54.230092 20705 solver.cpp:253]     Train net output #0: loss = 1.15683 (* 1 = 1.15683 loss)
I0525 23:46:54.230108 20705 sgd_solver.cpp:106] Iteration 30150, lr = 0.005
I0525 23:47:02.972297 20705 solver.cpp:237] Iteration 30300, loss = 1.2696
I0525 23:47:02.972467 20705 solver.cpp:253]     Train net output #0: loss = 1.2696 (* 1 = 1.2696 loss)
I0525 23:47:02.972484 20705 sgd_solver.cpp:106] Iteration 30300, lr = 0.005
I0525 23:47:11.714239 20705 solver.cpp:237] Iteration 30450, loss = 1.0752
I0525 23:47:11.714278 20705 solver.cpp:253]     Train net output #0: loss = 1.0752 (* 1 = 1.0752 loss)
I0525 23:47:11.714295 20705 sgd_solver.cpp:106] Iteration 30450, lr = 0.005
I0525 23:47:20.463011 20705 solver.cpp:237] Iteration 30600, loss = 1.06494
I0525 23:47:20.463068 20705 solver.cpp:253]     Train net output #0: loss = 1.06494 (* 1 = 1.06494 loss)
I0525 23:47:20.463093 20705 sgd_solver.cpp:106] Iteration 30600, lr = 0.005
I0525 23:47:29.198361 20705 solver.cpp:237] Iteration 30750, loss = 1.09226
I0525 23:47:29.198398 20705 solver.cpp:253]     Train net output #0: loss = 1.09226 (* 1 = 1.09226 loss)
I0525 23:47:29.198416 20705 sgd_solver.cpp:106] Iteration 30750, lr = 0.005
I0525 23:47:37.945631 20705 solver.cpp:237] Iteration 30900, loss = 1.07936
I0525 23:47:37.945806 20705 solver.cpp:253]     Train net output #0: loss = 1.07936 (* 1 = 1.07936 loss)
I0525 23:47:37.945823 20705 sgd_solver.cpp:106] Iteration 30900, lr = 0.005
I0525 23:48:07.521201 20705 solver.cpp:237] Iteration 31050, loss = 1.28819
I0525 23:48:07.521262 20705 solver.cpp:253]     Train net output #0: loss = 1.28819 (* 1 = 1.28819 loss)
I0525 23:48:07.521287 20705 sgd_solver.cpp:106] Iteration 31050, lr = 0.005
I0525 23:48:16.264766 20705 solver.cpp:237] Iteration 31200, loss = 0.914961
I0525 23:48:16.264932 20705 solver.cpp:253]     Train net output #0: loss = 0.914961 (* 1 = 0.914961 loss)
I0525 23:48:16.264950 20705 sgd_solver.cpp:106] Iteration 31200, lr = 0.005
I0525 23:48:25.006448 20705 solver.cpp:237] Iteration 31350, loss = 1.35658
I0525 23:48:25.006485 20705 solver.cpp:253]     Train net output #0: loss = 1.35658 (* 1 = 1.35658 loss)
I0525 23:48:25.006502 20705 sgd_solver.cpp:106] Iteration 31350, lr = 0.005
I0525 23:48:33.688397 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_31500.caffemodel
I0525 23:48:33.767711 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_31500.solverstate
I0525 23:48:33.811105 20705 solver.cpp:237] Iteration 31500, loss = 0.990961
I0525 23:48:33.811163 20705 solver.cpp:253]     Train net output #0: loss = 0.990961 (* 1 = 0.990961 loss)
I0525 23:48:33.811189 20705 sgd_solver.cpp:106] Iteration 31500, lr = 0.005
I0525 23:48:42.553606 20705 solver.cpp:237] Iteration 31650, loss = 1.18154
I0525 23:48:42.553643 20705 solver.cpp:253]     Train net output #0: loss = 1.18154 (* 1 = 1.18154 loss)
I0525 23:48:42.553663 20705 sgd_solver.cpp:106] Iteration 31650, lr = 0.005
I0525 23:48:51.292984 20705 solver.cpp:237] Iteration 31800, loss = 1.17359
I0525 23:48:51.293165 20705 solver.cpp:253]     Train net output #0: loss = 1.17359 (* 1 = 1.17359 loss)
I0525 23:48:51.293182 20705 sgd_solver.cpp:106] Iteration 31800, lr = 0.005
I0525 23:49:00.030676 20705 solver.cpp:237] Iteration 31950, loss = 1.17375
I0525 23:49:00.030730 20705 solver.cpp:253]     Train net output #0: loss = 1.17375 (* 1 = 1.17375 loss)
I0525 23:49:00.030758 20705 sgd_solver.cpp:106] Iteration 31950, lr = 0.005
I0525 23:49:29.640681 20705 solver.cpp:237] Iteration 32100, loss = 1.24682
I0525 23:49:29.640858 20705 solver.cpp:253]     Train net output #0: loss = 1.24682 (* 1 = 1.24682 loss)
I0525 23:49:29.640875 20705 sgd_solver.cpp:106] Iteration 32100, lr = 0.005
I0525 23:49:38.381541 20705 solver.cpp:237] Iteration 32250, loss = 1.14749
I0525 23:49:38.381578 20705 solver.cpp:253]     Train net output #0: loss = 1.14749 (* 1 = 1.14749 loss)
I0525 23:49:38.381597 20705 sgd_solver.cpp:106] Iteration 32250, lr = 0.005
I0525 23:49:47.116228 20705 solver.cpp:237] Iteration 32400, loss = 1.30106
I0525 23:49:47.116287 20705 solver.cpp:253]     Train net output #0: loss = 1.30106 (* 1 = 1.30106 loss)
I0525 23:49:47.116312 20705 sgd_solver.cpp:106] Iteration 32400, lr = 0.005
I0525 23:49:55.856629 20705 solver.cpp:237] Iteration 32550, loss = 1.03964
I0525 23:49:55.856665 20705 solver.cpp:253]     Train net output #0: loss = 1.03964 (* 1 = 1.03964 loss)
I0525 23:49:55.856683 20705 sgd_solver.cpp:106] Iteration 32550, lr = 0.005
I0525 23:50:04.590034 20705 solver.cpp:237] Iteration 32700, loss = 1.1669
I0525 23:50:04.590196 20705 solver.cpp:253]     Train net output #0: loss = 1.1669 (* 1 = 1.1669 loss)
I0525 23:50:04.590212 20705 sgd_solver.cpp:106] Iteration 32700, lr = 0.005
I0525 23:50:13.326076 20705 solver.cpp:237] Iteration 32850, loss = 1.22684
I0525 23:50:13.326131 20705 solver.cpp:253]     Train net output #0: loss = 1.22684 (* 1 = 1.22684 loss)
I0525 23:50:13.326150 20705 sgd_solver.cpp:106] Iteration 32850, lr = 0.005
I0525 23:50:22.016436 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_33000.caffemodel
I0525 23:50:22.096170 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_33000.solverstate
I0525 23:50:22.122316 20705 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 23:51:08.665954 20705 solver.cpp:409]     Test net output #0: accuracy = 0.885301
I0525 23:51:08.666136 20705 solver.cpp:409]     Test net output #1: loss = 0.367288 (* 1 = 0.367288 loss)
I0525 23:51:29.534180 20705 solver.cpp:237] Iteration 33000, loss = 1.00765
I0525 23:51:29.534245 20705 solver.cpp:253]     Train net output #0: loss = 1.00765 (* 1 = 1.00765 loss)
I0525 23:51:29.534273 20705 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I0525 23:51:38.284868 20705 solver.cpp:237] Iteration 33150, loss = 1.12137
I0525 23:51:38.284904 20705 solver.cpp:253]     Train net output #0: loss = 1.12137 (* 1 = 1.12137 loss)
I0525 23:51:38.284924 20705 sgd_solver.cpp:106] Iteration 33150, lr = 0.005
I0525 23:51:47.030798 20705 solver.cpp:237] Iteration 33300, loss = 1.22301
I0525 23:51:47.030982 20705 solver.cpp:253]     Train net output #0: loss = 1.22301 (* 1 = 1.22301 loss)
I0525 23:51:47.030998 20705 sgd_solver.cpp:106] Iteration 33300, lr = 0.005
I0525 23:51:55.780951 20705 solver.cpp:237] Iteration 33450, loss = 1.17024
I0525 23:51:55.781007 20705 solver.cpp:253]     Train net output #0: loss = 1.17024 (* 1 = 1.17024 loss)
I0525 23:51:55.781030 20705 sgd_solver.cpp:106] Iteration 33450, lr = 0.005
I0525 23:52:04.528327 20705 solver.cpp:237] Iteration 33600, loss = 1.01005
I0525 23:52:04.528368 20705 solver.cpp:253]     Train net output #0: loss = 1.01005 (* 1 = 1.01005 loss)
I0525 23:52:04.528388 20705 sgd_solver.cpp:106] Iteration 33600, lr = 0.005
I0525 23:52:13.276834 20705 solver.cpp:237] Iteration 33750, loss = 1.24217
I0525 23:52:13.276895 20705 solver.cpp:253]     Train net output #0: loss = 1.24217 (* 1 = 1.24217 loss)
I0525 23:52:13.276914 20705 sgd_solver.cpp:106] Iteration 33750, lr = 0.005
I0525 23:52:22.030324 20705 solver.cpp:237] Iteration 33900, loss = 1.12525
I0525 23:52:22.030490 20705 solver.cpp:253]     Train net output #0: loss = 1.12525 (* 1 = 1.12525 loss)
I0525 23:52:22.030506 20705 sgd_solver.cpp:106] Iteration 33900, lr = 0.005
I0525 23:52:51.632891 20705 solver.cpp:237] Iteration 34050, loss = 1.12399
I0525 23:52:51.632951 20705 solver.cpp:253]     Train net output #0: loss = 1.12399 (* 1 = 1.12399 loss)
I0525 23:52:51.632971 20705 sgd_solver.cpp:106] Iteration 34050, lr = 0.005
I0525 23:53:00.378093 20705 solver.cpp:237] Iteration 34200, loss = 1.21054
I0525 23:53:00.378257 20705 solver.cpp:253]     Train net output #0: loss = 1.21054 (* 1 = 1.21054 loss)
I0525 23:53:00.378274 20705 sgd_solver.cpp:106] Iteration 34200, lr = 0.005
I0525 23:53:09.128051 20705 solver.cpp:237] Iteration 34350, loss = 1.05329
I0525 23:53:09.128108 20705 solver.cpp:253]     Train net output #0: loss = 1.05329 (* 1 = 1.05329 loss)
I0525 23:53:09.128128 20705 sgd_solver.cpp:106] Iteration 34350, lr = 0.005
I0525 23:53:17.817570 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_34500.caffemodel
I0525 23:53:17.896328 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_34500.solverstate
I0525 23:53:17.940274 20705 solver.cpp:237] Iteration 34500, loss = 1.14052
I0525 23:53:17.940331 20705 solver.cpp:253]     Train net output #0: loss = 1.14052 (* 1 = 1.14052 loss)
I0525 23:53:17.940356 20705 sgd_solver.cpp:106] Iteration 34500, lr = 0.005
I0525 23:53:26.690304 20705 solver.cpp:237] Iteration 34650, loss = 1.13089
I0525 23:53:26.690340 20705 solver.cpp:253]     Train net output #0: loss = 1.13089 (* 1 = 1.13089 loss)
I0525 23:53:26.690364 20705 sgd_solver.cpp:106] Iteration 34650, lr = 0.005
I0525 23:53:35.439513 20705 solver.cpp:237] Iteration 34800, loss = 1.21923
I0525 23:53:35.439693 20705 solver.cpp:253]     Train net output #0: loss = 1.21923 (* 1 = 1.21923 loss)
I0525 23:53:35.439712 20705 sgd_solver.cpp:106] Iteration 34800, lr = 0.005
I0525 23:53:44.190538 20705 solver.cpp:237] Iteration 34950, loss = 0.96503
I0525 23:53:44.190577 20705 solver.cpp:253]     Train net output #0: loss = 0.96503 (* 1 = 0.96503 loss)
I0525 23:53:44.190594 20705 sgd_solver.cpp:106] Iteration 34950, lr = 0.005
I0525 23:54:13.773432 20705 solver.cpp:237] Iteration 35100, loss = 1.09814
I0525 23:54:13.773619 20705 solver.cpp:253]     Train net output #0: loss = 1.09814 (* 1 = 1.09814 loss)
I0525 23:54:13.773638 20705 sgd_solver.cpp:106] Iteration 35100, lr = 0.005
I0525 23:54:22.521364 20705 solver.cpp:237] Iteration 35250, loss = 0.953378
I0525 23:54:22.521417 20705 solver.cpp:253]     Train net output #0: loss = 0.953378 (* 1 = 0.953378 loss)
I0525 23:54:22.521437 20705 sgd_solver.cpp:106] Iteration 35250, lr = 0.005
I0525 23:54:31.269767 20705 solver.cpp:237] Iteration 35400, loss = 1.22851
I0525 23:54:31.269807 20705 solver.cpp:253]     Train net output #0: loss = 1.22851 (* 1 = 1.22851 loss)
I0525 23:54:31.269824 20705 sgd_solver.cpp:106] Iteration 35400, lr = 0.005
I0525 23:54:40.018852 20705 solver.cpp:237] Iteration 35550, loss = 1.20199
I0525 23:54:40.018889 20705 solver.cpp:253]     Train net output #0: loss = 1.20199 (* 1 = 1.20199 loss)
I0525 23:54:40.018908 20705 sgd_solver.cpp:106] Iteration 35550, lr = 0.005
I0525 23:54:48.767740 20705 solver.cpp:237] Iteration 35700, loss = 1.18458
I0525 23:54:48.767943 20705 solver.cpp:253]     Train net output #0: loss = 1.18458 (* 1 = 1.18458 loss)
I0525 23:54:48.767961 20705 sgd_solver.cpp:106] Iteration 35700, lr = 0.005
I0525 23:54:57.517529 20705 solver.cpp:237] Iteration 35850, loss = 1.06758
I0525 23:54:57.517565 20705 solver.cpp:253]     Train net output #0: loss = 1.06758 (* 1 = 1.06758 loss)
I0525 23:54:57.517583 20705 sgd_solver.cpp:106] Iteration 35850, lr = 0.005
I0525 23:55:06.206907 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_36000.caffemodel
I0525 23:55:06.285818 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_36000.solverstate
I0525 23:55:06.311622 20705 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 23:56:14.020159 20705 solver.cpp:409]     Test net output #0: accuracy = 0.887715
I0525 23:56:14.020366 20705 solver.cpp:409]     Test net output #1: loss = 0.368239 (* 1 = 0.368239 loss)
I0525 23:56:34.823951 20705 solver.cpp:237] Iteration 36000, loss = 1.16669
I0525 23:56:34.824019 20705 solver.cpp:253]     Train net output #0: loss = 1.16669 (* 1 = 1.16669 loss)
I0525 23:56:34.824039 20705 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I0525 23:56:43.563355 20705 solver.cpp:237] Iteration 36150, loss = 1.11805
I0525 23:56:43.563392 20705 solver.cpp:253]     Train net output #0: loss = 1.11805 (* 1 = 1.11805 loss)
I0525 23:56:43.563411 20705 sgd_solver.cpp:106] Iteration 36150, lr = 0.005
I0525 23:56:52.308745 20705 solver.cpp:237] Iteration 36300, loss = 1.0334
I0525 23:56:52.308933 20705 solver.cpp:253]     Train net output #0: loss = 1.0334 (* 1 = 1.0334 loss)
I0525 23:56:52.308951 20705 sgd_solver.cpp:106] Iteration 36300, lr = 0.005
I0525 23:57:01.048238 20705 solver.cpp:237] Iteration 36450, loss = 1.3674
I0525 23:57:01.048275 20705 solver.cpp:253]     Train net output #0: loss = 1.3674 (* 1 = 1.3674 loss)
I0525 23:57:01.048295 20705 sgd_solver.cpp:106] Iteration 36450, lr = 0.005
I0525 23:57:09.789772 20705 solver.cpp:237] Iteration 36600, loss = 1.30682
I0525 23:57:09.789808 20705 solver.cpp:253]     Train net output #0: loss = 1.30682 (* 1 = 1.30682 loss)
I0525 23:57:09.789827 20705 sgd_solver.cpp:106] Iteration 36600, lr = 0.005
I0525 23:57:18.538944 20705 solver.cpp:237] Iteration 36750, loss = 1.20773
I0525 23:57:18.538997 20705 solver.cpp:253]     Train net output #0: loss = 1.20773 (* 1 = 1.20773 loss)
I0525 23:57:18.539024 20705 sgd_solver.cpp:106] Iteration 36750, lr = 0.005
I0525 23:57:27.285747 20705 solver.cpp:237] Iteration 36900, loss = 1.21083
I0525 23:57:27.285909 20705 solver.cpp:253]     Train net output #0: loss = 1.21083 (* 1 = 1.21083 loss)
I0525 23:57:27.285926 20705 sgd_solver.cpp:106] Iteration 36900, lr = 0.005
I0525 23:57:56.841248 20705 solver.cpp:237] Iteration 37050, loss = 1.09574
I0525 23:57:56.841307 20705 solver.cpp:253]     Train net output #0: loss = 1.09574 (* 1 = 1.09574 loss)
I0525 23:57:56.841326 20705 sgd_solver.cpp:106] Iteration 37050, lr = 0.005
I0525 23:58:05.587077 20705 solver.cpp:237] Iteration 37200, loss = 1.0847
I0525 23:58:05.587263 20705 solver.cpp:253]     Train net output #0: loss = 1.0847 (* 1 = 1.0847 loss)
I0525 23:58:05.587280 20705 sgd_solver.cpp:106] Iteration 37200, lr = 0.005
I0525 23:58:14.315274 20705 solver.cpp:237] Iteration 37350, loss = 1.23632
I0525 23:58:14.315311 20705 solver.cpp:253]     Train net output #0: loss = 1.23632 (* 1 = 1.23632 loss)
I0525 23:58:14.315330 20705 sgd_solver.cpp:106] Iteration 37350, lr = 0.005
I0525 23:58:22.990130 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_37500.caffemodel
I0525 23:58:23.071368 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_37500.solverstate
I0525 23:58:23.117424 20705 solver.cpp:237] Iteration 37500, loss = 1.03702
I0525 23:58:23.117482 20705 solver.cpp:253]     Train net output #0: loss = 1.03702 (* 1 = 1.03702 loss)
I0525 23:58:23.117511 20705 sgd_solver.cpp:106] Iteration 37500, lr = 0.005
I0525 23:58:31.858502 20705 solver.cpp:237] Iteration 37650, loss = 1.27173
I0525 23:58:31.858553 20705 solver.cpp:253]     Train net output #0: loss = 1.27173 (* 1 = 1.27173 loss)
I0525 23:58:31.858578 20705 sgd_solver.cpp:106] Iteration 37650, lr = 0.005
I0525 23:58:40.595495 20705 solver.cpp:237] Iteration 37800, loss = 1.08256
I0525 23:58:40.595674 20705 solver.cpp:253]     Train net output #0: loss = 1.08256 (* 1 = 1.08256 loss)
I0525 23:58:40.595690 20705 sgd_solver.cpp:106] Iteration 37800, lr = 0.005
I0525 23:58:49.335274 20705 solver.cpp:237] Iteration 37950, loss = 1.13391
I0525 23:58:49.335310 20705 solver.cpp:253]     Train net output #0: loss = 1.13391 (* 1 = 1.13391 loss)
I0525 23:58:49.335330 20705 sgd_solver.cpp:106] Iteration 37950, lr = 0.005
I0525 23:59:18.887053 20705 solver.cpp:237] Iteration 38100, loss = 1.01813
I0525 23:59:18.887243 20705 solver.cpp:253]     Train net output #0: loss = 1.01813 (* 1 = 1.01813 loss)
I0525 23:59:18.887260 20705 sgd_solver.cpp:106] Iteration 38100, lr = 0.005
I0525 23:59:27.626549 20705 solver.cpp:237] Iteration 38250, loss = 1.25886
I0525 23:59:27.626586 20705 solver.cpp:253]     Train net output #0: loss = 1.25886 (* 1 = 1.25886 loss)
I0525 23:59:27.626610 20705 sgd_solver.cpp:106] Iteration 38250, lr = 0.005
I0525 23:59:36.358485 20705 solver.cpp:237] Iteration 38400, loss = 1.26985
I0525 23:59:36.358523 20705 solver.cpp:253]     Train net output #0: loss = 1.26985 (* 1 = 1.26985 loss)
I0525 23:59:36.358541 20705 sgd_solver.cpp:106] Iteration 38400, lr = 0.005
I0525 23:59:45.095216 20705 solver.cpp:237] Iteration 38550, loss = 1.4187
I0525 23:59:45.095269 20705 solver.cpp:253]     Train net output #0: loss = 1.4187 (* 1 = 1.4187 loss)
I0525 23:59:45.095298 20705 sgd_solver.cpp:106] Iteration 38550, lr = 0.005
I0525 23:59:53.835810 20705 solver.cpp:237] Iteration 38700, loss = 1.33541
I0525 23:59:53.835975 20705 solver.cpp:253]     Train net output #0: loss = 1.33541 (* 1 = 1.33541 loss)
I0525 23:59:53.835993 20705 sgd_solver.cpp:106] Iteration 38700, lr = 0.005
I0526 00:00:02.574604 20705 solver.cpp:237] Iteration 38850, loss = 1.02315
I0526 00:00:02.574642 20705 solver.cpp:253]     Train net output #0: loss = 1.02315 (* 1 = 1.02315 loss)
I0526 00:00:02.574659 20705 sgd_solver.cpp:106] Iteration 38850, lr = 0.005
I0526 00:00:11.257068 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_39000.caffemodel
I0526 00:00:11.336488 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_39000.solverstate
I0526 00:00:11.362851 20705 solver.cpp:341] Iteration 39000, Testing net (#0)
I0526 00:00:58.187230 20705 solver.cpp:409]     Test net output #0: accuracy = 0.891401
I0526 00:00:58.187418 20705 solver.cpp:409]     Test net output #1: loss = 0.352136 (* 1 = 0.352136 loss)
I0526 00:01:18.993124 20705 solver.cpp:237] Iteration 39000, loss = 1.10243
I0526 00:01:18.993187 20705 solver.cpp:253]     Train net output #0: loss = 1.10243 (* 1 = 1.10243 loss)
I0526 00:01:18.993207 20705 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I0526 00:01:27.722599 20705 solver.cpp:237] Iteration 39150, loss = 1.0937
I0526 00:01:27.722654 20705 solver.cpp:253]     Train net output #0: loss = 1.0937 (* 1 = 1.0937 loss)
I0526 00:01:27.722673 20705 sgd_solver.cpp:106] Iteration 39150, lr = 0.005
I0526 00:01:36.449990 20705 solver.cpp:237] Iteration 39300, loss = 1.21887
I0526 00:01:36.450170 20705 solver.cpp:253]     Train net output #0: loss = 1.21887 (* 1 = 1.21887 loss)
I0526 00:01:36.450186 20705 sgd_solver.cpp:106] Iteration 39300, lr = 0.005
I0526 00:01:45.180210 20705 solver.cpp:237] Iteration 39450, loss = 0.974246
I0526 00:01:45.180248 20705 solver.cpp:253]     Train net output #0: loss = 0.974246 (* 1 = 0.974246 loss)
I0526 00:01:45.180265 20705 sgd_solver.cpp:106] Iteration 39450, lr = 0.005
I0526 00:01:53.904412 20705 solver.cpp:237] Iteration 39600, loss = 1.30403
I0526 00:01:53.904466 20705 solver.cpp:253]     Train net output #0: loss = 1.30403 (* 1 = 1.30403 loss)
I0526 00:01:53.904491 20705 sgd_solver.cpp:106] Iteration 39600, lr = 0.005
I0526 00:02:02.639250 20705 solver.cpp:237] Iteration 39750, loss = 1.16094
I0526 00:02:02.639287 20705 solver.cpp:253]     Train net output #0: loss = 1.16094 (* 1 = 1.16094 loss)
I0526 00:02:02.639305 20705 sgd_solver.cpp:106] Iteration 39750, lr = 0.005
I0526 00:02:11.372526 20705 solver.cpp:237] Iteration 39900, loss = 1.1588
I0526 00:02:11.372689 20705 solver.cpp:253]     Train net output #0: loss = 1.1588 (* 1 = 1.1588 loss)
I0526 00:02:11.372706 20705 sgd_solver.cpp:106] Iteration 39900, lr = 0.005
I0526 00:02:40.884177 20705 solver.cpp:237] Iteration 40050, loss = 1.21556
I0526 00:02:40.884234 20705 solver.cpp:253]     Train net output #0: loss = 1.21556 (* 1 = 1.21556 loss)
I0526 00:02:40.884253 20705 sgd_solver.cpp:106] Iteration 40050, lr = 0.005
I0526 00:02:49.615972 20705 solver.cpp:237] Iteration 40200, loss = 1.1234
I0526 00:02:49.616152 20705 solver.cpp:253]     Train net output #0: loss = 1.1234 (* 1 = 1.1234 loss)
I0526 00:02:49.616168 20705 sgd_solver.cpp:106] Iteration 40200, lr = 0.005
I0526 00:02:58.348084 20705 solver.cpp:237] Iteration 40350, loss = 1.25489
I0526 00:02:58.348119 20705 solver.cpp:253]     Train net output #0: loss = 1.25489 (* 1 = 1.25489 loss)
I0526 00:02:58.348137 20705 sgd_solver.cpp:106] Iteration 40350, lr = 0.005
I0526 00:03:07.025722 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_40500.caffemodel
I0526 00:03:07.105067 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_40500.solverstate
I0526 00:03:07.148948 20705 solver.cpp:237] Iteration 40500, loss = 1.23128
I0526 00:03:07.149004 20705 solver.cpp:253]     Train net output #0: loss = 1.23128 (* 1 = 1.23128 loss)
I0526 00:03:07.149021 20705 sgd_solver.cpp:106] Iteration 40500, lr = 0.005
I0526 00:03:15.880977 20705 solver.cpp:237] Iteration 40650, loss = 1.05717
I0526 00:03:15.881016 20705 solver.cpp:253]     Train net output #0: loss = 1.05717 (* 1 = 1.05717 loss)
I0526 00:03:15.881033 20705 sgd_solver.cpp:106] Iteration 40650, lr = 0.005
I0526 00:03:24.614666 20705 solver.cpp:237] Iteration 40800, loss = 1.08561
I0526 00:03:24.614835 20705 solver.cpp:253]     Train net output #0: loss = 1.08561 (* 1 = 1.08561 loss)
I0526 00:03:24.614851 20705 sgd_solver.cpp:106] Iteration 40800, lr = 0.005
I0526 00:03:33.349169 20705 solver.cpp:237] Iteration 40950, loss = 1.20756
I0526 00:03:33.349223 20705 solver.cpp:253]     Train net output #0: loss = 1.20756 (* 1 = 1.20756 loss)
I0526 00:03:33.349251 20705 sgd_solver.cpp:106] Iteration 40950, lr = 0.005
I0526 00:04:02.868564 20705 solver.cpp:237] Iteration 41100, loss = 1.16773
I0526 00:04:02.868764 20705 solver.cpp:253]     Train net output #0: loss = 1.16773 (* 1 = 1.16773 loss)
I0526 00:04:02.868782 20705 sgd_solver.cpp:106] Iteration 41100, lr = 0.005
I0526 00:04:11.598781 20705 solver.cpp:237] Iteration 41250, loss = 1.12636
I0526 00:04:11.598817 20705 solver.cpp:253]     Train net output #0: loss = 1.12636 (* 1 = 1.12636 loss)
I0526 00:04:11.598841 20705 sgd_solver.cpp:106] Iteration 41250, lr = 0.005
I0526 00:04:20.329648 20705 solver.cpp:237] Iteration 41400, loss = 1.00766
I0526 00:04:20.329707 20705 solver.cpp:253]     Train net output #0: loss = 1.00766 (* 1 = 1.00766 loss)
I0526 00:04:20.329731 20705 sgd_solver.cpp:106] Iteration 41400, lr = 0.005
I0526 00:04:29.060860 20705 solver.cpp:237] Iteration 41550, loss = 1.24929
I0526 00:04:29.060896 20705 solver.cpp:253]     Train net output #0: loss = 1.24929 (* 1 = 1.24929 loss)
I0526 00:04:29.060915 20705 sgd_solver.cpp:106] Iteration 41550, lr = 0.005
I0526 00:04:37.790915 20705 solver.cpp:237] Iteration 41700, loss = 0.981313
I0526 00:04:37.791093 20705 solver.cpp:253]     Train net output #0: loss = 0.981313 (* 1 = 0.981313 loss)
I0526 00:04:37.791110 20705 sgd_solver.cpp:106] Iteration 41700, lr = 0.005
I0526 00:04:46.521247 20705 solver.cpp:237] Iteration 41850, loss = 1.11812
I0526 00:04:46.521302 20705 solver.cpp:253]     Train net output #0: loss = 1.11812 (* 1 = 1.11812 loss)
I0526 00:04:46.521329 20705 sgd_solver.cpp:106] Iteration 41850, lr = 0.005
I0526 00:04:55.195050 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_42000.caffemodel
I0526 00:04:55.274197 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_42000.solverstate
I0526 00:04:55.299912 20705 solver.cpp:341] Iteration 42000, Testing net (#0)
I0526 00:06:02.945559 20705 solver.cpp:409]     Test net output #0: accuracy = 0.894069
I0526 00:06:02.945757 20705 solver.cpp:409]     Test net output #1: loss = 0.355048 (* 1 = 0.355048 loss)
I0526 00:06:23.763634 20705 solver.cpp:237] Iteration 42000, loss = 1.02257
I0526 00:06:23.763697 20705 solver.cpp:253]     Train net output #0: loss = 1.02257 (* 1 = 1.02257 loss)
I0526 00:06:23.763727 20705 sgd_solver.cpp:106] Iteration 42000, lr = 0.005
I0526 00:06:32.522965 20705 solver.cpp:237] Iteration 42150, loss = 1.20161
I0526 00:06:32.523001 20705 solver.cpp:253]     Train net output #0: loss = 1.20161 (* 1 = 1.20161 loss)
I0526 00:06:32.523025 20705 sgd_solver.cpp:106] Iteration 42150, lr = 0.005
I0526 00:06:41.275327 20705 solver.cpp:237] Iteration 42300, loss = 1.0835
I0526 00:06:41.275507 20705 solver.cpp:253]     Train net output #0: loss = 1.0835 (* 1 = 1.0835 loss)
I0526 00:06:41.275524 20705 sgd_solver.cpp:106] Iteration 42300, lr = 0.005
I0526 00:06:50.039516 20705 solver.cpp:237] Iteration 42450, loss = 1.31878
I0526 00:06:50.039573 20705 solver.cpp:253]     Train net output #0: loss = 1.31878 (* 1 = 1.31878 loss)
I0526 00:06:50.039597 20705 sgd_solver.cpp:106] Iteration 42450, lr = 0.005
I0526 00:06:58.798177 20705 solver.cpp:237] Iteration 42600, loss = 1.30363
I0526 00:06:58.798213 20705 solver.cpp:253]     Train net output #0: loss = 1.30363 (* 1 = 1.30363 loss)
I0526 00:06:58.798231 20705 sgd_solver.cpp:106] Iteration 42600, lr = 0.005
I0526 00:07:07.554517 20705 solver.cpp:237] Iteration 42750, loss = 1.0556
I0526 00:07:07.554553 20705 solver.cpp:253]     Train net output #0: loss = 1.0556 (* 1 = 1.0556 loss)
I0526 00:07:07.554571 20705 sgd_solver.cpp:106] Iteration 42750, lr = 0.005
I0526 00:07:16.312590 20705 solver.cpp:237] Iteration 42900, loss = 0.960297
I0526 00:07:16.312772 20705 solver.cpp:253]     Train net output #0: loss = 0.960297 (* 1 = 0.960297 loss)
I0526 00:07:16.312789 20705 sgd_solver.cpp:106] Iteration 42900, lr = 0.005
I0526 00:07:45.864639 20705 solver.cpp:237] Iteration 43050, loss = 1.07436
I0526 00:07:45.864697 20705 solver.cpp:253]     Train net output #0: loss = 1.07436 (* 1 = 1.07436 loss)
I0526 00:07:45.864717 20705 sgd_solver.cpp:106] Iteration 43050, lr = 0.005
I0526 00:07:54.626443 20705 solver.cpp:237] Iteration 43200, loss = 1.27084
I0526 00:07:54.626636 20705 solver.cpp:253]     Train net output #0: loss = 1.27084 (* 1 = 1.27084 loss)
I0526 00:07:54.626653 20705 sgd_solver.cpp:106] Iteration 43200, lr = 0.005
I0526 00:08:03.380805 20705 solver.cpp:237] Iteration 43350, loss = 1.34761
I0526 00:08:03.380858 20705 solver.cpp:253]     Train net output #0: loss = 1.34761 (* 1 = 1.34761 loss)
I0526 00:08:03.380884 20705 sgd_solver.cpp:106] Iteration 43350, lr = 0.005
I0526 00:08:12.078289 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_43500.caffemodel
I0526 00:08:12.158771 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_43500.solverstate
I0526 00:08:12.204630 20705 solver.cpp:237] Iteration 43500, loss = 1.32498
I0526 00:08:12.204687 20705 solver.cpp:253]     Train net output #0: loss = 1.32498 (* 1 = 1.32498 loss)
I0526 00:08:12.204704 20705 sgd_solver.cpp:106] Iteration 43500, lr = 0.005
I0526 00:08:20.960953 20705 solver.cpp:237] Iteration 43650, loss = 1.23209
I0526 00:08:20.960989 20705 solver.cpp:253]     Train net output #0: loss = 1.23209 (* 1 = 1.23209 loss)
I0526 00:08:20.961014 20705 sgd_solver.cpp:106] Iteration 43650, lr = 0.005
I0526 00:08:29.713848 20705 solver.cpp:237] Iteration 43800, loss = 1.3492
I0526 00:08:29.714051 20705 solver.cpp:253]     Train net output #0: loss = 1.3492 (* 1 = 1.3492 loss)
I0526 00:08:29.714067 20705 sgd_solver.cpp:106] Iteration 43800, lr = 0.005
I0526 00:08:38.438563 20705 solver.cpp:237] Iteration 43950, loss = 0.991812
I0526 00:08:38.438601 20705 solver.cpp:253]     Train net output #0: loss = 0.991812 (* 1 = 0.991812 loss)
I0526 00:08:38.438618 20705 sgd_solver.cpp:106] Iteration 43950, lr = 0.005
I0526 00:09:08.006955 20705 solver.cpp:237] Iteration 44100, loss = 1.16736
I0526 00:09:08.007148 20705 solver.cpp:253]     Train net output #0: loss = 1.16736 (* 1 = 1.16736 loss)
I0526 00:09:08.007166 20705 sgd_solver.cpp:106] Iteration 44100, lr = 0.005
I0526 00:09:16.737727 20705 solver.cpp:237] Iteration 44250, loss = 1.1099
I0526 00:09:16.737764 20705 solver.cpp:253]     Train net output #0: loss = 1.1099 (* 1 = 1.1099 loss)
I0526 00:09:16.737783 20705 sgd_solver.cpp:106] Iteration 44250, lr = 0.005
I0526 00:09:25.495015 20705 solver.cpp:237] Iteration 44400, loss = 1.12973
I0526 00:09:25.495074 20705 solver.cpp:253]     Train net output #0: loss = 1.12973 (* 1 = 1.12973 loss)
I0526 00:09:25.495100 20705 sgd_solver.cpp:106] Iteration 44400, lr = 0.005
I0526 00:09:34.224119 20705 solver.cpp:237] Iteration 44550, loss = 1.09492
I0526 00:09:34.224156 20705 solver.cpp:253]     Train net output #0: loss = 1.09492 (* 1 = 1.09492 loss)
I0526 00:09:34.224175 20705 sgd_solver.cpp:106] Iteration 44550, lr = 0.005
I0526 00:09:42.952852 20705 solver.cpp:237] Iteration 44700, loss = 1.05961
I0526 00:09:42.953035 20705 solver.cpp:253]     Train net output #0: loss = 1.05961 (* 1 = 1.05961 loss)
I0526 00:09:42.953053 20705 sgd_solver.cpp:106] Iteration 44700, lr = 0.005
I0526 00:09:51.681078 20705 solver.cpp:237] Iteration 44850, loss = 1.23066
I0526 00:09:51.681115 20705 solver.cpp:253]     Train net output #0: loss = 1.23066 (* 1 = 1.23066 loss)
I0526 00:09:51.681134 20705 sgd_solver.cpp:106] Iteration 44850, lr = 0.005
I0526 00:10:00.351624 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_45000.caffemodel
I0526 00:10:00.432299 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_45000.solverstate
I0526 00:10:00.460098 20705 solver.cpp:341] Iteration 45000, Testing net (#0)
I0526 00:10:47.001979 20705 solver.cpp:409]     Test net output #0: accuracy = 0.890902
I0526 00:10:47.002179 20705 solver.cpp:409]     Test net output #1: loss = 0.355926 (* 1 = 0.355926 loss)
I0526 00:11:07.845583 20705 solver.cpp:237] Iteration 45000, loss = 1.09747
I0526 00:11:07.845645 20705 solver.cpp:253]     Train net output #0: loss = 1.09747 (* 1 = 1.09747 loss)
I0526 00:11:07.845665 20705 sgd_solver.cpp:106] Iteration 45000, lr = 0.005
I0526 00:11:16.575410 20705 solver.cpp:237] Iteration 45150, loss = 0.964828
I0526 00:11:16.575448 20705 solver.cpp:253]     Train net output #0: loss = 0.964828 (* 1 = 0.964828 loss)
I0526 00:11:16.575466 20705 sgd_solver.cpp:106] Iteration 45150, lr = 0.005
I0526 00:11:25.305770 20705 solver.cpp:237] Iteration 45300, loss = 1.06539
I0526 00:11:25.305958 20705 solver.cpp:253]     Train net output #0: loss = 1.06539 (* 1 = 1.06539 loss)
I0526 00:11:25.305974 20705 sgd_solver.cpp:106] Iteration 45300, lr = 0.005
I0526 00:11:34.034674 20705 solver.cpp:237] Iteration 45450, loss = 1.12156
I0526 00:11:34.034713 20705 solver.cpp:253]     Train net output #0: loss = 1.12156 (* 1 = 1.12156 loss)
I0526 00:11:34.034730 20705 sgd_solver.cpp:106] Iteration 45450, lr = 0.005
I0526 00:11:42.769182 20705 solver.cpp:237] Iteration 45600, loss = 1.08125
I0526 00:11:42.769218 20705 solver.cpp:253]     Train net output #0: loss = 1.08125 (* 1 = 1.08125 loss)
I0526 00:11:42.769237 20705 sgd_solver.cpp:106] Iteration 45600, lr = 0.005
I0526 00:11:51.503548 20705 solver.cpp:237] Iteration 45750, loss = 0.934567
I0526 00:11:51.503605 20705 solver.cpp:253]     Train net output #0: loss = 0.934567 (* 1 = 0.934567 loss)
I0526 00:11:51.503630 20705 sgd_solver.cpp:106] Iteration 45750, lr = 0.005
I0526 00:12:00.235251 20705 solver.cpp:237] Iteration 45900, loss = 1.32329
I0526 00:12:00.235420 20705 solver.cpp:253]     Train net output #0: loss = 1.32329 (* 1 = 1.32329 loss)
I0526 00:12:00.235437 20705 sgd_solver.cpp:106] Iteration 45900, lr = 0.005
I0526 00:12:29.753690 20705 solver.cpp:237] Iteration 46050, loss = 1.29315
I0526 00:12:29.753749 20705 solver.cpp:253]     Train net output #0: loss = 1.29315 (* 1 = 1.29315 loss)
I0526 00:12:29.753773 20705 sgd_solver.cpp:106] Iteration 46050, lr = 0.005
I0526 00:12:38.487881 20705 solver.cpp:237] Iteration 46200, loss = 0.965841
I0526 00:12:38.488071 20705 solver.cpp:253]     Train net output #0: loss = 0.965841 (* 1 = 0.965841 loss)
I0526 00:12:38.488088 20705 sgd_solver.cpp:106] Iteration 46200, lr = 0.005
I0526 00:12:47.216709 20705 solver.cpp:237] Iteration 46350, loss = 1.44168
I0526 00:12:47.216747 20705 solver.cpp:253]     Train net output #0: loss = 1.44168 (* 1 = 1.44168 loss)
I0526 00:12:47.216764 20705 sgd_solver.cpp:106] Iteration 46350, lr = 0.005
I0526 00:12:55.888731 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_46500.caffemodel
I0526 00:12:55.967488 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_46500.solverstate
I0526 00:12:56.011140 20705 solver.cpp:237] Iteration 46500, loss = 0.988793
I0526 00:12:56.011198 20705 solver.cpp:253]     Train net output #0: loss = 0.988793 (* 1 = 0.988793 loss)
I0526 00:12:56.011217 20705 sgd_solver.cpp:106] Iteration 46500, lr = 0.005
I0526 00:13:04.748154 20705 solver.cpp:237] Iteration 46650, loss = 1.21147
I0526 00:13:04.748209 20705 solver.cpp:253]     Train net output #0: loss = 1.21147 (* 1 = 1.21147 loss)
I0526 00:13:04.748226 20705 sgd_solver.cpp:106] Iteration 46650, lr = 0.005
I0526 00:13:13.477120 20705 solver.cpp:237] Iteration 46800, loss = 1.03594
I0526 00:13:13.477293 20705 solver.cpp:253]     Train net output #0: loss = 1.03594 (* 1 = 1.03594 loss)
I0526 00:13:13.477309 20705 sgd_solver.cpp:106] Iteration 46800, lr = 0.005
I0526 00:13:22.211748 20705 solver.cpp:237] Iteration 46950, loss = 1.23139
I0526 00:13:22.211784 20705 solver.cpp:253]     Train net output #0: loss = 1.23139 (* 1 = 1.23139 loss)
I0526 00:13:22.211802 20705 sgd_solver.cpp:106] Iteration 46950, lr = 0.005
I0526 00:13:51.778848 20705 solver.cpp:237] Iteration 47100, loss = 1.14643
I0526 00:13:51.779050 20705 solver.cpp:253]     Train net output #0: loss = 1.14643 (* 1 = 1.14643 loss)
I0526 00:13:51.779067 20705 sgd_solver.cpp:106] Iteration 47100, lr = 0.005
I0526 00:14:00.507910 20705 solver.cpp:237] Iteration 47250, loss = 1.29172
I0526 00:14:00.507966 20705 solver.cpp:253]     Train net output #0: loss = 1.29172 (* 1 = 1.29172 loss)
I0526 00:14:00.507992 20705 sgd_solver.cpp:106] Iteration 47250, lr = 0.005
I0526 00:14:09.240104 20705 solver.cpp:237] Iteration 47400, loss = 1.28984
I0526 00:14:09.240141 20705 solver.cpp:253]     Train net output #0: loss = 1.28984 (* 1 = 1.28984 loss)
I0526 00:14:09.240160 20705 sgd_solver.cpp:106] Iteration 47400, lr = 0.005
I0526 00:14:17.970685 20705 solver.cpp:237] Iteration 47550, loss = 1.00679
I0526 00:14:17.970743 20705 solver.cpp:253]     Train net output #0: loss = 1.00679 (* 1 = 1.00679 loss)
I0526 00:14:17.970768 20705 sgd_solver.cpp:106] Iteration 47550, lr = 0.005
I0526 00:14:26.700613 20705 solver.cpp:237] Iteration 47700, loss = 1.1487
I0526 00:14:26.700786 20705 solver.cpp:253]     Train net output #0: loss = 1.1487 (* 1 = 1.1487 loss)
I0526 00:14:26.700803 20705 sgd_solver.cpp:106] Iteration 47700, lr = 0.005
I0526 00:14:35.430752 20705 solver.cpp:237] Iteration 47850, loss = 1.19158
I0526 00:14:35.430788 20705 solver.cpp:253]     Train net output #0: loss = 1.19158 (* 1 = 1.19158 loss)
I0526 00:14:35.430805 20705 sgd_solver.cpp:106] Iteration 47850, lr = 0.005
I0526 00:14:44.105954 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_48000.caffemodel
I0526 00:14:44.184183 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_48000.solverstate
I0526 00:14:44.210585 20705 solver.cpp:341] Iteration 48000, Testing net (#0)
I0526 00:15:51.954877 20705 solver.cpp:409]     Test net output #0: accuracy = 0.893956
I0526 00:15:51.955068 20705 solver.cpp:409]     Test net output #1: loss = 0.34823 (* 1 = 0.34823 loss)
I0526 00:16:12.772470 20705 solver.cpp:237] Iteration 48000, loss = 1.15036
I0526 00:16:12.772534 20705 solver.cpp:253]     Train net output #0: loss = 1.15036 (* 1 = 1.15036 loss)
I0526 00:16:12.772554 20705 sgd_solver.cpp:106] Iteration 48000, lr = 0.005
I0526 00:16:21.504412 20705 solver.cpp:237] Iteration 48150, loss = 1.15594
I0526 00:16:21.504448 20705 solver.cpp:253]     Train net output #0: loss = 1.15594 (* 1 = 1.15594 loss)
I0526 00:16:21.504472 20705 sgd_solver.cpp:106] Iteration 48150, lr = 0.005
I0526 00:16:30.238384 20705 solver.cpp:237] Iteration 48300, loss = 1.20278
I0526 00:16:30.238566 20705 solver.cpp:253]     Train net output #0: loss = 1.20278 (* 1 = 1.20278 loss)
I0526 00:16:30.238584 20705 sgd_solver.cpp:106] Iteration 48300, lr = 0.005
I0526 00:16:38.971194 20705 solver.cpp:237] Iteration 48450, loss = 1.07925
I0526 00:16:38.971231 20705 solver.cpp:253]     Train net output #0: loss = 1.07925 (* 1 = 1.07925 loss)
I0526 00:16:38.971251 20705 sgd_solver.cpp:106] Iteration 48450, lr = 0.005
I0526 00:16:47.702345 20705 solver.cpp:237] Iteration 48600, loss = 1.01961
I0526 00:16:47.702399 20705 solver.cpp:253]     Train net output #0: loss = 1.01961 (* 1 = 1.01961 loss)
I0526 00:16:47.702425 20705 sgd_solver.cpp:106] Iteration 48600, lr = 0.005
I0526 00:16:56.432389 20705 solver.cpp:237] Iteration 48750, loss = 0.969564
I0526 00:16:56.432425 20705 solver.cpp:253]     Train net output #0: loss = 0.969564 (* 1 = 0.969564 loss)
I0526 00:16:56.432443 20705 sgd_solver.cpp:106] Iteration 48750, lr = 0.005
I0526 00:17:05.166287 20705 solver.cpp:237] Iteration 48900, loss = 1.1987
I0526 00:17:05.166467 20705 solver.cpp:253]     Train net output #0: loss = 1.1987 (* 1 = 1.1987 loss)
I0526 00:17:05.166484 20705 sgd_solver.cpp:106] Iteration 48900, lr = 0.005
I0526 00:17:34.732461 20705 solver.cpp:237] Iteration 49050, loss = 1.14681
I0526 00:17:34.732522 20705 solver.cpp:253]     Train net output #0: loss = 1.14681 (* 1 = 1.14681 loss)
I0526 00:17:34.732540 20705 sgd_solver.cpp:106] Iteration 49050, lr = 0.005
I0526 00:17:43.471103 20705 solver.cpp:237] Iteration 49200, loss = 1.04508
I0526 00:17:43.471299 20705 solver.cpp:253]     Train net output #0: loss = 1.04508 (* 1 = 1.04508 loss)
I0526 00:17:43.471318 20705 sgd_solver.cpp:106] Iteration 49200, lr = 0.005
I0526 00:17:52.207299 20705 solver.cpp:237] Iteration 49350, loss = 1.33291
I0526 00:17:52.207336 20705 solver.cpp:253]     Train net output #0: loss = 1.33291 (* 1 = 1.33291 loss)
I0526 00:17:52.207355 20705 sgd_solver.cpp:106] Iteration 49350, lr = 0.005
I0526 00:18:00.884027 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_49500.caffemodel
I0526 00:18:00.962627 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_49500.solverstate
I0526 00:18:01.006269 20705 solver.cpp:237] Iteration 49500, loss = 1.1652
I0526 00:18:01.006326 20705 solver.cpp:253]     Train net output #0: loss = 1.1652 (* 1 = 1.1652 loss)
I0526 00:18:01.006351 20705 sgd_solver.cpp:106] Iteration 49500, lr = 0.005
I0526 00:18:09.739480 20705 solver.cpp:237] Iteration 49650, loss = 1.23389
I0526 00:18:09.739537 20705 solver.cpp:253]     Train net output #0: loss = 1.23389 (* 1 = 1.23389 loss)
I0526 00:18:09.739562 20705 sgd_solver.cpp:106] Iteration 49650, lr = 0.005
I0526 00:18:18.471755 20705 solver.cpp:237] Iteration 49800, loss = 0.983595
I0526 00:18:18.471930 20705 solver.cpp:253]     Train net output #0: loss = 0.983595 (* 1 = 0.983595 loss)
I0526 00:18:18.471947 20705 sgd_solver.cpp:106] Iteration 49800, lr = 0.005
I0526 00:18:27.203680 20705 solver.cpp:237] Iteration 49950, loss = 1.14261
I0526 00:18:27.203717 20705 solver.cpp:253]     Train net output #0: loss = 1.14261 (* 1 = 1.14261 loss)
I0526 00:18:27.203735 20705 sgd_solver.cpp:106] Iteration 49950, lr = 0.005
I0526 00:18:56.742255 20705 solver.cpp:237] Iteration 50100, loss = 0.974709
I0526 00:18:56.742456 20705 solver.cpp:253]     Train net output #0: loss = 0.974709 (* 1 = 0.974709 loss)
I0526 00:18:56.742475 20705 sgd_solver.cpp:106] Iteration 50100, lr = 0.005
I0526 00:19:05.479898 20705 solver.cpp:237] Iteration 50250, loss = 0.999862
I0526 00:19:05.479935 20705 solver.cpp:253]     Train net output #0: loss = 0.999862 (* 1 = 0.999862 loss)
I0526 00:19:05.479954 20705 sgd_solver.cpp:106] Iteration 50250, lr = 0.005
I0526 00:19:14.213693 20705 solver.cpp:237] Iteration 50400, loss = 1.18982
I0526 00:19:14.213729 20705 solver.cpp:253]     Train net output #0: loss = 1.18982 (* 1 = 1.18982 loss)
I0526 00:19:14.213747 20705 sgd_solver.cpp:106] Iteration 50400, lr = 0.005
I0526 00:19:22.950980 20705 solver.cpp:237] Iteration 50550, loss = 1.11818
I0526 00:19:22.951035 20705 solver.cpp:253]     Train net output #0: loss = 1.11818 (* 1 = 1.11818 loss)
I0526 00:19:22.951056 20705 sgd_solver.cpp:106] Iteration 50550, lr = 0.005
I0526 00:19:31.686058 20705 solver.cpp:237] Iteration 50700, loss = 1.08734
I0526 00:19:31.686229 20705 solver.cpp:253]     Train net output #0: loss = 1.08734 (* 1 = 1.08734 loss)
I0526 00:19:31.686246 20705 sgd_solver.cpp:106] Iteration 50700, lr = 0.005
I0526 00:19:40.411464 20705 solver.cpp:237] Iteration 50850, loss = 0.990657
I0526 00:19:40.411500 20705 solver.cpp:253]     Train net output #0: loss = 0.990657 (* 1 = 0.990657 loss)
I0526 00:19:40.411519 20705 sgd_solver.cpp:106] Iteration 50850, lr = 0.005
I0526 00:19:49.096379 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_51000.caffemodel
I0526 00:19:49.175743 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_51000.solverstate
I0526 00:19:49.201411 20705 solver.cpp:341] Iteration 51000, Testing net (#0)
I0526 00:20:36.051898 20705 solver.cpp:409]     Test net output #0: accuracy = 0.892929
I0526 00:20:36.052103 20705 solver.cpp:409]     Test net output #1: loss = 0.358543 (* 1 = 0.358543 loss)
I0526 00:20:56.846817 20705 solver.cpp:237] Iteration 51000, loss = 1.03326
I0526 00:20:56.846881 20705 solver.cpp:253]     Train net output #0: loss = 1.03326 (* 1 = 1.03326 loss)
I0526 00:20:56.846909 20705 sgd_solver.cpp:106] Iteration 51000, lr = 0.005
I0526 00:21:05.604229 20705 solver.cpp:237] Iteration 51150, loss = 1.00869
I0526 00:21:05.604285 20705 solver.cpp:253]     Train net output #0: loss = 1.00869 (* 1 = 1.00869 loss)
I0526 00:21:05.604301 20705 sgd_solver.cpp:106] Iteration 51150, lr = 0.005
I0526 00:21:14.363903 20705 solver.cpp:237] Iteration 51300, loss = 1.17554
I0526 00:21:14.364078 20705 solver.cpp:253]     Train net output #0: loss = 1.17554 (* 1 = 1.17554 loss)
I0526 00:21:14.364094 20705 sgd_solver.cpp:106] Iteration 51300, lr = 0.005
I0526 00:21:23.122082 20705 solver.cpp:237] Iteration 51450, loss = 1.29476
I0526 00:21:23.122139 20705 solver.cpp:253]     Train net output #0: loss = 1.29476 (* 1 = 1.29476 loss)
I0526 00:21:23.122166 20705 sgd_solver.cpp:106] Iteration 51450, lr = 0.005
I0526 00:21:31.884717 20705 solver.cpp:237] Iteration 51600, loss = 1.20228
I0526 00:21:31.884754 20705 solver.cpp:253]     Train net output #0: loss = 1.20228 (* 1 = 1.20228 loss)
I0526 00:21:31.884773 20705 sgd_solver.cpp:106] Iteration 51600, lr = 0.005
I0526 00:21:40.641860 20705 solver.cpp:237] Iteration 51750, loss = 1.17772
I0526 00:21:40.641896 20705 solver.cpp:253]     Train net output #0: loss = 1.17772 (* 1 = 1.17772 loss)
I0526 00:21:40.641916 20705 sgd_solver.cpp:106] Iteration 51750, lr = 0.005
I0526 00:21:49.398087 20705 solver.cpp:237] Iteration 51900, loss = 1.20786
I0526 00:21:49.398275 20705 solver.cpp:253]     Train net output #0: loss = 1.20786 (* 1 = 1.20786 loss)
I0526 00:21:49.398293 20705 sgd_solver.cpp:106] Iteration 51900, lr = 0.005
I0526 00:22:18.973094 20705 solver.cpp:237] Iteration 52050, loss = 1.20181
I0526 00:22:18.973153 20705 solver.cpp:253]     Train net output #0: loss = 1.20181 (* 1 = 1.20181 loss)
I0526 00:22:18.973178 20705 sgd_solver.cpp:106] Iteration 52050, lr = 0.005
I0526 00:22:27.737749 20705 solver.cpp:237] Iteration 52200, loss = 1.03508
I0526 00:22:27.737927 20705 solver.cpp:253]     Train net output #0: loss = 1.03508 (* 1 = 1.03508 loss)
I0526 00:22:27.737944 20705 sgd_solver.cpp:106] Iteration 52200, lr = 0.005
I0526 00:22:36.492569 20705 solver.cpp:237] Iteration 52350, loss = 1.01386
I0526 00:22:36.492605 20705 solver.cpp:253]     Train net output #0: loss = 1.01386 (* 1 = 1.01386 loss)
I0526 00:22:36.492624 20705 sgd_solver.cpp:106] Iteration 52350, lr = 0.005
I0526 00:22:45.201701 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_52500.caffemodel
I0526 00:22:45.281932 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_52500.solverstate
I0526 00:22:45.327388 20705 solver.cpp:237] Iteration 52500, loss = 1.00765
I0526 00:22:45.327452 20705 solver.cpp:253]     Train net output #0: loss = 1.00765 (* 1 = 1.00765 loss)
I0526 00:22:45.327469 20705 sgd_solver.cpp:106] Iteration 52500, lr = 0.005
I0526 00:22:54.088418 20705 solver.cpp:237] Iteration 52650, loss = 1.0545
I0526 00:22:54.088454 20705 solver.cpp:253]     Train net output #0: loss = 1.0545 (* 1 = 1.0545 loss)
I0526 00:22:54.088472 20705 sgd_solver.cpp:106] Iteration 52650, lr = 0.005
I0526 00:23:02.844853 20705 solver.cpp:237] Iteration 52800, loss = 1.25733
I0526 00:23:02.845048 20705 solver.cpp:253]     Train net output #0: loss = 1.25733 (* 1 = 1.25733 loss)
I0526 00:23:02.845067 20705 sgd_solver.cpp:106] Iteration 52800, lr = 0.005
I0526 00:23:11.597478 20705 solver.cpp:237] Iteration 52950, loss = 1.15279
I0526 00:23:11.597517 20705 solver.cpp:253]     Train net output #0: loss = 1.15279 (* 1 = 1.15279 loss)
I0526 00:23:11.597533 20705 sgd_solver.cpp:106] Iteration 52950, lr = 0.005
I0526 00:23:41.218648 20705 solver.cpp:237] Iteration 53100, loss = 1.10518
I0526 00:23:41.218847 20705 solver.cpp:253]     Train net output #0: loss = 1.10518 (* 1 = 1.10518 loss)
I0526 00:23:41.218865 20705 sgd_solver.cpp:106] Iteration 53100, lr = 0.005
I0526 00:23:49.980577 20705 solver.cpp:237] Iteration 53250, loss = 1.10889
I0526 00:23:49.980613 20705 solver.cpp:253]     Train net output #0: loss = 1.10889 (* 1 = 1.10889 loss)
I0526 00:23:49.980638 20705 sgd_solver.cpp:106] Iteration 53250, lr = 0.005
I0526 00:23:58.740351 20705 solver.cpp:237] Iteration 53400, loss = 1.06773
I0526 00:23:58.740403 20705 solver.cpp:253]     Train net output #0: loss = 1.06773 (* 1 = 1.06773 loss)
I0526 00:23:58.740428 20705 sgd_solver.cpp:106] Iteration 53400, lr = 0.005
I0526 00:24:07.496196 20705 solver.cpp:237] Iteration 53550, loss = 1.11596
I0526 00:24:07.496232 20705 solver.cpp:253]     Train net output #0: loss = 1.11596 (* 1 = 1.11596 loss)
I0526 00:24:07.496251 20705 sgd_solver.cpp:106] Iteration 53550, lr = 0.005
I0526 00:24:16.256489 20705 solver.cpp:237] Iteration 53700, loss = 1.17574
I0526 00:24:16.256662 20705 solver.cpp:253]     Train net output #0: loss = 1.17574 (* 1 = 1.17574 loss)
I0526 00:24:16.256680 20705 sgd_solver.cpp:106] Iteration 53700, lr = 0.005
I0526 00:24:25.015524 20705 solver.cpp:237] Iteration 53850, loss = 1.03654
I0526 00:24:25.015578 20705 solver.cpp:253]     Train net output #0: loss = 1.03654 (* 1 = 1.03654 loss)
I0526 00:24:25.015602 20705 sgd_solver.cpp:106] Iteration 53850, lr = 0.005
I0526 00:24:33.713829 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_54000.caffemodel
I0526 00:24:33.794862 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_54000.solverstate
I0526 00:24:33.822656 20705 solver.cpp:341] Iteration 54000, Testing net (#0)
I0526 00:25:41.498845 20705 solver.cpp:409]     Test net output #0: accuracy = 0.892995
I0526 00:25:41.499044 20705 solver.cpp:409]     Test net output #1: loss = 0.350228 (* 1 = 0.350228 loss)
I0526 00:26:02.316102 20705 solver.cpp:237] Iteration 54000, loss = 1.11004
I0526 00:26:02.316164 20705 solver.cpp:253]     Train net output #0: loss = 1.11004 (* 1 = 1.11004 loss)
I0526 00:26:02.316184 20705 sgd_solver.cpp:106] Iteration 54000, lr = 0.005
I0526 00:26:11.055219 20705 solver.cpp:237] Iteration 54150, loss = 1.13331
I0526 00:26:11.055256 20705 solver.cpp:253]     Train net output #0: loss = 1.13331 (* 1 = 1.13331 loss)
I0526 00:26:11.055274 20705 sgd_solver.cpp:106] Iteration 54150, lr = 0.005
I0526 00:26:19.798635 20705 solver.cpp:237] Iteration 54300, loss = 1.22557
I0526 00:26:19.798821 20705 solver.cpp:253]     Train net output #0: loss = 1.22557 (* 1 = 1.22557 loss)
I0526 00:26:19.798838 20705 sgd_solver.cpp:106] Iteration 54300, lr = 0.005
I0526 00:26:28.538102 20705 solver.cpp:237] Iteration 54450, loss = 1.17529
I0526 00:26:28.538158 20705 solver.cpp:253]     Train net output #0: loss = 1.17529 (* 1 = 1.17529 loss)
I0526 00:26:28.538182 20705 sgd_solver.cpp:106] Iteration 54450, lr = 0.005
I0526 00:26:37.279041 20705 solver.cpp:237] Iteration 54600, loss = 1.20296
I0526 00:26:37.279078 20705 solver.cpp:253]     Train net output #0: loss = 1.20296 (* 1 = 1.20296 loss)
I0526 00:26:37.279095 20705 sgd_solver.cpp:106] Iteration 54600, lr = 0.005
I0526 00:26:46.019791 20705 solver.cpp:237] Iteration 54750, loss = 1.08508
I0526 00:26:46.019829 20705 solver.cpp:253]     Train net output #0: loss = 1.08508 (* 1 = 1.08508 loss)
I0526 00:26:46.019847 20705 sgd_solver.cpp:106] Iteration 54750, lr = 0.005
I0526 00:26:54.763886 20705 solver.cpp:237] Iteration 54900, loss = 1.11683
I0526 00:26:54.764091 20705 solver.cpp:253]     Train net output #0: loss = 1.11683 (* 1 = 1.11683 loss)
I0526 00:26:54.764108 20705 sgd_solver.cpp:106] Iteration 54900, lr = 0.005
I0526 00:27:24.348300 20705 solver.cpp:237] Iteration 55050, loss = 1.12402
I0526 00:27:24.348364 20705 solver.cpp:253]     Train net output #0: loss = 1.12402 (* 1 = 1.12402 loss)
I0526 00:27:24.348390 20705 sgd_solver.cpp:106] Iteration 55050, lr = 0.005
I0526 00:27:33.094605 20705 solver.cpp:237] Iteration 55200, loss = 1.16446
I0526 00:27:33.094787 20705 solver.cpp:253]     Train net output #0: loss = 1.16446 (* 1 = 1.16446 loss)
I0526 00:27:33.094804 20705 sgd_solver.cpp:106] Iteration 55200, lr = 0.005
I0526 00:27:41.857738 20705 solver.cpp:237] Iteration 55350, loss = 1.13672
I0526 00:27:41.857798 20705 solver.cpp:253]     Train net output #0: loss = 1.13672 (* 1 = 1.13672 loss)
I0526 00:27:41.857822 20705 sgd_solver.cpp:106] Iteration 55350, lr = 0.005
I0526 00:27:50.535117 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_55500.caffemodel
I0526 00:27:50.614276 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_55500.solverstate
I0526 00:27:50.658236 20705 solver.cpp:237] Iteration 55500, loss = 1.12607
I0526 00:27:50.658291 20705 solver.cpp:253]     Train net output #0: loss = 1.12607 (* 1 = 1.12607 loss)
I0526 00:27:50.658318 20705 sgd_solver.cpp:106] Iteration 55500, lr = 0.005
I0526 00:27:59.405364 20705 solver.cpp:237] Iteration 55650, loss = 1.13501
I0526 00:27:59.405400 20705 solver.cpp:253]     Train net output #0: loss = 1.13501 (* 1 = 1.13501 loss)
I0526 00:27:59.405419 20705 sgd_solver.cpp:106] Iteration 55650, lr = 0.005
I0526 00:28:08.149653 20705 solver.cpp:237] Iteration 55800, loss = 0.968892
I0526 00:28:08.149854 20705 solver.cpp:253]     Train net output #0: loss = 0.968892 (* 1 = 0.968892 loss)
I0526 00:28:08.149873 20705 sgd_solver.cpp:106] Iteration 55800, lr = 0.005
I0526 00:28:16.892011 20705 solver.cpp:237] Iteration 55950, loss = 1.22302
I0526 00:28:16.892048 20705 solver.cpp:253]     Train net output #0: loss = 1.22302 (* 1 = 1.22302 loss)
I0526 00:28:16.892066 20705 sgd_solver.cpp:106] Iteration 55950, lr = 0.005
I0526 00:28:46.458029 20705 solver.cpp:237] Iteration 56100, loss = 0.993543
I0526 00:28:46.458240 20705 solver.cpp:253]     Train net output #0: loss = 0.993543 (* 1 = 0.993543 loss)
I0526 00:28:46.458256 20705 sgd_solver.cpp:106] Iteration 56100, lr = 0.005
I0526 00:28:55.201055 20705 solver.cpp:237] Iteration 56250, loss = 1.41208
I0526 00:28:55.201113 20705 solver.cpp:253]     Train net output #0: loss = 1.41208 (* 1 = 1.41208 loss)
I0526 00:28:55.201138 20705 sgd_solver.cpp:106] Iteration 56250, lr = 0.005
I0526 00:29:03.951498 20705 solver.cpp:237] Iteration 56400, loss = 1.1089
I0526 00:29:03.951534 20705 solver.cpp:253]     Train net output #0: loss = 1.1089 (* 1 = 1.1089 loss)
I0526 00:29:03.951553 20705 sgd_solver.cpp:106] Iteration 56400, lr = 0.005
I0526 00:29:12.692600 20705 solver.cpp:237] Iteration 56550, loss = 1.28769
I0526 00:29:12.692636 20705 solver.cpp:253]     Train net output #0: loss = 1.28769 (* 1 = 1.28769 loss)
I0526 00:29:12.692654 20705 sgd_solver.cpp:106] Iteration 56550, lr = 0.005
I0526 00:29:21.436179 20705 solver.cpp:237] Iteration 56700, loss = 1.28087
I0526 00:29:21.436383 20705 solver.cpp:253]     Train net output #0: loss = 1.28087 (* 1 = 1.28087 loss)
I0526 00:29:21.436399 20705 sgd_solver.cpp:106] Iteration 56700, lr = 0.005
I0526 00:29:30.179558 20705 solver.cpp:237] Iteration 56850, loss = 1.00979
I0526 00:29:30.179594 20705 solver.cpp:253]     Train net output #0: loss = 1.00979 (* 1 = 1.00979 loss)
I0526 00:29:30.179615 20705 sgd_solver.cpp:106] Iteration 56850, lr = 0.005
I0526 00:29:38.857367 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_57000.caffemodel
I0526 00:29:38.936266 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_57000.solverstate
I0526 00:29:38.962420 20705 solver.cpp:341] Iteration 57000, Testing net (#0)
I0526 00:30:25.477126 20705 solver.cpp:409]     Test net output #0: accuracy = 0.895597
I0526 00:30:25.477330 20705 solver.cpp:409]     Test net output #1: loss = 0.332509 (* 1 = 0.332509 loss)
I0526 00:30:46.288888 20705 solver.cpp:237] Iteration 57000, loss = 1.26986
I0526 00:30:46.288950 20705 solver.cpp:253]     Train net output #0: loss = 1.26986 (* 1 = 1.26986 loss)
I0526 00:30:46.288971 20705 sgd_solver.cpp:106] Iteration 57000, lr = 0.005
I0526 00:30:55.015130 20705 solver.cpp:237] Iteration 57150, loss = 0.993727
I0526 00:30:55.015168 20705 solver.cpp:253]     Train net output #0: loss = 0.993727 (* 1 = 0.993727 loss)
I0526 00:30:55.015187 20705 sgd_solver.cpp:106] Iteration 57150, lr = 0.005
I0526 00:31:03.746685 20705 solver.cpp:237] Iteration 57300, loss = 1.06037
I0526 00:31:03.746876 20705 solver.cpp:253]     Train net output #0: loss = 1.06037 (* 1 = 1.06037 loss)
I0526 00:31:03.746893 20705 sgd_solver.cpp:106] Iteration 57300, lr = 0.005
I0526 00:31:12.476454 20705 solver.cpp:237] Iteration 57450, loss = 1.24439
I0526 00:31:12.476490 20705 solver.cpp:253]     Train net output #0: loss = 1.24439 (* 1 = 1.24439 loss)
I0526 00:31:12.476510 20705 sgd_solver.cpp:106] Iteration 57450, lr = 0.005
I0526 00:31:21.205282 20705 solver.cpp:237] Iteration 57600, loss = 1.20242
I0526 00:31:21.205318 20705 solver.cpp:253]     Train net output #0: loss = 1.20242 (* 1 = 1.20242 loss)
I0526 00:31:21.205337 20705 sgd_solver.cpp:106] Iteration 57600, lr = 0.005
I0526 00:31:29.932020 20705 solver.cpp:237] Iteration 57750, loss = 1.17675
I0526 00:31:29.932067 20705 solver.cpp:253]     Train net output #0: loss = 1.17675 (* 1 = 1.17675 loss)
I0526 00:31:29.932086 20705 sgd_solver.cpp:106] Iteration 57750, lr = 0.005
I0526 00:31:38.666363 20705 solver.cpp:237] Iteration 57900, loss = 0.970772
I0526 00:31:38.666549 20705 solver.cpp:253]     Train net output #0: loss = 0.970772 (* 1 = 0.970772 loss)
I0526 00:31:38.666566 20705 sgd_solver.cpp:106] Iteration 57900, lr = 0.005
I0526 00:32:08.177278 20705 solver.cpp:237] Iteration 58050, loss = 1.08247
I0526 00:32:08.177338 20705 solver.cpp:253]     Train net output #0: loss = 1.08247 (* 1 = 1.08247 loss)
I0526 00:32:08.177357 20705 sgd_solver.cpp:106] Iteration 58050, lr = 0.005
I0526 00:32:16.905637 20705 solver.cpp:237] Iteration 58200, loss = 1.18706
I0526 00:32:16.905848 20705 solver.cpp:253]     Train net output #0: loss = 1.18706 (* 1 = 1.18706 loss)
I0526 00:32:16.905865 20705 sgd_solver.cpp:106] Iteration 58200, lr = 0.005
I0526 00:32:25.634367 20705 solver.cpp:237] Iteration 58350, loss = 1.20773
I0526 00:32:25.634404 20705 solver.cpp:253]     Train net output #0: loss = 1.20773 (* 1 = 1.20773 loss)
I0526 00:32:25.634423 20705 sgd_solver.cpp:106] Iteration 58350, lr = 0.005
I0526 00:32:34.310540 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_58500.caffemodel
I0526 00:32:34.389631 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_58500.solverstate
I0526 00:32:34.433745 20705 solver.cpp:237] Iteration 58500, loss = 1.28172
I0526 00:32:34.433801 20705 solver.cpp:253]     Train net output #0: loss = 1.28172 (* 1 = 1.28172 loss)
I0526 00:32:34.433820 20705 sgd_solver.cpp:106] Iteration 58500, lr = 0.005
I0526 00:32:43.163477 20705 solver.cpp:237] Iteration 58650, loss = 1.14129
I0526 00:32:43.163533 20705 solver.cpp:253]     Train net output #0: loss = 1.14129 (* 1 = 1.14129 loss)
I0526 00:32:43.163559 20705 sgd_solver.cpp:106] Iteration 58650, lr = 0.005
I0526 00:32:51.893468 20705 solver.cpp:237] Iteration 58800, loss = 1.27713
I0526 00:32:51.893658 20705 solver.cpp:253]     Train net output #0: loss = 1.27713 (* 1 = 1.27713 loss)
I0526 00:32:51.893676 20705 sgd_solver.cpp:106] Iteration 58800, lr = 0.005
I0526 00:33:00.620301 20705 solver.cpp:237] Iteration 58950, loss = 0.967609
I0526 00:33:00.620343 20705 solver.cpp:253]     Train net output #0: loss = 0.967609 (* 1 = 0.967609 loss)
I0526 00:33:00.620360 20705 sgd_solver.cpp:106] Iteration 58950, lr = 0.005
I0526 00:33:30.158776 20705 solver.cpp:237] Iteration 59100, loss = 1.15516
I0526 00:33:30.158980 20705 solver.cpp:253]     Train net output #0: loss = 1.15516 (* 1 = 1.15516 loss)
I0526 00:33:30.158998 20705 sgd_solver.cpp:106] Iteration 59100, lr = 0.005
I0526 00:33:38.885931 20705 solver.cpp:237] Iteration 59250, loss = 1.02026
I0526 00:33:38.885967 20705 solver.cpp:253]     Train net output #0: loss = 1.02026 (* 1 = 1.02026 loss)
I0526 00:33:38.885987 20705 sgd_solver.cpp:106] Iteration 59250, lr = 0.005
I0526 00:33:47.620596 20705 solver.cpp:237] Iteration 59400, loss = 1.04203
I0526 00:33:47.620633 20705 solver.cpp:253]     Train net output #0: loss = 1.04203 (* 1 = 1.04203 loss)
I0526 00:33:47.620652 20705 sgd_solver.cpp:106] Iteration 59400, lr = 0.005
I0526 00:33:56.353880 20705 solver.cpp:237] Iteration 59550, loss = 1.088
I0526 00:33:56.353941 20705 solver.cpp:253]     Train net output #0: loss = 1.088 (* 1 = 1.088 loss)
I0526 00:33:56.353960 20705 sgd_solver.cpp:106] Iteration 59550, lr = 0.005
I0526 00:34:05.082466 20705 solver.cpp:237] Iteration 59700, loss = 1.13157
I0526 00:34:05.082644 20705 solver.cpp:253]     Train net output #0: loss = 1.13157 (* 1 = 1.13157 loss)
I0526 00:34:05.082661 20705 sgd_solver.cpp:106] Iteration 59700, lr = 0.005
I0526 00:34:13.811097 20705 solver.cpp:237] Iteration 59850, loss = 1.21911
I0526 00:34:13.811136 20705 solver.cpp:253]     Train net output #0: loss = 1.21911 (* 1 = 1.21911 loss)
I0526 00:34:13.811152 20705 sgd_solver.cpp:106] Iteration 59850, lr = 0.005
I0526 00:34:22.482195 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_60000.caffemodel
I0526 00:34:22.562788 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_60000.solverstate
I0526 00:34:22.590785 20705 solver.cpp:341] Iteration 60000, Testing net (#0)
I0526 00:35:30.275262 20705 solver.cpp:409]     Test net output #0: accuracy = 0.898029
I0526 00:35:30.275467 20705 solver.cpp:409]     Test net output #1: loss = 0.324807 (* 1 = 0.324807 loss)
I0526 00:35:51.138283 20705 solver.cpp:237] Iteration 60000, loss = 1.07879
I0526 00:35:51.138345 20705 solver.cpp:253]     Train net output #0: loss = 1.07879 (* 1 = 1.07879 loss)
I0526 00:35:51.138365 20705 sgd_solver.cpp:106] Iteration 60000, lr = 0.005
I0526 00:35:59.883875 20705 solver.cpp:237] Iteration 60150, loss = 1.15391
I0526 00:35:59.883934 20705 solver.cpp:253]     Train net output #0: loss = 1.15391 (* 1 = 1.15391 loss)
I0526 00:35:59.883958 20705 sgd_solver.cpp:106] Iteration 60150, lr = 0.005
I0526 00:36:08.635999 20705 solver.cpp:237] Iteration 60300, loss = 1.39426
I0526 00:36:08.636198 20705 solver.cpp:253]     Train net output #0: loss = 1.39426 (* 1 = 1.39426 loss)
I0526 00:36:08.636214 20705 sgd_solver.cpp:106] Iteration 60300, lr = 0.005
I0526 00:36:17.382382 20705 solver.cpp:237] Iteration 60450, loss = 1.22409
I0526 00:36:17.382421 20705 solver.cpp:253]     Train net output #0: loss = 1.22409 (* 1 = 1.22409 loss)
I0526 00:36:17.382436 20705 sgd_solver.cpp:106] Iteration 60450, lr = 0.005
I0526 00:36:26.129657 20705 solver.cpp:237] Iteration 60600, loss = 1.03767
I0526 00:36:26.129712 20705 solver.cpp:253]     Train net output #0: loss = 1.03767 (* 1 = 1.03767 loss)
I0526 00:36:26.129732 20705 sgd_solver.cpp:106] Iteration 60600, lr = 0.005
I0526 00:36:34.876027 20705 solver.cpp:237] Iteration 60750, loss = 1.08252
I0526 00:36:34.876065 20705 solver.cpp:253]     Train net output #0: loss = 1.08252 (* 1 = 1.08252 loss)
I0526 00:36:34.876082 20705 sgd_solver.cpp:106] Iteration 60750, lr = 0.005
I0526 00:36:43.620342 20705 solver.cpp:237] Iteration 60900, loss = 1.09778
I0526 00:36:43.620533 20705 solver.cpp:253]     Train net output #0: loss = 1.09778 (* 1 = 1.09778 loss)
I0526 00:36:43.620550 20705 sgd_solver.cpp:106] Iteration 60900, lr = 0.005
I0526 00:37:13.177381 20705 solver.cpp:237] Iteration 61050, loss = 1.31681
I0526 00:37:13.177443 20705 solver.cpp:253]     Train net output #0: loss = 1.31681 (* 1 = 1.31681 loss)
I0526 00:37:13.177462 20705 sgd_solver.cpp:106] Iteration 61050, lr = 0.005
I0526 00:37:21.921618 20705 solver.cpp:237] Iteration 61200, loss = 1.11647
I0526 00:37:21.921802 20705 solver.cpp:253]     Train net output #0: loss = 1.11647 (* 1 = 1.11647 loss)
I0526 00:37:21.921819 20705 sgd_solver.cpp:106] Iteration 61200, lr = 0.005
I0526 00:37:30.665709 20705 solver.cpp:237] Iteration 61350, loss = 1.28791
I0526 00:37:30.665745 20705 solver.cpp:253]     Train net output #0: loss = 1.28791 (* 1 = 1.28791 loss)
I0526 00:37:30.665763 20705 sgd_solver.cpp:106] Iteration 61350, lr = 0.005
I0526 00:37:39.356024 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_61500.caffemodel
I0526 00:37:39.435726 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_61500.solverstate
I0526 00:37:39.479475 20705 solver.cpp:237] Iteration 61500, loss = 1.07368
I0526 00:37:39.479532 20705 solver.cpp:253]     Train net output #0: loss = 1.07368 (* 1 = 1.07368 loss)
I0526 00:37:39.479558 20705 sgd_solver.cpp:106] Iteration 61500, lr = 0.005
I0526 00:37:48.224568 20705 solver.cpp:237] Iteration 61650, loss = 1.23435
I0526 00:37:48.224604 20705 solver.cpp:253]     Train net output #0: loss = 1.23435 (* 1 = 1.23435 loss)
I0526 00:37:48.224623 20705 sgd_solver.cpp:106] Iteration 61650, lr = 0.005
I0526 00:37:56.971232 20705 solver.cpp:237] Iteration 61800, loss = 0.973774
I0526 00:37:56.971424 20705 solver.cpp:253]     Train net output #0: loss = 0.973774 (* 1 = 0.973774 loss)
I0526 00:37:56.971441 20705 sgd_solver.cpp:106] Iteration 61800, lr = 0.005
I0526 00:38:05.719666 20705 solver.cpp:237] Iteration 61950, loss = 1.20889
I0526 00:38:05.719723 20705 solver.cpp:253]     Train net output #0: loss = 1.20889 (* 1 = 1.20889 loss)
I0526 00:38:05.719749 20705 sgd_solver.cpp:106] Iteration 61950, lr = 0.005
I0526 00:38:35.290750 20705 solver.cpp:237] Iteration 62100, loss = 1.24001
I0526 00:38:35.290953 20705 solver.cpp:253]     Train net output #0: loss = 1.24001 (* 1 = 1.24001 loss)
I0526 00:38:35.290973 20705 sgd_solver.cpp:106] Iteration 62100, lr = 0.005
I0526 00:38:44.028878 20705 solver.cpp:237] Iteration 62250, loss = 1.10905
I0526 00:38:44.028915 20705 solver.cpp:253]     Train net output #0: loss = 1.10905 (* 1 = 1.10905 loss)
I0526 00:38:44.028934 20705 sgd_solver.cpp:106] Iteration 62250, lr = 0.005
I0526 00:38:52.778622 20705 solver.cpp:237] Iteration 62400, loss = 1.27298
I0526 00:38:52.778681 20705 solver.cpp:253]     Train net output #0: loss = 1.27298 (* 1 = 1.27298 loss)
I0526 00:38:52.778707 20705 sgd_solver.cpp:106] Iteration 62400, lr = 0.005
I0526 00:39:01.522130 20705 solver.cpp:237] Iteration 62550, loss = 1.07336
I0526 00:39:01.522166 20705 solver.cpp:253]     Train net output #0: loss = 1.07336 (* 1 = 1.07336 loss)
I0526 00:39:01.522184 20705 sgd_solver.cpp:106] Iteration 62550, lr = 0.005
I0526 00:39:10.267199 20705 solver.cpp:237] Iteration 62700, loss = 1.10766
I0526 00:39:10.267388 20705 solver.cpp:253]     Train net output #0: loss = 1.10766 (* 1 = 1.10766 loss)
I0526 00:39:10.267405 20705 sgd_solver.cpp:106] Iteration 62700, lr = 0.005
I0526 00:39:19.010879 20705 solver.cpp:237] Iteration 62850, loss = 1.10194
I0526 00:39:19.010932 20705 solver.cpp:253]     Train net output #0: loss = 1.10194 (* 1 = 1.10194 loss)
I0526 00:39:19.010952 20705 sgd_solver.cpp:106] Iteration 62850, lr = 0.005
I0526 00:39:27.697165 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_63000.caffemodel
I0526 00:39:27.776206 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_63000.solverstate
I0526 00:39:27.802023 20705 solver.cpp:341] Iteration 63000, Testing net (#0)
I0526 00:40:14.658326 20705 solver.cpp:409]     Test net output #0: accuracy = 0.89743
I0526 00:40:14.658530 20705 solver.cpp:409]     Test net output #1: loss = 0.32127 (* 1 = 0.32127 loss)
I0526 00:40:35.467090 20705 solver.cpp:237] Iteration 63000, loss = 1.08439
I0526 00:40:35.467154 20705 solver.cpp:253]     Train net output #0: loss = 1.08439 (* 1 = 1.08439 loss)
I0526 00:40:35.467173 20705 sgd_solver.cpp:106] Iteration 63000, lr = 0.005
I0526 00:40:44.224602 20705 solver.cpp:237] Iteration 63150, loss = 1.22761
I0526 00:40:44.224638 20705 solver.cpp:253]     Train net output #0: loss = 1.22761 (* 1 = 1.22761 loss)
I0526 00:40:44.224663 20705 sgd_solver.cpp:106] Iteration 63150, lr = 0.005
I0526 00:40:52.985183 20705 solver.cpp:237] Iteration 63300, loss = 1.22824
I0526 00:40:52.985365 20705 solver.cpp:253]     Train net output #0: loss = 1.22824 (* 1 = 1.22824 loss)
I0526 00:40:52.985383 20705 sgd_solver.cpp:106] Iteration 63300, lr = 0.005
I0526 00:41:01.743446 20705 solver.cpp:237] Iteration 63450, loss = 1.36796
I0526 00:41:01.743502 20705 solver.cpp:253]     Train net output #0: loss = 1.36796 (* 1 = 1.36796 loss)
I0526 00:41:01.743531 20705 sgd_solver.cpp:106] Iteration 63450, lr = 0.005
I0526 00:41:10.503402 20705 solver.cpp:237] Iteration 63600, loss = 1.00271
I0526 00:41:10.503440 20705 solver.cpp:253]     Train net output #0: loss = 1.00271 (* 1 = 1.00271 loss)
I0526 00:41:10.503458 20705 sgd_solver.cpp:106] Iteration 63600, lr = 0.005
I0526 00:41:19.261502 20705 solver.cpp:237] Iteration 63750, loss = 1.03336
I0526 00:41:19.261538 20705 solver.cpp:253]     Train net output #0: loss = 1.03336 (* 1 = 1.03336 loss)
I0526 00:41:19.261556 20705 sgd_solver.cpp:106] Iteration 63750, lr = 0.005
I0526 00:41:28.028853 20705 solver.cpp:237] Iteration 63900, loss = 1.22687
I0526 00:41:28.029054 20705 solver.cpp:253]     Train net output #0: loss = 1.22687 (* 1 = 1.22687 loss)
I0526 00:41:28.029072 20705 sgd_solver.cpp:106] Iteration 63900, lr = 0.005
I0526 00:41:57.581876 20705 solver.cpp:237] Iteration 64050, loss = 1.06663
I0526 00:41:57.581933 20705 solver.cpp:253]     Train net output #0: loss = 1.06663 (* 1 = 1.06663 loss)
I0526 00:41:57.581961 20705 sgd_solver.cpp:106] Iteration 64050, lr = 0.005
I0526 00:42:06.339689 20705 solver.cpp:237] Iteration 64200, loss = 1.0907
I0526 00:42:06.339874 20705 solver.cpp:253]     Train net output #0: loss = 1.0907 (* 1 = 1.0907 loss)
I0526 00:42:06.339890 20705 sgd_solver.cpp:106] Iteration 64200, lr = 0.005
I0526 00:42:15.101537 20705 solver.cpp:237] Iteration 64350, loss = 1.20253
I0526 00:42:15.101595 20705 solver.cpp:253]     Train net output #0: loss = 1.20253 (* 1 = 1.20253 loss)
I0526 00:42:15.101621 20705 sgd_solver.cpp:106] Iteration 64350, lr = 0.005
I0526 00:42:23.802448 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_64500.caffemodel
I0526 00:42:23.881021 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_64500.solverstate
I0526 00:42:23.924420 20705 solver.cpp:237] Iteration 64500, loss = 1.03099
I0526 00:42:23.924479 20705 solver.cpp:253]     Train net output #0: loss = 1.03099 (* 1 = 1.03099 loss)
I0526 00:42:23.924505 20705 sgd_solver.cpp:106] Iteration 64500, lr = 0.005
I0526 00:42:32.684140 20705 solver.cpp:237] Iteration 64650, loss = 1.14429
I0526 00:42:32.684177 20705 solver.cpp:253]     Train net output #0: loss = 1.14429 (* 1 = 1.14429 loss)
I0526 00:42:32.684201 20705 sgd_solver.cpp:106] Iteration 64650, lr = 0.005
I0526 00:42:41.441633 20705 solver.cpp:237] Iteration 64800, loss = 1.10971
I0526 00:42:41.441843 20705 solver.cpp:253]     Train net output #0: loss = 1.10971 (* 1 = 1.10971 loss)
I0526 00:42:41.441860 20705 sgd_solver.cpp:106] Iteration 64800, lr = 0.005
I0526 00:42:50.195842 20705 solver.cpp:237] Iteration 64950, loss = 1.16167
I0526 00:42:50.195878 20705 solver.cpp:253]     Train net output #0: loss = 1.16167 (* 1 = 1.16167 loss)
I0526 00:42:50.195896 20705 sgd_solver.cpp:106] Iteration 64950, lr = 0.005
I0526 00:43:19.776157 20705 solver.cpp:237] Iteration 65100, loss = 1.04445
I0526 00:43:19.776373 20705 solver.cpp:253]     Train net output #0: loss = 1.04445 (* 1 = 1.04445 loss)
I0526 00:43:19.776391 20705 sgd_solver.cpp:106] Iteration 65100, lr = 0.005
I0526 00:43:28.536878 20705 solver.cpp:237] Iteration 65250, loss = 1.07574
I0526 00:43:28.536932 20705 solver.cpp:253]     Train net output #0: loss = 1.07574 (* 1 = 1.07574 loss)
I0526 00:43:28.536958 20705 sgd_solver.cpp:106] Iteration 65250, lr = 0.005
I0526 00:43:37.301105 20705 solver.cpp:237] Iteration 65400, loss = 1.17681
I0526 00:43:37.301141 20705 solver.cpp:253]     Train net output #0: loss = 1.17681 (* 1 = 1.17681 loss)
I0526 00:43:37.301158 20705 sgd_solver.cpp:106] Iteration 65400, lr = 0.005
I0526 00:43:46.060868 20705 solver.cpp:237] Iteration 65550, loss = 1.05676
I0526 00:43:46.060909 20705 solver.cpp:253]     Train net output #0: loss = 1.05676 (* 1 = 1.05676 loss)
I0526 00:43:46.060925 20705 sgd_solver.cpp:106] Iteration 65550, lr = 0.005
I0526 00:43:54.817173 20705 solver.cpp:237] Iteration 65700, loss = 1.05402
I0526 00:43:54.817369 20705 solver.cpp:253]     Train net output #0: loss = 1.05402 (* 1 = 1.05402 loss)
I0526 00:43:54.817386 20705 sgd_solver.cpp:106] Iteration 65700, lr = 0.005
I0526 00:44:03.577517 20705 solver.cpp:237] Iteration 65850, loss = 1.09707
I0526 00:44:03.577559 20705 solver.cpp:253]     Train net output #0: loss = 1.09707 (* 1 = 1.09707 loss)
I0526 00:44:03.577576 20705 sgd_solver.cpp:106] Iteration 65850, lr = 0.005
I0526 00:44:12.275938 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_66000.caffemodel
I0526 00:44:12.354773 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_66000.solverstate
I0526 00:44:12.381152 20705 solver.cpp:341] Iteration 66000, Testing net (#0)
I0526 00:45:20.082406 20705 solver.cpp:409]     Test net output #0: accuracy = 0.898049
I0526 00:45:20.082610 20705 solver.cpp:409]     Test net output #1: loss = 0.343121 (* 1 = 0.343121 loss)
I0526 00:45:40.908058 20705 solver.cpp:237] Iteration 66000, loss = 1.1198
I0526 00:45:40.908121 20705 solver.cpp:253]     Train net output #0: loss = 1.1198 (* 1 = 1.1198 loss)
I0526 00:45:40.908150 20705 sgd_solver.cpp:106] Iteration 66000, lr = 0.005
I0526 00:45:49.647856 20705 solver.cpp:237] Iteration 66150, loss = 1.11314
I0526 00:45:49.647897 20705 solver.cpp:253]     Train net output #0: loss = 1.11314 (* 1 = 1.11314 loss)
I0526 00:45:49.647913 20705 sgd_solver.cpp:106] Iteration 66150, lr = 0.005
I0526 00:45:58.389564 20705 solver.cpp:237] Iteration 66300, loss = 1.22287
I0526 00:45:58.389766 20705 solver.cpp:253]     Train net output #0: loss = 1.22287 (* 1 = 1.22287 loss)
I0526 00:45:58.389786 20705 sgd_solver.cpp:106] Iteration 66300, lr = 0.005
I0526 00:46:07.126433 20705 solver.cpp:237] Iteration 66450, loss = 1.03532
I0526 00:46:07.126471 20705 solver.cpp:253]     Train net output #0: loss = 1.03532 (* 1 = 1.03532 loss)
I0526 00:46:07.126489 20705 sgd_solver.cpp:106] Iteration 66450, lr = 0.005
I0526 00:46:15.862002 20705 solver.cpp:237] Iteration 66600, loss = 1.07704
I0526 00:46:15.862038 20705 solver.cpp:253]     Train net output #0: loss = 1.07704 (* 1 = 1.07704 loss)
I0526 00:46:15.862056 20705 sgd_solver.cpp:106] Iteration 66600, lr = 0.005
I0526 00:46:24.602349 20705 solver.cpp:237] Iteration 66750, loss = 1.25124
I0526 00:46:24.602406 20705 solver.cpp:253]     Train net output #0: loss = 1.25124 (* 1 = 1.25124 loss)
I0526 00:46:24.602432 20705 sgd_solver.cpp:106] Iteration 66750, lr = 0.005
I0526 00:46:33.326575 20705 solver.cpp:237] Iteration 66900, loss = 1.17362
I0526 00:46:33.326761 20705 solver.cpp:253]     Train net output #0: loss = 1.17362 (* 1 = 1.17362 loss)
I0526 00:46:33.326776 20705 sgd_solver.cpp:106] Iteration 66900, lr = 0.005
I0526 00:47:02.864938 20705 solver.cpp:237] Iteration 67050, loss = 1.12394
I0526 00:47:02.864995 20705 solver.cpp:253]     Train net output #0: loss = 1.12394 (* 1 = 1.12394 loss)
I0526 00:47:02.865020 20705 sgd_solver.cpp:106] Iteration 67050, lr = 0.005
I0526 00:47:11.599488 20705 solver.cpp:237] Iteration 67200, loss = 1.07696
I0526 00:47:11.599684 20705 solver.cpp:253]     Train net output #0: loss = 1.07696 (* 1 = 1.07696 loss)
I0526 00:47:11.599701 20705 sgd_solver.cpp:106] Iteration 67200, lr = 0.005
I0526 00:47:20.336314 20705 solver.cpp:237] Iteration 67350, loss = 1.1185
I0526 00:47:20.336362 20705 solver.cpp:253]     Train net output #0: loss = 1.1185 (* 1 = 1.1185 loss)
I0526 00:47:20.336379 20705 sgd_solver.cpp:106] Iteration 67350, lr = 0.005
I0526 00:47:29.012744 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_67500.caffemodel
I0526 00:47:29.093052 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_67500.solverstate
I0526 00:47:29.138484 20705 solver.cpp:237] Iteration 67500, loss = 1.27023
I0526 00:47:29.138548 20705 solver.cpp:253]     Train net output #0: loss = 1.27023 (* 1 = 1.27023 loss)
I0526 00:47:29.138566 20705 sgd_solver.cpp:106] Iteration 67500, lr = 0.005
I0526 00:47:37.870746 20705 solver.cpp:237] Iteration 67650, loss = 1.13887
I0526 00:47:37.870806 20705 solver.cpp:253]     Train net output #0: loss = 1.13887 (* 1 = 1.13887 loss)
I0526 00:47:37.870832 20705 sgd_solver.cpp:106] Iteration 67650, lr = 0.005
I0526 00:47:46.598700 20705 solver.cpp:237] Iteration 67800, loss = 1.12979
I0526 00:47:46.598884 20705 solver.cpp:253]     Train net output #0: loss = 1.12979 (* 1 = 1.12979 loss)
I0526 00:47:46.598901 20705 sgd_solver.cpp:106] Iteration 67800, lr = 0.005
I0526 00:47:55.327350 20705 solver.cpp:237] Iteration 67950, loss = 1.22476
I0526 00:47:55.327386 20705 solver.cpp:253]     Train net output #0: loss = 1.22476 (* 1 = 1.22476 loss)
I0526 00:47:55.327404 20705 sgd_solver.cpp:106] Iteration 67950, lr = 0.005
I0526 00:48:24.843070 20705 solver.cpp:237] Iteration 68100, loss = 1.22422
I0526 00:48:24.843274 20705 solver.cpp:253]     Train net output #0: loss = 1.22422 (* 1 = 1.22422 loss)
I0526 00:48:24.843292 20705 sgd_solver.cpp:106] Iteration 68100, lr = 0.005
I0526 00:48:33.568558 20705 solver.cpp:237] Iteration 68250, loss = 1.20765
I0526 00:48:33.568617 20705 solver.cpp:253]     Train net output #0: loss = 1.20765 (* 1 = 1.20765 loss)
I0526 00:48:33.568637 20705 sgd_solver.cpp:106] Iteration 68250, lr = 0.005
I0526 00:48:42.296170 20705 solver.cpp:237] Iteration 68400, loss = 1.10277
I0526 00:48:42.296207 20705 solver.cpp:253]     Train net output #0: loss = 1.10277 (* 1 = 1.10277 loss)
I0526 00:48:42.296226 20705 sgd_solver.cpp:106] Iteration 68400, lr = 0.005
I0526 00:48:51.027648 20705 solver.cpp:237] Iteration 68550, loss = 1.32093
I0526 00:48:51.027686 20705 solver.cpp:253]     Train net output #0: loss = 1.32093 (* 1 = 1.32093 loss)
I0526 00:48:51.027704 20705 sgd_solver.cpp:106] Iteration 68550, lr = 0.005
I0526 00:48:59.753872 20705 solver.cpp:237] Iteration 68700, loss = 1.12378
I0526 00:48:59.754081 20705 solver.cpp:253]     Train net output #0: loss = 1.12378 (* 1 = 1.12378 loss)
I0526 00:48:59.754097 20705 sgd_solver.cpp:106] Iteration 68700, lr = 0.005
I0526 00:49:08.482179 20705 solver.cpp:237] Iteration 68850, loss = 1.03377
I0526 00:49:08.482215 20705 solver.cpp:253]     Train net output #0: loss = 1.03377 (* 1 = 1.03377 loss)
I0526 00:49:08.482234 20705 sgd_solver.cpp:106] Iteration 68850, lr = 0.005
I0526 00:49:17.154099 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_69000.caffemodel
I0526 00:49:17.240005 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_69000.solverstate
I0526 00:49:17.265873 20705 solver.cpp:341] Iteration 69000, Testing net (#0)
I0526 00:50:03.763422 20705 solver.cpp:409]     Test net output #0: accuracy = 0.899143
I0526 00:50:03.763627 20705 solver.cpp:409]     Test net output #1: loss = 0.3268 (* 1 = 0.3268 loss)
I0526 00:50:24.598650 20705 solver.cpp:237] Iteration 69000, loss = 1.19995
I0526 00:50:24.598712 20705 solver.cpp:253]     Train net output #0: loss = 1.19995 (* 1 = 1.19995 loss)
I0526 00:50:24.598733 20705 sgd_solver.cpp:106] Iteration 69000, lr = 0.005
I0526 00:50:33.329062 20705 solver.cpp:237] Iteration 69150, loss = 1.20065
I0526 00:50:33.329124 20705 solver.cpp:253]     Train net output #0: loss = 1.20065 (* 1 = 1.20065 loss)
I0526 00:50:33.329144 20705 sgd_solver.cpp:106] Iteration 69150, lr = 0.005
I0526 00:50:42.062379 20705 solver.cpp:237] Iteration 69300, loss = 1.03683
I0526 00:50:42.062568 20705 solver.cpp:253]     Train net output #0: loss = 1.03683 (* 1 = 1.03683 loss)
I0526 00:50:42.062585 20705 sgd_solver.cpp:106] Iteration 69300, lr = 0.005
I0526 00:50:50.799034 20705 solver.cpp:237] Iteration 69450, loss = 1.09778
I0526 00:50:50.799077 20705 solver.cpp:253]     Train net output #0: loss = 1.09778 (* 1 = 1.09778 loss)
I0526 00:50:50.799093 20705 sgd_solver.cpp:106] Iteration 69450, lr = 0.005
I0526 00:50:59.531724 20705 solver.cpp:237] Iteration 69600, loss = 1.27565
I0526 00:50:59.531777 20705 solver.cpp:253]     Train net output #0: loss = 1.27565 (* 1 = 1.27565 loss)
I0526 00:50:59.531802 20705 sgd_solver.cpp:106] Iteration 69600, lr = 0.005
I0526 00:51:08.268250 20705 solver.cpp:237] Iteration 69750, loss = 1.25485
I0526 00:51:08.268286 20705 solver.cpp:253]     Train net output #0: loss = 1.25485 (* 1 = 1.25485 loss)
I0526 00:51:08.268306 20705 sgd_solver.cpp:106] Iteration 69750, lr = 0.005
I0526 00:51:17.000280 20705 solver.cpp:237] Iteration 69900, loss = 1.03488
I0526 00:51:17.000468 20705 solver.cpp:253]     Train net output #0: loss = 1.03488 (* 1 = 1.03488 loss)
I0526 00:51:17.000484 20705 sgd_solver.cpp:106] Iteration 69900, lr = 0.005
I0526 00:51:46.554610 20705 solver.cpp:237] Iteration 70050, loss = 1.40116
I0526 00:51:46.554666 20705 solver.cpp:253]     Train net output #0: loss = 1.40116 (* 1 = 1.40116 loss)
I0526 00:51:46.554692 20705 sgd_solver.cpp:106] Iteration 70050, lr = 0.005
I0526 00:51:55.287102 20705 solver.cpp:237] Iteration 70200, loss = 1.12512
I0526 00:51:55.287315 20705 solver.cpp:253]     Train net output #0: loss = 1.12512 (* 1 = 1.12512 loss)
I0526 00:51:55.287333 20705 sgd_solver.cpp:106] Iteration 70200, lr = 0.005
I0526 00:52:04.021185 20705 solver.cpp:237] Iteration 70350, loss = 1.02669
I0526 00:52:04.021224 20705 solver.cpp:253]     Train net output #0: loss = 1.02669 (* 1 = 1.02669 loss)
I0526 00:52:04.021240 20705 sgd_solver.cpp:106] Iteration 70350, lr = 0.005
I0526 00:52:12.700593 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_70500.caffemodel
I0526 00:52:12.779198 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_70500.solverstate
I0526 00:52:12.822679 20705 solver.cpp:237] Iteration 70500, loss = 1.1488
I0526 00:52:12.822736 20705 solver.cpp:253]     Train net output #0: loss = 1.1488 (* 1 = 1.1488 loss)
I0526 00:52:12.822760 20705 sgd_solver.cpp:106] Iteration 70500, lr = 0.005
I0526 00:52:21.555367 20705 solver.cpp:237] Iteration 70650, loss = 1.03375
I0526 00:52:21.555405 20705 solver.cpp:253]     Train net output #0: loss = 1.03375 (* 1 = 1.03375 loss)
I0526 00:52:21.555428 20705 sgd_solver.cpp:106] Iteration 70650, lr = 0.005
I0526 00:52:30.289614 20705 solver.cpp:237] Iteration 70800, loss = 1.08429
I0526 00:52:30.289810 20705 solver.cpp:253]     Train net output #0: loss = 1.08429 (* 1 = 1.08429 loss)
I0526 00:52:30.289829 20705 sgd_solver.cpp:106] Iteration 70800, lr = 0.005
I0526 00:52:39.026623 20705 solver.cpp:237] Iteration 70950, loss = 1.29792
I0526 00:52:39.026681 20705 solver.cpp:253]     Train net output #0: loss = 1.29792 (* 1 = 1.29792 loss)
I0526 00:52:39.026705 20705 sgd_solver.cpp:106] Iteration 70950, lr = 0.005
I0526 00:53:08.539172 20705 solver.cpp:237] Iteration 71100, loss = 1.1741
I0526 00:53:08.539386 20705 solver.cpp:253]     Train net output #0: loss = 1.1741 (* 1 = 1.1741 loss)
I0526 00:53:08.539403 20705 sgd_solver.cpp:106] Iteration 71100, lr = 0.005
I0526 00:53:17.279919 20705 solver.cpp:237] Iteration 71250, loss = 1.34445
I0526 00:53:17.279955 20705 solver.cpp:253]     Train net output #0: loss = 1.34445 (* 1 = 1.34445 loss)
I0526 00:53:17.279974 20705 sgd_solver.cpp:106] Iteration 71250, lr = 0.005
I0526 00:53:26.015763 20705 solver.cpp:237] Iteration 71400, loss = 1.19976
I0526 00:53:26.015800 20705 solver.cpp:253]     Train net output #0: loss = 1.19976 (* 1 = 1.19976 loss)
I0526 00:53:26.015817 20705 sgd_solver.cpp:106] Iteration 71400, lr = 0.005
I0526 00:53:34.758169 20705 solver.cpp:237] Iteration 71550, loss = 1.19535
I0526 00:53:34.758224 20705 solver.cpp:253]     Train net output #0: loss = 1.19535 (* 1 = 1.19535 loss)
I0526 00:53:34.758250 20705 sgd_solver.cpp:106] Iteration 71550, lr = 0.005
I0526 00:53:43.495594 20705 solver.cpp:237] Iteration 71700, loss = 1.20268
I0526 00:53:43.495779 20705 solver.cpp:253]     Train net output #0: loss = 1.20268 (* 1 = 1.20268 loss)
I0526 00:53:43.495795 20705 sgd_solver.cpp:106] Iteration 71700, lr = 0.005
I0526 00:53:52.233883 20705 solver.cpp:237] Iteration 71850, loss = 1.13064
I0526 00:53:52.233921 20705 solver.cpp:253]     Train net output #0: loss = 1.13064 (* 1 = 1.13064 loss)
I0526 00:53:52.233937 20705 sgd_solver.cpp:106] Iteration 71850, lr = 0.005
I0526 00:54:00.917538 20705 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_72000.caffemodel
I0526 00:54:00.996450 20705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0050_2016-05-20T15.49.27.359689_iter_72000.solverstate
I0526 00:54:01.022028 20705 solver.cpp:341] Iteration 72000, Testing net (#0)
I0526 00:55:08.692734 20705 solver.cpp:409]     Test net output #0: accuracy = 0.898196
I0526 00:55:08.692939 20705 solver.cpp:409]     Test net output #1: loss = 0.319075 (* 1 = 0.319075 loss)
I0526 00:55:29.502076 20705 solver.cpp:237] Iteration 72000, loss = 1.21441
I0526 00:55:29.502138 20705 solver.cpp:253]     Train net output #0: loss = 1.21441 (* 1 = 1.21441 loss)
I0526 00:55:29.502163 20705 sgd_solver.cpp:106] Iteration 72000, lr = 0.005
I0526 00:55:38.243480 20705 solver.cpp:237] Iteration 72150, loss = 1.21691
I0526 00:55:38.243540 20705 solver.cpp:253]     Train net output #0: loss = 1.21691 (* 1 = 1.21691 loss)
I0526 00:55:38.243564 20705 sgd_solver.cpp:106] Iteration 72150, lr = 0.005
I0526 00:55:46.981107 20705 solver.cpp:237] Iteration 72300, loss = 1.05379
I0526 00:55:46.981307 20705 solver.cpp:253]     Train net output #0: loss = 1.05379 (* 1 = 1.05379 loss)
I0526 00:55:46.981323 20705 sgd_solver.cpp:106] Iteration 72300, lr = 0.005
I0526 00:55:55.724696 20705 solver.cpp:237] Iteration 72450, loss = 1.19675
I0526 00:55:55.724733 20705 solver.cpp:253]     Train net output #0: loss = 1.19675 (* 1 = 1.19675 loss)
I0526 00:55:55.724752 20705 sgd_solver.cpp:106] Iteration 72450, lr = 0.005
I0526 00:56:04.468971 20705 solver.cpp:237] Iteration 72600, loss = 1.52668
I0526 00:56:04.469027 20705 solver.cpp:253]     Train net output #0: loss = 1.52668 (* 1 = 1.52668 loss)
I0526 00:56:04.469051 20705 sgd_solver.cpp:106] Iteration 72600, lr = 0.005
aprun: Apid 11266085: Caught signal Terminated, sending to application
*** Aborted at 1464238572 (unix time) try "date -d @1464238572" if you are using GNU date ***
aprun: Apid 11266085: Caught signal Terminated, sending to application
aprun: Apid 11266085: Caught signal Terminated, sending to application
PC: @     0x2aaab930eb63 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
*** SIGTERM (@0x50de) received by PID 20705 (TID 0x2aaac746f900) from PID 20702; stack trace: ***
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab930eb63 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab928a3b8 (unknown)
=>> PBS: job killed: walltime 7239 exceeded limit 7200
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11266085: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 02136] [c4-3c1s3n0] [Thu May 26 00:56:14 2016] PE RANK 0 exit signal Terminated
Application 11266085 exit codes: 143
Application 11266085 resources: utime ~6243s, stime ~979s, Rss ~5330064, inblocks ~16605999, outblocks ~740501
