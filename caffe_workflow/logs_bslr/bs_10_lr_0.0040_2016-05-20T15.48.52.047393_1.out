2806884
I0521 17:39:59.811892 12543 caffe.cpp:184] Using GPUs 0
I0521 17:40:00.236629 12543 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.004
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393.prototxt"
I0521 17:40:00.238211 12543 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393.prototxt
I0521 17:40:00.250543 12543 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 17:40:00.250602 12543 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 17:40:00.250948 12543 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 17:40:00.251132 12543 layer_factory.hpp:77] Creating layer data_hdf5
I0521 17:40:00.251157 12543 net.cpp:106] Creating Layer data_hdf5
I0521 17:40:00.251171 12543 net.cpp:411] data_hdf5 -> data
I0521 17:40:00.251204 12543 net.cpp:411] data_hdf5 -> label
I0521 17:40:00.251235 12543 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 17:40:00.252461 12543 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 17:40:00.254627 12543 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 17:40:21.790148 12543 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 17:40:21.795313 12543 net.cpp:150] Setting up data_hdf5
I0521 17:40:21.795354 12543 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 17:40:21.795368 12543 net.cpp:157] Top shape: 10 (10)
I0521 17:40:21.795380 12543 net.cpp:165] Memory required for data: 254040
I0521 17:40:21.795394 12543 layer_factory.hpp:77] Creating layer conv1
I0521 17:40:21.795428 12543 net.cpp:106] Creating Layer conv1
I0521 17:40:21.795439 12543 net.cpp:454] conv1 <- data
I0521 17:40:21.795459 12543 net.cpp:411] conv1 -> conv1
I0521 17:40:22.159103 12543 net.cpp:150] Setting up conv1
I0521 17:40:22.159149 12543 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 17:40:22.159160 12543 net.cpp:165] Memory required for data: 3018840
I0521 17:40:22.159190 12543 layer_factory.hpp:77] Creating layer relu1
I0521 17:40:22.159211 12543 net.cpp:106] Creating Layer relu1
I0521 17:40:22.159222 12543 net.cpp:454] relu1 <- conv1
I0521 17:40:22.159235 12543 net.cpp:397] relu1 -> conv1 (in-place)
I0521 17:40:22.159764 12543 net.cpp:150] Setting up relu1
I0521 17:40:22.159780 12543 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 17:40:22.159790 12543 net.cpp:165] Memory required for data: 5783640
I0521 17:40:22.159802 12543 layer_factory.hpp:77] Creating layer pool1
I0521 17:40:22.159819 12543 net.cpp:106] Creating Layer pool1
I0521 17:40:22.159829 12543 net.cpp:454] pool1 <- conv1
I0521 17:40:22.159842 12543 net.cpp:411] pool1 -> pool1
I0521 17:40:22.159922 12543 net.cpp:150] Setting up pool1
I0521 17:40:22.159935 12543 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 17:40:22.159945 12543 net.cpp:165] Memory required for data: 7166040
I0521 17:40:22.159956 12543 layer_factory.hpp:77] Creating layer conv2
I0521 17:40:22.159978 12543 net.cpp:106] Creating Layer conv2
I0521 17:40:22.159989 12543 net.cpp:454] conv2 <- pool1
I0521 17:40:22.160003 12543 net.cpp:411] conv2 -> conv2
I0521 17:40:22.162724 12543 net.cpp:150] Setting up conv2
I0521 17:40:22.162752 12543 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 17:40:22.162762 12543 net.cpp:165] Memory required for data: 9153240
I0521 17:40:22.162781 12543 layer_factory.hpp:77] Creating layer relu2
I0521 17:40:22.162796 12543 net.cpp:106] Creating Layer relu2
I0521 17:40:22.162806 12543 net.cpp:454] relu2 <- conv2
I0521 17:40:22.162818 12543 net.cpp:397] relu2 -> conv2 (in-place)
I0521 17:40:22.163149 12543 net.cpp:150] Setting up relu2
I0521 17:40:22.163164 12543 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 17:40:22.163174 12543 net.cpp:165] Memory required for data: 11140440
I0521 17:40:22.163185 12543 layer_factory.hpp:77] Creating layer pool2
I0521 17:40:22.163197 12543 net.cpp:106] Creating Layer pool2
I0521 17:40:22.163208 12543 net.cpp:454] pool2 <- conv2
I0521 17:40:22.163220 12543 net.cpp:411] pool2 -> pool2
I0521 17:40:22.163300 12543 net.cpp:150] Setting up pool2
I0521 17:40:22.163313 12543 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 17:40:22.163322 12543 net.cpp:165] Memory required for data: 12134040
I0521 17:40:22.163332 12543 layer_factory.hpp:77] Creating layer conv3
I0521 17:40:22.163350 12543 net.cpp:106] Creating Layer conv3
I0521 17:40:22.163360 12543 net.cpp:454] conv3 <- pool2
I0521 17:40:22.163373 12543 net.cpp:411] conv3 -> conv3
I0521 17:40:22.165464 12543 net.cpp:150] Setting up conv3
I0521 17:40:22.165488 12543 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 17:40:22.165500 12543 net.cpp:165] Memory required for data: 13218200
I0521 17:40:22.165518 12543 layer_factory.hpp:77] Creating layer relu3
I0521 17:40:22.165534 12543 net.cpp:106] Creating Layer relu3
I0521 17:40:22.165544 12543 net.cpp:454] relu3 <- conv3
I0521 17:40:22.165557 12543 net.cpp:397] relu3 -> conv3 (in-place)
I0521 17:40:22.166021 12543 net.cpp:150] Setting up relu3
I0521 17:40:22.166039 12543 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 17:40:22.166049 12543 net.cpp:165] Memory required for data: 14302360
I0521 17:40:22.166060 12543 layer_factory.hpp:77] Creating layer pool3
I0521 17:40:22.166074 12543 net.cpp:106] Creating Layer pool3
I0521 17:40:22.166084 12543 net.cpp:454] pool3 <- conv3
I0521 17:40:22.166105 12543 net.cpp:411] pool3 -> pool3
I0521 17:40:22.166172 12543 net.cpp:150] Setting up pool3
I0521 17:40:22.166184 12543 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 17:40:22.166194 12543 net.cpp:165] Memory required for data: 14844440
I0521 17:40:22.166203 12543 layer_factory.hpp:77] Creating layer conv4
I0521 17:40:22.166220 12543 net.cpp:106] Creating Layer conv4
I0521 17:40:22.166230 12543 net.cpp:454] conv4 <- pool3
I0521 17:40:22.166245 12543 net.cpp:411] conv4 -> conv4
I0521 17:40:22.168959 12543 net.cpp:150] Setting up conv4
I0521 17:40:22.168987 12543 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 17:40:22.168998 12543 net.cpp:165] Memory required for data: 15207320
I0521 17:40:22.169013 12543 layer_factory.hpp:77] Creating layer relu4
I0521 17:40:22.169028 12543 net.cpp:106] Creating Layer relu4
I0521 17:40:22.169037 12543 net.cpp:454] relu4 <- conv4
I0521 17:40:22.169050 12543 net.cpp:397] relu4 -> conv4 (in-place)
I0521 17:40:22.169513 12543 net.cpp:150] Setting up relu4
I0521 17:40:22.169529 12543 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 17:40:22.169539 12543 net.cpp:165] Memory required for data: 15570200
I0521 17:40:22.169549 12543 layer_factory.hpp:77] Creating layer pool4
I0521 17:40:22.169562 12543 net.cpp:106] Creating Layer pool4
I0521 17:40:22.169572 12543 net.cpp:454] pool4 <- conv4
I0521 17:40:22.169585 12543 net.cpp:411] pool4 -> pool4
I0521 17:40:22.169654 12543 net.cpp:150] Setting up pool4
I0521 17:40:22.169667 12543 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 17:40:22.169677 12543 net.cpp:165] Memory required for data: 15751640
I0521 17:40:22.169687 12543 layer_factory.hpp:77] Creating layer ip1
I0521 17:40:22.169705 12543 net.cpp:106] Creating Layer ip1
I0521 17:40:22.169715 12543 net.cpp:454] ip1 <- pool4
I0521 17:40:22.169728 12543 net.cpp:411] ip1 -> ip1
I0521 17:40:22.185144 12543 net.cpp:150] Setting up ip1
I0521 17:40:22.185173 12543 net.cpp:157] Top shape: 10 196 (1960)
I0521 17:40:22.185184 12543 net.cpp:165] Memory required for data: 15759480
I0521 17:40:22.185205 12543 layer_factory.hpp:77] Creating layer relu5
I0521 17:40:22.185220 12543 net.cpp:106] Creating Layer relu5
I0521 17:40:22.185230 12543 net.cpp:454] relu5 <- ip1
I0521 17:40:22.185243 12543 net.cpp:397] relu5 -> ip1 (in-place)
I0521 17:40:22.185586 12543 net.cpp:150] Setting up relu5
I0521 17:40:22.185600 12543 net.cpp:157] Top shape: 10 196 (1960)
I0521 17:40:22.185611 12543 net.cpp:165] Memory required for data: 15767320
I0521 17:40:22.185621 12543 layer_factory.hpp:77] Creating layer drop1
I0521 17:40:22.185642 12543 net.cpp:106] Creating Layer drop1
I0521 17:40:22.185652 12543 net.cpp:454] drop1 <- ip1
I0521 17:40:22.185665 12543 net.cpp:397] drop1 -> ip1 (in-place)
I0521 17:40:22.185724 12543 net.cpp:150] Setting up drop1
I0521 17:40:22.185737 12543 net.cpp:157] Top shape: 10 196 (1960)
I0521 17:40:22.185747 12543 net.cpp:165] Memory required for data: 15775160
I0521 17:40:22.185757 12543 layer_factory.hpp:77] Creating layer ip2
I0521 17:40:22.185775 12543 net.cpp:106] Creating Layer ip2
I0521 17:40:22.185786 12543 net.cpp:454] ip2 <- ip1
I0521 17:40:22.185798 12543 net.cpp:411] ip2 -> ip2
I0521 17:40:22.186269 12543 net.cpp:150] Setting up ip2
I0521 17:40:22.186282 12543 net.cpp:157] Top shape: 10 98 (980)
I0521 17:40:22.186292 12543 net.cpp:165] Memory required for data: 15779080
I0521 17:40:22.186307 12543 layer_factory.hpp:77] Creating layer relu6
I0521 17:40:22.186321 12543 net.cpp:106] Creating Layer relu6
I0521 17:40:22.186329 12543 net.cpp:454] relu6 <- ip2
I0521 17:40:22.186342 12543 net.cpp:397] relu6 -> ip2 (in-place)
I0521 17:40:22.186863 12543 net.cpp:150] Setting up relu6
I0521 17:40:22.186879 12543 net.cpp:157] Top shape: 10 98 (980)
I0521 17:40:22.186889 12543 net.cpp:165] Memory required for data: 15783000
I0521 17:40:22.186899 12543 layer_factory.hpp:77] Creating layer drop2
I0521 17:40:22.186913 12543 net.cpp:106] Creating Layer drop2
I0521 17:40:22.186921 12543 net.cpp:454] drop2 <- ip2
I0521 17:40:22.186934 12543 net.cpp:397] drop2 -> ip2 (in-place)
I0521 17:40:22.186977 12543 net.cpp:150] Setting up drop2
I0521 17:40:22.186990 12543 net.cpp:157] Top shape: 10 98 (980)
I0521 17:40:22.187000 12543 net.cpp:165] Memory required for data: 15786920
I0521 17:40:22.187010 12543 layer_factory.hpp:77] Creating layer ip3
I0521 17:40:22.187023 12543 net.cpp:106] Creating Layer ip3
I0521 17:40:22.187032 12543 net.cpp:454] ip3 <- ip2
I0521 17:40:22.187046 12543 net.cpp:411] ip3 -> ip3
I0521 17:40:22.187253 12543 net.cpp:150] Setting up ip3
I0521 17:40:22.187266 12543 net.cpp:157] Top shape: 10 11 (110)
I0521 17:40:22.187276 12543 net.cpp:165] Memory required for data: 15787360
I0521 17:40:22.187293 12543 layer_factory.hpp:77] Creating layer drop3
I0521 17:40:22.187304 12543 net.cpp:106] Creating Layer drop3
I0521 17:40:22.187314 12543 net.cpp:454] drop3 <- ip3
I0521 17:40:22.187326 12543 net.cpp:397] drop3 -> ip3 (in-place)
I0521 17:40:22.187366 12543 net.cpp:150] Setting up drop3
I0521 17:40:22.187377 12543 net.cpp:157] Top shape: 10 11 (110)
I0521 17:40:22.187388 12543 net.cpp:165] Memory required for data: 15787800
I0521 17:40:22.187397 12543 layer_factory.hpp:77] Creating layer loss
I0521 17:40:22.187417 12543 net.cpp:106] Creating Layer loss
I0521 17:40:22.187427 12543 net.cpp:454] loss <- ip3
I0521 17:40:22.187438 12543 net.cpp:454] loss <- label
I0521 17:40:22.187449 12543 net.cpp:411] loss -> loss
I0521 17:40:22.187466 12543 layer_factory.hpp:77] Creating layer loss
I0521 17:40:22.188108 12543 net.cpp:150] Setting up loss
I0521 17:40:22.188123 12543 net.cpp:157] Top shape: (1)
I0521 17:40:22.188134 12543 net.cpp:160]     with loss weight 1
I0521 17:40:22.188179 12543 net.cpp:165] Memory required for data: 15787804
I0521 17:40:22.188189 12543 net.cpp:226] loss needs backward computation.
I0521 17:40:22.188200 12543 net.cpp:226] drop3 needs backward computation.
I0521 17:40:22.188208 12543 net.cpp:226] ip3 needs backward computation.
I0521 17:40:22.188220 12543 net.cpp:226] drop2 needs backward computation.
I0521 17:40:22.188228 12543 net.cpp:226] relu6 needs backward computation.
I0521 17:40:22.188238 12543 net.cpp:226] ip2 needs backward computation.
I0521 17:40:22.188248 12543 net.cpp:226] drop1 needs backward computation.
I0521 17:40:22.188258 12543 net.cpp:226] relu5 needs backward computation.
I0521 17:40:22.188267 12543 net.cpp:226] ip1 needs backward computation.
I0521 17:40:22.188277 12543 net.cpp:226] pool4 needs backward computation.
I0521 17:40:22.188287 12543 net.cpp:226] relu4 needs backward computation.
I0521 17:40:22.188297 12543 net.cpp:226] conv4 needs backward computation.
I0521 17:40:22.188308 12543 net.cpp:226] pool3 needs backward computation.
I0521 17:40:22.188318 12543 net.cpp:226] relu3 needs backward computation.
I0521 17:40:22.188328 12543 net.cpp:226] conv3 needs backward computation.
I0521 17:40:22.188347 12543 net.cpp:226] pool2 needs backward computation.
I0521 17:40:22.188359 12543 net.cpp:226] relu2 needs backward computation.
I0521 17:40:22.188369 12543 net.cpp:226] conv2 needs backward computation.
I0521 17:40:22.188380 12543 net.cpp:226] pool1 needs backward computation.
I0521 17:40:22.188390 12543 net.cpp:226] relu1 needs backward computation.
I0521 17:40:22.188400 12543 net.cpp:226] conv1 needs backward computation.
I0521 17:40:22.188411 12543 net.cpp:228] data_hdf5 does not need backward computation.
I0521 17:40:22.188421 12543 net.cpp:270] This network produces output loss
I0521 17:40:22.188443 12543 net.cpp:283] Network initialization done.
I0521 17:40:22.190070 12543 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393.prototxt
I0521 17:40:22.190155 12543 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 17:40:22.190505 12543 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 17:40:22.190696 12543 layer_factory.hpp:77] Creating layer data_hdf5
I0521 17:40:22.190711 12543 net.cpp:106] Creating Layer data_hdf5
I0521 17:40:22.190722 12543 net.cpp:411] data_hdf5 -> data
I0521 17:40:22.190739 12543 net.cpp:411] data_hdf5 -> label
I0521 17:40:22.190755 12543 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 17:40:22.191993 12543 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 17:40:43.511703 12543 net.cpp:150] Setting up data_hdf5
I0521 17:40:43.511885 12543 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 17:40:43.511900 12543 net.cpp:157] Top shape: 10 (10)
I0521 17:40:43.511912 12543 net.cpp:165] Memory required for data: 254040
I0521 17:40:43.511925 12543 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 17:40:43.511955 12543 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 17:40:43.511965 12543 net.cpp:454] label_data_hdf5_1_split <- label
I0521 17:40:43.511981 12543 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 17:40:43.512002 12543 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 17:40:43.512074 12543 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 17:40:43.512089 12543 net.cpp:157] Top shape: 10 (10)
I0521 17:40:43.512100 12543 net.cpp:157] Top shape: 10 (10)
I0521 17:40:43.512109 12543 net.cpp:165] Memory required for data: 254120
I0521 17:40:43.512120 12543 layer_factory.hpp:77] Creating layer conv1
I0521 17:40:43.512142 12543 net.cpp:106] Creating Layer conv1
I0521 17:40:43.512152 12543 net.cpp:454] conv1 <- data
I0521 17:40:43.512167 12543 net.cpp:411] conv1 -> conv1
I0521 17:40:43.514144 12543 net.cpp:150] Setting up conv1
I0521 17:40:43.514168 12543 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 17:40:43.514180 12543 net.cpp:165] Memory required for data: 3018920
I0521 17:40:43.514200 12543 layer_factory.hpp:77] Creating layer relu1
I0521 17:40:43.514215 12543 net.cpp:106] Creating Layer relu1
I0521 17:40:43.514225 12543 net.cpp:454] relu1 <- conv1
I0521 17:40:43.514237 12543 net.cpp:397] relu1 -> conv1 (in-place)
I0521 17:40:43.514750 12543 net.cpp:150] Setting up relu1
I0521 17:40:43.514765 12543 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 17:40:43.514776 12543 net.cpp:165] Memory required for data: 5783720
I0521 17:40:43.514786 12543 layer_factory.hpp:77] Creating layer pool1
I0521 17:40:43.514802 12543 net.cpp:106] Creating Layer pool1
I0521 17:40:43.514812 12543 net.cpp:454] pool1 <- conv1
I0521 17:40:43.514825 12543 net.cpp:411] pool1 -> pool1
I0521 17:40:43.514900 12543 net.cpp:150] Setting up pool1
I0521 17:40:43.514914 12543 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 17:40:43.514924 12543 net.cpp:165] Memory required for data: 7166120
I0521 17:40:43.514935 12543 layer_factory.hpp:77] Creating layer conv2
I0521 17:40:43.514951 12543 net.cpp:106] Creating Layer conv2
I0521 17:40:43.514961 12543 net.cpp:454] conv2 <- pool1
I0521 17:40:43.514976 12543 net.cpp:411] conv2 -> conv2
I0521 17:40:43.516896 12543 net.cpp:150] Setting up conv2
I0521 17:40:43.516918 12543 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 17:40:43.516930 12543 net.cpp:165] Memory required for data: 9153320
I0521 17:40:43.516948 12543 layer_factory.hpp:77] Creating layer relu2
I0521 17:40:43.516963 12543 net.cpp:106] Creating Layer relu2
I0521 17:40:43.516973 12543 net.cpp:454] relu2 <- conv2
I0521 17:40:43.516985 12543 net.cpp:397] relu2 -> conv2 (in-place)
I0521 17:40:43.517319 12543 net.cpp:150] Setting up relu2
I0521 17:40:43.517333 12543 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 17:40:43.517343 12543 net.cpp:165] Memory required for data: 11140520
I0521 17:40:43.517354 12543 layer_factory.hpp:77] Creating layer pool2
I0521 17:40:43.517367 12543 net.cpp:106] Creating Layer pool2
I0521 17:40:43.517376 12543 net.cpp:454] pool2 <- conv2
I0521 17:40:43.517390 12543 net.cpp:411] pool2 -> pool2
I0521 17:40:43.517462 12543 net.cpp:150] Setting up pool2
I0521 17:40:43.517475 12543 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 17:40:43.517485 12543 net.cpp:165] Memory required for data: 12134120
I0521 17:40:43.517494 12543 layer_factory.hpp:77] Creating layer conv3
I0521 17:40:43.517513 12543 net.cpp:106] Creating Layer conv3
I0521 17:40:43.517524 12543 net.cpp:454] conv3 <- pool2
I0521 17:40:43.517537 12543 net.cpp:411] conv3 -> conv3
I0521 17:40:43.519551 12543 net.cpp:150] Setting up conv3
I0521 17:40:43.519572 12543 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 17:40:43.519585 12543 net.cpp:165] Memory required for data: 13218280
I0521 17:40:43.519603 12543 layer_factory.hpp:77] Creating layer relu3
I0521 17:40:43.519630 12543 net.cpp:106] Creating Layer relu3
I0521 17:40:43.519640 12543 net.cpp:454] relu3 <- conv3
I0521 17:40:43.519654 12543 net.cpp:397] relu3 -> conv3 (in-place)
I0521 17:40:43.520126 12543 net.cpp:150] Setting up relu3
I0521 17:40:43.520143 12543 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 17:40:43.520154 12543 net.cpp:165] Memory required for data: 14302440
I0521 17:40:43.520164 12543 layer_factory.hpp:77] Creating layer pool3
I0521 17:40:43.520177 12543 net.cpp:106] Creating Layer pool3
I0521 17:40:43.520186 12543 net.cpp:454] pool3 <- conv3
I0521 17:40:43.520200 12543 net.cpp:411] pool3 -> pool3
I0521 17:40:43.520272 12543 net.cpp:150] Setting up pool3
I0521 17:40:43.520285 12543 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 17:40:43.520295 12543 net.cpp:165] Memory required for data: 14844520
I0521 17:40:43.520304 12543 layer_factory.hpp:77] Creating layer conv4
I0521 17:40:43.520323 12543 net.cpp:106] Creating Layer conv4
I0521 17:40:43.520334 12543 net.cpp:454] conv4 <- pool3
I0521 17:40:43.520349 12543 net.cpp:411] conv4 -> conv4
I0521 17:40:43.522416 12543 net.cpp:150] Setting up conv4
I0521 17:40:43.522439 12543 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 17:40:43.522451 12543 net.cpp:165] Memory required for data: 15207400
I0521 17:40:43.522466 12543 layer_factory.hpp:77] Creating layer relu4
I0521 17:40:43.522480 12543 net.cpp:106] Creating Layer relu4
I0521 17:40:43.522490 12543 net.cpp:454] relu4 <- conv4
I0521 17:40:43.522502 12543 net.cpp:397] relu4 -> conv4 (in-place)
I0521 17:40:43.522970 12543 net.cpp:150] Setting up relu4
I0521 17:40:43.522986 12543 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 17:40:43.522996 12543 net.cpp:165] Memory required for data: 15570280
I0521 17:40:43.523006 12543 layer_factory.hpp:77] Creating layer pool4
I0521 17:40:43.523020 12543 net.cpp:106] Creating Layer pool4
I0521 17:40:43.523030 12543 net.cpp:454] pool4 <- conv4
I0521 17:40:43.523043 12543 net.cpp:411] pool4 -> pool4
I0521 17:40:43.523114 12543 net.cpp:150] Setting up pool4
I0521 17:40:43.523128 12543 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 17:40:43.523138 12543 net.cpp:165] Memory required for data: 15751720
I0521 17:40:43.523145 12543 layer_factory.hpp:77] Creating layer ip1
I0521 17:40:43.523161 12543 net.cpp:106] Creating Layer ip1
I0521 17:40:43.523171 12543 net.cpp:454] ip1 <- pool4
I0521 17:40:43.523185 12543 net.cpp:411] ip1 -> ip1
I0521 17:40:43.538642 12543 net.cpp:150] Setting up ip1
I0521 17:40:43.538671 12543 net.cpp:157] Top shape: 10 196 (1960)
I0521 17:40:43.538682 12543 net.cpp:165] Memory required for data: 15759560
I0521 17:40:43.538704 12543 layer_factory.hpp:77] Creating layer relu5
I0521 17:40:43.538719 12543 net.cpp:106] Creating Layer relu5
I0521 17:40:43.538730 12543 net.cpp:454] relu5 <- ip1
I0521 17:40:43.538743 12543 net.cpp:397] relu5 -> ip1 (in-place)
I0521 17:40:43.539091 12543 net.cpp:150] Setting up relu5
I0521 17:40:43.539105 12543 net.cpp:157] Top shape: 10 196 (1960)
I0521 17:40:43.539115 12543 net.cpp:165] Memory required for data: 15767400
I0521 17:40:43.539125 12543 layer_factory.hpp:77] Creating layer drop1
I0521 17:40:43.539144 12543 net.cpp:106] Creating Layer drop1
I0521 17:40:43.539154 12543 net.cpp:454] drop1 <- ip1
I0521 17:40:43.539166 12543 net.cpp:397] drop1 -> ip1 (in-place)
I0521 17:40:43.539211 12543 net.cpp:150] Setting up drop1
I0521 17:40:43.539223 12543 net.cpp:157] Top shape: 10 196 (1960)
I0521 17:40:43.539233 12543 net.cpp:165] Memory required for data: 15775240
I0521 17:40:43.539242 12543 layer_factory.hpp:77] Creating layer ip2
I0521 17:40:43.539257 12543 net.cpp:106] Creating Layer ip2
I0521 17:40:43.539266 12543 net.cpp:454] ip2 <- ip1
I0521 17:40:43.539280 12543 net.cpp:411] ip2 -> ip2
I0521 17:40:43.539758 12543 net.cpp:150] Setting up ip2
I0521 17:40:43.539772 12543 net.cpp:157] Top shape: 10 98 (980)
I0521 17:40:43.539782 12543 net.cpp:165] Memory required for data: 15779160
I0521 17:40:43.539796 12543 layer_factory.hpp:77] Creating layer relu6
I0521 17:40:43.539822 12543 net.cpp:106] Creating Layer relu6
I0521 17:40:43.539832 12543 net.cpp:454] relu6 <- ip2
I0521 17:40:43.539844 12543 net.cpp:397] relu6 -> ip2 (in-place)
I0521 17:40:43.540381 12543 net.cpp:150] Setting up relu6
I0521 17:40:43.540397 12543 net.cpp:157] Top shape: 10 98 (980)
I0521 17:40:43.540407 12543 net.cpp:165] Memory required for data: 15783080
I0521 17:40:43.540416 12543 layer_factory.hpp:77] Creating layer drop2
I0521 17:40:43.540431 12543 net.cpp:106] Creating Layer drop2
I0521 17:40:43.540441 12543 net.cpp:454] drop2 <- ip2
I0521 17:40:43.540453 12543 net.cpp:397] drop2 -> ip2 (in-place)
I0521 17:40:43.540498 12543 net.cpp:150] Setting up drop2
I0521 17:40:43.540510 12543 net.cpp:157] Top shape: 10 98 (980)
I0521 17:40:43.540520 12543 net.cpp:165] Memory required for data: 15787000
I0521 17:40:43.540529 12543 layer_factory.hpp:77] Creating layer ip3
I0521 17:40:43.540544 12543 net.cpp:106] Creating Layer ip3
I0521 17:40:43.540555 12543 net.cpp:454] ip3 <- ip2
I0521 17:40:43.540568 12543 net.cpp:411] ip3 -> ip3
I0521 17:40:43.540791 12543 net.cpp:150] Setting up ip3
I0521 17:40:43.540803 12543 net.cpp:157] Top shape: 10 11 (110)
I0521 17:40:43.540813 12543 net.cpp:165] Memory required for data: 15787440
I0521 17:40:43.540828 12543 layer_factory.hpp:77] Creating layer drop3
I0521 17:40:43.540841 12543 net.cpp:106] Creating Layer drop3
I0521 17:40:43.540851 12543 net.cpp:454] drop3 <- ip3
I0521 17:40:43.540864 12543 net.cpp:397] drop3 -> ip3 (in-place)
I0521 17:40:43.540905 12543 net.cpp:150] Setting up drop3
I0521 17:40:43.540918 12543 net.cpp:157] Top shape: 10 11 (110)
I0521 17:40:43.540928 12543 net.cpp:165] Memory required for data: 15787880
I0521 17:40:43.540938 12543 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 17:40:43.540951 12543 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 17:40:43.540961 12543 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 17:40:43.540974 12543 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 17:40:43.540989 12543 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 17:40:43.541062 12543 net.cpp:150] Setting up ip3_drop3_0_split
I0521 17:40:43.541075 12543 net.cpp:157] Top shape: 10 11 (110)
I0521 17:40:43.541087 12543 net.cpp:157] Top shape: 10 11 (110)
I0521 17:40:43.541098 12543 net.cpp:165] Memory required for data: 15788760
I0521 17:40:43.541108 12543 layer_factory.hpp:77] Creating layer accuracy
I0521 17:40:43.541131 12543 net.cpp:106] Creating Layer accuracy
I0521 17:40:43.541141 12543 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 17:40:43.541152 12543 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 17:40:43.541167 12543 net.cpp:411] accuracy -> accuracy
I0521 17:40:43.541190 12543 net.cpp:150] Setting up accuracy
I0521 17:40:43.541203 12543 net.cpp:157] Top shape: (1)
I0521 17:40:43.541213 12543 net.cpp:165] Memory required for data: 15788764
I0521 17:40:43.541223 12543 layer_factory.hpp:77] Creating layer loss
I0521 17:40:43.541235 12543 net.cpp:106] Creating Layer loss
I0521 17:40:43.541245 12543 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 17:40:43.541256 12543 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 17:40:43.541270 12543 net.cpp:411] loss -> loss
I0521 17:40:43.541287 12543 layer_factory.hpp:77] Creating layer loss
I0521 17:40:43.541774 12543 net.cpp:150] Setting up loss
I0521 17:40:43.541786 12543 net.cpp:157] Top shape: (1)
I0521 17:40:43.541796 12543 net.cpp:160]     with loss weight 1
I0521 17:40:43.541816 12543 net.cpp:165] Memory required for data: 15788768
I0521 17:40:43.541827 12543 net.cpp:226] loss needs backward computation.
I0521 17:40:43.541838 12543 net.cpp:228] accuracy does not need backward computation.
I0521 17:40:43.541849 12543 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 17:40:43.541860 12543 net.cpp:226] drop3 needs backward computation.
I0521 17:40:43.541872 12543 net.cpp:226] ip3 needs backward computation.
I0521 17:40:43.541882 12543 net.cpp:226] drop2 needs backward computation.
I0521 17:40:43.541892 12543 net.cpp:226] relu6 needs backward computation.
I0521 17:40:43.541909 12543 net.cpp:226] ip2 needs backward computation.
I0521 17:40:43.541919 12543 net.cpp:226] drop1 needs backward computation.
I0521 17:40:43.541929 12543 net.cpp:226] relu5 needs backward computation.
I0521 17:40:43.541939 12543 net.cpp:226] ip1 needs backward computation.
I0521 17:40:43.541949 12543 net.cpp:226] pool4 needs backward computation.
I0521 17:40:43.541960 12543 net.cpp:226] relu4 needs backward computation.
I0521 17:40:43.541970 12543 net.cpp:226] conv4 needs backward computation.
I0521 17:40:43.541978 12543 net.cpp:226] pool3 needs backward computation.
I0521 17:40:43.541990 12543 net.cpp:226] relu3 needs backward computation.
I0521 17:40:43.541999 12543 net.cpp:226] conv3 needs backward computation.
I0521 17:40:43.542009 12543 net.cpp:226] pool2 needs backward computation.
I0521 17:40:43.542021 12543 net.cpp:226] relu2 needs backward computation.
I0521 17:40:43.542031 12543 net.cpp:226] conv2 needs backward computation.
I0521 17:40:43.542040 12543 net.cpp:226] pool1 needs backward computation.
I0521 17:40:43.542050 12543 net.cpp:226] relu1 needs backward computation.
I0521 17:40:43.542060 12543 net.cpp:226] conv1 needs backward computation.
I0521 17:40:43.542073 12543 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 17:40:43.542083 12543 net.cpp:228] data_hdf5 does not need backward computation.
I0521 17:40:43.542101 12543 net.cpp:270] This network produces output accuracy
I0521 17:40:43.542112 12543 net.cpp:270] This network produces output loss
I0521 17:40:43.542140 12543 net.cpp:283] Network initialization done.
I0521 17:40:43.542273 12543 solver.cpp:60] Solver scaffolding done.
I0521 17:40:43.543412 12543 caffe.cpp:212] Starting Optimization
I0521 17:40:43.543431 12543 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 17:40:43.543444 12543 solver.cpp:289] Learning Rate Policy: fixed
I0521 17:40:43.544507 12543 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 17:41:44.002815 12543 solver.cpp:409]     Test net output #0: accuracy = 0.109312
I0521 17:41:44.002979 12543 solver.cpp:409]     Test net output #1: loss = 2.39841 (* 1 = 2.39841 loss)
I0521 17:41:44.020747 12543 solver.cpp:237] Iteration 0, loss = 2.388
I0521 17:41:44.020784 12543 solver.cpp:253]     Train net output #0: loss = 2.388 (* 1 = 2.388 loss)
I0521 17:41:44.020802 12543 sgd_solver.cpp:106] Iteration 0, lr = 0.004
I0521 17:42:00.805575 12543 solver.cpp:237] Iteration 1500, loss = 1.9802
I0521 17:42:00.805613 12543 solver.cpp:253]     Train net output #0: loss = 1.9802 (* 1 = 1.9802 loss)
I0521 17:42:00.805630 12543 sgd_solver.cpp:106] Iteration 1500, lr = 0.004
I0521 17:42:17.546684 12543 solver.cpp:237] Iteration 3000, loss = 1.46219
I0521 17:42:17.546846 12543 solver.cpp:253]     Train net output #0: loss = 1.46219 (* 1 = 1.46219 loss)
I0521 17:42:17.546861 12543 sgd_solver.cpp:106] Iteration 3000, lr = 0.004
I0521 17:42:34.306457 12543 solver.cpp:237] Iteration 4500, loss = 1.30348
I0521 17:42:34.306509 12543 solver.cpp:253]     Train net output #0: loss = 1.30348 (* 1 = 1.30348 loss)
I0521 17:42:34.306524 12543 sgd_solver.cpp:106] Iteration 4500, lr = 0.004
I0521 17:42:51.053462 12543 solver.cpp:237] Iteration 6000, loss = 1.27696
I0521 17:42:51.053602 12543 solver.cpp:253]     Train net output #0: loss = 1.27696 (* 1 = 1.27696 loss)
I0521 17:42:51.053617 12543 sgd_solver.cpp:106] Iteration 6000, lr = 0.004
I0521 17:43:07.720096 12543 solver.cpp:237] Iteration 7500, loss = 1.44176
I0521 17:43:07.720150 12543 solver.cpp:253]     Train net output #0: loss = 1.44176 (* 1 = 1.44176 loss)
I0521 17:43:07.720165 12543 sgd_solver.cpp:106] Iteration 7500, lr = 0.004
I0521 17:43:24.343190 12543 solver.cpp:237] Iteration 9000, loss = 1.54439
I0521 17:43:24.343344 12543 solver.cpp:253]     Train net output #0: loss = 1.54439 (* 1 = 1.54439 loss)
I0521 17:43:24.343358 12543 sgd_solver.cpp:106] Iteration 9000, lr = 0.004
I0521 17:44:03.043512 12543 solver.cpp:237] Iteration 10500, loss = 1.50997
I0521 17:44:03.043678 12543 solver.cpp:253]     Train net output #0: loss = 1.50997 (* 1 = 1.50997 loss)
I0521 17:44:03.043691 12543 sgd_solver.cpp:106] Iteration 10500, lr = 0.004
I0521 17:44:19.691807 12543 solver.cpp:237] Iteration 12000, loss = 1.25954
I0521 17:44:19.691857 12543 solver.cpp:253]     Train net output #0: loss = 1.25954 (* 1 = 1.25954 loss)
I0521 17:44:19.691871 12543 sgd_solver.cpp:106] Iteration 12000, lr = 0.004
I0521 17:44:36.319036 12543 solver.cpp:237] Iteration 13500, loss = 1.51401
I0521 17:44:36.319171 12543 solver.cpp:253]     Train net output #0: loss = 1.51401 (* 1 = 1.51401 loss)
I0521 17:44:36.319185 12543 sgd_solver.cpp:106] Iteration 13500, lr = 0.004
I0521 17:44:52.909842 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_15000.caffemodel
I0521 17:44:52.958782 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_15000.solverstate
I0521 17:44:52.987179 12543 solver.cpp:237] Iteration 15000, loss = 1.18168
I0521 17:44:52.987227 12543 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0521 17:44:52.987241 12543 sgd_solver.cpp:106] Iteration 15000, lr = 0.004
I0521 17:45:09.596119 12543 solver.cpp:237] Iteration 16500, loss = 1.04192
I0521 17:45:09.596274 12543 solver.cpp:253]     Train net output #0: loss = 1.04192 (* 1 = 1.04192 loss)
I0521 17:45:09.596288 12543 sgd_solver.cpp:106] Iteration 16500, lr = 0.004
I0521 17:45:26.184100 12543 solver.cpp:237] Iteration 18000, loss = 1.54144
I0521 17:45:26.184137 12543 solver.cpp:253]     Train net output #0: loss = 1.54144 (* 1 = 1.54144 loss)
I0521 17:45:26.184151 12543 sgd_solver.cpp:106] Iteration 18000, lr = 0.004
I0521 17:45:42.769246 12543 solver.cpp:237] Iteration 19500, loss = 1.45038
I0521 17:45:42.769392 12543 solver.cpp:253]     Train net output #0: loss = 1.45038 (* 1 = 1.45038 loss)
I0521 17:45:42.769404 12543 sgd_solver.cpp:106] Iteration 19500, lr = 0.004
I0521 17:46:21.453536 12543 solver.cpp:237] Iteration 21000, loss = 1.62097
I0521 17:46:21.453698 12543 solver.cpp:253]     Train net output #0: loss = 1.62097 (* 1 = 1.62097 loss)
I0521 17:46:21.453713 12543 sgd_solver.cpp:106] Iteration 21000, lr = 0.004
I0521 17:46:38.083820 12543 solver.cpp:237] Iteration 22500, loss = 0.931539
I0521 17:46:38.083858 12543 solver.cpp:253]     Train net output #0: loss = 0.931538 (* 1 = 0.931538 loss)
I0521 17:46:38.083873 12543 sgd_solver.cpp:106] Iteration 22500, lr = 0.004
I0521 17:46:54.703042 12543 solver.cpp:237] Iteration 24000, loss = 0.96031
I0521 17:46:54.703212 12543 solver.cpp:253]     Train net output #0: loss = 0.960309 (* 1 = 0.960309 loss)
I0521 17:46:54.703227 12543 sgd_solver.cpp:106] Iteration 24000, lr = 0.004
I0521 17:47:11.326462 12543 solver.cpp:237] Iteration 25500, loss = 1.35218
I0521 17:47:11.326508 12543 solver.cpp:253]     Train net output #0: loss = 1.35218 (* 1 = 1.35218 loss)
I0521 17:47:11.326524 12543 sgd_solver.cpp:106] Iteration 25500, lr = 0.004
I0521 17:47:27.920910 12543 solver.cpp:237] Iteration 27000, loss = 0.765773
I0521 17:47:27.921046 12543 solver.cpp:253]     Train net output #0: loss = 0.765772 (* 1 = 0.765772 loss)
I0521 17:47:27.921061 12543 sgd_solver.cpp:106] Iteration 27000, lr = 0.004
I0521 17:47:44.531922 12543 solver.cpp:237] Iteration 28500, loss = 1.46906
I0521 17:47:44.531970 12543 solver.cpp:253]     Train net output #0: loss = 1.46906 (* 1 = 1.46906 loss)
I0521 17:47:44.531987 12543 sgd_solver.cpp:106] Iteration 28500, lr = 0.004
I0521 17:48:01.117885 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_30000.caffemodel
I0521 17:48:01.165596 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_30000.solverstate
I0521 17:48:01.191949 12543 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 17:49:00.582996 12543 solver.cpp:409]     Test net output #0: accuracy = 0.852431
I0521 17:49:00.583158 12543 solver.cpp:409]     Test net output #1: loss = 0.491633 (* 1 = 0.491633 loss)
I0521 17:49:22.740764 12543 solver.cpp:237] Iteration 30000, loss = 1.36485
I0521 17:49:22.740819 12543 solver.cpp:253]     Train net output #0: loss = 1.36484 (* 1 = 1.36484 loss)
I0521 17:49:22.740836 12543 sgd_solver.cpp:106] Iteration 30000, lr = 0.004
I0521 17:49:39.691834 12543 solver.cpp:237] Iteration 31500, loss = 1.14351
I0521 17:49:39.691992 12543 solver.cpp:253]     Train net output #0: loss = 1.14351 (* 1 = 1.14351 loss)
I0521 17:49:39.692005 12543 sgd_solver.cpp:106] Iteration 31500, lr = 0.004
I0521 17:49:56.650048 12543 solver.cpp:237] Iteration 33000, loss = 1.104
I0521 17:49:56.650084 12543 solver.cpp:253]     Train net output #0: loss = 1.104 (* 1 = 1.104 loss)
I0521 17:49:56.650104 12543 sgd_solver.cpp:106] Iteration 33000, lr = 0.004
I0521 17:50:13.582094 12543 solver.cpp:237] Iteration 34500, loss = 1.30003
I0521 17:50:13.582244 12543 solver.cpp:253]     Train net output #0: loss = 1.30003 (* 1 = 1.30003 loss)
I0521 17:50:13.582259 12543 sgd_solver.cpp:106] Iteration 34500, lr = 0.004
I0521 17:50:30.548208 12543 solver.cpp:237] Iteration 36000, loss = 1.12195
I0521 17:50:30.548259 12543 solver.cpp:253]     Train net output #0: loss = 1.12195 (* 1 = 1.12195 loss)
I0521 17:50:30.548274 12543 sgd_solver.cpp:106] Iteration 36000, lr = 0.004
I0521 17:50:47.487351 12543 solver.cpp:237] Iteration 37500, loss = 1.54112
I0521 17:50:47.487489 12543 solver.cpp:253]     Train net output #0: loss = 1.54112 (* 1 = 1.54112 loss)
I0521 17:50:47.487505 12543 sgd_solver.cpp:106] Iteration 37500, lr = 0.004
I0521 17:51:04.446046 12543 solver.cpp:237] Iteration 39000, loss = 1.12844
I0521 17:51:04.446106 12543 solver.cpp:253]     Train net output #0: loss = 1.12844 (* 1 = 1.12844 loss)
I0521 17:51:04.446120 12543 sgd_solver.cpp:106] Iteration 39000, lr = 0.004
I0521 17:51:43.529949 12543 solver.cpp:237] Iteration 40500, loss = 1.78576
I0521 17:51:43.530118 12543 solver.cpp:253]     Train net output #0: loss = 1.78576 (* 1 = 1.78576 loss)
I0521 17:51:43.530133 12543 sgd_solver.cpp:106] Iteration 40500, lr = 0.004
I0521 17:52:00.479940 12543 solver.cpp:237] Iteration 42000, loss = 1.01624
I0521 17:52:00.479977 12543 solver.cpp:253]     Train net output #0: loss = 1.01624 (* 1 = 1.01624 loss)
I0521 17:52:00.479993 12543 sgd_solver.cpp:106] Iteration 42000, lr = 0.004
I0521 17:52:17.313778 12543 solver.cpp:237] Iteration 43500, loss = 1.56117
I0521 17:52:17.313946 12543 solver.cpp:253]     Train net output #0: loss = 1.56117 (* 1 = 1.56117 loss)
I0521 17:52:17.313961 12543 sgd_solver.cpp:106] Iteration 43500, lr = 0.004
I0521 17:52:34.057473 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_45000.caffemodel
I0521 17:52:34.105092 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_45000.solverstate
I0521 17:52:34.136682 12543 solver.cpp:237] Iteration 45000, loss = 0.823312
I0521 17:52:34.136735 12543 solver.cpp:253]     Train net output #0: loss = 0.823313 (* 1 = 0.823313 loss)
I0521 17:52:34.136750 12543 sgd_solver.cpp:106] Iteration 45000, lr = 0.004
I0521 17:52:50.911449 12543 solver.cpp:237] Iteration 46500, loss = 1.33212
I0521 17:52:50.911595 12543 solver.cpp:253]     Train net output #0: loss = 1.33213 (* 1 = 1.33213 loss)
I0521 17:52:50.911609 12543 sgd_solver.cpp:106] Iteration 46500, lr = 0.004
I0521 17:53:07.675103 12543 solver.cpp:237] Iteration 48000, loss = 1.41552
I0521 17:53:07.675156 12543 solver.cpp:253]     Train net output #0: loss = 1.41552 (* 1 = 1.41552 loss)
I0521 17:53:07.675173 12543 sgd_solver.cpp:106] Iteration 48000, lr = 0.004
I0521 17:53:24.524698 12543 solver.cpp:237] Iteration 49500, loss = 0.587288
I0521 17:53:24.524859 12543 solver.cpp:253]     Train net output #0: loss = 0.587289 (* 1 = 0.587289 loss)
I0521 17:53:24.524873 12543 sgd_solver.cpp:106] Iteration 49500, lr = 0.004
I0521 17:54:03.610915 12543 solver.cpp:237] Iteration 51000, loss = 1.02026
I0521 17:54:03.611076 12543 solver.cpp:253]     Train net output #0: loss = 1.02026 (* 1 = 1.02026 loss)
I0521 17:54:03.611091 12543 sgd_solver.cpp:106] Iteration 51000, lr = 0.004
I0521 17:54:20.567536 12543 solver.cpp:237] Iteration 52500, loss = 1.10185
I0521 17:54:20.567587 12543 solver.cpp:253]     Train net output #0: loss = 1.10185 (* 1 = 1.10185 loss)
I0521 17:54:20.567601 12543 sgd_solver.cpp:106] Iteration 52500, lr = 0.004
I0521 17:54:37.525290 12543 solver.cpp:237] Iteration 54000, loss = 1.30437
I0521 17:54:37.525442 12543 solver.cpp:253]     Train net output #0: loss = 1.30437 (* 1 = 1.30437 loss)
I0521 17:54:37.525456 12543 sgd_solver.cpp:106] Iteration 54000, lr = 0.004
I0521 17:54:54.481324 12543 solver.cpp:237] Iteration 55500, loss = 1.22478
I0521 17:54:54.481361 12543 solver.cpp:253]     Train net output #0: loss = 1.22478 (* 1 = 1.22478 loss)
I0521 17:54:54.481376 12543 sgd_solver.cpp:106] Iteration 55500, lr = 0.004
I0521 17:55:11.456504 12543 solver.cpp:237] Iteration 57000, loss = 1.28304
I0521 17:55:11.456645 12543 solver.cpp:253]     Train net output #0: loss = 1.28304 (* 1 = 1.28304 loss)
I0521 17:55:11.456660 12543 sgd_solver.cpp:106] Iteration 57000, lr = 0.004
I0521 17:55:28.404808 12543 solver.cpp:237] Iteration 58500, loss = 0.973125
I0521 17:55:28.404853 12543 solver.cpp:253]     Train net output #0: loss = 0.973123 (* 1 = 0.973123 loss)
I0521 17:55:28.404870 12543 sgd_solver.cpp:106] Iteration 58500, lr = 0.004
I0521 17:55:45.335806 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_60000.caffemodel
I0521 17:55:45.383033 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_60000.solverstate
I0521 17:55:45.411314 12543 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 17:57:05.618737 12543 solver.cpp:409]     Test net output #0: accuracy = 0.863876
I0521 17:57:05.618901 12543 solver.cpp:409]     Test net output #1: loss = 0.530386 (* 1 = 0.530386 loss)
I0521 17:57:27.976685 12543 solver.cpp:237] Iteration 60000, loss = 1.37823
I0521 17:57:27.976742 12543 solver.cpp:253]     Train net output #0: loss = 1.37823 (* 1 = 1.37823 loss)
I0521 17:57:27.976758 12543 sgd_solver.cpp:106] Iteration 60000, lr = 0.004
I0521 17:57:44.752467 12543 solver.cpp:237] Iteration 61500, loss = 0.89191
I0521 17:57:44.752647 12543 solver.cpp:253]     Train net output #0: loss = 0.891909 (* 1 = 0.891909 loss)
I0521 17:57:44.752662 12543 sgd_solver.cpp:106] Iteration 61500, lr = 0.004
I0521 17:58:01.542503 12543 solver.cpp:237] Iteration 63000, loss = 0.930321
I0521 17:58:01.542551 12543 solver.cpp:253]     Train net output #0: loss = 0.93032 (* 1 = 0.93032 loss)
I0521 17:58:01.542567 12543 sgd_solver.cpp:106] Iteration 63000, lr = 0.004
I0521 17:58:18.274180 12543 solver.cpp:237] Iteration 64500, loss = 1.64704
I0521 17:58:18.274322 12543 solver.cpp:253]     Train net output #0: loss = 1.64704 (* 1 = 1.64704 loss)
I0521 17:58:18.274335 12543 sgd_solver.cpp:106] Iteration 64500, lr = 0.004
I0521 17:58:35.039204 12543 solver.cpp:237] Iteration 66000, loss = 1.03525
I0521 17:58:35.039253 12543 solver.cpp:253]     Train net output #0: loss = 1.03525 (* 1 = 1.03525 loss)
I0521 17:58:35.039269 12543 sgd_solver.cpp:106] Iteration 66000, lr = 0.004
I0521 17:58:51.852040 12543 solver.cpp:237] Iteration 67500, loss = 0.800941
I0521 17:58:51.852193 12543 solver.cpp:253]     Train net output #0: loss = 0.800939 (* 1 = 0.800939 loss)
I0521 17:58:51.852207 12543 sgd_solver.cpp:106] Iteration 67500, lr = 0.004
I0521 17:59:08.624976 12543 solver.cpp:237] Iteration 69000, loss = 0.797435
I0521 17:59:08.625013 12543 solver.cpp:253]     Train net output #0: loss = 0.797433 (* 1 = 0.797433 loss)
I0521 17:59:08.625027 12543 sgd_solver.cpp:106] Iteration 69000, lr = 0.004
I0521 17:59:47.584648 12543 solver.cpp:237] Iteration 70500, loss = 1.29845
I0521 17:59:47.584811 12543 solver.cpp:253]     Train net output #0: loss = 1.29845 (* 1 = 1.29845 loss)
I0521 17:59:47.584825 12543 sgd_solver.cpp:106] Iteration 70500, lr = 0.004
I0521 18:00:04.333142 12543 solver.cpp:237] Iteration 72000, loss = 0.868487
I0521 18:00:04.333194 12543 solver.cpp:253]     Train net output #0: loss = 0.868486 (* 1 = 0.868486 loss)
I0521 18:00:04.333207 12543 sgd_solver.cpp:106] Iteration 72000, lr = 0.004
I0521 18:00:21.112304 12543 solver.cpp:237] Iteration 73500, loss = 0.894278
I0521 18:00:21.112447 12543 solver.cpp:253]     Train net output #0: loss = 0.894277 (* 1 = 0.894277 loss)
I0521 18:00:21.112459 12543 sgd_solver.cpp:106] Iteration 73500, lr = 0.004
I0521 18:00:37.866570 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_75000.caffemodel
I0521 18:00:37.914983 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_75000.solverstate
I0521 18:00:37.946775 12543 solver.cpp:237] Iteration 75000, loss = 1.09604
I0521 18:00:37.946828 12543 solver.cpp:253]     Train net output #0: loss = 1.09604 (* 1 = 1.09604 loss)
I0521 18:00:37.946844 12543 sgd_solver.cpp:106] Iteration 75000, lr = 0.004
I0521 18:00:54.704300 12543 solver.cpp:237] Iteration 76500, loss = 1.48315
I0521 18:00:54.704462 12543 solver.cpp:253]     Train net output #0: loss = 1.48315 (* 1 = 1.48315 loss)
I0521 18:00:54.704475 12543 sgd_solver.cpp:106] Iteration 76500, lr = 0.004
I0521 18:01:11.453790 12543 solver.cpp:237] Iteration 78000, loss = 1.05041
I0521 18:01:11.453827 12543 solver.cpp:253]     Train net output #0: loss = 1.05041 (* 1 = 1.05041 loss)
I0521 18:01:11.453841 12543 sgd_solver.cpp:106] Iteration 78000, lr = 0.004
I0521 18:01:28.226706 12543 solver.cpp:237] Iteration 79500, loss = 1.36744
I0521 18:01:28.226867 12543 solver.cpp:253]     Train net output #0: loss = 1.36744 (* 1 = 1.36744 loss)
I0521 18:01:28.226883 12543 sgd_solver.cpp:106] Iteration 79500, lr = 0.004
I0521 18:02:07.147972 12543 solver.cpp:237] Iteration 81000, loss = 1.01234
I0521 18:02:07.148165 12543 solver.cpp:253]     Train net output #0: loss = 1.01233 (* 1 = 1.01233 loss)
I0521 18:02:07.148180 12543 sgd_solver.cpp:106] Iteration 81000, lr = 0.004
I0521 18:02:23.920857 12543 solver.cpp:237] Iteration 82500, loss = 1.0851
I0521 18:02:23.920894 12543 solver.cpp:253]     Train net output #0: loss = 1.0851 (* 1 = 1.0851 loss)
I0521 18:02:23.920909 12543 sgd_solver.cpp:106] Iteration 82500, lr = 0.004
I0521 18:02:40.669826 12543 solver.cpp:237] Iteration 84000, loss = 0.983337
I0521 18:02:40.669983 12543 solver.cpp:253]     Train net output #0: loss = 0.983335 (* 1 = 0.983335 loss)
I0521 18:02:40.669998 12543 sgd_solver.cpp:106] Iteration 84000, lr = 0.004
I0521 18:02:57.422236 12543 solver.cpp:237] Iteration 85500, loss = 0.870863
I0521 18:02:57.422288 12543 solver.cpp:253]     Train net output #0: loss = 0.870862 (* 1 = 0.870862 loss)
I0521 18:02:57.422302 12543 sgd_solver.cpp:106] Iteration 85500, lr = 0.004
I0521 18:03:14.214257 12543 solver.cpp:237] Iteration 87000, loss = 0.878209
I0521 18:03:14.214401 12543 solver.cpp:253]     Train net output #0: loss = 0.878208 (* 1 = 0.878208 loss)
I0521 18:03:14.214416 12543 sgd_solver.cpp:106] Iteration 87000, lr = 0.004
I0521 18:03:30.991636 12543 solver.cpp:237] Iteration 88500, loss = 0.92487
I0521 18:03:30.991685 12543 solver.cpp:253]     Train net output #0: loss = 0.92487 (* 1 = 0.92487 loss)
I0521 18:03:30.991699 12543 sgd_solver.cpp:106] Iteration 88500, lr = 0.004
I0521 18:03:47.773058 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_90000.caffemodel
I0521 18:03:47.818548 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_90000.solverstate
I0521 18:03:47.844655 12543 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 18:04:46.875934 12543 solver.cpp:409]     Test net output #0: accuracy = 0.861663
I0521 18:04:46.876096 12543 solver.cpp:409]     Test net output #1: loss = 0.430545 (* 1 = 0.430545 loss)
I0521 18:05:09.030097 12543 solver.cpp:237] Iteration 90000, loss = 0.759126
I0521 18:05:09.030153 12543 solver.cpp:253]     Train net output #0: loss = 0.759125 (* 1 = 0.759125 loss)
I0521 18:05:09.030169 12543 sgd_solver.cpp:106] Iteration 90000, lr = 0.004
I0521 18:05:25.894040 12543 solver.cpp:237] Iteration 91500, loss = 1.10963
I0521 18:05:25.894199 12543 solver.cpp:253]     Train net output #0: loss = 1.10963 (* 1 = 1.10963 loss)
I0521 18:05:25.894214 12543 sgd_solver.cpp:106] Iteration 91500, lr = 0.004
I0521 18:05:42.800192 12543 solver.cpp:237] Iteration 93000, loss = 0.536118
I0521 18:05:42.800245 12543 solver.cpp:253]     Train net output #0: loss = 0.536118 (* 1 = 0.536118 loss)
I0521 18:05:42.800259 12543 sgd_solver.cpp:106] Iteration 93000, lr = 0.004
I0521 18:05:59.697829 12543 solver.cpp:237] Iteration 94500, loss = 1.64703
I0521 18:05:59.697986 12543 solver.cpp:253]     Train net output #0: loss = 1.64703 (* 1 = 1.64703 loss)
I0521 18:05:59.698001 12543 sgd_solver.cpp:106] Iteration 94500, lr = 0.004
I0521 18:06:16.549382 12543 solver.cpp:237] Iteration 96000, loss = 0.731086
I0521 18:06:16.549437 12543 solver.cpp:253]     Train net output #0: loss = 0.731086 (* 1 = 0.731086 loss)
I0521 18:06:16.549450 12543 sgd_solver.cpp:106] Iteration 96000, lr = 0.004
I0521 18:06:33.151118 12543 solver.cpp:237] Iteration 97500, loss = 1.32206
I0521 18:06:33.151264 12543 solver.cpp:253]     Train net output #0: loss = 1.32206 (* 1 = 1.32206 loss)
I0521 18:06:33.151278 12543 sgd_solver.cpp:106] Iteration 97500, lr = 0.004
I0521 18:06:49.751358 12543 solver.cpp:237] Iteration 99000, loss = 1.26461
I0521 18:06:49.751404 12543 solver.cpp:253]     Train net output #0: loss = 1.26461 (* 1 = 1.26461 loss)
I0521 18:06:49.751418 12543 sgd_solver.cpp:106] Iteration 99000, lr = 0.004
I0521 18:07:28.563194 12543 solver.cpp:237] Iteration 100500, loss = 1.3792
I0521 18:07:28.563376 12543 solver.cpp:253]     Train net output #0: loss = 1.3792 (* 1 = 1.3792 loss)
I0521 18:07:28.563390 12543 sgd_solver.cpp:106] Iteration 100500, lr = 0.004
I0521 18:07:45.188944 12543 solver.cpp:237] Iteration 102000, loss = 1.36874
I0521 18:07:45.188994 12543 solver.cpp:253]     Train net output #0: loss = 1.36874 (* 1 = 1.36874 loss)
I0521 18:07:45.189009 12543 sgd_solver.cpp:106] Iteration 102000, lr = 0.004
I0521 18:08:01.831812 12543 solver.cpp:237] Iteration 103500, loss = 1.02936
I0521 18:08:01.831975 12543 solver.cpp:253]     Train net output #0: loss = 1.02936 (* 1 = 1.02936 loss)
I0521 18:08:01.831990 12543 sgd_solver.cpp:106] Iteration 103500, lr = 0.004
I0521 18:08:18.438779 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_105000.caffemodel
I0521 18:08:18.488157 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_105000.solverstate
I0521 18:08:18.516692 12543 solver.cpp:237] Iteration 105000, loss = 1.63315
I0521 18:08:18.516741 12543 solver.cpp:253]     Train net output #0: loss = 1.63315 (* 1 = 1.63315 loss)
I0521 18:08:18.516754 12543 sgd_solver.cpp:106] Iteration 105000, lr = 0.004
I0521 18:08:35.142626 12543 solver.cpp:237] Iteration 106500, loss = 0.953442
I0521 18:08:35.142792 12543 solver.cpp:253]     Train net output #0: loss = 0.953442 (* 1 = 0.953442 loss)
I0521 18:08:35.142808 12543 sgd_solver.cpp:106] Iteration 106500, lr = 0.004
I0521 18:08:51.778555 12543 solver.cpp:237] Iteration 108000, loss = 0.998628
I0521 18:08:51.778606 12543 solver.cpp:253]     Train net output #0: loss = 0.998629 (* 1 = 0.998629 loss)
I0521 18:08:51.778622 12543 sgd_solver.cpp:106] Iteration 108000, lr = 0.004
I0521 18:09:08.405288 12543 solver.cpp:237] Iteration 109500, loss = 1.16305
I0521 18:09:08.405441 12543 solver.cpp:253]     Train net output #0: loss = 1.16305 (* 1 = 1.16305 loss)
I0521 18:09:08.405455 12543 sgd_solver.cpp:106] Iteration 109500, lr = 0.004
I0521 18:09:47.189779 12543 solver.cpp:237] Iteration 111000, loss = 1.73142
I0521 18:09:47.189961 12543 solver.cpp:253]     Train net output #0: loss = 1.73143 (* 1 = 1.73143 loss)
I0521 18:09:47.189977 12543 sgd_solver.cpp:106] Iteration 111000, lr = 0.004
I0521 18:10:03.772105 12543 solver.cpp:237] Iteration 112500, loss = 3.7364
I0521 18:10:03.772159 12543 solver.cpp:253]     Train net output #0: loss = 3.73641 (* 1 = 3.73641 loss)
I0521 18:10:03.772173 12543 sgd_solver.cpp:106] Iteration 112500, lr = 0.004
I0521 18:10:20.398824 12543 solver.cpp:237] Iteration 114000, loss = 1.73305
I0521 18:10:20.398970 12543 solver.cpp:253]     Train net output #0: loss = 1.73305 (* 1 = 1.73305 loss)
I0521 18:10:20.398983 12543 sgd_solver.cpp:106] Iteration 114000, lr = 0.004
I0521 18:10:37.042795 12543 solver.cpp:237] Iteration 115500, loss = 0.697137
I0521 18:10:37.042845 12543 solver.cpp:253]     Train net output #0: loss = 0.69714 (* 1 = 0.69714 loss)
I0521 18:10:37.042860 12543 sgd_solver.cpp:106] Iteration 115500, lr = 0.004
I0521 18:10:53.629577 12543 solver.cpp:237] Iteration 117000, loss = 1.4167
I0521 18:10:53.629732 12543 solver.cpp:253]     Train net output #0: loss = 1.4167 (* 1 = 1.4167 loss)
I0521 18:10:53.629746 12543 sgd_solver.cpp:106] Iteration 117000, lr = 0.004
I0521 18:11:10.253183 12543 solver.cpp:237] Iteration 118500, loss = 1.51736
I0521 18:11:10.253219 12543 solver.cpp:253]     Train net output #0: loss = 1.51736 (* 1 = 1.51736 loss)
I0521 18:11:10.253237 12543 sgd_solver.cpp:106] Iteration 118500, lr = 0.004
I0521 18:11:26.875885 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_120000.caffemodel
I0521 18:11:26.922022 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_120000.solverstate
I0521 18:11:26.946852 12543 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 18:12:47.021158 12543 solver.cpp:409]     Test net output #0: accuracy = 0.872763
I0521 18:12:47.021345 12543 solver.cpp:409]     Test net output #1: loss = 0.428297 (* 1 = 0.428297 loss)
I0521 18:13:09.134250 12543 solver.cpp:237] Iteration 120000, loss = 2.2141
I0521 18:13:09.134306 12543 solver.cpp:253]     Train net output #0: loss = 2.2141 (* 1 = 2.2141 loss)
I0521 18:13:09.134320 12543 sgd_solver.cpp:106] Iteration 120000, lr = 0.004
I0521 18:13:26.091078 12543 solver.cpp:237] Iteration 121500, loss = 1.60778
I0521 18:13:26.091246 12543 solver.cpp:253]     Train net output #0: loss = 1.60778 (* 1 = 1.60778 loss)
I0521 18:13:26.091260 12543 sgd_solver.cpp:106] Iteration 121500, lr = 0.004
I0521 18:13:43.065738 12543 solver.cpp:237] Iteration 123000, loss = 1.39095
I0521 18:13:43.065775 12543 solver.cpp:253]     Train net output #0: loss = 1.39095 (* 1 = 1.39095 loss)
I0521 18:13:43.065791 12543 sgd_solver.cpp:106] Iteration 123000, lr = 0.004
I0521 18:14:00.026937 12543 solver.cpp:237] Iteration 124500, loss = 0.529738
I0521 18:14:00.027101 12543 solver.cpp:253]     Train net output #0: loss = 0.529742 (* 1 = 0.529742 loss)
I0521 18:14:00.027117 12543 sgd_solver.cpp:106] Iteration 124500, lr = 0.004
I0521 18:14:16.995648 12543 solver.cpp:237] Iteration 126000, loss = 0.598809
I0521 18:14:16.995697 12543 solver.cpp:253]     Train net output #0: loss = 0.598813 (* 1 = 0.598813 loss)
I0521 18:14:16.995712 12543 sgd_solver.cpp:106] Iteration 126000, lr = 0.004
I0521 18:14:33.957672 12543 solver.cpp:237] Iteration 127500, loss = 1.12144
I0521 18:14:33.957815 12543 solver.cpp:253]     Train net output #0: loss = 1.12144 (* 1 = 1.12144 loss)
I0521 18:14:33.957830 12543 sgd_solver.cpp:106] Iteration 127500, lr = 0.004
I0521 18:14:50.936338 12543 solver.cpp:237] Iteration 129000, loss = 1.44532
I0521 18:14:50.936385 12543 solver.cpp:253]     Train net output #0: loss = 1.44533 (* 1 = 1.44533 loss)
I0521 18:14:50.936401 12543 sgd_solver.cpp:106] Iteration 129000, lr = 0.004
I0521 18:15:30.031229 12543 solver.cpp:237] Iteration 130500, loss = 1.13049
I0521 18:15:30.031399 12543 solver.cpp:253]     Train net output #0: loss = 1.13049 (* 1 = 1.13049 loss)
I0521 18:15:30.031414 12543 sgd_solver.cpp:106] Iteration 130500, lr = 0.004
I0521 18:15:46.965878 12543 solver.cpp:237] Iteration 132000, loss = 1.14832
I0521 18:15:46.965914 12543 solver.cpp:253]     Train net output #0: loss = 1.14832 (* 1 = 1.14832 loss)
I0521 18:15:46.965929 12543 sgd_solver.cpp:106] Iteration 132000, lr = 0.004
I0521 18:16:03.930196 12543 solver.cpp:237] Iteration 133500, loss = 1.53682
I0521 18:16:03.930348 12543 solver.cpp:253]     Train net output #0: loss = 1.53683 (* 1 = 1.53683 loss)
I0521 18:16:03.930362 12543 sgd_solver.cpp:106] Iteration 133500, lr = 0.004
I0521 18:16:20.914604 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_135000.caffemodel
I0521 18:16:20.962508 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_135000.solverstate
I0521 18:16:20.993059 12543 solver.cpp:237] Iteration 135000, loss = 2.30434
I0521 18:16:20.993109 12543 solver.cpp:253]     Train net output #0: loss = 2.30434 (* 1 = 2.30434 loss)
I0521 18:16:20.993124 12543 sgd_solver.cpp:106] Iteration 135000, lr = 0.004
I0521 18:16:37.969560 12543 solver.cpp:237] Iteration 136500, loss = 1.36478
I0521 18:16:37.969712 12543 solver.cpp:253]     Train net output #0: loss = 1.36478 (* 1 = 1.36478 loss)
I0521 18:16:37.969727 12543 sgd_solver.cpp:106] Iteration 136500, lr = 0.004
I0521 18:16:54.923997 12543 solver.cpp:237] Iteration 138000, loss = 2.42957
I0521 18:16:54.924054 12543 solver.cpp:253]     Train net output #0: loss = 2.42957 (* 1 = 2.42957 loss)
I0521 18:16:54.924068 12543 sgd_solver.cpp:106] Iteration 138000, lr = 0.004
I0521 18:17:11.882107 12543 solver.cpp:237] Iteration 139500, loss = 1.56798
I0521 18:17:11.882283 12543 solver.cpp:253]     Train net output #0: loss = 1.56798 (* 1 = 1.56798 loss)
I0521 18:17:11.882297 12543 sgd_solver.cpp:106] Iteration 139500, lr = 0.004
I0521 18:17:51.019008 12543 solver.cpp:237] Iteration 141000, loss = 0.799666
I0521 18:17:51.019184 12543 solver.cpp:253]     Train net output #0: loss = 0.799668 (* 1 = 0.799668 loss)
I0521 18:17:51.019199 12543 sgd_solver.cpp:106] Iteration 141000, lr = 0.004
I0521 18:18:07.962373 12543 solver.cpp:237] Iteration 142500, loss = 1.171
I0521 18:18:07.962424 12543 solver.cpp:253]     Train net output #0: loss = 1.171 (* 1 = 1.171 loss)
I0521 18:18:07.962436 12543 sgd_solver.cpp:106] Iteration 142500, lr = 0.004
I0521 18:18:24.924491 12543 solver.cpp:237] Iteration 144000, loss = 1.77376
I0521 18:18:24.924646 12543 solver.cpp:253]     Train net output #0: loss = 1.77376 (* 1 = 1.77376 loss)
I0521 18:18:24.924660 12543 sgd_solver.cpp:106] Iteration 144000, lr = 0.004
I0521 18:18:41.881467 12543 solver.cpp:237] Iteration 145500, loss = 1.22425
I0521 18:18:41.881505 12543 solver.cpp:253]     Train net output #0: loss = 1.22426 (* 1 = 1.22426 loss)
I0521 18:18:41.881521 12543 sgd_solver.cpp:106] Iteration 145500, lr = 0.004
I0521 18:18:58.847138 12543 solver.cpp:237] Iteration 147000, loss = 1.27579
I0521 18:18:58.847301 12543 solver.cpp:253]     Train net output #0: loss = 1.27579 (* 1 = 1.27579 loss)
I0521 18:18:58.847317 12543 sgd_solver.cpp:106] Iteration 147000, lr = 0.004
I0521 18:19:15.786463 12543 solver.cpp:237] Iteration 148500, loss = 1.20631
I0521 18:19:15.786509 12543 solver.cpp:253]     Train net output #0: loss = 1.20631 (* 1 = 1.20631 loss)
I0521 18:19:15.786527 12543 sgd_solver.cpp:106] Iteration 148500, lr = 0.004
I0521 18:19:32.710121 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_150000.caffemodel
I0521 18:19:32.758381 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_150000.solverstate
I0521 18:19:32.785711 12543 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 18:20:32.155616 12543 solver.cpp:409]     Test net output #0: accuracy = 0.876766
I0521 18:20:32.155786 12543 solver.cpp:409]     Test net output #1: loss = 0.409206 (* 1 = 0.409206 loss)
I0521 18:20:53.064924 12543 solver.cpp:237] Iteration 150000, loss = 1.48362
I0521 18:20:53.064978 12543 solver.cpp:253]     Train net output #0: loss = 1.48362 (* 1 = 1.48362 loss)
I0521 18:20:53.064996 12543 sgd_solver.cpp:106] Iteration 150000, lr = 0.004
I0521 18:21:09.939136 12543 solver.cpp:237] Iteration 151500, loss = 1.08158
I0521 18:21:09.939290 12543 solver.cpp:253]     Train net output #0: loss = 1.08158 (* 1 = 1.08158 loss)
I0521 18:21:09.939302 12543 sgd_solver.cpp:106] Iteration 151500, lr = 0.004
I0521 18:21:26.815661 12543 solver.cpp:237] Iteration 153000, loss = 1.75549
I0521 18:21:26.815712 12543 solver.cpp:253]     Train net output #0: loss = 1.7555 (* 1 = 1.7555 loss)
I0521 18:21:26.815726 12543 sgd_solver.cpp:106] Iteration 153000, lr = 0.004
I0521 18:21:43.640702 12543 solver.cpp:237] Iteration 154500, loss = 1.22858
I0521 18:21:43.640866 12543 solver.cpp:253]     Train net output #0: loss = 1.22858 (* 1 = 1.22858 loss)
I0521 18:21:43.640882 12543 sgd_solver.cpp:106] Iteration 154500, lr = 0.004
I0521 18:22:00.490294 12543 solver.cpp:237] Iteration 156000, loss = 1.49342
I0521 18:22:00.490331 12543 solver.cpp:253]     Train net output #0: loss = 1.49342 (* 1 = 1.49342 loss)
I0521 18:22:00.490347 12543 sgd_solver.cpp:106] Iteration 156000, lr = 0.004
I0521 18:22:17.303756 12543 solver.cpp:237] Iteration 157500, loss = 1.08255
I0521 18:22:17.303928 12543 solver.cpp:253]     Train net output #0: loss = 1.08256 (* 1 = 1.08256 loss)
I0521 18:22:17.303944 12543 sgd_solver.cpp:106] Iteration 157500, lr = 0.004
I0521 18:22:34.084007 12543 solver.cpp:237] Iteration 159000, loss = 1.98692
I0521 18:22:34.084055 12543 solver.cpp:253]     Train net output #0: loss = 1.98692 (* 1 = 1.98692 loss)
I0521 18:22:34.084072 12543 sgd_solver.cpp:106] Iteration 159000, lr = 0.004
I0521 18:23:11.718014 12543 solver.cpp:237] Iteration 160500, loss = 1.13297
I0521 18:23:11.718188 12543 solver.cpp:253]     Train net output #0: loss = 1.13297 (* 1 = 1.13297 loss)
I0521 18:23:11.718201 12543 sgd_solver.cpp:106] Iteration 160500, lr = 0.004
I0521 18:23:28.503556 12543 solver.cpp:237] Iteration 162000, loss = 1.88514
I0521 18:23:28.503607 12543 solver.cpp:253]     Train net output #0: loss = 1.88514 (* 1 = 1.88514 loss)
I0521 18:23:28.503623 12543 sgd_solver.cpp:106] Iteration 162000, lr = 0.004
I0521 18:23:45.261420 12543 solver.cpp:237] Iteration 163500, loss = 1.11405
I0521 18:23:45.261566 12543 solver.cpp:253]     Train net output #0: loss = 1.11406 (* 1 = 1.11406 loss)
I0521 18:23:45.261580 12543 sgd_solver.cpp:106] Iteration 163500, lr = 0.004
I0521 18:24:02.031651 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_165000.caffemodel
I0521 18:24:02.076779 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_165000.solverstate
I0521 18:24:02.105142 12543 solver.cpp:237] Iteration 165000, loss = 0.966292
I0521 18:24:02.105193 12543 solver.cpp:253]     Train net output #0: loss = 0.966295 (* 1 = 0.966295 loss)
I0521 18:24:02.105208 12543 sgd_solver.cpp:106] Iteration 165000, lr = 0.004
I0521 18:24:18.910706 12543 solver.cpp:237] Iteration 166500, loss = 1.55403
I0521 18:24:18.910876 12543 solver.cpp:253]     Train net output #0: loss = 1.55404 (* 1 = 1.55404 loss)
I0521 18:24:18.910890 12543 sgd_solver.cpp:106] Iteration 166500, lr = 0.004
I0521 18:24:35.874730 12543 solver.cpp:237] Iteration 168000, loss = 0.929537
I0521 18:24:35.874768 12543 solver.cpp:253]     Train net output #0: loss = 0.92954 (* 1 = 0.92954 loss)
I0521 18:24:35.874785 12543 sgd_solver.cpp:106] Iteration 168000, lr = 0.004
I0521 18:24:52.833967 12543 solver.cpp:237] Iteration 169500, loss = 1.23953
I0521 18:24:52.834127 12543 solver.cpp:253]     Train net output #0: loss = 1.23953 (* 1 = 1.23953 loss)
I0521 18:24:52.834143 12543 sgd_solver.cpp:106] Iteration 169500, lr = 0.004
I0521 18:25:30.658891 12543 solver.cpp:237] Iteration 171000, loss = 1.20897
I0521 18:25:30.659065 12543 solver.cpp:253]     Train net output #0: loss = 1.20897 (* 1 = 1.20897 loss)
I0521 18:25:30.659078 12543 sgd_solver.cpp:106] Iteration 171000, lr = 0.004
I0521 18:25:47.601997 12543 solver.cpp:237] Iteration 172500, loss = 0.707364
I0521 18:25:47.602035 12543 solver.cpp:253]     Train net output #0: loss = 0.707366 (* 1 = 0.707366 loss)
I0521 18:25:47.602048 12543 sgd_solver.cpp:106] Iteration 172500, lr = 0.004
I0521 18:26:04.541966 12543 solver.cpp:237] Iteration 174000, loss = 1.35421
I0521 18:26:04.542140 12543 solver.cpp:253]     Train net output #0: loss = 1.35421 (* 1 = 1.35421 loss)
I0521 18:26:04.542155 12543 sgd_solver.cpp:106] Iteration 174000, lr = 0.004
I0521 18:26:21.492727 12543 solver.cpp:237] Iteration 175500, loss = 0.95353
I0521 18:26:21.492780 12543 solver.cpp:253]     Train net output #0: loss = 0.953531 (* 1 = 0.953531 loss)
I0521 18:26:21.492794 12543 sgd_solver.cpp:106] Iteration 175500, lr = 0.004
I0521 18:26:38.484170 12543 solver.cpp:237] Iteration 177000, loss = 1.35503
I0521 18:26:38.484320 12543 solver.cpp:253]     Train net output #0: loss = 1.35503 (* 1 = 1.35503 loss)
I0521 18:26:38.484333 12543 sgd_solver.cpp:106] Iteration 177000, lr = 0.004
I0521 18:26:55.149302 12543 solver.cpp:237] Iteration 178500, loss = 1.0639
I0521 18:26:55.149348 12543 solver.cpp:253]     Train net output #0: loss = 1.06391 (* 1 = 1.06391 loss)
I0521 18:26:55.149364 12543 sgd_solver.cpp:106] Iteration 178500, lr = 0.004
I0521 18:27:11.752496 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_180000.caffemodel
I0521 18:27:11.797842 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_180000.solverstate
I0521 18:27:11.822706 12543 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 18:28:31.872462 12543 solver.cpp:409]     Test net output #0: accuracy = 0.883699
I0521 18:28:31.872633 12543 solver.cpp:409]     Test net output #1: loss = 0.395971 (* 1 = 0.395971 loss)
I0521 18:28:52.769577 12543 solver.cpp:237] Iteration 180000, loss = 1.05313
I0521 18:28:52.769634 12543 solver.cpp:253]     Train net output #0: loss = 1.05313 (* 1 = 1.05313 loss)
I0521 18:28:52.769650 12543 sgd_solver.cpp:106] Iteration 180000, lr = 0.004
I0521 18:29:09.545013 12543 solver.cpp:237] Iteration 181500, loss = 1.54565
I0521 18:29:09.545173 12543 solver.cpp:253]     Train net output #0: loss = 1.54566 (* 1 = 1.54566 loss)
I0521 18:29:09.545187 12543 sgd_solver.cpp:106] Iteration 181500, lr = 0.004
I0521 18:29:26.331959 12543 solver.cpp:237] Iteration 183000, loss = 1.09058
I0521 18:29:26.332010 12543 solver.cpp:253]     Train net output #0: loss = 1.09058 (* 1 = 1.09058 loss)
I0521 18:29:26.332025 12543 sgd_solver.cpp:106] Iteration 183000, lr = 0.004
I0521 18:29:43.120646 12543 solver.cpp:237] Iteration 184500, loss = 1.0273
I0521 18:29:43.120813 12543 solver.cpp:253]     Train net output #0: loss = 1.02731 (* 1 = 1.02731 loss)
I0521 18:29:43.120828 12543 sgd_solver.cpp:106] Iteration 184500, lr = 0.004
I0521 18:29:59.866580 12543 solver.cpp:237] Iteration 186000, loss = 1.44418
I0521 18:29:59.866611 12543 solver.cpp:253]     Train net output #0: loss = 1.44418 (* 1 = 1.44418 loss)
I0521 18:29:59.866632 12543 sgd_solver.cpp:106] Iteration 186000, lr = 0.004
I0521 18:30:16.649679 12543 solver.cpp:237] Iteration 187500, loss = 1.47402
I0521 18:30:16.649837 12543 solver.cpp:253]     Train net output #0: loss = 1.47402 (* 1 = 1.47402 loss)
I0521 18:30:16.649849 12543 sgd_solver.cpp:106] Iteration 187500, lr = 0.004
I0521 18:30:33.421608 12543 solver.cpp:237] Iteration 189000, loss = 0.791861
I0521 18:30:33.421651 12543 solver.cpp:253]     Train net output #0: loss = 0.791863 (* 1 = 0.791863 loss)
I0521 18:30:33.421674 12543 sgd_solver.cpp:106] Iteration 189000, lr = 0.004
I0521 18:31:11.098080 12543 solver.cpp:237] Iteration 190500, loss = 1.24619
I0521 18:31:11.098260 12543 solver.cpp:253]     Train net output #0: loss = 1.2462 (* 1 = 1.2462 loss)
I0521 18:31:11.098274 12543 sgd_solver.cpp:106] Iteration 190500, lr = 0.004
I0521 18:31:27.865094 12543 solver.cpp:237] Iteration 192000, loss = 1.30885
I0521 18:31:27.865139 12543 solver.cpp:253]     Train net output #0: loss = 1.30885 (* 1 = 1.30885 loss)
I0521 18:31:27.865154 12543 sgd_solver.cpp:106] Iteration 192000, lr = 0.004
I0521 18:31:44.635522 12543 solver.cpp:237] Iteration 193500, loss = 1.07148
I0521 18:31:44.635679 12543 solver.cpp:253]     Train net output #0: loss = 1.07148 (* 1 = 1.07148 loss)
I0521 18:31:44.635694 12543 sgd_solver.cpp:106] Iteration 193500, lr = 0.004
I0521 18:32:01.374071 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_195000.caffemodel
I0521 18:32:01.419554 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_195000.solverstate
I0521 18:32:01.447767 12543 solver.cpp:237] Iteration 195000, loss = 1.18322
I0521 18:32:01.447814 12543 solver.cpp:253]     Train net output #0: loss = 1.18322 (* 1 = 1.18322 loss)
I0521 18:32:01.447832 12543 sgd_solver.cpp:106] Iteration 195000, lr = 0.004
I0521 18:32:18.116539 12543 solver.cpp:237] Iteration 196500, loss = 1.51264
I0521 18:32:18.116719 12543 solver.cpp:253]     Train net output #0: loss = 1.51265 (* 1 = 1.51265 loss)
I0521 18:32:18.116734 12543 sgd_solver.cpp:106] Iteration 196500, lr = 0.004
I0521 18:32:34.729872 12543 solver.cpp:237] Iteration 198000, loss = 1.53024
I0521 18:32:34.729923 12543 solver.cpp:253]     Train net output #0: loss = 1.53025 (* 1 = 1.53025 loss)
I0521 18:32:34.729939 12543 sgd_solver.cpp:106] Iteration 198000, lr = 0.004
I0521 18:32:51.321066 12543 solver.cpp:237] Iteration 199500, loss = 0.620073
I0521 18:32:51.321218 12543 solver.cpp:253]     Train net output #0: loss = 0.620077 (* 1 = 0.620077 loss)
I0521 18:32:51.321233 12543 sgd_solver.cpp:106] Iteration 199500, lr = 0.004
I0521 18:33:28.987609 12543 solver.cpp:237] Iteration 201000, loss = 1.01799
I0521 18:33:28.987787 12543 solver.cpp:253]     Train net output #0: loss = 1.01799 (* 1 = 1.01799 loss)
I0521 18:33:28.987800 12543 sgd_solver.cpp:106] Iteration 201000, lr = 0.004
I0521 18:33:45.824941 12543 solver.cpp:237] Iteration 202500, loss = 0.938111
I0521 18:33:45.824978 12543 solver.cpp:253]     Train net output #0: loss = 0.938116 (* 1 = 0.938116 loss)
I0521 18:33:45.824992 12543 sgd_solver.cpp:106] Iteration 202500, lr = 0.004
I0521 18:34:02.700292 12543 solver.cpp:237] Iteration 204000, loss = 0.656664
I0521 18:34:02.700456 12543 solver.cpp:253]     Train net output #0: loss = 0.656669 (* 1 = 0.656669 loss)
I0521 18:34:02.700470 12543 sgd_solver.cpp:106] Iteration 204000, lr = 0.004
I0521 18:34:19.561275 12543 solver.cpp:237] Iteration 205500, loss = 0.85845
I0521 18:34:19.561324 12543 solver.cpp:253]     Train net output #0: loss = 0.858454 (* 1 = 0.858454 loss)
I0521 18:34:19.561341 12543 sgd_solver.cpp:106] Iteration 205500, lr = 0.004
I0521 18:34:36.429514 12543 solver.cpp:237] Iteration 207000, loss = 1.38544
I0521 18:34:36.429678 12543 solver.cpp:253]     Train net output #0: loss = 1.38544 (* 1 = 1.38544 loss)
I0521 18:34:36.429692 12543 sgd_solver.cpp:106] Iteration 207000, lr = 0.004
I0521 18:34:53.288517 12543 solver.cpp:237] Iteration 208500, loss = 0.566869
I0521 18:34:53.288553 12543 solver.cpp:253]     Train net output #0: loss = 0.566874 (* 1 = 0.566874 loss)
I0521 18:34:53.288573 12543 sgd_solver.cpp:106] Iteration 208500, lr = 0.004
I0521 18:35:10.047724 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_210000.caffemodel
I0521 18:35:10.093080 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_210000.solverstate
I0521 18:35:10.117982 12543 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 18:36:09.447161 12543 solver.cpp:409]     Test net output #0: accuracy = 0.878902
I0521 18:36:09.447342 12543 solver.cpp:409]     Test net output #1: loss = 0.445858 (* 1 = 0.445858 loss)
I0521 18:36:30.334080 12543 solver.cpp:237] Iteration 210000, loss = 1.3156
I0521 18:36:30.334141 12543 solver.cpp:253]     Train net output #0: loss = 1.31561 (* 1 = 1.31561 loss)
I0521 18:36:30.334161 12543 sgd_solver.cpp:106] Iteration 210000, lr = 0.004
I0521 18:36:47.096276 12543 solver.cpp:237] Iteration 211500, loss = 1.26045
I0521 18:36:47.096444 12543 solver.cpp:253]     Train net output #0: loss = 1.26046 (* 1 = 1.26046 loss)
I0521 18:36:47.096458 12543 sgd_solver.cpp:106] Iteration 211500, lr = 0.004
I0521 18:37:03.871532 12543 solver.cpp:237] Iteration 213000, loss = 0.81828
I0521 18:37:03.871568 12543 solver.cpp:253]     Train net output #0: loss = 0.818283 (* 1 = 0.818283 loss)
I0521 18:37:03.871587 12543 sgd_solver.cpp:106] Iteration 213000, lr = 0.004
I0521 18:37:20.647446 12543 solver.cpp:237] Iteration 214500, loss = 1.64588
I0521 18:37:20.647613 12543 solver.cpp:253]     Train net output #0: loss = 1.64588 (* 1 = 1.64588 loss)
I0521 18:37:20.647627 12543 sgd_solver.cpp:106] Iteration 214500, lr = 0.004
I0521 18:37:37.451279 12543 solver.cpp:237] Iteration 216000, loss = 1.11693
I0521 18:37:37.451330 12543 solver.cpp:253]     Train net output #0: loss = 1.11693 (* 1 = 1.11693 loss)
I0521 18:37:37.451344 12543 sgd_solver.cpp:106] Iteration 216000, lr = 0.004
I0521 18:37:54.257926 12543 solver.cpp:237] Iteration 217500, loss = 0.82794
I0521 18:37:54.258102 12543 solver.cpp:253]     Train net output #0: loss = 0.827941 (* 1 = 0.827941 loss)
I0521 18:37:54.258116 12543 sgd_solver.cpp:106] Iteration 217500, lr = 0.004
I0521 18:38:11.049569 12543 solver.cpp:237] Iteration 219000, loss = 0.950526
I0521 18:38:11.049618 12543 solver.cpp:253]     Train net output #0: loss = 0.950527 (* 1 = 0.950527 loss)
I0521 18:38:11.049635 12543 sgd_solver.cpp:106] Iteration 219000, lr = 0.004
I0521 18:38:48.682147 12543 solver.cpp:237] Iteration 220500, loss = 1.80098
I0521 18:38:48.682327 12543 solver.cpp:253]     Train net output #0: loss = 1.80098 (* 1 = 1.80098 loss)
I0521 18:38:48.682342 12543 sgd_solver.cpp:106] Iteration 220500, lr = 0.004
I0521 18:39:05.318480 12543 solver.cpp:237] Iteration 222000, loss = 1.81789
I0521 18:39:05.318511 12543 solver.cpp:253]     Train net output #0: loss = 1.81789 (* 1 = 1.81789 loss)
I0521 18:39:05.318528 12543 sgd_solver.cpp:106] Iteration 222000, lr = 0.004
I0521 18:39:21.922463 12543 solver.cpp:237] Iteration 223500, loss = 1.05952
I0521 18:39:21.922627 12543 solver.cpp:253]     Train net output #0: loss = 1.05953 (* 1 = 1.05953 loss)
I0521 18:39:21.922641 12543 sgd_solver.cpp:106] Iteration 223500, lr = 0.004
I0521 18:39:38.513804 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_225000.caffemodel
I0521 18:39:38.561211 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_225000.solverstate
I0521 18:39:38.591756 12543 solver.cpp:237] Iteration 225000, loss = 0.942306
I0521 18:39:38.591810 12543 solver.cpp:253]     Train net output #0: loss = 0.942307 (* 1 = 0.942307 loss)
I0521 18:39:38.591827 12543 sgd_solver.cpp:106] Iteration 225000, lr = 0.004
I0521 18:39:55.183938 12543 solver.cpp:237] Iteration 226500, loss = 1.83965
I0521 18:39:55.184097 12543 solver.cpp:253]     Train net output #0: loss = 1.83965 (* 1 = 1.83965 loss)
I0521 18:39:55.184109 12543 sgd_solver.cpp:106] Iteration 226500, lr = 0.004
I0521 18:40:11.787995 12543 solver.cpp:237] Iteration 228000, loss = 1.56775
I0521 18:40:11.788043 12543 solver.cpp:253]     Train net output #0: loss = 1.56775 (* 1 = 1.56775 loss)
I0521 18:40:11.788063 12543 sgd_solver.cpp:106] Iteration 228000, lr = 0.004
I0521 18:40:28.433511 12543 solver.cpp:237] Iteration 229500, loss = 1.32589
I0521 18:40:28.433688 12543 solver.cpp:253]     Train net output #0: loss = 1.32589 (* 1 = 1.32589 loss)
I0521 18:40:28.433703 12543 sgd_solver.cpp:106] Iteration 229500, lr = 0.004
I0521 18:41:06.093873 12543 solver.cpp:237] Iteration 231000, loss = 1.01676
I0521 18:41:06.094049 12543 solver.cpp:253]     Train net output #0: loss = 1.01676 (* 1 = 1.01676 loss)
I0521 18:41:06.094063 12543 sgd_solver.cpp:106] Iteration 231000, lr = 0.004
I0521 18:41:22.882104 12543 solver.cpp:237] Iteration 232500, loss = 0.590694
I0521 18:41:22.882150 12543 solver.cpp:253]     Train net output #0: loss = 0.590695 (* 1 = 0.590695 loss)
I0521 18:41:22.882170 12543 sgd_solver.cpp:106] Iteration 232500, lr = 0.004
I0521 18:41:39.639930 12543 solver.cpp:237] Iteration 234000, loss = 0.95206
I0521 18:41:39.640079 12543 solver.cpp:253]     Train net output #0: loss = 0.952063 (* 1 = 0.952063 loss)
I0521 18:41:39.640094 12543 sgd_solver.cpp:106] Iteration 234000, lr = 0.004
I0521 18:41:56.412374 12543 solver.cpp:237] Iteration 235500, loss = 1.21812
I0521 18:41:56.412423 12543 solver.cpp:253]     Train net output #0: loss = 1.21812 (* 1 = 1.21812 loss)
I0521 18:41:56.412442 12543 sgd_solver.cpp:106] Iteration 235500, lr = 0.004
I0521 18:42:13.179172 12543 solver.cpp:237] Iteration 237000, loss = 1.09564
I0521 18:42:13.179348 12543 solver.cpp:253]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0521 18:42:13.179363 12543 sgd_solver.cpp:106] Iteration 237000, lr = 0.004
I0521 18:42:29.960721 12543 solver.cpp:237] Iteration 238500, loss = 0.6713
I0521 18:42:29.960752 12543 solver.cpp:253]     Train net output #0: loss = 0.671302 (* 1 = 0.671302 loss)
I0521 18:42:29.960775 12543 sgd_solver.cpp:106] Iteration 238500, lr = 0.004
I0521 18:42:46.729105 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_240000.caffemodel
I0521 18:42:46.775110 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_240000.solverstate
I0521 18:42:46.800074 12543 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 18:44:07.040725 12543 solver.cpp:409]     Test net output #0: accuracy = 0.886322
I0521 18:44:07.040904 12543 solver.cpp:409]     Test net output #1: loss = 0.389789 (* 1 = 0.389789 loss)
I0521 18:44:27.936544 12543 solver.cpp:237] Iteration 240000, loss = 0.656734
I0521 18:44:27.936602 12543 solver.cpp:253]     Train net output #0: loss = 0.656737 (* 1 = 0.656737 loss)
I0521 18:44:27.936619 12543 sgd_solver.cpp:106] Iteration 240000, lr = 0.004
I0521 18:44:45.135356 12543 solver.cpp:237] Iteration 241500, loss = 0.585598
I0521 18:44:45.135529 12543 solver.cpp:253]     Train net output #0: loss = 0.585601 (* 1 = 0.585601 loss)
I0521 18:44:45.135542 12543 sgd_solver.cpp:106] Iteration 241500, lr = 0.004
I0521 18:45:02.310515 12543 solver.cpp:237] Iteration 243000, loss = 1.5032
I0521 18:45:02.310565 12543 solver.cpp:253]     Train net output #0: loss = 1.5032 (* 1 = 1.5032 loss)
I0521 18:45:02.310582 12543 sgd_solver.cpp:106] Iteration 243000, lr = 0.004
I0521 18:45:19.468963 12543 solver.cpp:237] Iteration 244500, loss = 1.53402
I0521 18:45:19.469118 12543 solver.cpp:253]     Train net output #0: loss = 1.53403 (* 1 = 1.53403 loss)
I0521 18:45:19.469131 12543 sgd_solver.cpp:106] Iteration 244500, lr = 0.004
I0521 18:45:36.619086 12543 solver.cpp:237] Iteration 246000, loss = 1.15768
I0521 18:45:36.619137 12543 solver.cpp:253]     Train net output #0: loss = 1.15768 (* 1 = 1.15768 loss)
I0521 18:45:36.619154 12543 sgd_solver.cpp:106] Iteration 246000, lr = 0.004
I0521 18:45:53.829685 12543 solver.cpp:237] Iteration 247500, loss = 1.42914
I0521 18:45:53.829859 12543 solver.cpp:253]     Train net output #0: loss = 1.42914 (* 1 = 1.42914 loss)
I0521 18:45:53.829874 12543 sgd_solver.cpp:106] Iteration 247500, lr = 0.004
I0521 18:46:11.016104 12543 solver.cpp:237] Iteration 249000, loss = 1.43983
I0521 18:46:11.016139 12543 solver.cpp:253]     Train net output #0: loss = 1.43984 (* 1 = 1.43984 loss)
I0521 18:46:11.016156 12543 sgd_solver.cpp:106] Iteration 249000, lr = 0.004
I0521 18:46:49.054164 12543 solver.cpp:237] Iteration 250500, loss = 1.38577
I0521 18:46:49.054343 12543 solver.cpp:253]     Train net output #0: loss = 1.38577 (* 1 = 1.38577 loss)
I0521 18:46:49.054358 12543 sgd_solver.cpp:106] Iteration 250500, lr = 0.004
I0521 18:47:06.276758 12543 solver.cpp:237] Iteration 252000, loss = 1.0076
I0521 18:47:06.276789 12543 solver.cpp:253]     Train net output #0: loss = 1.0076 (* 1 = 1.0076 loss)
I0521 18:47:06.276813 12543 sgd_solver.cpp:106] Iteration 252000, lr = 0.004
I0521 18:47:23.451582 12543 solver.cpp:237] Iteration 253500, loss = 1.57828
I0521 18:47:23.451755 12543 solver.cpp:253]     Train net output #0: loss = 1.57828 (* 1 = 1.57828 loss)
I0521 18:47:23.451768 12543 sgd_solver.cpp:106] Iteration 253500, lr = 0.004
I0521 18:47:40.609048 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_255000.caffemodel
I0521 18:47:40.654734 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_255000.solverstate
I0521 18:47:40.683284 12543 solver.cpp:237] Iteration 255000, loss = 1.78714
I0521 18:47:40.683328 12543 solver.cpp:253]     Train net output #0: loss = 1.78715 (* 1 = 1.78715 loss)
I0521 18:47:40.683351 12543 sgd_solver.cpp:106] Iteration 255000, lr = 0.004
I0521 18:47:57.883936 12543 solver.cpp:237] Iteration 256500, loss = 0.854392
I0521 18:47:57.884119 12543 solver.cpp:253]     Train net output #0: loss = 0.854396 (* 1 = 0.854396 loss)
I0521 18:47:57.884135 12543 sgd_solver.cpp:106] Iteration 256500, lr = 0.004
I0521 18:48:15.091159 12543 solver.cpp:237] Iteration 258000, loss = 1.23204
I0521 18:48:15.091195 12543 solver.cpp:253]     Train net output #0: loss = 1.23204 (* 1 = 1.23204 loss)
I0521 18:48:15.091215 12543 sgd_solver.cpp:106] Iteration 258000, lr = 0.004
I0521 18:48:32.280362 12543 solver.cpp:237] Iteration 259500, loss = 0.771449
I0521 18:48:32.280537 12543 solver.cpp:253]     Train net output #0: loss = 0.771453 (* 1 = 0.771453 loss)
I0521 18:48:32.280552 12543 sgd_solver.cpp:106] Iteration 259500, lr = 0.004
I0521 18:49:10.301692 12543 solver.cpp:237] Iteration 261000, loss = 1.18075
I0521 18:49:10.301872 12543 solver.cpp:253]     Train net output #0: loss = 1.18076 (* 1 = 1.18076 loss)
I0521 18:49:10.301885 12543 sgd_solver.cpp:106] Iteration 261000, lr = 0.004
I0521 18:49:27.491369 12543 solver.cpp:237] Iteration 262500, loss = 2.34943
I0521 18:49:27.491416 12543 solver.cpp:253]     Train net output #0: loss = 2.34943 (* 1 = 2.34943 loss)
I0521 18:49:27.491430 12543 sgd_solver.cpp:106] Iteration 262500, lr = 0.004
I0521 18:49:44.622344 12543 solver.cpp:237] Iteration 264000, loss = 2.04124
I0521 18:49:44.622514 12543 solver.cpp:253]     Train net output #0: loss = 2.04125 (* 1 = 2.04125 loss)
I0521 18:49:44.622529 12543 sgd_solver.cpp:106] Iteration 264000, lr = 0.004
I0521 18:50:01.647343 12543 solver.cpp:237] Iteration 265500, loss = 1.76439
I0521 18:50:01.647392 12543 solver.cpp:253]     Train net output #0: loss = 1.76439 (* 1 = 1.76439 loss)
I0521 18:50:01.647409 12543 sgd_solver.cpp:106] Iteration 265500, lr = 0.004
I0521 18:50:18.674536 12543 solver.cpp:237] Iteration 267000, loss = 1.45475
I0521 18:50:18.674686 12543 solver.cpp:253]     Train net output #0: loss = 1.45475 (* 1 = 1.45475 loss)
I0521 18:50:18.674700 12543 sgd_solver.cpp:106] Iteration 267000, lr = 0.004
I0521 18:50:35.704040 12543 solver.cpp:237] Iteration 268500, loss = 0.831277
I0521 18:50:35.704082 12543 solver.cpp:253]     Train net output #0: loss = 0.831282 (* 1 = 0.831282 loss)
I0521 18:50:35.704102 12543 sgd_solver.cpp:106] Iteration 268500, lr = 0.004
I0521 18:50:52.729334 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_270000.caffemodel
I0521 18:50:52.775173 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_270000.solverstate
I0521 18:50:52.799729 12543 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 18:51:52.431289 12543 solver.cpp:409]     Test net output #0: accuracy = 0.884941
I0521 18:51:52.431473 12543 solver.cpp:409]     Test net output #1: loss = 0.357541 (* 1 = 0.357541 loss)
I0521 18:52:13.268020 12543 solver.cpp:237] Iteration 270000, loss = 2.7363
I0521 18:52:13.268074 12543 solver.cpp:253]     Train net output #0: loss = 2.7363 (* 1 = 2.7363 loss)
I0521 18:52:13.268093 12543 sgd_solver.cpp:106] Iteration 270000, lr = 0.004
I0521 18:52:30.136543 12543 solver.cpp:237] Iteration 271500, loss = 1.64988
I0521 18:52:30.136706 12543 solver.cpp:253]     Train net output #0: loss = 1.64989 (* 1 = 1.64989 loss)
I0521 18:52:30.136719 12543 sgd_solver.cpp:106] Iteration 271500, lr = 0.004
I0521 18:52:47.017562 12543 solver.cpp:237] Iteration 273000, loss = 1.13561
I0521 18:52:47.017609 12543 solver.cpp:253]     Train net output #0: loss = 1.13561 (* 1 = 1.13561 loss)
I0521 18:52:47.017628 12543 sgd_solver.cpp:106] Iteration 273000, lr = 0.004
I0521 18:53:03.934664 12543 solver.cpp:237] Iteration 274500, loss = 0.843757
I0521 18:53:03.934854 12543 solver.cpp:253]     Train net output #0: loss = 0.843762 (* 1 = 0.843762 loss)
I0521 18:53:03.934867 12543 sgd_solver.cpp:106] Iteration 274500, lr = 0.004
I0521 18:53:20.816876 12543 solver.cpp:237] Iteration 276000, loss = 1.09766
I0521 18:53:20.816912 12543 solver.cpp:253]     Train net output #0: loss = 1.09767 (* 1 = 1.09767 loss)
I0521 18:53:20.816929 12543 sgd_solver.cpp:106] Iteration 276000, lr = 0.004
I0521 18:53:37.670902 12543 solver.cpp:237] Iteration 277500, loss = 1.30194
I0521 18:53:37.671080 12543 solver.cpp:253]     Train net output #0: loss = 1.30194 (* 1 = 1.30194 loss)
I0521 18:53:37.671093 12543 sgd_solver.cpp:106] Iteration 277500, lr = 0.004
I0521 18:53:54.543617 12543 solver.cpp:237] Iteration 279000, loss = 1.768
I0521 18:53:54.543664 12543 solver.cpp:253]     Train net output #0: loss = 1.76801 (* 1 = 1.76801 loss)
I0521 18:53:54.543685 12543 sgd_solver.cpp:106] Iteration 279000, lr = 0.004
I0521 18:54:32.287295 12543 solver.cpp:237] Iteration 280500, loss = 0.861179
I0521 18:54:32.287478 12543 solver.cpp:253]     Train net output #0: loss = 0.861185 (* 1 = 0.861185 loss)
I0521 18:54:32.287492 12543 sgd_solver.cpp:106] Iteration 280500, lr = 0.004
I0521 18:54:49.144641 12543 solver.cpp:237] Iteration 282000, loss = 1.4337
I0521 18:54:49.144682 12543 solver.cpp:253]     Train net output #0: loss = 1.43371 (* 1 = 1.43371 loss)
I0521 18:54:49.144706 12543 sgd_solver.cpp:106] Iteration 282000, lr = 0.004
I0521 18:55:06.068913 12543 solver.cpp:237] Iteration 283500, loss = 1.00005
I0521 18:55:06.069077 12543 solver.cpp:253]     Train net output #0: loss = 1.00006 (* 1 = 1.00006 loss)
I0521 18:55:06.069092 12543 sgd_solver.cpp:106] Iteration 283500, lr = 0.004
I0521 18:55:22.938422 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_285000.caffemodel
I0521 18:55:22.986749 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_285000.solverstate
I0521 18:55:23.017395 12543 solver.cpp:237] Iteration 285000, loss = 1.45847
I0521 18:55:23.017446 12543 solver.cpp:253]     Train net output #0: loss = 1.45848 (* 1 = 1.45848 loss)
I0521 18:55:23.017463 12543 sgd_solver.cpp:106] Iteration 285000, lr = 0.004
I0521 18:55:39.892686 12543 solver.cpp:237] Iteration 286500, loss = 1.23271
I0521 18:55:39.892859 12543 solver.cpp:253]     Train net output #0: loss = 1.23271 (* 1 = 1.23271 loss)
I0521 18:55:39.892874 12543 sgd_solver.cpp:106] Iteration 286500, lr = 0.004
I0521 18:55:56.741948 12543 solver.cpp:237] Iteration 288000, loss = 2.36034
I0521 18:55:56.741998 12543 solver.cpp:253]     Train net output #0: loss = 2.36035 (* 1 = 2.36035 loss)
I0521 18:55:56.742017 12543 sgd_solver.cpp:106] Iteration 288000, lr = 0.004
I0521 18:56:13.574375 12543 solver.cpp:237] Iteration 289500, loss = 1.32556
I0521 18:56:13.574529 12543 solver.cpp:253]     Train net output #0: loss = 1.32556 (* 1 = 1.32556 loss)
I0521 18:56:13.574543 12543 sgd_solver.cpp:106] Iteration 289500, lr = 0.004
I0521 18:56:51.375960 12543 solver.cpp:237] Iteration 291000, loss = 0.676996
I0521 18:56:51.376142 12543 solver.cpp:253]     Train net output #0: loss = 0.677004 (* 1 = 0.677004 loss)
I0521 18:56:51.376157 12543 sgd_solver.cpp:106] Iteration 291000, lr = 0.004
I0521 18:57:08.277391 12543 solver.cpp:237] Iteration 292500, loss = 1.15214
I0521 18:57:08.277438 12543 solver.cpp:253]     Train net output #0: loss = 1.15215 (* 1 = 1.15215 loss)
I0521 18:57:08.277457 12543 sgd_solver.cpp:106] Iteration 292500, lr = 0.004
I0521 18:57:25.183806 12543 solver.cpp:237] Iteration 294000, loss = 1.78936
I0521 18:57:25.183981 12543 solver.cpp:253]     Train net output #0: loss = 1.78937 (* 1 = 1.78937 loss)
I0521 18:57:25.183996 12543 sgd_solver.cpp:106] Iteration 294000, lr = 0.004
I0521 18:57:42.065786 12543 solver.cpp:237] Iteration 295500, loss = 1.13691
I0521 18:57:42.065836 12543 solver.cpp:253]     Train net output #0: loss = 1.13692 (* 1 = 1.13692 loss)
I0521 18:57:42.065855 12543 sgd_solver.cpp:106] Iteration 295500, lr = 0.004
I0521 18:57:58.960424 12543 solver.cpp:237] Iteration 297000, loss = 1.27362
I0521 18:57:58.960610 12543 solver.cpp:253]     Train net output #0: loss = 1.27363 (* 1 = 1.27363 loss)
I0521 18:57:58.960624 12543 sgd_solver.cpp:106] Iteration 297000, lr = 0.004
I0521 18:58:15.858302 12543 solver.cpp:237] Iteration 298500, loss = 0.780258
I0521 18:58:15.858340 12543 solver.cpp:253]     Train net output #0: loss = 0.780268 (* 1 = 0.780268 loss)
I0521 18:58:15.858356 12543 sgd_solver.cpp:106] Iteration 298500, lr = 0.004
I0521 18:58:32.706223 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_300000.caffemodel
I0521 18:58:32.754286 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_300000.solverstate
I0521 18:58:32.781787 12543 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 18:59:53.007998 12543 solver.cpp:409]     Test net output #0: accuracy = 0.884648
I0521 18:59:53.008179 12543 solver.cpp:409]     Test net output #1: loss = 0.382167 (* 1 = 0.382167 loss)
I0521 19:00:13.863227 12543 solver.cpp:237] Iteration 300000, loss = 1.02143
I0521 19:00:13.863278 12543 solver.cpp:253]     Train net output #0: loss = 1.02144 (* 1 = 1.02144 loss)
I0521 19:00:13.863299 12543 sgd_solver.cpp:106] Iteration 300000, lr = 0.004
I0521 19:00:30.636240 12543 solver.cpp:237] Iteration 301500, loss = 1.49358
I0521 19:00:30.636415 12543 solver.cpp:253]     Train net output #0: loss = 1.49359 (* 1 = 1.49359 loss)
I0521 19:00:30.636430 12543 sgd_solver.cpp:106] Iteration 301500, lr = 0.004
I0521 19:00:47.415441 12543 solver.cpp:237] Iteration 303000, loss = 1.49932
I0521 19:00:47.415470 12543 solver.cpp:253]     Train net output #0: loss = 1.49933 (* 1 = 1.49933 loss)
I0521 19:00:47.415488 12543 sgd_solver.cpp:106] Iteration 303000, lr = 0.004
I0521 19:01:04.376106 12543 solver.cpp:237] Iteration 304500, loss = 1.00562
I0521 19:01:04.376271 12543 solver.cpp:253]     Train net output #0: loss = 1.00563 (* 1 = 1.00563 loss)
I0521 19:01:04.376284 12543 sgd_solver.cpp:106] Iteration 304500, lr = 0.004
I0521 19:01:21.404196 12543 solver.cpp:237] Iteration 306000, loss = 0.887925
I0521 19:01:21.404245 12543 solver.cpp:253]     Train net output #0: loss = 0.887936 (* 1 = 0.887936 loss)
I0521 19:01:21.404268 12543 sgd_solver.cpp:106] Iteration 306000, lr = 0.004
I0521 19:01:38.430245 12543 solver.cpp:237] Iteration 307500, loss = 1.29805
I0521 19:01:38.430402 12543 solver.cpp:253]     Train net output #0: loss = 1.29806 (* 1 = 1.29806 loss)
I0521 19:01:38.430415 12543 sgd_solver.cpp:106] Iteration 307500, lr = 0.004
I0521 19:01:55.473232 12543 solver.cpp:237] Iteration 309000, loss = 1.43156
I0521 19:01:55.473281 12543 solver.cpp:253]     Train net output #0: loss = 1.43157 (* 1 = 1.43157 loss)
I0521 19:01:55.473299 12543 sgd_solver.cpp:106] Iteration 309000, lr = 0.004
I0521 19:02:33.374805 12543 solver.cpp:237] Iteration 310500, loss = 1.08025
I0521 19:02:33.374984 12543 solver.cpp:253]     Train net output #0: loss = 1.08026 (* 1 = 1.08026 loss)
I0521 19:02:33.374997 12543 sgd_solver.cpp:106] Iteration 310500, lr = 0.004
I0521 19:02:50.416290 12543 solver.cpp:237] Iteration 312000, loss = 1.2078
I0521 19:02:50.416326 12543 solver.cpp:253]     Train net output #0: loss = 1.20781 (* 1 = 1.20781 loss)
I0521 19:02:50.416344 12543 sgd_solver.cpp:106] Iteration 312000, lr = 0.004
I0521 19:03:07.436535 12543 solver.cpp:237] Iteration 313500, loss = 1.55049
I0521 19:03:07.436720 12543 solver.cpp:253]     Train net output #0: loss = 1.5505 (* 1 = 1.5505 loss)
I0521 19:03:07.436734 12543 sgd_solver.cpp:106] Iteration 313500, lr = 0.004
I0521 19:03:24.452639 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_315000.caffemodel
I0521 19:03:24.498440 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_315000.solverstate
I0521 19:03:24.526756 12543 solver.cpp:237] Iteration 315000, loss = 0.757427
I0521 19:03:24.526805 12543 solver.cpp:253]     Train net output #0: loss = 0.757437 (* 1 = 0.757437 loss)
I0521 19:03:24.526819 12543 sgd_solver.cpp:106] Iteration 315000, lr = 0.004
I0521 19:03:41.537287 12543 solver.cpp:237] Iteration 316500, loss = 1.01997
I0521 19:03:41.537446 12543 solver.cpp:253]     Train net output #0: loss = 1.01998 (* 1 = 1.01998 loss)
I0521 19:03:41.537461 12543 sgd_solver.cpp:106] Iteration 316500, lr = 0.004
I0521 19:03:58.614212 12543 solver.cpp:237] Iteration 318000, loss = 0.812725
I0521 19:03:58.614253 12543 solver.cpp:253]     Train net output #0: loss = 0.812735 (* 1 = 0.812735 loss)
I0521 19:03:58.614274 12543 sgd_solver.cpp:106] Iteration 318000, lr = 0.004
I0521 19:04:15.646993 12543 solver.cpp:237] Iteration 319500, loss = 1.01194
I0521 19:04:15.647156 12543 solver.cpp:253]     Train net output #0: loss = 1.01195 (* 1 = 1.01195 loss)
I0521 19:04:15.647169 12543 sgd_solver.cpp:106] Iteration 319500, lr = 0.004
I0521 19:04:53.555089 12543 solver.cpp:237] Iteration 321000, loss = 1.40605
I0521 19:04:53.555271 12543 solver.cpp:253]     Train net output #0: loss = 1.40606 (* 1 = 1.40606 loss)
I0521 19:04:53.555285 12543 sgd_solver.cpp:106] Iteration 321000, lr = 0.004
I0521 19:05:10.607182 12543 solver.cpp:237] Iteration 322500, loss = 1.4071
I0521 19:05:10.607226 12543 solver.cpp:253]     Train net output #0: loss = 1.40711 (* 1 = 1.40711 loss)
I0521 19:05:10.607245 12543 sgd_solver.cpp:106] Iteration 322500, lr = 0.004
I0521 19:05:27.636925 12543 solver.cpp:237] Iteration 324000, loss = 1.3253
I0521 19:05:27.637095 12543 solver.cpp:253]     Train net output #0: loss = 1.32531 (* 1 = 1.32531 loss)
I0521 19:05:27.637109 12543 sgd_solver.cpp:106] Iteration 324000, lr = 0.004
I0521 19:05:44.699977 12543 solver.cpp:237] Iteration 325500, loss = 0.848183
I0521 19:05:44.700013 12543 solver.cpp:253]     Train net output #0: loss = 0.848193 (* 1 = 0.848193 loss)
I0521 19:05:44.700032 12543 sgd_solver.cpp:106] Iteration 325500, lr = 0.004
I0521 19:06:01.726351 12543 solver.cpp:237] Iteration 327000, loss = 1.13515
I0521 19:06:01.726534 12543 solver.cpp:253]     Train net output #0: loss = 1.13516 (* 1 = 1.13516 loss)
I0521 19:06:01.726547 12543 sgd_solver.cpp:106] Iteration 327000, lr = 0.004
I0521 19:06:18.751469 12543 solver.cpp:237] Iteration 328500, loss = 1.47089
I0521 19:06:18.751520 12543 solver.cpp:253]     Train net output #0: loss = 1.4709 (* 1 = 1.4709 loss)
I0521 19:06:18.751535 12543 sgd_solver.cpp:106] Iteration 328500, lr = 0.004
I0521 19:06:35.642722 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_330000.caffemodel
I0521 19:06:35.687950 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_330000.solverstate
I0521 19:06:35.712743 12543 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 19:07:34.773090 12543 solver.cpp:409]     Test net output #0: accuracy = 0.887976
I0521 19:07:34.773268 12543 solver.cpp:409]     Test net output #1: loss = 0.349023 (* 1 = 0.349023 loss)
I0521 19:07:55.672171 12543 solver.cpp:237] Iteration 330000, loss = 1.3411
I0521 19:07:55.672226 12543 solver.cpp:253]     Train net output #0: loss = 1.34111 (* 1 = 1.34111 loss)
I0521 19:07:55.672245 12543 sgd_solver.cpp:106] Iteration 330000, lr = 0.004
I0521 19:08:12.305354 12543 solver.cpp:237] Iteration 331500, loss = 0.661062
I0521 19:08:12.305549 12543 solver.cpp:253]     Train net output #0: loss = 0.661072 (* 1 = 0.661072 loss)
I0521 19:08:12.305563 12543 sgd_solver.cpp:106] Iteration 331500, lr = 0.004
I0521 19:08:28.930177 12543 solver.cpp:237] Iteration 333000, loss = 0.795182
I0521 19:08:28.930232 12543 solver.cpp:253]     Train net output #0: loss = 0.795192 (* 1 = 0.795192 loss)
I0521 19:08:28.930248 12543 sgd_solver.cpp:106] Iteration 333000, lr = 0.004
I0521 19:08:45.551020 12543 solver.cpp:237] Iteration 334500, loss = 1.16054
I0521 19:08:45.551180 12543 solver.cpp:253]     Train net output #0: loss = 1.16055 (* 1 = 1.16055 loss)
I0521 19:08:45.551193 12543 sgd_solver.cpp:106] Iteration 334500, lr = 0.004
I0521 19:09:02.163666 12543 solver.cpp:237] Iteration 336000, loss = 1.19587
I0521 19:09:02.163712 12543 solver.cpp:253]     Train net output #0: loss = 1.19587 (* 1 = 1.19587 loss)
I0521 19:09:02.163734 12543 sgd_solver.cpp:106] Iteration 336000, lr = 0.004
I0521 19:09:18.794764 12543 solver.cpp:237] Iteration 337500, loss = 1.4
I0521 19:09:18.794945 12543 solver.cpp:253]     Train net output #0: loss = 1.40001 (* 1 = 1.40001 loss)
I0521 19:09:18.794958 12543 sgd_solver.cpp:106] Iteration 337500, lr = 0.004
I0521 19:09:35.438706 12543 solver.cpp:237] Iteration 339000, loss = 0.704797
I0521 19:09:35.438743 12543 solver.cpp:253]     Train net output #0: loss = 0.704806 (* 1 = 0.704806 loss)
I0521 19:09:35.438760 12543 sgd_solver.cpp:106] Iteration 339000, lr = 0.004
I0521 19:10:12.925475 12543 solver.cpp:237] Iteration 340500, loss = 2.02793
I0521 19:10:12.925660 12543 solver.cpp:253]     Train net output #0: loss = 2.02794 (* 1 = 2.02794 loss)
I0521 19:10:12.925674 12543 sgd_solver.cpp:106] Iteration 340500, lr = 0.004
I0521 19:10:29.554158 12543 solver.cpp:237] Iteration 342000, loss = 1.41836
I0521 19:10:29.554208 12543 solver.cpp:253]     Train net output #0: loss = 1.41837 (* 1 = 1.41837 loss)
I0521 19:10:29.554226 12543 sgd_solver.cpp:106] Iteration 342000, lr = 0.004
I0521 19:10:46.153867 12543 solver.cpp:237] Iteration 343500, loss = 1.1546
I0521 19:10:46.154023 12543 solver.cpp:253]     Train net output #0: loss = 1.15461 (* 1 = 1.15461 loss)
I0521 19:10:46.154037 12543 sgd_solver.cpp:106] Iteration 343500, lr = 0.004
I0521 19:11:02.763871 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_345000.caffemodel
I0521 19:11:02.809331 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_345000.solverstate
I0521 19:11:02.838068 12543 solver.cpp:237] Iteration 345000, loss = 0.973252
I0521 19:11:02.838129 12543 solver.cpp:253]     Train net output #0: loss = 0.973262 (* 1 = 0.973262 loss)
I0521 19:11:02.838148 12543 sgd_solver.cpp:106] Iteration 345000, lr = 0.004
I0521 19:11:19.466132 12543 solver.cpp:237] Iteration 346500, loss = 1.75967
I0521 19:11:19.466303 12543 solver.cpp:253]     Train net output #0: loss = 1.75968 (* 1 = 1.75968 loss)
I0521 19:11:19.466318 12543 sgd_solver.cpp:106] Iteration 346500, lr = 0.004
I0521 19:11:36.097339 12543 solver.cpp:237] Iteration 348000, loss = 0.924507
I0521 19:11:36.097371 12543 solver.cpp:253]     Train net output #0: loss = 0.924516 (* 1 = 0.924516 loss)
I0521 19:11:36.097395 12543 sgd_solver.cpp:106] Iteration 348000, lr = 0.004
I0521 19:11:52.748155 12543 solver.cpp:237] Iteration 349500, loss = 1.30849
I0521 19:11:52.748327 12543 solver.cpp:253]     Train net output #0: loss = 1.3085 (* 1 = 1.3085 loss)
I0521 19:11:52.748342 12543 sgd_solver.cpp:106] Iteration 349500, lr = 0.004
I0521 19:12:30.211655 12543 solver.cpp:237] Iteration 351000, loss = 0.521282
I0521 19:12:30.211851 12543 solver.cpp:253]     Train net output #0: loss = 0.521292 (* 1 = 0.521292 loss)
I0521 19:12:30.211866 12543 sgd_solver.cpp:106] Iteration 351000, lr = 0.004
I0521 19:12:46.831411 12543 solver.cpp:237] Iteration 352500, loss = 1.52527
I0521 19:12:46.831461 12543 solver.cpp:253]     Train net output #0: loss = 1.52528 (* 1 = 1.52528 loss)
I0521 19:12:46.831477 12543 sgd_solver.cpp:106] Iteration 352500, lr = 0.004
I0521 19:13:03.459234 12543 solver.cpp:237] Iteration 354000, loss = 1.78928
I0521 19:13:03.459424 12543 solver.cpp:253]     Train net output #0: loss = 1.78929 (* 1 = 1.78929 loss)
I0521 19:13:03.459439 12543 sgd_solver.cpp:106] Iteration 354000, lr = 0.004
I0521 19:13:20.051236 12543 solver.cpp:237] Iteration 355500, loss = 0.896355
I0521 19:13:20.051271 12543 solver.cpp:253]     Train net output #0: loss = 0.896365 (* 1 = 0.896365 loss)
I0521 19:13:20.051292 12543 sgd_solver.cpp:106] Iteration 355500, lr = 0.004
I0521 19:13:36.685628 12543 solver.cpp:237] Iteration 357000, loss = 1.0052
I0521 19:13:36.685801 12543 solver.cpp:253]     Train net output #0: loss = 1.00521 (* 1 = 1.00521 loss)
I0521 19:13:36.685816 12543 sgd_solver.cpp:106] Iteration 357000, lr = 0.004
I0521 19:13:53.295305 12543 solver.cpp:237] Iteration 358500, loss = 1.27083
I0521 19:13:53.295351 12543 solver.cpp:253]     Train net output #0: loss = 1.27084 (* 1 = 1.27084 loss)
I0521 19:13:53.295369 12543 sgd_solver.cpp:106] Iteration 358500, lr = 0.004
I0521 19:14:09.912235 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_360000.caffemodel
I0521 19:14:09.957314 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_360000.solverstate
I0521 19:14:09.981967 12543 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 19:15:30.318848 12543 solver.cpp:409]     Test net output #0: accuracy = 0.88236
I0521 19:15:30.319031 12543 solver.cpp:409]     Test net output #1: loss = 0.415991 (* 1 = 0.415991 loss)
I0521 19:15:51.152516 12543 solver.cpp:237] Iteration 360000, loss = 1.04843
I0521 19:15:51.152573 12543 solver.cpp:253]     Train net output #0: loss = 1.04844 (* 1 = 1.04844 loss)
I0521 19:15:51.152590 12543 sgd_solver.cpp:106] Iteration 360000, lr = 0.004
I0521 19:16:08.187413 12543 solver.cpp:237] Iteration 361500, loss = 0.589865
I0521 19:16:08.187593 12543 solver.cpp:253]     Train net output #0: loss = 0.589874 (* 1 = 0.589874 loss)
I0521 19:16:08.187608 12543 sgd_solver.cpp:106] Iteration 361500, lr = 0.004
I0521 19:16:25.203394 12543 solver.cpp:237] Iteration 363000, loss = 1.33366
I0521 19:16:25.203446 12543 solver.cpp:253]     Train net output #0: loss = 1.33367 (* 1 = 1.33367 loss)
I0521 19:16:25.203465 12543 sgd_solver.cpp:106] Iteration 363000, lr = 0.004
I0521 19:16:42.259254 12543 solver.cpp:237] Iteration 364500, loss = 0.862657
I0521 19:16:42.259429 12543 solver.cpp:253]     Train net output #0: loss = 0.862666 (* 1 = 0.862666 loss)
I0521 19:16:42.259444 12543 sgd_solver.cpp:106] Iteration 364500, lr = 0.004
I0521 19:16:59.315096 12543 solver.cpp:237] Iteration 366000, loss = 1.13056
I0521 19:16:59.315131 12543 solver.cpp:253]     Train net output #0: loss = 1.13057 (* 1 = 1.13057 loss)
I0521 19:16:59.315150 12543 sgd_solver.cpp:106] Iteration 366000, lr = 0.004
I0521 19:17:16.311183 12543 solver.cpp:237] Iteration 367500, loss = 1.19456
I0521 19:17:16.311357 12543 solver.cpp:253]     Train net output #0: loss = 1.19457 (* 1 = 1.19457 loss)
I0521 19:17:16.311372 12543 sgd_solver.cpp:106] Iteration 367500, lr = 0.004
I0521 19:17:33.331076 12543 solver.cpp:237] Iteration 369000, loss = 0.973566
I0521 19:17:33.331123 12543 solver.cpp:253]     Train net output #0: loss = 0.973574 (* 1 = 0.973574 loss)
I0521 19:17:33.331141 12543 sgd_solver.cpp:106] Iteration 369000, lr = 0.004
I0521 19:18:11.200287 12543 solver.cpp:237] Iteration 370500, loss = 1.69369
I0521 19:18:11.200482 12543 solver.cpp:253]     Train net output #0: loss = 1.6937 (* 1 = 1.6937 loss)
I0521 19:18:11.200496 12543 sgd_solver.cpp:106] Iteration 370500, lr = 0.004
I0521 19:18:28.250486 12543 solver.cpp:237] Iteration 372000, loss = 0.720377
I0521 19:18:28.250536 12543 solver.cpp:253]     Train net output #0: loss = 0.720385 (* 1 = 0.720385 loss)
I0521 19:18:28.250555 12543 sgd_solver.cpp:106] Iteration 372000, lr = 0.004
I0521 19:18:45.299765 12543 solver.cpp:237] Iteration 373500, loss = 1.17225
I0521 19:18:45.299927 12543 solver.cpp:253]     Train net output #0: loss = 1.17226 (* 1 = 1.17226 loss)
I0521 19:18:45.299942 12543 sgd_solver.cpp:106] Iteration 373500, lr = 0.004
I0521 19:19:02.271773 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_375000.caffemodel
I0521 19:19:02.319296 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_375000.solverstate
I0521 19:19:02.349721 12543 solver.cpp:237] Iteration 375000, loss = 0.855045
I0521 19:19:02.349776 12543 solver.cpp:253]     Train net output #0: loss = 0.855053 (* 1 = 0.855053 loss)
I0521 19:19:02.349793 12543 sgd_solver.cpp:106] Iteration 375000, lr = 0.004
I0521 19:19:19.386205 12543 solver.cpp:237] Iteration 376500, loss = 1.69173
I0521 19:19:19.386395 12543 solver.cpp:253]     Train net output #0: loss = 1.69174 (* 1 = 1.69174 loss)
I0521 19:19:19.386409 12543 sgd_solver.cpp:106] Iteration 376500, lr = 0.004
I0521 19:19:36.414352 12543 solver.cpp:237] Iteration 378000, loss = 0.758469
I0521 19:19:36.414407 12543 solver.cpp:253]     Train net output #0: loss = 0.758478 (* 1 = 0.758478 loss)
I0521 19:19:36.414420 12543 sgd_solver.cpp:106] Iteration 378000, lr = 0.004
I0521 19:19:53.457638 12543 solver.cpp:237] Iteration 379500, loss = 0.74413
I0521 19:19:53.457809 12543 solver.cpp:253]     Train net output #0: loss = 0.744139 (* 1 = 0.744139 loss)
I0521 19:19:53.457823 12543 sgd_solver.cpp:106] Iteration 379500, lr = 0.004
I0521 19:20:31.379322 12543 solver.cpp:237] Iteration 381000, loss = 1.40392
I0521 19:20:31.379506 12543 solver.cpp:253]     Train net output #0: loss = 1.40393 (* 1 = 1.40393 loss)
I0521 19:20:31.379520 12543 sgd_solver.cpp:106] Iteration 381000, lr = 0.004
I0521 19:20:48.415967 12543 solver.cpp:237] Iteration 382500, loss = 1.08043
I0521 19:20:48.416002 12543 solver.cpp:253]     Train net output #0: loss = 1.08044 (* 1 = 1.08044 loss)
I0521 19:20:48.416021 12543 sgd_solver.cpp:106] Iteration 382500, lr = 0.004
I0521 19:21:05.487260 12543 solver.cpp:237] Iteration 384000, loss = 1.17233
I0521 19:21:05.487437 12543 solver.cpp:253]     Train net output #0: loss = 1.17234 (* 1 = 1.17234 loss)
I0521 19:21:05.487452 12543 sgd_solver.cpp:106] Iteration 384000, lr = 0.004
I0521 19:21:22.499414 12543 solver.cpp:237] Iteration 385500, loss = 1.19426
I0521 19:21:22.499464 12543 solver.cpp:253]     Train net output #0: loss = 1.19427 (* 1 = 1.19427 loss)
I0521 19:21:22.499482 12543 sgd_solver.cpp:106] Iteration 385500, lr = 0.004
I0521 19:21:39.548956 12543 solver.cpp:237] Iteration 387000, loss = 1.383
I0521 19:21:39.549116 12543 solver.cpp:253]     Train net output #0: loss = 1.38301 (* 1 = 1.38301 loss)
I0521 19:21:39.549129 12543 sgd_solver.cpp:106] Iteration 387000, lr = 0.004
I0521 19:21:56.592579 12543 solver.cpp:237] Iteration 388500, loss = 1.01808
I0521 19:21:56.592624 12543 solver.cpp:253]     Train net output #0: loss = 1.01808 (* 1 = 1.01808 loss)
I0521 19:21:56.592643 12543 sgd_solver.cpp:106] Iteration 388500, lr = 0.004
I0521 19:22:13.614755 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_390000.caffemodel
I0521 19:22:13.660706 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_390000.solverstate
I0521 19:22:13.685849 12543 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 19:23:13.334425 12543 solver.cpp:409]     Test net output #0: accuracy = 0.889719
I0521 19:23:13.334611 12543 solver.cpp:409]     Test net output #1: loss = 0.376667 (* 1 = 0.376667 loss)
I0521 19:23:34.175747 12543 solver.cpp:237] Iteration 390000, loss = 0.955677
I0521 19:23:34.175803 12543 solver.cpp:253]     Train net output #0: loss = 0.955684 (* 1 = 0.955684 loss)
I0521 19:23:34.175818 12543 sgd_solver.cpp:106] Iteration 390000, lr = 0.004
I0521 19:23:50.888074 12543 solver.cpp:237] Iteration 391500, loss = 0.615106
I0521 19:23:50.888257 12543 solver.cpp:253]     Train net output #0: loss = 0.615114 (* 1 = 0.615114 loss)
I0521 19:23:50.888272 12543 sgd_solver.cpp:106] Iteration 391500, lr = 0.004
I0521 19:24:07.872454 12543 solver.cpp:237] Iteration 393000, loss = 2.10222
I0521 19:24:07.872485 12543 solver.cpp:253]     Train net output #0: loss = 2.10223 (* 1 = 2.10223 loss)
I0521 19:24:07.872509 12543 sgd_solver.cpp:106] Iteration 393000, lr = 0.004
I0521 19:24:24.826870 12543 solver.cpp:237] Iteration 394500, loss = 1.17981
I0521 19:24:24.827051 12543 solver.cpp:253]     Train net output #0: loss = 1.17981 (* 1 = 1.17981 loss)
I0521 19:24:24.827065 12543 sgd_solver.cpp:106] Iteration 394500, lr = 0.004
I0521 19:24:41.748888 12543 solver.cpp:237] Iteration 396000, loss = 0.600913
I0521 19:24:41.748932 12543 solver.cpp:253]     Train net output #0: loss = 0.600921 (* 1 = 0.600921 loss)
I0521 19:24:41.748955 12543 sgd_solver.cpp:106] Iteration 396000, lr = 0.004
I0521 19:24:58.688844 12543 solver.cpp:237] Iteration 397500, loss = 0.885679
I0521 19:24:58.689004 12543 solver.cpp:253]     Train net output #0: loss = 0.885687 (* 1 = 0.885687 loss)
I0521 19:24:58.689018 12543 sgd_solver.cpp:106] Iteration 397500, lr = 0.004
I0521 19:25:15.633268 12543 solver.cpp:237] Iteration 399000, loss = 0.991957
I0521 19:25:15.633312 12543 solver.cpp:253]     Train net output #0: loss = 0.991965 (* 1 = 0.991965 loss)
I0521 19:25:15.633335 12543 sgd_solver.cpp:106] Iteration 399000, lr = 0.004
I0521 19:25:53.426774 12543 solver.cpp:237] Iteration 400500, loss = 1.74983
I0521 19:25:53.426960 12543 solver.cpp:253]     Train net output #0: loss = 1.74983 (* 1 = 1.74983 loss)
I0521 19:25:53.426975 12543 sgd_solver.cpp:106] Iteration 400500, lr = 0.004
I0521 19:26:10.365180 12543 solver.cpp:237] Iteration 402000, loss = 1.39045
I0521 19:26:10.365216 12543 solver.cpp:253]     Train net output #0: loss = 1.39046 (* 1 = 1.39046 loss)
I0521 19:26:10.365236 12543 sgd_solver.cpp:106] Iteration 402000, lr = 0.004
I0521 19:26:27.332098 12543 solver.cpp:237] Iteration 403500, loss = 1.65009
I0521 19:26:27.332285 12543 solver.cpp:253]     Train net output #0: loss = 1.6501 (* 1 = 1.6501 loss)
I0521 19:26:27.332299 12543 sgd_solver.cpp:106] Iteration 403500, lr = 0.004
I0521 19:26:44.251514 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_405000.caffemodel
I0521 19:26:44.296463 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_405000.solverstate
I0521 19:26:44.324899 12543 solver.cpp:237] Iteration 405000, loss = 1.15353
I0521 19:26:44.324947 12543 solver.cpp:253]     Train net output #0: loss = 1.15353 (* 1 = 1.15353 loss)
I0521 19:26:44.324964 12543 sgd_solver.cpp:106] Iteration 405000, lr = 0.004
I0521 19:27:01.305132 12543 solver.cpp:237] Iteration 406500, loss = 0.974641
I0521 19:27:01.305299 12543 solver.cpp:253]     Train net output #0: loss = 0.974647 (* 1 = 0.974647 loss)
I0521 19:27:01.305312 12543 sgd_solver.cpp:106] Iteration 406500, lr = 0.004
I0521 19:27:18.256266 12543 solver.cpp:237] Iteration 408000, loss = 0.907013
I0521 19:27:18.256315 12543 solver.cpp:253]     Train net output #0: loss = 0.907019 (* 1 = 0.907019 loss)
I0521 19:27:18.256335 12543 sgd_solver.cpp:106] Iteration 408000, lr = 0.004
I0521 19:27:35.223712 12543 solver.cpp:237] Iteration 409500, loss = 0.809678
I0521 19:27:35.223901 12543 solver.cpp:253]     Train net output #0: loss = 0.809684 (* 1 = 0.809684 loss)
I0521 19:27:35.223915 12543 sgd_solver.cpp:106] Iteration 409500, lr = 0.004
I0521 19:28:13.022956 12543 solver.cpp:237] Iteration 411000, loss = 1.47566
I0521 19:28:13.023147 12543 solver.cpp:253]     Train net output #0: loss = 1.47567 (* 1 = 1.47567 loss)
I0521 19:28:13.023161 12543 sgd_solver.cpp:106] Iteration 411000, lr = 0.004
I0521 19:28:29.901196 12543 solver.cpp:237] Iteration 412500, loss = 1.75241
I0521 19:28:29.901249 12543 solver.cpp:253]     Train net output #0: loss = 1.75242 (* 1 = 1.75242 loss)
I0521 19:28:29.901268 12543 sgd_solver.cpp:106] Iteration 412500, lr = 0.004
I0521 19:28:46.547724 12543 solver.cpp:237] Iteration 414000, loss = 1.37589
I0521 19:28:46.547902 12543 solver.cpp:253]     Train net output #0: loss = 1.3759 (* 1 = 1.3759 loss)
I0521 19:28:46.547917 12543 sgd_solver.cpp:106] Iteration 414000, lr = 0.004
I0521 19:29:03.164685 12543 solver.cpp:237] Iteration 415500, loss = 1.06779
I0521 19:29:03.164721 12543 solver.cpp:253]     Train net output #0: loss = 1.06779 (* 1 = 1.06779 loss)
I0521 19:29:03.164736 12543 sgd_solver.cpp:106] Iteration 415500, lr = 0.004
I0521 19:29:19.796712 12543 solver.cpp:237] Iteration 417000, loss = 1.32874
I0521 19:29:19.796885 12543 solver.cpp:253]     Train net output #0: loss = 1.32874 (* 1 = 1.32874 loss)
I0521 19:29:19.796900 12543 sgd_solver.cpp:106] Iteration 417000, lr = 0.004
I0521 19:29:36.411963 12543 solver.cpp:237] Iteration 418500, loss = 1.25186
I0521 19:29:36.412010 12543 solver.cpp:253]     Train net output #0: loss = 1.25186 (* 1 = 1.25186 loss)
I0521 19:29:36.412029 12543 sgd_solver.cpp:106] Iteration 418500, lr = 0.004
I0521 19:29:53.000824 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_420000.caffemodel
I0521 19:29:53.046813 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_420000.solverstate
I0521 19:29:53.071907 12543 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 19:31:13.268863 12543 solver.cpp:409]     Test net output #0: accuracy = 0.881447
I0521 19:31:13.269047 12543 solver.cpp:409]     Test net output #1: loss = 0.365354 (* 1 = 0.365354 loss)
I0521 19:31:34.102529 12543 solver.cpp:237] Iteration 420000, loss = 2.84132
I0521 19:31:34.102583 12543 solver.cpp:253]     Train net output #0: loss = 2.84132 (* 1 = 2.84132 loss)
I0521 19:31:34.102602 12543 sgd_solver.cpp:106] Iteration 420000, lr = 0.004
I0521 19:31:51.077285 12543 solver.cpp:237] Iteration 421500, loss = 2.13674
I0521 19:31:51.077466 12543 solver.cpp:253]     Train net output #0: loss = 2.13675 (* 1 = 2.13675 loss)
I0521 19:31:51.077481 12543 sgd_solver.cpp:106] Iteration 421500, lr = 0.004
I0521 19:32:07.919930 12543 solver.cpp:237] Iteration 423000, loss = 1.28304
I0521 19:32:07.919977 12543 solver.cpp:253]     Train net output #0: loss = 1.28305 (* 1 = 1.28305 loss)
I0521 19:32:07.919996 12543 sgd_solver.cpp:106] Iteration 423000, lr = 0.004
I0521 19:32:24.767410 12543 solver.cpp:237] Iteration 424500, loss = 1.26177
I0521 19:32:24.767575 12543 solver.cpp:253]     Train net output #0: loss = 1.26178 (* 1 = 1.26178 loss)
I0521 19:32:24.767587 12543 sgd_solver.cpp:106] Iteration 424500, lr = 0.004
I0521 19:32:41.618244 12543 solver.cpp:237] Iteration 426000, loss = 0.793422
I0521 19:32:41.618293 12543 solver.cpp:253]     Train net output #0: loss = 0.793428 (* 1 = 0.793428 loss)
I0521 19:32:41.618309 12543 sgd_solver.cpp:106] Iteration 426000, lr = 0.004
I0521 19:32:58.500432 12543 solver.cpp:237] Iteration 427500, loss = 1.49014
I0521 19:32:58.500639 12543 solver.cpp:253]     Train net output #0: loss = 1.49015 (* 1 = 1.49015 loss)
I0521 19:32:58.500653 12543 sgd_solver.cpp:106] Iteration 427500, lr = 0.004
I0521 19:33:15.317592 12543 solver.cpp:237] Iteration 429000, loss = 0.415745
I0521 19:33:15.317627 12543 solver.cpp:253]     Train net output #0: loss = 0.415751 (* 1 = 0.415751 loss)
I0521 19:33:15.317644 12543 sgd_solver.cpp:106] Iteration 429000, lr = 0.004
I0521 19:33:53.045243 12543 solver.cpp:237] Iteration 430500, loss = 0.45677
I0521 19:33:53.045447 12543 solver.cpp:253]     Train net output #0: loss = 0.456776 (* 1 = 0.456776 loss)
I0521 19:33:53.045462 12543 sgd_solver.cpp:106] Iteration 430500, lr = 0.004
I0521 19:34:09.901854 12543 solver.cpp:237] Iteration 432000, loss = 0.757973
I0521 19:34:09.901891 12543 solver.cpp:253]     Train net output #0: loss = 0.757979 (* 1 = 0.757979 loss)
I0521 19:34:09.901907 12543 sgd_solver.cpp:106] Iteration 432000, lr = 0.004
I0521 19:34:26.767621 12543 solver.cpp:237] Iteration 433500, loss = 1.24698
I0521 19:34:26.767798 12543 solver.cpp:253]     Train net output #0: loss = 1.24699 (* 1 = 1.24699 loss)
I0521 19:34:26.767812 12543 sgd_solver.cpp:106] Iteration 433500, lr = 0.004
I0521 19:34:43.623563 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_435000.caffemodel
I0521 19:34:43.670696 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_435000.solverstate
I0521 19:34:43.701299 12543 solver.cpp:237] Iteration 435000, loss = 1.36012
I0521 19:34:43.701352 12543 solver.cpp:253]     Train net output #0: loss = 1.36013 (* 1 = 1.36013 loss)
I0521 19:34:43.701370 12543 sgd_solver.cpp:106] Iteration 435000, lr = 0.004
I0521 19:35:00.595176 12543 solver.cpp:237] Iteration 436500, loss = 1.21869
I0521 19:35:00.595346 12543 solver.cpp:253]     Train net output #0: loss = 1.21869 (* 1 = 1.21869 loss)
I0521 19:35:00.595360 12543 sgd_solver.cpp:106] Iteration 436500, lr = 0.004
I0521 19:35:17.471168 12543 solver.cpp:237] Iteration 438000, loss = 4.3738
I0521 19:35:17.471215 12543 solver.cpp:253]     Train net output #0: loss = 4.37381 (* 1 = 4.37381 loss)
I0521 19:35:17.471235 12543 sgd_solver.cpp:106] Iteration 438000, lr = 0.004
I0521 19:35:34.307477 12543 solver.cpp:237] Iteration 439500, loss = 1.30888
I0521 19:35:34.307660 12543 solver.cpp:253]     Train net output #0: loss = 1.30889 (* 1 = 1.30889 loss)
I0521 19:35:34.307675 12543 sgd_solver.cpp:106] Iteration 439500, lr = 0.004
I0521 19:36:11.964027 12543 solver.cpp:237] Iteration 441000, loss = 1.20789
I0521 19:36:11.964215 12543 solver.cpp:253]     Train net output #0: loss = 1.2079 (* 1 = 1.2079 loss)
I0521 19:36:11.964229 12543 sgd_solver.cpp:106] Iteration 441000, lr = 0.004
I0521 19:36:28.823693 12543 solver.cpp:237] Iteration 442500, loss = 1.17981
I0521 19:36:28.823746 12543 solver.cpp:253]     Train net output #0: loss = 1.17982 (* 1 = 1.17982 loss)
I0521 19:36:28.823765 12543 sgd_solver.cpp:106] Iteration 442500, lr = 0.004
I0521 19:36:45.689798 12543 solver.cpp:237] Iteration 444000, loss = 1.63552
I0521 19:36:45.689982 12543 solver.cpp:253]     Train net output #0: loss = 1.63553 (* 1 = 1.63553 loss)
I0521 19:36:45.689996 12543 sgd_solver.cpp:106] Iteration 444000, lr = 0.004
I0521 19:37:02.513617 12543 solver.cpp:237] Iteration 445500, loss = 1.75052
I0521 19:37:02.513651 12543 solver.cpp:253]     Train net output #0: loss = 1.75053 (* 1 = 1.75053 loss)
I0521 19:37:02.513669 12543 sgd_solver.cpp:106] Iteration 445500, lr = 0.004
I0521 19:37:19.390275 12543 solver.cpp:237] Iteration 447000, loss = 1.13231
I0521 19:37:19.390462 12543 solver.cpp:253]     Train net output #0: loss = 1.13232 (* 1 = 1.13232 loss)
I0521 19:37:19.390476 12543 sgd_solver.cpp:106] Iteration 447000, lr = 0.004
I0521 19:37:36.223701 12543 solver.cpp:237] Iteration 448500, loss = 0.90691
I0521 19:37:36.223753 12543 solver.cpp:253]     Train net output #0: loss = 0.906919 (* 1 = 0.906919 loss)
I0521 19:37:36.223772 12543 sgd_solver.cpp:106] Iteration 448500, lr = 0.004
I0521 19:37:53.059519 12543 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_450000.caffemodel
I0521 19:37:53.107045 12543 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_450000.solverstate
I0521 19:37:53.134320 12543 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 19:38:52.128007 12543 solver.cpp:409]     Test net output #0: accuracy = 0.890495
I0521 19:38:52.128204 12543 solver.cpp:409]     Test net output #1: loss = 0.369094 (* 1 = 0.369094 loss)
I0521 19:39:12.994905 12543 solver.cpp:237] Iteration 450000, loss = 0.835416
I0521 19:39:12.994962 12543 solver.cpp:253]     Train net output #0: loss = 0.835426 (* 1 = 0.835426 loss)
I0521 19:39:12.994979 12543 sgd_solver.cpp:106] Iteration 450000, lr = 0.004
I0521 19:39:29.951200 12543 solver.cpp:237] Iteration 451500, loss = 1.20193
I0521 19:39:29.951371 12543 solver.cpp:253]     Train net output #0: loss = 1.20194 (* 1 = 1.20194 loss)
I0521 19:39:29.951385 12543 sgd_solver.cpp:106] Iteration 451500, lr = 0.004
I0521 19:39:46.908362 12543 solver.cpp:237] Iteration 453000, loss = 1.77024
I0521 19:39:46.908412 12543 solver.cpp:253]     Train net output #0: loss = 1.77025 (* 1 = 1.77025 loss)
I0521 19:39:46.908432 12543 sgd_solver.cpp:106] Iteration 453000, lr = 0.004
I0521 19:40:03.862795 12543 solver.cpp:237] Iteration 454500, loss = 1.574
I0521 19:40:03.862978 12543 solver.cpp:253]     Train net output #0: loss = 1.57401 (* 1 = 1.57401 loss)
I0521 19:40:03.862993 12543 sgd_solver.cpp:106] Iteration 454500, lr = 0.004
aprun: Apid 11240559: Caught signal Terminated, sending to application
*** Aborted at 1463874015 (unix time) try "date -d @1463874015" if you are using GNU date ***
aprun: Apid 11240559: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7225 exceeded limit 7200
PC: @     0x2aaab92fb470 (unknown)
aprun: Apid 11240559: Caught signal Terminated, sending to application
*** SIGTERM (@0x30fc) received by PID 12543 (TID 0x2aaac746f900) from PID 12540; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @     0x2aaab92fb470 (unknown)
    @     0x2aaab928ec4d (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11240559: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
aprun: Apid 11240559: Caught signal Terminated, sending to application
