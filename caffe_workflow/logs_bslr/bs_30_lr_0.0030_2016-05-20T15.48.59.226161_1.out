2807438
I0522 11:48:43.247702 12588 caffe.cpp:184] Using GPUs 0
I0522 11:48:43.693609 12588 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.003
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161.prototxt"
I0522 11:48:43.695571 12588 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161.prototxt
I0522 11:48:43.716413 12588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 11:48:43.716472 12588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 11:48:43.716820 12588 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 11:48:43.717000 12588 layer_factory.hpp:77] Creating layer data_hdf5
I0522 11:48:43.717025 12588 net.cpp:106] Creating Layer data_hdf5
I0522 11:48:43.717039 12588 net.cpp:411] data_hdf5 -> data
I0522 11:48:43.717073 12588 net.cpp:411] data_hdf5 -> label
I0522 11:48:43.717105 12588 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 11:48:43.732151 12588 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 11:48:43.743871 12588 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 11:49:05.314070 12588 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 11:49:05.319293 12588 net.cpp:150] Setting up data_hdf5
I0522 11:49:05.319332 12588 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 11:49:05.319347 12588 net.cpp:157] Top shape: 30 (30)
I0522 11:49:05.319360 12588 net.cpp:165] Memory required for data: 762120
I0522 11:49:05.319372 12588 layer_factory.hpp:77] Creating layer conv1
I0522 11:49:05.319406 12588 net.cpp:106] Creating Layer conv1
I0522 11:49:05.319417 12588 net.cpp:454] conv1 <- data
I0522 11:49:05.319438 12588 net.cpp:411] conv1 -> conv1
I0522 11:49:07.771167 12588 net.cpp:150] Setting up conv1
I0522 11:49:07.771214 12588 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 11:49:07.771226 12588 net.cpp:165] Memory required for data: 9056520
I0522 11:49:07.771255 12588 layer_factory.hpp:77] Creating layer relu1
I0522 11:49:07.771276 12588 net.cpp:106] Creating Layer relu1
I0522 11:49:07.771287 12588 net.cpp:454] relu1 <- conv1
I0522 11:49:07.771301 12588 net.cpp:397] relu1 -> conv1 (in-place)
I0522 11:49:07.771817 12588 net.cpp:150] Setting up relu1
I0522 11:49:07.771834 12588 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 11:49:07.771845 12588 net.cpp:165] Memory required for data: 17350920
I0522 11:49:07.771855 12588 layer_factory.hpp:77] Creating layer pool1
I0522 11:49:07.771873 12588 net.cpp:106] Creating Layer pool1
I0522 11:49:07.771883 12588 net.cpp:454] pool1 <- conv1
I0522 11:49:07.771898 12588 net.cpp:411] pool1 -> pool1
I0522 11:49:07.771977 12588 net.cpp:150] Setting up pool1
I0522 11:49:07.771991 12588 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 11:49:07.772001 12588 net.cpp:165] Memory required for data: 21498120
I0522 11:49:07.772012 12588 layer_factory.hpp:77] Creating layer conv2
I0522 11:49:07.772034 12588 net.cpp:106] Creating Layer conv2
I0522 11:49:07.772045 12588 net.cpp:454] conv2 <- pool1
I0522 11:49:07.772058 12588 net.cpp:411] conv2 -> conv2
I0522 11:49:07.774758 12588 net.cpp:150] Setting up conv2
I0522 11:49:07.774785 12588 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 11:49:07.774797 12588 net.cpp:165] Memory required for data: 27459720
I0522 11:49:07.774816 12588 layer_factory.hpp:77] Creating layer relu2
I0522 11:49:07.774830 12588 net.cpp:106] Creating Layer relu2
I0522 11:49:07.774842 12588 net.cpp:454] relu2 <- conv2
I0522 11:49:07.774854 12588 net.cpp:397] relu2 -> conv2 (in-place)
I0522 11:49:07.775183 12588 net.cpp:150] Setting up relu2
I0522 11:49:07.775197 12588 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 11:49:07.775207 12588 net.cpp:165] Memory required for data: 33421320
I0522 11:49:07.775218 12588 layer_factory.hpp:77] Creating layer pool2
I0522 11:49:07.775230 12588 net.cpp:106] Creating Layer pool2
I0522 11:49:07.775240 12588 net.cpp:454] pool2 <- conv2
I0522 11:49:07.775254 12588 net.cpp:411] pool2 -> pool2
I0522 11:49:07.775333 12588 net.cpp:150] Setting up pool2
I0522 11:49:07.775347 12588 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 11:49:07.775357 12588 net.cpp:165] Memory required for data: 36402120
I0522 11:49:07.775367 12588 layer_factory.hpp:77] Creating layer conv3
I0522 11:49:07.775385 12588 net.cpp:106] Creating Layer conv3
I0522 11:49:07.775396 12588 net.cpp:454] conv3 <- pool2
I0522 11:49:07.775409 12588 net.cpp:411] conv3 -> conv3
I0522 11:49:07.777354 12588 net.cpp:150] Setting up conv3
I0522 11:49:07.777379 12588 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 11:49:07.777390 12588 net.cpp:165] Memory required for data: 39654600
I0522 11:49:07.777408 12588 layer_factory.hpp:77] Creating layer relu3
I0522 11:49:07.777425 12588 net.cpp:106] Creating Layer relu3
I0522 11:49:07.777436 12588 net.cpp:454] relu3 <- conv3
I0522 11:49:07.777447 12588 net.cpp:397] relu3 -> conv3 (in-place)
I0522 11:49:07.777914 12588 net.cpp:150] Setting up relu3
I0522 11:49:07.777931 12588 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 11:49:07.777941 12588 net.cpp:165] Memory required for data: 42907080
I0522 11:49:07.777951 12588 layer_factory.hpp:77] Creating layer pool3
I0522 11:49:07.777964 12588 net.cpp:106] Creating Layer pool3
I0522 11:49:07.777974 12588 net.cpp:454] pool3 <- conv3
I0522 11:49:07.777987 12588 net.cpp:411] pool3 -> pool3
I0522 11:49:07.778053 12588 net.cpp:150] Setting up pool3
I0522 11:49:07.778075 12588 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 11:49:07.778085 12588 net.cpp:165] Memory required for data: 44533320
I0522 11:49:07.778095 12588 layer_factory.hpp:77] Creating layer conv4
I0522 11:49:07.778111 12588 net.cpp:106] Creating Layer conv4
I0522 11:49:07.778122 12588 net.cpp:454] conv4 <- pool3
I0522 11:49:07.778137 12588 net.cpp:411] conv4 -> conv4
I0522 11:49:07.780855 12588 net.cpp:150] Setting up conv4
I0522 11:49:07.780884 12588 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 11:49:07.780894 12588 net.cpp:165] Memory required for data: 45621960
I0522 11:49:07.780910 12588 layer_factory.hpp:77] Creating layer relu4
I0522 11:49:07.780925 12588 net.cpp:106] Creating Layer relu4
I0522 11:49:07.780935 12588 net.cpp:454] relu4 <- conv4
I0522 11:49:07.780947 12588 net.cpp:397] relu4 -> conv4 (in-place)
I0522 11:49:07.781407 12588 net.cpp:150] Setting up relu4
I0522 11:49:07.781424 12588 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 11:49:07.781435 12588 net.cpp:165] Memory required for data: 46710600
I0522 11:49:07.781445 12588 layer_factory.hpp:77] Creating layer pool4
I0522 11:49:07.781458 12588 net.cpp:106] Creating Layer pool4
I0522 11:49:07.781468 12588 net.cpp:454] pool4 <- conv4
I0522 11:49:07.781481 12588 net.cpp:411] pool4 -> pool4
I0522 11:49:07.781548 12588 net.cpp:150] Setting up pool4
I0522 11:49:07.781563 12588 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 11:49:07.781572 12588 net.cpp:165] Memory required for data: 47254920
I0522 11:49:07.781582 12588 layer_factory.hpp:77] Creating layer ip1
I0522 11:49:07.781604 12588 net.cpp:106] Creating Layer ip1
I0522 11:49:07.781615 12588 net.cpp:454] ip1 <- pool4
I0522 11:49:07.781626 12588 net.cpp:411] ip1 -> ip1
I0522 11:49:07.797214 12588 net.cpp:150] Setting up ip1
I0522 11:49:07.797243 12588 net.cpp:157] Top shape: 30 196 (5880)
I0522 11:49:07.797260 12588 net.cpp:165] Memory required for data: 47278440
I0522 11:49:07.797284 12588 layer_factory.hpp:77] Creating layer relu5
I0522 11:49:07.797299 12588 net.cpp:106] Creating Layer relu5
I0522 11:49:07.797309 12588 net.cpp:454] relu5 <- ip1
I0522 11:49:07.797323 12588 net.cpp:397] relu5 -> ip1 (in-place)
I0522 11:49:07.797667 12588 net.cpp:150] Setting up relu5
I0522 11:49:07.797680 12588 net.cpp:157] Top shape: 30 196 (5880)
I0522 11:49:07.797691 12588 net.cpp:165] Memory required for data: 47301960
I0522 11:49:07.797701 12588 layer_factory.hpp:77] Creating layer drop1
I0522 11:49:07.797722 12588 net.cpp:106] Creating Layer drop1
I0522 11:49:07.797734 12588 net.cpp:454] drop1 <- ip1
I0522 11:49:07.797745 12588 net.cpp:397] drop1 -> ip1 (in-place)
I0522 11:49:07.797804 12588 net.cpp:150] Setting up drop1
I0522 11:49:07.797818 12588 net.cpp:157] Top shape: 30 196 (5880)
I0522 11:49:07.797828 12588 net.cpp:165] Memory required for data: 47325480
I0522 11:49:07.797838 12588 layer_factory.hpp:77] Creating layer ip2
I0522 11:49:07.797857 12588 net.cpp:106] Creating Layer ip2
I0522 11:49:07.797868 12588 net.cpp:454] ip2 <- ip1
I0522 11:49:07.797879 12588 net.cpp:411] ip2 -> ip2
I0522 11:49:07.798348 12588 net.cpp:150] Setting up ip2
I0522 11:49:07.798360 12588 net.cpp:157] Top shape: 30 98 (2940)
I0522 11:49:07.798370 12588 net.cpp:165] Memory required for data: 47337240
I0522 11:49:07.798385 12588 layer_factory.hpp:77] Creating layer relu6
I0522 11:49:07.798398 12588 net.cpp:106] Creating Layer relu6
I0522 11:49:07.798408 12588 net.cpp:454] relu6 <- ip2
I0522 11:49:07.798419 12588 net.cpp:397] relu6 -> ip2 (in-place)
I0522 11:49:07.798933 12588 net.cpp:150] Setting up relu6
I0522 11:49:07.798949 12588 net.cpp:157] Top shape: 30 98 (2940)
I0522 11:49:07.798960 12588 net.cpp:165] Memory required for data: 47349000
I0522 11:49:07.798970 12588 layer_factory.hpp:77] Creating layer drop2
I0522 11:49:07.798984 12588 net.cpp:106] Creating Layer drop2
I0522 11:49:07.798993 12588 net.cpp:454] drop2 <- ip2
I0522 11:49:07.799005 12588 net.cpp:397] drop2 -> ip2 (in-place)
I0522 11:49:07.799048 12588 net.cpp:150] Setting up drop2
I0522 11:49:07.799062 12588 net.cpp:157] Top shape: 30 98 (2940)
I0522 11:49:07.799072 12588 net.cpp:165] Memory required for data: 47360760
I0522 11:49:07.799082 12588 layer_factory.hpp:77] Creating layer ip3
I0522 11:49:07.799095 12588 net.cpp:106] Creating Layer ip3
I0522 11:49:07.799104 12588 net.cpp:454] ip3 <- ip2
I0522 11:49:07.799118 12588 net.cpp:411] ip3 -> ip3
I0522 11:49:07.799327 12588 net.cpp:150] Setting up ip3
I0522 11:49:07.799340 12588 net.cpp:157] Top shape: 30 11 (330)
I0522 11:49:07.799350 12588 net.cpp:165] Memory required for data: 47362080
I0522 11:49:07.799365 12588 layer_factory.hpp:77] Creating layer drop3
I0522 11:49:07.799378 12588 net.cpp:106] Creating Layer drop3
I0522 11:49:07.799388 12588 net.cpp:454] drop3 <- ip3
I0522 11:49:07.799401 12588 net.cpp:397] drop3 -> ip3 (in-place)
I0522 11:49:07.799440 12588 net.cpp:150] Setting up drop3
I0522 11:49:07.799453 12588 net.cpp:157] Top shape: 30 11 (330)
I0522 11:49:07.799463 12588 net.cpp:165] Memory required for data: 47363400
I0522 11:49:07.799474 12588 layer_factory.hpp:77] Creating layer loss
I0522 11:49:07.799492 12588 net.cpp:106] Creating Layer loss
I0522 11:49:07.799501 12588 net.cpp:454] loss <- ip3
I0522 11:49:07.799512 12588 net.cpp:454] loss <- label
I0522 11:49:07.799525 12588 net.cpp:411] loss -> loss
I0522 11:49:07.799542 12588 layer_factory.hpp:77] Creating layer loss
I0522 11:49:07.800184 12588 net.cpp:150] Setting up loss
I0522 11:49:07.800199 12588 net.cpp:157] Top shape: (1)
I0522 11:49:07.800210 12588 net.cpp:160]     with loss weight 1
I0522 11:49:07.800252 12588 net.cpp:165] Memory required for data: 47363404
I0522 11:49:07.800263 12588 net.cpp:226] loss needs backward computation.
I0522 11:49:07.800274 12588 net.cpp:226] drop3 needs backward computation.
I0522 11:49:07.800284 12588 net.cpp:226] ip3 needs backward computation.
I0522 11:49:07.800292 12588 net.cpp:226] drop2 needs backward computation.
I0522 11:49:07.800303 12588 net.cpp:226] relu6 needs backward computation.
I0522 11:49:07.800313 12588 net.cpp:226] ip2 needs backward computation.
I0522 11:49:07.800323 12588 net.cpp:226] drop1 needs backward computation.
I0522 11:49:07.800333 12588 net.cpp:226] relu5 needs backward computation.
I0522 11:49:07.800343 12588 net.cpp:226] ip1 needs backward computation.
I0522 11:49:07.800354 12588 net.cpp:226] pool4 needs backward computation.
I0522 11:49:07.800364 12588 net.cpp:226] relu4 needs backward computation.
I0522 11:49:07.800374 12588 net.cpp:226] conv4 needs backward computation.
I0522 11:49:07.800384 12588 net.cpp:226] pool3 needs backward computation.
I0522 11:49:07.800395 12588 net.cpp:226] relu3 needs backward computation.
I0522 11:49:07.800405 12588 net.cpp:226] conv3 needs backward computation.
I0522 11:49:07.800425 12588 net.cpp:226] pool2 needs backward computation.
I0522 11:49:07.800436 12588 net.cpp:226] relu2 needs backward computation.
I0522 11:49:07.800446 12588 net.cpp:226] conv2 needs backward computation.
I0522 11:49:07.800457 12588 net.cpp:226] pool1 needs backward computation.
I0522 11:49:07.800467 12588 net.cpp:226] relu1 needs backward computation.
I0522 11:49:07.800477 12588 net.cpp:226] conv1 needs backward computation.
I0522 11:49:07.800487 12588 net.cpp:228] data_hdf5 does not need backward computation.
I0522 11:49:07.800498 12588 net.cpp:270] This network produces output loss
I0522 11:49:07.800521 12588 net.cpp:283] Network initialization done.
I0522 11:49:07.802314 12588 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161.prototxt
I0522 11:49:07.802386 12588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 11:49:07.802741 12588 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 11:49:07.802927 12588 layer_factory.hpp:77] Creating layer data_hdf5
I0522 11:49:07.802942 12588 net.cpp:106] Creating Layer data_hdf5
I0522 11:49:07.802955 12588 net.cpp:411] data_hdf5 -> data
I0522 11:49:07.802971 12588 net.cpp:411] data_hdf5 -> label
I0522 11:49:07.802986 12588 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 11:49:07.814856 12588 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 11:49:29.219735 12588 net.cpp:150] Setting up data_hdf5
I0522 11:49:29.219899 12588 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 11:49:29.219914 12588 net.cpp:157] Top shape: 30 (30)
I0522 11:49:29.219926 12588 net.cpp:165] Memory required for data: 762120
I0522 11:49:29.219939 12588 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 11:49:29.219966 12588 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 11:49:29.219977 12588 net.cpp:454] label_data_hdf5_1_split <- label
I0522 11:49:29.219992 12588 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 11:49:29.220015 12588 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 11:49:29.220087 12588 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 11:49:29.220100 12588 net.cpp:157] Top shape: 30 (30)
I0522 11:49:29.220113 12588 net.cpp:157] Top shape: 30 (30)
I0522 11:49:29.220121 12588 net.cpp:165] Memory required for data: 762360
I0522 11:49:29.220131 12588 layer_factory.hpp:77] Creating layer conv1
I0522 11:49:29.220154 12588 net.cpp:106] Creating Layer conv1
I0522 11:49:29.220165 12588 net.cpp:454] conv1 <- data
I0522 11:49:29.220178 12588 net.cpp:411] conv1 -> conv1
I0522 11:49:29.222106 12588 net.cpp:150] Setting up conv1
I0522 11:49:29.222131 12588 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 11:49:29.222141 12588 net.cpp:165] Memory required for data: 9056760
I0522 11:49:29.222162 12588 layer_factory.hpp:77] Creating layer relu1
I0522 11:49:29.222177 12588 net.cpp:106] Creating Layer relu1
I0522 11:49:29.222187 12588 net.cpp:454] relu1 <- conv1
I0522 11:49:29.222200 12588 net.cpp:397] relu1 -> conv1 (in-place)
I0522 11:49:29.222702 12588 net.cpp:150] Setting up relu1
I0522 11:49:29.222718 12588 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 11:49:29.222728 12588 net.cpp:165] Memory required for data: 17351160
I0522 11:49:29.222738 12588 layer_factory.hpp:77] Creating layer pool1
I0522 11:49:29.222754 12588 net.cpp:106] Creating Layer pool1
I0522 11:49:29.222764 12588 net.cpp:454] pool1 <- conv1
I0522 11:49:29.222777 12588 net.cpp:411] pool1 -> pool1
I0522 11:49:29.222852 12588 net.cpp:150] Setting up pool1
I0522 11:49:29.222865 12588 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 11:49:29.222875 12588 net.cpp:165] Memory required for data: 21498360
I0522 11:49:29.222884 12588 layer_factory.hpp:77] Creating layer conv2
I0522 11:49:29.222903 12588 net.cpp:106] Creating Layer conv2
I0522 11:49:29.222913 12588 net.cpp:454] conv2 <- pool1
I0522 11:49:29.222926 12588 net.cpp:411] conv2 -> conv2
I0522 11:49:29.224838 12588 net.cpp:150] Setting up conv2
I0522 11:49:29.224860 12588 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 11:49:29.224872 12588 net.cpp:165] Memory required for data: 27459960
I0522 11:49:29.224890 12588 layer_factory.hpp:77] Creating layer relu2
I0522 11:49:29.224905 12588 net.cpp:106] Creating Layer relu2
I0522 11:49:29.224915 12588 net.cpp:454] relu2 <- conv2
I0522 11:49:29.224926 12588 net.cpp:397] relu2 -> conv2 (in-place)
I0522 11:49:29.225257 12588 net.cpp:150] Setting up relu2
I0522 11:49:29.225271 12588 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 11:49:29.225281 12588 net.cpp:165] Memory required for data: 33421560
I0522 11:49:29.225291 12588 layer_factory.hpp:77] Creating layer pool2
I0522 11:49:29.225304 12588 net.cpp:106] Creating Layer pool2
I0522 11:49:29.225314 12588 net.cpp:454] pool2 <- conv2
I0522 11:49:29.225327 12588 net.cpp:411] pool2 -> pool2
I0522 11:49:29.225399 12588 net.cpp:150] Setting up pool2
I0522 11:49:29.225412 12588 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 11:49:29.225421 12588 net.cpp:165] Memory required for data: 36402360
I0522 11:49:29.225431 12588 layer_factory.hpp:77] Creating layer conv3
I0522 11:49:29.225450 12588 net.cpp:106] Creating Layer conv3
I0522 11:49:29.225460 12588 net.cpp:454] conv3 <- pool2
I0522 11:49:29.225473 12588 net.cpp:411] conv3 -> conv3
I0522 11:49:29.227452 12588 net.cpp:150] Setting up conv3
I0522 11:49:29.227475 12588 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 11:49:29.227488 12588 net.cpp:165] Memory required for data: 39654840
I0522 11:49:29.227519 12588 layer_factory.hpp:77] Creating layer relu3
I0522 11:49:29.227533 12588 net.cpp:106] Creating Layer relu3
I0522 11:49:29.227543 12588 net.cpp:454] relu3 <- conv3
I0522 11:49:29.227556 12588 net.cpp:397] relu3 -> conv3 (in-place)
I0522 11:49:29.228026 12588 net.cpp:150] Setting up relu3
I0522 11:49:29.228041 12588 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 11:49:29.228052 12588 net.cpp:165] Memory required for data: 42907320
I0522 11:49:29.228061 12588 layer_factory.hpp:77] Creating layer pool3
I0522 11:49:29.228075 12588 net.cpp:106] Creating Layer pool3
I0522 11:49:29.228085 12588 net.cpp:454] pool3 <- conv3
I0522 11:49:29.228097 12588 net.cpp:411] pool3 -> pool3
I0522 11:49:29.228169 12588 net.cpp:150] Setting up pool3
I0522 11:49:29.228183 12588 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 11:49:29.228191 12588 net.cpp:165] Memory required for data: 44533560
I0522 11:49:29.228202 12588 layer_factory.hpp:77] Creating layer conv4
I0522 11:49:29.228219 12588 net.cpp:106] Creating Layer conv4
I0522 11:49:29.228230 12588 net.cpp:454] conv4 <- pool3
I0522 11:49:29.228245 12588 net.cpp:411] conv4 -> conv4
I0522 11:49:29.230314 12588 net.cpp:150] Setting up conv4
I0522 11:49:29.230336 12588 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 11:49:29.230350 12588 net.cpp:165] Memory required for data: 45622200
I0522 11:49:29.230365 12588 layer_factory.hpp:77] Creating layer relu4
I0522 11:49:29.230377 12588 net.cpp:106] Creating Layer relu4
I0522 11:49:29.230388 12588 net.cpp:454] relu4 <- conv4
I0522 11:49:29.230401 12588 net.cpp:397] relu4 -> conv4 (in-place)
I0522 11:49:29.230871 12588 net.cpp:150] Setting up relu4
I0522 11:49:29.230887 12588 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 11:49:29.230897 12588 net.cpp:165] Memory required for data: 46710840
I0522 11:49:29.230907 12588 layer_factory.hpp:77] Creating layer pool4
I0522 11:49:29.230921 12588 net.cpp:106] Creating Layer pool4
I0522 11:49:29.230931 12588 net.cpp:454] pool4 <- conv4
I0522 11:49:29.230944 12588 net.cpp:411] pool4 -> pool4
I0522 11:49:29.231015 12588 net.cpp:150] Setting up pool4
I0522 11:49:29.231029 12588 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 11:49:29.231039 12588 net.cpp:165] Memory required for data: 47255160
I0522 11:49:29.231048 12588 layer_factory.hpp:77] Creating layer ip1
I0522 11:49:29.231061 12588 net.cpp:106] Creating Layer ip1
I0522 11:49:29.231072 12588 net.cpp:454] ip1 <- pool4
I0522 11:49:29.231086 12588 net.cpp:411] ip1 -> ip1
I0522 11:49:29.246573 12588 net.cpp:150] Setting up ip1
I0522 11:49:29.246600 12588 net.cpp:157] Top shape: 30 196 (5880)
I0522 11:49:29.246615 12588 net.cpp:165] Memory required for data: 47278680
I0522 11:49:29.246637 12588 layer_factory.hpp:77] Creating layer relu5
I0522 11:49:29.246651 12588 net.cpp:106] Creating Layer relu5
I0522 11:49:29.246662 12588 net.cpp:454] relu5 <- ip1
I0522 11:49:29.246675 12588 net.cpp:397] relu5 -> ip1 (in-place)
I0522 11:49:29.247020 12588 net.cpp:150] Setting up relu5
I0522 11:49:29.247035 12588 net.cpp:157] Top shape: 30 196 (5880)
I0522 11:49:29.247045 12588 net.cpp:165] Memory required for data: 47302200
I0522 11:49:29.247054 12588 layer_factory.hpp:77] Creating layer drop1
I0522 11:49:29.247073 12588 net.cpp:106] Creating Layer drop1
I0522 11:49:29.247083 12588 net.cpp:454] drop1 <- ip1
I0522 11:49:29.247097 12588 net.cpp:397] drop1 -> ip1 (in-place)
I0522 11:49:29.247143 12588 net.cpp:150] Setting up drop1
I0522 11:49:29.247155 12588 net.cpp:157] Top shape: 30 196 (5880)
I0522 11:49:29.247164 12588 net.cpp:165] Memory required for data: 47325720
I0522 11:49:29.247174 12588 layer_factory.hpp:77] Creating layer ip2
I0522 11:49:29.247189 12588 net.cpp:106] Creating Layer ip2
I0522 11:49:29.247198 12588 net.cpp:454] ip2 <- ip1
I0522 11:49:29.247212 12588 net.cpp:411] ip2 -> ip2
I0522 11:49:29.247689 12588 net.cpp:150] Setting up ip2
I0522 11:49:29.247704 12588 net.cpp:157] Top shape: 30 98 (2940)
I0522 11:49:29.247714 12588 net.cpp:165] Memory required for data: 47337480
I0522 11:49:29.247728 12588 layer_factory.hpp:77] Creating layer relu6
I0522 11:49:29.247753 12588 net.cpp:106] Creating Layer relu6
I0522 11:49:29.247763 12588 net.cpp:454] relu6 <- ip2
I0522 11:49:29.247778 12588 net.cpp:397] relu6 -> ip2 (in-place)
I0522 11:49:29.248311 12588 net.cpp:150] Setting up relu6
I0522 11:49:29.248327 12588 net.cpp:157] Top shape: 30 98 (2940)
I0522 11:49:29.248337 12588 net.cpp:165] Memory required for data: 47349240
I0522 11:49:29.248347 12588 layer_factory.hpp:77] Creating layer drop2
I0522 11:49:29.248360 12588 net.cpp:106] Creating Layer drop2
I0522 11:49:29.248370 12588 net.cpp:454] drop2 <- ip2
I0522 11:49:29.248383 12588 net.cpp:397] drop2 -> ip2 (in-place)
I0522 11:49:29.248427 12588 net.cpp:150] Setting up drop2
I0522 11:49:29.248440 12588 net.cpp:157] Top shape: 30 98 (2940)
I0522 11:49:29.248450 12588 net.cpp:165] Memory required for data: 47361000
I0522 11:49:29.248459 12588 layer_factory.hpp:77] Creating layer ip3
I0522 11:49:29.248473 12588 net.cpp:106] Creating Layer ip3
I0522 11:49:29.248483 12588 net.cpp:454] ip3 <- ip2
I0522 11:49:29.248497 12588 net.cpp:411] ip3 -> ip3
I0522 11:49:29.248719 12588 net.cpp:150] Setting up ip3
I0522 11:49:29.248733 12588 net.cpp:157] Top shape: 30 11 (330)
I0522 11:49:29.248742 12588 net.cpp:165] Memory required for data: 47362320
I0522 11:49:29.248757 12588 layer_factory.hpp:77] Creating layer drop3
I0522 11:49:29.248770 12588 net.cpp:106] Creating Layer drop3
I0522 11:49:29.248780 12588 net.cpp:454] drop3 <- ip3
I0522 11:49:29.248793 12588 net.cpp:397] drop3 -> ip3 (in-place)
I0522 11:49:29.248834 12588 net.cpp:150] Setting up drop3
I0522 11:49:29.248847 12588 net.cpp:157] Top shape: 30 11 (330)
I0522 11:49:29.248857 12588 net.cpp:165] Memory required for data: 47363640
I0522 11:49:29.248865 12588 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 11:49:29.248879 12588 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 11:49:29.248888 12588 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 11:49:29.248901 12588 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 11:49:29.248916 12588 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 11:49:29.248989 12588 net.cpp:150] Setting up ip3_drop3_0_split
I0522 11:49:29.249002 12588 net.cpp:157] Top shape: 30 11 (330)
I0522 11:49:29.249014 12588 net.cpp:157] Top shape: 30 11 (330)
I0522 11:49:29.249024 12588 net.cpp:165] Memory required for data: 47366280
I0522 11:49:29.249037 12588 layer_factory.hpp:77] Creating layer accuracy
I0522 11:49:29.249058 12588 net.cpp:106] Creating Layer accuracy
I0522 11:49:29.249068 12588 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 11:49:29.249079 12588 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 11:49:29.249092 12588 net.cpp:411] accuracy -> accuracy
I0522 11:49:29.249115 12588 net.cpp:150] Setting up accuracy
I0522 11:49:29.249128 12588 net.cpp:157] Top shape: (1)
I0522 11:49:29.249138 12588 net.cpp:165] Memory required for data: 47366284
I0522 11:49:29.249147 12588 layer_factory.hpp:77] Creating layer loss
I0522 11:49:29.249161 12588 net.cpp:106] Creating Layer loss
I0522 11:49:29.249171 12588 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 11:49:29.249181 12588 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 11:49:29.249196 12588 net.cpp:411] loss -> loss
I0522 11:49:29.249212 12588 layer_factory.hpp:77] Creating layer loss
I0522 11:49:29.249697 12588 net.cpp:150] Setting up loss
I0522 11:49:29.249711 12588 net.cpp:157] Top shape: (1)
I0522 11:49:29.249722 12588 net.cpp:160]     with loss weight 1
I0522 11:49:29.249739 12588 net.cpp:165] Memory required for data: 47366288
I0522 11:49:29.249749 12588 net.cpp:226] loss needs backward computation.
I0522 11:49:29.249760 12588 net.cpp:228] accuracy does not need backward computation.
I0522 11:49:29.249771 12588 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 11:49:29.249783 12588 net.cpp:226] drop3 needs backward computation.
I0522 11:49:29.249790 12588 net.cpp:226] ip3 needs backward computation.
I0522 11:49:29.249800 12588 net.cpp:226] drop2 needs backward computation.
I0522 11:49:29.249810 12588 net.cpp:226] relu6 needs backward computation.
I0522 11:49:29.249828 12588 net.cpp:226] ip2 needs backward computation.
I0522 11:49:29.249838 12588 net.cpp:226] drop1 needs backward computation.
I0522 11:49:29.249848 12588 net.cpp:226] relu5 needs backward computation.
I0522 11:49:29.249857 12588 net.cpp:226] ip1 needs backward computation.
I0522 11:49:29.249867 12588 net.cpp:226] pool4 needs backward computation.
I0522 11:49:29.249877 12588 net.cpp:226] relu4 needs backward computation.
I0522 11:49:29.249887 12588 net.cpp:226] conv4 needs backward computation.
I0522 11:49:29.249896 12588 net.cpp:226] pool3 needs backward computation.
I0522 11:49:29.249907 12588 net.cpp:226] relu3 needs backward computation.
I0522 11:49:29.249917 12588 net.cpp:226] conv3 needs backward computation.
I0522 11:49:29.249927 12588 net.cpp:226] pool2 needs backward computation.
I0522 11:49:29.249936 12588 net.cpp:226] relu2 needs backward computation.
I0522 11:49:29.249946 12588 net.cpp:226] conv2 needs backward computation.
I0522 11:49:29.249956 12588 net.cpp:226] pool1 needs backward computation.
I0522 11:49:29.249968 12588 net.cpp:226] relu1 needs backward computation.
I0522 11:49:29.249976 12588 net.cpp:226] conv1 needs backward computation.
I0522 11:49:29.249989 12588 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 11:49:29.250000 12588 net.cpp:228] data_hdf5 does not need backward computation.
I0522 11:49:29.250010 12588 net.cpp:270] This network produces output accuracy
I0522 11:49:29.250020 12588 net.cpp:270] This network produces output loss
I0522 11:49:29.250048 12588 net.cpp:283] Network initialization done.
I0522 11:49:29.250190 12588 solver.cpp:60] Solver scaffolding done.
I0522 11:49:29.251322 12588 caffe.cpp:212] Starting Optimization
I0522 11:49:29.251341 12588 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 11:49:29.251354 12588 solver.cpp:289] Learning Rate Policy: fixed
I0522 11:49:29.252569 12588 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 11:50:19.849720 12588 solver.cpp:409]     Test net output #0: accuracy = 0.0912283
I0522 11:50:19.849879 12588 solver.cpp:409]     Test net output #1: loss = 2.39812 (* 1 = 2.39812 loss)
I0522 11:50:19.870666 12588 solver.cpp:237] Iteration 0, loss = 2.39332
I0522 11:50:19.870703 12588 solver.cpp:253]     Train net output #0: loss = 2.39332 (* 1 = 2.39332 loss)
I0522 11:50:19.870721 12588 sgd_solver.cpp:106] Iteration 0, lr = 0.003
I0522 11:50:30.410514 12588 solver.cpp:237] Iteration 500, loss = 2.1732
I0522 11:50:30.410552 12588 solver.cpp:253]     Train net output #0: loss = 2.1732 (* 1 = 2.1732 loss)
I0522 11:50:30.410567 12588 sgd_solver.cpp:106] Iteration 500, lr = 0.003
I0522 11:50:40.971770 12588 solver.cpp:237] Iteration 1000, loss = 1.99538
I0522 11:50:40.971815 12588 solver.cpp:253]     Train net output #0: loss = 1.99538 (* 1 = 1.99538 loss)
I0522 11:50:40.971832 12588 sgd_solver.cpp:106] Iteration 1000, lr = 0.003
I0522 11:50:51.524417 12588 solver.cpp:237] Iteration 1500, loss = 1.89484
I0522 11:50:51.524565 12588 solver.cpp:253]     Train net output #0: loss = 1.89484 (* 1 = 1.89484 loss)
I0522 11:50:51.524581 12588 sgd_solver.cpp:106] Iteration 1500, lr = 0.003
I0522 11:51:02.074224 12588 solver.cpp:237] Iteration 2000, loss = 1.71157
I0522 11:51:02.074267 12588 solver.cpp:253]     Train net output #0: loss = 1.71157 (* 1 = 1.71157 loss)
I0522 11:51:02.074283 12588 sgd_solver.cpp:106] Iteration 2000, lr = 0.003
I0522 11:51:12.626221 12588 solver.cpp:237] Iteration 2500, loss = 1.90649
I0522 11:51:12.626257 12588 solver.cpp:253]     Train net output #0: loss = 1.90649 (* 1 = 1.90649 loss)
I0522 11:51:12.626273 12588 sgd_solver.cpp:106] Iteration 2500, lr = 0.003
I0522 11:51:23.188233 12588 solver.cpp:237] Iteration 3000, loss = 1.40034
I0522 11:51:23.188369 12588 solver.cpp:253]     Train net output #0: loss = 1.40034 (* 1 = 1.40034 loss)
I0522 11:51:23.188382 12588 sgd_solver.cpp:106] Iteration 3000, lr = 0.003
I0522 11:51:55.945513 12588 solver.cpp:237] Iteration 3500, loss = 1.39053
I0522 11:51:55.945677 12588 solver.cpp:253]     Train net output #0: loss = 1.39053 (* 1 = 1.39053 loss)
I0522 11:51:55.945693 12588 sgd_solver.cpp:106] Iteration 3500, lr = 0.003
I0522 11:52:06.499210 12588 solver.cpp:237] Iteration 4000, loss = 1.2434
I0522 11:52:06.499246 12588 solver.cpp:253]     Train net output #0: loss = 1.2434 (* 1 = 1.2434 loss)
I0522 11:52:06.499263 12588 sgd_solver.cpp:106] Iteration 4000, lr = 0.003
I0522 11:52:17.046368 12588 solver.cpp:237] Iteration 4500, loss = 1.5364
I0522 11:52:17.046416 12588 solver.cpp:253]     Train net output #0: loss = 1.5364 (* 1 = 1.5364 loss)
I0522 11:52:17.046432 12588 sgd_solver.cpp:106] Iteration 4500, lr = 0.003
I0522 11:52:27.575428 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_5000.caffemodel
I0522 11:52:27.632055 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_5000.solverstate
I0522 11:52:27.663835 12588 solver.cpp:237] Iteration 5000, loss = 1.43874
I0522 11:52:27.663879 12588 solver.cpp:253]     Train net output #0: loss = 1.43874 (* 1 = 1.43874 loss)
I0522 11:52:27.663894 12588 sgd_solver.cpp:106] Iteration 5000, lr = 0.003
I0522 11:52:38.213973 12588 solver.cpp:237] Iteration 5500, loss = 1.7679
I0522 11:52:38.214010 12588 solver.cpp:253]     Train net output #0: loss = 1.7679 (* 1 = 1.7679 loss)
I0522 11:52:38.214026 12588 sgd_solver.cpp:106] Iteration 5500, lr = 0.003
I0522 11:52:48.777729 12588 solver.cpp:237] Iteration 6000, loss = 1.4095
I0522 11:52:48.777773 12588 solver.cpp:253]     Train net output #0: loss = 1.4095 (* 1 = 1.4095 loss)
I0522 11:52:48.777788 12588 sgd_solver.cpp:106] Iteration 6000, lr = 0.003
I0522 11:52:59.321898 12588 solver.cpp:237] Iteration 6500, loss = 1.55326
I0522 11:52:59.322041 12588 solver.cpp:253]     Train net output #0: loss = 1.55326 (* 1 = 1.55326 loss)
I0522 11:52:59.322054 12588 sgd_solver.cpp:106] Iteration 6500, lr = 0.003
I0522 11:53:32.087265 12588 solver.cpp:237] Iteration 7000, loss = 1.43985
I0522 11:53:32.087435 12588 solver.cpp:253]     Train net output #0: loss = 1.43985 (* 1 = 1.43985 loss)
I0522 11:53:32.087450 12588 sgd_solver.cpp:106] Iteration 7000, lr = 0.003
I0522 11:53:42.658851 12588 solver.cpp:237] Iteration 7500, loss = 1.45118
I0522 11:53:42.658887 12588 solver.cpp:253]     Train net output #0: loss = 1.45118 (* 1 = 1.45118 loss)
I0522 11:53:42.658905 12588 sgd_solver.cpp:106] Iteration 7500, lr = 0.003
I0522 11:53:53.233355 12588 solver.cpp:237] Iteration 8000, loss = 1.36679
I0522 11:53:53.233391 12588 solver.cpp:253]     Train net output #0: loss = 1.36679 (* 1 = 1.36679 loss)
I0522 11:53:53.233407 12588 sgd_solver.cpp:106] Iteration 8000, lr = 0.003
I0522 11:54:03.807837 12588 solver.cpp:237] Iteration 8500, loss = 1.64839
I0522 11:54:03.807998 12588 solver.cpp:253]     Train net output #0: loss = 1.64839 (* 1 = 1.64839 loss)
I0522 11:54:03.808013 12588 sgd_solver.cpp:106] Iteration 8500, lr = 0.003
I0522 11:54:14.372728 12588 solver.cpp:237] Iteration 9000, loss = 1.18565
I0522 11:54:14.372764 12588 solver.cpp:253]     Train net output #0: loss = 1.18565 (* 1 = 1.18565 loss)
I0522 11:54:14.372781 12588 sgd_solver.cpp:106] Iteration 9000, lr = 0.003
I0522 11:54:24.937371 12588 solver.cpp:237] Iteration 9500, loss = 1.57878
I0522 11:54:24.937417 12588 solver.cpp:253]     Train net output #0: loss = 1.57878 (* 1 = 1.57878 loss)
I0522 11:54:24.937430 12588 sgd_solver.cpp:106] Iteration 9500, lr = 0.003
I0522 11:54:35.482431 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_10000.caffemodel
I0522 11:54:35.534821 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_10000.solverstate
I0522 11:54:35.560341 12588 solver.cpp:341] Iteration 10000, Testing net (#0)
I0522 11:55:25.143996 12588 solver.cpp:409]     Test net output #0: accuracy = 0.826418
I0522 11:55:25.144170 12588 solver.cpp:409]     Test net output #1: loss = 0.586402 (* 1 = 0.586402 loss)
I0522 11:55:47.363342 12588 solver.cpp:237] Iteration 10000, loss = 1.21521
I0522 11:55:47.363395 12588 solver.cpp:253]     Train net output #0: loss = 1.21521 (* 1 = 1.21521 loss)
I0522 11:55:47.363409 12588 sgd_solver.cpp:106] Iteration 10000, lr = 0.003
I0522 11:55:57.958966 12588 solver.cpp:237] Iteration 10500, loss = 1.04214
I0522 11:55:57.959123 12588 solver.cpp:253]     Train net output #0: loss = 1.04214 (* 1 = 1.04214 loss)
I0522 11:55:57.959137 12588 sgd_solver.cpp:106] Iteration 10500, lr = 0.003
I0522 11:56:08.555291 12588 solver.cpp:237] Iteration 11000, loss = 1.51005
I0522 11:56:08.555346 12588 solver.cpp:253]     Train net output #0: loss = 1.51005 (* 1 = 1.51005 loss)
I0522 11:56:08.555361 12588 sgd_solver.cpp:106] Iteration 11000, lr = 0.003
I0522 11:56:19.146631 12588 solver.cpp:237] Iteration 11500, loss = 1.4711
I0522 11:56:19.146667 12588 solver.cpp:253]     Train net output #0: loss = 1.4711 (* 1 = 1.4711 loss)
I0522 11:56:19.146682 12588 sgd_solver.cpp:106] Iteration 11500, lr = 0.003
I0522 11:56:29.746778 12588 solver.cpp:237] Iteration 12000, loss = 1.05589
I0522 11:56:29.746928 12588 solver.cpp:253]     Train net output #0: loss = 1.05589 (* 1 = 1.05589 loss)
I0522 11:56:29.746943 12588 sgd_solver.cpp:106] Iteration 12000, lr = 0.003
I0522 11:56:40.337455 12588 solver.cpp:237] Iteration 12500, loss = 1.53231
I0522 11:56:40.337492 12588 solver.cpp:253]     Train net output #0: loss = 1.53231 (* 1 = 1.53231 loss)
I0522 11:56:40.337508 12588 sgd_solver.cpp:106] Iteration 12500, lr = 0.003
I0522 11:56:50.938271 12588 solver.cpp:237] Iteration 13000, loss = 1.22309
I0522 11:56:50.938313 12588 solver.cpp:253]     Train net output #0: loss = 1.22309 (* 1 = 1.22309 loss)
I0522 11:56:50.938330 12588 sgd_solver.cpp:106] Iteration 13000, lr = 0.003
I0522 11:57:23.773663 12588 solver.cpp:237] Iteration 13500, loss = 0.931393
I0522 11:57:23.773826 12588 solver.cpp:253]     Train net output #0: loss = 0.931393 (* 1 = 0.931393 loss)
I0522 11:57:23.773843 12588 sgd_solver.cpp:106] Iteration 13500, lr = 0.003
I0522 11:57:34.365008 12588 solver.cpp:237] Iteration 14000, loss = 1.53575
I0522 11:57:34.365044 12588 solver.cpp:253]     Train net output #0: loss = 1.53575 (* 1 = 1.53575 loss)
I0522 11:57:34.365057 12588 sgd_solver.cpp:106] Iteration 14000, lr = 0.003
I0522 11:57:44.913605 12588 solver.cpp:237] Iteration 14500, loss = 1.4064
I0522 11:57:44.913651 12588 solver.cpp:253]     Train net output #0: loss = 1.4064 (* 1 = 1.4064 loss)
I0522 11:57:44.913666 12588 sgd_solver.cpp:106] Iteration 14500, lr = 0.003
I0522 11:57:55.384274 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_15000.caffemodel
I0522 11:57:55.439208 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_15000.solverstate
I0522 11:57:55.473536 12588 solver.cpp:237] Iteration 15000, loss = 1.31219
I0522 11:57:55.473585 12588 solver.cpp:253]     Train net output #0: loss = 1.31219 (* 1 = 1.31219 loss)
I0522 11:57:55.473599 12588 sgd_solver.cpp:106] Iteration 15000, lr = 0.003
I0522 11:58:05.973724 12588 solver.cpp:237] Iteration 15500, loss = 1.33764
I0522 11:58:05.973775 12588 solver.cpp:253]     Train net output #0: loss = 1.33764 (* 1 = 1.33764 loss)
I0522 11:58:05.973790 12588 sgd_solver.cpp:106] Iteration 15500, lr = 0.003
I0522 11:58:16.594521 12588 solver.cpp:237] Iteration 16000, loss = 1.1686
I0522 11:58:16.594557 12588 solver.cpp:253]     Train net output #0: loss = 1.1686 (* 1 = 1.1686 loss)
I0522 11:58:16.594573 12588 sgd_solver.cpp:106] Iteration 16000, lr = 0.003
I0522 11:58:27.200793 12588 solver.cpp:237] Iteration 16500, loss = 1.142
I0522 11:58:27.200940 12588 solver.cpp:253]     Train net output #0: loss = 1.142 (* 1 = 1.142 loss)
I0522 11:58:27.200953 12588 sgd_solver.cpp:106] Iteration 16500, lr = 0.003
I0522 11:58:59.967638 12588 solver.cpp:237] Iteration 17000, loss = 1.44165
I0522 11:58:59.967813 12588 solver.cpp:253]     Train net output #0: loss = 1.44165 (* 1 = 1.44165 loss)
I0522 11:58:59.967828 12588 sgd_solver.cpp:106] Iteration 17000, lr = 0.003
I0522 11:59:10.514945 12588 solver.cpp:237] Iteration 17500, loss = 1.5379
I0522 11:59:10.514981 12588 solver.cpp:253]     Train net output #0: loss = 1.5379 (* 1 = 1.5379 loss)
I0522 11:59:10.514998 12588 sgd_solver.cpp:106] Iteration 17500, lr = 0.003
I0522 11:59:21.073381 12588 solver.cpp:237] Iteration 18000, loss = 1.20174
I0522 11:59:21.073426 12588 solver.cpp:253]     Train net output #0: loss = 1.20174 (* 1 = 1.20174 loss)
I0522 11:59:21.073442 12588 sgd_solver.cpp:106] Iteration 18000, lr = 0.003
I0522 11:59:31.647574 12588 solver.cpp:237] Iteration 18500, loss = 1.29842
I0522 11:59:31.647730 12588 solver.cpp:253]     Train net output #0: loss = 1.29842 (* 1 = 1.29842 loss)
I0522 11:59:31.647743 12588 sgd_solver.cpp:106] Iteration 18500, lr = 0.003
I0522 11:59:42.191481 12588 solver.cpp:237] Iteration 19000, loss = 1.32716
I0522 11:59:42.191517 12588 solver.cpp:253]     Train net output #0: loss = 1.32716 (* 1 = 1.32716 loss)
I0522 11:59:42.191534 12588 sgd_solver.cpp:106] Iteration 19000, lr = 0.003
I0522 11:59:52.744665 12588 solver.cpp:237] Iteration 19500, loss = 0.998259
I0522 11:59:52.744714 12588 solver.cpp:253]     Train net output #0: loss = 0.998259 (* 1 = 0.998259 loss)
I0522 11:59:52.744729 12588 sgd_solver.cpp:106] Iteration 19500, lr = 0.003
I0522 12:00:03.274051 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_20000.caffemodel
I0522 12:00:03.331265 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_20000.solverstate
I0522 12:00:03.360450 12588 solver.cpp:341] Iteration 20000, Testing net (#0)
I0522 12:01:13.855803 12588 solver.cpp:409]     Test net output #0: accuracy = 0.849614
I0522 12:01:13.855960 12588 solver.cpp:409]     Test net output #1: loss = 0.522894 (* 1 = 0.522894 loss)
I0522 12:01:36.051143 12588 solver.cpp:237] Iteration 20000, loss = 1.13504
I0522 12:01:36.051198 12588 solver.cpp:253]     Train net output #0: loss = 1.13504 (* 1 = 1.13504 loss)
I0522 12:01:36.051213 12588 sgd_solver.cpp:106] Iteration 20000, lr = 0.003
I0522 12:01:46.549826 12588 solver.cpp:237] Iteration 20500, loss = 1.24899
I0522 12:01:46.549985 12588 solver.cpp:253]     Train net output #0: loss = 1.24899 (* 1 = 1.24899 loss)
I0522 12:01:46.549999 12588 sgd_solver.cpp:106] Iteration 20500, lr = 0.003
I0522 12:01:57.058964 12588 solver.cpp:237] Iteration 21000, loss = 1.65369
I0522 12:01:57.059007 12588 solver.cpp:253]     Train net output #0: loss = 1.65369 (* 1 = 1.65369 loss)
I0522 12:01:57.059023 12588 sgd_solver.cpp:106] Iteration 21000, lr = 0.003
I0522 12:02:07.562562 12588 solver.cpp:237] Iteration 21500, loss = 1.07219
I0522 12:02:07.562598 12588 solver.cpp:253]     Train net output #0: loss = 1.07219 (* 1 = 1.07219 loss)
I0522 12:02:07.562614 12588 sgd_solver.cpp:106] Iteration 21500, lr = 0.003
I0522 12:02:18.062679 12588 solver.cpp:237] Iteration 22000, loss = 1.53478
I0522 12:02:18.062829 12588 solver.cpp:253]     Train net output #0: loss = 1.53478 (* 1 = 1.53478 loss)
I0522 12:02:18.062844 12588 sgd_solver.cpp:106] Iteration 22000, lr = 0.003
I0522 12:02:28.580114 12588 solver.cpp:237] Iteration 22500, loss = 1.07124
I0522 12:02:28.580148 12588 solver.cpp:253]     Train net output #0: loss = 1.07124 (* 1 = 1.07124 loss)
I0522 12:02:28.580166 12588 sgd_solver.cpp:106] Iteration 22500, lr = 0.003
I0522 12:02:39.086464 12588 solver.cpp:237] Iteration 23000, loss = 1.25012
I0522 12:02:39.086510 12588 solver.cpp:253]     Train net output #0: loss = 1.25012 (* 1 = 1.25012 loss)
I0522 12:02:39.086524 12588 sgd_solver.cpp:106] Iteration 23000, lr = 0.003
I0522 12:03:11.829200 12588 solver.cpp:237] Iteration 23500, loss = 1.31171
I0522 12:03:11.829365 12588 solver.cpp:253]     Train net output #0: loss = 1.31171 (* 1 = 1.31171 loss)
I0522 12:03:11.829380 12588 sgd_solver.cpp:106] Iteration 23500, lr = 0.003
I0522 12:03:22.331061 12588 solver.cpp:237] Iteration 24000, loss = 1.22643
I0522 12:03:22.331097 12588 solver.cpp:253]     Train net output #0: loss = 1.22644 (* 1 = 1.22644 loss)
I0522 12:03:22.331113 12588 sgd_solver.cpp:106] Iteration 24000, lr = 0.003
I0522 12:03:32.842725 12588 solver.cpp:237] Iteration 24500, loss = 1.12574
I0522 12:03:32.842772 12588 solver.cpp:253]     Train net output #0: loss = 1.12574 (* 1 = 1.12574 loss)
I0522 12:03:32.842787 12588 sgd_solver.cpp:106] Iteration 24500, lr = 0.003
I0522 12:03:43.317468 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_25000.caffemodel
I0522 12:03:43.372387 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_25000.solverstate
I0522 12:03:43.407490 12588 solver.cpp:237] Iteration 25000, loss = 1.25757
I0522 12:03:43.407538 12588 solver.cpp:253]     Train net output #0: loss = 1.25757 (* 1 = 1.25757 loss)
I0522 12:03:43.407552 12588 sgd_solver.cpp:106] Iteration 25000, lr = 0.003
I0522 12:03:53.919906 12588 solver.cpp:237] Iteration 25500, loss = 1.33012
I0522 12:03:53.919937 12588 solver.cpp:253]     Train net output #0: loss = 1.33012 (* 1 = 1.33012 loss)
I0522 12:03:53.919950 12588 sgd_solver.cpp:106] Iteration 25500, lr = 0.003
I0522 12:04:04.454596 12588 solver.cpp:237] Iteration 26000, loss = 1.24541
I0522 12:04:04.454632 12588 solver.cpp:253]     Train net output #0: loss = 1.24541 (* 1 = 1.24541 loss)
I0522 12:04:04.454649 12588 sgd_solver.cpp:106] Iteration 26000, lr = 0.003
I0522 12:04:14.968145 12588 solver.cpp:237] Iteration 26500, loss = 1.20381
I0522 12:04:14.968282 12588 solver.cpp:253]     Train net output #0: loss = 1.20381 (* 1 = 1.20381 loss)
I0522 12:04:14.968297 12588 sgd_solver.cpp:106] Iteration 26500, lr = 0.003
I0522 12:04:47.786835 12588 solver.cpp:237] Iteration 27000, loss = 1.12003
I0522 12:04:47.787011 12588 solver.cpp:253]     Train net output #0: loss = 1.12003 (* 1 = 1.12003 loss)
I0522 12:04:47.787027 12588 sgd_solver.cpp:106] Iteration 27000, lr = 0.003
I0522 12:04:58.304466 12588 solver.cpp:237] Iteration 27500, loss = 0.850446
I0522 12:04:58.304502 12588 solver.cpp:253]     Train net output #0: loss = 0.850447 (* 1 = 0.850447 loss)
I0522 12:04:58.304518 12588 sgd_solver.cpp:106] Iteration 27500, lr = 0.003
I0522 12:05:08.812312 12588 solver.cpp:237] Iteration 28000, loss = 1.45625
I0522 12:05:08.812348 12588 solver.cpp:253]     Train net output #0: loss = 1.45625 (* 1 = 1.45625 loss)
I0522 12:05:08.812366 12588 sgd_solver.cpp:106] Iteration 28000, lr = 0.003
I0522 12:05:19.305681 12588 solver.cpp:237] Iteration 28500, loss = 1.20291
I0522 12:05:19.305832 12588 solver.cpp:253]     Train net output #0: loss = 1.20291 (* 1 = 1.20291 loss)
I0522 12:05:19.305848 12588 sgd_solver.cpp:106] Iteration 28500, lr = 0.003
I0522 12:05:29.799285 12588 solver.cpp:237] Iteration 29000, loss = 1.2699
I0522 12:05:29.799320 12588 solver.cpp:253]     Train net output #0: loss = 1.2699 (* 1 = 1.2699 loss)
I0522 12:05:29.799334 12588 sgd_solver.cpp:106] Iteration 29000, lr = 0.003
I0522 12:05:40.304322 12588 solver.cpp:237] Iteration 29500, loss = 1.04783
I0522 12:05:40.304368 12588 solver.cpp:253]     Train net output #0: loss = 1.04783 (* 1 = 1.04783 loss)
I0522 12:05:40.304383 12588 sgd_solver.cpp:106] Iteration 29500, lr = 0.003
I0522 12:05:50.776958 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_30000.caffemodel
I0522 12:05:50.833029 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_30000.solverstate
I0522 12:05:50.859246 12588 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 12:06:40.129081 12588 solver.cpp:409]     Test net output #0: accuracy = 0.859391
I0522 12:06:40.129254 12588 solver.cpp:409]     Test net output #1: loss = 0.471834 (* 1 = 0.471834 loss)
I0522 12:07:02.380378 12588 solver.cpp:237] Iteration 30000, loss = 1.1948
I0522 12:07:02.380429 12588 solver.cpp:253]     Train net output #0: loss = 1.1948 (* 1 = 1.1948 loss)
I0522 12:07:02.380444 12588 sgd_solver.cpp:106] Iteration 30000, lr = 0.003
I0522 12:07:12.893952 12588 solver.cpp:237] Iteration 30500, loss = 1.13033
I0522 12:07:12.894121 12588 solver.cpp:253]     Train net output #0: loss = 1.13033 (* 1 = 1.13033 loss)
I0522 12:07:12.894135 12588 sgd_solver.cpp:106] Iteration 30500, lr = 0.003
I0522 12:07:23.415138 12588 solver.cpp:237] Iteration 31000, loss = 1.4674
I0522 12:07:23.415181 12588 solver.cpp:253]     Train net output #0: loss = 1.4674 (* 1 = 1.4674 loss)
I0522 12:07:23.415196 12588 sgd_solver.cpp:106] Iteration 31000, lr = 0.003
I0522 12:07:33.967433 12588 solver.cpp:237] Iteration 31500, loss = 1.16805
I0522 12:07:33.967469 12588 solver.cpp:253]     Train net output #0: loss = 1.16805 (* 1 = 1.16805 loss)
I0522 12:07:33.967486 12588 sgd_solver.cpp:106] Iteration 31500, lr = 0.003
I0522 12:07:44.516536 12588 solver.cpp:237] Iteration 32000, loss = 1.10307
I0522 12:07:44.516690 12588 solver.cpp:253]     Train net output #0: loss = 1.10307 (* 1 = 1.10307 loss)
I0522 12:07:44.516706 12588 sgd_solver.cpp:106] Iteration 32000, lr = 0.003
I0522 12:07:55.081233 12588 solver.cpp:237] Iteration 32500, loss = 1.32167
I0522 12:07:55.081269 12588 solver.cpp:253]     Train net output #0: loss = 1.32167 (* 1 = 1.32167 loss)
I0522 12:07:55.081285 12588 sgd_solver.cpp:106] Iteration 32500, lr = 0.003
I0522 12:08:05.618657 12588 solver.cpp:237] Iteration 33000, loss = 1.05011
I0522 12:08:05.618703 12588 solver.cpp:253]     Train net output #0: loss = 1.05011 (* 1 = 1.05011 loss)
I0522 12:08:05.618718 12588 sgd_solver.cpp:106] Iteration 33000, lr = 0.003
I0522 12:08:38.431522 12588 solver.cpp:237] Iteration 33500, loss = 1.35736
I0522 12:08:38.431700 12588 solver.cpp:253]     Train net output #0: loss = 1.35736 (* 1 = 1.35736 loss)
I0522 12:08:38.431716 12588 sgd_solver.cpp:106] Iteration 33500, lr = 0.003
I0522 12:08:48.992059 12588 solver.cpp:237] Iteration 34000, loss = 1.28566
I0522 12:08:48.992095 12588 solver.cpp:253]     Train net output #0: loss = 1.28566 (* 1 = 1.28566 loss)
I0522 12:08:48.992113 12588 sgd_solver.cpp:106] Iteration 34000, lr = 0.003
I0522 12:08:59.547694 12588 solver.cpp:237] Iteration 34500, loss = 1.31757
I0522 12:08:59.547744 12588 solver.cpp:253]     Train net output #0: loss = 1.31757 (* 1 = 1.31757 loss)
I0522 12:08:59.547757 12588 sgd_solver.cpp:106] Iteration 34500, lr = 0.003
I0522 12:09:10.077322 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_35000.caffemodel
I0522 12:09:10.130312 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_35000.solverstate
I0522 12:09:10.163847 12588 solver.cpp:237] Iteration 35000, loss = 1.31477
I0522 12:09:10.163894 12588 solver.cpp:253]     Train net output #0: loss = 1.31477 (* 1 = 1.31477 loss)
I0522 12:09:10.163908 12588 sgd_solver.cpp:106] Iteration 35000, lr = 0.003
I0522 12:09:20.711576 12588 solver.cpp:237] Iteration 35500, loss = 1.4014
I0522 12:09:20.711624 12588 solver.cpp:253]     Train net output #0: loss = 1.4014 (* 1 = 1.4014 loss)
I0522 12:09:20.711638 12588 sgd_solver.cpp:106] Iteration 35500, lr = 0.003
I0522 12:09:31.262722 12588 solver.cpp:237] Iteration 36000, loss = 1.25229
I0522 12:09:31.262759 12588 solver.cpp:253]     Train net output #0: loss = 1.25229 (* 1 = 1.25229 loss)
I0522 12:09:31.262774 12588 sgd_solver.cpp:106] Iteration 36000, lr = 0.003
I0522 12:09:41.807785 12588 solver.cpp:237] Iteration 36500, loss = 1.22976
I0522 12:09:41.807932 12588 solver.cpp:253]     Train net output #0: loss = 1.22976 (* 1 = 1.22976 loss)
I0522 12:09:41.807946 12588 sgd_solver.cpp:106] Iteration 36500, lr = 0.003
I0522 12:10:14.609629 12588 solver.cpp:237] Iteration 37000, loss = 0.886174
I0522 12:10:14.609797 12588 solver.cpp:253]     Train net output #0: loss = 0.886175 (* 1 = 0.886175 loss)
I0522 12:10:14.609813 12588 sgd_solver.cpp:106] Iteration 37000, lr = 0.003
I0522 12:10:25.158131 12588 solver.cpp:237] Iteration 37500, loss = 1.45171
I0522 12:10:25.158167 12588 solver.cpp:253]     Train net output #0: loss = 1.45171 (* 1 = 1.45171 loss)
I0522 12:10:25.158185 12588 sgd_solver.cpp:106] Iteration 37500, lr = 0.003
I0522 12:10:35.716323 12588 solver.cpp:237] Iteration 38000, loss = 1.39242
I0522 12:10:35.716370 12588 solver.cpp:253]     Train net output #0: loss = 1.39242 (* 1 = 1.39242 loss)
I0522 12:10:35.716385 12588 sgd_solver.cpp:106] Iteration 38000, lr = 0.003
I0522 12:10:46.268504 12588 solver.cpp:237] Iteration 38500, loss = 1.26746
I0522 12:10:46.268661 12588 solver.cpp:253]     Train net output #0: loss = 1.26746 (* 1 = 1.26746 loss)
I0522 12:10:46.268676 12588 sgd_solver.cpp:106] Iteration 38500, lr = 0.003
I0522 12:10:56.824375 12588 solver.cpp:237] Iteration 39000, loss = 1.24243
I0522 12:10:56.824411 12588 solver.cpp:253]     Train net output #0: loss = 1.24243 (* 1 = 1.24243 loss)
I0522 12:10:56.824427 12588 sgd_solver.cpp:106] Iteration 39000, lr = 0.003
I0522 12:11:07.371834 12588 solver.cpp:237] Iteration 39500, loss = 1.08603
I0522 12:11:07.371881 12588 solver.cpp:253]     Train net output #0: loss = 1.08603 (* 1 = 1.08603 loss)
I0522 12:11:07.371896 12588 sgd_solver.cpp:106] Iteration 39500, lr = 0.003
I0522 12:11:17.893196 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_40000.caffemodel
I0522 12:11:17.949333 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_40000.solverstate
I0522 12:11:17.975739 12588 solver.cpp:341] Iteration 40000, Testing net (#0)
I0522 12:12:28.415508 12588 solver.cpp:409]     Test net output #0: accuracy = 0.874476
I0522 12:12:28.415681 12588 solver.cpp:409]     Test net output #1: loss = 0.395579 (* 1 = 0.395579 loss)
I0522 12:12:50.610268 12588 solver.cpp:237] Iteration 40000, loss = 1.55268
I0522 12:12:50.610321 12588 solver.cpp:253]     Train net output #0: loss = 1.55268 (* 1 = 1.55268 loss)
I0522 12:12:50.610334 12588 sgd_solver.cpp:106] Iteration 40000, lr = 0.003
I0522 12:13:01.175539 12588 solver.cpp:237] Iteration 40500, loss = 1.02757
I0522 12:13:01.175695 12588 solver.cpp:253]     Train net output #0: loss = 1.02757 (* 1 = 1.02757 loss)
I0522 12:13:01.175709 12588 sgd_solver.cpp:106] Iteration 40500, lr = 0.003
I0522 12:13:11.738122 12588 solver.cpp:237] Iteration 41000, loss = 1.09164
I0522 12:13:11.738168 12588 solver.cpp:253]     Train net output #0: loss = 1.09164 (* 1 = 1.09164 loss)
I0522 12:13:11.738183 12588 sgd_solver.cpp:106] Iteration 41000, lr = 0.003
I0522 12:13:22.315209 12588 solver.cpp:237] Iteration 41500, loss = 0.814736
I0522 12:13:22.315245 12588 solver.cpp:253]     Train net output #0: loss = 0.814737 (* 1 = 0.814737 loss)
I0522 12:13:22.315261 12588 sgd_solver.cpp:106] Iteration 41500, lr = 0.003
I0522 12:13:32.873724 12588 solver.cpp:237] Iteration 42000, loss = 1.38977
I0522 12:13:32.873883 12588 solver.cpp:253]     Train net output #0: loss = 1.38977 (* 1 = 1.38977 loss)
I0522 12:13:32.873898 12588 sgd_solver.cpp:106] Iteration 42000, lr = 0.003
I0522 12:13:43.424881 12588 solver.cpp:237] Iteration 42500, loss = 1.0303
I0522 12:13:43.424916 12588 solver.cpp:253]     Train net output #0: loss = 1.0303 (* 1 = 1.0303 loss)
I0522 12:13:43.424932 12588 sgd_solver.cpp:106] Iteration 42500, lr = 0.003
I0522 12:13:53.992183 12588 solver.cpp:237] Iteration 43000, loss = 1.2833
I0522 12:13:53.992220 12588 solver.cpp:253]     Train net output #0: loss = 1.28331 (* 1 = 1.28331 loss)
I0522 12:13:53.992235 12588 sgd_solver.cpp:106] Iteration 43000, lr = 0.003
I0522 12:14:26.789654 12588 solver.cpp:237] Iteration 43500, loss = 1.40441
I0522 12:14:26.789824 12588 solver.cpp:253]     Train net output #0: loss = 1.40442 (* 1 = 1.40442 loss)
I0522 12:14:26.789839 12588 sgd_solver.cpp:106] Iteration 43500, lr = 0.003
I0522 12:14:37.340709 12588 solver.cpp:237] Iteration 44000, loss = 1.10525
I0522 12:14:37.340745 12588 solver.cpp:253]     Train net output #0: loss = 1.10525 (* 1 = 1.10525 loss)
I0522 12:14:37.340762 12588 sgd_solver.cpp:106] Iteration 44000, lr = 0.003
I0522 12:14:47.917984 12588 solver.cpp:237] Iteration 44500, loss = 1.33641
I0522 12:14:47.918031 12588 solver.cpp:253]     Train net output #0: loss = 1.33642 (* 1 = 1.33642 loss)
I0522 12:14:47.918046 12588 sgd_solver.cpp:106] Iteration 44500, lr = 0.003
I0522 12:14:58.466708 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_45000.caffemodel
I0522 12:14:58.521551 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_45000.solverstate
I0522 12:14:58.556628 12588 solver.cpp:237] Iteration 45000, loss = 1.72504
I0522 12:14:58.556679 12588 solver.cpp:253]     Train net output #0: loss = 1.72504 (* 1 = 1.72504 loss)
I0522 12:14:58.556694 12588 sgd_solver.cpp:106] Iteration 45000, lr = 0.003
I0522 12:15:09.107372 12588 solver.cpp:237] Iteration 45500, loss = 1.24321
I0522 12:15:09.107420 12588 solver.cpp:253]     Train net output #0: loss = 1.24321 (* 1 = 1.24321 loss)
I0522 12:15:09.107437 12588 sgd_solver.cpp:106] Iteration 45500, lr = 0.003
I0522 12:15:19.667363 12588 solver.cpp:237] Iteration 46000, loss = 1.63227
I0522 12:15:19.667399 12588 solver.cpp:253]     Train net output #0: loss = 1.63227 (* 1 = 1.63227 loss)
I0522 12:15:19.667415 12588 sgd_solver.cpp:106] Iteration 46000, lr = 0.003
I0522 12:15:30.229069 12588 solver.cpp:237] Iteration 46500, loss = 1.39121
I0522 12:15:30.229229 12588 solver.cpp:253]     Train net output #0: loss = 1.39121 (* 1 = 1.39121 loss)
I0522 12:15:30.229244 12588 sgd_solver.cpp:106] Iteration 46500, lr = 0.003
I0522 12:16:03.088088 12588 solver.cpp:237] Iteration 47000, loss = 1.00561
I0522 12:16:03.088256 12588 solver.cpp:253]     Train net output #0: loss = 1.00561 (* 1 = 1.00561 loss)
I0522 12:16:03.088274 12588 sgd_solver.cpp:106] Iteration 47000, lr = 0.003
I0522 12:16:13.638873 12588 solver.cpp:237] Iteration 47500, loss = 0.908428
I0522 12:16:13.638909 12588 solver.cpp:253]     Train net output #0: loss = 0.908429 (* 1 = 0.908429 loss)
I0522 12:16:13.638926 12588 sgd_solver.cpp:106] Iteration 47500, lr = 0.003
I0522 12:16:24.200004 12588 solver.cpp:237] Iteration 48000, loss = 1.21471
I0522 12:16:24.200048 12588 solver.cpp:253]     Train net output #0: loss = 1.21471 (* 1 = 1.21471 loss)
I0522 12:16:24.200067 12588 sgd_solver.cpp:106] Iteration 48000, lr = 0.003
I0522 12:16:34.753566 12588 solver.cpp:237] Iteration 48500, loss = 1.02556
I0522 12:16:34.753710 12588 solver.cpp:253]     Train net output #0: loss = 1.02557 (* 1 = 1.02557 loss)
I0522 12:16:34.753725 12588 sgd_solver.cpp:106] Iteration 48500, lr = 0.003
I0522 12:16:45.322365 12588 solver.cpp:237] Iteration 49000, loss = 1.43097
I0522 12:16:45.322399 12588 solver.cpp:253]     Train net output #0: loss = 1.43097 (* 1 = 1.43097 loss)
I0522 12:16:45.322417 12588 sgd_solver.cpp:106] Iteration 49000, lr = 0.003
I0522 12:16:55.880937 12588 solver.cpp:237] Iteration 49500, loss = 1.51679
I0522 12:16:55.880985 12588 solver.cpp:253]     Train net output #0: loss = 1.51679 (* 1 = 1.51679 loss)
I0522 12:16:55.881000 12588 sgd_solver.cpp:106] Iteration 49500, lr = 0.003
I0522 12:17:06.419862 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_50000.caffemodel
I0522 12:17:06.475055 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_50000.solverstate
I0522 12:17:06.503576 12588 solver.cpp:341] Iteration 50000, Testing net (#0)
I0522 12:17:56.149850 12588 solver.cpp:409]     Test net output #0: accuracy = 0.880334
I0522 12:17:56.150022 12588 solver.cpp:409]     Test net output #1: loss = 0.396547 (* 1 = 0.396547 loss)
I0522 12:18:17.107311 12588 solver.cpp:237] Iteration 50000, loss = 1.16005
I0522 12:18:17.107362 12588 solver.cpp:253]     Train net output #0: loss = 1.16005 (* 1 = 1.16005 loss)
I0522 12:18:17.107378 12588 sgd_solver.cpp:106] Iteration 50000, lr = 0.003
I0522 12:18:27.660909 12588 solver.cpp:237] Iteration 50500, loss = 1.36362
I0522 12:18:27.661062 12588 solver.cpp:253]     Train net output #0: loss = 1.36362 (* 1 = 1.36362 loss)
I0522 12:18:27.661075 12588 sgd_solver.cpp:106] Iteration 50500, lr = 0.003
I0522 12:18:38.215591 12588 solver.cpp:237] Iteration 51000, loss = 1.59429
I0522 12:18:38.215638 12588 solver.cpp:253]     Train net output #0: loss = 1.59429 (* 1 = 1.59429 loss)
I0522 12:18:38.215653 12588 sgd_solver.cpp:106] Iteration 51000, lr = 0.003
I0522 12:18:48.762923 12588 solver.cpp:237] Iteration 51500, loss = 1.13262
I0522 12:18:48.762959 12588 solver.cpp:253]     Train net output #0: loss = 1.13262 (* 1 = 1.13262 loss)
I0522 12:18:48.762972 12588 sgd_solver.cpp:106] Iteration 51500, lr = 0.003
I0522 12:18:59.305713 12588 solver.cpp:237] Iteration 52000, loss = 0.988644
I0522 12:18:59.305871 12588 solver.cpp:253]     Train net output #0: loss = 0.988645 (* 1 = 0.988645 loss)
I0522 12:18:59.305886 12588 sgd_solver.cpp:106] Iteration 52000, lr = 0.003
I0522 12:19:09.866927 12588 solver.cpp:237] Iteration 52500, loss = 1.51183
I0522 12:19:09.866963 12588 solver.cpp:253]     Train net output #0: loss = 1.51183 (* 1 = 1.51183 loss)
I0522 12:19:09.866979 12588 sgd_solver.cpp:106] Iteration 52500, lr = 0.003
I0522 12:19:20.415563 12588 solver.cpp:237] Iteration 53000, loss = 1.39812
I0522 12:19:20.415608 12588 solver.cpp:253]     Train net output #0: loss = 1.39812 (* 1 = 1.39812 loss)
I0522 12:19:20.415624 12588 sgd_solver.cpp:106] Iteration 53000, lr = 0.003
I0522 12:19:51.884666 12588 solver.cpp:237] Iteration 53500, loss = 0.848848
I0522 12:19:51.884845 12588 solver.cpp:253]     Train net output #0: loss = 0.848848 (* 1 = 0.848848 loss)
I0522 12:19:51.884860 12588 sgd_solver.cpp:106] Iteration 53500, lr = 0.003
I0522 12:20:02.434999 12588 solver.cpp:237] Iteration 54000, loss = 0.867442
I0522 12:20:02.435035 12588 solver.cpp:253]     Train net output #0: loss = 0.867443 (* 1 = 0.867443 loss)
I0522 12:20:02.435051 12588 sgd_solver.cpp:106] Iteration 54000, lr = 0.003
I0522 12:20:12.992256 12588 solver.cpp:237] Iteration 54500, loss = 2.32988
I0522 12:20:12.992303 12588 solver.cpp:253]     Train net output #0: loss = 2.32988 (* 1 = 2.32988 loss)
I0522 12:20:12.992319 12588 sgd_solver.cpp:106] Iteration 54500, lr = 0.003
I0522 12:20:23.529870 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_55000.caffemodel
I0522 12:20:23.582190 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_55000.solverstate
I0522 12:20:23.615274 12588 solver.cpp:237] Iteration 55000, loss = 1.33732
I0522 12:20:23.615316 12588 solver.cpp:253]     Train net output #0: loss = 1.33732 (* 1 = 1.33732 loss)
I0522 12:20:23.615334 12588 sgd_solver.cpp:106] Iteration 55000, lr = 0.003
I0522 12:20:34.164479 12588 solver.cpp:237] Iteration 55500, loss = 1.24864
I0522 12:20:34.164523 12588 solver.cpp:253]     Train net output #0: loss = 1.24864 (* 1 = 1.24864 loss)
I0522 12:20:34.164542 12588 sgd_solver.cpp:106] Iteration 55500, lr = 0.003
I0522 12:20:44.715870 12588 solver.cpp:237] Iteration 56000, loss = 1.1569
I0522 12:20:44.715905 12588 solver.cpp:253]     Train net output #0: loss = 1.1569 (* 1 = 1.1569 loss)
I0522 12:20:44.715921 12588 sgd_solver.cpp:106] Iteration 56000, lr = 0.003
I0522 12:20:55.273052 12588 solver.cpp:237] Iteration 56500, loss = 0.945315
I0522 12:20:55.273214 12588 solver.cpp:253]     Train net output #0: loss = 0.945316 (* 1 = 0.945316 loss)
I0522 12:20:55.273229 12588 sgd_solver.cpp:106] Iteration 56500, lr = 0.003
I0522 12:21:26.768095 12588 solver.cpp:237] Iteration 57000, loss = 1.02143
I0522 12:21:26.768265 12588 solver.cpp:253]     Train net output #0: loss = 1.02143 (* 1 = 1.02143 loss)
I0522 12:21:26.768280 12588 sgd_solver.cpp:106] Iteration 57000, lr = 0.003
I0522 12:21:37.311884 12588 solver.cpp:237] Iteration 57500, loss = 1.39636
I0522 12:21:37.311919 12588 solver.cpp:253]     Train net output #0: loss = 1.39636 (* 1 = 1.39636 loss)
I0522 12:21:37.311933 12588 sgd_solver.cpp:106] Iteration 57500, lr = 0.003
I0522 12:21:47.867765 12588 solver.cpp:237] Iteration 58000, loss = 1.11988
I0522 12:21:47.867801 12588 solver.cpp:253]     Train net output #0: loss = 1.11988 (* 1 = 1.11988 loss)
I0522 12:21:47.867820 12588 sgd_solver.cpp:106] Iteration 58000, lr = 0.003
I0522 12:21:58.417632 12588 solver.cpp:237] Iteration 58500, loss = 1.4612
I0522 12:21:58.417791 12588 solver.cpp:253]     Train net output #0: loss = 1.4612 (* 1 = 1.4612 loss)
I0522 12:21:58.417806 12588 sgd_solver.cpp:106] Iteration 58500, lr = 0.003
I0522 12:22:08.965945 12588 solver.cpp:237] Iteration 59000, loss = 1.27661
I0522 12:22:08.965981 12588 solver.cpp:253]     Train net output #0: loss = 1.27661 (* 1 = 1.27661 loss)
I0522 12:22:08.965999 12588 sgd_solver.cpp:106] Iteration 59000, lr = 0.003
I0522 12:22:19.508179 12588 solver.cpp:237] Iteration 59500, loss = 1.09046
I0522 12:22:19.508226 12588 solver.cpp:253]     Train net output #0: loss = 1.09046 (* 1 = 1.09046 loss)
I0522 12:22:19.508240 12588 sgd_solver.cpp:106] Iteration 59500, lr = 0.003
I0522 12:22:30.043028 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_60000.caffemodel
I0522 12:22:30.095197 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_60000.solverstate
I0522 12:22:30.121681 12588 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 12:23:40.637917 12588 solver.cpp:409]     Test net output #0: accuracy = 0.883607
I0522 12:23:40.638093 12588 solver.cpp:409]     Test net output #1: loss = 0.36841 (* 1 = 0.36841 loss)
I0522 12:24:01.541537 12588 solver.cpp:237] Iteration 60000, loss = 1.03994
I0522 12:24:01.541589 12588 solver.cpp:253]     Train net output #0: loss = 1.03994 (* 1 = 1.03994 loss)
I0522 12:24:01.541604 12588 sgd_solver.cpp:106] Iteration 60000, lr = 0.003
I0522 12:24:12.086326 12588 solver.cpp:237] Iteration 60500, loss = 1.12723
I0522 12:24:12.086482 12588 solver.cpp:253]     Train net output #0: loss = 1.12723 (* 1 = 1.12723 loss)
I0522 12:24:12.086496 12588 sgd_solver.cpp:106] Iteration 60500, lr = 0.003
I0522 12:24:22.636116 12588 solver.cpp:237] Iteration 61000, loss = 1.32395
I0522 12:24:22.636162 12588 solver.cpp:253]     Train net output #0: loss = 1.32395 (* 1 = 1.32395 loss)
I0522 12:24:22.636176 12588 sgd_solver.cpp:106] Iteration 61000, lr = 0.003
I0522 12:24:33.195691 12588 solver.cpp:237] Iteration 61500, loss = 1.28564
I0522 12:24:33.195727 12588 solver.cpp:253]     Train net output #0: loss = 1.28564 (* 1 = 1.28564 loss)
I0522 12:24:33.195745 12588 sgd_solver.cpp:106] Iteration 61500, lr = 0.003
I0522 12:24:43.740933 12588 solver.cpp:237] Iteration 62000, loss = 1.43541
I0522 12:24:43.741091 12588 solver.cpp:253]     Train net output #0: loss = 1.43541 (* 1 = 1.43541 loss)
I0522 12:24:43.741106 12588 sgd_solver.cpp:106] Iteration 62000, lr = 0.003
I0522 12:24:54.296176 12588 solver.cpp:237] Iteration 62500, loss = 1.22648
I0522 12:24:54.296223 12588 solver.cpp:253]     Train net output #0: loss = 1.22648 (* 1 = 1.22648 loss)
I0522 12:24:54.296238 12588 sgd_solver.cpp:106] Iteration 62500, lr = 0.003
I0522 12:25:04.839045 12588 solver.cpp:237] Iteration 63000, loss = 1.21629
I0522 12:25:04.839081 12588 solver.cpp:253]     Train net output #0: loss = 1.21629 (* 1 = 1.21629 loss)
I0522 12:25:04.839097 12588 sgd_solver.cpp:106] Iteration 63000, lr = 0.003
I0522 12:25:36.307260 12588 solver.cpp:237] Iteration 63500, loss = 1.35485
I0522 12:25:36.307430 12588 solver.cpp:253]     Train net output #0: loss = 1.35485 (* 1 = 1.35485 loss)
I0522 12:25:36.307446 12588 sgd_solver.cpp:106] Iteration 63500, lr = 0.003
I0522 12:25:46.841385 12588 solver.cpp:237] Iteration 64000, loss = 1.06522
I0522 12:25:46.841421 12588 solver.cpp:253]     Train net output #0: loss = 1.06522 (* 1 = 1.06522 loss)
I0522 12:25:46.841439 12588 sgd_solver.cpp:106] Iteration 64000, lr = 0.003
I0522 12:25:57.389597 12588 solver.cpp:237] Iteration 64500, loss = 1.43162
I0522 12:25:57.389633 12588 solver.cpp:253]     Train net output #0: loss = 1.43162 (* 1 = 1.43162 loss)
I0522 12:25:57.389647 12588 sgd_solver.cpp:106] Iteration 64500, lr = 0.003
I0522 12:26:07.924087 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_65000.caffemodel
I0522 12:26:07.976536 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_65000.solverstate
I0522 12:26:08.009443 12588 solver.cpp:237] Iteration 65000, loss = 1.1739
I0522 12:26:08.009482 12588 solver.cpp:253]     Train net output #0: loss = 1.1739 (* 1 = 1.1739 loss)
I0522 12:26:08.009503 12588 sgd_solver.cpp:106] Iteration 65000, lr = 0.003
I0522 12:26:18.548734 12588 solver.cpp:237] Iteration 65500, loss = 1.1751
I0522 12:26:18.548770 12588 solver.cpp:253]     Train net output #0: loss = 1.1751 (* 1 = 1.1751 loss)
I0522 12:26:18.548786 12588 sgd_solver.cpp:106] Iteration 65500, lr = 0.003
I0522 12:26:29.091450 12588 solver.cpp:237] Iteration 66000, loss = 1.19184
I0522 12:26:29.091497 12588 solver.cpp:253]     Train net output #0: loss = 1.19184 (* 1 = 1.19184 loss)
I0522 12:26:29.091512 12588 sgd_solver.cpp:106] Iteration 66000, lr = 0.003
I0522 12:26:39.631839 12588 solver.cpp:237] Iteration 66500, loss = 1.0996
I0522 12:26:39.632004 12588 solver.cpp:253]     Train net output #0: loss = 1.0996 (* 1 = 1.0996 loss)
I0522 12:26:39.632019 12588 sgd_solver.cpp:106] Iteration 66500, lr = 0.003
I0522 12:27:11.107414 12588 solver.cpp:237] Iteration 67000, loss = 1.15387
I0522 12:27:11.107589 12588 solver.cpp:253]     Train net output #0: loss = 1.15387 (* 1 = 1.15387 loss)
I0522 12:27:11.107604 12588 sgd_solver.cpp:106] Iteration 67000, lr = 0.003
I0522 12:27:21.656119 12588 solver.cpp:237] Iteration 67500, loss = 1.2858
I0522 12:27:21.656168 12588 solver.cpp:253]     Train net output #0: loss = 1.2858 (* 1 = 1.2858 loss)
I0522 12:27:21.656183 12588 sgd_solver.cpp:106] Iteration 67500, lr = 0.003
I0522 12:27:32.195423 12588 solver.cpp:237] Iteration 68000, loss = 0.992453
I0522 12:27:32.195461 12588 solver.cpp:253]     Train net output #0: loss = 0.992454 (* 1 = 0.992454 loss)
I0522 12:27:32.195477 12588 sgd_solver.cpp:106] Iteration 68000, lr = 0.003
I0522 12:27:42.752967 12588 solver.cpp:237] Iteration 68500, loss = 1.26091
I0522 12:27:42.753141 12588 solver.cpp:253]     Train net output #0: loss = 1.26091 (* 1 = 1.26091 loss)
I0522 12:27:42.753159 12588 sgd_solver.cpp:106] Iteration 68500, lr = 0.003
I0522 12:27:53.318877 12588 solver.cpp:237] Iteration 69000, loss = 1.29577
I0522 12:27:53.318913 12588 solver.cpp:253]     Train net output #0: loss = 1.29577 (* 1 = 1.29577 loss)
I0522 12:27:53.318928 12588 sgd_solver.cpp:106] Iteration 69000, lr = 0.003
I0522 12:28:03.862164 12588 solver.cpp:237] Iteration 69500, loss = 0.943068
I0522 12:28:03.862200 12588 solver.cpp:253]     Train net output #0: loss = 0.943068 (* 1 = 0.943068 loss)
I0522 12:28:03.862216 12588 sgd_solver.cpp:106] Iteration 69500, lr = 0.003
I0522 12:28:14.379184 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_70000.caffemodel
I0522 12:28:14.431391 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_70000.solverstate
I0522 12:28:14.457731 12588 solver.cpp:341] Iteration 70000, Testing net (#0)
I0522 12:29:03.741250 12588 solver.cpp:409]     Test net output #0: accuracy = 0.885488
I0522 12:29:03.741420 12588 solver.cpp:409]     Test net output #1: loss = 0.368287 (* 1 = 0.368287 loss)
I0522 12:29:24.658213 12588 solver.cpp:237] Iteration 70000, loss = 1.33792
I0522 12:29:24.658267 12588 solver.cpp:253]     Train net output #0: loss = 1.33792 (* 1 = 1.33792 loss)
I0522 12:29:24.658282 12588 sgd_solver.cpp:106] Iteration 70000, lr = 0.003
I0522 12:29:35.213697 12588 solver.cpp:237] Iteration 70500, loss = 1.02548
I0522 12:29:35.213856 12588 solver.cpp:253]     Train net output #0: loss = 1.02549 (* 1 = 1.02549 loss)
I0522 12:29:35.213871 12588 sgd_solver.cpp:106] Iteration 70500, lr = 0.003
I0522 12:29:45.768419 12588 solver.cpp:237] Iteration 71000, loss = 1.37226
I0522 12:29:45.768466 12588 solver.cpp:253]     Train net output #0: loss = 1.37226 (* 1 = 1.37226 loss)
I0522 12:29:45.768481 12588 sgd_solver.cpp:106] Iteration 71000, lr = 0.003
I0522 12:29:56.328205 12588 solver.cpp:237] Iteration 71500, loss = 1.36591
I0522 12:29:56.328241 12588 solver.cpp:253]     Train net output #0: loss = 1.36591 (* 1 = 1.36591 loss)
I0522 12:29:56.328255 12588 sgd_solver.cpp:106] Iteration 71500, lr = 0.003
I0522 12:30:06.872974 12588 solver.cpp:237] Iteration 72000, loss = 1.20697
I0522 12:30:06.873124 12588 solver.cpp:253]     Train net output #0: loss = 1.20697 (* 1 = 1.20697 loss)
I0522 12:30:06.873139 12588 sgd_solver.cpp:106] Iteration 72000, lr = 0.003
I0522 12:30:17.413993 12588 solver.cpp:237] Iteration 72500, loss = 0.993291
I0522 12:30:17.414041 12588 solver.cpp:253]     Train net output #0: loss = 0.993292 (* 1 = 0.993292 loss)
I0522 12:30:17.414057 12588 sgd_solver.cpp:106] Iteration 72500, lr = 0.003
I0522 12:30:27.978736 12588 solver.cpp:237] Iteration 73000, loss = 1.49913
I0522 12:30:27.978772 12588 solver.cpp:253]     Train net output #0: loss = 1.49913 (* 1 = 1.49913 loss)
I0522 12:30:27.978790 12588 sgd_solver.cpp:106] Iteration 73000, lr = 0.003
I0522 12:30:59.474011 12588 solver.cpp:237] Iteration 73500, loss = 1.29756
I0522 12:30:59.474205 12588 solver.cpp:253]     Train net output #0: loss = 1.29757 (* 1 = 1.29757 loss)
I0522 12:30:59.474220 12588 sgd_solver.cpp:106] Iteration 73500, lr = 0.003
I0522 12:31:10.028753 12588 solver.cpp:237] Iteration 74000, loss = 0.932569
I0522 12:31:10.028790 12588 solver.cpp:253]     Train net output #0: loss = 0.93257 (* 1 = 0.93257 loss)
I0522 12:31:10.028806 12588 sgd_solver.cpp:106] Iteration 74000, lr = 0.003
I0522 12:31:20.581785 12588 solver.cpp:237] Iteration 74500, loss = 1.14057
I0522 12:31:20.581820 12588 solver.cpp:253]     Train net output #0: loss = 1.14057 (* 1 = 1.14057 loss)
I0522 12:31:20.581837 12588 sgd_solver.cpp:106] Iteration 74500, lr = 0.003
I0522 12:31:31.123584 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_75000.caffemodel
I0522 12:31:31.179905 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_75000.solverstate
I0522 12:31:31.215188 12588 solver.cpp:237] Iteration 75000, loss = 1.21894
I0522 12:31:31.215236 12588 solver.cpp:253]     Train net output #0: loss = 1.21894 (* 1 = 1.21894 loss)
I0522 12:31:31.215255 12588 sgd_solver.cpp:106] Iteration 75000, lr = 0.003
I0522 12:31:41.767261 12588 solver.cpp:237] Iteration 75500, loss = 1.21956
I0522 12:31:41.767298 12588 solver.cpp:253]     Train net output #0: loss = 1.21956 (* 1 = 1.21956 loss)
I0522 12:31:41.767313 12588 sgd_solver.cpp:106] Iteration 75500, lr = 0.003
I0522 12:31:52.330476 12588 solver.cpp:237] Iteration 76000, loss = 1.32512
I0522 12:31:52.330524 12588 solver.cpp:253]     Train net output #0: loss = 1.32512 (* 1 = 1.32512 loss)
I0522 12:31:52.330539 12588 sgd_solver.cpp:106] Iteration 76000, lr = 0.003
I0522 12:32:02.887233 12588 solver.cpp:237] Iteration 76500, loss = 1.40183
I0522 12:32:02.887389 12588 solver.cpp:253]     Train net output #0: loss = 1.40183 (* 1 = 1.40183 loss)
I0522 12:32:02.887404 12588 sgd_solver.cpp:106] Iteration 76500, lr = 0.003
I0522 12:32:34.360231 12588 solver.cpp:237] Iteration 77000, loss = 1.07453
I0522 12:32:34.360415 12588 solver.cpp:253]     Train net output #0: loss = 1.07453 (* 1 = 1.07453 loss)
I0522 12:32:34.360430 12588 sgd_solver.cpp:106] Iteration 77000, lr = 0.003
I0522 12:32:44.911972 12588 solver.cpp:237] Iteration 77500, loss = 1.24577
I0522 12:32:44.912015 12588 solver.cpp:253]     Train net output #0: loss = 1.24577 (* 1 = 1.24577 loss)
I0522 12:32:44.912031 12588 sgd_solver.cpp:106] Iteration 77500, lr = 0.003
I0522 12:32:55.465405 12588 solver.cpp:237] Iteration 78000, loss = 1.42791
I0522 12:32:55.465440 12588 solver.cpp:253]     Train net output #0: loss = 1.42792 (* 1 = 1.42792 loss)
I0522 12:32:55.465456 12588 sgd_solver.cpp:106] Iteration 78000, lr = 0.003
I0522 12:33:06.018441 12588 solver.cpp:237] Iteration 78500, loss = 1.14478
I0522 12:33:06.018605 12588 solver.cpp:253]     Train net output #0: loss = 1.14478 (* 1 = 1.14478 loss)
I0522 12:33:06.018621 12588 sgd_solver.cpp:106] Iteration 78500, lr = 0.003
I0522 12:33:16.579524 12588 solver.cpp:237] Iteration 79000, loss = 1.28955
I0522 12:33:16.579560 12588 solver.cpp:253]     Train net output #0: loss = 1.28955 (* 1 = 1.28955 loss)
I0522 12:33:16.579576 12588 sgd_solver.cpp:106] Iteration 79000, lr = 0.003
I0522 12:33:27.129408 12588 solver.cpp:237] Iteration 79500, loss = 1.24856
I0522 12:33:27.129444 12588 solver.cpp:253]     Train net output #0: loss = 1.24856 (* 1 = 1.24856 loss)
I0522 12:33:27.129461 12588 sgd_solver.cpp:106] Iteration 79500, lr = 0.003
I0522 12:33:37.658318 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_80000.caffemodel
I0522 12:33:37.710731 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_80000.solverstate
I0522 12:33:37.737406 12588 solver.cpp:341] Iteration 80000, Testing net (#0)
I0522 12:34:48.284476 12588 solver.cpp:409]     Test net output #0: accuracy = 0.88309
I0522 12:34:48.284657 12588 solver.cpp:409]     Test net output #1: loss = 0.362109 (* 1 = 0.362109 loss)
I0522 12:35:09.183858 12588 solver.cpp:237] Iteration 80000, loss = 0.631266
I0522 12:35:09.183907 12588 solver.cpp:253]     Train net output #0: loss = 0.631266 (* 1 = 0.631266 loss)
I0522 12:35:09.183923 12588 sgd_solver.cpp:106] Iteration 80000, lr = 0.003
I0522 12:35:19.682157 12588 solver.cpp:237] Iteration 80500, loss = 1.06722
I0522 12:35:19.682314 12588 solver.cpp:253]     Train net output #0: loss = 1.06722 (* 1 = 1.06722 loss)
I0522 12:35:19.682328 12588 sgd_solver.cpp:106] Iteration 80500, lr = 0.003
I0522 12:35:30.192674 12588 solver.cpp:237] Iteration 81000, loss = 1.11144
I0522 12:35:30.192710 12588 solver.cpp:253]     Train net output #0: loss = 1.11144 (* 1 = 1.11144 loss)
I0522 12:35:30.192726 12588 sgd_solver.cpp:106] Iteration 81000, lr = 0.003
I0522 12:35:40.734287 12588 solver.cpp:237] Iteration 81500, loss = 1.47435
I0522 12:35:40.734335 12588 solver.cpp:253]     Train net output #0: loss = 1.47435 (* 1 = 1.47435 loss)
I0522 12:35:40.734349 12588 sgd_solver.cpp:106] Iteration 81500, lr = 0.003
I0522 12:35:51.260274 12588 solver.cpp:237] Iteration 82000, loss = 1.14412
I0522 12:35:51.260428 12588 solver.cpp:253]     Train net output #0: loss = 1.14412 (* 1 = 1.14412 loss)
I0522 12:35:51.260444 12588 sgd_solver.cpp:106] Iteration 82000, lr = 0.003
I0522 12:36:01.781692 12588 solver.cpp:237] Iteration 82500, loss = 1.19096
I0522 12:36:01.781741 12588 solver.cpp:253]     Train net output #0: loss = 1.19096 (* 1 = 1.19096 loss)
I0522 12:36:01.781755 12588 sgd_solver.cpp:106] Iteration 82500, lr = 0.003
I0522 12:36:12.311789 12588 solver.cpp:237] Iteration 83000, loss = 0.953604
I0522 12:36:12.311825 12588 solver.cpp:253]     Train net output #0: loss = 0.953605 (* 1 = 0.953605 loss)
I0522 12:36:12.311841 12588 sgd_solver.cpp:106] Iteration 83000, lr = 0.003
I0522 12:36:43.766383 12588 solver.cpp:237] Iteration 83500, loss = 1.06206
I0522 12:36:43.766558 12588 solver.cpp:253]     Train net output #0: loss = 1.06206 (* 1 = 1.06206 loss)
I0522 12:36:43.766576 12588 sgd_solver.cpp:106] Iteration 83500, lr = 0.003
I0522 12:36:54.293486 12588 solver.cpp:237] Iteration 84000, loss = 0.842788
I0522 12:36:54.293536 12588 solver.cpp:253]     Train net output #0: loss = 0.842788 (* 1 = 0.842788 loss)
I0522 12:36:54.293550 12588 sgd_solver.cpp:106] Iteration 84000, lr = 0.003
I0522 12:37:04.813854 12588 solver.cpp:237] Iteration 84500, loss = 1.26561
I0522 12:37:04.813890 12588 solver.cpp:253]     Train net output #0: loss = 1.26561 (* 1 = 1.26561 loss)
I0522 12:37:04.813906 12588 sgd_solver.cpp:106] Iteration 84500, lr = 0.003
I0522 12:37:15.335089 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_85000.caffemodel
I0522 12:37:15.387583 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_85000.solverstate
I0522 12:37:15.420518 12588 solver.cpp:237] Iteration 85000, loss = 1.11476
I0522 12:37:15.420560 12588 solver.cpp:253]     Train net output #0: loss = 1.11476 (* 1 = 1.11476 loss)
I0522 12:37:15.420583 12588 sgd_solver.cpp:106] Iteration 85000, lr = 0.003
I0522 12:37:25.945749 12588 solver.cpp:237] Iteration 85500, loss = 1.05449
I0522 12:37:25.945785 12588 solver.cpp:253]     Train net output #0: loss = 1.05449 (* 1 = 1.05449 loss)
I0522 12:37:25.945801 12588 sgd_solver.cpp:106] Iteration 85500, lr = 0.003
I0522 12:37:36.487236 12588 solver.cpp:237] Iteration 86000, loss = 1.21029
I0522 12:37:36.487272 12588 solver.cpp:253]     Train net output #0: loss = 1.21029 (* 1 = 1.21029 loss)
I0522 12:37:36.487287 12588 sgd_solver.cpp:106] Iteration 86000, lr = 0.003
I0522 12:37:47.017271 12588 solver.cpp:237] Iteration 86500, loss = 1.08583
I0522 12:37:47.017452 12588 solver.cpp:253]     Train net output #0: loss = 1.08583 (* 1 = 1.08583 loss)
I0522 12:37:47.017467 12588 sgd_solver.cpp:106] Iteration 86500, lr = 0.003
I0522 12:38:18.427742 12588 solver.cpp:237] Iteration 87000, loss = 1.03024
I0522 12:38:18.427918 12588 solver.cpp:253]     Train net output #0: loss = 1.03024 (* 1 = 1.03024 loss)
I0522 12:38:18.427933 12588 sgd_solver.cpp:106] Iteration 87000, lr = 0.003
I0522 12:38:28.962095 12588 solver.cpp:237] Iteration 87500, loss = 1.50406
I0522 12:38:28.962142 12588 solver.cpp:253]     Train net output #0: loss = 1.50406 (* 1 = 1.50406 loss)
I0522 12:38:28.962157 12588 sgd_solver.cpp:106] Iteration 87500, lr = 0.003
I0522 12:38:39.488420 12588 solver.cpp:237] Iteration 88000, loss = 1.34768
I0522 12:38:39.488454 12588 solver.cpp:253]     Train net output #0: loss = 1.34768 (* 1 = 1.34768 loss)
I0522 12:38:39.488471 12588 sgd_solver.cpp:106] Iteration 88000, lr = 0.003
I0522 12:38:50.015008 12588 solver.cpp:237] Iteration 88500, loss = 1.24118
I0522 12:38:50.015171 12588 solver.cpp:253]     Train net output #0: loss = 1.24118 (* 1 = 1.24118 loss)
I0522 12:38:50.015187 12588 sgd_solver.cpp:106] Iteration 88500, lr = 0.003
I0522 12:39:00.542544 12588 solver.cpp:237] Iteration 89000, loss = 0.710162
I0522 12:39:00.542593 12588 solver.cpp:253]     Train net output #0: loss = 0.710163 (* 1 = 0.710163 loss)
I0522 12:39:00.542606 12588 sgd_solver.cpp:106] Iteration 89000, lr = 0.003
I0522 12:39:11.072296 12588 solver.cpp:237] Iteration 89500, loss = 1.4625
I0522 12:39:11.072332 12588 solver.cpp:253]     Train net output #0: loss = 1.4625 (* 1 = 1.4625 loss)
I0522 12:39:11.072348 12588 sgd_solver.cpp:106] Iteration 89500, lr = 0.003
I0522 12:39:21.584931 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_90000.caffemodel
I0522 12:39:21.637369 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_90000.solverstate
I0522 12:39:21.663792 12588 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 12:40:11.227619 12588 solver.cpp:409]     Test net output #0: accuracy = 0.885842
I0522 12:40:11.227790 12588 solver.cpp:409]     Test net output #1: loss = 0.354306 (* 1 = 0.354306 loss)
I0522 12:40:32.120944 12588 solver.cpp:237] Iteration 90000, loss = 1.39113
I0522 12:40:32.120996 12588 solver.cpp:253]     Train net output #0: loss = 1.39113 (* 1 = 1.39113 loss)
I0522 12:40:32.121011 12588 sgd_solver.cpp:106] Iteration 90000, lr = 0.003
I0522 12:40:42.706465 12588 solver.cpp:237] Iteration 90500, loss = 0.897463
I0522 12:40:42.706635 12588 solver.cpp:253]     Train net output #0: loss = 0.897464 (* 1 = 0.897464 loss)
I0522 12:40:42.706651 12588 sgd_solver.cpp:106] Iteration 90500, lr = 0.003
I0522 12:40:53.263723 12588 solver.cpp:237] Iteration 91000, loss = 0.96516
I0522 12:40:53.263759 12588 solver.cpp:253]     Train net output #0: loss = 0.965161 (* 1 = 0.965161 loss)
I0522 12:40:53.263775 12588 sgd_solver.cpp:106] Iteration 91000, lr = 0.003
I0522 12:41:03.825987 12588 solver.cpp:237] Iteration 91500, loss = 0.677032
I0522 12:41:03.826036 12588 solver.cpp:253]     Train net output #0: loss = 0.677033 (* 1 = 0.677033 loss)
I0522 12:41:03.826050 12588 sgd_solver.cpp:106] Iteration 91500, lr = 0.003
I0522 12:41:14.397861 12588 solver.cpp:237] Iteration 92000, loss = 1.19962
I0522 12:41:14.398026 12588 solver.cpp:253]     Train net output #0: loss = 1.19962 (* 1 = 1.19962 loss)
I0522 12:41:14.398041 12588 sgd_solver.cpp:106] Iteration 92000, lr = 0.003
I0522 12:41:24.973572 12588 solver.cpp:237] Iteration 92500, loss = 0.864874
I0522 12:41:24.973619 12588 solver.cpp:253]     Train net output #0: loss = 0.864875 (* 1 = 0.864875 loss)
I0522 12:41:24.973636 12588 sgd_solver.cpp:106] Iteration 92500, lr = 0.003
I0522 12:41:35.541951 12588 solver.cpp:237] Iteration 93000, loss = 0.747147
I0522 12:41:35.541988 12588 solver.cpp:253]     Train net output #0: loss = 0.747148 (* 1 = 0.747148 loss)
I0522 12:41:35.542003 12588 sgd_solver.cpp:106] Iteration 93000, lr = 0.003
I0522 12:42:07.014287 12588 solver.cpp:237] Iteration 93500, loss = 0.814319
I0522 12:42:07.014468 12588 solver.cpp:253]     Train net output #0: loss = 0.81432 (* 1 = 0.81432 loss)
I0522 12:42:07.014484 12588 sgd_solver.cpp:106] Iteration 93500, lr = 0.003
I0522 12:42:17.573760 12588 solver.cpp:237] Iteration 94000, loss = 0.966667
I0522 12:42:17.573807 12588 solver.cpp:253]     Train net output #0: loss = 0.966668 (* 1 = 0.966668 loss)
I0522 12:42:17.573822 12588 sgd_solver.cpp:106] Iteration 94000, lr = 0.003
I0522 12:42:28.136211 12588 solver.cpp:237] Iteration 94500, loss = 1.03372
I0522 12:42:28.136246 12588 solver.cpp:253]     Train net output #0: loss = 1.03372 (* 1 = 1.03372 loss)
I0522 12:42:28.136262 12588 sgd_solver.cpp:106] Iteration 94500, lr = 0.003
I0522 12:42:38.676844 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_95000.caffemodel
I0522 12:42:38.731768 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_95000.solverstate
I0522 12:42:38.767076 12588 solver.cpp:237] Iteration 95000, loss = 1.63622
I0522 12:42:38.767124 12588 solver.cpp:253]     Train net output #0: loss = 1.63622 (* 1 = 1.63622 loss)
I0522 12:42:38.767138 12588 sgd_solver.cpp:106] Iteration 95000, lr = 0.003
I0522 12:42:49.326134 12588 solver.cpp:237] Iteration 95500, loss = 1.01337
I0522 12:42:49.326177 12588 solver.cpp:253]     Train net output #0: loss = 1.01337 (* 1 = 1.01337 loss)
I0522 12:42:49.326194 12588 sgd_solver.cpp:106] Iteration 95500, lr = 0.003
I0522 12:42:59.867604 12588 solver.cpp:237] Iteration 96000, loss = 1.4404
I0522 12:42:59.867640 12588 solver.cpp:253]     Train net output #0: loss = 1.4404 (* 1 = 1.4404 loss)
I0522 12:42:59.867655 12588 sgd_solver.cpp:106] Iteration 96000, lr = 0.003
I0522 12:43:10.420640 12588 solver.cpp:237] Iteration 96500, loss = 1.15778
I0522 12:43:10.420814 12588 solver.cpp:253]     Train net output #0: loss = 1.15778 (* 1 = 1.15778 loss)
I0522 12:43:10.420830 12588 sgd_solver.cpp:106] Iteration 96500, lr = 0.003
I0522 12:43:41.848366 12588 solver.cpp:237] Iteration 97000, loss = 0.823641
I0522 12:43:41.848546 12588 solver.cpp:253]     Train net output #0: loss = 0.823641 (* 1 = 0.823641 loss)
I0522 12:43:41.848562 12588 sgd_solver.cpp:106] Iteration 97000, lr = 0.003
I0522 12:43:52.403523 12588 solver.cpp:237] Iteration 97500, loss = 1.53566
I0522 12:43:52.403559 12588 solver.cpp:253]     Train net output #0: loss = 1.53566 (* 1 = 1.53566 loss)
I0522 12:43:52.403574 12588 sgd_solver.cpp:106] Iteration 97500, lr = 0.003
I0522 12:44:02.972570 12588 solver.cpp:237] Iteration 98000, loss = 1.1699
I0522 12:44:02.972616 12588 solver.cpp:253]     Train net output #0: loss = 1.1699 (* 1 = 1.1699 loss)
I0522 12:44:02.972630 12588 sgd_solver.cpp:106] Iteration 98000, lr = 0.003
I0522 12:44:13.556059 12588 solver.cpp:237] Iteration 98500, loss = 1.21625
I0522 12:44:13.556226 12588 solver.cpp:253]     Train net output #0: loss = 1.21625 (* 1 = 1.21625 loss)
I0522 12:44:13.556241 12588 sgd_solver.cpp:106] Iteration 98500, lr = 0.003
I0522 12:44:24.148576 12588 solver.cpp:237] Iteration 99000, loss = 1.26086
I0522 12:44:24.148627 12588 solver.cpp:253]     Train net output #0: loss = 1.26086 (* 1 = 1.26086 loss)
I0522 12:44:24.148640 12588 sgd_solver.cpp:106] Iteration 99000, lr = 0.003
I0522 12:44:34.740272 12588 solver.cpp:237] Iteration 99500, loss = 1.30053
I0522 12:44:34.740306 12588 solver.cpp:253]     Train net output #0: loss = 1.30053 (* 1 = 1.30053 loss)
I0522 12:44:34.740322 12588 sgd_solver.cpp:106] Iteration 99500, lr = 0.003
I0522 12:44:45.296972 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_100000.caffemodel
I0522 12:44:45.352227 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_100000.solverstate
I0522 12:44:45.380034 12588 solver.cpp:341] Iteration 100000, Testing net (#0)
I0522 12:45:55.891088 12588 solver.cpp:409]     Test net output #0: accuracy = 0.892079
I0522 12:45:55.891264 12588 solver.cpp:409]     Test net output #1: loss = 0.354297 (* 1 = 0.354297 loss)
I0522 12:46:16.773582 12588 solver.cpp:237] Iteration 100000, loss = 1.45477
I0522 12:46:16.773634 12588 solver.cpp:253]     Train net output #0: loss = 1.45477 (* 1 = 1.45477 loss)
I0522 12:46:16.773649 12588 sgd_solver.cpp:106] Iteration 100000, lr = 0.003
I0522 12:46:27.362587 12588 solver.cpp:237] Iteration 100500, loss = 0.873655
I0522 12:46:27.362756 12588 solver.cpp:253]     Train net output #0: loss = 0.873656 (* 1 = 0.873656 loss)
I0522 12:46:27.362771 12588 sgd_solver.cpp:106] Iteration 100500, lr = 0.003
I0522 12:46:37.952293 12588 solver.cpp:237] Iteration 101000, loss = 1.51667
I0522 12:46:37.952329 12588 solver.cpp:253]     Train net output #0: loss = 1.51667 (* 1 = 1.51667 loss)
I0522 12:46:37.952347 12588 sgd_solver.cpp:106] Iteration 101000, lr = 0.003
I0522 12:46:48.529433 12588 solver.cpp:237] Iteration 101500, loss = 1.10796
I0522 12:46:48.529469 12588 solver.cpp:253]     Train net output #0: loss = 1.10796 (* 1 = 1.10796 loss)
I0522 12:46:48.529485 12588 sgd_solver.cpp:106] Iteration 101500, lr = 0.003
I0522 12:46:59.109388 12588 solver.cpp:237] Iteration 102000, loss = 1.27819
I0522 12:46:59.109544 12588 solver.cpp:253]     Train net output #0: loss = 1.27819 (* 1 = 1.27819 loss)
I0522 12:46:59.109558 12588 sgd_solver.cpp:106] Iteration 102000, lr = 0.003
I0522 12:47:09.705310 12588 solver.cpp:237] Iteration 102500, loss = 1.18564
I0522 12:47:09.705345 12588 solver.cpp:253]     Train net output #0: loss = 1.18564 (* 1 = 1.18564 loss)
I0522 12:47:09.705363 12588 sgd_solver.cpp:106] Iteration 102500, lr = 0.003
I0522 12:47:20.302639 12588 solver.cpp:237] Iteration 103000, loss = 1.32016
I0522 12:47:20.302681 12588 solver.cpp:253]     Train net output #0: loss = 1.32016 (* 1 = 1.32016 loss)
I0522 12:47:20.302697 12588 sgd_solver.cpp:106] Iteration 103000, lr = 0.003
I0522 12:47:51.734545 12588 solver.cpp:237] Iteration 103500, loss = 0.779848
I0522 12:47:51.734725 12588 solver.cpp:253]     Train net output #0: loss = 0.779849 (* 1 = 0.779849 loss)
I0522 12:47:51.734741 12588 sgd_solver.cpp:106] Iteration 103500, lr = 0.003
I0522 12:48:02.321533 12588 solver.cpp:237] Iteration 104000, loss = 0.86234
I0522 12:48:02.321569 12588 solver.cpp:253]     Train net output #0: loss = 0.862341 (* 1 = 0.862341 loss)
I0522 12:48:02.321585 12588 sgd_solver.cpp:106] Iteration 104000, lr = 0.003
I0522 12:48:12.902990 12588 solver.cpp:237] Iteration 104500, loss = 1.60424
I0522 12:48:12.903033 12588 solver.cpp:253]     Train net output #0: loss = 1.60424 (* 1 = 1.60424 loss)
I0522 12:48:12.903049 12588 sgd_solver.cpp:106] Iteration 104500, lr = 0.003
I0522 12:48:23.465569 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_105000.caffemodel
I0522 12:48:23.517653 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_105000.solverstate
I0522 12:48:23.549733 12588 solver.cpp:237] Iteration 105000, loss = 1.18715
I0522 12:48:23.549774 12588 solver.cpp:253]     Train net output #0: loss = 1.18715 (* 1 = 1.18715 loss)
I0522 12:48:23.549793 12588 sgd_solver.cpp:106] Iteration 105000, lr = 0.003
I0522 12:48:34.142402 12588 solver.cpp:237] Iteration 105500, loss = 1.43353
I0522 12:48:34.142452 12588 solver.cpp:253]     Train net output #0: loss = 1.43353 (* 1 = 1.43353 loss)
I0522 12:48:34.142464 12588 sgd_solver.cpp:106] Iteration 105500, lr = 0.003
I0522 12:48:44.717562 12588 solver.cpp:237] Iteration 106000, loss = 1.15831
I0522 12:48:44.717598 12588 solver.cpp:253]     Train net output #0: loss = 1.15831 (* 1 = 1.15831 loss)
I0522 12:48:44.717614 12588 sgd_solver.cpp:106] Iteration 106000, lr = 0.003
I0522 12:48:55.307097 12588 solver.cpp:237] Iteration 106500, loss = 1.04806
I0522 12:48:55.307271 12588 solver.cpp:253]     Train net output #0: loss = 1.04806 (* 1 = 1.04806 loss)
I0522 12:48:55.307287 12588 sgd_solver.cpp:106] Iteration 106500, lr = 0.003
I0522 12:49:26.771176 12588 solver.cpp:237] Iteration 107000, loss = 1.17276
I0522 12:49:26.771356 12588 solver.cpp:253]     Train net output #0: loss = 1.17276 (* 1 = 1.17276 loss)
I0522 12:49:26.771371 12588 sgd_solver.cpp:106] Iteration 107000, lr = 0.003
I0522 12:49:37.364325 12588 solver.cpp:237] Iteration 107500, loss = 1.25992
I0522 12:49:37.364362 12588 solver.cpp:253]     Train net output #0: loss = 1.25992 (* 1 = 1.25992 loss)
I0522 12:49:37.364374 12588 sgd_solver.cpp:106] Iteration 107500, lr = 0.003
I0522 12:49:47.959157 12588 solver.cpp:237] Iteration 108000, loss = 0.951416
I0522 12:49:47.959206 12588 solver.cpp:253]     Train net output #0: loss = 0.951416 (* 1 = 0.951416 loss)
I0522 12:49:47.959220 12588 sgd_solver.cpp:106] Iteration 108000, lr = 0.003
I0522 12:49:58.528291 12588 solver.cpp:237] Iteration 108500, loss = 1.02285
I0522 12:49:58.528450 12588 solver.cpp:253]     Train net output #0: loss = 1.02285 (* 1 = 1.02285 loss)
I0522 12:49:58.528465 12588 sgd_solver.cpp:106] Iteration 108500, lr = 0.003
I0522 12:50:09.120528 12588 solver.cpp:237] Iteration 109000, loss = 1.60592
I0522 12:50:09.120576 12588 solver.cpp:253]     Train net output #0: loss = 1.60592 (* 1 = 1.60592 loss)
I0522 12:50:09.120594 12588 sgd_solver.cpp:106] Iteration 109000, lr = 0.003
I0522 12:50:19.693522 12588 solver.cpp:237] Iteration 109500, loss = 1.11279
I0522 12:50:19.693558 12588 solver.cpp:253]     Train net output #0: loss = 1.11279 (* 1 = 1.11279 loss)
I0522 12:50:19.693574 12588 sgd_solver.cpp:106] Iteration 109500, lr = 0.003
I0522 12:50:30.252377 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_110000.caffemodel
I0522 12:50:30.305018 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_110000.solverstate
I0522 12:50:30.330734 12588 solver.cpp:341] Iteration 110000, Testing net (#0)
I0522 12:51:19.593544 12588 solver.cpp:409]     Test net output #0: accuracy = 0.894599
I0522 12:51:19.593720 12588 solver.cpp:409]     Test net output #1: loss = 0.334433 (* 1 = 0.334433 loss)
I0522 12:51:40.486255 12588 solver.cpp:237] Iteration 110000, loss = 0.951734
I0522 12:51:40.486309 12588 solver.cpp:253]     Train net output #0: loss = 0.951734 (* 1 = 0.951734 loss)
I0522 12:51:40.486323 12588 sgd_solver.cpp:106] Iteration 110000, lr = 0.003
I0522 12:51:51.000653 12588 solver.cpp:237] Iteration 110500, loss = 0.936148
I0522 12:51:51.000836 12588 solver.cpp:253]     Train net output #0: loss = 0.936149 (* 1 = 0.936149 loss)
I0522 12:51:51.000851 12588 sgd_solver.cpp:106] Iteration 110500, lr = 0.003
I0522 12:52:01.525214 12588 solver.cpp:237] Iteration 111000, loss = 0.750121
I0522 12:52:01.525251 12588 solver.cpp:253]     Train net output #0: loss = 0.750121 (* 1 = 0.750121 loss)
I0522 12:52:01.525266 12588 sgd_solver.cpp:106] Iteration 111000, lr = 0.003
I0522 12:52:12.045027 12588 solver.cpp:237] Iteration 111500, loss = 1.24991
I0522 12:52:12.045063 12588 solver.cpp:253]     Train net output #0: loss = 1.24991 (* 1 = 1.24991 loss)
I0522 12:52:12.045080 12588 sgd_solver.cpp:106] Iteration 111500, lr = 0.003
I0522 12:52:22.551249 12588 solver.cpp:237] Iteration 112000, loss = 0.984265
I0522 12:52:22.551424 12588 solver.cpp:253]     Train net output #0: loss = 0.984265 (* 1 = 0.984265 loss)
I0522 12:52:22.551440 12588 sgd_solver.cpp:106] Iteration 112000, lr = 0.003
I0522 12:52:33.060683 12588 solver.cpp:237] Iteration 112500, loss = 1.45645
I0522 12:52:33.060714 12588 solver.cpp:253]     Train net output #0: loss = 1.45645 (* 1 = 1.45645 loss)
I0522 12:52:33.060729 12588 sgd_solver.cpp:106] Iteration 112500, lr = 0.003
I0522 12:52:43.587884 12588 solver.cpp:237] Iteration 113000, loss = 0.929356
I0522 12:52:43.587929 12588 solver.cpp:253]     Train net output #0: loss = 0.929357 (* 1 = 0.929357 loss)
I0522 12:52:43.587944 12588 sgd_solver.cpp:106] Iteration 113000, lr = 0.003
I0522 12:53:14.987098 12588 solver.cpp:237] Iteration 113500, loss = 1.26208
I0522 12:53:14.987277 12588 solver.cpp:253]     Train net output #0: loss = 1.26208 (* 1 = 1.26208 loss)
I0522 12:53:14.987293 12588 sgd_solver.cpp:106] Iteration 113500, lr = 0.003
I0522 12:53:25.509770 12588 solver.cpp:237] Iteration 114000, loss = 0.981595
I0522 12:53:25.509806 12588 solver.cpp:253]     Train net output #0: loss = 0.981595 (* 1 = 0.981595 loss)
I0522 12:53:25.509822 12588 sgd_solver.cpp:106] Iteration 114000, lr = 0.003
I0522 12:53:36.020118 12588 solver.cpp:237] Iteration 114500, loss = 1.1105
I0522 12:53:36.020164 12588 solver.cpp:253]     Train net output #0: loss = 1.1105 (* 1 = 1.1105 loss)
I0522 12:53:36.020180 12588 sgd_solver.cpp:106] Iteration 114500, lr = 0.003
I0522 12:53:46.519351 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_115000.caffemodel
I0522 12:53:46.572219 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_115000.solverstate
I0522 12:53:46.604454 12588 solver.cpp:237] Iteration 115000, loss = 1.17259
I0522 12:53:46.604498 12588 solver.cpp:253]     Train net output #0: loss = 1.17259 (* 1 = 1.17259 loss)
I0522 12:53:46.604512 12588 sgd_solver.cpp:106] Iteration 115000, lr = 0.003
I0522 12:53:57.106900 12588 solver.cpp:237] Iteration 115500, loss = 1.19381
I0522 12:53:57.106950 12588 solver.cpp:253]     Train net output #0: loss = 1.19381 (* 1 = 1.19381 loss)
I0522 12:53:57.106964 12588 sgd_solver.cpp:106] Iteration 115500, lr = 0.003
I0522 12:54:07.603688 12588 solver.cpp:237] Iteration 116000, loss = 0.864954
I0522 12:54:07.603724 12588 solver.cpp:253]     Train net output #0: loss = 0.864954 (* 1 = 0.864954 loss)
I0522 12:54:07.603740 12588 sgd_solver.cpp:106] Iteration 116000, lr = 0.003
I0522 12:54:18.107689 12588 solver.cpp:237] Iteration 116500, loss = 1.55188
I0522 12:54:18.107853 12588 solver.cpp:253]     Train net output #0: loss = 1.55188 (* 1 = 1.55188 loss)
I0522 12:54:18.107867 12588 sgd_solver.cpp:106] Iteration 116500, lr = 0.003
I0522 12:54:49.497200 12588 solver.cpp:237] Iteration 117000, loss = 1.03283
I0522 12:54:49.497380 12588 solver.cpp:253]     Train net output #0: loss = 1.03283 (* 1 = 1.03283 loss)
I0522 12:54:49.497396 12588 sgd_solver.cpp:106] Iteration 117000, lr = 0.003
I0522 12:55:00.003195 12588 solver.cpp:237] Iteration 117500, loss = 1.18381
I0522 12:55:00.003231 12588 solver.cpp:253]     Train net output #0: loss = 1.18382 (* 1 = 1.18382 loss)
I0522 12:55:00.003247 12588 sgd_solver.cpp:106] Iteration 117500, lr = 0.003
I0522 12:55:10.521824 12588 solver.cpp:237] Iteration 118000, loss = 1.16631
I0522 12:55:10.521873 12588 solver.cpp:253]     Train net output #0: loss = 1.16631 (* 1 = 1.16631 loss)
I0522 12:55:10.521888 12588 sgd_solver.cpp:106] Iteration 118000, lr = 0.003
I0522 12:55:21.038532 12588 solver.cpp:237] Iteration 118500, loss = 0.90998
I0522 12:55:21.038704 12588 solver.cpp:253]     Train net output #0: loss = 0.909981 (* 1 = 0.909981 loss)
I0522 12:55:21.038718 12588 sgd_solver.cpp:106] Iteration 118500, lr = 0.003
I0522 12:55:31.548579 12588 solver.cpp:237] Iteration 119000, loss = 0.86707
I0522 12:55:31.548615 12588 solver.cpp:253]     Train net output #0: loss = 0.86707 (* 1 = 0.86707 loss)
I0522 12:55:31.548631 12588 sgd_solver.cpp:106] Iteration 119000, lr = 0.003
I0522 12:55:42.066963 12588 solver.cpp:237] Iteration 119500, loss = 1.11658
I0522 12:55:42.067013 12588 solver.cpp:253]     Train net output #0: loss = 1.11658 (* 1 = 1.11658 loss)
I0522 12:55:42.067028 12588 sgd_solver.cpp:106] Iteration 119500, lr = 0.003
I0522 12:55:52.556288 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_120000.caffemodel
I0522 12:55:52.609191 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_120000.solverstate
I0522 12:55:52.634999 12588 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 12:57:03.131158 12588 solver.cpp:409]     Test net output #0: accuracy = 0.892385
I0522 12:57:03.131335 12588 solver.cpp:409]     Test net output #1: loss = 0.358413 (* 1 = 0.358413 loss)
I0522 12:57:24.076994 12588 solver.cpp:237] Iteration 120000, loss = 0.748938
I0522 12:57:24.077049 12588 solver.cpp:253]     Train net output #0: loss = 0.748938 (* 1 = 0.748938 loss)
I0522 12:57:24.077064 12588 sgd_solver.cpp:106] Iteration 120000, lr = 0.003
I0522 12:57:34.676336 12588 solver.cpp:237] Iteration 120500, loss = 1.00897
I0522 12:57:34.676512 12588 solver.cpp:253]     Train net output #0: loss = 1.00897 (* 1 = 1.00897 loss)
I0522 12:57:34.676524 12588 sgd_solver.cpp:106] Iteration 120500, lr = 0.003
I0522 12:57:45.289027 12588 solver.cpp:237] Iteration 121000, loss = 1.44057
I0522 12:57:45.289077 12588 solver.cpp:253]     Train net output #0: loss = 1.44057 (* 1 = 1.44057 loss)
I0522 12:57:45.289090 12588 sgd_solver.cpp:106] Iteration 121000, lr = 0.003
I0522 12:57:55.904132 12588 solver.cpp:237] Iteration 121500, loss = 1.269
I0522 12:57:55.904167 12588 solver.cpp:253]     Train net output #0: loss = 1.269 (* 1 = 1.269 loss)
I0522 12:57:55.904184 12588 sgd_solver.cpp:106] Iteration 121500, lr = 0.003
I0522 12:58:06.514924 12588 solver.cpp:237] Iteration 122000, loss = 1.18013
I0522 12:58:06.515095 12588 solver.cpp:253]     Train net output #0: loss = 1.18013 (* 1 = 1.18013 loss)
I0522 12:58:06.515111 12588 sgd_solver.cpp:106] Iteration 122000, lr = 0.003
I0522 12:58:17.111299 12588 solver.cpp:237] Iteration 122500, loss = 0.892758
I0522 12:58:17.111336 12588 solver.cpp:253]     Train net output #0: loss = 0.892758 (* 1 = 0.892758 loss)
I0522 12:58:17.111353 12588 sgd_solver.cpp:106] Iteration 122500, lr = 0.003
I0522 12:58:27.712982 12588 solver.cpp:237] Iteration 123000, loss = 1.18766
I0522 12:58:27.713018 12588 solver.cpp:253]     Train net output #0: loss = 1.18766 (* 1 = 1.18766 loss)
I0522 12:58:27.713034 12588 sgd_solver.cpp:106] Iteration 123000, lr = 0.003
I0522 12:58:59.207016 12588 solver.cpp:237] Iteration 123500, loss = 1.23564
I0522 12:58:59.207195 12588 solver.cpp:253]     Train net output #0: loss = 1.23564 (* 1 = 1.23564 loss)
I0522 12:58:59.207211 12588 sgd_solver.cpp:106] Iteration 123500, lr = 0.003
I0522 12:59:09.807669 12588 solver.cpp:237] Iteration 124000, loss = 1.24069
I0522 12:59:09.807705 12588 solver.cpp:253]     Train net output #0: loss = 1.24069 (* 1 = 1.24069 loss)
I0522 12:59:09.807721 12588 sgd_solver.cpp:106] Iteration 124000, lr = 0.003
I0522 12:59:20.408785 12588 solver.cpp:237] Iteration 124500, loss = 1.00718
I0522 12:59:20.408833 12588 solver.cpp:253]     Train net output #0: loss = 1.00718 (* 1 = 1.00718 loss)
I0522 12:59:20.408845 12588 sgd_solver.cpp:106] Iteration 124500, lr = 0.003
I0522 12:59:31.012058 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_125000.caffemodel
I0522 12:59:31.066627 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_125000.solverstate
I0522 12:59:31.100428 12588 solver.cpp:237] Iteration 125000, loss = 1.27095
I0522 12:59:31.100478 12588 solver.cpp:253]     Train net output #0: loss = 1.27095 (* 1 = 1.27095 loss)
I0522 12:59:31.100494 12588 sgd_solver.cpp:106] Iteration 125000, lr = 0.003
I0522 12:59:41.706117 12588 solver.cpp:237] Iteration 125500, loss = 1.15632
I0522 12:59:41.706153 12588 solver.cpp:253]     Train net output #0: loss = 1.15632 (* 1 = 1.15632 loss)
I0522 12:59:41.706171 12588 sgd_solver.cpp:106] Iteration 125500, lr = 0.003
I0522 12:59:52.304936 12588 solver.cpp:237] Iteration 126000, loss = 1.13527
I0522 12:59:52.304985 12588 solver.cpp:253]     Train net output #0: loss = 1.13527 (* 1 = 1.13527 loss)
I0522 12:59:52.304998 12588 sgd_solver.cpp:106] Iteration 126000, lr = 0.003
I0522 13:00:02.898847 12588 solver.cpp:237] Iteration 126500, loss = 0.96245
I0522 13:00:02.899015 12588 solver.cpp:253]     Train net output #0: loss = 0.96245 (* 1 = 0.96245 loss)
I0522 13:00:02.899030 12588 sgd_solver.cpp:106] Iteration 126500, lr = 0.003
I0522 13:00:34.386941 12588 solver.cpp:237] Iteration 127000, loss = 1.02105
I0522 13:00:34.387115 12588 solver.cpp:253]     Train net output #0: loss = 1.02105 (* 1 = 1.02105 loss)
I0522 13:00:34.387130 12588 sgd_solver.cpp:106] Iteration 127000, lr = 0.003
I0522 13:00:44.992632 12588 solver.cpp:237] Iteration 127500, loss = 1.18587
I0522 13:00:44.992668 12588 solver.cpp:253]     Train net output #0: loss = 1.18587 (* 1 = 1.18587 loss)
I0522 13:00:44.992686 12588 sgd_solver.cpp:106] Iteration 127500, lr = 0.003
I0522 13:00:55.578857 12588 solver.cpp:237] Iteration 128000, loss = 1.16001
I0522 13:00:55.578893 12588 solver.cpp:253]     Train net output #0: loss = 1.16001 (* 1 = 1.16001 loss)
I0522 13:00:55.578909 12588 sgd_solver.cpp:106] Iteration 128000, lr = 0.003
I0522 13:01:06.158447 12588 solver.cpp:237] Iteration 128500, loss = 1.13566
I0522 13:01:06.158622 12588 solver.cpp:253]     Train net output #0: loss = 1.13566 (* 1 = 1.13566 loss)
I0522 13:01:06.158638 12588 sgd_solver.cpp:106] Iteration 128500, lr = 0.003
I0522 13:01:16.755640 12588 solver.cpp:237] Iteration 129000, loss = 1.05006
I0522 13:01:16.755676 12588 solver.cpp:253]     Train net output #0: loss = 1.05006 (* 1 = 1.05006 loss)
I0522 13:01:16.755692 12588 sgd_solver.cpp:106] Iteration 129000, lr = 0.003
I0522 13:01:27.346153 12588 solver.cpp:237] Iteration 129500, loss = 1.0675
I0522 13:01:27.346199 12588 solver.cpp:253]     Train net output #0: loss = 1.0675 (* 1 = 1.0675 loss)
I0522 13:01:27.346211 12588 sgd_solver.cpp:106] Iteration 129500, lr = 0.003
I0522 13:01:37.926079 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_130000.caffemodel
I0522 13:01:37.978843 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_130000.solverstate
I0522 13:01:38.004194 12588 solver.cpp:341] Iteration 130000, Testing net (#0)
I0522 13:02:27.619235 12588 solver.cpp:409]     Test net output #0: accuracy = 0.895566
I0522 13:02:27.619424 12588 solver.cpp:409]     Test net output #1: loss = 0.345105 (* 1 = 0.345105 loss)
I0522 13:02:48.504549 12588 solver.cpp:237] Iteration 130000, loss = 1.18398
I0522 13:02:48.504602 12588 solver.cpp:253]     Train net output #0: loss = 1.18398 (* 1 = 1.18398 loss)
I0522 13:02:48.504618 12588 sgd_solver.cpp:106] Iteration 130000, lr = 0.003
I0522 13:02:59.041604 12588 solver.cpp:237] Iteration 130500, loss = 1.03018
I0522 13:02:59.041772 12588 solver.cpp:253]     Train net output #0: loss = 1.03018 (* 1 = 1.03018 loss)
I0522 13:02:59.041788 12588 sgd_solver.cpp:106] Iteration 130500, lr = 0.003
I0522 13:03:09.595564 12588 solver.cpp:237] Iteration 131000, loss = 1.7614
I0522 13:03:09.595610 12588 solver.cpp:253]     Train net output #0: loss = 1.7614 (* 1 = 1.7614 loss)
I0522 13:03:09.595623 12588 sgd_solver.cpp:106] Iteration 131000, lr = 0.003
I0522 13:03:20.143187 12588 solver.cpp:237] Iteration 131500, loss = 1.51469
I0522 13:03:20.143224 12588 solver.cpp:253]     Train net output #0: loss = 1.51469 (* 1 = 1.51469 loss)
I0522 13:03:20.143239 12588 sgd_solver.cpp:106] Iteration 131500, lr = 0.003
I0522 13:03:30.700809 12588 solver.cpp:237] Iteration 132000, loss = 0.925579
I0522 13:03:30.700989 12588 solver.cpp:253]     Train net output #0: loss = 0.925579 (* 1 = 0.925579 loss)
I0522 13:03:30.701004 12588 sgd_solver.cpp:106] Iteration 132000, lr = 0.003
I0522 13:03:41.261030 12588 solver.cpp:237] Iteration 132500, loss = 1.21877
I0522 13:03:41.261066 12588 solver.cpp:253]     Train net output #0: loss = 1.21877 (* 1 = 1.21877 loss)
I0522 13:03:41.261082 12588 sgd_solver.cpp:106] Iteration 132500, lr = 0.003
I0522 13:03:51.828428 12588 solver.cpp:237] Iteration 133000, loss = 1.24214
I0522 13:03:51.828462 12588 solver.cpp:253]     Train net output #0: loss = 1.24214 (* 1 = 1.24214 loss)
I0522 13:03:51.828476 12588 sgd_solver.cpp:106] Iteration 133000, lr = 0.003
I0522 13:04:23.291692 12588 solver.cpp:237] Iteration 133500, loss = 0.940893
I0522 13:04:23.291877 12588 solver.cpp:253]     Train net output #0: loss = 0.940893 (* 1 = 0.940893 loss)
I0522 13:04:23.291892 12588 sgd_solver.cpp:106] Iteration 133500, lr = 0.003
I0522 13:04:33.827440 12588 solver.cpp:237] Iteration 134000, loss = 0.751522
I0522 13:04:33.827477 12588 solver.cpp:253]     Train net output #0: loss = 0.751522 (* 1 = 0.751522 loss)
I0522 13:04:33.827493 12588 sgd_solver.cpp:106] Iteration 134000, lr = 0.003
I0522 13:04:44.388613 12588 solver.cpp:237] Iteration 134500, loss = 1.23552
I0522 13:04:44.388661 12588 solver.cpp:253]     Train net output #0: loss = 1.23552 (* 1 = 1.23552 loss)
I0522 13:04:44.388676 12588 sgd_solver.cpp:106] Iteration 134500, lr = 0.003
I0522 13:04:54.928357 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_135000.caffemodel
I0522 13:04:54.983415 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_135000.solverstate
I0522 13:04:55.015029 12588 solver.cpp:237] Iteration 135000, loss = 0.909408
I0522 13:04:55.015071 12588 solver.cpp:253]     Train net output #0: loss = 0.909409 (* 1 = 0.909409 loss)
I0522 13:04:55.015089 12588 sgd_solver.cpp:106] Iteration 135000, lr = 0.003
I0522 13:05:05.557219 12588 solver.cpp:237] Iteration 135500, loss = 1.17174
I0522 13:05:05.557255 12588 solver.cpp:253]     Train net output #0: loss = 1.17174 (* 1 = 1.17174 loss)
I0522 13:05:05.557271 12588 sgd_solver.cpp:106] Iteration 135500, lr = 0.003
I0522 13:05:16.119776 12588 solver.cpp:237] Iteration 136000, loss = 0.834356
I0522 13:05:16.119827 12588 solver.cpp:253]     Train net output #0: loss = 0.834356 (* 1 = 0.834356 loss)
I0522 13:05:16.119842 12588 sgd_solver.cpp:106] Iteration 136000, lr = 0.003
I0522 13:05:26.682186 12588 solver.cpp:237] Iteration 136500, loss = 0.964661
I0522 13:05:26.682354 12588 solver.cpp:253]     Train net output #0: loss = 0.964661 (* 1 = 0.964661 loss)
I0522 13:05:26.682369 12588 sgd_solver.cpp:106] Iteration 136500, lr = 0.003
I0522 13:05:58.137394 12588 solver.cpp:237] Iteration 137000, loss = 1.09827
I0522 13:05:58.137589 12588 solver.cpp:253]     Train net output #0: loss = 1.09827 (* 1 = 1.09827 loss)
I0522 13:05:58.137604 12588 sgd_solver.cpp:106] Iteration 137000, lr = 0.003
I0522 13:06:08.686980 12588 solver.cpp:237] Iteration 137500, loss = 1.64397
I0522 13:06:08.687028 12588 solver.cpp:253]     Train net output #0: loss = 1.64397 (* 1 = 1.64397 loss)
I0522 13:06:08.687042 12588 sgd_solver.cpp:106] Iteration 137500, lr = 0.003
I0522 13:06:19.232182 12588 solver.cpp:237] Iteration 138000, loss = 1.43925
I0522 13:06:19.232218 12588 solver.cpp:253]     Train net output #0: loss = 1.43925 (* 1 = 1.43925 loss)
I0522 13:06:19.232234 12588 sgd_solver.cpp:106] Iteration 138000, lr = 0.003
I0522 13:06:29.773972 12588 solver.cpp:237] Iteration 138500, loss = 1.26725
I0522 13:06:29.774159 12588 solver.cpp:253]     Train net output #0: loss = 1.26725 (* 1 = 1.26725 loss)
I0522 13:06:29.774174 12588 sgd_solver.cpp:106] Iteration 138500, lr = 0.003
I0522 13:06:40.328511 12588 solver.cpp:237] Iteration 139000, loss = 0.966585
I0522 13:06:40.328548 12588 solver.cpp:253]     Train net output #0: loss = 0.966586 (* 1 = 0.966586 loss)
I0522 13:06:40.328562 12588 sgd_solver.cpp:106] Iteration 139000, lr = 0.003
I0522 13:06:50.886072 12588 solver.cpp:237] Iteration 139500, loss = 0.952926
I0522 13:06:50.886119 12588 solver.cpp:253]     Train net output #0: loss = 0.952926 (* 1 = 0.952926 loss)
I0522 13:06:50.886133 12588 sgd_solver.cpp:106] Iteration 139500, lr = 0.003
I0522 13:07:01.425191 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_140000.caffemodel
I0522 13:07:01.477886 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_140000.solverstate
I0522 13:07:01.504005 12588 solver.cpp:341] Iteration 140000, Testing net (#0)
I0522 13:08:11.996237 12588 solver.cpp:409]     Test net output #0: accuracy = 0.896492
I0522 13:08:11.996419 12588 solver.cpp:409]     Test net output #1: loss = 0.317454 (* 1 = 0.317454 loss)
I0522 13:08:32.913779 12588 solver.cpp:237] Iteration 140000, loss = 1.42739
I0522 13:08:32.913831 12588 solver.cpp:253]     Train net output #0: loss = 1.42739 (* 1 = 1.42739 loss)
I0522 13:08:32.913847 12588 sgd_solver.cpp:106] Iteration 140000, lr = 0.003
I0522 13:08:43.485958 12588 solver.cpp:237] Iteration 140500, loss = 1.01034
I0522 13:08:43.486145 12588 solver.cpp:253]     Train net output #0: loss = 1.01034 (* 1 = 1.01034 loss)
I0522 13:08:43.486160 12588 sgd_solver.cpp:106] Iteration 140500, lr = 0.003
I0522 13:08:54.055831 12588 solver.cpp:237] Iteration 141000, loss = 1.41182
I0522 13:08:54.055876 12588 solver.cpp:253]     Train net output #0: loss = 1.41182 (* 1 = 1.41182 loss)
I0522 13:08:54.055891 12588 sgd_solver.cpp:106] Iteration 141000, lr = 0.003
I0522 13:09:04.622491 12588 solver.cpp:237] Iteration 141500, loss = 0.813401
I0522 13:09:04.622529 12588 solver.cpp:253]     Train net output #0: loss = 0.813401 (* 1 = 0.813401 loss)
I0522 13:09:04.622545 12588 sgd_solver.cpp:106] Iteration 141500, lr = 0.003
I0522 13:09:15.192611 12588 solver.cpp:237] Iteration 142000, loss = 1.26935
I0522 13:09:15.192775 12588 solver.cpp:253]     Train net output #0: loss = 1.26935 (* 1 = 1.26935 loss)
I0522 13:09:15.192790 12588 sgd_solver.cpp:106] Iteration 142000, lr = 0.003
I0522 13:09:25.748884 12588 solver.cpp:237] Iteration 142500, loss = 0.911682
I0522 13:09:25.748930 12588 solver.cpp:253]     Train net output #0: loss = 0.911682 (* 1 = 0.911682 loss)
I0522 13:09:25.748945 12588 sgd_solver.cpp:106] Iteration 142500, lr = 0.003
I0522 13:09:36.317486 12588 solver.cpp:237] Iteration 143000, loss = 1.1893
I0522 13:09:36.317522 12588 solver.cpp:253]     Train net output #0: loss = 1.1893 (* 1 = 1.1893 loss)
I0522 13:09:36.317538 12588 sgd_solver.cpp:106] Iteration 143000, lr = 0.003
I0522 13:10:07.807116 12588 solver.cpp:237] Iteration 143500, loss = 0.82029
I0522 13:10:07.807315 12588 solver.cpp:253]     Train net output #0: loss = 0.82029 (* 1 = 0.82029 loss)
I0522 13:10:07.807330 12588 sgd_solver.cpp:106] Iteration 143500, lr = 0.003
I0522 13:10:18.372704 12588 solver.cpp:237] Iteration 144000, loss = 1.49543
I0522 13:10:18.372748 12588 solver.cpp:253]     Train net output #0: loss = 1.49543 (* 1 = 1.49543 loss)
I0522 13:10:18.372763 12588 sgd_solver.cpp:106] Iteration 144000, lr = 0.003
I0522 13:10:28.925132 12588 solver.cpp:237] Iteration 144500, loss = 1.17853
I0522 13:10:28.925168 12588 solver.cpp:253]     Train net output #0: loss = 1.17853 (* 1 = 1.17853 loss)
I0522 13:10:28.925184 12588 sgd_solver.cpp:106] Iteration 144500, lr = 0.003
I0522 13:10:39.486474 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_145000.caffemodel
I0522 13:10:39.541342 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_145000.solverstate
I0522 13:10:39.575637 12588 solver.cpp:237] Iteration 145000, loss = 1.27938
I0522 13:10:39.575687 12588 solver.cpp:253]     Train net output #0: loss = 1.27938 (* 1 = 1.27938 loss)
I0522 13:10:39.575702 12588 sgd_solver.cpp:106] Iteration 145000, lr = 0.003
I0522 13:10:50.139004 12588 solver.cpp:237] Iteration 145500, loss = 0.958841
I0522 13:10:50.139041 12588 solver.cpp:253]     Train net output #0: loss = 0.958842 (* 1 = 0.958842 loss)
I0522 13:10:50.139056 12588 sgd_solver.cpp:106] Iteration 145500, lr = 0.003
I0522 13:11:00.718983 12588 solver.cpp:237] Iteration 146000, loss = 1.59721
I0522 13:11:00.719035 12588 solver.cpp:253]     Train net output #0: loss = 1.59721 (* 1 = 1.59721 loss)
I0522 13:11:00.719049 12588 sgd_solver.cpp:106] Iteration 146000, lr = 0.003
I0522 13:11:11.298460 12588 solver.cpp:237] Iteration 146500, loss = 1.11459
I0522 13:11:11.298630 12588 solver.cpp:253]     Train net output #0: loss = 1.11459 (* 1 = 1.11459 loss)
I0522 13:11:11.298645 12588 sgd_solver.cpp:106] Iteration 146500, lr = 0.003
I0522 13:11:42.748143 12588 solver.cpp:237] Iteration 147000, loss = 0.937973
I0522 13:11:42.748330 12588 solver.cpp:253]     Train net output #0: loss = 0.937974 (* 1 = 0.937974 loss)
I0522 13:11:42.748345 12588 sgd_solver.cpp:106] Iteration 147000, lr = 0.003
I0522 13:11:53.309006 12588 solver.cpp:237] Iteration 147500, loss = 1.36089
I0522 13:11:53.309048 12588 solver.cpp:253]     Train net output #0: loss = 1.36089 (* 1 = 1.36089 loss)
I0522 13:11:53.309065 12588 sgd_solver.cpp:106] Iteration 147500, lr = 0.003
I0522 13:12:03.869626 12588 solver.cpp:237] Iteration 148000, loss = 0.991088
I0522 13:12:03.869662 12588 solver.cpp:253]     Train net output #0: loss = 0.991089 (* 1 = 0.991089 loss)
I0522 13:12:03.869678 12588 sgd_solver.cpp:106] Iteration 148000, lr = 0.003
I0522 13:12:14.454318 12588 solver.cpp:237] Iteration 148500, loss = 1.32117
I0522 13:12:14.454489 12588 solver.cpp:253]     Train net output #0: loss = 1.32117 (* 1 = 1.32117 loss)
I0522 13:12:14.454504 12588 sgd_solver.cpp:106] Iteration 148500, lr = 0.003
I0522 13:12:25.023198 12588 solver.cpp:237] Iteration 149000, loss = 1.29544
I0522 13:12:25.023234 12588 solver.cpp:253]     Train net output #0: loss = 1.29544 (* 1 = 1.29544 loss)
I0522 13:12:25.023250 12588 sgd_solver.cpp:106] Iteration 149000, lr = 0.003
I0522 13:12:35.601161 12588 solver.cpp:237] Iteration 149500, loss = 1.44285
I0522 13:12:35.601197 12588 solver.cpp:253]     Train net output #0: loss = 1.44285 (* 1 = 1.44285 loss)
I0522 13:12:35.601212 12588 sgd_solver.cpp:106] Iteration 149500, lr = 0.003
I0522 13:12:46.137382 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_150000.caffemodel
I0522 13:12:46.193167 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_150000.solverstate
I0522 13:12:46.220679 12588 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 13:13:35.510010 12588 solver.cpp:409]     Test net output #0: accuracy = 0.897144
I0522 13:13:35.510207 12588 solver.cpp:409]     Test net output #1: loss = 0.346571 (* 1 = 0.346571 loss)
I0522 13:13:56.426345 12588 solver.cpp:237] Iteration 150000, loss = 1.2044
I0522 13:13:56.426398 12588 solver.cpp:253]     Train net output #0: loss = 1.2044 (* 1 = 1.2044 loss)
I0522 13:13:56.426412 12588 sgd_solver.cpp:106] Iteration 150000, lr = 0.003
I0522 13:14:06.973623 12588 solver.cpp:237] Iteration 150500, loss = 0.790802
I0522 13:14:06.973794 12588 solver.cpp:253]     Train net output #0: loss = 0.790803 (* 1 = 0.790803 loss)
I0522 13:14:06.973809 12588 sgd_solver.cpp:106] Iteration 150500, lr = 0.003
I0522 13:14:17.520171 12588 solver.cpp:237] Iteration 151000, loss = 1.24379
I0522 13:14:17.520207 12588 solver.cpp:253]     Train net output #0: loss = 1.24379 (* 1 = 1.24379 loss)
I0522 13:14:17.520223 12588 sgd_solver.cpp:106] Iteration 151000, lr = 0.003
I0522 13:14:28.073779 12588 solver.cpp:237] Iteration 151500, loss = 1.47593
I0522 13:14:28.073824 12588 solver.cpp:253]     Train net output #0: loss = 1.47594 (* 1 = 1.47594 loss)
I0522 13:14:28.073842 12588 sgd_solver.cpp:106] Iteration 151500, lr = 0.003
I0522 13:14:38.635483 12588 solver.cpp:237] Iteration 152000, loss = 1.12742
I0522 13:14:38.635648 12588 solver.cpp:253]     Train net output #0: loss = 1.12742 (* 1 = 1.12742 loss)
I0522 13:14:38.635661 12588 sgd_solver.cpp:106] Iteration 152000, lr = 0.003
I0522 13:14:49.177122 12588 solver.cpp:237] Iteration 152500, loss = 1.15589
I0522 13:14:49.177167 12588 solver.cpp:253]     Train net output #0: loss = 1.15589 (* 1 = 1.15589 loss)
I0522 13:14:49.177182 12588 sgd_solver.cpp:106] Iteration 152500, lr = 0.003
I0522 13:14:59.734678 12588 solver.cpp:237] Iteration 153000, loss = 1.3662
I0522 13:14:59.734714 12588 solver.cpp:253]     Train net output #0: loss = 1.3662 (* 1 = 1.3662 loss)
I0522 13:14:59.734730 12588 sgd_solver.cpp:106] Iteration 153000, lr = 0.003
I0522 13:15:31.206048 12588 solver.cpp:237] Iteration 153500, loss = 1.71451
I0522 13:15:31.206240 12588 solver.cpp:253]     Train net output #0: loss = 1.71451 (* 1 = 1.71451 loss)
I0522 13:15:31.206256 12588 sgd_solver.cpp:106] Iteration 153500, lr = 0.003
I0522 13:15:41.747889 12588 solver.cpp:237] Iteration 154000, loss = 1.21653
I0522 13:15:41.747937 12588 solver.cpp:253]     Train net output #0: loss = 1.21653 (* 1 = 1.21653 loss)
I0522 13:15:41.747952 12588 sgd_solver.cpp:106] Iteration 154000, lr = 0.003
I0522 13:15:52.292160 12588 solver.cpp:237] Iteration 154500, loss = 1.77192
I0522 13:15:52.292194 12588 solver.cpp:253]     Train net output #0: loss = 1.77192 (* 1 = 1.77192 loss)
I0522 13:15:52.292210 12588 sgd_solver.cpp:106] Iteration 154500, lr = 0.003
I0522 13:16:02.820523 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_155000.caffemodel
I0522 13:16:02.874420 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_155000.solverstate
I0522 13:16:02.906864 12588 solver.cpp:237] Iteration 155000, loss = 1.18564
I0522 13:16:02.906910 12588 solver.cpp:253]     Train net output #0: loss = 1.18564 (* 1 = 1.18564 loss)
I0522 13:16:02.906927 12588 sgd_solver.cpp:106] Iteration 155000, lr = 0.003
I0522 13:16:13.451150 12588 solver.cpp:237] Iteration 155500, loss = 1.04128
I0522 13:16:13.451185 12588 solver.cpp:253]     Train net output #0: loss = 1.04128 (* 1 = 1.04128 loss)
I0522 13:16:13.451202 12588 sgd_solver.cpp:106] Iteration 155500, lr = 0.003
I0522 13:16:24.000193 12588 solver.cpp:237] Iteration 156000, loss = 1.13306
I0522 13:16:24.000233 12588 solver.cpp:253]     Train net output #0: loss = 1.13306 (* 1 = 1.13306 loss)
I0522 13:16:24.000247 12588 sgd_solver.cpp:106] Iteration 156000, lr = 0.003
I0522 13:16:34.555102 12588 solver.cpp:237] Iteration 156500, loss = 1.05964
I0522 13:16:34.555282 12588 solver.cpp:253]     Train net output #0: loss = 1.05965 (* 1 = 1.05965 loss)
I0522 13:16:34.555296 12588 sgd_solver.cpp:106] Iteration 156500, lr = 0.003
I0522 13:17:06.083493 12588 solver.cpp:237] Iteration 157000, loss = 1.0623
I0522 13:17:06.083681 12588 solver.cpp:253]     Train net output #0: loss = 1.0623 (* 1 = 1.0623 loss)
I0522 13:17:06.083696 12588 sgd_solver.cpp:106] Iteration 157000, lr = 0.003
I0522 13:17:16.614136 12588 solver.cpp:237] Iteration 157500, loss = 1.53009
I0522 13:17:16.614187 12588 solver.cpp:253]     Train net output #0: loss = 1.53009 (* 1 = 1.53009 loss)
I0522 13:17:16.614200 12588 sgd_solver.cpp:106] Iteration 157500, lr = 0.003
I0522 13:17:27.166056 12588 solver.cpp:237] Iteration 158000, loss = 1.29807
I0522 13:17:27.166097 12588 solver.cpp:253]     Train net output #0: loss = 1.29807 (* 1 = 1.29807 loss)
I0522 13:17:27.166115 12588 sgd_solver.cpp:106] Iteration 158000, lr = 0.003
I0522 13:17:37.721773 12588 solver.cpp:237] Iteration 158500, loss = 1.2729
I0522 13:17:37.721941 12588 solver.cpp:253]     Train net output #0: loss = 1.2729 (* 1 = 1.2729 loss)
I0522 13:17:37.721956 12588 sgd_solver.cpp:106] Iteration 158500, lr = 0.003
I0522 13:17:48.243033 12588 solver.cpp:237] Iteration 159000, loss = 1.19883
I0522 13:17:48.243079 12588 solver.cpp:253]     Train net output #0: loss = 1.19883 (* 1 = 1.19883 loss)
I0522 13:17:48.243094 12588 sgd_solver.cpp:106] Iteration 159000, lr = 0.003
I0522 13:17:58.776852 12588 solver.cpp:237] Iteration 159500, loss = 1.24764
I0522 13:17:58.776890 12588 solver.cpp:253]     Train net output #0: loss = 1.24764 (* 1 = 1.24764 loss)
I0522 13:17:58.776904 12588 sgd_solver.cpp:106] Iteration 159500, lr = 0.003
I0522 13:18:09.289093 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_160000.caffemodel
I0522 13:18:09.341905 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_160000.solverstate
I0522 13:18:09.367835 12588 solver.cpp:341] Iteration 160000, Testing net (#0)
I0522 13:19:19.917322 12588 solver.cpp:409]     Test net output #0: accuracy = 0.898752
I0522 13:19:19.917505 12588 solver.cpp:409]     Test net output #1: loss = 0.335305 (* 1 = 0.335305 loss)
I0522 13:19:40.822764 12588 solver.cpp:237] Iteration 160000, loss = 1.05137
I0522 13:19:40.822818 12588 solver.cpp:253]     Train net output #0: loss = 1.05137 (* 1 = 1.05137 loss)
I0522 13:19:40.822832 12588 sgd_solver.cpp:106] Iteration 160000, lr = 0.003
I0522 13:19:51.407872 12588 solver.cpp:237] Iteration 160500, loss = 1.12688
I0522 13:19:51.408056 12588 solver.cpp:253]     Train net output #0: loss = 1.12688 (* 1 = 1.12688 loss)
I0522 13:19:51.408071 12588 sgd_solver.cpp:106] Iteration 160500, lr = 0.003
I0522 13:20:01.985255 12588 solver.cpp:237] Iteration 161000, loss = 0.967651
I0522 13:20:01.985293 12588 solver.cpp:253]     Train net output #0: loss = 0.967652 (* 1 = 0.967652 loss)
I0522 13:20:01.985309 12588 sgd_solver.cpp:106] Iteration 161000, lr = 0.003
I0522 13:20:12.560839 12588 solver.cpp:237] Iteration 161500, loss = 1.49743
I0522 13:20:12.560885 12588 solver.cpp:253]     Train net output #0: loss = 1.49743 (* 1 = 1.49743 loss)
I0522 13:20:12.560899 12588 sgd_solver.cpp:106] Iteration 161500, lr = 0.003
I0522 13:20:23.150624 12588 solver.cpp:237] Iteration 162000, loss = 0.90248
I0522 13:20:23.150802 12588 solver.cpp:253]     Train net output #0: loss = 0.902482 (* 1 = 0.902482 loss)
I0522 13:20:23.150817 12588 sgd_solver.cpp:106] Iteration 162000, lr = 0.003
I0522 13:20:33.727675 12588 solver.cpp:237] Iteration 162500, loss = 1.09335
I0522 13:20:33.727711 12588 solver.cpp:253]     Train net output #0: loss = 1.09336 (* 1 = 1.09336 loss)
I0522 13:20:33.727727 12588 sgd_solver.cpp:106] Iteration 162500, lr = 0.003
I0522 13:20:44.309963 12588 solver.cpp:237] Iteration 163000, loss = 1.51659
I0522 13:20:44.310010 12588 solver.cpp:253]     Train net output #0: loss = 1.51659 (* 1 = 1.51659 loss)
I0522 13:20:44.310024 12588 sgd_solver.cpp:106] Iteration 163000, lr = 0.003
I0522 13:21:15.805961 12588 solver.cpp:237] Iteration 163500, loss = 0.86521
I0522 13:21:15.806169 12588 solver.cpp:253]     Train net output #0: loss = 0.865212 (* 1 = 0.865212 loss)
I0522 13:21:15.806185 12588 sgd_solver.cpp:106] Iteration 163500, lr = 0.003
I0522 13:21:26.382442 12588 solver.cpp:237] Iteration 164000, loss = 1.29572
I0522 13:21:26.382491 12588 solver.cpp:253]     Train net output #0: loss = 1.29572 (* 1 = 1.29572 loss)
I0522 13:21:26.382505 12588 sgd_solver.cpp:106] Iteration 164000, lr = 0.003
I0522 13:21:36.956841 12588 solver.cpp:237] Iteration 164500, loss = 1.28818
I0522 13:21:36.956877 12588 solver.cpp:253]     Train net output #0: loss = 1.28818 (* 1 = 1.28818 loss)
I0522 13:21:36.956894 12588 sgd_solver.cpp:106] Iteration 164500, lr = 0.003
I0522 13:21:47.520565 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_165000.caffemodel
I0522 13:21:47.573143 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_165000.solverstate
I0522 13:21:47.605166 12588 solver.cpp:237] Iteration 165000, loss = 0.978373
I0522 13:21:47.605206 12588 solver.cpp:253]     Train net output #0: loss = 0.978375 (* 1 = 0.978375 loss)
I0522 13:21:47.605226 12588 sgd_solver.cpp:106] Iteration 165000, lr = 0.003
I0522 13:21:58.204802 12588 solver.cpp:237] Iteration 165500, loss = 1.27737
I0522 13:21:58.204848 12588 solver.cpp:253]     Train net output #0: loss = 1.27737 (* 1 = 1.27737 loss)
I0522 13:21:58.204864 12588 sgd_solver.cpp:106] Iteration 165500, lr = 0.003
I0522 13:22:08.822028 12588 solver.cpp:237] Iteration 166000, loss = 1.23546
I0522 13:22:08.822077 12588 solver.cpp:253]     Train net output #0: loss = 1.23546 (* 1 = 1.23546 loss)
I0522 13:22:08.822090 12588 sgd_solver.cpp:106] Iteration 166000, lr = 0.003
I0522 13:22:19.402375 12588 solver.cpp:237] Iteration 166500, loss = 1.17036
I0522 13:22:19.402559 12588 solver.cpp:253]     Train net output #0: loss = 1.17036 (* 1 = 1.17036 loss)
I0522 13:22:19.402575 12588 sgd_solver.cpp:106] Iteration 166500, lr = 0.003
I0522 13:22:50.929139 12588 solver.cpp:237] Iteration 167000, loss = 1.16418
I0522 13:22:50.929328 12588 solver.cpp:253]     Train net output #0: loss = 1.16418 (* 1 = 1.16418 loss)
I0522 13:22:50.929344 12588 sgd_solver.cpp:106] Iteration 167000, lr = 0.003
I0522 13:23:01.498273 12588 solver.cpp:237] Iteration 167500, loss = 1.46006
I0522 13:23:01.498309 12588 solver.cpp:253]     Train net output #0: loss = 1.46007 (* 1 = 1.46007 loss)
I0522 13:23:01.498325 12588 sgd_solver.cpp:106] Iteration 167500, lr = 0.003
I0522 13:23:12.077844 12588 solver.cpp:237] Iteration 168000, loss = 1.01229
I0522 13:23:12.077891 12588 solver.cpp:253]     Train net output #0: loss = 1.01229 (* 1 = 1.01229 loss)
I0522 13:23:12.077908 12588 sgd_solver.cpp:106] Iteration 168000, lr = 0.003
I0522 13:23:22.654567 12588 solver.cpp:237] Iteration 168500, loss = 1.22654
I0522 13:23:22.654734 12588 solver.cpp:253]     Train net output #0: loss = 1.22654 (* 1 = 1.22654 loss)
I0522 13:23:22.654750 12588 sgd_solver.cpp:106] Iteration 168500, lr = 0.003
I0522 13:23:33.240381 12588 solver.cpp:237] Iteration 169000, loss = 1.23468
I0522 13:23:33.240427 12588 solver.cpp:253]     Train net output #0: loss = 1.23469 (* 1 = 1.23469 loss)
I0522 13:23:33.240442 12588 sgd_solver.cpp:106] Iteration 169000, lr = 0.003
I0522 13:23:43.833408 12588 solver.cpp:237] Iteration 169500, loss = 0.815922
I0522 13:23:43.833446 12588 solver.cpp:253]     Train net output #0: loss = 0.815924 (* 1 = 0.815924 loss)
I0522 13:23:43.833461 12588 sgd_solver.cpp:106] Iteration 169500, lr = 0.003
I0522 13:23:54.397851 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_170000.caffemodel
I0522 13:23:54.449650 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_170000.solverstate
I0522 13:23:54.475616 12588 solver.cpp:341] Iteration 170000, Testing net (#0)
I0522 13:24:44.082798 12588 solver.cpp:409]     Test net output #0: accuracy = 0.897999
I0522 13:24:44.082980 12588 solver.cpp:409]     Test net output #1: loss = 0.330296 (* 1 = 0.330296 loss)
I0522 13:25:04.959954 12588 solver.cpp:237] Iteration 170000, loss = 1.21521
I0522 13:25:04.960007 12588 solver.cpp:253]     Train net output #0: loss = 1.21521 (* 1 = 1.21521 loss)
I0522 13:25:04.960022 12588 sgd_solver.cpp:106] Iteration 170000, lr = 0.003
I0522 13:25:15.488427 12588 solver.cpp:237] Iteration 170500, loss = 0.745494
I0522 13:25:15.488612 12588 solver.cpp:253]     Train net output #0: loss = 0.745496 (* 1 = 0.745496 loss)
I0522 13:25:15.488627 12588 sgd_solver.cpp:106] Iteration 170500, lr = 0.003
I0522 13:25:26.013932 12588 solver.cpp:237] Iteration 171000, loss = 1.64817
I0522 13:25:26.013968 12588 solver.cpp:253]     Train net output #0: loss = 1.64817 (* 1 = 1.64817 loss)
I0522 13:25:26.013981 12588 sgd_solver.cpp:106] Iteration 171000, lr = 0.003
I0522 13:25:36.522975 12588 solver.cpp:237] Iteration 171500, loss = 1.01376
I0522 13:25:36.523021 12588 solver.cpp:253]     Train net output #0: loss = 1.01376 (* 1 = 1.01376 loss)
I0522 13:25:36.523036 12588 sgd_solver.cpp:106] Iteration 171500, lr = 0.003
I0522 13:25:47.058943 12588 solver.cpp:237] Iteration 172000, loss = 1.26317
I0522 13:25:47.059111 12588 solver.cpp:253]     Train net output #0: loss = 1.26318 (* 1 = 1.26318 loss)
I0522 13:25:47.059124 12588 sgd_solver.cpp:106] Iteration 172000, lr = 0.003
I0522 13:25:57.586159 12588 solver.cpp:237] Iteration 172500, loss = 1.00815
I0522 13:25:57.586194 12588 solver.cpp:253]     Train net output #0: loss = 1.00815 (* 1 = 1.00815 loss)
I0522 13:25:57.586211 12588 sgd_solver.cpp:106] Iteration 172500, lr = 0.003
I0522 13:26:08.116500 12588 solver.cpp:237] Iteration 173000, loss = 1.33865
I0522 13:26:08.116545 12588 solver.cpp:253]     Train net output #0: loss = 1.33865 (* 1 = 1.33865 loss)
I0522 13:26:08.116559 12588 sgd_solver.cpp:106] Iteration 173000, lr = 0.003
I0522 13:26:39.543836 12588 solver.cpp:237] Iteration 173500, loss = 1.05497
I0522 13:26:39.544026 12588 solver.cpp:253]     Train net output #0: loss = 1.05497 (* 1 = 1.05497 loss)
I0522 13:26:39.544042 12588 sgd_solver.cpp:106] Iteration 173500, lr = 0.003
I0522 13:26:50.047240 12588 solver.cpp:237] Iteration 174000, loss = 0.930501
I0522 13:26:50.047289 12588 solver.cpp:253]     Train net output #0: loss = 0.930503 (* 1 = 0.930503 loss)
I0522 13:26:50.047303 12588 sgd_solver.cpp:106] Iteration 174000, lr = 0.003
I0522 13:27:00.565029 12588 solver.cpp:237] Iteration 174500, loss = 1.25805
I0522 13:27:00.565065 12588 solver.cpp:253]     Train net output #0: loss = 1.25805 (* 1 = 1.25805 loss)
I0522 13:27:00.565081 12588 sgd_solver.cpp:106] Iteration 174500, lr = 0.003
I0522 13:27:11.066192 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_175000.caffemodel
I0522 13:27:11.120764 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_175000.solverstate
I0522 13:27:11.154639 12588 solver.cpp:237] Iteration 175000, loss = 1.33534
I0522 13:27:11.154687 12588 solver.cpp:253]     Train net output #0: loss = 1.33535 (* 1 = 1.33535 loss)
I0522 13:27:11.154703 12588 sgd_solver.cpp:106] Iteration 175000, lr = 0.003
I0522 13:27:21.689441 12588 solver.cpp:237] Iteration 175500, loss = 1.12656
I0522 13:27:21.689486 12588 solver.cpp:253]     Train net output #0: loss = 1.12657 (* 1 = 1.12657 loss)
I0522 13:27:21.689502 12588 sgd_solver.cpp:106] Iteration 175500, lr = 0.003
I0522 13:27:32.212564 12588 solver.cpp:237] Iteration 176000, loss = 1.34765
I0522 13:27:32.212600 12588 solver.cpp:253]     Train net output #0: loss = 1.34766 (* 1 = 1.34766 loss)
I0522 13:27:32.212616 12588 sgd_solver.cpp:106] Iteration 176000, lr = 0.003
I0522 13:27:42.735791 12588 solver.cpp:237] Iteration 176500, loss = 0.987097
I0522 13:27:42.735991 12588 solver.cpp:253]     Train net output #0: loss = 0.987099 (* 1 = 0.987099 loss)
I0522 13:27:42.736006 12588 sgd_solver.cpp:106] Iteration 176500, lr = 0.003
I0522 13:28:14.151538 12588 solver.cpp:237] Iteration 177000, loss = 0.903589
I0522 13:28:14.151731 12588 solver.cpp:253]     Train net output #0: loss = 0.90359 (* 1 = 0.90359 loss)
I0522 13:28:14.151747 12588 sgd_solver.cpp:106] Iteration 177000, lr = 0.003
I0522 13:28:24.661234 12588 solver.cpp:237] Iteration 177500, loss = 1.14814
I0522 13:28:24.661269 12588 solver.cpp:253]     Train net output #0: loss = 1.14814 (* 1 = 1.14814 loss)
I0522 13:28:24.661285 12588 sgd_solver.cpp:106] Iteration 177500, lr = 0.003
I0522 13:28:35.180404 12588 solver.cpp:237] Iteration 178000, loss = 1.34105
I0522 13:28:35.180452 12588 solver.cpp:253]     Train net output #0: loss = 1.34105 (* 1 = 1.34105 loss)
I0522 13:28:35.180469 12588 sgd_solver.cpp:106] Iteration 178000, lr = 0.003
I0522 13:28:45.694715 12588 solver.cpp:237] Iteration 178500, loss = 1.1747
I0522 13:28:45.694900 12588 solver.cpp:253]     Train net output #0: loss = 1.1747 (* 1 = 1.1747 loss)
I0522 13:28:45.694914 12588 sgd_solver.cpp:106] Iteration 178500, lr = 0.003
I0522 13:28:56.217972 12588 solver.cpp:237] Iteration 179000, loss = 0.832663
I0522 13:28:56.218022 12588 solver.cpp:253]     Train net output #0: loss = 0.832665 (* 1 = 0.832665 loss)
I0522 13:28:56.218035 12588 sgd_solver.cpp:106] Iteration 179000, lr = 0.003
I0522 13:29:06.734697 12588 solver.cpp:237] Iteration 179500, loss = 0.918783
I0522 13:29:06.734735 12588 solver.cpp:253]     Train net output #0: loss = 0.918785 (* 1 = 0.918785 loss)
I0522 13:29:06.734750 12588 sgd_solver.cpp:106] Iteration 179500, lr = 0.003
I0522 13:29:17.256856 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_180000.caffemodel
I0522 13:29:17.312809 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_180000.solverstate
I0522 13:29:17.340329 12588 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 13:30:27.785075 12588 solver.cpp:409]     Test net output #0: accuracy = 0.899679
I0522 13:30:27.785264 12588 solver.cpp:409]     Test net output #1: loss = 0.324475 (* 1 = 0.324475 loss)
I0522 13:30:48.664961 12588 solver.cpp:237] Iteration 180000, loss = 1.14398
I0522 13:30:48.665014 12588 solver.cpp:253]     Train net output #0: loss = 1.14398 (* 1 = 1.14398 loss)
I0522 13:30:48.665029 12588 sgd_solver.cpp:106] Iteration 180000, lr = 0.003
I0522 13:30:59.211683 12588 solver.cpp:237] Iteration 180500, loss = 1.07019
I0522 13:30:59.211869 12588 solver.cpp:253]     Train net output #0: loss = 1.07019 (* 1 = 1.07019 loss)
I0522 13:30:59.211884 12588 sgd_solver.cpp:106] Iteration 180500, lr = 0.003
I0522 13:31:09.764367 12588 solver.cpp:237] Iteration 181000, loss = 1.11289
I0522 13:31:09.764405 12588 solver.cpp:253]     Train net output #0: loss = 1.11289 (* 1 = 1.11289 loss)
I0522 13:31:09.764420 12588 sgd_solver.cpp:106] Iteration 181000, lr = 0.003
I0522 13:31:20.315654 12588 solver.cpp:237] Iteration 181500, loss = 1.30452
I0522 13:31:20.315690 12588 solver.cpp:253]     Train net output #0: loss = 1.30452 (* 1 = 1.30452 loss)
I0522 13:31:20.315706 12588 sgd_solver.cpp:106] Iteration 181500, lr = 0.003
I0522 13:31:30.860015 12588 solver.cpp:237] Iteration 182000, loss = 1.29352
I0522 13:31:30.860208 12588 solver.cpp:253]     Train net output #0: loss = 1.29352 (* 1 = 1.29352 loss)
I0522 13:31:30.860224 12588 sgd_solver.cpp:106] Iteration 182000, lr = 0.003
I0522 13:31:41.411335 12588 solver.cpp:237] Iteration 182500, loss = 1.1781
I0522 13:31:41.411371 12588 solver.cpp:253]     Train net output #0: loss = 1.1781 (* 1 = 1.1781 loss)
I0522 13:31:41.411388 12588 sgd_solver.cpp:106] Iteration 182500, lr = 0.003
I0522 13:31:51.962450 12588 solver.cpp:237] Iteration 183000, loss = 1.02887
I0522 13:31:51.962496 12588 solver.cpp:253]     Train net output #0: loss = 1.02887 (* 1 = 1.02887 loss)
I0522 13:31:51.962512 12588 sgd_solver.cpp:106] Iteration 183000, lr = 0.003
I0522 13:32:23.374320 12588 solver.cpp:237] Iteration 183500, loss = 1.07864
I0522 13:32:23.374513 12588 solver.cpp:253]     Train net output #0: loss = 1.07864 (* 1 = 1.07864 loss)
I0522 13:32:23.374529 12588 sgd_solver.cpp:106] Iteration 183500, lr = 0.003
I0522 13:32:33.937417 12588 solver.cpp:237] Iteration 184000, loss = 0.752425
I0522 13:32:33.937453 12588 solver.cpp:253]     Train net output #0: loss = 0.752427 (* 1 = 0.752427 loss)
I0522 13:32:33.937469 12588 sgd_solver.cpp:106] Iteration 184000, lr = 0.003
I0522 13:32:44.492936 12588 solver.cpp:237] Iteration 184500, loss = 1.5239
I0522 13:32:44.492985 12588 solver.cpp:253]     Train net output #0: loss = 1.5239 (* 1 = 1.5239 loss)
I0522 13:32:44.493000 12588 sgd_solver.cpp:106] Iteration 184500, lr = 0.003
I0522 13:32:54.996220 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_185000.caffemodel
I0522 13:32:55.049340 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_185000.solverstate
I0522 13:32:55.082118 12588 solver.cpp:237] Iteration 185000, loss = 1.20741
I0522 13:32:55.082165 12588 solver.cpp:253]     Train net output #0: loss = 1.20741 (* 1 = 1.20741 loss)
I0522 13:32:55.082178 12588 sgd_solver.cpp:106] Iteration 185000, lr = 0.003
I0522 13:33:05.614553 12588 solver.cpp:237] Iteration 185500, loss = 1.09092
I0522 13:33:05.614600 12588 solver.cpp:253]     Train net output #0: loss = 1.09092 (* 1 = 1.09092 loss)
I0522 13:33:05.614614 12588 sgd_solver.cpp:106] Iteration 185500, lr = 0.003
I0522 13:33:16.153331 12588 solver.cpp:237] Iteration 186000, loss = 1.24371
I0522 13:33:16.153367 12588 solver.cpp:253]     Train net output #0: loss = 1.24371 (* 1 = 1.24371 loss)
I0522 13:33:16.153383 12588 sgd_solver.cpp:106] Iteration 186000, lr = 0.003
I0522 13:33:26.694243 12588 solver.cpp:237] Iteration 186500, loss = 1.23224
I0522 13:33:26.694421 12588 solver.cpp:253]     Train net output #0: loss = 1.23224 (* 1 = 1.23224 loss)
I0522 13:33:26.694435 12588 sgd_solver.cpp:106] Iteration 186500, lr = 0.003
I0522 13:33:58.113024 12588 solver.cpp:237] Iteration 187000, loss = 1.1497
I0522 13:33:58.113214 12588 solver.cpp:253]     Train net output #0: loss = 1.1497 (* 1 = 1.1497 loss)
I0522 13:33:58.113227 12588 sgd_solver.cpp:106] Iteration 187000, lr = 0.003
I0522 13:34:08.652060 12588 solver.cpp:237] Iteration 187500, loss = 0.89686
I0522 13:34:08.652096 12588 solver.cpp:253]     Train net output #0: loss = 0.896861 (* 1 = 0.896861 loss)
I0522 13:34:08.652112 12588 sgd_solver.cpp:106] Iteration 187500, lr = 0.003
I0522 13:34:19.198164 12588 solver.cpp:237] Iteration 188000, loss = 1.1508
I0522 13:34:19.198212 12588 solver.cpp:253]     Train net output #0: loss = 1.1508 (* 1 = 1.1508 loss)
I0522 13:34:19.198228 12588 sgd_solver.cpp:106] Iteration 188000, lr = 0.003
I0522 13:34:29.739403 12588 solver.cpp:237] Iteration 188500, loss = 1.11247
I0522 13:34:29.739588 12588 solver.cpp:253]     Train net output #0: loss = 1.11247 (* 1 = 1.11247 loss)
I0522 13:34:29.739601 12588 sgd_solver.cpp:106] Iteration 188500, lr = 0.003
I0522 13:34:40.274994 12588 solver.cpp:237] Iteration 189000, loss = 1.15668
I0522 13:34:40.275030 12588 solver.cpp:253]     Train net output #0: loss = 1.15668 (* 1 = 1.15668 loss)
I0522 13:34:40.275046 12588 sgd_solver.cpp:106] Iteration 189000, lr = 0.003
I0522 13:34:50.814262 12588 solver.cpp:237] Iteration 189500, loss = 1.37912
I0522 13:34:50.814308 12588 solver.cpp:253]     Train net output #0: loss = 1.37912 (* 1 = 1.37912 loss)
I0522 13:34:50.814323 12588 sgd_solver.cpp:106] Iteration 189500, lr = 0.003
I0522 13:35:01.334000 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_190000.caffemodel
I0522 13:35:01.386680 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_190000.solverstate
I0522 13:35:01.412374 12588 solver.cpp:341] Iteration 190000, Testing net (#0)
I0522 13:35:50.706390 12588 solver.cpp:409]     Test net output #0: accuracy = 0.901985
I0522 13:35:50.706583 12588 solver.cpp:409]     Test net output #1: loss = 0.305399 (* 1 = 0.305399 loss)
I0522 13:36:11.601598 12588 solver.cpp:237] Iteration 190000, loss = 1.18615
I0522 13:36:11.601650 12588 solver.cpp:253]     Train net output #0: loss = 1.18615 (* 1 = 1.18615 loss)
I0522 13:36:11.601667 12588 sgd_solver.cpp:106] Iteration 190000, lr = 0.003
I0522 13:36:22.183701 12588 solver.cpp:237] Iteration 190500, loss = 1.17964
I0522 13:36:22.183876 12588 solver.cpp:253]     Train net output #0: loss = 1.17964 (* 1 = 1.17964 loss)
I0522 13:36:22.183890 12588 sgd_solver.cpp:106] Iteration 190500, lr = 0.003
I0522 13:36:32.757364 12588 solver.cpp:237] Iteration 191000, loss = 0.946922
I0522 13:36:32.757410 12588 solver.cpp:253]     Train net output #0: loss = 0.946923 (* 1 = 0.946923 loss)
I0522 13:36:32.757424 12588 sgd_solver.cpp:106] Iteration 191000, lr = 0.003
I0522 13:36:43.293483 12588 solver.cpp:237] Iteration 191500, loss = 0.881582
I0522 13:36:43.293520 12588 solver.cpp:253]     Train net output #0: loss = 0.881583 (* 1 = 0.881583 loss)
I0522 13:36:43.293535 12588 sgd_solver.cpp:106] Iteration 191500, lr = 0.003
I0522 13:36:53.806298 12588 solver.cpp:237] Iteration 192000, loss = 1.23099
I0522 13:36:53.806481 12588 solver.cpp:253]     Train net output #0: loss = 1.23099 (* 1 = 1.23099 loss)
I0522 13:36:53.806496 12588 sgd_solver.cpp:106] Iteration 192000, lr = 0.003
I0522 13:37:04.311278 12588 solver.cpp:237] Iteration 192500, loss = 1.10105
I0522 13:37:04.311314 12588 solver.cpp:253]     Train net output #0: loss = 1.10105 (* 1 = 1.10105 loss)
I0522 13:37:04.311331 12588 sgd_solver.cpp:106] Iteration 192500, lr = 0.003
I0522 13:37:14.827168 12588 solver.cpp:237] Iteration 193000, loss = 1.12839
I0522 13:37:14.827213 12588 solver.cpp:253]     Train net output #0: loss = 1.12839 (* 1 = 1.12839 loss)
I0522 13:37:14.827229 12588 sgd_solver.cpp:106] Iteration 193000, lr = 0.003
I0522 13:37:46.224069 12588 solver.cpp:237] Iteration 193500, loss = 1.3291
I0522 13:37:46.224266 12588 solver.cpp:253]     Train net output #0: loss = 1.3291 (* 1 = 1.3291 loss)
I0522 13:37:46.224280 12588 sgd_solver.cpp:106] Iteration 193500, lr = 0.003
I0522 13:37:56.738554 12588 solver.cpp:237] Iteration 194000, loss = 1.09663
I0522 13:37:56.738590 12588 solver.cpp:253]     Train net output #0: loss = 1.09663 (* 1 = 1.09663 loss)
I0522 13:37:56.738605 12588 sgd_solver.cpp:106] Iteration 194000, lr = 0.003
I0522 13:38:07.256335 12588 solver.cpp:237] Iteration 194500, loss = 1.19389
I0522 13:38:07.256379 12588 solver.cpp:253]     Train net output #0: loss = 1.1939 (* 1 = 1.1939 loss)
I0522 13:38:07.256394 12588 sgd_solver.cpp:106] Iteration 194500, lr = 0.003
I0522 13:38:17.779551 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_195000.caffemodel
I0522 13:38:17.832206 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_195000.solverstate
I0522 13:38:17.863584 12588 solver.cpp:237] Iteration 195000, loss = 1.43909
I0522 13:38:17.863627 12588 solver.cpp:253]     Train net output #0: loss = 1.43909 (* 1 = 1.43909 loss)
I0522 13:38:17.863641 12588 sgd_solver.cpp:106] Iteration 195000, lr = 0.003
I0522 13:38:28.399687 12588 solver.cpp:237] Iteration 195500, loss = 1.15368
I0522 13:38:28.399722 12588 solver.cpp:253]     Train net output #0: loss = 1.15368 (* 1 = 1.15368 loss)
I0522 13:38:28.399737 12588 sgd_solver.cpp:106] Iteration 195500, lr = 0.003
I0522 13:38:38.934638 12588 solver.cpp:237] Iteration 196000, loss = 1.33104
I0522 13:38:38.934676 12588 solver.cpp:253]     Train net output #0: loss = 1.33104 (* 1 = 1.33104 loss)
I0522 13:38:38.934694 12588 sgd_solver.cpp:106] Iteration 196000, lr = 0.003
I0522 13:38:49.477648 12588 solver.cpp:237] Iteration 196500, loss = 1.14284
I0522 13:38:49.477828 12588 solver.cpp:253]     Train net output #0: loss = 1.14284 (* 1 = 1.14284 loss)
I0522 13:38:49.477841 12588 sgd_solver.cpp:106] Iteration 196500, lr = 0.003
I0522 13:39:20.930110 12588 solver.cpp:237] Iteration 197000, loss = 1.04436
I0522 13:39:20.930304 12588 solver.cpp:253]     Train net output #0: loss = 1.04436 (* 1 = 1.04436 loss)
I0522 13:39:20.930318 12588 sgd_solver.cpp:106] Iteration 197000, lr = 0.003
I0522 13:39:31.474611 12588 solver.cpp:237] Iteration 197500, loss = 1.13323
I0522 13:39:31.474647 12588 solver.cpp:253]     Train net output #0: loss = 1.13323 (* 1 = 1.13323 loss)
I0522 13:39:31.474663 12588 sgd_solver.cpp:106] Iteration 197500, lr = 0.003
I0522 13:39:42.005298 12588 solver.cpp:237] Iteration 198000, loss = 1.53009
I0522 13:39:42.005334 12588 solver.cpp:253]     Train net output #0: loss = 1.53009 (* 1 = 1.53009 loss)
I0522 13:39:42.005352 12588 sgd_solver.cpp:106] Iteration 198000, lr = 0.003
I0522 13:39:52.539755 12588 solver.cpp:237] Iteration 198500, loss = 1.21122
I0522 13:39:52.539939 12588 solver.cpp:253]     Train net output #0: loss = 1.21122 (* 1 = 1.21122 loss)
I0522 13:39:52.539954 12588 sgd_solver.cpp:106] Iteration 198500, lr = 0.003
I0522 13:40:03.074339 12588 solver.cpp:237] Iteration 199000, loss = 1.48824
I0522 13:40:03.074376 12588 solver.cpp:253]     Train net output #0: loss = 1.48824 (* 1 = 1.48824 loss)
I0522 13:40:03.074393 12588 sgd_solver.cpp:106] Iteration 199000, lr = 0.003
I0522 13:40:13.611866 12588 solver.cpp:237] Iteration 199500, loss = 1.3881
I0522 13:40:13.611919 12588 solver.cpp:253]     Train net output #0: loss = 1.3881 (* 1 = 1.3881 loss)
I0522 13:40:13.611934 12588 sgd_solver.cpp:106] Iteration 199500, lr = 0.003
I0522 13:40:24.129022 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_200000.caffemodel
I0522 13:40:24.185091 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_200000.solverstate
I0522 13:40:24.213440 12588 solver.cpp:341] Iteration 200000, Testing net (#0)
I0522 13:41:34.747536 12588 solver.cpp:409]     Test net output #0: accuracy = 0.900865
I0522 13:41:34.747728 12588 solver.cpp:409]     Test net output #1: loss = 0.326375 (* 1 = 0.326375 loss)
I0522 13:41:55.611156 12588 solver.cpp:237] Iteration 200000, loss = 1.51063
I0522 13:41:55.611208 12588 solver.cpp:253]     Train net output #0: loss = 1.51063 (* 1 = 1.51063 loss)
I0522 13:41:55.611223 12588 sgd_solver.cpp:106] Iteration 200000, lr = 0.003
I0522 13:42:06.120311 12588 solver.cpp:237] Iteration 200500, loss = 0.769096
I0522 13:42:06.120501 12588 solver.cpp:253]     Train net output #0: loss = 0.769097 (* 1 = 0.769097 loss)
I0522 13:42:06.120515 12588 sgd_solver.cpp:106] Iteration 200500, lr = 0.003
I0522 13:42:16.640792 12588 solver.cpp:237] Iteration 201000, loss = 0.792238
I0522 13:42:16.640836 12588 solver.cpp:253]     Train net output #0: loss = 0.792239 (* 1 = 0.792239 loss)
I0522 13:42:16.640851 12588 sgd_solver.cpp:106] Iteration 201000, lr = 0.003
I0522 13:42:27.140348 12588 solver.cpp:237] Iteration 201500, loss = 1.3014
I0522 13:42:27.140383 12588 solver.cpp:253]     Train net output #0: loss = 1.3014 (* 1 = 1.3014 loss)
I0522 13:42:27.140400 12588 sgd_solver.cpp:106] Iteration 201500, lr = 0.003
I0522 13:42:37.637486 12588 solver.cpp:237] Iteration 202000, loss = 0.817535
I0522 13:42:37.637660 12588 solver.cpp:253]     Train net output #0: loss = 0.817537 (* 1 = 0.817537 loss)
I0522 13:42:37.637675 12588 sgd_solver.cpp:106] Iteration 202000, lr = 0.003
I0522 13:42:48.154474 12588 solver.cpp:237] Iteration 202500, loss = 1.2318
I0522 13:42:48.154515 12588 solver.cpp:253]     Train net output #0: loss = 1.2318 (* 1 = 1.2318 loss)
I0522 13:42:48.154531 12588 sgd_solver.cpp:106] Iteration 202500, lr = 0.003
I0522 13:42:58.675408 12588 solver.cpp:237] Iteration 203000, loss = 1.29092
I0522 13:42:58.675443 12588 solver.cpp:253]     Train net output #0: loss = 1.29092 (* 1 = 1.29092 loss)
I0522 13:42:58.675460 12588 sgd_solver.cpp:106] Iteration 203000, lr = 0.003
I0522 13:43:30.091384 12588 solver.cpp:237] Iteration 203500, loss = 1.14911
I0522 13:43:30.091578 12588 solver.cpp:253]     Train net output #0: loss = 1.14911 (* 1 = 1.14911 loss)
I0522 13:43:30.091593 12588 sgd_solver.cpp:106] Iteration 203500, lr = 0.003
I0522 13:43:40.598359 12588 solver.cpp:237] Iteration 204000, loss = 1.06439
I0522 13:43:40.598394 12588 solver.cpp:253]     Train net output #0: loss = 1.06439 (* 1 = 1.06439 loss)
I0522 13:43:40.598408 12588 sgd_solver.cpp:106] Iteration 204000, lr = 0.003
I0522 13:43:51.112370 12588 solver.cpp:237] Iteration 204500, loss = 1.50483
I0522 13:43:51.112406 12588 solver.cpp:253]     Train net output #0: loss = 1.50483 (* 1 = 1.50483 loss)
I0522 13:43:51.112422 12588 sgd_solver.cpp:106] Iteration 204500, lr = 0.003
I0522 13:44:01.600258 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_205000.caffemodel
I0522 13:44:01.652427 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_205000.solverstate
I0522 13:44:01.684428 12588 solver.cpp:237] Iteration 205000, loss = 1.28002
I0522 13:44:01.684474 12588 solver.cpp:253]     Train net output #0: loss = 1.28002 (* 1 = 1.28002 loss)
I0522 13:44:01.684490 12588 sgd_solver.cpp:106] Iteration 205000, lr = 0.003
I0522 13:44:12.188029 12588 solver.cpp:237] Iteration 205500, loss = 1.26811
I0522 13:44:12.188065 12588 solver.cpp:253]     Train net output #0: loss = 1.26812 (* 1 = 1.26812 loss)
I0522 13:44:12.188079 12588 sgd_solver.cpp:106] Iteration 205500, lr = 0.003
I0522 13:44:22.702906 12588 solver.cpp:237] Iteration 206000, loss = 0.935681
I0522 13:44:22.702953 12588 solver.cpp:253]     Train net output #0: loss = 0.935682 (* 1 = 0.935682 loss)
I0522 13:44:22.702968 12588 sgd_solver.cpp:106] Iteration 206000, lr = 0.003
I0522 13:44:33.227578 12588 solver.cpp:237] Iteration 206500, loss = 1.08312
I0522 13:44:33.227757 12588 solver.cpp:253]     Train net output #0: loss = 1.08312 (* 1 = 1.08312 loss)
I0522 13:44:33.227771 12588 sgd_solver.cpp:106] Iteration 206500, lr = 0.003
I0522 13:45:04.610167 12588 solver.cpp:237] Iteration 207000, loss = 1.04003
I0522 13:45:04.610373 12588 solver.cpp:253]     Train net output #0: loss = 1.04003 (* 1 = 1.04003 loss)
I0522 13:45:04.610388 12588 sgd_solver.cpp:106] Iteration 207000, lr = 0.003
I0522 13:45:15.122272 12588 solver.cpp:237] Iteration 207500, loss = 0.850937
I0522 13:45:15.122323 12588 solver.cpp:253]     Train net output #0: loss = 0.850938 (* 1 = 0.850938 loss)
I0522 13:45:15.122337 12588 sgd_solver.cpp:106] Iteration 207500, lr = 0.003
I0522 13:45:25.632836 12588 solver.cpp:237] Iteration 208000, loss = 1.02747
I0522 13:45:25.632872 12588 solver.cpp:253]     Train net output #0: loss = 1.02747 (* 1 = 1.02747 loss)
I0522 13:45:25.632889 12588 sgd_solver.cpp:106] Iteration 208000, lr = 0.003
I0522 13:45:36.137642 12588 solver.cpp:237] Iteration 208500, loss = 1.17399
I0522 13:45:36.137840 12588 solver.cpp:253]     Train net output #0: loss = 1.17399 (* 1 = 1.17399 loss)
I0522 13:45:36.137856 12588 sgd_solver.cpp:106] Iteration 208500, lr = 0.003
I0522 13:45:46.651090 12588 solver.cpp:237] Iteration 209000, loss = 1.47892
I0522 13:45:46.651125 12588 solver.cpp:253]     Train net output #0: loss = 1.47892 (* 1 = 1.47892 loss)
I0522 13:45:46.651142 12588 sgd_solver.cpp:106] Iteration 209000, lr = 0.003
I0522 13:45:57.157714 12588 solver.cpp:237] Iteration 209500, loss = 1.28472
I0522 13:45:57.157750 12588 solver.cpp:253]     Train net output #0: loss = 1.28472 (* 1 = 1.28472 loss)
I0522 13:45:57.157766 12588 sgd_solver.cpp:106] Iteration 209500, lr = 0.003
I0522 13:46:07.658658 12588 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_210000.caffemodel
I0522 13:46:07.711477 12588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0030_2016-05-20T15.48.59.226161_iter_210000.solverstate
I0522 13:46:07.736790 12588 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 13:46:57.307989 12588 solver.cpp:409]     Test net output #0: accuracy = 0.900817
I0522 13:46:57.308182 12588 solver.cpp:409]     Test net output #1: loss = 0.327522 (* 1 = 0.327522 loss)
I0522 13:47:18.169536 12588 solver.cpp:237] Iteration 210000, loss = 0.909321
I0522 13:47:18.169589 12588 solver.cpp:253]     Train net output #0: loss = 0.909322 (* 1 = 0.909322 loss)
I0522 13:47:18.169605 12588 sgd_solver.cpp:106] Iteration 210000, lr = 0.003
I0522 13:47:28.691995 12588 solver.cpp:237] Iteration 210500, loss = 0.850128
I0522 13:47:28.692178 12588 solver.cpp:253]     Train net output #0: loss = 0.850128 (* 1 = 0.850128 loss)
I0522 13:47:28.692193 12588 sgd_solver.cpp:106] Iteration 210500, lr = 0.003
I0522 13:47:39.202965 12588 solver.cpp:237] Iteration 211000, loss = 1.01822
I0522 13:47:39.203013 12588 solver.cpp:253]     Train net output #0: loss = 1.01822 (* 1 = 1.01822 loss)
I0522 13:47:39.203029 12588 sgd_solver.cpp:106] Iteration 211000, lr = 0.003
I0522 13:47:49.695488 12588 solver.cpp:237] Iteration 211500, loss = 1.15422
I0522 13:47:49.695524 12588 solver.cpp:253]     Train net output #0: loss = 1.15422 (* 1 = 1.15422 loss)
I0522 13:47:49.695541 12588 sgd_solver.cpp:106] Iteration 211500, lr = 0.003
I0522 13:48:00.216688 12588 solver.cpp:237] Iteration 212000, loss = 1.28881
I0522 13:48:00.216866 12588 solver.cpp:253]     Train net output #0: loss = 1.28881 (* 1 = 1.28881 loss)
I0522 13:48:00.216881 12588 sgd_solver.cpp:106] Iteration 212000, lr = 0.003
I0522 13:48:10.735757 12588 solver.cpp:237] Iteration 212500, loss = 1.27863
I0522 13:48:10.735805 12588 solver.cpp:253]     Train net output #0: loss = 1.27863 (* 1 = 1.27863 loss)
I0522 13:48:10.735821 12588 sgd_solver.cpp:106] Iteration 212500, lr = 0.003
I0522 13:48:21.249727 12588 solver.cpp:237] Iteration 213000, loss = 1.03899
I0522 13:48:21.249763 12588 solver.cpp:253]     Train net output #0: loss = 1.03899 (* 1 = 1.03899 loss)
I0522 13:48:21.249778 12588 sgd_solver.cpp:106] Iteration 213000, lr = 0.003
aprun: Apid 11247771: Caught signal Terminated, sending to application
*** Aborted at 1463939313 (unix time) try "date -d @1463939313" if you are using GNU date ***
aprun: Apid 11247771: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9b834 (unknown)
aprun: Apid 11247771: Caught signal Terminated, sending to application
*** SIGTERM (@0x3129) received by PID 12588 (TID 0x2aaac746f900) from PID 12585; stack trace: ***
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaac5e9b834 (unknown)
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
=>> PBS: job killed: walltime 7202 exceeded limit 7200
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11247771: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11247771: Caught signal Terminated, sending to application
aprun: Apid 11247771: Caught signal Terminated, sending to application
aprun: Apid 11247771: Caught signal Terminated, sending to application
aprun: Apid 11247771: Caught signal Terminated, sending to application
