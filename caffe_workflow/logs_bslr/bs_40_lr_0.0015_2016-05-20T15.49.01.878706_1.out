2805531
I0520 16:13:06.136948 25100 caffe.cpp:184] Using GPUs 0
I0520 16:13:06.562151 25100 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0015
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706.prototxt"
I0520 16:13:06.563684 25100 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706.prototxt
I0520 16:13:06.567344 25100 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0520 16:13:06.567404 25100 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0520 16:13:06.567760 25100 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0520 16:13:06.567939 25100 layer_factory.hpp:77] Creating layer data_hdf5
I0520 16:13:06.567963 25100 net.cpp:106] Creating Layer data_hdf5
I0520 16:13:06.567977 25100 net.cpp:411] data_hdf5 -> data
I0520 16:13:06.568011 25100 net.cpp:411] data_hdf5 -> label
I0520 16:13:06.568044 25100 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0520 16:13:06.569402 25100 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0520 16:13:06.571796 25100 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0520 16:13:28.142680 25100 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0520 16:13:28.147711 25100 net.cpp:150] Setting up data_hdf5
I0520 16:13:28.147750 25100 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0520 16:13:28.147765 25100 net.cpp:157] Top shape: 40 (40)
I0520 16:13:28.147778 25100 net.cpp:165] Memory required for data: 1016160
I0520 16:13:28.147792 25100 layer_factory.hpp:77] Creating layer conv1
I0520 16:13:28.147826 25100 net.cpp:106] Creating Layer conv1
I0520 16:13:28.147837 25100 net.cpp:454] conv1 <- data
I0520 16:13:28.147860 25100 net.cpp:411] conv1 -> conv1
I0520 16:13:29.268195 25100 net.cpp:150] Setting up conv1
I0520 16:13:29.268241 25100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0520 16:13:29.268252 25100 net.cpp:165] Memory required for data: 12075360
I0520 16:13:29.268282 25100 layer_factory.hpp:77] Creating layer relu1
I0520 16:13:29.268303 25100 net.cpp:106] Creating Layer relu1
I0520 16:13:29.268314 25100 net.cpp:454] relu1 <- conv1
I0520 16:13:29.268328 25100 net.cpp:397] relu1 -> conv1 (in-place)
I0520 16:13:29.268846 25100 net.cpp:150] Setting up relu1
I0520 16:13:29.268862 25100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0520 16:13:29.268872 25100 net.cpp:165] Memory required for data: 23134560
I0520 16:13:29.268883 25100 layer_factory.hpp:77] Creating layer pool1
I0520 16:13:29.268899 25100 net.cpp:106] Creating Layer pool1
I0520 16:13:29.268909 25100 net.cpp:454] pool1 <- conv1
I0520 16:13:29.268923 25100 net.cpp:411] pool1 -> pool1
I0520 16:13:29.269002 25100 net.cpp:150] Setting up pool1
I0520 16:13:29.269016 25100 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0520 16:13:29.269026 25100 net.cpp:165] Memory required for data: 28664160
I0520 16:13:29.269037 25100 layer_factory.hpp:77] Creating layer conv2
I0520 16:13:29.269059 25100 net.cpp:106] Creating Layer conv2
I0520 16:13:29.269069 25100 net.cpp:454] conv2 <- pool1
I0520 16:13:29.269083 25100 net.cpp:411] conv2 -> conv2
I0520 16:13:29.271760 25100 net.cpp:150] Setting up conv2
I0520 16:13:29.271787 25100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0520 16:13:29.271798 25100 net.cpp:165] Memory required for data: 36612960
I0520 16:13:29.271817 25100 layer_factory.hpp:77] Creating layer relu2
I0520 16:13:29.271831 25100 net.cpp:106] Creating Layer relu2
I0520 16:13:29.271842 25100 net.cpp:454] relu2 <- conv2
I0520 16:13:29.271854 25100 net.cpp:397] relu2 -> conv2 (in-place)
I0520 16:13:29.272183 25100 net.cpp:150] Setting up relu2
I0520 16:13:29.272197 25100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0520 16:13:29.272208 25100 net.cpp:165] Memory required for data: 44561760
I0520 16:13:29.272218 25100 layer_factory.hpp:77] Creating layer pool2
I0520 16:13:29.272230 25100 net.cpp:106] Creating Layer pool2
I0520 16:13:29.272240 25100 net.cpp:454] pool2 <- conv2
I0520 16:13:29.272253 25100 net.cpp:411] pool2 -> pool2
I0520 16:13:29.272333 25100 net.cpp:150] Setting up pool2
I0520 16:13:29.272346 25100 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0520 16:13:29.272356 25100 net.cpp:165] Memory required for data: 48536160
I0520 16:13:29.272364 25100 layer_factory.hpp:77] Creating layer conv3
I0520 16:13:29.272382 25100 net.cpp:106] Creating Layer conv3
I0520 16:13:29.272393 25100 net.cpp:454] conv3 <- pool2
I0520 16:13:29.272406 25100 net.cpp:411] conv3 -> conv3
I0520 16:13:29.274335 25100 net.cpp:150] Setting up conv3
I0520 16:13:29.274358 25100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0520 16:13:29.274370 25100 net.cpp:165] Memory required for data: 52872800
I0520 16:13:29.274389 25100 layer_factory.hpp:77] Creating layer relu3
I0520 16:13:29.274405 25100 net.cpp:106] Creating Layer relu3
I0520 16:13:29.274415 25100 net.cpp:454] relu3 <- conv3
I0520 16:13:29.274426 25100 net.cpp:397] relu3 -> conv3 (in-place)
I0520 16:13:29.274894 25100 net.cpp:150] Setting up relu3
I0520 16:13:29.274911 25100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0520 16:13:29.274921 25100 net.cpp:165] Memory required for data: 57209440
I0520 16:13:29.274932 25100 layer_factory.hpp:77] Creating layer pool3
I0520 16:13:29.274945 25100 net.cpp:106] Creating Layer pool3
I0520 16:13:29.274955 25100 net.cpp:454] pool3 <- conv3
I0520 16:13:29.274967 25100 net.cpp:411] pool3 -> pool3
I0520 16:13:29.275034 25100 net.cpp:150] Setting up pool3
I0520 16:13:29.275048 25100 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0520 16:13:29.275058 25100 net.cpp:165] Memory required for data: 59377760
I0520 16:13:29.275065 25100 layer_factory.hpp:77] Creating layer conv4
I0520 16:13:29.275082 25100 net.cpp:106] Creating Layer conv4
I0520 16:13:29.275092 25100 net.cpp:454] conv4 <- pool3
I0520 16:13:29.275106 25100 net.cpp:411] conv4 -> conv4
I0520 16:13:29.277854 25100 net.cpp:150] Setting up conv4
I0520 16:13:29.277878 25100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0520 16:13:29.277887 25100 net.cpp:165] Memory required for data: 60829280
I0520 16:13:29.277904 25100 layer_factory.hpp:77] Creating layer relu4
I0520 16:13:29.277917 25100 net.cpp:106] Creating Layer relu4
I0520 16:13:29.277927 25100 net.cpp:454] relu4 <- conv4
I0520 16:13:29.277941 25100 net.cpp:397] relu4 -> conv4 (in-place)
I0520 16:13:29.278412 25100 net.cpp:150] Setting up relu4
I0520 16:13:29.278429 25100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0520 16:13:29.278439 25100 net.cpp:165] Memory required for data: 62280800
I0520 16:13:29.278450 25100 layer_factory.hpp:77] Creating layer pool4
I0520 16:13:29.278462 25100 net.cpp:106] Creating Layer pool4
I0520 16:13:29.278471 25100 net.cpp:454] pool4 <- conv4
I0520 16:13:29.278484 25100 net.cpp:411] pool4 -> pool4
I0520 16:13:29.278553 25100 net.cpp:150] Setting up pool4
I0520 16:13:29.278565 25100 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0520 16:13:29.278576 25100 net.cpp:165] Memory required for data: 63006560
I0520 16:13:29.278586 25100 layer_factory.hpp:77] Creating layer ip1
I0520 16:13:29.278604 25100 net.cpp:106] Creating Layer ip1
I0520 16:13:29.278614 25100 net.cpp:454] ip1 <- pool4
I0520 16:13:29.278627 25100 net.cpp:411] ip1 -> ip1
I0520 16:13:29.294056 25100 net.cpp:150] Setting up ip1
I0520 16:13:29.294085 25100 net.cpp:157] Top shape: 40 196 (7840)
I0520 16:13:29.294097 25100 net.cpp:165] Memory required for data: 63037920
I0520 16:13:29.294119 25100 layer_factory.hpp:77] Creating layer relu5
I0520 16:13:29.294134 25100 net.cpp:106] Creating Layer relu5
I0520 16:13:29.294144 25100 net.cpp:454] relu5 <- ip1
I0520 16:13:29.294157 25100 net.cpp:397] relu5 -> ip1 (in-place)
I0520 16:13:29.294499 25100 net.cpp:150] Setting up relu5
I0520 16:13:29.294513 25100 net.cpp:157] Top shape: 40 196 (7840)
I0520 16:13:29.294524 25100 net.cpp:165] Memory required for data: 63069280
I0520 16:13:29.294534 25100 layer_factory.hpp:77] Creating layer drop1
I0520 16:13:29.294556 25100 net.cpp:106] Creating Layer drop1
I0520 16:13:29.294566 25100 net.cpp:454] drop1 <- ip1
I0520 16:13:29.294579 25100 net.cpp:397] drop1 -> ip1 (in-place)
I0520 16:13:29.294637 25100 net.cpp:150] Setting up drop1
I0520 16:13:29.294651 25100 net.cpp:157] Top shape: 40 196 (7840)
I0520 16:13:29.294661 25100 net.cpp:165] Memory required for data: 63100640
I0520 16:13:29.294670 25100 layer_factory.hpp:77] Creating layer ip2
I0520 16:13:29.294688 25100 net.cpp:106] Creating Layer ip2
I0520 16:13:29.294699 25100 net.cpp:454] ip2 <- ip1
I0520 16:13:29.294713 25100 net.cpp:411] ip2 -> ip2
I0520 16:13:29.295176 25100 net.cpp:150] Setting up ip2
I0520 16:13:29.295188 25100 net.cpp:157] Top shape: 40 98 (3920)
I0520 16:13:29.295198 25100 net.cpp:165] Memory required for data: 63116320
I0520 16:13:29.295213 25100 layer_factory.hpp:77] Creating layer relu6
I0520 16:13:29.295227 25100 net.cpp:106] Creating Layer relu6
I0520 16:13:29.295235 25100 net.cpp:454] relu6 <- ip2
I0520 16:13:29.295248 25100 net.cpp:397] relu6 -> ip2 (in-place)
I0520 16:13:29.295769 25100 net.cpp:150] Setting up relu6
I0520 16:13:29.295785 25100 net.cpp:157] Top shape: 40 98 (3920)
I0520 16:13:29.295795 25100 net.cpp:165] Memory required for data: 63132000
I0520 16:13:29.295805 25100 layer_factory.hpp:77] Creating layer drop2
I0520 16:13:29.295819 25100 net.cpp:106] Creating Layer drop2
I0520 16:13:29.295828 25100 net.cpp:454] drop2 <- ip2
I0520 16:13:29.295841 25100 net.cpp:397] drop2 -> ip2 (in-place)
I0520 16:13:29.295883 25100 net.cpp:150] Setting up drop2
I0520 16:13:29.295897 25100 net.cpp:157] Top shape: 40 98 (3920)
I0520 16:13:29.295907 25100 net.cpp:165] Memory required for data: 63147680
I0520 16:13:29.295917 25100 layer_factory.hpp:77] Creating layer ip3
I0520 16:13:29.295931 25100 net.cpp:106] Creating Layer ip3
I0520 16:13:29.295940 25100 net.cpp:454] ip3 <- ip2
I0520 16:13:29.295953 25100 net.cpp:411] ip3 -> ip3
I0520 16:13:29.296165 25100 net.cpp:150] Setting up ip3
I0520 16:13:29.296177 25100 net.cpp:157] Top shape: 40 11 (440)
I0520 16:13:29.296187 25100 net.cpp:165] Memory required for data: 63149440
I0520 16:13:29.296202 25100 layer_factory.hpp:77] Creating layer drop3
I0520 16:13:29.296216 25100 net.cpp:106] Creating Layer drop3
I0520 16:13:29.296224 25100 net.cpp:454] drop3 <- ip3
I0520 16:13:29.296237 25100 net.cpp:397] drop3 -> ip3 (in-place)
I0520 16:13:29.296277 25100 net.cpp:150] Setting up drop3
I0520 16:13:29.296289 25100 net.cpp:157] Top shape: 40 11 (440)
I0520 16:13:29.296299 25100 net.cpp:165] Memory required for data: 63151200
I0520 16:13:29.296309 25100 layer_factory.hpp:77] Creating layer loss
I0520 16:13:29.296329 25100 net.cpp:106] Creating Layer loss
I0520 16:13:29.296339 25100 net.cpp:454] loss <- ip3
I0520 16:13:29.296349 25100 net.cpp:454] loss <- label
I0520 16:13:29.296361 25100 net.cpp:411] loss -> loss
I0520 16:13:29.296378 25100 layer_factory.hpp:77] Creating layer loss
I0520 16:13:29.297019 25100 net.cpp:150] Setting up loss
I0520 16:13:29.297039 25100 net.cpp:157] Top shape: (1)
I0520 16:13:29.297052 25100 net.cpp:160]     with loss weight 1
I0520 16:13:29.297096 25100 net.cpp:165] Memory required for data: 63151204
I0520 16:13:29.297107 25100 net.cpp:226] loss needs backward computation.
I0520 16:13:29.297118 25100 net.cpp:226] drop3 needs backward computation.
I0520 16:13:29.297125 25100 net.cpp:226] ip3 needs backward computation.
I0520 16:13:29.297137 25100 net.cpp:226] drop2 needs backward computation.
I0520 16:13:29.297147 25100 net.cpp:226] relu6 needs backward computation.
I0520 16:13:29.297157 25100 net.cpp:226] ip2 needs backward computation.
I0520 16:13:29.297166 25100 net.cpp:226] drop1 needs backward computation.
I0520 16:13:29.297176 25100 net.cpp:226] relu5 needs backward computation.
I0520 16:13:29.297188 25100 net.cpp:226] ip1 needs backward computation.
I0520 16:13:29.297197 25100 net.cpp:226] pool4 needs backward computation.
I0520 16:13:29.297207 25100 net.cpp:226] relu4 needs backward computation.
I0520 16:13:29.297217 25100 net.cpp:226] conv4 needs backward computation.
I0520 16:13:29.297227 25100 net.cpp:226] pool3 needs backward computation.
I0520 16:13:29.297240 25100 net.cpp:226] relu3 needs backward computation.
I0520 16:13:29.297248 25100 net.cpp:226] conv3 needs backward computation.
I0520 16:13:29.297269 25100 net.cpp:226] pool2 needs backward computation.
I0520 16:13:29.297281 25100 net.cpp:226] relu2 needs backward computation.
I0520 16:13:29.297289 25100 net.cpp:226] conv2 needs backward computation.
I0520 16:13:29.297300 25100 net.cpp:226] pool1 needs backward computation.
I0520 16:13:29.297310 25100 net.cpp:226] relu1 needs backward computation.
I0520 16:13:29.297320 25100 net.cpp:226] conv1 needs backward computation.
I0520 16:13:29.297332 25100 net.cpp:228] data_hdf5 does not need backward computation.
I0520 16:13:29.297341 25100 net.cpp:270] This network produces output loss
I0520 16:13:29.297365 25100 net.cpp:283] Network initialization done.
I0520 16:13:29.298908 25100 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706.prototxt
I0520 16:13:29.298980 25100 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0520 16:13:29.299335 25100 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0520 16:13:29.299523 25100 layer_factory.hpp:77] Creating layer data_hdf5
I0520 16:13:29.299538 25100 net.cpp:106] Creating Layer data_hdf5
I0520 16:13:29.299551 25100 net.cpp:411] data_hdf5 -> data
I0520 16:13:29.299567 25100 net.cpp:411] data_hdf5 -> label
I0520 16:13:29.299583 25100 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0520 16:13:29.300743 25100 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0520 16:13:50.625139 25100 net.cpp:150] Setting up data_hdf5
I0520 16:13:50.625316 25100 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0520 16:13:50.625330 25100 net.cpp:157] Top shape: 40 (40)
I0520 16:13:50.625344 25100 net.cpp:165] Memory required for data: 1016160
I0520 16:13:50.625356 25100 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0520 16:13:50.625385 25100 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0520 16:13:50.625396 25100 net.cpp:454] label_data_hdf5_1_split <- label
I0520 16:13:50.625411 25100 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0520 16:13:50.625432 25100 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0520 16:13:50.625505 25100 net.cpp:150] Setting up label_data_hdf5_1_split
I0520 16:13:50.625519 25100 net.cpp:157] Top shape: 40 (40)
I0520 16:13:50.625531 25100 net.cpp:157] Top shape: 40 (40)
I0520 16:13:50.625538 25100 net.cpp:165] Memory required for data: 1016480
I0520 16:13:50.625548 25100 layer_factory.hpp:77] Creating layer conv1
I0520 16:13:50.625568 25100 net.cpp:106] Creating Layer conv1
I0520 16:13:50.625579 25100 net.cpp:454] conv1 <- data
I0520 16:13:50.625593 25100 net.cpp:411] conv1 -> conv1
I0520 16:13:50.627504 25100 net.cpp:150] Setting up conv1
I0520 16:13:50.627528 25100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0520 16:13:50.627539 25100 net.cpp:165] Memory required for data: 12075680
I0520 16:13:50.627560 25100 layer_factory.hpp:77] Creating layer relu1
I0520 16:13:50.627575 25100 net.cpp:106] Creating Layer relu1
I0520 16:13:50.627585 25100 net.cpp:454] relu1 <- conv1
I0520 16:13:50.627599 25100 net.cpp:397] relu1 -> conv1 (in-place)
I0520 16:13:50.628108 25100 net.cpp:150] Setting up relu1
I0520 16:13:50.628123 25100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0520 16:13:50.628134 25100 net.cpp:165] Memory required for data: 23134880
I0520 16:13:50.628144 25100 layer_factory.hpp:77] Creating layer pool1
I0520 16:13:50.628160 25100 net.cpp:106] Creating Layer pool1
I0520 16:13:50.628170 25100 net.cpp:454] pool1 <- conv1
I0520 16:13:50.628183 25100 net.cpp:411] pool1 -> pool1
I0520 16:13:50.628258 25100 net.cpp:150] Setting up pool1
I0520 16:13:50.628271 25100 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0520 16:13:50.628281 25100 net.cpp:165] Memory required for data: 28664480
I0520 16:13:50.628289 25100 layer_factory.hpp:77] Creating layer conv2
I0520 16:13:50.628307 25100 net.cpp:106] Creating Layer conv2
I0520 16:13:50.628319 25100 net.cpp:454] conv2 <- pool1
I0520 16:13:50.628332 25100 net.cpp:411] conv2 -> conv2
I0520 16:13:50.630231 25100 net.cpp:150] Setting up conv2
I0520 16:13:50.630254 25100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0520 16:13:50.630265 25100 net.cpp:165] Memory required for data: 36613280
I0520 16:13:50.630283 25100 layer_factory.hpp:77] Creating layer relu2
I0520 16:13:50.630296 25100 net.cpp:106] Creating Layer relu2
I0520 16:13:50.630306 25100 net.cpp:454] relu2 <- conv2
I0520 16:13:50.630318 25100 net.cpp:397] relu2 -> conv2 (in-place)
I0520 16:13:50.630648 25100 net.cpp:150] Setting up relu2
I0520 16:13:50.630662 25100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0520 16:13:50.630672 25100 net.cpp:165] Memory required for data: 44562080
I0520 16:13:50.630682 25100 layer_factory.hpp:77] Creating layer pool2
I0520 16:13:50.630697 25100 net.cpp:106] Creating Layer pool2
I0520 16:13:50.630707 25100 net.cpp:454] pool2 <- conv2
I0520 16:13:50.630720 25100 net.cpp:411] pool2 -> pool2
I0520 16:13:50.630792 25100 net.cpp:150] Setting up pool2
I0520 16:13:50.630805 25100 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0520 16:13:50.630815 25100 net.cpp:165] Memory required for data: 48536480
I0520 16:13:50.630825 25100 layer_factory.hpp:77] Creating layer conv3
I0520 16:13:50.630843 25100 net.cpp:106] Creating Layer conv3
I0520 16:13:50.630854 25100 net.cpp:454] conv3 <- pool2
I0520 16:13:50.630867 25100 net.cpp:411] conv3 -> conv3
I0520 16:13:50.632839 25100 net.cpp:150] Setting up conv3
I0520 16:13:50.632863 25100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0520 16:13:50.632874 25100 net.cpp:165] Memory required for data: 52873120
I0520 16:13:50.632907 25100 layer_factory.hpp:77] Creating layer relu3
I0520 16:13:50.632920 25100 net.cpp:106] Creating Layer relu3
I0520 16:13:50.632931 25100 net.cpp:454] relu3 <- conv3
I0520 16:13:50.632943 25100 net.cpp:397] relu3 -> conv3 (in-place)
I0520 16:13:50.633415 25100 net.cpp:150] Setting up relu3
I0520 16:13:50.633431 25100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0520 16:13:50.633441 25100 net.cpp:165] Memory required for data: 57209760
I0520 16:13:50.633451 25100 layer_factory.hpp:77] Creating layer pool3
I0520 16:13:50.633465 25100 net.cpp:106] Creating Layer pool3
I0520 16:13:50.633474 25100 net.cpp:454] pool3 <- conv3
I0520 16:13:50.633486 25100 net.cpp:411] pool3 -> pool3
I0520 16:13:50.633558 25100 net.cpp:150] Setting up pool3
I0520 16:13:50.633571 25100 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0520 16:13:50.633581 25100 net.cpp:165] Memory required for data: 59378080
I0520 16:13:50.633591 25100 layer_factory.hpp:77] Creating layer conv4
I0520 16:13:50.633610 25100 net.cpp:106] Creating Layer conv4
I0520 16:13:50.633620 25100 net.cpp:454] conv4 <- pool3
I0520 16:13:50.633635 25100 net.cpp:411] conv4 -> conv4
I0520 16:13:50.635692 25100 net.cpp:150] Setting up conv4
I0520 16:13:50.635715 25100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0520 16:13:50.635727 25100 net.cpp:165] Memory required for data: 60829600
I0520 16:13:50.635742 25100 layer_factory.hpp:77] Creating layer relu4
I0520 16:13:50.635756 25100 net.cpp:106] Creating Layer relu4
I0520 16:13:50.635766 25100 net.cpp:454] relu4 <- conv4
I0520 16:13:50.635778 25100 net.cpp:397] relu4 -> conv4 (in-place)
I0520 16:13:50.636252 25100 net.cpp:150] Setting up relu4
I0520 16:13:50.636268 25100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0520 16:13:50.636278 25100 net.cpp:165] Memory required for data: 62281120
I0520 16:13:50.636288 25100 layer_factory.hpp:77] Creating layer pool4
I0520 16:13:50.636301 25100 net.cpp:106] Creating Layer pool4
I0520 16:13:50.636312 25100 net.cpp:454] pool4 <- conv4
I0520 16:13:50.636324 25100 net.cpp:411] pool4 -> pool4
I0520 16:13:50.636394 25100 net.cpp:150] Setting up pool4
I0520 16:13:50.636407 25100 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0520 16:13:50.636417 25100 net.cpp:165] Memory required for data: 63006880
I0520 16:13:50.636427 25100 layer_factory.hpp:77] Creating layer ip1
I0520 16:13:50.636442 25100 net.cpp:106] Creating Layer ip1
I0520 16:13:50.636452 25100 net.cpp:454] ip1 <- pool4
I0520 16:13:50.636466 25100 net.cpp:411] ip1 -> ip1
I0520 16:13:50.651923 25100 net.cpp:150] Setting up ip1
I0520 16:13:50.651950 25100 net.cpp:157] Top shape: 40 196 (7840)
I0520 16:13:50.651963 25100 net.cpp:165] Memory required for data: 63038240
I0520 16:13:50.651984 25100 layer_factory.hpp:77] Creating layer relu5
I0520 16:13:50.651999 25100 net.cpp:106] Creating Layer relu5
I0520 16:13:50.652010 25100 net.cpp:454] relu5 <- ip1
I0520 16:13:50.652024 25100 net.cpp:397] relu5 -> ip1 (in-place)
I0520 16:13:50.652370 25100 net.cpp:150] Setting up relu5
I0520 16:13:50.652384 25100 net.cpp:157] Top shape: 40 196 (7840)
I0520 16:13:50.652395 25100 net.cpp:165] Memory required for data: 63069600
I0520 16:13:50.652405 25100 layer_factory.hpp:77] Creating layer drop1
I0520 16:13:50.652423 25100 net.cpp:106] Creating Layer drop1
I0520 16:13:50.652432 25100 net.cpp:454] drop1 <- ip1
I0520 16:13:50.652446 25100 net.cpp:397] drop1 -> ip1 (in-place)
I0520 16:13:50.652492 25100 net.cpp:150] Setting up drop1
I0520 16:13:50.652503 25100 net.cpp:157] Top shape: 40 196 (7840)
I0520 16:13:50.652513 25100 net.cpp:165] Memory required for data: 63100960
I0520 16:13:50.652523 25100 layer_factory.hpp:77] Creating layer ip2
I0520 16:13:50.652537 25100 net.cpp:106] Creating Layer ip2
I0520 16:13:50.652547 25100 net.cpp:454] ip2 <- ip1
I0520 16:13:50.652560 25100 net.cpp:411] ip2 -> ip2
I0520 16:13:50.653038 25100 net.cpp:150] Setting up ip2
I0520 16:13:50.653051 25100 net.cpp:157] Top shape: 40 98 (3920)
I0520 16:13:50.653061 25100 net.cpp:165] Memory required for data: 63116640
I0520 16:13:50.653076 25100 layer_factory.hpp:77] Creating layer relu6
I0520 16:13:50.653101 25100 net.cpp:106] Creating Layer relu6
I0520 16:13:50.653111 25100 net.cpp:454] relu6 <- ip2
I0520 16:13:50.653125 25100 net.cpp:397] relu6 -> ip2 (in-place)
I0520 16:13:50.653657 25100 net.cpp:150] Setting up relu6
I0520 16:13:50.653673 25100 net.cpp:157] Top shape: 40 98 (3920)
I0520 16:13:50.653683 25100 net.cpp:165] Memory required for data: 63132320
I0520 16:13:50.653692 25100 layer_factory.hpp:77] Creating layer drop2
I0520 16:13:50.653705 25100 net.cpp:106] Creating Layer drop2
I0520 16:13:50.653715 25100 net.cpp:454] drop2 <- ip2
I0520 16:13:50.653728 25100 net.cpp:397] drop2 -> ip2 (in-place)
I0520 16:13:50.653771 25100 net.cpp:150] Setting up drop2
I0520 16:13:50.653784 25100 net.cpp:157] Top shape: 40 98 (3920)
I0520 16:13:50.653795 25100 net.cpp:165] Memory required for data: 63148000
I0520 16:13:50.653803 25100 layer_factory.hpp:77] Creating layer ip3
I0520 16:13:50.653818 25100 net.cpp:106] Creating Layer ip3
I0520 16:13:50.653828 25100 net.cpp:454] ip3 <- ip2
I0520 16:13:50.653841 25100 net.cpp:411] ip3 -> ip3
I0520 16:13:50.654063 25100 net.cpp:150] Setting up ip3
I0520 16:13:50.654076 25100 net.cpp:157] Top shape: 40 11 (440)
I0520 16:13:50.654086 25100 net.cpp:165] Memory required for data: 63149760
I0520 16:13:50.654101 25100 layer_factory.hpp:77] Creating layer drop3
I0520 16:13:50.654114 25100 net.cpp:106] Creating Layer drop3
I0520 16:13:50.654124 25100 net.cpp:454] drop3 <- ip3
I0520 16:13:50.654136 25100 net.cpp:397] drop3 -> ip3 (in-place)
I0520 16:13:50.654177 25100 net.cpp:150] Setting up drop3
I0520 16:13:50.654189 25100 net.cpp:157] Top shape: 40 11 (440)
I0520 16:13:50.654199 25100 net.cpp:165] Memory required for data: 63151520
I0520 16:13:50.654208 25100 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0520 16:13:50.654222 25100 net.cpp:106] Creating Layer ip3_drop3_0_split
I0520 16:13:50.654232 25100 net.cpp:454] ip3_drop3_0_split <- ip3
I0520 16:13:50.654244 25100 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0520 16:13:50.654258 25100 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0520 16:13:50.654332 25100 net.cpp:150] Setting up ip3_drop3_0_split
I0520 16:13:50.654345 25100 net.cpp:157] Top shape: 40 11 (440)
I0520 16:13:50.654358 25100 net.cpp:157] Top shape: 40 11 (440)
I0520 16:13:50.654368 25100 net.cpp:165] Memory required for data: 63155040
I0520 16:13:50.654378 25100 layer_factory.hpp:77] Creating layer accuracy
I0520 16:13:50.654399 25100 net.cpp:106] Creating Layer accuracy
I0520 16:13:50.654409 25100 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0520 16:13:50.654420 25100 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0520 16:13:50.654434 25100 net.cpp:411] accuracy -> accuracy
I0520 16:13:50.654458 25100 net.cpp:150] Setting up accuracy
I0520 16:13:50.654469 25100 net.cpp:157] Top shape: (1)
I0520 16:13:50.654479 25100 net.cpp:165] Memory required for data: 63155044
I0520 16:13:50.654489 25100 layer_factory.hpp:77] Creating layer loss
I0520 16:13:50.654503 25100 net.cpp:106] Creating Layer loss
I0520 16:13:50.654513 25100 net.cpp:454] loss <- ip3_drop3_0_split_1
I0520 16:13:50.654525 25100 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0520 16:13:50.654537 25100 net.cpp:411] loss -> loss
I0520 16:13:50.654556 25100 layer_factory.hpp:77] Creating layer loss
I0520 16:13:50.655040 25100 net.cpp:150] Setting up loss
I0520 16:13:50.655055 25100 net.cpp:157] Top shape: (1)
I0520 16:13:50.655064 25100 net.cpp:160]     with loss weight 1
I0520 16:13:50.655086 25100 net.cpp:165] Memory required for data: 63155048
I0520 16:13:50.655095 25100 net.cpp:226] loss needs backward computation.
I0520 16:13:50.655107 25100 net.cpp:228] accuracy does not need backward computation.
I0520 16:13:50.655118 25100 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0520 16:13:50.655128 25100 net.cpp:226] drop3 needs backward computation.
I0520 16:13:50.655138 25100 net.cpp:226] ip3 needs backward computation.
I0520 16:13:50.655149 25100 net.cpp:226] drop2 needs backward computation.
I0520 16:13:50.655158 25100 net.cpp:226] relu6 needs backward computation.
I0520 16:13:50.655176 25100 net.cpp:226] ip2 needs backward computation.
I0520 16:13:50.655186 25100 net.cpp:226] drop1 needs backward computation.
I0520 16:13:50.655195 25100 net.cpp:226] relu5 needs backward computation.
I0520 16:13:50.655205 25100 net.cpp:226] ip1 needs backward computation.
I0520 16:13:50.655215 25100 net.cpp:226] pool4 needs backward computation.
I0520 16:13:50.655225 25100 net.cpp:226] relu4 needs backward computation.
I0520 16:13:50.655236 25100 net.cpp:226] conv4 needs backward computation.
I0520 16:13:50.655248 25100 net.cpp:226] pool3 needs backward computation.
I0520 16:13:50.655258 25100 net.cpp:226] relu3 needs backward computation.
I0520 16:13:50.655268 25100 net.cpp:226] conv3 needs backward computation.
I0520 16:13:50.655279 25100 net.cpp:226] pool2 needs backward computation.
I0520 16:13:50.655289 25100 net.cpp:226] relu2 needs backward computation.
I0520 16:13:50.655299 25100 net.cpp:226] conv2 needs backward computation.
I0520 16:13:50.655310 25100 net.cpp:226] pool1 needs backward computation.
I0520 16:13:50.655320 25100 net.cpp:226] relu1 needs backward computation.
I0520 16:13:50.655330 25100 net.cpp:226] conv1 needs backward computation.
I0520 16:13:50.655341 25100 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0520 16:13:50.655354 25100 net.cpp:228] data_hdf5 does not need backward computation.
I0520 16:13:50.655364 25100 net.cpp:270] This network produces output accuracy
I0520 16:13:50.655375 25100 net.cpp:270] This network produces output loss
I0520 16:13:50.655403 25100 net.cpp:283] Network initialization done.
I0520 16:13:50.655536 25100 solver.cpp:60] Solver scaffolding done.
I0520 16:13:50.656674 25100 caffe.cpp:212] Starting Optimization
I0520 16:13:50.656692 25100 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0520 16:13:50.656707 25100 solver.cpp:289] Learning Rate Policy: fixed
I0520 16:13:50.657915 25100 solver.cpp:341] Iteration 0, Testing net (#0)
I0520 16:14:40.043056 25100 solver.cpp:409]     Test net output #0: accuracy = 0.0459533
I0520 16:14:40.043231 25100 solver.cpp:409]     Test net output #1: loss = 2.40085 (* 1 = 2.40085 loss)
I0520 16:14:40.065773 25100 solver.cpp:237] Iteration 0, loss = 2.39985
I0520 16:14:40.065807 25100 solver.cpp:253]     Train net output #0: loss = 2.39985 (* 1 = 2.39985 loss)
I0520 16:14:40.065825 25100 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0520 16:14:49.914671 25100 solver.cpp:237] Iteration 375, loss = 2.28788
I0520 16:14:49.914707 25100 solver.cpp:253]     Train net output #0: loss = 2.28788 (* 1 = 2.28788 loss)
I0520 16:14:49.914724 25100 sgd_solver.cpp:106] Iteration 375, lr = 0.0015
I0520 16:14:59.769050 25100 solver.cpp:237] Iteration 750, loss = 2.09296
I0520 16:14:59.769086 25100 solver.cpp:253]     Train net output #0: loss = 2.09296 (* 1 = 2.09296 loss)
I0520 16:14:59.769101 25100 sgd_solver.cpp:106] Iteration 750, lr = 0.0015
I0520 16:15:09.624171 25100 solver.cpp:237] Iteration 1125, loss = 2.12694
I0520 16:15:09.624212 25100 solver.cpp:253]     Train net output #0: loss = 2.12694 (* 1 = 2.12694 loss)
I0520 16:15:09.624234 25100 sgd_solver.cpp:106] Iteration 1125, lr = 0.0015
I0520 16:15:19.483544 25100 solver.cpp:237] Iteration 1500, loss = 1.75063
I0520 16:15:19.483700 25100 solver.cpp:253]     Train net output #0: loss = 1.75063 (* 1 = 1.75063 loss)
I0520 16:15:19.483714 25100 sgd_solver.cpp:106] Iteration 1500, lr = 0.0015
I0520 16:15:29.346076 25100 solver.cpp:237] Iteration 1875, loss = 1.97815
I0520 16:15:29.346125 25100 solver.cpp:253]     Train net output #0: loss = 1.97815 (* 1 = 1.97815 loss)
I0520 16:15:29.346143 25100 sgd_solver.cpp:106] Iteration 1875, lr = 0.0015
I0520 16:15:39.209269 25100 solver.cpp:237] Iteration 2250, loss = 1.78753
I0520 16:15:39.209305 25100 solver.cpp:253]     Train net output #0: loss = 1.78753 (* 1 = 1.78753 loss)
I0520 16:15:39.209317 25100 sgd_solver.cpp:106] Iteration 2250, lr = 0.0015
I0520 16:16:11.200304 25100 solver.cpp:237] Iteration 2625, loss = 1.64989
I0520 16:16:11.200467 25100 solver.cpp:253]     Train net output #0: loss = 1.64989 (* 1 = 1.64989 loss)
I0520 16:16:11.200481 25100 sgd_solver.cpp:106] Iteration 2625, lr = 0.0015
I0520 16:16:21.060503 25100 solver.cpp:237] Iteration 3000, loss = 1.35695
I0520 16:16:21.060550 25100 solver.cpp:253]     Train net output #0: loss = 1.35695 (* 1 = 1.35695 loss)
I0520 16:16:21.060570 25100 sgd_solver.cpp:106] Iteration 3000, lr = 0.0015
I0520 16:16:30.923594 25100 solver.cpp:237] Iteration 3375, loss = 1.8261
I0520 16:16:30.923630 25100 solver.cpp:253]     Train net output #0: loss = 1.8261 (* 1 = 1.8261 loss)
I0520 16:16:30.923648 25100 sgd_solver.cpp:106] Iteration 3375, lr = 0.0015
I0520 16:16:40.761533 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_3750.caffemodel
I0520 16:16:40.821516 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_3750.solverstate
I0520 16:16:40.854727 25100 solver.cpp:237] Iteration 3750, loss = 1.49309
I0520 16:16:40.854775 25100 solver.cpp:253]     Train net output #0: loss = 1.49309 (* 1 = 1.49309 loss)
I0520 16:16:40.854789 25100 sgd_solver.cpp:106] Iteration 3750, lr = 0.0015
I0520 16:16:50.711437 25100 solver.cpp:237] Iteration 4125, loss = 1.62435
I0520 16:16:50.711598 25100 solver.cpp:253]     Train net output #0: loss = 1.62435 (* 1 = 1.62435 loss)
I0520 16:16:50.711613 25100 sgd_solver.cpp:106] Iteration 4125, lr = 0.0015
I0520 16:17:00.572783 25100 solver.cpp:237] Iteration 4500, loss = 1.56218
I0520 16:17:00.572818 25100 solver.cpp:253]     Train net output #0: loss = 1.56218 (* 1 = 1.56218 loss)
I0520 16:17:00.572836 25100 sgd_solver.cpp:106] Iteration 4500, lr = 0.0015
I0520 16:17:10.426748 25100 solver.cpp:237] Iteration 4875, loss = 1.77258
I0520 16:17:10.426797 25100 solver.cpp:253]     Train net output #0: loss = 1.77258 (* 1 = 1.77258 loss)
I0520 16:17:10.426813 25100 sgd_solver.cpp:106] Iteration 4875, lr = 0.0015
I0520 16:17:42.429236 25100 solver.cpp:237] Iteration 5250, loss = 1.42715
I0520 16:17:42.429397 25100 solver.cpp:253]     Train net output #0: loss = 1.42715 (* 1 = 1.42715 loss)
I0520 16:17:42.429411 25100 sgd_solver.cpp:106] Iteration 5250, lr = 0.0015
I0520 16:17:52.290823 25100 solver.cpp:237] Iteration 5625, loss = 1.40708
I0520 16:17:52.290858 25100 solver.cpp:253]     Train net output #0: loss = 1.40708 (* 1 = 1.40708 loss)
I0520 16:17:52.290874 25100 sgd_solver.cpp:106] Iteration 5625, lr = 0.0015
I0520 16:18:02.157907 25100 solver.cpp:237] Iteration 6000, loss = 1.50884
I0520 16:18:02.157958 25100 solver.cpp:253]     Train net output #0: loss = 1.50884 (* 1 = 1.50884 loss)
I0520 16:18:02.157970 25100 sgd_solver.cpp:106] Iteration 6000, lr = 0.0015
I0520 16:18:12.026142 25100 solver.cpp:237] Iteration 6375, loss = 1.59317
I0520 16:18:12.026178 25100 solver.cpp:253]     Train net output #0: loss = 1.59317 (* 1 = 1.59317 loss)
I0520 16:18:12.026195 25100 sgd_solver.cpp:106] Iteration 6375, lr = 0.0015
I0520 16:18:21.897557 25100 solver.cpp:237] Iteration 6750, loss = 1.83063
I0520 16:18:21.897716 25100 solver.cpp:253]     Train net output #0: loss = 1.83063 (* 1 = 1.83063 loss)
I0520 16:18:21.897730 25100 sgd_solver.cpp:106] Iteration 6750, lr = 0.0015
I0520 16:18:31.761579 25100 solver.cpp:237] Iteration 7125, loss = 1.297
I0520 16:18:31.761631 25100 solver.cpp:253]     Train net output #0: loss = 1.297 (* 1 = 1.297 loss)
I0520 16:18:31.761646 25100 sgd_solver.cpp:106] Iteration 7125, lr = 0.0015
I0520 16:18:41.603415 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_7500.caffemodel
I0520 16:18:41.659718 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_7500.solverstate
I0520 16:18:41.685235 25100 solver.cpp:341] Iteration 7500, Testing net (#0)
I0520 16:19:30.217630 25100 solver.cpp:409]     Test net output #0: accuracy = 0.771467
I0520 16:19:30.217794 25100 solver.cpp:409]     Test net output #1: loss = 0.815311 (* 1 = 0.815311 loss)
I0520 16:19:52.355201 25100 solver.cpp:237] Iteration 7500, loss = 1.5985
I0520 16:19:52.355257 25100 solver.cpp:253]     Train net output #0: loss = 1.5985 (* 1 = 1.5985 loss)
I0520 16:19:52.355271 25100 sgd_solver.cpp:106] Iteration 7500, lr = 0.0015
I0520 16:20:02.236637 25100 solver.cpp:237] Iteration 7875, loss = 1.44203
I0520 16:20:02.236780 25100 solver.cpp:253]     Train net output #0: loss = 1.44203 (* 1 = 1.44203 loss)
I0520 16:20:02.236794 25100 sgd_solver.cpp:106] Iteration 7875, lr = 0.0015
I0520 16:20:12.129631 25100 solver.cpp:237] Iteration 8250, loss = 1.72629
I0520 16:20:12.129676 25100 solver.cpp:253]     Train net output #0: loss = 1.72629 (* 1 = 1.72629 loss)
I0520 16:20:12.129695 25100 sgd_solver.cpp:106] Iteration 8250, lr = 0.0015
I0520 16:20:22.018479 25100 solver.cpp:237] Iteration 8625, loss = 1.59203
I0520 16:20:22.018515 25100 solver.cpp:253]     Train net output #0: loss = 1.59203 (* 1 = 1.59203 loss)
I0520 16:20:22.018532 25100 sgd_solver.cpp:106] Iteration 8625, lr = 0.0015
I0520 16:20:31.898116 25100 solver.cpp:237] Iteration 9000, loss = 1.1019
I0520 16:20:31.898160 25100 solver.cpp:253]     Train net output #0: loss = 1.1019 (* 1 = 1.1019 loss)
I0520 16:20:31.898182 25100 sgd_solver.cpp:106] Iteration 9000, lr = 0.0015
I0520 16:20:41.779114 25100 solver.cpp:237] Iteration 9375, loss = 1.57916
I0520 16:20:41.779254 25100 solver.cpp:253]     Train net output #0: loss = 1.57916 (* 1 = 1.57916 loss)
I0520 16:20:41.779268 25100 sgd_solver.cpp:106] Iteration 9375, lr = 0.0015
I0520 16:20:51.652055 25100 solver.cpp:237] Iteration 9750, loss = 1.30639
I0520 16:20:51.652089 25100 solver.cpp:253]     Train net output #0: loss = 1.30639 (* 1 = 1.30639 loss)
I0520 16:20:51.652107 25100 sgd_solver.cpp:106] Iteration 9750, lr = 0.0015
I0520 16:21:23.714102 25100 solver.cpp:237] Iteration 10125, loss = 1.46779
I0520 16:21:23.714267 25100 solver.cpp:253]     Train net output #0: loss = 1.46779 (* 1 = 1.46779 loss)
I0520 16:21:23.714283 25100 sgd_solver.cpp:106] Iteration 10125, lr = 0.0015
I0520 16:21:33.593616 25100 solver.cpp:237] Iteration 10500, loss = 1.22938
I0520 16:21:33.593652 25100 solver.cpp:253]     Train net output #0: loss = 1.22938 (* 1 = 1.22938 loss)
I0520 16:21:33.593669 25100 sgd_solver.cpp:106] Iteration 10500, lr = 0.0015
I0520 16:21:43.482508 25100 solver.cpp:237] Iteration 10875, loss = 1.45637
I0520 16:21:43.482544 25100 solver.cpp:253]     Train net output #0: loss = 1.45637 (* 1 = 1.45637 loss)
I0520 16:21:43.482560 25100 sgd_solver.cpp:106] Iteration 10875, lr = 0.0015
I0520 16:21:53.342092 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_11250.caffemodel
I0520 16:21:53.400519 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_11250.solverstate
I0520 16:21:53.435876 25100 solver.cpp:237] Iteration 11250, loss = 1.28784
I0520 16:21:53.435925 25100 solver.cpp:253]     Train net output #0: loss = 1.28784 (* 1 = 1.28784 loss)
I0520 16:21:53.435946 25100 sgd_solver.cpp:106] Iteration 11250, lr = 0.0015
I0520 16:22:03.309406 25100 solver.cpp:237] Iteration 11625, loss = 1.33654
I0520 16:22:03.309559 25100 solver.cpp:253]     Train net output #0: loss = 1.33654 (* 1 = 1.33654 loss)
I0520 16:22:03.309574 25100 sgd_solver.cpp:106] Iteration 11625, lr = 0.0015
I0520 16:22:13.189151 25100 solver.cpp:237] Iteration 12000, loss = 1.33544
I0520 16:22:13.189206 25100 solver.cpp:253]     Train net output #0: loss = 1.33544 (* 1 = 1.33544 loss)
I0520 16:22:13.189221 25100 sgd_solver.cpp:106] Iteration 12000, lr = 0.0015
I0520 16:22:23.068423 25100 solver.cpp:237] Iteration 12375, loss = 1.65646
I0520 16:22:23.068459 25100 solver.cpp:253]     Train net output #0: loss = 1.65646 (* 1 = 1.65646 loss)
I0520 16:22:23.068475 25100 sgd_solver.cpp:106] Iteration 12375, lr = 0.0015
I0520 16:22:55.158493 25100 solver.cpp:237] Iteration 12750, loss = 1.34139
I0520 16:22:55.158663 25100 solver.cpp:253]     Train net output #0: loss = 1.34139 (* 1 = 1.34139 loss)
I0520 16:22:55.158677 25100 sgd_solver.cpp:106] Iteration 12750, lr = 0.0015
I0520 16:23:05.046398 25100 solver.cpp:237] Iteration 13125, loss = 1.4928
I0520 16:23:05.046447 25100 solver.cpp:253]     Train net output #0: loss = 1.4928 (* 1 = 1.4928 loss)
I0520 16:23:05.046464 25100 sgd_solver.cpp:106] Iteration 13125, lr = 0.0015
I0520 16:23:14.924512 25100 solver.cpp:237] Iteration 13500, loss = 1.5792
I0520 16:23:14.924546 25100 solver.cpp:253]     Train net output #0: loss = 1.5792 (* 1 = 1.5792 loss)
I0520 16:23:14.924564 25100 sgd_solver.cpp:106] Iteration 13500, lr = 0.0015
I0520 16:23:24.802847 25100 solver.cpp:237] Iteration 13875, loss = 1.19269
I0520 16:23:24.802891 25100 solver.cpp:253]     Train net output #0: loss = 1.19269 (* 1 = 1.19269 loss)
I0520 16:23:24.802907 25100 sgd_solver.cpp:106] Iteration 13875, lr = 0.0015
I0520 16:23:34.687319 25100 solver.cpp:237] Iteration 14250, loss = 0.986023
I0520 16:23:34.687458 25100 solver.cpp:253]     Train net output #0: loss = 0.986023 (* 1 = 0.986023 loss)
I0520 16:23:34.687474 25100 sgd_solver.cpp:106] Iteration 14250, lr = 0.0015
I0520 16:23:44.566452 25100 solver.cpp:237] Iteration 14625, loss = 1.25495
I0520 16:23:44.566486 25100 solver.cpp:253]     Train net output #0: loss = 1.25495 (* 1 = 1.25495 loss)
I0520 16:23:44.566504 25100 sgd_solver.cpp:106] Iteration 14625, lr = 0.0015
I0520 16:23:54.421221 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_15000.caffemodel
I0520 16:23:54.479975 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_15000.solverstate
I0520 16:23:54.507550 25100 solver.cpp:341] Iteration 15000, Testing net (#0)
I0520 16:25:03.900950 25100 solver.cpp:409]     Test net output #0: accuracy = 0.824427
I0520 16:25:03.901101 25100 solver.cpp:409]     Test net output #1: loss = 0.695166 (* 1 = 0.695166 loss)
I0520 16:25:26.128710 25100 solver.cpp:237] Iteration 15000, loss = 1.43191
I0520 16:25:26.128767 25100 solver.cpp:253]     Train net output #0: loss = 1.43191 (* 1 = 1.43191 loss)
I0520 16:25:26.128784 25100 sgd_solver.cpp:106] Iteration 15000, lr = 0.0015
I0520 16:25:36.010501 25100 solver.cpp:237] Iteration 15375, loss = 0.938162
I0520 16:25:36.010670 25100 solver.cpp:253]     Train net output #0: loss = 0.938162 (* 1 = 0.938162 loss)
I0520 16:25:36.010684 25100 sgd_solver.cpp:106] Iteration 15375, lr = 0.0015
I0520 16:25:45.884053 25100 solver.cpp:237] Iteration 15750, loss = 1.72878
I0520 16:25:45.884088 25100 solver.cpp:253]     Train net output #0: loss = 1.72878 (* 1 = 1.72878 loss)
I0520 16:25:45.884106 25100 sgd_solver.cpp:106] Iteration 15750, lr = 0.0015
I0520 16:25:55.768090 25100 solver.cpp:237] Iteration 16125, loss = 1.38326
I0520 16:25:55.768133 25100 solver.cpp:253]     Train net output #0: loss = 1.38326 (* 1 = 1.38326 loss)
I0520 16:25:55.768152 25100 sgd_solver.cpp:106] Iteration 16125, lr = 0.0015
I0520 16:26:05.644911 25100 solver.cpp:237] Iteration 16500, loss = 1.45298
I0520 16:26:05.644945 25100 solver.cpp:253]     Train net output #0: loss = 1.45298 (* 1 = 1.45298 loss)
I0520 16:26:05.644963 25100 sgd_solver.cpp:106] Iteration 16500, lr = 0.0015
I0520 16:26:15.522687 25100 solver.cpp:237] Iteration 16875, loss = 1.27629
I0520 16:26:15.522826 25100 solver.cpp:253]     Train net output #0: loss = 1.27629 (* 1 = 1.27629 loss)
I0520 16:26:15.522840 25100 sgd_solver.cpp:106] Iteration 16875, lr = 0.0015
I0520 16:26:25.403609 25100 solver.cpp:237] Iteration 17250, loss = 1.1906
I0520 16:26:25.403661 25100 solver.cpp:253]     Train net output #0: loss = 1.1906 (* 1 = 1.1906 loss)
I0520 16:26:25.403676 25100 sgd_solver.cpp:106] Iteration 17250, lr = 0.0015
I0520 16:26:57.464232 25100 solver.cpp:237] Iteration 17625, loss = 0.96617
I0520 16:26:57.464395 25100 solver.cpp:253]     Train net output #0: loss = 0.96617 (* 1 = 0.96617 loss)
I0520 16:26:57.464411 25100 sgd_solver.cpp:106] Iteration 17625, lr = 0.0015
I0520 16:27:07.341842 25100 solver.cpp:237] Iteration 18000, loss = 1.49437
I0520 16:27:07.341877 25100 solver.cpp:253]     Train net output #0: loss = 1.49437 (* 1 = 1.49437 loss)
I0520 16:27:07.341895 25100 sgd_solver.cpp:106] Iteration 18000, lr = 0.0015
I0520 16:27:17.227296 25100 solver.cpp:237] Iteration 18375, loss = 1.23493
I0520 16:27:17.227335 25100 solver.cpp:253]     Train net output #0: loss = 1.23493 (* 1 = 1.23493 loss)
I0520 16:27:17.227358 25100 sgd_solver.cpp:106] Iteration 18375, lr = 0.0015
I0520 16:27:27.080987 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_18750.caffemodel
I0520 16:27:27.139375 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_18750.solverstate
I0520 16:27:27.175993 25100 solver.cpp:237] Iteration 18750, loss = 1.16109
I0520 16:27:27.176046 25100 solver.cpp:253]     Train net output #0: loss = 1.16109 (* 1 = 1.16109 loss)
I0520 16:27:27.176064 25100 sgd_solver.cpp:106] Iteration 18750, lr = 0.0015
I0520 16:27:37.058471 25100 solver.cpp:237] Iteration 19125, loss = 1.5876
I0520 16:27:37.058631 25100 solver.cpp:253]     Train net output #0: loss = 1.5876 (* 1 = 1.5876 loss)
I0520 16:27:37.058645 25100 sgd_solver.cpp:106] Iteration 19125, lr = 0.0015
I0520 16:27:46.935580 25100 solver.cpp:237] Iteration 19500, loss = 1.0851
I0520 16:27:46.935616 25100 solver.cpp:253]     Train net output #0: loss = 1.0851 (* 1 = 1.0851 loss)
I0520 16:27:46.935632 25100 sgd_solver.cpp:106] Iteration 19500, lr = 0.0015
I0520 16:27:56.815975 25100 solver.cpp:237] Iteration 19875, loss = 1.34012
I0520 16:27:56.816010 25100 solver.cpp:253]     Train net output #0: loss = 1.34012 (* 1 = 1.34012 loss)
I0520 16:27:56.816028 25100 sgd_solver.cpp:106] Iteration 19875, lr = 0.0015
I0520 16:28:28.878221 25100 solver.cpp:237] Iteration 20250, loss = 1.52505
I0520 16:28:28.878403 25100 solver.cpp:253]     Train net output #0: loss = 1.52505 (* 1 = 1.52505 loss)
I0520 16:28:28.878418 25100 sgd_solver.cpp:106] Iteration 20250, lr = 0.0015
I0520 16:28:38.755414 25100 solver.cpp:237] Iteration 20625, loss = 1.40721
I0520 16:28:38.755450 25100 solver.cpp:253]     Train net output #0: loss = 1.40721 (* 1 = 1.40721 loss)
I0520 16:28:38.755466 25100 sgd_solver.cpp:106] Iteration 20625, lr = 0.0015
I0520 16:28:48.629549 25100 solver.cpp:237] Iteration 21000, loss = 1.29283
I0520 16:28:48.629585 25100 solver.cpp:253]     Train net output #0: loss = 1.29283 (* 1 = 1.29283 loss)
I0520 16:28:48.629602 25100 sgd_solver.cpp:106] Iteration 21000, lr = 0.0015
I0520 16:28:58.511217 25100 solver.cpp:237] Iteration 21375, loss = 1.5989
I0520 16:28:58.511260 25100 solver.cpp:253]     Train net output #0: loss = 1.5989 (* 1 = 1.5989 loss)
I0520 16:28:58.511277 25100 sgd_solver.cpp:106] Iteration 21375, lr = 0.0015
I0520 16:29:08.394804 25100 solver.cpp:237] Iteration 21750, loss = 1.13664
I0520 16:29:08.394954 25100 solver.cpp:253]     Train net output #0: loss = 1.13664 (* 1 = 1.13664 loss)
I0520 16:29:08.394970 25100 sgd_solver.cpp:106] Iteration 21750, lr = 0.0015
I0520 16:29:18.279399 25100 solver.cpp:237] Iteration 22125, loss = 1.13178
I0520 16:29:18.279443 25100 solver.cpp:253]     Train net output #0: loss = 1.13178 (* 1 = 1.13178 loss)
I0520 16:29:18.279463 25100 sgd_solver.cpp:106] Iteration 22125, lr = 0.0015
I0520 16:29:28.128697 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_22500.caffemodel
I0520 16:29:28.184396 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_22500.solverstate
I0520 16:29:28.210388 25100 solver.cpp:341] Iteration 22500, Testing net (#0)
I0520 16:30:16.386968 25100 solver.cpp:409]     Test net output #0: accuracy = 0.8399
I0520 16:30:16.387135 25100 solver.cpp:409]     Test net output #1: loss = 0.538215 (* 1 = 0.538215 loss)
I0520 16:30:38.634006 25100 solver.cpp:237] Iteration 22500, loss = 1.2393
I0520 16:30:38.634059 25100 solver.cpp:253]     Train net output #0: loss = 1.2393 (* 1 = 1.2393 loss)
I0520 16:30:38.634078 25100 sgd_solver.cpp:106] Iteration 22500, lr = 0.0015
I0520 16:30:48.320823 25100 solver.cpp:237] Iteration 22875, loss = 1.18946
I0520 16:30:48.320973 25100 solver.cpp:253]     Train net output #0: loss = 1.18946 (* 1 = 1.18946 loss)
I0520 16:30:48.320986 25100 sgd_solver.cpp:106] Iteration 22875, lr = 0.0015
I0520 16:30:58.009295 25100 solver.cpp:237] Iteration 23250, loss = 1.27679
I0520 16:30:58.009341 25100 solver.cpp:253]     Train net output #0: loss = 1.27679 (* 1 = 1.27679 loss)
I0520 16:30:58.009359 25100 sgd_solver.cpp:106] Iteration 23250, lr = 0.0015
I0520 16:31:07.690625 25100 solver.cpp:237] Iteration 23625, loss = 1.34006
I0520 16:31:07.690660 25100 solver.cpp:253]     Train net output #0: loss = 1.34006 (* 1 = 1.34006 loss)
I0520 16:31:07.690677 25100 sgd_solver.cpp:106] Iteration 23625, lr = 0.0015
I0520 16:31:17.367442 25100 solver.cpp:237] Iteration 24000, loss = 1.33177
I0520 16:31:17.367477 25100 solver.cpp:253]     Train net output #0: loss = 1.33177 (* 1 = 1.33177 loss)
I0520 16:31:17.367494 25100 sgd_solver.cpp:106] Iteration 24000, lr = 0.0015
I0520 16:31:27.060824 25100 solver.cpp:237] Iteration 24375, loss = 1.17851
I0520 16:31:27.060971 25100 solver.cpp:253]     Train net output #0: loss = 1.17851 (* 1 = 1.17851 loss)
I0520 16:31:27.060984 25100 sgd_solver.cpp:106] Iteration 24375, lr = 0.0015
I0520 16:31:36.755919 25100 solver.cpp:237] Iteration 24750, loss = 1.16637
I0520 16:31:36.755954 25100 solver.cpp:253]     Train net output #0: loss = 1.16637 (* 1 = 1.16637 loss)
I0520 16:31:36.755969 25100 sgd_solver.cpp:106] Iteration 24750, lr = 0.0015
I0520 16:32:08.647361 25100 solver.cpp:237] Iteration 25125, loss = 1.41841
I0520 16:32:08.647533 25100 solver.cpp:253]     Train net output #0: loss = 1.41841 (* 1 = 1.41841 loss)
I0520 16:32:08.647549 25100 sgd_solver.cpp:106] Iteration 25125, lr = 0.0015
I0520 16:32:18.337472 25100 solver.cpp:237] Iteration 25500, loss = 1.08448
I0520 16:32:18.337505 25100 solver.cpp:253]     Train net output #0: loss = 1.08448 (* 1 = 1.08448 loss)
I0520 16:32:18.337523 25100 sgd_solver.cpp:106] Iteration 25500, lr = 0.0015
I0520 16:32:28.028961 25100 solver.cpp:237] Iteration 25875, loss = 1.32219
I0520 16:32:28.028997 25100 solver.cpp:253]     Train net output #0: loss = 1.32219 (* 1 = 1.32219 loss)
I0520 16:32:28.029013 25100 sgd_solver.cpp:106] Iteration 25875, lr = 0.0015
I0520 16:32:37.698353 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_26250.caffemodel
I0520 16:32:37.764559 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_26250.solverstate
I0520 16:32:37.798951 25100 solver.cpp:237] Iteration 26250, loss = 1.5217
I0520 16:32:37.798996 25100 solver.cpp:253]     Train net output #0: loss = 1.5217 (* 1 = 1.5217 loss)
I0520 16:32:37.799016 25100 sgd_solver.cpp:106] Iteration 26250, lr = 0.0015
I0520 16:32:47.487283 25100 solver.cpp:237] Iteration 26625, loss = 1.23252
I0520 16:32:47.487431 25100 solver.cpp:253]     Train net output #0: loss = 1.23252 (* 1 = 1.23252 loss)
I0520 16:32:47.487444 25100 sgd_solver.cpp:106] Iteration 26625, lr = 0.0015
I0520 16:32:57.177366 25100 solver.cpp:237] Iteration 27000, loss = 1.08279
I0520 16:32:57.177402 25100 solver.cpp:253]     Train net output #0: loss = 1.08279 (* 1 = 1.08279 loss)
I0520 16:32:57.177418 25100 sgd_solver.cpp:106] Iteration 27000, lr = 0.0015
I0520 16:33:06.867722 25100 solver.cpp:237] Iteration 27375, loss = 1.19754
I0520 16:33:06.867763 25100 solver.cpp:253]     Train net output #0: loss = 1.19754 (* 1 = 1.19754 loss)
I0520 16:33:06.867784 25100 sgd_solver.cpp:106] Iteration 27375, lr = 0.0015
I0520 16:33:38.753021 25100 solver.cpp:237] Iteration 27750, loss = 1.23253
I0520 16:33:38.753193 25100 solver.cpp:253]     Train net output #0: loss = 1.23253 (* 1 = 1.23253 loss)
I0520 16:33:38.753209 25100 sgd_solver.cpp:106] Iteration 27750, lr = 0.0015
I0520 16:33:48.439030 25100 solver.cpp:237] Iteration 28125, loss = 1.40559
I0520 16:33:48.439064 25100 solver.cpp:253]     Train net output #0: loss = 1.40559 (* 1 = 1.40559 loss)
I0520 16:33:48.439079 25100 sgd_solver.cpp:106] Iteration 28125, lr = 0.0015
I0520 16:33:58.127743 25100 solver.cpp:237] Iteration 28500, loss = 1.41145
I0520 16:33:58.127782 25100 solver.cpp:253]     Train net output #0: loss = 1.41145 (* 1 = 1.41145 loss)
I0520 16:33:58.127802 25100 sgd_solver.cpp:106] Iteration 28500, lr = 0.0015
I0520 16:34:07.817652 25100 solver.cpp:237] Iteration 28875, loss = 1.26183
I0520 16:34:07.817688 25100 solver.cpp:253]     Train net output #0: loss = 1.26183 (* 1 = 1.26183 loss)
I0520 16:34:07.817706 25100 sgd_solver.cpp:106] Iteration 28875, lr = 0.0015
I0520 16:34:17.508666 25100 solver.cpp:237] Iteration 29250, loss = 1.29001
I0520 16:34:17.508817 25100 solver.cpp:253]     Train net output #0: loss = 1.29001 (* 1 = 1.29001 loss)
I0520 16:34:17.508831 25100 sgd_solver.cpp:106] Iteration 29250, lr = 0.0015
I0520 16:34:27.198211 25100 solver.cpp:237] Iteration 29625, loss = 1.27433
I0520 16:34:27.198247 25100 solver.cpp:253]     Train net output #0: loss = 1.27433 (* 1 = 1.27433 loss)
I0520 16:34:27.198263 25100 sgd_solver.cpp:106] Iteration 29625, lr = 0.0015
I0520 16:34:36.855916 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_30000.caffemodel
I0520 16:34:36.912080 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_30000.solverstate
I0520 16:34:36.938457 25100 solver.cpp:341] Iteration 30000, Testing net (#0)
I0520 16:35:46.337115 25100 solver.cpp:409]     Test net output #0: accuracy = 0.854179
I0520 16:35:46.337288 25100 solver.cpp:409]     Test net output #1: loss = 0.482217 (* 1 = 0.482217 loss)
I0520 16:36:08.549299 25100 solver.cpp:237] Iteration 30000, loss = 1.43657
I0520 16:36:08.549353 25100 solver.cpp:253]     Train net output #0: loss = 1.43657 (* 1 = 1.43657 loss)
I0520 16:36:08.549371 25100 sgd_solver.cpp:106] Iteration 30000, lr = 0.0015
I0520 16:36:18.410137 25100 solver.cpp:237] Iteration 30375, loss = 1.12899
I0520 16:36:18.410292 25100 solver.cpp:253]     Train net output #0: loss = 1.12899 (* 1 = 1.12899 loss)
I0520 16:36:18.410307 25100 sgd_solver.cpp:106] Iteration 30375, lr = 0.0015
I0520 16:36:28.275604 25100 solver.cpp:237] Iteration 30750, loss = 1.05316
I0520 16:36:28.275646 25100 solver.cpp:253]     Train net output #0: loss = 1.05316 (* 1 = 1.05316 loss)
I0520 16:36:28.275671 25100 sgd_solver.cpp:106] Iteration 30750, lr = 0.0015
I0520 16:36:38.144625 25100 solver.cpp:237] Iteration 31125, loss = 0.991878
I0520 16:36:38.144662 25100 solver.cpp:253]     Train net output #0: loss = 0.991878 (* 1 = 0.991878 loss)
I0520 16:36:38.144678 25100 sgd_solver.cpp:106] Iteration 31125, lr = 0.0015
I0520 16:36:48.012749 25100 solver.cpp:237] Iteration 31500, loss = 1.17404
I0520 16:36:48.012797 25100 solver.cpp:253]     Train net output #0: loss = 1.17404 (* 1 = 1.17404 loss)
I0520 16:36:48.012811 25100 sgd_solver.cpp:106] Iteration 31500, lr = 0.0015
I0520 16:36:57.877758 25100 solver.cpp:237] Iteration 31875, loss = 1.25431
I0520 16:36:57.877902 25100 solver.cpp:253]     Train net output #0: loss = 1.25431 (* 1 = 1.25431 loss)
I0520 16:36:57.877915 25100 sgd_solver.cpp:106] Iteration 31875, lr = 0.0015
I0520 16:37:07.745347 25100 solver.cpp:237] Iteration 32250, loss = 1.11835
I0520 16:37:07.745383 25100 solver.cpp:253]     Train net output #0: loss = 1.11835 (* 1 = 1.11835 loss)
I0520 16:37:07.745399 25100 sgd_solver.cpp:106] Iteration 32250, lr = 0.0015
I0520 16:37:39.802980 25100 solver.cpp:237] Iteration 32625, loss = 1.30942
I0520 16:37:39.803145 25100 solver.cpp:253]     Train net output #0: loss = 1.30942 (* 1 = 1.30942 loss)
I0520 16:37:39.803161 25100 sgd_solver.cpp:106] Iteration 32625, lr = 0.0015
I0520 16:37:49.672950 25100 solver.cpp:237] Iteration 33000, loss = 1.54546
I0520 16:37:49.672984 25100 solver.cpp:253]     Train net output #0: loss = 1.54546 (* 1 = 1.54546 loss)
I0520 16:37:49.673002 25100 sgd_solver.cpp:106] Iteration 33000, lr = 0.0015
I0520 16:37:59.539196 25100 solver.cpp:237] Iteration 33375, loss = 1.32046
I0520 16:37:59.539239 25100 solver.cpp:253]     Train net output #0: loss = 1.32046 (* 1 = 1.32046 loss)
I0520 16:37:59.539261 25100 sgd_solver.cpp:106] Iteration 33375, lr = 0.0015
I0520 16:38:09.373805 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_33750.caffemodel
I0520 16:38:09.431874 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_33750.solverstate
I0520 16:38:09.468487 25100 solver.cpp:237] Iteration 33750, loss = 1.38613
I0520 16:38:09.468539 25100 solver.cpp:253]     Train net output #0: loss = 1.38613 (* 1 = 1.38613 loss)
I0520 16:38:09.468556 25100 sgd_solver.cpp:106] Iteration 33750, lr = 0.0015
I0520 16:38:19.333485 25100 solver.cpp:237] Iteration 34125, loss = 1.12825
I0520 16:38:19.333633 25100 solver.cpp:253]     Train net output #0: loss = 1.12825 (* 1 = 1.12825 loss)
I0520 16:38:19.333647 25100 sgd_solver.cpp:106] Iteration 34125, lr = 0.0015
I0520 16:38:29.196688 25100 solver.cpp:237] Iteration 34500, loss = 1.30926
I0520 16:38:29.196733 25100 solver.cpp:253]     Train net output #0: loss = 1.30926 (* 1 = 1.30926 loss)
I0520 16:38:29.196753 25100 sgd_solver.cpp:106] Iteration 34500, lr = 0.0015
I0520 16:38:39.058918 25100 solver.cpp:237] Iteration 34875, loss = 1.50497
I0520 16:38:39.058954 25100 solver.cpp:253]     Train net output #0: loss = 1.50497 (* 1 = 1.50497 loss)
I0520 16:38:39.058971 25100 sgd_solver.cpp:106] Iteration 34875, lr = 0.0015
I0520 16:39:11.059593 25100 solver.cpp:237] Iteration 35250, loss = 1.0883
I0520 16:39:11.059784 25100 solver.cpp:253]     Train net output #0: loss = 1.0883 (* 1 = 1.0883 loss)
I0520 16:39:11.059800 25100 sgd_solver.cpp:106] Iteration 35250, lr = 0.0015
I0520 16:39:20.920125 25100 solver.cpp:237] Iteration 35625, loss = 1.27665
I0520 16:39:20.920173 25100 solver.cpp:253]     Train net output #0: loss = 1.27665 (* 1 = 1.27665 loss)
I0520 16:39:20.920189 25100 sgd_solver.cpp:106] Iteration 35625, lr = 0.0015
I0520 16:39:30.790424 25100 solver.cpp:237] Iteration 36000, loss = 1.04855
I0520 16:39:30.790460 25100 solver.cpp:253]     Train net output #0: loss = 1.04855 (* 1 = 1.04855 loss)
I0520 16:39:30.790477 25100 sgd_solver.cpp:106] Iteration 36000, lr = 0.0015
I0520 16:39:40.660178 25100 solver.cpp:237] Iteration 36375, loss = 1.21678
I0520 16:39:40.660228 25100 solver.cpp:253]     Train net output #0: loss = 1.21678 (* 1 = 1.21678 loss)
I0520 16:39:40.660245 25100 sgd_solver.cpp:106] Iteration 36375, lr = 0.0015
I0520 16:39:50.522470 25100 solver.cpp:237] Iteration 36750, loss = 1.37834
I0520 16:39:50.522616 25100 solver.cpp:253]     Train net output #0: loss = 1.37834 (* 1 = 1.37834 loss)
I0520 16:39:50.522630 25100 sgd_solver.cpp:106] Iteration 36750, lr = 0.0015
I0520 16:40:00.387195 25100 solver.cpp:237] Iteration 37125, loss = 1.5464
I0520 16:40:00.387229 25100 solver.cpp:253]     Train net output #0: loss = 1.5464 (* 1 = 1.5464 loss)
I0520 16:40:00.387248 25100 sgd_solver.cpp:106] Iteration 37125, lr = 0.0015
I0520 16:40:10.225350 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_37500.caffemodel
I0520 16:40:10.283943 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_37500.solverstate
I0520 16:40:10.312634 25100 solver.cpp:341] Iteration 37500, Testing net (#0)
I0520 16:40:58.805315 25100 solver.cpp:409]     Test net output #0: accuracy = 0.861921
I0520 16:40:58.805482 25100 solver.cpp:409]     Test net output #1: loss = 0.463745 (* 1 = 0.463745 loss)
I0520 16:41:19.707015 25100 solver.cpp:237] Iteration 37500, loss = 1.14229
I0520 16:41:19.707072 25100 solver.cpp:253]     Train net output #0: loss = 1.14229 (* 1 = 1.14229 loss)
I0520 16:41:19.707088 25100 sgd_solver.cpp:106] Iteration 37500, lr = 0.0015
I0520 16:41:29.586107 25100 solver.cpp:237] Iteration 37875, loss = 1.36389
I0520 16:41:29.586254 25100 solver.cpp:253]     Train net output #0: loss = 1.36389 (* 1 = 1.36389 loss)
I0520 16:41:29.586267 25100 sgd_solver.cpp:106] Iteration 37875, lr = 0.0015
I0520 16:41:39.466855 25100 solver.cpp:237] Iteration 38250, loss = 1.32663
I0520 16:41:39.466889 25100 solver.cpp:253]     Train net output #0: loss = 1.32663 (* 1 = 1.32663 loss)
I0520 16:41:39.466905 25100 sgd_solver.cpp:106] Iteration 38250, lr = 0.0015
I0520 16:41:49.348901 25100 solver.cpp:237] Iteration 38625, loss = 1.10285
I0520 16:41:49.348949 25100 solver.cpp:253]     Train net output #0: loss = 1.10285 (* 1 = 1.10285 loss)
I0520 16:41:49.348968 25100 sgd_solver.cpp:106] Iteration 38625, lr = 0.0015
I0520 16:41:59.231834 25100 solver.cpp:237] Iteration 39000, loss = 1.09435
I0520 16:41:59.231869 25100 solver.cpp:253]     Train net output #0: loss = 1.09435 (* 1 = 1.09435 loss)
I0520 16:41:59.231885 25100 sgd_solver.cpp:106] Iteration 39000, lr = 0.0015
I0520 16:42:09.115234 25100 solver.cpp:237] Iteration 39375, loss = 1.34583
I0520 16:42:09.115406 25100 solver.cpp:253]     Train net output #0: loss = 1.34583 (* 1 = 1.34583 loss)
I0520 16:42:09.115419 25100 sgd_solver.cpp:106] Iteration 39375, lr = 0.0015
I0520 16:42:18.999752 25100 solver.cpp:237] Iteration 39750, loss = 1.44895
I0520 16:42:18.999786 25100 solver.cpp:253]     Train net output #0: loss = 1.44895 (* 1 = 1.44895 loss)
I0520 16:42:18.999800 25100 sgd_solver.cpp:106] Iteration 39750, lr = 0.0015
I0520 16:42:49.722055 25100 solver.cpp:237] Iteration 40125, loss = 1.1887
I0520 16:42:49.722230 25100 solver.cpp:253]     Train net output #0: loss = 1.1887 (* 1 = 1.1887 loss)
I0520 16:42:49.722245 25100 sgd_solver.cpp:106] Iteration 40125, lr = 0.0015
I0520 16:42:59.604902 25100 solver.cpp:237] Iteration 40500, loss = 1.34956
I0520 16:42:59.604953 25100 solver.cpp:253]     Train net output #0: loss = 1.34956 (* 1 = 1.34956 loss)
I0520 16:42:59.604971 25100 sgd_solver.cpp:106] Iteration 40500, lr = 0.0015
I0520 16:43:09.488948 25100 solver.cpp:237] Iteration 40875, loss = 1.35308
I0520 16:43:09.488986 25100 solver.cpp:253]     Train net output #0: loss = 1.35308 (* 1 = 1.35308 loss)
I0520 16:43:09.489002 25100 sgd_solver.cpp:106] Iteration 40875, lr = 0.0015
I0520 16:43:19.343880 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_41250.caffemodel
I0520 16:43:19.399813 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_41250.solverstate
I0520 16:43:19.433913 25100 solver.cpp:237] Iteration 41250, loss = 1.124
I0520 16:43:19.433961 25100 solver.cpp:253]     Train net output #0: loss = 1.124 (* 1 = 1.124 loss)
I0520 16:43:19.433975 25100 sgd_solver.cpp:106] Iteration 41250, lr = 0.0015
I0520 16:43:29.314939 25100 solver.cpp:237] Iteration 41625, loss = 1.21617
I0520 16:43:29.315102 25100 solver.cpp:253]     Train net output #0: loss = 1.21617 (* 1 = 1.21617 loss)
I0520 16:43:29.315116 25100 sgd_solver.cpp:106] Iteration 41625, lr = 0.0015
I0520 16:43:39.195209 25100 solver.cpp:237] Iteration 42000, loss = 1.18518
I0520 16:43:39.195242 25100 solver.cpp:253]     Train net output #0: loss = 1.18518 (* 1 = 1.18518 loss)
I0520 16:43:39.195260 25100 sgd_solver.cpp:106] Iteration 42000, lr = 0.0015
I0520 16:43:49.088902 25100 solver.cpp:237] Iteration 42375, loss = 0.869452
I0520 16:43:49.088951 25100 solver.cpp:253]     Train net output #0: loss = 0.869452 (* 1 = 0.869452 loss)
I0520 16:43:49.088969 25100 sgd_solver.cpp:106] Iteration 42375, lr = 0.0015
I0520 16:44:19.819128 25100 solver.cpp:237] Iteration 42750, loss = 1.29822
I0520 16:44:19.819304 25100 solver.cpp:253]     Train net output #0: loss = 1.29822 (* 1 = 1.29822 loss)
I0520 16:44:19.819319 25100 sgd_solver.cpp:106] Iteration 42750, lr = 0.0015
I0520 16:44:29.704988 25100 solver.cpp:237] Iteration 43125, loss = 1.3408
I0520 16:44:29.705024 25100 solver.cpp:253]     Train net output #0: loss = 1.3408 (* 1 = 1.3408 loss)
I0520 16:44:29.705040 25100 sgd_solver.cpp:106] Iteration 43125, lr = 0.0015
I0520 16:44:39.591233 25100 solver.cpp:237] Iteration 43500, loss = 1.34075
I0520 16:44:39.591276 25100 solver.cpp:253]     Train net output #0: loss = 1.34075 (* 1 = 1.34075 loss)
I0520 16:44:39.591298 25100 sgd_solver.cpp:106] Iteration 43500, lr = 0.0015
I0520 16:44:49.471889 25100 solver.cpp:237] Iteration 43875, loss = 1.37444
I0520 16:44:49.471925 25100 solver.cpp:253]     Train net output #0: loss = 1.37444 (* 1 = 1.37444 loss)
I0520 16:44:49.471941 25100 sgd_solver.cpp:106] Iteration 43875, lr = 0.0015
I0520 16:44:59.358508 25100 solver.cpp:237] Iteration 44250, loss = 1.21242
I0520 16:44:59.358651 25100 solver.cpp:253]     Train net output #0: loss = 1.21242 (* 1 = 1.21242 loss)
I0520 16:44:59.358665 25100 sgd_solver.cpp:106] Iteration 44250, lr = 0.0015
I0520 16:45:09.241983 25100 solver.cpp:237] Iteration 44625, loss = 1.27037
I0520 16:45:09.242033 25100 solver.cpp:253]     Train net output #0: loss = 1.27037 (* 1 = 1.27037 loss)
I0520 16:45:09.242048 25100 sgd_solver.cpp:106] Iteration 44625, lr = 0.0015
I0520 16:45:19.103178 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_45000.caffemodel
I0520 16:45:19.159178 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_45000.solverstate
I0520 16:45:19.185269 25100 solver.cpp:341] Iteration 45000, Testing net (#0)
I0520 16:46:28.540938 25100 solver.cpp:409]     Test net output #0: accuracy = 0.864026
I0520 16:46:28.541121 25100 solver.cpp:409]     Test net output #1: loss = 0.432283 (* 1 = 0.432283 loss)
I0520 16:46:49.405354 25100 solver.cpp:237] Iteration 45000, loss = 1.08968
I0520 16:46:49.405411 25100 solver.cpp:253]     Train net output #0: loss = 1.08968 (* 1 = 1.08968 loss)
I0520 16:46:49.405428 25100 sgd_solver.cpp:106] Iteration 45000, lr = 0.0015
I0520 16:46:59.284466 25100 solver.cpp:237] Iteration 45375, loss = 1.38749
I0520 16:46:59.284620 25100 solver.cpp:253]     Train net output #0: loss = 1.38749 (* 1 = 1.38749 loss)
I0520 16:46:59.284633 25100 sgd_solver.cpp:106] Iteration 45375, lr = 0.0015
I0520 16:47:09.167173 25100 solver.cpp:237] Iteration 45750, loss = 1.05817
I0520 16:47:09.167227 25100 solver.cpp:253]     Train net output #0: loss = 1.05817 (* 1 = 1.05817 loss)
I0520 16:47:09.167243 25100 sgd_solver.cpp:106] Iteration 45750, lr = 0.0015
I0520 16:47:19.051961 25100 solver.cpp:237] Iteration 46125, loss = 1.21288
I0520 16:47:19.051995 25100 solver.cpp:253]     Train net output #0: loss = 1.21288 (* 1 = 1.21288 loss)
I0520 16:47:19.052012 25100 sgd_solver.cpp:106] Iteration 46125, lr = 0.0015
I0520 16:47:28.929530 25100 solver.cpp:237] Iteration 46500, loss = 1.24447
I0520 16:47:28.929566 25100 solver.cpp:253]     Train net output #0: loss = 1.24447 (* 1 = 1.24447 loss)
I0520 16:47:28.929582 25100 sgd_solver.cpp:106] Iteration 46500, lr = 0.0015
I0520 16:47:38.814952 25100 solver.cpp:237] Iteration 46875, loss = 1.28419
I0520 16:47:38.815125 25100 solver.cpp:253]     Train net output #0: loss = 1.28419 (* 1 = 1.28419 loss)
I0520 16:47:38.815140 25100 sgd_solver.cpp:106] Iteration 46875, lr = 0.0015
I0520 16:47:48.698230 25100 solver.cpp:237] Iteration 47250, loss = 1.02794
I0520 16:47:48.698263 25100 solver.cpp:253]     Train net output #0: loss = 1.02794 (* 1 = 1.02794 loss)
I0520 16:47:48.698281 25100 sgd_solver.cpp:106] Iteration 47250, lr = 0.0015
I0520 16:48:19.430878 25100 solver.cpp:237] Iteration 47625, loss = 1.37716
I0520 16:48:19.431054 25100 solver.cpp:253]     Train net output #0: loss = 1.37716 (* 1 = 1.37716 loss)
I0520 16:48:19.431069 25100 sgd_solver.cpp:106] Iteration 47625, lr = 0.0015
I0520 16:48:29.313814 25100 solver.cpp:237] Iteration 48000, loss = 1.11296
I0520 16:48:29.313868 25100 solver.cpp:253]     Train net output #0: loss = 1.11296 (* 1 = 1.11296 loss)
I0520 16:48:29.313881 25100 sgd_solver.cpp:106] Iteration 48000, lr = 0.0015
I0520 16:48:39.195225 25100 solver.cpp:237] Iteration 48375, loss = 1.14043
I0520 16:48:39.195261 25100 solver.cpp:253]     Train net output #0: loss = 1.14043 (* 1 = 1.14043 loss)
I0520 16:48:39.195278 25100 sgd_solver.cpp:106] Iteration 48375, lr = 0.0015
I0520 16:48:49.057440 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_48750.caffemodel
I0520 16:48:49.113426 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_48750.solverstate
I0520 16:48:49.147836 25100 solver.cpp:237] Iteration 48750, loss = 1.15714
I0520 16:48:49.147886 25100 solver.cpp:253]     Train net output #0: loss = 1.15714 (* 1 = 1.15714 loss)
I0520 16:48:49.147904 25100 sgd_solver.cpp:106] Iteration 48750, lr = 0.0015
I0520 16:48:59.033994 25100 solver.cpp:237] Iteration 49125, loss = 0.890109
I0520 16:48:59.034157 25100 solver.cpp:253]     Train net output #0: loss = 0.890109 (* 1 = 0.890109 loss)
I0520 16:48:59.034171 25100 sgd_solver.cpp:106] Iteration 49125, lr = 0.0015
I0520 16:49:08.918151 25100 solver.cpp:237] Iteration 49500, loss = 1.0951
I0520 16:49:08.918189 25100 solver.cpp:253]     Train net output #0: loss = 1.0951 (* 1 = 1.0951 loss)
I0520 16:49:08.918205 25100 sgd_solver.cpp:106] Iteration 49500, lr = 0.0015
I0520 16:49:18.801151 25100 solver.cpp:237] Iteration 49875, loss = 1.32083
I0520 16:49:18.801194 25100 solver.cpp:253]     Train net output #0: loss = 1.32083 (* 1 = 1.32083 loss)
I0520 16:49:18.801214 25100 sgd_solver.cpp:106] Iteration 49875, lr = 0.0015
I0520 16:49:49.570134 25100 solver.cpp:237] Iteration 50250, loss = 1.68438
I0520 16:49:49.570312 25100 solver.cpp:253]     Train net output #0: loss = 1.68438 (* 1 = 1.68438 loss)
I0520 16:49:49.570327 25100 sgd_solver.cpp:106] Iteration 50250, lr = 0.0015
I0520 16:49:59.446511 25100 solver.cpp:237] Iteration 50625, loss = 1.24398
I0520 16:49:59.446547 25100 solver.cpp:253]     Train net output #0: loss = 1.24398 (* 1 = 1.24398 loss)
I0520 16:49:59.446565 25100 sgd_solver.cpp:106] Iteration 50625, lr = 0.0015
I0520 16:50:09.328824 25100 solver.cpp:237] Iteration 51000, loss = 1.03644
I0520 16:50:09.328876 25100 solver.cpp:253]     Train net output #0: loss = 1.03644 (* 1 = 1.03644 loss)
I0520 16:50:09.328892 25100 sgd_solver.cpp:106] Iteration 51000, lr = 0.0015
I0520 16:50:19.212635 25100 solver.cpp:237] Iteration 51375, loss = 0.892634
I0520 16:50:19.212671 25100 solver.cpp:253]     Train net output #0: loss = 0.892634 (* 1 = 0.892634 loss)
I0520 16:50:19.212687 25100 sgd_solver.cpp:106] Iteration 51375, lr = 0.0015
I0520 16:50:29.088803 25100 solver.cpp:237] Iteration 51750, loss = 1.04546
I0520 16:50:29.088968 25100 solver.cpp:253]     Train net output #0: loss = 1.04546 (* 1 = 1.04546 loss)
I0520 16:50:29.088984 25100 sgd_solver.cpp:106] Iteration 51750, lr = 0.0015
I0520 16:50:38.966112 25100 solver.cpp:237] Iteration 52125, loss = 1.21937
I0520 16:50:38.966147 25100 solver.cpp:253]     Train net output #0: loss = 1.21937 (* 1 = 1.21937 loss)
I0520 16:50:38.966166 25100 sgd_solver.cpp:106] Iteration 52125, lr = 0.0015
I0520 16:50:48.816634 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_52500.caffemodel
I0520 16:50:48.872874 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_52500.solverstate
I0520 16:50:48.898952 25100 solver.cpp:341] Iteration 52500, Testing net (#0)
I0520 16:51:37.110070 25100 solver.cpp:409]     Test net output #0: accuracy = 0.871633
I0520 16:51:37.110246 25100 solver.cpp:409]     Test net output #1: loss = 0.44544 (* 1 = 0.44544 loss)
I0520 16:51:57.990859 25100 solver.cpp:237] Iteration 52500, loss = 1.02903
I0520 16:51:57.990917 25100 solver.cpp:253]     Train net output #0: loss = 1.02903 (* 1 = 1.02903 loss)
I0520 16:51:57.990932 25100 sgd_solver.cpp:106] Iteration 52500, lr = 0.0015
I0520 16:52:07.671715 25100 solver.cpp:237] Iteration 52875, loss = 0.908445
I0520 16:52:07.671871 25100 solver.cpp:253]     Train net output #0: loss = 0.908445 (* 1 = 0.908445 loss)
I0520 16:52:07.671886 25100 sgd_solver.cpp:106] Iteration 52875, lr = 0.0015
I0520 16:52:17.361029 25100 solver.cpp:237] Iteration 53250, loss = 1.3725
I0520 16:52:17.361069 25100 solver.cpp:253]     Train net output #0: loss = 1.3725 (* 1 = 1.3725 loss)
I0520 16:52:17.361091 25100 sgd_solver.cpp:106] Iteration 53250, lr = 0.0015
I0520 16:52:27.040513 25100 solver.cpp:237] Iteration 53625, loss = 1.08595
I0520 16:52:27.040547 25100 solver.cpp:253]     Train net output #0: loss = 1.08595 (* 1 = 1.08595 loss)
I0520 16:52:27.040565 25100 sgd_solver.cpp:106] Iteration 53625, lr = 0.0015
I0520 16:52:36.725945 25100 solver.cpp:237] Iteration 54000, loss = 1.07618
I0520 16:52:36.725983 25100 solver.cpp:253]     Train net output #0: loss = 1.07618 (* 1 = 1.07618 loss)
I0520 16:52:36.726006 25100 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015
I0520 16:52:46.408032 25100 solver.cpp:237] Iteration 54375, loss = 1.09176
I0520 16:52:46.408192 25100 solver.cpp:253]     Train net output #0: loss = 1.09176 (* 1 = 1.09176 loss)
I0520 16:52:46.408205 25100 sgd_solver.cpp:106] Iteration 54375, lr = 0.0015
I0520 16:52:56.093768 25100 solver.cpp:237] Iteration 54750, loss = 1.20436
I0520 16:52:56.093803 25100 solver.cpp:253]     Train net output #0: loss = 1.20436 (* 1 = 1.20436 loss)
I0520 16:52:56.093821 25100 sgd_solver.cpp:106] Iteration 54750, lr = 0.0015
I0520 16:53:26.648767 25100 solver.cpp:237] Iteration 55125, loss = 1.07485
I0520 16:53:26.648954 25100 solver.cpp:253]     Train net output #0: loss = 1.07485 (* 1 = 1.07485 loss)
I0520 16:53:26.648969 25100 sgd_solver.cpp:106] Iteration 55125, lr = 0.0015
I0520 16:53:36.334178 25100 solver.cpp:237] Iteration 55500, loss = 1.20115
I0520 16:53:36.334213 25100 solver.cpp:253]     Train net output #0: loss = 1.20115 (* 1 = 1.20115 loss)
I0520 16:53:36.334230 25100 sgd_solver.cpp:106] Iteration 55500, lr = 0.0015
I0520 16:53:46.017935 25100 solver.cpp:237] Iteration 55875, loss = 1.06517
I0520 16:53:46.017968 25100 solver.cpp:253]     Train net output #0: loss = 1.06517 (* 1 = 1.06517 loss)
I0520 16:53:46.017987 25100 sgd_solver.cpp:106] Iteration 55875, lr = 0.0015
I0520 16:53:55.679404 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_56250.caffemodel
I0520 16:53:55.737082 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_56250.solverstate
I0520 16:53:55.773495 25100 solver.cpp:237] Iteration 56250, loss = 1.04488
I0520 16:53:55.773550 25100 solver.cpp:253]     Train net output #0: loss = 1.04488 (* 1 = 1.04488 loss)
I0520 16:53:55.773564 25100 sgd_solver.cpp:106] Iteration 56250, lr = 0.0015
I0520 16:54:05.450959 25100 solver.cpp:237] Iteration 56625, loss = 1.21964
I0520 16:54:05.451115 25100 solver.cpp:253]     Train net output #0: loss = 1.21964 (* 1 = 1.21964 loss)
I0520 16:54:05.451130 25100 sgd_solver.cpp:106] Iteration 56625, lr = 0.0015
I0520 16:54:15.137356 25100 solver.cpp:237] Iteration 57000, loss = 1.48137
I0520 16:54:15.137410 25100 solver.cpp:253]     Train net output #0: loss = 1.48137 (* 1 = 1.48137 loss)
I0520 16:54:15.137428 25100 sgd_solver.cpp:106] Iteration 57000, lr = 0.0015
I0520 16:54:24.828807 25100 solver.cpp:237] Iteration 57375, loss = 1.30072
I0520 16:54:24.828845 25100 solver.cpp:253]     Train net output #0: loss = 1.30072 (* 1 = 1.30072 loss)
I0520 16:54:24.828860 25100 sgd_solver.cpp:106] Iteration 57375, lr = 0.0015
I0520 16:54:55.399502 25100 solver.cpp:237] Iteration 57750, loss = 1.11669
I0520 16:54:55.399685 25100 solver.cpp:253]     Train net output #0: loss = 1.11669 (* 1 = 1.11669 loss)
I0520 16:54:55.399701 25100 sgd_solver.cpp:106] Iteration 57750, lr = 0.0015
I0520 16:55:05.080834 25100 solver.cpp:237] Iteration 58125, loss = 0.935239
I0520 16:55:05.080880 25100 solver.cpp:253]     Train net output #0: loss = 0.935239 (* 1 = 0.935239 loss)
I0520 16:55:05.080902 25100 sgd_solver.cpp:106] Iteration 58125, lr = 0.0015
I0520 16:55:14.765257 25100 solver.cpp:237] Iteration 58500, loss = 1.27286
I0520 16:55:14.765293 25100 solver.cpp:253]     Train net output #0: loss = 1.27286 (* 1 = 1.27286 loss)
I0520 16:55:14.765310 25100 sgd_solver.cpp:106] Iteration 58500, lr = 0.0015
I0520 16:55:24.444550 25100 solver.cpp:237] Iteration 58875, loss = 1.11238
I0520 16:55:24.444586 25100 solver.cpp:253]     Train net output #0: loss = 1.11238 (* 1 = 1.11238 loss)
I0520 16:55:24.444602 25100 sgd_solver.cpp:106] Iteration 58875, lr = 0.0015
I0520 16:55:34.132475 25100 solver.cpp:237] Iteration 59250, loss = 1.26351
I0520 16:55:34.132657 25100 solver.cpp:253]     Train net output #0: loss = 1.26351 (* 1 = 1.26351 loss)
I0520 16:55:34.132671 25100 sgd_solver.cpp:106] Iteration 59250, lr = 0.0015
I0520 16:55:43.819715 25100 solver.cpp:237] Iteration 59625, loss = 1.1427
I0520 16:55:43.819746 25100 solver.cpp:253]     Train net output #0: loss = 1.1427 (* 1 = 1.1427 loss)
I0520 16:55:43.819759 25100 sgd_solver.cpp:106] Iteration 59625, lr = 0.0015
I0520 16:55:53.483064 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_60000.caffemodel
I0520 16:55:53.538189 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_60000.solverstate
I0520 16:55:53.564079 25100 solver.cpp:341] Iteration 60000, Testing net (#0)
I0520 16:57:03.009428 25100 solver.cpp:409]     Test net output #0: accuracy = 0.875167
I0520 16:57:03.009606 25100 solver.cpp:409]     Test net output #1: loss = 0.392595 (* 1 = 0.392595 loss)
I0520 16:57:23.859822 25100 solver.cpp:237] Iteration 60000, loss = 1.00087
I0520 16:57:23.859877 25100 solver.cpp:253]     Train net output #0: loss = 1.00087 (* 1 = 1.00087 loss)
I0520 16:57:23.859895 25100 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0520 16:57:33.726411 25100 solver.cpp:237] Iteration 60375, loss = 1.12306
I0520 16:57:33.726580 25100 solver.cpp:253]     Train net output #0: loss = 1.12306 (* 1 = 1.12306 loss)
I0520 16:57:33.726594 25100 sgd_solver.cpp:106] Iteration 60375, lr = 0.0015
I0520 16:57:43.597548 25100 solver.cpp:237] Iteration 60750, loss = 1.14808
I0520 16:57:43.597582 25100 solver.cpp:253]     Train net output #0: loss = 1.14808 (* 1 = 1.14808 loss)
I0520 16:57:43.597596 25100 sgd_solver.cpp:106] Iteration 60750, lr = 0.0015
I0520 16:57:53.462983 25100 solver.cpp:237] Iteration 61125, loss = 1.25949
I0520 16:57:53.463019 25100 solver.cpp:253]     Train net output #0: loss = 1.25949 (* 1 = 1.25949 loss)
I0520 16:57:53.463035 25100 sgd_solver.cpp:106] Iteration 61125, lr = 0.0015
I0520 16:58:03.334902 25100 solver.cpp:237] Iteration 61500, loss = 1.41453
I0520 16:58:03.334949 25100 solver.cpp:253]     Train net output #0: loss = 1.41453 (* 1 = 1.41453 loss)
I0520 16:58:03.334965 25100 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0520 16:58:13.196151 25100 solver.cpp:237] Iteration 61875, loss = 1.15388
I0520 16:58:13.196303 25100 solver.cpp:253]     Train net output #0: loss = 1.15388 (* 1 = 1.15388 loss)
I0520 16:58:13.196317 25100 sgd_solver.cpp:106] Iteration 61875, lr = 0.0015
I0520 16:58:23.059514 25100 solver.cpp:237] Iteration 62250, loss = 1.02992
I0520 16:58:23.059550 25100 solver.cpp:253]     Train net output #0: loss = 1.02992 (* 1 = 1.02992 loss)
I0520 16:58:23.059566 25100 sgd_solver.cpp:106] Iteration 62250, lr = 0.0015
I0520 16:58:53.827836 25100 solver.cpp:237] Iteration 62625, loss = 1.23766
I0520 16:58:53.828011 25100 solver.cpp:253]     Train net output #0: loss = 1.23766 (* 1 = 1.23766 loss)
I0520 16:58:53.828027 25100 sgd_solver.cpp:106] Iteration 62625, lr = 0.0015
I0520 16:59:03.702790 25100 solver.cpp:237] Iteration 63000, loss = 1.02711
I0520 16:59:03.702826 25100 solver.cpp:253]     Train net output #0: loss = 1.02711 (* 1 = 1.02711 loss)
I0520 16:59:03.702842 25100 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0520 16:59:13.578336 25100 solver.cpp:237] Iteration 63375, loss = 1.0468
I0520 16:59:13.578372 25100 solver.cpp:253]     Train net output #0: loss = 1.0468 (* 1 = 1.0468 loss)
I0520 16:59:13.578389 25100 sgd_solver.cpp:106] Iteration 63375, lr = 0.0015
I0520 16:59:23.425374 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_63750.caffemodel
I0520 16:59:23.487659 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_63750.solverstate
I0520 16:59:23.521782 25100 solver.cpp:237] Iteration 63750, loss = 1.1398
I0520 16:59:23.521829 25100 solver.cpp:253]     Train net output #0: loss = 1.1398 (* 1 = 1.1398 loss)
I0520 16:59:23.521847 25100 sgd_solver.cpp:106] Iteration 63750, lr = 0.0015
I0520 16:59:33.392655 25100 solver.cpp:237] Iteration 64125, loss = 1.20337
I0520 16:59:33.392822 25100 solver.cpp:253]     Train net output #0: loss = 1.20337 (* 1 = 1.20337 loss)
I0520 16:59:33.392835 25100 sgd_solver.cpp:106] Iteration 64125, lr = 0.0015
I0520 16:59:43.275959 25100 solver.cpp:237] Iteration 64500, loss = 1.3629
I0520 16:59:43.276005 25100 solver.cpp:253]     Train net output #0: loss = 1.3629 (* 1 = 1.3629 loss)
I0520 16:59:43.276022 25100 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0520 16:59:53.146311 25100 solver.cpp:237] Iteration 64875, loss = 1.24719
I0520 16:59:53.146347 25100 solver.cpp:253]     Train net output #0: loss = 1.24719 (* 1 = 1.24719 loss)
I0520 16:59:53.146363 25100 sgd_solver.cpp:106] Iteration 64875, lr = 0.0015
I0520 17:00:23.895771 25100 solver.cpp:237] Iteration 65250, loss = 1.05557
I0520 17:00:23.895951 25100 solver.cpp:253]     Train net output #0: loss = 1.05557 (* 1 = 1.05557 loss)
I0520 17:00:23.895967 25100 sgd_solver.cpp:106] Iteration 65250, lr = 0.0015
I0520 17:00:33.769840 25100 solver.cpp:237] Iteration 65625, loss = 1.52937
I0520 17:00:33.769886 25100 solver.cpp:253]     Train net output #0: loss = 1.52937 (* 1 = 1.52937 loss)
I0520 17:00:33.769903 25100 sgd_solver.cpp:106] Iteration 65625, lr = 0.0015
I0520 17:00:43.646404 25100 solver.cpp:237] Iteration 66000, loss = 1.1474
I0520 17:00:43.646440 25100 solver.cpp:253]     Train net output #0: loss = 1.1474 (* 1 = 1.1474 loss)
I0520 17:00:43.646456 25100 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0520 17:00:53.527048 25100 solver.cpp:237] Iteration 66375, loss = 1.13332
I0520 17:00:53.527084 25100 solver.cpp:253]     Train net output #0: loss = 1.13332 (* 1 = 1.13332 loss)
I0520 17:00:53.527101 25100 sgd_solver.cpp:106] Iteration 66375, lr = 0.0015
I0520 17:01:03.402250 25100 solver.cpp:237] Iteration 66750, loss = 1.29075
I0520 17:01:03.402406 25100 solver.cpp:253]     Train net output #0: loss = 1.29075 (* 1 = 1.29075 loss)
I0520 17:01:03.402420 25100 sgd_solver.cpp:106] Iteration 66750, lr = 0.0015
I0520 17:01:13.277570 25100 solver.cpp:237] Iteration 67125, loss = 1.10574
I0520 17:01:13.277604 25100 solver.cpp:253]     Train net output #0: loss = 1.10574 (* 1 = 1.10574 loss)
I0520 17:01:13.277622 25100 sgd_solver.cpp:106] Iteration 67125, lr = 0.0015
I0520 17:01:23.126389 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_67500.caffemodel
I0520 17:01:23.182685 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_67500.solverstate
I0520 17:01:23.208886 25100 solver.cpp:341] Iteration 67500, Testing net (#0)
I0520 17:02:11.761907 25100 solver.cpp:409]     Test net output #0: accuracy = 0.87936
I0520 17:02:11.762079 25100 solver.cpp:409]     Test net output #1: loss = 0.38742 (* 1 = 0.38742 loss)
I0520 17:02:32.684408 25100 solver.cpp:237] Iteration 67500, loss = 1.45821
I0520 17:02:32.684465 25100 solver.cpp:253]     Train net output #0: loss = 1.45821 (* 1 = 1.45821 loss)
I0520 17:02:32.684480 25100 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0520 17:02:42.360102 25100 solver.cpp:237] Iteration 67875, loss = 1.19182
I0520 17:02:42.360276 25100 solver.cpp:253]     Train net output #0: loss = 1.19182 (* 1 = 1.19182 loss)
I0520 17:02:42.360291 25100 sgd_solver.cpp:106] Iteration 67875, lr = 0.0015
I0520 17:02:52.039856 25100 solver.cpp:237] Iteration 68250, loss = 1.03716
I0520 17:02:52.039891 25100 solver.cpp:253]     Train net output #0: loss = 1.03716 (* 1 = 1.03716 loss)
I0520 17:02:52.039908 25100 sgd_solver.cpp:106] Iteration 68250, lr = 0.0015
I0520 17:03:01.725522 25100 solver.cpp:237] Iteration 68625, loss = 0.843605
I0520 17:03:01.725566 25100 solver.cpp:253]     Train net output #0: loss = 0.843605 (* 1 = 0.843605 loss)
I0520 17:03:01.725589 25100 sgd_solver.cpp:106] Iteration 68625, lr = 0.0015
I0520 17:03:11.403863 25100 solver.cpp:237] Iteration 69000, loss = 1.05749
I0520 17:03:11.403898 25100 solver.cpp:253]     Train net output #0: loss = 1.05749 (* 1 = 1.05749 loss)
I0520 17:03:11.403913 25100 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0520 17:03:21.080606 25100 solver.cpp:237] Iteration 69375, loss = 1.06609
I0520 17:03:21.080765 25100 solver.cpp:253]     Train net output #0: loss = 1.06609 (* 1 = 1.06609 loss)
I0520 17:03:21.080780 25100 sgd_solver.cpp:106] Iteration 69375, lr = 0.0015
I0520 17:03:30.762017 25100 solver.cpp:237] Iteration 69750, loss = 1.13747
I0520 17:03:30.762063 25100 solver.cpp:253]     Train net output #0: loss = 1.13747 (* 1 = 1.13747 loss)
I0520 17:03:30.762084 25100 sgd_solver.cpp:106] Iteration 69750, lr = 0.0015
I0520 17:04:01.321713 25100 solver.cpp:237] Iteration 70125, loss = 1.24994
I0520 17:04:01.321893 25100 solver.cpp:253]     Train net output #0: loss = 1.24994 (* 1 = 1.24994 loss)
I0520 17:04:01.321908 25100 sgd_solver.cpp:106] Iteration 70125, lr = 0.0015
I0520 17:04:11.007355 25100 solver.cpp:237] Iteration 70500, loss = 1.35861
I0520 17:04:11.007390 25100 solver.cpp:253]     Train net output #0: loss = 1.35861 (* 1 = 1.35861 loss)
I0520 17:04:11.007407 25100 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0520 17:04:20.719832 25100 solver.cpp:237] Iteration 70875, loss = 1.05284
I0520 17:04:20.719885 25100 solver.cpp:253]     Train net output #0: loss = 1.05284 (* 1 = 1.05284 loss)
I0520 17:04:20.719899 25100 sgd_solver.cpp:106] Iteration 70875, lr = 0.0015
I0520 17:04:30.419203 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_71250.caffemodel
I0520 17:04:30.478271 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_71250.solverstate
I0520 17:04:30.515113 25100 solver.cpp:237] Iteration 71250, loss = 1.15062
I0520 17:04:30.515166 25100 solver.cpp:253]     Train net output #0: loss = 1.15062 (* 1 = 1.15062 loss)
I0520 17:04:30.515180 25100 sgd_solver.cpp:106] Iteration 71250, lr = 0.0015
I0520 17:04:40.240725 25100 solver.cpp:237] Iteration 71625, loss = 1.16685
I0520 17:04:40.240905 25100 solver.cpp:253]     Train net output #0: loss = 1.16685 (* 1 = 1.16685 loss)
I0520 17:04:40.240918 25100 sgd_solver.cpp:106] Iteration 71625, lr = 0.0015
I0520 17:04:49.967207 25100 solver.cpp:237] Iteration 72000, loss = 1.5954
I0520 17:04:49.967242 25100 solver.cpp:253]     Train net output #0: loss = 1.5954 (* 1 = 1.5954 loss)
I0520 17:04:49.967260 25100 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0520 17:04:59.695076 25100 solver.cpp:237] Iteration 72375, loss = 1.28025
I0520 17:04:59.695112 25100 solver.cpp:253]     Train net output #0: loss = 1.28025 (* 1 = 1.28025 loss)
I0520 17:04:59.695125 25100 sgd_solver.cpp:106] Iteration 72375, lr = 0.0015
I0520 17:05:30.327148 25100 solver.cpp:237] Iteration 72750, loss = 1.05904
I0520 17:05:30.327329 25100 solver.cpp:253]     Train net output #0: loss = 1.05904 (* 1 = 1.05904 loss)
I0520 17:05:30.327344 25100 sgd_solver.cpp:106] Iteration 72750, lr = 0.0015
I0520 17:05:40.058092 25100 solver.cpp:237] Iteration 73125, loss = 1.54545
I0520 17:05:40.058127 25100 solver.cpp:253]     Train net output #0: loss = 1.54545 (* 1 = 1.54545 loss)
I0520 17:05:40.058145 25100 sgd_solver.cpp:106] Iteration 73125, lr = 0.0015
I0520 17:05:49.790026 25100 solver.cpp:237] Iteration 73500, loss = 1.09823
I0520 17:05:49.790062 25100 solver.cpp:253]     Train net output #0: loss = 1.09823 (* 1 = 1.09823 loss)
I0520 17:05:49.790079 25100 sgd_solver.cpp:106] Iteration 73500, lr = 0.0015
I0520 17:05:59.517103 25100 solver.cpp:237] Iteration 73875, loss = 1.22849
I0520 17:05:59.517150 25100 solver.cpp:253]     Train net output #0: loss = 1.22849 (* 1 = 1.22849 loss)
I0520 17:05:59.517168 25100 sgd_solver.cpp:106] Iteration 73875, lr = 0.0015
I0520 17:06:09.246448 25100 solver.cpp:237] Iteration 74250, loss = 1.18721
I0520 17:06:09.246614 25100 solver.cpp:253]     Train net output #0: loss = 1.18721 (* 1 = 1.18721 loss)
I0520 17:06:09.246629 25100 sgd_solver.cpp:106] Iteration 74250, lr = 0.0015
I0520 17:06:18.976250 25100 solver.cpp:237] Iteration 74625, loss = 1.45204
I0520 17:06:18.976299 25100 solver.cpp:253]     Train net output #0: loss = 1.45204 (* 1 = 1.45204 loss)
I0520 17:06:18.976312 25100 sgd_solver.cpp:106] Iteration 74625, lr = 0.0015
I0520 17:06:28.678380 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_75000.caffemodel
I0520 17:06:28.736706 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_75000.solverstate
I0520 17:06:28.765014 25100 solver.cpp:341] Iteration 75000, Testing net (#0)
I0520 17:07:38.199967 25100 solver.cpp:409]     Test net output #0: accuracy = 0.881186
I0520 17:07:38.200146 25100 solver.cpp:409]     Test net output #1: loss = 0.36834 (* 1 = 0.36834 loss)
I0520 17:07:59.070019 25100 solver.cpp:237] Iteration 75000, loss = 1.19792
I0520 17:07:59.070075 25100 solver.cpp:253]     Train net output #0: loss = 1.19792 (* 1 = 1.19792 loss)
I0520 17:07:59.070093 25100 sgd_solver.cpp:106] Iteration 75000, lr = 0.0015
I0520 17:08:08.871192 25100 solver.cpp:237] Iteration 75375, loss = 0.983649
I0520 17:08:08.871354 25100 solver.cpp:253]     Train net output #0: loss = 0.983649 (* 1 = 0.983649 loss)
I0520 17:08:08.871369 25100 sgd_solver.cpp:106] Iteration 75375, lr = 0.0015
I0520 17:08:18.671231 25100 solver.cpp:237] Iteration 75750, loss = 1.05347
I0520 17:08:18.671265 25100 solver.cpp:253]     Train net output #0: loss = 1.05347 (* 1 = 1.05347 loss)
I0520 17:08:18.671283 25100 sgd_solver.cpp:106] Iteration 75750, lr = 0.0015
I0520 17:08:28.474925 25100 solver.cpp:237] Iteration 76125, loss = 1.30652
I0520 17:08:28.474970 25100 solver.cpp:253]     Train net output #0: loss = 1.30652 (* 1 = 1.30652 loss)
I0520 17:08:28.474984 25100 sgd_solver.cpp:106] Iteration 76125, lr = 0.0015
I0520 17:08:38.281802 25100 solver.cpp:237] Iteration 76500, loss = 1.28221
I0520 17:08:38.281838 25100 solver.cpp:253]     Train net output #0: loss = 1.28221 (* 1 = 1.28221 loss)
I0520 17:08:38.281854 25100 sgd_solver.cpp:106] Iteration 76500, lr = 0.0015
I0520 17:08:48.080272 25100 solver.cpp:237] Iteration 76875, loss = 1.08552
I0520 17:08:48.080427 25100 solver.cpp:253]     Train net output #0: loss = 1.08552 (* 1 = 1.08552 loss)
I0520 17:08:48.080440 25100 sgd_solver.cpp:106] Iteration 76875, lr = 0.0015
I0520 17:08:57.876163 25100 solver.cpp:237] Iteration 77250, loss = 1.03251
I0520 17:08:57.876199 25100 solver.cpp:253]     Train net output #0: loss = 1.03251 (* 1 = 1.03251 loss)
I0520 17:08:57.876216 25100 sgd_solver.cpp:106] Iteration 77250, lr = 0.0015
I0520 17:09:28.590991 25100 solver.cpp:237] Iteration 77625, loss = 1.0573
I0520 17:09:28.591168 25100 solver.cpp:253]     Train net output #0: loss = 1.0573 (* 1 = 1.0573 loss)
I0520 17:09:28.591186 25100 sgd_solver.cpp:106] Iteration 77625, lr = 0.0015
I0520 17:09:38.398530 25100 solver.cpp:237] Iteration 78000, loss = 0.992133
I0520 17:09:38.398566 25100 solver.cpp:253]     Train net output #0: loss = 0.992133 (* 1 = 0.992133 loss)
I0520 17:09:38.398583 25100 sgd_solver.cpp:106] Iteration 78000, lr = 0.0015
I0520 17:09:48.198716 25100 solver.cpp:237] Iteration 78375, loss = 1.95005
I0520 17:09:48.198760 25100 solver.cpp:253]     Train net output #0: loss = 1.95005 (* 1 = 1.95005 loss)
I0520 17:09:48.198777 25100 sgd_solver.cpp:106] Iteration 78375, lr = 0.0015
I0520 17:09:57.973793 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_78750.caffemodel
I0520 17:09:58.030272 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_78750.solverstate
I0520 17:09:58.064549 25100 solver.cpp:237] Iteration 78750, loss = 1.1304
I0520 17:09:58.064594 25100 solver.cpp:253]     Train net output #0: loss = 1.1304 (* 1 = 1.1304 loss)
I0520 17:09:58.064615 25100 sgd_solver.cpp:106] Iteration 78750, lr = 0.0015
I0520 17:10:07.863399 25100 solver.cpp:237] Iteration 79125, loss = 1.25574
I0520 17:10:07.863579 25100 solver.cpp:253]     Train net output #0: loss = 1.25574 (* 1 = 1.25574 loss)
I0520 17:10:07.863593 25100 sgd_solver.cpp:106] Iteration 79125, lr = 0.0015
I0520 17:10:17.664414 25100 solver.cpp:237] Iteration 79500, loss = 1.15267
I0520 17:10:17.664448 25100 solver.cpp:253]     Train net output #0: loss = 1.15267 (* 1 = 1.15267 loss)
I0520 17:10:17.664466 25100 sgd_solver.cpp:106] Iteration 79500, lr = 0.0015
I0520 17:10:27.457345 25100 solver.cpp:237] Iteration 79875, loss = 0.942614
I0520 17:10:27.457381 25100 solver.cpp:253]     Train net output #0: loss = 0.942614 (* 1 = 0.942614 loss)
I0520 17:10:27.457398 25100 sgd_solver.cpp:106] Iteration 79875, lr = 0.0015
I0520 17:10:58.162072 25100 solver.cpp:237] Iteration 80250, loss = 0.983178
I0520 17:10:58.162251 25100 solver.cpp:253]     Train net output #0: loss = 0.983178 (* 1 = 0.983178 loss)
I0520 17:10:58.162267 25100 sgd_solver.cpp:106] Iteration 80250, lr = 0.0015
I0520 17:11:07.963989 25100 solver.cpp:237] Iteration 80625, loss = 1.30524
I0520 17:11:07.964025 25100 solver.cpp:253]     Train net output #0: loss = 1.30524 (* 1 = 1.30524 loss)
I0520 17:11:07.964041 25100 sgd_solver.cpp:106] Iteration 80625, lr = 0.0015
I0520 17:11:17.762858 25100 solver.cpp:237] Iteration 81000, loss = 1.34389
I0520 17:11:17.762894 25100 solver.cpp:253]     Train net output #0: loss = 1.34389 (* 1 = 1.34389 loss)
I0520 17:11:17.762910 25100 sgd_solver.cpp:106] Iteration 81000, lr = 0.0015
I0520 17:11:27.565562 25100 solver.cpp:237] Iteration 81375, loss = 1.16273
I0520 17:11:27.565611 25100 solver.cpp:253]     Train net output #0: loss = 1.16273 (* 1 = 1.16273 loss)
I0520 17:11:27.565629 25100 sgd_solver.cpp:106] Iteration 81375, lr = 0.0015
I0520 17:11:37.364291 25100 solver.cpp:237] Iteration 81750, loss = 0.914573
I0520 17:11:37.364446 25100 solver.cpp:253]     Train net output #0: loss = 0.914573 (* 1 = 0.914573 loss)
I0520 17:11:37.364462 25100 sgd_solver.cpp:106] Iteration 81750, lr = 0.0015
I0520 17:11:47.161769 25100 solver.cpp:237] Iteration 82125, loss = 1.1498
I0520 17:11:47.161819 25100 solver.cpp:253]     Train net output #0: loss = 1.1498 (* 1 = 1.1498 loss)
I0520 17:11:47.161836 25100 sgd_solver.cpp:106] Iteration 82125, lr = 0.0015
I0520 17:11:56.935359 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_82500.caffemodel
I0520 17:11:56.991240 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_82500.solverstate
I0520 17:11:57.017375 25100 solver.cpp:341] Iteration 82500, Testing net (#0)
I0520 17:12:45.239003 25100 solver.cpp:409]     Test net output #0: accuracy = 0.88464
I0520 17:12:45.239184 25100 solver.cpp:409]     Test net output #1: loss = 0.371684 (* 1 = 0.371684 loss)
I0520 17:13:06.097873 25100 solver.cpp:237] Iteration 82500, loss = 1.09282
I0520 17:13:06.097928 25100 solver.cpp:253]     Train net output #0: loss = 1.09282 (* 1 = 1.09282 loss)
I0520 17:13:06.097942 25100 sgd_solver.cpp:106] Iteration 82500, lr = 0.0015
I0520 17:13:15.972431 25100 solver.cpp:237] Iteration 82875, loss = 1.11469
I0520 17:13:15.972599 25100 solver.cpp:253]     Train net output #0: loss = 1.11469 (* 1 = 1.11469 loss)
I0520 17:13:15.972612 25100 sgd_solver.cpp:106] Iteration 82875, lr = 0.0015
I0520 17:13:25.854364 25100 solver.cpp:237] Iteration 83250, loss = 1.2803
I0520 17:13:25.854418 25100 solver.cpp:253]     Train net output #0: loss = 1.2803 (* 1 = 1.2803 loss)
I0520 17:13:25.854434 25100 sgd_solver.cpp:106] Iteration 83250, lr = 0.0015
I0520 17:13:35.733523 25100 solver.cpp:237] Iteration 83625, loss = 1.15742
I0520 17:13:35.733558 25100 solver.cpp:253]     Train net output #0: loss = 1.15742 (* 1 = 1.15742 loss)
I0520 17:13:35.733577 25100 sgd_solver.cpp:106] Iteration 83625, lr = 0.0015
I0520 17:13:45.612079 25100 solver.cpp:237] Iteration 84000, loss = 1.47162
I0520 17:13:45.612113 25100 solver.cpp:253]     Train net output #0: loss = 1.47162 (* 1 = 1.47162 loss)
I0520 17:13:45.612131 25100 sgd_solver.cpp:106] Iteration 84000, lr = 0.0015
I0520 17:13:55.492840 25100 solver.cpp:237] Iteration 84375, loss = 1.35108
I0520 17:13:55.493006 25100 solver.cpp:253]     Train net output #0: loss = 1.35108 (* 1 = 1.35108 loss)
I0520 17:13:55.493021 25100 sgd_solver.cpp:106] Iteration 84375, lr = 0.0015
I0520 17:14:05.365737 25100 solver.cpp:237] Iteration 84750, loss = 1.09942
I0520 17:14:05.365772 25100 solver.cpp:253]     Train net output #0: loss = 1.09942 (* 1 = 1.09942 loss)
I0520 17:14:05.365790 25100 sgd_solver.cpp:106] Iteration 84750, lr = 0.0015
I0520 17:14:36.131397 25100 solver.cpp:237] Iteration 85125, loss = 1.14679
I0520 17:14:36.131582 25100 solver.cpp:253]     Train net output #0: loss = 1.14679 (* 1 = 1.14679 loss)
I0520 17:14:36.131597 25100 sgd_solver.cpp:106] Iteration 85125, lr = 0.0015
I0520 17:14:46.015707 25100 solver.cpp:237] Iteration 85500, loss = 1.03057
I0520 17:14:46.015754 25100 solver.cpp:253]     Train net output #0: loss = 1.03057 (* 1 = 1.03057 loss)
I0520 17:14:46.015774 25100 sgd_solver.cpp:106] Iteration 85500, lr = 0.0015
I0520 17:14:55.899261 25100 solver.cpp:237] Iteration 85875, loss = 1.3934
I0520 17:14:55.899297 25100 solver.cpp:253]     Train net output #0: loss = 1.3934 (* 1 = 1.3934 loss)
I0520 17:14:55.899314 25100 sgd_solver.cpp:106] Iteration 85875, lr = 0.0015
I0520 17:15:05.755422 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_86250.caffemodel
I0520 17:15:05.811549 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_86250.solverstate
I0520 17:15:05.845865 25100 solver.cpp:237] Iteration 86250, loss = 1.16011
I0520 17:15:05.845914 25100 solver.cpp:253]     Train net output #0: loss = 1.16011 (* 1 = 1.16011 loss)
I0520 17:15:05.845930 25100 sgd_solver.cpp:106] Iteration 86250, lr = 0.0015
I0520 17:15:15.731016 25100 solver.cpp:237] Iteration 86625, loss = 1.1751
I0520 17:15:15.731178 25100 solver.cpp:253]     Train net output #0: loss = 1.1751 (* 1 = 1.1751 loss)
I0520 17:15:15.731192 25100 sgd_solver.cpp:106] Iteration 86625, lr = 0.0015
I0520 17:15:25.614243 25100 solver.cpp:237] Iteration 87000, loss = 1.26072
I0520 17:15:25.614279 25100 solver.cpp:253]     Train net output #0: loss = 1.26072 (* 1 = 1.26072 loss)
I0520 17:15:25.614296 25100 sgd_solver.cpp:106] Iteration 87000, lr = 0.0015
I0520 17:15:35.495384 25100 solver.cpp:237] Iteration 87375, loss = 1.45765
I0520 17:15:35.495424 25100 solver.cpp:253]     Train net output #0: loss = 1.45765 (* 1 = 1.45765 loss)
I0520 17:15:35.495442 25100 sgd_solver.cpp:106] Iteration 87375, lr = 0.0015
I0520 17:16:06.236385 25100 solver.cpp:237] Iteration 87750, loss = 1.43971
I0520 17:16:06.236569 25100 solver.cpp:253]     Train net output #0: loss = 1.43971 (* 1 = 1.43971 loss)
I0520 17:16:06.236584 25100 sgd_solver.cpp:106] Iteration 87750, lr = 0.0015
I0520 17:16:16.118692 25100 solver.cpp:237] Iteration 88125, loss = 1.06021
I0520 17:16:16.118728 25100 solver.cpp:253]     Train net output #0: loss = 1.06021 (* 1 = 1.06021 loss)
I0520 17:16:16.118746 25100 sgd_solver.cpp:106] Iteration 88125, lr = 0.0015
I0520 17:16:26.033546 25100 solver.cpp:237] Iteration 88500, loss = 0.950032
I0520 17:16:26.033602 25100 solver.cpp:253]     Train net output #0: loss = 0.950032 (* 1 = 0.950032 loss)
I0520 17:16:26.033617 25100 sgd_solver.cpp:106] Iteration 88500, lr = 0.0015
I0520 17:16:35.952177 25100 solver.cpp:237] Iteration 88875, loss = 1.13868
I0520 17:16:35.952213 25100 solver.cpp:253]     Train net output #0: loss = 1.13868 (* 1 = 1.13868 loss)
I0520 17:16:35.952229 25100 sgd_solver.cpp:106] Iteration 88875, lr = 0.0015
I0520 17:16:45.877287 25100 solver.cpp:237] Iteration 89250, loss = 1.1643
I0520 17:16:45.877471 25100 solver.cpp:253]     Train net output #0: loss = 1.1643 (* 1 = 1.1643 loss)
I0520 17:16:45.877485 25100 sgd_solver.cpp:106] Iteration 89250, lr = 0.0015
I0520 17:16:55.804786 25100 solver.cpp:237] Iteration 89625, loss = 0.842254
I0520 17:16:55.804822 25100 solver.cpp:253]     Train net output #0: loss = 0.842254 (* 1 = 0.842254 loss)
I0520 17:16:55.804839 25100 sgd_solver.cpp:106] Iteration 89625, lr = 0.0015
I0520 17:17:05.700799 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_90000.caffemodel
I0520 17:17:05.757786 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_90000.solverstate
I0520 17:17:05.783660 25100 solver.cpp:341] Iteration 90000, Testing net (#0)
I0520 17:18:15.222254 25100 solver.cpp:409]     Test net output #0: accuracy = 0.881746
I0520 17:18:15.222432 25100 solver.cpp:409]     Test net output #1: loss = 0.383004 (* 1 = 0.383004 loss)
I0520 17:18:36.141054 25100 solver.cpp:237] Iteration 90000, loss = 1.40837
I0520 17:18:36.141113 25100 solver.cpp:253]     Train net output #0: loss = 1.40837 (* 1 = 1.40837 loss)
I0520 17:18:36.141129 25100 sgd_solver.cpp:106] Iteration 90000, lr = 0.0015
I0520 17:18:45.891577 25100 solver.cpp:237] Iteration 90375, loss = 1.12977
I0520 17:18:45.891752 25100 solver.cpp:253]     Train net output #0: loss = 1.12977 (* 1 = 1.12977 loss)
I0520 17:18:45.891767 25100 sgd_solver.cpp:106] Iteration 90375, lr = 0.0015
I0520 17:18:55.639369 25100 solver.cpp:237] Iteration 90750, loss = 1.58367
I0520 17:18:55.639421 25100 solver.cpp:253]     Train net output #0: loss = 1.58367 (* 1 = 1.58367 loss)
I0520 17:18:55.639438 25100 sgd_solver.cpp:106] Iteration 90750, lr = 0.0015
I0520 17:19:05.381248 25100 solver.cpp:237] Iteration 91125, loss = 1.15556
I0520 17:19:05.381283 25100 solver.cpp:253]     Train net output #0: loss = 1.15556 (* 1 = 1.15556 loss)
I0520 17:19:05.381299 25100 sgd_solver.cpp:106] Iteration 91125, lr = 0.0015
I0520 17:19:15.127303 25100 solver.cpp:237] Iteration 91500, loss = 1.23167
I0520 17:19:15.127346 25100 solver.cpp:253]     Train net output #0: loss = 1.23167 (* 1 = 1.23167 loss)
I0520 17:19:15.127364 25100 sgd_solver.cpp:106] Iteration 91500, lr = 0.0015
I0520 17:19:24.875419 25100 solver.cpp:237] Iteration 91875, loss = 1.15079
I0520 17:19:24.875591 25100 solver.cpp:253]     Train net output #0: loss = 1.15079 (* 1 = 1.15079 loss)
I0520 17:19:24.875605 25100 sgd_solver.cpp:106] Iteration 91875, lr = 0.0015
I0520 17:19:34.616425 25100 solver.cpp:237] Iteration 92250, loss = 1.37443
I0520 17:19:34.616459 25100 solver.cpp:253]     Train net output #0: loss = 1.37443 (* 1 = 1.37443 loss)
I0520 17:19:34.616478 25100 sgd_solver.cpp:106] Iteration 92250, lr = 0.0015
I0520 17:20:05.278352 25100 solver.cpp:237] Iteration 92625, loss = 1.11205
I0520 17:20:05.278547 25100 solver.cpp:253]     Train net output #0: loss = 1.11205 (* 1 = 1.11205 loss)
I0520 17:20:05.278561 25100 sgd_solver.cpp:106] Iteration 92625, lr = 0.0015
I0520 17:20:15.033767 25100 solver.cpp:237] Iteration 93000, loss = 1.25614
I0520 17:20:15.033802 25100 solver.cpp:253]     Train net output #0: loss = 1.25614 (* 1 = 1.25614 loss)
I0520 17:20:15.033820 25100 sgd_solver.cpp:106] Iteration 93000, lr = 0.0015
I0520 17:20:24.782500 25100 solver.cpp:237] Iteration 93375, loss = 0.894777
I0520 17:20:24.782536 25100 solver.cpp:253]     Train net output #0: loss = 0.894777 (* 1 = 0.894777 loss)
I0520 17:20:24.782553 25100 sgd_solver.cpp:106] Iteration 93375, lr = 0.0015
I0520 17:20:34.507175 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_93750.caffemodel
I0520 17:20:34.564808 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_93750.solverstate
I0520 17:20:34.601394 25100 solver.cpp:237] Iteration 93750, loss = 1.25079
I0520 17:20:34.601449 25100 solver.cpp:253]     Train net output #0: loss = 1.25079 (* 1 = 1.25079 loss)
I0520 17:20:34.601462 25100 sgd_solver.cpp:106] Iteration 93750, lr = 0.0015
I0520 17:20:44.349031 25100 solver.cpp:237] Iteration 94125, loss = 1.08908
I0520 17:20:44.349208 25100 solver.cpp:253]     Train net output #0: loss = 1.08908 (* 1 = 1.08908 loss)
I0520 17:20:44.349222 25100 sgd_solver.cpp:106] Iteration 94125, lr = 0.0015
I0520 17:20:54.097797 25100 solver.cpp:237] Iteration 94500, loss = 1.40959
I0520 17:20:54.097849 25100 solver.cpp:253]     Train net output #0: loss = 1.40959 (* 1 = 1.40959 loss)
I0520 17:20:54.097863 25100 sgd_solver.cpp:106] Iteration 94500, lr = 0.0015
I0520 17:21:03.853234 25100 solver.cpp:237] Iteration 94875, loss = 1.2383
I0520 17:21:03.853269 25100 solver.cpp:253]     Train net output #0: loss = 1.2383 (* 1 = 1.2383 loss)
I0520 17:21:03.853286 25100 sgd_solver.cpp:106] Iteration 94875, lr = 0.0015
I0520 17:21:34.497498 25100 solver.cpp:237] Iteration 95250, loss = 1.09373
I0520 17:21:34.497684 25100 solver.cpp:253]     Train net output #0: loss = 1.09373 (* 1 = 1.09373 loss)
I0520 17:21:34.497699 25100 sgd_solver.cpp:106] Iteration 95250, lr = 0.0015
I0520 17:21:44.244518 25100 solver.cpp:237] Iteration 95625, loss = 0.994055
I0520 17:21:44.244573 25100 solver.cpp:253]     Train net output #0: loss = 0.994055 (* 1 = 0.994055 loss)
I0520 17:21:44.244588 25100 sgd_solver.cpp:106] Iteration 95625, lr = 0.0015
I0520 17:21:54.038678 25100 solver.cpp:237] Iteration 96000, loss = 1.21078
I0520 17:21:54.038714 25100 solver.cpp:253]     Train net output #0: loss = 1.21078 (* 1 = 1.21078 loss)
I0520 17:21:54.038729 25100 sgd_solver.cpp:106] Iteration 96000, lr = 0.0015
I0520 17:22:03.824750 25100 solver.cpp:237] Iteration 96375, loss = 1.09383
I0520 17:22:03.824786 25100 solver.cpp:253]     Train net output #0: loss = 1.09383 (* 1 = 1.09383 loss)
I0520 17:22:03.824803 25100 sgd_solver.cpp:106] Iteration 96375, lr = 0.0015
I0520 17:22:13.616240 25100 solver.cpp:237] Iteration 96750, loss = 1.07016
I0520 17:22:13.616412 25100 solver.cpp:253]     Train net output #0: loss = 1.07016 (* 1 = 1.07016 loss)
I0520 17:22:13.616426 25100 sgd_solver.cpp:106] Iteration 96750, lr = 0.0015
I0520 17:22:23.406724 25100 solver.cpp:237] Iteration 97125, loss = 0.972128
I0520 17:22:23.406759 25100 solver.cpp:253]     Train net output #0: loss = 0.972128 (* 1 = 0.972128 loss)
I0520 17:22:23.406775 25100 sgd_solver.cpp:106] Iteration 97125, lr = 0.0015
I0520 17:22:33.176954 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_97500.caffemodel
I0520 17:22:33.233006 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_97500.solverstate
I0520 17:22:33.259057 25100 solver.cpp:341] Iteration 97500, Testing net (#0)
I0520 17:23:21.828055 25100 solver.cpp:409]     Test net output #0: accuracy = 0.882493
I0520 17:23:21.828248 25100 solver.cpp:409]     Test net output #1: loss = 0.35909 (* 1 = 0.35909 loss)
I0520 17:23:42.699973 25100 solver.cpp:237] Iteration 97500, loss = 0.857993
I0520 17:23:42.700029 25100 solver.cpp:253]     Train net output #0: loss = 0.857993 (* 1 = 0.857993 loss)
I0520 17:23:42.700044 25100 sgd_solver.cpp:106] Iteration 97500, lr = 0.0015
I0520 17:23:52.424832 25100 solver.cpp:237] Iteration 97875, loss = 1.11654
I0520 17:23:52.425014 25100 solver.cpp:253]     Train net output #0: loss = 1.11654 (* 1 = 1.11654 loss)
I0520 17:23:52.425027 25100 sgd_solver.cpp:106] Iteration 97875, lr = 0.0015
I0520 17:24:02.141454 25100 solver.cpp:237] Iteration 98250, loss = 0.95773
I0520 17:24:02.141491 25100 solver.cpp:253]     Train net output #0: loss = 0.95773 (* 1 = 0.95773 loss)
I0520 17:24:02.141507 25100 sgd_solver.cpp:106] Iteration 98250, lr = 0.0015
I0520 17:24:11.863077 25100 solver.cpp:237] Iteration 98625, loss = 1.49772
I0520 17:24:11.863112 25100 solver.cpp:253]     Train net output #0: loss = 1.49772 (* 1 = 1.49772 loss)
I0520 17:24:11.863131 25100 sgd_solver.cpp:106] Iteration 98625, lr = 0.0015
I0520 17:24:21.586693 25100 solver.cpp:237] Iteration 99000, loss = 1.30171
I0520 17:24:21.586740 25100 solver.cpp:253]     Train net output #0: loss = 1.30171 (* 1 = 1.30171 loss)
I0520 17:24:21.586758 25100 sgd_solver.cpp:106] Iteration 99000, lr = 0.0015
I0520 17:24:31.310163 25100 solver.cpp:237] Iteration 99375, loss = 1.27112
I0520 17:24:31.310326 25100 solver.cpp:253]     Train net output #0: loss = 1.27112 (* 1 = 1.27112 loss)
I0520 17:24:31.310341 25100 sgd_solver.cpp:106] Iteration 99375, lr = 0.0015
I0520 17:24:41.034627 25100 solver.cpp:237] Iteration 99750, loss = 0.769701
I0520 17:24:41.034675 25100 solver.cpp:253]     Train net output #0: loss = 0.769701 (* 1 = 0.769701 loss)
I0520 17:24:41.034693 25100 sgd_solver.cpp:106] Iteration 99750, lr = 0.0015
I0520 17:25:11.654798 25100 solver.cpp:237] Iteration 100125, loss = 1.19892
I0520 17:25:11.654983 25100 solver.cpp:253]     Train net output #0: loss = 1.19892 (* 1 = 1.19892 loss)
I0520 17:25:11.654999 25100 sgd_solver.cpp:106] Iteration 100125, lr = 0.0015
I0520 17:25:21.374131 25100 solver.cpp:237] Iteration 100500, loss = 1.0349
I0520 17:25:21.374166 25100 solver.cpp:253]     Train net output #0: loss = 1.0349 (* 1 = 1.0349 loss)
I0520 17:25:21.374183 25100 sgd_solver.cpp:106] Iteration 100500, lr = 0.0015
I0520 17:25:31.088909 25100 solver.cpp:237] Iteration 100875, loss = 0.942397
I0520 17:25:31.088960 25100 solver.cpp:253]     Train net output #0: loss = 0.942397 (* 1 = 0.942397 loss)
I0520 17:25:31.088979 25100 sgd_solver.cpp:106] Iteration 100875, lr = 0.0015
I0520 17:25:40.786700 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_101250.caffemodel
I0520 17:25:40.842483 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_101250.solverstate
I0520 17:25:40.875705 25100 solver.cpp:237] Iteration 101250, loss = 0.908508
I0520 17:25:40.875754 25100 solver.cpp:253]     Train net output #0: loss = 0.908508 (* 1 = 0.908508 loss)
I0520 17:25:40.875771 25100 sgd_solver.cpp:106] Iteration 101250, lr = 0.0015
I0520 17:25:50.606097 25100 solver.cpp:237] Iteration 101625, loss = 1.26005
I0520 17:25:50.606261 25100 solver.cpp:253]     Train net output #0: loss = 1.26005 (* 1 = 1.26005 loss)
I0520 17:25:50.606273 25100 sgd_solver.cpp:106] Iteration 101625, lr = 0.0015
I0520 17:26:00.328261 25100 solver.cpp:237] Iteration 102000, loss = 1.16732
I0520 17:26:00.328305 25100 solver.cpp:253]     Train net output #0: loss = 1.16732 (* 1 = 1.16732 loss)
I0520 17:26:00.328328 25100 sgd_solver.cpp:106] Iteration 102000, lr = 0.0015
I0520 17:26:10.047814 25100 solver.cpp:237] Iteration 102375, loss = 1.25986
I0520 17:26:10.047850 25100 solver.cpp:253]     Train net output #0: loss = 1.25986 (* 1 = 1.25986 loss)
I0520 17:26:10.047863 25100 sgd_solver.cpp:106] Iteration 102375, lr = 0.0015
I0520 17:26:40.658367 25100 solver.cpp:237] Iteration 102750, loss = 1.30283
I0520 17:26:40.658566 25100 solver.cpp:253]     Train net output #0: loss = 1.30283 (* 1 = 1.30283 loss)
I0520 17:26:40.658581 25100 sgd_solver.cpp:106] Iteration 102750, lr = 0.0015
I0520 17:26:50.379624 25100 solver.cpp:237] Iteration 103125, loss = 1.38181
I0520 17:26:50.379680 25100 solver.cpp:253]     Train net output #0: loss = 1.38181 (* 1 = 1.38181 loss)
I0520 17:26:50.379696 25100 sgd_solver.cpp:106] Iteration 103125, lr = 0.0015
I0520 17:27:00.103579 25100 solver.cpp:237] Iteration 103500, loss = 1.37115
I0520 17:27:00.103615 25100 solver.cpp:253]     Train net output #0: loss = 1.37115 (* 1 = 1.37115 loss)
I0520 17:27:00.103629 25100 sgd_solver.cpp:106] Iteration 103500, lr = 0.0015
I0520 17:27:09.824173 25100 solver.cpp:237] Iteration 103875, loss = 1.25284
I0520 17:27:09.824219 25100 solver.cpp:253]     Train net output #0: loss = 1.25284 (* 1 = 1.25284 loss)
I0520 17:27:09.824240 25100 sgd_solver.cpp:106] Iteration 103875, lr = 0.0015
I0520 17:27:19.554738 25100 solver.cpp:237] Iteration 104250, loss = 1.01291
I0520 17:27:19.554905 25100 solver.cpp:253]     Train net output #0: loss = 1.01291 (* 1 = 1.01291 loss)
I0520 17:27:19.554919 25100 sgd_solver.cpp:106] Iteration 104250, lr = 0.0015
I0520 17:27:29.278314 25100 solver.cpp:237] Iteration 104625, loss = 1.38251
I0520 17:27:29.278348 25100 solver.cpp:253]     Train net output #0: loss = 1.38251 (* 1 = 1.38251 loss)
I0520 17:27:29.278365 25100 sgd_solver.cpp:106] Iteration 104625, lr = 0.0015
I0520 17:27:38.977946 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_105000.caffemodel
I0520 17:27:39.033000 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_105000.solverstate
I0520 17:27:39.057813 25100 solver.cpp:341] Iteration 105000, Testing net (#0)
I0520 17:28:48.553957 25100 solver.cpp:409]     Test net output #0: accuracy = 0.885488
I0520 17:28:48.554143 25100 solver.cpp:409]     Test net output #1: loss = 0.35906 (* 1 = 0.35906 loss)
I0520 17:29:09.432651 25100 solver.cpp:237] Iteration 105000, loss = 1.32724
I0520 17:29:09.432708 25100 solver.cpp:253]     Train net output #0: loss = 1.32724 (* 1 = 1.32724 loss)
I0520 17:29:09.432723 25100 sgd_solver.cpp:106] Iteration 105000, lr = 0.0015
I0520 17:29:19.217440 25100 solver.cpp:237] Iteration 105375, loss = 1.27761
I0520 17:29:19.217628 25100 solver.cpp:253]     Train net output #0: loss = 1.27761 (* 1 = 1.27761 loss)
I0520 17:29:19.217643 25100 sgd_solver.cpp:106] Iteration 105375, lr = 0.0015
I0520 17:29:29.006522 25100 solver.cpp:237] Iteration 105750, loss = 1.3382
I0520 17:29:29.006557 25100 solver.cpp:253]     Train net output #0: loss = 1.3382 (* 1 = 1.3382 loss)
I0520 17:29:29.006572 25100 sgd_solver.cpp:106] Iteration 105750, lr = 0.0015
I0520 17:29:38.791280 25100 solver.cpp:237] Iteration 106125, loss = 0.953092
I0520 17:29:38.791323 25100 solver.cpp:253]     Train net output #0: loss = 0.953092 (* 1 = 0.953092 loss)
I0520 17:29:38.791338 25100 sgd_solver.cpp:106] Iteration 106125, lr = 0.0015
I0520 17:29:48.583341 25100 solver.cpp:237] Iteration 106500, loss = 1.42169
I0520 17:29:48.583376 25100 solver.cpp:253]     Train net output #0: loss = 1.42169 (* 1 = 1.42169 loss)
I0520 17:29:48.583395 25100 sgd_solver.cpp:106] Iteration 106500, lr = 0.0015
I0520 17:29:58.368335 25100 solver.cpp:237] Iteration 106875, loss = 0.887477
I0520 17:29:58.368495 25100 solver.cpp:253]     Train net output #0: loss = 0.887477 (* 1 = 0.887477 loss)
I0520 17:29:58.368508 25100 sgd_solver.cpp:106] Iteration 106875, lr = 0.0015
I0520 17:30:08.156755 25100 solver.cpp:237] Iteration 107250, loss = 1.22232
I0520 17:30:08.156807 25100 solver.cpp:253]     Train net output #0: loss = 1.22232 (* 1 = 1.22232 loss)
I0520 17:30:08.156823 25100 sgd_solver.cpp:106] Iteration 107250, lr = 0.0015
I0520 17:30:38.791918 25100 solver.cpp:237] Iteration 107625, loss = 1.36919
I0520 17:30:38.792117 25100 solver.cpp:253]     Train net output #0: loss = 1.36919 (* 1 = 1.36919 loss)
I0520 17:30:38.792134 25100 sgd_solver.cpp:106] Iteration 107625, lr = 0.0015
I0520 17:30:48.583953 25100 solver.cpp:237] Iteration 108000, loss = 1.31617
I0520 17:30:48.583988 25100 solver.cpp:253]     Train net output #0: loss = 1.31617 (* 1 = 1.31617 loss)
I0520 17:30:48.584007 25100 sgd_solver.cpp:106] Iteration 108000, lr = 0.0015
I0520 17:30:58.371495 25100 solver.cpp:237] Iteration 108375, loss = 1.31741
I0520 17:30:58.371546 25100 solver.cpp:253]     Train net output #0: loss = 1.31741 (* 1 = 1.31741 loss)
I0520 17:30:58.371558 25100 sgd_solver.cpp:106] Iteration 108375, lr = 0.0015
I0520 17:31:08.139408 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_108750.caffemodel
I0520 17:31:08.198073 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_108750.solverstate
I0520 17:31:08.233239 25100 solver.cpp:237] Iteration 108750, loss = 1.55458
I0520 17:31:08.233291 25100 solver.cpp:253]     Train net output #0: loss = 1.55458 (* 1 = 1.55458 loss)
I0520 17:31:08.233306 25100 sgd_solver.cpp:106] Iteration 108750, lr = 0.0015
I0520 17:31:18.024272 25100 solver.cpp:237] Iteration 109125, loss = 1.42646
I0520 17:31:18.024442 25100 solver.cpp:253]     Train net output #0: loss = 1.42646 (* 1 = 1.42646 loss)
I0520 17:31:18.024456 25100 sgd_solver.cpp:106] Iteration 109125, lr = 0.0015
I0520 17:31:27.819824 25100 solver.cpp:237] Iteration 109500, loss = 1.13536
I0520 17:31:27.819875 25100 solver.cpp:253]     Train net output #0: loss = 1.13536 (* 1 = 1.13536 loss)
I0520 17:31:27.819891 25100 sgd_solver.cpp:106] Iteration 109500, lr = 0.0015
I0520 17:31:37.609385 25100 solver.cpp:237] Iteration 109875, loss = 1.01982
I0520 17:31:37.609421 25100 solver.cpp:253]     Train net output #0: loss = 1.01982 (* 1 = 1.01982 loss)
I0520 17:31:37.609437 25100 sgd_solver.cpp:106] Iteration 109875, lr = 0.0015
I0520 17:32:08.285445 25100 solver.cpp:237] Iteration 110250, loss = 1.31012
I0520 17:32:08.285635 25100 solver.cpp:253]     Train net output #0: loss = 1.31012 (* 1 = 1.31012 loss)
I0520 17:32:08.285651 25100 sgd_solver.cpp:106] Iteration 110250, lr = 0.0015
I0520 17:32:18.076664 25100 solver.cpp:237] Iteration 110625, loss = 1.3392
I0520 17:32:18.076710 25100 solver.cpp:253]     Train net output #0: loss = 1.3392 (* 1 = 1.3392 loss)
I0520 17:32:18.076730 25100 sgd_solver.cpp:106] Iteration 110625, lr = 0.0015
I0520 17:32:27.876626 25100 solver.cpp:237] Iteration 111000, loss = 1.19284
I0520 17:32:27.876662 25100 solver.cpp:253]     Train net output #0: loss = 1.19284 (* 1 = 1.19284 loss)
I0520 17:32:27.876678 25100 sgd_solver.cpp:106] Iteration 111000, lr = 0.0015
I0520 17:32:37.672351 25100 solver.cpp:237] Iteration 111375, loss = 1.25426
I0520 17:32:37.672401 25100 solver.cpp:253]     Train net output #0: loss = 1.25426 (* 1 = 1.25426 loss)
I0520 17:32:37.672418 25100 sgd_solver.cpp:106] Iteration 111375, lr = 0.0015
I0520 17:32:47.463227 25100 solver.cpp:237] Iteration 111750, loss = 1.32374
I0520 17:32:47.463392 25100 solver.cpp:253]     Train net output #0: loss = 1.32374 (* 1 = 1.32374 loss)
I0520 17:32:47.463404 25100 sgd_solver.cpp:106] Iteration 111750, lr = 0.0015
I0520 17:32:57.258595 25100 solver.cpp:237] Iteration 112125, loss = 1.0936
I0520 17:32:57.258630 25100 solver.cpp:253]     Train net output #0: loss = 1.0936 (* 1 = 1.0936 loss)
I0520 17:32:57.258647 25100 sgd_solver.cpp:106] Iteration 112125, lr = 0.0015
I0520 17:33:07.029775 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_112500.caffemodel
I0520 17:33:07.088037 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_112500.solverstate
I0520 17:33:07.115303 25100 solver.cpp:341] Iteration 112500, Testing net (#0)
I0520 17:33:55.305168 25100 solver.cpp:409]     Test net output #0: accuracy = 0.887232
I0520 17:33:55.305366 25100 solver.cpp:409]     Test net output #1: loss = 0.379953 (* 1 = 0.379953 loss)
I0520 17:34:16.221021 25100 solver.cpp:237] Iteration 112500, loss = 1.23663
I0520 17:34:16.221077 25100 solver.cpp:253]     Train net output #0: loss = 1.23663 (* 1 = 1.23663 loss)
I0520 17:34:16.221094 25100 sgd_solver.cpp:106] Iteration 112500, lr = 0.0015
I0520 17:34:25.937854 25100 solver.cpp:237] Iteration 112875, loss = 1.04482
I0520 17:34:25.938021 25100 solver.cpp:253]     Train net output #0: loss = 1.04482 (* 1 = 1.04482 loss)
I0520 17:34:25.938035 25100 sgd_solver.cpp:106] Iteration 112875, lr = 0.0015
I0520 17:34:35.658238 25100 solver.cpp:237] Iteration 113250, loss = 1.12574
I0520 17:34:35.658273 25100 solver.cpp:253]     Train net output #0: loss = 1.12574 (* 1 = 1.12574 loss)
I0520 17:34:35.658290 25100 sgd_solver.cpp:106] Iteration 113250, lr = 0.0015
I0520 17:34:45.370918 25100 solver.cpp:237] Iteration 113625, loss = 0.828738
I0520 17:34:45.370962 25100 solver.cpp:253]     Train net output #0: loss = 0.828738 (* 1 = 0.828738 loss)
I0520 17:34:45.370985 25100 sgd_solver.cpp:106] Iteration 113625, lr = 0.0015
I0520 17:34:55.086108 25100 solver.cpp:237] Iteration 114000, loss = 1.04218
I0520 17:34:55.086143 25100 solver.cpp:253]     Train net output #0: loss = 1.04218 (* 1 = 1.04218 loss)
I0520 17:34:55.086160 25100 sgd_solver.cpp:106] Iteration 114000, lr = 0.0015
I0520 17:35:04.787832 25100 solver.cpp:237] Iteration 114375, loss = 1.21608
I0520 17:35:04.788020 25100 solver.cpp:253]     Train net output #0: loss = 1.21608 (* 1 = 1.21608 loss)
I0520 17:35:04.788034 25100 sgd_solver.cpp:106] Iteration 114375, lr = 0.0015
I0520 17:35:14.488517 25100 solver.cpp:237] Iteration 114750, loss = 1.26801
I0520 17:35:14.488550 25100 solver.cpp:253]     Train net output #0: loss = 1.26801 (* 1 = 1.26801 loss)
I0520 17:35:14.488569 25100 sgd_solver.cpp:106] Iteration 114750, lr = 0.0015
I0520 17:35:45.044416 25100 solver.cpp:237] Iteration 115125, loss = 0.971172
I0520 17:35:45.044608 25100 solver.cpp:253]     Train net output #0: loss = 0.971172 (* 1 = 0.971172 loss)
I0520 17:35:45.044623 25100 sgd_solver.cpp:106] Iteration 115125, lr = 0.0015
I0520 17:35:54.737431 25100 solver.cpp:237] Iteration 115500, loss = 1.33454
I0520 17:35:54.737474 25100 solver.cpp:253]     Train net output #0: loss = 1.33454 (* 1 = 1.33454 loss)
I0520 17:35:54.737498 25100 sgd_solver.cpp:106] Iteration 115500, lr = 0.0015
I0520 17:36:04.443061 25100 solver.cpp:237] Iteration 115875, loss = 1.71002
I0520 17:36:04.443096 25100 solver.cpp:253]     Train net output #0: loss = 1.71002 (* 1 = 1.71002 loss)
I0520 17:36:04.443110 25100 sgd_solver.cpp:106] Iteration 115875, lr = 0.0015
I0520 17:36:14.129694 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_116250.caffemodel
I0520 17:36:14.185390 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_116250.solverstate
I0520 17:36:14.218492 25100 solver.cpp:237] Iteration 116250, loss = 1.05563
I0520 17:36:14.218536 25100 solver.cpp:253]     Train net output #0: loss = 1.05563 (* 1 = 1.05563 loss)
I0520 17:36:14.218551 25100 sgd_solver.cpp:106] Iteration 116250, lr = 0.0015
I0520 17:36:23.927829 25100 solver.cpp:237] Iteration 116625, loss = 1.15036
I0520 17:36:23.928020 25100 solver.cpp:253]     Train net output #0: loss = 1.15036 (* 1 = 1.15036 loss)
I0520 17:36:23.928035 25100 sgd_solver.cpp:106] Iteration 116625, lr = 0.0015
I0520 17:36:33.639433 25100 solver.cpp:237] Iteration 117000, loss = 1.11422
I0520 17:36:33.639468 25100 solver.cpp:253]     Train net output #0: loss = 1.11422 (* 1 = 1.11422 loss)
I0520 17:36:33.639487 25100 sgd_solver.cpp:106] Iteration 117000, lr = 0.0015
I0520 17:36:43.350980 25100 solver.cpp:237] Iteration 117375, loss = 1.38481
I0520 17:36:43.351016 25100 solver.cpp:253]     Train net output #0: loss = 1.38481 (* 1 = 1.38481 loss)
I0520 17:36:43.351029 25100 sgd_solver.cpp:106] Iteration 117375, lr = 0.0015
I0520 17:37:13.917819 25100 solver.cpp:237] Iteration 117750, loss = 1.09201
I0520 17:37:13.918017 25100 solver.cpp:253]     Train net output #0: loss = 1.09201 (* 1 = 1.09201 loss)
I0520 17:37:13.918033 25100 sgd_solver.cpp:106] Iteration 117750, lr = 0.0015
I0520 17:37:23.630178 25100 solver.cpp:237] Iteration 118125, loss = 0.998458
I0520 17:37:23.630215 25100 solver.cpp:253]     Train net output #0: loss = 0.998458 (* 1 = 0.998458 loss)
I0520 17:37:23.630233 25100 sgd_solver.cpp:106] Iteration 118125, lr = 0.0015
I0520 17:37:33.333725 25100 solver.cpp:237] Iteration 118500, loss = 1.08384
I0520 17:37:33.333761 25100 solver.cpp:253]     Train net output #0: loss = 1.08384 (* 1 = 1.08384 loss)
I0520 17:37:33.333778 25100 sgd_solver.cpp:106] Iteration 118500, lr = 0.0015
I0520 17:37:43.092500 25100 solver.cpp:237] Iteration 118875, loss = 1.29832
I0520 17:37:43.092550 25100 solver.cpp:253]     Train net output #0: loss = 1.29832 (* 1 = 1.29832 loss)
I0520 17:37:43.092567 25100 sgd_solver.cpp:106] Iteration 118875, lr = 0.0015
I0520 17:37:52.852394 25100 solver.cpp:237] Iteration 119250, loss = 1.30984
I0520 17:37:52.852566 25100 solver.cpp:253]     Train net output #0: loss = 1.30984 (* 1 = 1.30984 loss)
I0520 17:37:52.852579 25100 sgd_solver.cpp:106] Iteration 119250, lr = 0.0015
I0520 17:38:02.612202 25100 solver.cpp:237] Iteration 119625, loss = 1.28082
I0520 17:38:02.612253 25100 solver.cpp:253]     Train net output #0: loss = 1.28082 (* 1 = 1.28082 loss)
I0520 17:38:02.612269 25100 sgd_solver.cpp:106] Iteration 119625, lr = 0.0015
I0520 17:38:12.342852 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_120000.caffemodel
I0520 17:38:12.398416 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_120000.solverstate
I0520 17:38:12.423220 25100 solver.cpp:341] Iteration 120000, Testing net (#0)
I0520 17:39:21.869560 25100 solver.cpp:409]     Test net output #0: accuracy = 0.89
I0520 17:39:21.869753 25100 solver.cpp:409]     Test net output #1: loss = 0.343318 (* 1 = 0.343318 loss)
I0520 17:39:42.752586 25100 solver.cpp:237] Iteration 120000, loss = 0.912537
I0520 17:39:42.752643 25100 solver.cpp:253]     Train net output #0: loss = 0.912537 (* 1 = 0.912537 loss)
I0520 17:39:42.752661 25100 sgd_solver.cpp:106] Iteration 120000, lr = 0.0015
I0520 17:39:52.493897 25100 solver.cpp:237] Iteration 120375, loss = 1.05939
I0520 17:39:52.494071 25100 solver.cpp:253]     Train net output #0: loss = 1.05939 (* 1 = 1.05939 loss)
I0520 17:39:52.494084 25100 sgd_solver.cpp:106] Iteration 120375, lr = 0.0015
I0520 17:40:02.238641 25100 solver.cpp:237] Iteration 120750, loss = 1.2212
I0520 17:40:02.238675 25100 solver.cpp:253]     Train net output #0: loss = 1.2212 (* 1 = 1.2212 loss)
I0520 17:40:02.238692 25100 sgd_solver.cpp:106] Iteration 120750, lr = 0.0015
I0520 17:40:11.980900 25100 solver.cpp:237] Iteration 121125, loss = 1.2086
I0520 17:40:11.980944 25100 solver.cpp:253]     Train net output #0: loss = 1.2086 (* 1 = 1.2086 loss)
I0520 17:40:11.980965 25100 sgd_solver.cpp:106] Iteration 121125, lr = 0.0015
I0520 17:40:21.719059 25100 solver.cpp:237] Iteration 121500, loss = 1.21661
I0520 17:40:21.719094 25100 solver.cpp:253]     Train net output #0: loss = 1.21661 (* 1 = 1.21661 loss)
I0520 17:40:21.719111 25100 sgd_solver.cpp:106] Iteration 121500, lr = 0.0015
I0520 17:40:31.466866 25100 solver.cpp:237] Iteration 121875, loss = 1.0707
I0520 17:40:31.467061 25100 solver.cpp:253]     Train net output #0: loss = 1.0707 (* 1 = 1.0707 loss)
I0520 17:40:31.467075 25100 sgd_solver.cpp:106] Iteration 121875, lr = 0.0015
I0520 17:40:41.210592 25100 solver.cpp:237] Iteration 122250, loss = 0.764978
I0520 17:40:41.210628 25100 solver.cpp:253]     Train net output #0: loss = 0.764978 (* 1 = 0.764978 loss)
I0520 17:40:41.210644 25100 sgd_solver.cpp:106] Iteration 122250, lr = 0.0015
I0520 17:41:11.822571 25100 solver.cpp:237] Iteration 122625, loss = 1.48657
I0520 17:41:11.822767 25100 solver.cpp:253]     Train net output #0: loss = 1.48657 (* 1 = 1.48657 loss)
I0520 17:41:11.822782 25100 sgd_solver.cpp:106] Iteration 122625, lr = 0.0015
I0520 17:41:21.565861 25100 solver.cpp:237] Iteration 123000, loss = 1.18157
I0520 17:41:21.565904 25100 solver.cpp:253]     Train net output #0: loss = 1.18157 (* 1 = 1.18157 loss)
I0520 17:41:21.565922 25100 sgd_solver.cpp:106] Iteration 123000, lr = 0.0015
I0520 17:41:31.304636 25100 solver.cpp:237] Iteration 123375, loss = 1.39171
I0520 17:41:31.304672 25100 solver.cpp:253]     Train net output #0: loss = 1.39171 (* 1 = 1.39171 loss)
I0520 17:41:31.304687 25100 sgd_solver.cpp:106] Iteration 123375, lr = 0.0015
I0520 17:41:41.019071 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_123750.caffemodel
I0520 17:41:41.075227 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_123750.solverstate
I0520 17:41:41.108428 25100 solver.cpp:237] Iteration 123750, loss = 1.11758
I0520 17:41:41.108474 25100 solver.cpp:253]     Train net output #0: loss = 1.11758 (* 1 = 1.11758 loss)
I0520 17:41:41.108487 25100 sgd_solver.cpp:106] Iteration 123750, lr = 0.0015
I0520 17:41:50.850658 25100 solver.cpp:237] Iteration 124125, loss = 0.925807
I0520 17:41:50.850841 25100 solver.cpp:253]     Train net output #0: loss = 0.925807 (* 1 = 0.925807 loss)
I0520 17:41:50.850857 25100 sgd_solver.cpp:106] Iteration 124125, lr = 0.0015
I0520 17:42:00.598842 25100 solver.cpp:237] Iteration 124500, loss = 1.05045
I0520 17:42:00.598877 25100 solver.cpp:253]     Train net output #0: loss = 1.05045 (* 1 = 1.05045 loss)
I0520 17:42:00.598894 25100 sgd_solver.cpp:106] Iteration 124500, lr = 0.0015
I0520 17:42:10.340961 25100 solver.cpp:237] Iteration 124875, loss = 1.11975
I0520 17:42:10.341006 25100 solver.cpp:253]     Train net output #0: loss = 1.11975 (* 1 = 1.11975 loss)
I0520 17:42:10.341028 25100 sgd_solver.cpp:106] Iteration 124875, lr = 0.0015
I0520 17:42:40.971102 25100 solver.cpp:237] Iteration 125250, loss = 0.990429
I0520 17:42:40.971297 25100 solver.cpp:253]     Train net output #0: loss = 0.990429 (* 1 = 0.990429 loss)
I0520 17:42:40.971312 25100 sgd_solver.cpp:106] Iteration 125250, lr = 0.0015
I0520 17:42:50.723573 25100 solver.cpp:237] Iteration 125625, loss = 1.28695
I0520 17:42:50.723609 25100 solver.cpp:253]     Train net output #0: loss = 1.28695 (* 1 = 1.28695 loss)
I0520 17:42:50.723623 25100 sgd_solver.cpp:106] Iteration 125625, lr = 0.0015
I0520 17:43:00.472426 25100 solver.cpp:237] Iteration 126000, loss = 1.20882
I0520 17:43:00.472475 25100 solver.cpp:253]     Train net output #0: loss = 1.20882 (* 1 = 1.20882 loss)
I0520 17:43:00.472496 25100 sgd_solver.cpp:106] Iteration 126000, lr = 0.0015
I0520 17:43:10.210698 25100 solver.cpp:237] Iteration 126375, loss = 1.12598
I0520 17:43:10.210734 25100 solver.cpp:253]     Train net output #0: loss = 1.12598 (* 1 = 1.12598 loss)
I0520 17:43:10.210750 25100 sgd_solver.cpp:106] Iteration 126375, lr = 0.0015
I0520 17:43:19.957098 25100 solver.cpp:237] Iteration 126750, loss = 0.987567
I0520 17:43:19.957269 25100 solver.cpp:253]     Train net output #0: loss = 0.987567 (* 1 = 0.987567 loss)
I0520 17:43:19.957284 25100 sgd_solver.cpp:106] Iteration 126750, lr = 0.0015
I0520 17:43:29.705354 25100 solver.cpp:237] Iteration 127125, loss = 0.923771
I0520 17:43:29.705399 25100 solver.cpp:253]     Train net output #0: loss = 0.923771 (* 1 = 0.923771 loss)
I0520 17:43:29.705420 25100 sgd_solver.cpp:106] Iteration 127125, lr = 0.0015
I0520 17:43:39.427193 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_127500.caffemodel
I0520 17:43:39.483412 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_127500.solverstate
I0520 17:43:39.508275 25100 solver.cpp:341] Iteration 127500, Testing net (#0)
I0520 17:44:28.029697 25100 solver.cpp:409]     Test net output #0: accuracy = 0.89074
I0520 17:44:28.029897 25100 solver.cpp:409]     Test net output #1: loss = 0.37199 (* 1 = 0.37199 loss)
I0520 17:44:48.926614 25100 solver.cpp:237] Iteration 127500, loss = 1.20422
I0520 17:44:48.926671 25100 solver.cpp:253]     Train net output #0: loss = 1.20422 (* 1 = 1.20422 loss)
I0520 17:44:48.926687 25100 sgd_solver.cpp:106] Iteration 127500, lr = 0.0015
I0520 17:44:58.804666 25100 solver.cpp:237] Iteration 127875, loss = 0.953944
I0520 17:44:58.804841 25100 solver.cpp:253]     Train net output #0: loss = 0.953944 (* 1 = 0.953944 loss)
I0520 17:44:58.804855 25100 sgd_solver.cpp:106] Iteration 127875, lr = 0.0015
I0520 17:45:08.685111 25100 solver.cpp:237] Iteration 128250, loss = 1.28666
I0520 17:45:08.685154 25100 solver.cpp:253]     Train net output #0: loss = 1.28666 (* 1 = 1.28666 loss)
I0520 17:45:08.685175 25100 sgd_solver.cpp:106] Iteration 128250, lr = 0.0015
I0520 17:45:18.568142 25100 solver.cpp:237] Iteration 128625, loss = 0.934569
I0520 17:45:18.568178 25100 solver.cpp:253]     Train net output #0: loss = 0.934569 (* 1 = 0.934569 loss)
I0520 17:45:18.568194 25100 sgd_solver.cpp:106] Iteration 128625, lr = 0.0015
I0520 17:45:28.448583 25100 solver.cpp:237] Iteration 129000, loss = 1.19032
I0520 17:45:28.448619 25100 solver.cpp:253]     Train net output #0: loss = 1.19032 (* 1 = 1.19032 loss)
I0520 17:45:28.448637 25100 sgd_solver.cpp:106] Iteration 129000, lr = 0.0015
I0520 17:45:38.331351 25100 solver.cpp:237] Iteration 129375, loss = 1.1354
I0520 17:45:38.331539 25100 solver.cpp:253]     Train net output #0: loss = 1.1354 (* 1 = 1.1354 loss)
I0520 17:45:38.331553 25100 sgd_solver.cpp:106] Iteration 129375, lr = 0.0015
I0520 17:45:48.216297 25100 solver.cpp:237] Iteration 129750, loss = 1.4464
I0520 17:45:48.216331 25100 solver.cpp:253]     Train net output #0: loss = 1.4464 (* 1 = 1.4464 loss)
I0520 17:45:48.216348 25100 sgd_solver.cpp:106] Iteration 129750, lr = 0.0015
I0520 17:46:18.967324 25100 solver.cpp:237] Iteration 130125, loss = 1.26445
I0520 17:46:18.967512 25100 solver.cpp:253]     Train net output #0: loss = 1.26445 (* 1 = 1.26445 loss)
I0520 17:46:18.967527 25100 sgd_solver.cpp:106] Iteration 130125, lr = 0.0015
I0520 17:46:28.843587 25100 solver.cpp:237] Iteration 130500, loss = 1.14808
I0520 17:46:28.843622 25100 solver.cpp:253]     Train net output #0: loss = 1.14808 (* 1 = 1.14808 loss)
I0520 17:46:28.843641 25100 sgd_solver.cpp:106] Iteration 130500, lr = 0.0015
I0520 17:46:38.724859 25100 solver.cpp:237] Iteration 130875, loss = 1.02002
I0520 17:46:38.724895 25100 solver.cpp:253]     Train net output #0: loss = 1.02002 (* 1 = 1.02002 loss)
I0520 17:46:38.724913 25100 sgd_solver.cpp:106] Iteration 130875, lr = 0.0015
I0520 17:46:48.577138 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_131250.caffemodel
I0520 17:46:48.635613 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_131250.solverstate
I0520 17:46:48.671200 25100 solver.cpp:237] Iteration 131250, loss = 1.04561
I0520 17:46:48.671253 25100 solver.cpp:253]     Train net output #0: loss = 1.04561 (* 1 = 1.04561 loss)
I0520 17:46:48.671272 25100 sgd_solver.cpp:106] Iteration 131250, lr = 0.0015
I0520 17:46:58.556849 25100 solver.cpp:237] Iteration 131625, loss = 1.40924
I0520 17:46:58.557032 25100 solver.cpp:253]     Train net output #0: loss = 1.40924 (* 1 = 1.40924 loss)
I0520 17:46:58.557046 25100 sgd_solver.cpp:106] Iteration 131625, lr = 0.0015
I0520 17:47:08.440263 25100 solver.cpp:237] Iteration 132000, loss = 1.25724
I0520 17:47:08.440297 25100 solver.cpp:253]     Train net output #0: loss = 1.25724 (* 1 = 1.25724 loss)
I0520 17:47:08.440315 25100 sgd_solver.cpp:106] Iteration 132000, lr = 0.0015
I0520 17:47:18.324954 25100 solver.cpp:237] Iteration 132375, loss = 1.3268
I0520 17:47:18.324985 25100 solver.cpp:253]     Train net output #0: loss = 1.3268 (* 1 = 1.3268 loss)
I0520 17:47:18.325007 25100 sgd_solver.cpp:106] Iteration 132375, lr = 0.0015
I0520 17:47:49.093793 25100 solver.cpp:237] Iteration 132750, loss = 1.38719
I0520 17:47:49.093986 25100 solver.cpp:253]     Train net output #0: loss = 1.38719 (* 1 = 1.38719 loss)
I0520 17:47:49.094002 25100 sgd_solver.cpp:106] Iteration 132750, lr = 0.0015
I0520 17:47:58.967566 25100 solver.cpp:237] Iteration 133125, loss = 1.0154
I0520 17:47:58.967615 25100 solver.cpp:253]     Train net output #0: loss = 1.0154 (* 1 = 1.0154 loss)
I0520 17:47:58.967633 25100 sgd_solver.cpp:106] Iteration 133125, lr = 0.0015
I0520 17:48:08.853588 25100 solver.cpp:237] Iteration 133500, loss = 1.08796
I0520 17:48:08.853626 25100 solver.cpp:253]     Train net output #0: loss = 1.08796 (* 1 = 1.08796 loss)
I0520 17:48:08.853641 25100 sgd_solver.cpp:106] Iteration 133500, lr = 0.0015
I0520 17:48:18.741394 25100 solver.cpp:237] Iteration 133875, loss = 1.2337
I0520 17:48:18.741430 25100 solver.cpp:253]     Train net output #0: loss = 1.2337 (* 1 = 1.2337 loss)
I0520 17:48:18.741444 25100 sgd_solver.cpp:106] Iteration 133875, lr = 0.0015
I0520 17:48:28.610918 25100 solver.cpp:237] Iteration 134250, loss = 1.04942
I0520 17:48:28.611102 25100 solver.cpp:253]     Train net output #0: loss = 1.04942 (* 1 = 1.04942 loss)
I0520 17:48:28.611116 25100 sgd_solver.cpp:106] Iteration 134250, lr = 0.0015
I0520 17:48:38.485816 25100 solver.cpp:237] Iteration 134625, loss = 0.889087
I0520 17:48:38.485852 25100 solver.cpp:253]     Train net output #0: loss = 0.889087 (* 1 = 0.889087 loss)
I0520 17:48:38.485868 25100 sgd_solver.cpp:106] Iteration 134625, lr = 0.0015
I0520 17:48:48.340322 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_135000.caffemodel
I0520 17:48:48.398874 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_135000.solverstate
I0520 17:48:48.430245 25100 solver.cpp:341] Iteration 135000, Testing net (#0)
I0520 17:49:57.822139 25100 solver.cpp:409]     Test net output #0: accuracy = 0.894239
I0520 17:49:57.822334 25100 solver.cpp:409]     Test net output #1: loss = 0.329679 (* 1 = 0.329679 loss)
I0520 17:50:18.692749 25100 solver.cpp:237] Iteration 135000, loss = 0.676463
I0520 17:50:18.692806 25100 solver.cpp:253]     Train net output #0: loss = 0.676463 (* 1 = 0.676463 loss)
I0520 17:50:18.692821 25100 sgd_solver.cpp:106] Iteration 135000, lr = 0.0015
I0520 17:50:28.396091 25100 solver.cpp:237] Iteration 135375, loss = 1.04421
I0520 17:50:28.396266 25100 solver.cpp:253]     Train net output #0: loss = 1.04421 (* 1 = 1.04421 loss)
I0520 17:50:28.396281 25100 sgd_solver.cpp:106] Iteration 135375, lr = 0.0015
I0520 17:50:38.106526 25100 solver.cpp:237] Iteration 135750, loss = 0.98576
I0520 17:50:38.106573 25100 solver.cpp:253]     Train net output #0: loss = 0.98576 (* 1 = 0.98576 loss)
I0520 17:50:38.106590 25100 sgd_solver.cpp:106] Iteration 135750, lr = 0.0015
I0520 17:50:47.805502 25100 solver.cpp:237] Iteration 136125, loss = 1.34877
I0520 17:50:47.805538 25100 solver.cpp:253]     Train net output #0: loss = 1.34877 (* 1 = 1.34877 loss)
I0520 17:50:47.805552 25100 sgd_solver.cpp:106] Iteration 136125, lr = 0.0015
I0520 17:50:57.511554 25100 solver.cpp:237] Iteration 136500, loss = 1.33161
I0520 17:50:57.511600 25100 solver.cpp:253]     Train net output #0: loss = 1.33161 (* 1 = 1.33161 loss)
I0520 17:50:57.511620 25100 sgd_solver.cpp:106] Iteration 136500, lr = 0.0015
I0520 17:51:07.214288 25100 solver.cpp:237] Iteration 136875, loss = 1.18426
I0520 17:51:07.214471 25100 solver.cpp:253]     Train net output #0: loss = 1.18426 (* 1 = 1.18426 loss)
I0520 17:51:07.214485 25100 sgd_solver.cpp:106] Iteration 136875, lr = 0.0015
I0520 17:51:16.918617 25100 solver.cpp:237] Iteration 137250, loss = 0.85119
I0520 17:51:16.918653 25100 solver.cpp:253]     Train net output #0: loss = 0.85119 (* 1 = 0.85119 loss)
I0520 17:51:16.918668 25100 sgd_solver.cpp:106] Iteration 137250, lr = 0.0015
I0520 17:51:47.504348 25100 solver.cpp:237] Iteration 137625, loss = 1.04668
I0520 17:51:47.504544 25100 solver.cpp:253]     Train net output #0: loss = 1.04668 (* 1 = 1.04668 loss)
I0520 17:51:47.504559 25100 sgd_solver.cpp:106] Iteration 137625, lr = 0.0015
I0520 17:51:57.203188 25100 solver.cpp:237] Iteration 138000, loss = 1.20892
I0520 17:51:57.203222 25100 solver.cpp:253]     Train net output #0: loss = 1.20892 (* 1 = 1.20892 loss)
I0520 17:51:57.203239 25100 sgd_solver.cpp:106] Iteration 138000, lr = 0.0015
I0520 17:52:06.903120 25100 solver.cpp:237] Iteration 138375, loss = 1.04716
I0520 17:52:06.903156 25100 solver.cpp:253]     Train net output #0: loss = 1.04716 (* 1 = 1.04716 loss)
I0520 17:52:06.903169 25100 sgd_solver.cpp:106] Iteration 138375, lr = 0.0015
I0520 17:52:16.580020 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_138750.caffemodel
I0520 17:52:16.635553 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_138750.solverstate
I0520 17:52:16.669119 25100 solver.cpp:237] Iteration 138750, loss = 0.968278
I0520 17:52:16.669174 25100 solver.cpp:253]     Train net output #0: loss = 0.968278 (* 1 = 0.968278 loss)
I0520 17:52:16.669188 25100 sgd_solver.cpp:106] Iteration 138750, lr = 0.0015
I0520 17:52:26.373189 25100 solver.cpp:237] Iteration 139125, loss = 1.16225
I0520 17:52:26.373365 25100 solver.cpp:253]     Train net output #0: loss = 1.16225 (* 1 = 1.16225 loss)
I0520 17:52:26.373378 25100 sgd_solver.cpp:106] Iteration 139125, lr = 0.0015
I0520 17:52:36.079488 25100 solver.cpp:237] Iteration 139500, loss = 1.02303
I0520 17:52:36.079536 25100 solver.cpp:253]     Train net output #0: loss = 1.02303 (* 1 = 1.02303 loss)
I0520 17:52:36.079553 25100 sgd_solver.cpp:106] Iteration 139500, lr = 0.0015
I0520 17:52:45.780149 25100 solver.cpp:237] Iteration 139875, loss = 1.11334
I0520 17:52:45.780185 25100 solver.cpp:253]     Train net output #0: loss = 1.11334 (* 1 = 1.11334 loss)
I0520 17:52:45.780201 25100 sgd_solver.cpp:106] Iteration 139875, lr = 0.0015
I0520 17:53:16.359796 25100 solver.cpp:237] Iteration 140250, loss = 1.00399
I0520 17:53:16.359994 25100 solver.cpp:253]     Train net output #0: loss = 1.00399 (* 1 = 1.00399 loss)
I0520 17:53:16.360009 25100 sgd_solver.cpp:106] Iteration 140250, lr = 0.0015
I0520 17:53:26.060974 25100 solver.cpp:237] Iteration 140625, loss = 1.70287
I0520 17:53:26.061027 25100 solver.cpp:253]     Train net output #0: loss = 1.70287 (* 1 = 1.70287 loss)
I0520 17:53:26.061043 25100 sgd_solver.cpp:106] Iteration 140625, lr = 0.0015
I0520 17:53:35.762176 25100 solver.cpp:237] Iteration 141000, loss = 1.12243
I0520 17:53:35.762212 25100 solver.cpp:253]     Train net output #0: loss = 1.12243 (* 1 = 1.12243 loss)
I0520 17:53:35.762229 25100 sgd_solver.cpp:106] Iteration 141000, lr = 0.0015
I0520 17:53:45.472548 25100 solver.cpp:237] Iteration 141375, loss = 1.39393
I0520 17:53:45.472584 25100 solver.cpp:253]     Train net output #0: loss = 1.39393 (* 1 = 1.39393 loss)
I0520 17:53:45.472600 25100 sgd_solver.cpp:106] Iteration 141375, lr = 0.0015
I0520 17:53:55.176439 25100 solver.cpp:237] Iteration 141750, loss = 1.04222
I0520 17:53:55.176631 25100 solver.cpp:253]     Train net output #0: loss = 1.04222 (* 1 = 1.04222 loss)
I0520 17:53:55.176645 25100 sgd_solver.cpp:106] Iteration 141750, lr = 0.0015
I0520 17:54:04.880066 25100 solver.cpp:237] Iteration 142125, loss = 0.884163
I0520 17:54:04.880101 25100 solver.cpp:253]     Train net output #0: loss = 0.884163 (* 1 = 0.884163 loss)
I0520 17:54:04.880118 25100 sgd_solver.cpp:106] Iteration 142125, lr = 0.0015
I0520 17:54:14.550990 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_142500.caffemodel
I0520 17:54:14.606227 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_142500.solverstate
I0520 17:54:14.631621 25100 solver.cpp:341] Iteration 142500, Testing net (#0)
I0520 17:55:02.854859 25100 solver.cpp:409]     Test net output #0: accuracy = 0.892719
I0520 17:55:02.855054 25100 solver.cpp:409]     Test net output #1: loss = 0.344433 (* 1 = 0.344433 loss)
I0520 17:55:23.717712 25100 solver.cpp:237] Iteration 142500, loss = 1.1499
I0520 17:55:23.717768 25100 solver.cpp:253]     Train net output #0: loss = 1.1499 (* 1 = 1.1499 loss)
I0520 17:55:23.717783 25100 sgd_solver.cpp:106] Iteration 142500, lr = 0.0015
I0520 17:55:33.469498 25100 solver.cpp:237] Iteration 142875, loss = 1.49278
I0520 17:55:33.469684 25100 solver.cpp:253]     Train net output #0: loss = 1.49278 (* 1 = 1.49278 loss)
I0520 17:55:33.469698 25100 sgd_solver.cpp:106] Iteration 142875, lr = 0.0015
I0520 17:55:43.229934 25100 solver.cpp:237] Iteration 143250, loss = 1.17955
I0520 17:55:43.229969 25100 solver.cpp:253]     Train net output #0: loss = 1.17955 (* 1 = 1.17955 loss)
I0520 17:55:43.229987 25100 sgd_solver.cpp:106] Iteration 143250, lr = 0.0015
I0520 17:55:52.987725 25100 solver.cpp:237] Iteration 143625, loss = 1.05163
I0520 17:55:52.987759 25100 solver.cpp:253]     Train net output #0: loss = 1.05163 (* 1 = 1.05163 loss)
I0520 17:55:52.987776 25100 sgd_solver.cpp:106] Iteration 143625, lr = 0.0015
I0520 17:56:02.745605 25100 solver.cpp:237] Iteration 144000, loss = 1.23913
I0520 17:56:02.745645 25100 solver.cpp:253]     Train net output #0: loss = 1.23913 (* 1 = 1.23913 loss)
I0520 17:56:02.745662 25100 sgd_solver.cpp:106] Iteration 144000, lr = 0.0015
I0520 17:56:12.501905 25100 solver.cpp:237] Iteration 144375, loss = 1.2288
I0520 17:56:12.502076 25100 solver.cpp:253]     Train net output #0: loss = 1.2288 (* 1 = 1.2288 loss)
I0520 17:56:12.502090 25100 sgd_solver.cpp:106] Iteration 144375, lr = 0.0015
I0520 17:56:22.255280 25100 solver.cpp:237] Iteration 144750, loss = 0.905352
I0520 17:56:22.255327 25100 solver.cpp:253]     Train net output #0: loss = 0.905352 (* 1 = 0.905352 loss)
I0520 17:56:22.255347 25100 sgd_solver.cpp:106] Iteration 144750, lr = 0.0015
I0520 17:56:52.862360 25100 solver.cpp:237] Iteration 145125, loss = 1.17997
I0520 17:56:52.862557 25100 solver.cpp:253]     Train net output #0: loss = 1.17997 (* 1 = 1.17997 loss)
I0520 17:56:52.862572 25100 sgd_solver.cpp:106] Iteration 145125, lr = 0.0015
I0520 17:57:02.624639 25100 solver.cpp:237] Iteration 145500, loss = 1.23698
I0520 17:57:02.624675 25100 solver.cpp:253]     Train net output #0: loss = 1.23698 (* 1 = 1.23698 loss)
I0520 17:57:02.624691 25100 sgd_solver.cpp:106] Iteration 145500, lr = 0.0015
I0520 17:57:12.383194 25100 solver.cpp:237] Iteration 145875, loss = 0.984686
I0520 17:57:12.383241 25100 solver.cpp:253]     Train net output #0: loss = 0.984686 (* 1 = 0.984686 loss)
I0520 17:57:12.383258 25100 sgd_solver.cpp:106] Iteration 145875, lr = 0.0015
I0520 17:57:22.122792 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_146250.caffemodel
I0520 17:57:22.178843 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_146250.solverstate
I0520 17:57:22.211803 25100 solver.cpp:237] Iteration 146250, loss = 1.18853
I0520 17:57:22.211851 25100 solver.cpp:253]     Train net output #0: loss = 1.18853 (* 1 = 1.18853 loss)
I0520 17:57:22.211869 25100 sgd_solver.cpp:106] Iteration 146250, lr = 0.0015
I0520 17:57:31.974475 25100 solver.cpp:237] Iteration 146625, loss = 1.29681
I0520 17:57:31.974668 25100 solver.cpp:253]     Train net output #0: loss = 1.29681 (* 1 = 1.29681 loss)
I0520 17:57:31.974683 25100 sgd_solver.cpp:106] Iteration 146625, lr = 0.0015
I0520 17:57:41.744518 25100 solver.cpp:237] Iteration 147000, loss = 1.48169
I0520 17:57:41.744565 25100 solver.cpp:253]     Train net output #0: loss = 1.48169 (* 1 = 1.48169 loss)
I0520 17:57:41.744583 25100 sgd_solver.cpp:106] Iteration 147000, lr = 0.0015
I0520 17:57:51.511307 25100 solver.cpp:237] Iteration 147375, loss = 1.31499
I0520 17:57:51.511343 25100 solver.cpp:253]     Train net output #0: loss = 1.31499 (* 1 = 1.31499 loss)
I0520 17:57:51.511356 25100 sgd_solver.cpp:106] Iteration 147375, lr = 0.0015
I0520 17:58:22.163853 25100 solver.cpp:237] Iteration 147750, loss = 1.11964
I0520 17:58:22.164053 25100 solver.cpp:253]     Train net output #0: loss = 1.11964 (* 1 = 1.11964 loss)
I0520 17:58:22.164069 25100 sgd_solver.cpp:106] Iteration 147750, lr = 0.0015
I0520 17:58:31.928498 25100 solver.cpp:237] Iteration 148125, loss = 1.07046
I0520 17:58:31.928540 25100 solver.cpp:253]     Train net output #0: loss = 1.07046 (* 1 = 1.07046 loss)
I0520 17:58:31.928558 25100 sgd_solver.cpp:106] Iteration 148125, lr = 0.0015
I0520 17:58:41.692898 25100 solver.cpp:237] Iteration 148500, loss = 1.40299
I0520 17:58:41.692934 25100 solver.cpp:253]     Train net output #0: loss = 1.40299 (* 1 = 1.40299 loss)
I0520 17:58:41.692947 25100 sgd_solver.cpp:106] Iteration 148500, lr = 0.0015
I0520 17:58:51.454150 25100 solver.cpp:237] Iteration 148875, loss = 1.15463
I0520 17:58:51.454195 25100 solver.cpp:253]     Train net output #0: loss = 1.15463 (* 1 = 1.15463 loss)
I0520 17:58:51.454213 25100 sgd_solver.cpp:106] Iteration 148875, lr = 0.0015
I0520 17:59:01.218611 25100 solver.cpp:237] Iteration 149250, loss = 0.924514
I0520 17:59:01.218787 25100 solver.cpp:253]     Train net output #0: loss = 0.924514 (* 1 = 0.924514 loss)
I0520 17:59:01.218801 25100 sgd_solver.cpp:106] Iteration 149250, lr = 0.0015
I0520 17:59:10.977347 25100 solver.cpp:237] Iteration 149625, loss = 1.3846
I0520 17:59:10.977382 25100 solver.cpp:253]     Train net output #0: loss = 1.3846 (* 1 = 1.3846 loss)
I0520 17:59:10.977399 25100 sgd_solver.cpp:106] Iteration 149625, lr = 0.0015
I0520 17:59:20.716559 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_150000.caffemodel
I0520 17:59:20.775316 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_150000.solverstate
I0520 17:59:20.802901 25100 solver.cpp:341] Iteration 150000, Testing net (#0)
I0520 18:00:30.294664 25100 solver.cpp:409]     Test net output #0: accuracy = 0.891373
I0520 18:00:30.294862 25100 solver.cpp:409]     Test net output #1: loss = 0.353902 (* 1 = 0.353902 loss)
I0520 18:00:51.179424 25100 solver.cpp:237] Iteration 150000, loss = 1.09998
I0520 18:00:51.179478 25100 solver.cpp:253]     Train net output #0: loss = 1.09998 (* 1 = 1.09998 loss)
I0520 18:00:51.179493 25100 sgd_solver.cpp:106] Iteration 150000, lr = 0.0015
I0520 18:01:00.917635 25100 solver.cpp:237] Iteration 150375, loss = 1.29468
I0520 18:01:00.917841 25100 solver.cpp:253]     Train net output #0: loss = 1.29468 (* 1 = 1.29468 loss)
I0520 18:01:00.917855 25100 sgd_solver.cpp:106] Iteration 150375, lr = 0.0015
I0520 18:01:10.648178 25100 solver.cpp:237] Iteration 150750, loss = 1.31198
I0520 18:01:10.648213 25100 solver.cpp:253]     Train net output #0: loss = 1.31198 (* 1 = 1.31198 loss)
I0520 18:01:10.648231 25100 sgd_solver.cpp:106] Iteration 150750, lr = 0.0015
I0520 18:01:20.388134 25100 solver.cpp:237] Iteration 151125, loss = 1.17482
I0520 18:01:20.388180 25100 solver.cpp:253]     Train net output #0: loss = 1.17482 (* 1 = 1.17482 loss)
I0520 18:01:20.388198 25100 sgd_solver.cpp:106] Iteration 151125, lr = 0.0015
I0520 18:01:30.139513 25100 solver.cpp:237] Iteration 151500, loss = 1.10362
I0520 18:01:30.139549 25100 solver.cpp:253]     Train net output #0: loss = 1.10362 (* 1 = 1.10362 loss)
I0520 18:01:30.139565 25100 sgd_solver.cpp:106] Iteration 151500, lr = 0.0015
I0520 18:01:39.885282 25100 solver.cpp:237] Iteration 151875, loss = 0.978034
I0520 18:01:39.885458 25100 solver.cpp:253]     Train net output #0: loss = 0.978034 (* 1 = 0.978034 loss)
I0520 18:01:39.885474 25100 sgd_solver.cpp:106] Iteration 151875, lr = 0.0015
I0520 18:01:49.634107 25100 solver.cpp:237] Iteration 152250, loss = 1.5188
I0520 18:01:49.634152 25100 solver.cpp:253]     Train net output #0: loss = 1.5188 (* 1 = 1.5188 loss)
I0520 18:01:49.634174 25100 sgd_solver.cpp:106] Iteration 152250, lr = 0.0015
I0520 18:02:20.271769 25100 solver.cpp:237] Iteration 152625, loss = 0.963989
I0520 18:02:20.271973 25100 solver.cpp:253]     Train net output #0: loss = 0.963989 (* 1 = 0.963989 loss)
I0520 18:02:20.271988 25100 sgd_solver.cpp:106] Iteration 152625, lr = 0.0015
I0520 18:02:30.015297 25100 solver.cpp:237] Iteration 153000, loss = 1.02061
I0520 18:02:30.015332 25100 solver.cpp:253]     Train net output #0: loss = 1.02061 (* 1 = 1.02061 loss)
I0520 18:02:30.015350 25100 sgd_solver.cpp:106] Iteration 153000, lr = 0.0015
I0520 18:02:39.760681 25100 solver.cpp:237] Iteration 153375, loss = 1.45198
I0520 18:02:39.760730 25100 solver.cpp:253]     Train net output #0: loss = 1.45198 (* 1 = 1.45198 loss)
I0520 18:02:39.760747 25100 sgd_solver.cpp:106] Iteration 153375, lr = 0.0015
I0520 18:02:49.480459 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_153750.caffemodel
I0520 18:02:49.536182 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_153750.solverstate
I0520 18:02:49.569113 25100 solver.cpp:237] Iteration 153750, loss = 1.00512
I0520 18:02:49.569159 25100 solver.cpp:253]     Train net output #0: loss = 1.00512 (* 1 = 1.00512 loss)
I0520 18:02:49.569177 25100 sgd_solver.cpp:106] Iteration 153750, lr = 0.0015
I0520 18:02:59.315506 25100 solver.cpp:237] Iteration 154125, loss = 1.15632
I0520 18:02:59.315706 25100 solver.cpp:253]     Train net output #0: loss = 1.15632 (* 1 = 1.15632 loss)
I0520 18:02:59.315721 25100 sgd_solver.cpp:106] Iteration 154125, lr = 0.0015
I0520 18:03:09.063627 25100 solver.cpp:237] Iteration 154500, loss = 1.21401
I0520 18:03:09.063669 25100 solver.cpp:253]     Train net output #0: loss = 1.21401 (* 1 = 1.21401 loss)
I0520 18:03:09.063683 25100 sgd_solver.cpp:106] Iteration 154500, lr = 0.0015
I0520 18:03:18.820704 25100 solver.cpp:237] Iteration 154875, loss = 1.06121
I0520 18:03:18.820740 25100 solver.cpp:253]     Train net output #0: loss = 1.06121 (* 1 = 1.06121 loss)
I0520 18:03:18.820757 25100 sgd_solver.cpp:106] Iteration 154875, lr = 0.0015
I0520 18:03:49.499320 25100 solver.cpp:237] Iteration 155250, loss = 1.08042
I0520 18:03:49.499517 25100 solver.cpp:253]     Train net output #0: loss = 1.08042 (* 1 = 1.08042 loss)
I0520 18:03:49.499532 25100 sgd_solver.cpp:106] Iteration 155250, lr = 0.0015
I0520 18:03:59.251281 25100 solver.cpp:237] Iteration 155625, loss = 1.33121
I0520 18:03:59.251317 25100 solver.cpp:253]     Train net output #0: loss = 1.33121 (* 1 = 1.33121 loss)
I0520 18:03:59.251333 25100 sgd_solver.cpp:106] Iteration 155625, lr = 0.0015
I0520 18:04:08.991786 25100 solver.cpp:237] Iteration 156000, loss = 1.10557
I0520 18:04:08.991822 25100 solver.cpp:253]     Train net output #0: loss = 1.10557 (* 1 = 1.10557 loss)
I0520 18:04:08.991837 25100 sgd_solver.cpp:106] Iteration 156000, lr = 0.0015
I0520 18:04:18.738507 25100 solver.cpp:237] Iteration 156375, loss = 1.1598
I0520 18:04:18.738554 25100 solver.cpp:253]     Train net output #0: loss = 1.1598 (* 1 = 1.1598 loss)
I0520 18:04:18.738574 25100 sgd_solver.cpp:106] Iteration 156375, lr = 0.0015
I0520 18:04:28.482092 25100 solver.cpp:237] Iteration 156750, loss = 1.17806
I0520 18:04:28.482278 25100 solver.cpp:253]     Train net output #0: loss = 1.17806 (* 1 = 1.17806 loss)
I0520 18:04:28.482292 25100 sgd_solver.cpp:106] Iteration 156750, lr = 0.0015
I0520 18:04:38.225606 25100 solver.cpp:237] Iteration 157125, loss = 1.28396
I0520 18:04:38.225641 25100 solver.cpp:253]     Train net output #0: loss = 1.28396 (* 1 = 1.28396 loss)
I0520 18:04:38.225657 25100 sgd_solver.cpp:106] Iteration 157125, lr = 0.0015
I0520 18:04:47.942298 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_157500.caffemodel
I0520 18:04:47.997985 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_157500.solverstate
I0520 18:04:48.023811 25100 solver.cpp:341] Iteration 157500, Testing net (#0)
I0520 18:05:36.555299 25100 solver.cpp:409]     Test net output #0: accuracy = 0.895107
I0520 18:05:36.555500 25100 solver.cpp:409]     Test net output #1: loss = 0.333959 (* 1 = 0.333959 loss)
I0520 18:05:57.425561 25100 solver.cpp:237] Iteration 157500, loss = 1.09235
I0520 18:05:57.425617 25100 solver.cpp:253]     Train net output #0: loss = 1.09235 (* 1 = 1.09235 loss)
I0520 18:05:57.425635 25100 sgd_solver.cpp:106] Iteration 157500, lr = 0.0015
I0520 18:06:07.196879 25100 solver.cpp:237] Iteration 157875, loss = 1.13795
I0520 18:06:07.197063 25100 solver.cpp:253]     Train net output #0: loss = 1.13795 (* 1 = 1.13795 loss)
I0520 18:06:07.197077 25100 sgd_solver.cpp:106] Iteration 157875, lr = 0.0015
I0520 18:06:16.971179 25100 solver.cpp:237] Iteration 158250, loss = 1.02233
I0520 18:06:16.971213 25100 solver.cpp:253]     Train net output #0: loss = 1.02233 (* 1 = 1.02233 loss)
I0520 18:06:16.971231 25100 sgd_solver.cpp:106] Iteration 158250, lr = 0.0015
I0520 18:06:26.743646 25100 solver.cpp:237] Iteration 158625, loss = 1.04175
I0520 18:06:26.743698 25100 solver.cpp:253]     Train net output #0: loss = 1.04175 (* 1 = 1.04175 loss)
I0520 18:06:26.743716 25100 sgd_solver.cpp:106] Iteration 158625, lr = 0.0015
I0520 18:06:36.521008 25100 solver.cpp:237] Iteration 159000, loss = 0.888381
I0520 18:06:36.521044 25100 solver.cpp:253]     Train net output #0: loss = 0.888381 (* 1 = 0.888381 loss)
I0520 18:06:36.521062 25100 sgd_solver.cpp:106] Iteration 159000, lr = 0.0015
I0520 18:06:46.293341 25100 solver.cpp:237] Iteration 159375, loss = 1.28977
I0520 18:06:46.293534 25100 solver.cpp:253]     Train net output #0: loss = 1.28977 (* 1 = 1.28977 loss)
I0520 18:06:46.293546 25100 sgd_solver.cpp:106] Iteration 159375, lr = 0.0015
I0520 18:06:56.068615 25100 solver.cpp:237] Iteration 159750, loss = 1.23033
I0520 18:06:56.068650 25100 solver.cpp:253]     Train net output #0: loss = 1.23033 (* 1 = 1.23033 loss)
I0520 18:06:56.068670 25100 sgd_solver.cpp:106] Iteration 159750, lr = 0.0015
I0520 18:07:26.712893 25100 solver.cpp:237] Iteration 160125, loss = 1.28587
I0520 18:07:26.713095 25100 solver.cpp:253]     Train net output #0: loss = 1.28587 (* 1 = 1.28587 loss)
I0520 18:07:26.713111 25100 sgd_solver.cpp:106] Iteration 160125, lr = 0.0015
I0520 18:07:36.491577 25100 solver.cpp:237] Iteration 160500, loss = 0.846983
I0520 18:07:36.491624 25100 solver.cpp:253]     Train net output #0: loss = 0.846983 (* 1 = 0.846983 loss)
I0520 18:07:36.491644 25100 sgd_solver.cpp:106] Iteration 160500, lr = 0.0015
I0520 18:07:46.267328 25100 solver.cpp:237] Iteration 160875, loss = 1.64018
I0520 18:07:46.267364 25100 solver.cpp:253]     Train net output #0: loss = 1.64018 (* 1 = 1.64018 loss)
I0520 18:07:46.267380 25100 sgd_solver.cpp:106] Iteration 160875, lr = 0.0015
I0520 18:07:56.019103 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_161250.caffemodel
I0520 18:07:56.075893 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_161250.solverstate
I0520 18:07:56.109542 25100 solver.cpp:237] Iteration 161250, loss = 1.14965
I0520 18:07:56.109591 25100 solver.cpp:253]     Train net output #0: loss = 1.14965 (* 1 = 1.14965 loss)
I0520 18:07:56.109606 25100 sgd_solver.cpp:106] Iteration 161250, lr = 0.0015
I0520 18:08:05.887730 25100 solver.cpp:237] Iteration 161625, loss = 0.95134
I0520 18:08:05.887944 25100 solver.cpp:253]     Train net output #0: loss = 0.95134 (* 1 = 0.95134 loss)
I0520 18:08:05.887959 25100 sgd_solver.cpp:106] Iteration 161625, lr = 0.0015
I0520 18:08:15.656396 25100 solver.cpp:237] Iteration 162000, loss = 0.94492
I0520 18:08:15.656432 25100 solver.cpp:253]     Train net output #0: loss = 0.94492 (* 1 = 0.94492 loss)
I0520 18:08:15.656450 25100 sgd_solver.cpp:106] Iteration 162000, lr = 0.0015
I0520 18:08:25.427502 25100 solver.cpp:237] Iteration 162375, loss = 1.36596
I0520 18:08:25.427549 25100 solver.cpp:253]     Train net output #0: loss = 1.36596 (* 1 = 1.36596 loss)
I0520 18:08:25.427569 25100 sgd_solver.cpp:106] Iteration 162375, lr = 0.0015
I0520 18:08:56.071646 25100 solver.cpp:237] Iteration 162750, loss = 1.05316
I0520 18:08:56.071858 25100 solver.cpp:253]     Train net output #0: loss = 1.05316 (* 1 = 1.05316 loss)
I0520 18:08:56.071874 25100 sgd_solver.cpp:106] Iteration 162750, lr = 0.0015
I0520 18:09:05.844898 25100 solver.cpp:237] Iteration 163125, loss = 1.15507
I0520 18:09:05.844933 25100 solver.cpp:253]     Train net output #0: loss = 1.15507 (* 1 = 1.15507 loss)
I0520 18:09:05.844951 25100 sgd_solver.cpp:106] Iteration 163125, lr = 0.0015
I0520 18:09:15.618667 25100 solver.cpp:237] Iteration 163500, loss = 1.29407
I0520 18:09:15.618708 25100 solver.cpp:253]     Train net output #0: loss = 1.29407 (* 1 = 1.29407 loss)
I0520 18:09:15.618729 25100 sgd_solver.cpp:106] Iteration 163500, lr = 0.0015
I0520 18:09:25.392256 25100 solver.cpp:237] Iteration 163875, loss = 1.22966
I0520 18:09:25.392290 25100 solver.cpp:253]     Train net output #0: loss = 1.22966 (* 1 = 1.22966 loss)
I0520 18:09:25.392308 25100 sgd_solver.cpp:106] Iteration 163875, lr = 0.0015
I0520 18:09:35.165722 25100 solver.cpp:237] Iteration 164250, loss = 0.976383
I0520 18:09:35.165905 25100 solver.cpp:253]     Train net output #0: loss = 0.976383 (* 1 = 0.976383 loss)
I0520 18:09:35.165920 25100 sgd_solver.cpp:106] Iteration 164250, lr = 0.0015
I0520 18:09:44.936492 25100 solver.cpp:237] Iteration 164625, loss = 0.878188
I0520 18:09:44.936543 25100 solver.cpp:253]     Train net output #0: loss = 0.878188 (* 1 = 0.878188 loss)
I0520 18:09:44.936561 25100 sgd_solver.cpp:106] Iteration 164625, lr = 0.0015
I0520 18:09:54.680546 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_165000.caffemodel
I0520 18:09:54.737795 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_165000.solverstate
I0520 18:09:54.763156 25100 solver.cpp:341] Iteration 165000, Testing net (#0)
I0520 18:11:04.187572 25100 solver.cpp:409]     Test net output #0: accuracy = 0.892806
I0520 18:11:04.187793 25100 solver.cpp:409]     Test net output #1: loss = 0.342527 (* 1 = 0.342527 loss)
I0520 18:11:25.064680 25100 solver.cpp:237] Iteration 165000, loss = 0.864552
I0520 18:11:25.064738 25100 solver.cpp:253]     Train net output #0: loss = 0.864552 (* 1 = 0.864552 loss)
I0520 18:11:25.064755 25100 sgd_solver.cpp:106] Iteration 165000, lr = 0.0015
I0520 18:11:34.750598 25100 solver.cpp:237] Iteration 165375, loss = 1.02943
I0520 18:11:34.750783 25100 solver.cpp:253]     Train net output #0: loss = 1.02943 (* 1 = 1.02943 loss)
I0520 18:11:34.750797 25100 sgd_solver.cpp:106] Iteration 165375, lr = 0.0015
I0520 18:11:44.441090 25100 solver.cpp:237] Iteration 165750, loss = 1.19167
I0520 18:11:44.441138 25100 solver.cpp:253]     Train net output #0: loss = 1.19167 (* 1 = 1.19167 loss)
I0520 18:11:44.441156 25100 sgd_solver.cpp:106] Iteration 165750, lr = 0.0015
I0520 18:11:54.128865 25100 solver.cpp:237] Iteration 166125, loss = 1.06229
I0520 18:11:54.128901 25100 solver.cpp:253]     Train net output #0: loss = 1.06229 (* 1 = 1.06229 loss)
I0520 18:11:54.128916 25100 sgd_solver.cpp:106] Iteration 166125, lr = 0.0015
I0520 18:12:03.812490 25100 solver.cpp:237] Iteration 166500, loss = 1.0207
I0520 18:12:03.812526 25100 solver.cpp:253]     Train net output #0: loss = 1.0207 (* 1 = 1.0207 loss)
I0520 18:12:03.812543 25100 sgd_solver.cpp:106] Iteration 166500, lr = 0.0015
I0520 18:12:13.498057 25100 solver.cpp:237] Iteration 166875, loss = 0.875521
I0520 18:12:13.498251 25100 solver.cpp:253]     Train net output #0: loss = 0.875521 (* 1 = 0.875521 loss)
I0520 18:12:13.498265 25100 sgd_solver.cpp:106] Iteration 166875, lr = 0.0015
I0520 18:12:23.188412 25100 solver.cpp:237] Iteration 167250, loss = 1.1559
I0520 18:12:23.188446 25100 solver.cpp:253]     Train net output #0: loss = 1.1559 (* 1 = 1.1559 loss)
I0520 18:12:23.188464 25100 sgd_solver.cpp:106] Iteration 167250, lr = 0.0015
I0520 18:12:53.760874 25100 solver.cpp:237] Iteration 167625, loss = 1.27026
I0520 18:12:53.761078 25100 solver.cpp:253]     Train net output #0: loss = 1.27026 (* 1 = 1.27026 loss)
I0520 18:12:53.761095 25100 sgd_solver.cpp:106] Iteration 167625, lr = 0.0015
I0520 18:13:03.448472 25100 solver.cpp:237] Iteration 168000, loss = 1.03302
I0520 18:13:03.448513 25100 solver.cpp:253]     Train net output #0: loss = 1.03302 (* 1 = 1.03302 loss)
I0520 18:13:03.448535 25100 sgd_solver.cpp:106] Iteration 168000, lr = 0.0015
I0520 18:13:13.135474 25100 solver.cpp:237] Iteration 168375, loss = 0.926198
I0520 18:13:13.135510 25100 solver.cpp:253]     Train net output #0: loss = 0.926198 (* 1 = 0.926198 loss)
I0520 18:13:13.135524 25100 sgd_solver.cpp:106] Iteration 168375, lr = 0.0015
I0520 18:13:22.792032 25100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_168750.caffemodel
I0520 18:13:22.853029 25100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_168750.solverstate
I0520 18:13:22.888258 25100 solver.cpp:237] Iteration 168750, loss = 0.978373
I0520 18:13:22.888308 25100 solver.cpp:253]     Train net output #0: loss = 0.978373 (* 1 = 0.978373 loss)
I0520 18:13:22.888329 25100 sgd_solver.cpp:106] Iteration 168750, lr = 0.0015
aprun: Apid 11233228: Caught signal Terminated, sending to application
*** Aborted at 1463782405 (unix time) try "date -d @1463782405" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x6209) received by PID 25100 (TID 0x2aaac746f900) from PID 25097; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7228 exceeded limit 7200
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11233228: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
aprun: Apid 11233228: Caught signal Terminated, sending to application
