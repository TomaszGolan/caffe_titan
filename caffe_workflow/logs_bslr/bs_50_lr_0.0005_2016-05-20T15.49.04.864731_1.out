2808052
I0523 01:53:27.386687  8024 caffe.cpp:184] Using GPUs 0
I0523 01:53:27.815016  8024 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3000
test_interval: 6000
base_lr: 0.0005
display: 300
max_iter: 300000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731.prototxt"
I0523 01:53:27.816396  8024 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731.prototxt
I0523 01:53:27.828313  8024 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 01:53:27.828372  8024 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 01:53:27.828723  8024 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 01:53:27.828902  8024 layer_factory.hpp:77] Creating layer data_hdf5
I0523 01:53:27.828925  8024 net.cpp:106] Creating Layer data_hdf5
I0523 01:53:27.828940  8024 net.cpp:411] data_hdf5 -> data
I0523 01:53:27.828974  8024 net.cpp:411] data_hdf5 -> label
I0523 01:53:27.829006  8024 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 01:53:27.841097  8024 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 01:53:27.858062  8024 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 01:53:49.494143  8024 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 01:53:49.499335  8024 net.cpp:150] Setting up data_hdf5
I0523 01:53:49.499375  8024 net.cpp:157] Top shape: 50 1 127 50 (317500)
I0523 01:53:49.499389  8024 net.cpp:157] Top shape: 50 (50)
I0523 01:53:49.499402  8024 net.cpp:165] Memory required for data: 1270200
I0523 01:53:49.499416  8024 layer_factory.hpp:77] Creating layer conv1
I0523 01:53:49.499450  8024 net.cpp:106] Creating Layer conv1
I0523 01:53:49.499461  8024 net.cpp:454] conv1 <- data
I0523 01:53:49.499482  8024 net.cpp:411] conv1 -> conv1
I0523 01:53:52.641866  8024 net.cpp:150] Setting up conv1
I0523 01:53:52.641911  8024 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 01:53:52.641922  8024 net.cpp:165] Memory required for data: 15094200
I0523 01:53:52.641952  8024 layer_factory.hpp:77] Creating layer relu1
I0523 01:53:52.641974  8024 net.cpp:106] Creating Layer relu1
I0523 01:53:52.641985  8024 net.cpp:454] relu1 <- conv1
I0523 01:53:52.641999  8024 net.cpp:397] relu1 -> conv1 (in-place)
I0523 01:53:52.642530  8024 net.cpp:150] Setting up relu1
I0523 01:53:52.642546  8024 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 01:53:52.642557  8024 net.cpp:165] Memory required for data: 28918200
I0523 01:53:52.642567  8024 layer_factory.hpp:77] Creating layer pool1
I0523 01:53:52.642585  8024 net.cpp:106] Creating Layer pool1
I0523 01:53:52.642595  8024 net.cpp:454] pool1 <- conv1
I0523 01:53:52.642607  8024 net.cpp:411] pool1 -> pool1
I0523 01:53:52.642688  8024 net.cpp:150] Setting up pool1
I0523 01:53:52.642702  8024 net.cpp:157] Top shape: 50 12 60 48 (1728000)
I0523 01:53:52.642712  8024 net.cpp:165] Memory required for data: 35830200
I0523 01:53:52.642722  8024 layer_factory.hpp:77] Creating layer conv2
I0523 01:53:52.642745  8024 net.cpp:106] Creating Layer conv2
I0523 01:53:52.642755  8024 net.cpp:454] conv2 <- pool1
I0523 01:53:52.642768  8024 net.cpp:411] conv2 -> conv2
I0523 01:53:52.645422  8024 net.cpp:150] Setting up conv2
I0523 01:53:52.645450  8024 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 01:53:52.645460  8024 net.cpp:165] Memory required for data: 45766200
I0523 01:53:52.645479  8024 layer_factory.hpp:77] Creating layer relu2
I0523 01:53:52.645494  8024 net.cpp:106] Creating Layer relu2
I0523 01:53:52.645504  8024 net.cpp:454] relu2 <- conv2
I0523 01:53:52.645517  8024 net.cpp:397] relu2 -> conv2 (in-place)
I0523 01:53:52.645848  8024 net.cpp:150] Setting up relu2
I0523 01:53:52.645862  8024 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 01:53:52.645874  8024 net.cpp:165] Memory required for data: 55702200
I0523 01:53:52.645884  8024 layer_factory.hpp:77] Creating layer pool2
I0523 01:53:52.645896  8024 net.cpp:106] Creating Layer pool2
I0523 01:53:52.645906  8024 net.cpp:454] pool2 <- conv2
I0523 01:53:52.645918  8024 net.cpp:411] pool2 -> pool2
I0523 01:53:52.645999  8024 net.cpp:150] Setting up pool2
I0523 01:53:52.646013  8024 net.cpp:157] Top shape: 50 20 27 46 (1242000)
I0523 01:53:52.646023  8024 net.cpp:165] Memory required for data: 60670200
I0523 01:53:52.646034  8024 layer_factory.hpp:77] Creating layer conv3
I0523 01:53:52.646051  8024 net.cpp:106] Creating Layer conv3
I0523 01:53:52.646061  8024 net.cpp:454] conv3 <- pool2
I0523 01:53:52.646075  8024 net.cpp:411] conv3 -> conv3
I0523 01:53:52.648017  8024 net.cpp:150] Setting up conv3
I0523 01:53:52.648041  8024 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 01:53:52.648051  8024 net.cpp:165] Memory required for data: 66091000
I0523 01:53:52.648072  8024 layer_factory.hpp:77] Creating layer relu3
I0523 01:53:52.648087  8024 net.cpp:106] Creating Layer relu3
I0523 01:53:52.648097  8024 net.cpp:454] relu3 <- conv3
I0523 01:53:52.648110  8024 net.cpp:397] relu3 -> conv3 (in-place)
I0523 01:53:52.648581  8024 net.cpp:150] Setting up relu3
I0523 01:53:52.648598  8024 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 01:53:52.648608  8024 net.cpp:165] Memory required for data: 71511800
I0523 01:53:52.648619  8024 layer_factory.hpp:77] Creating layer pool3
I0523 01:53:52.648633  8024 net.cpp:106] Creating Layer pool3
I0523 01:53:52.648641  8024 net.cpp:454] pool3 <- conv3
I0523 01:53:52.648654  8024 net.cpp:411] pool3 -> pool3
I0523 01:53:52.648721  8024 net.cpp:150] Setting up pool3
I0523 01:53:52.648735  8024 net.cpp:157] Top shape: 50 28 11 44 (677600)
I0523 01:53:52.648744  8024 net.cpp:165] Memory required for data: 74222200
I0523 01:53:52.648753  8024 layer_factory.hpp:77] Creating layer conv4
I0523 01:53:52.648772  8024 net.cpp:106] Creating Layer conv4
I0523 01:53:52.648782  8024 net.cpp:454] conv4 <- pool3
I0523 01:53:52.648795  8024 net.cpp:411] conv4 -> conv4
I0523 01:53:52.651562  8024 net.cpp:150] Setting up conv4
I0523 01:53:52.651592  8024 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 01:53:52.651602  8024 net.cpp:165] Memory required for data: 76036600
I0523 01:53:52.651618  8024 layer_factory.hpp:77] Creating layer relu4
I0523 01:53:52.651633  8024 net.cpp:106] Creating Layer relu4
I0523 01:53:52.651643  8024 net.cpp:454] relu4 <- conv4
I0523 01:53:52.651655  8024 net.cpp:397] relu4 -> conv4 (in-place)
I0523 01:53:52.652128  8024 net.cpp:150] Setting up relu4
I0523 01:53:52.652145  8024 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 01:53:52.652155  8024 net.cpp:165] Memory required for data: 77851000
I0523 01:53:52.652166  8024 layer_factory.hpp:77] Creating layer pool4
I0523 01:53:52.652179  8024 net.cpp:106] Creating Layer pool4
I0523 01:53:52.652189  8024 net.cpp:454] pool4 <- conv4
I0523 01:53:52.652201  8024 net.cpp:411] pool4 -> pool4
I0523 01:53:52.652269  8024 net.cpp:150] Setting up pool4
I0523 01:53:52.652282  8024 net.cpp:157] Top shape: 50 36 3 42 (226800)
I0523 01:53:52.652293  8024 net.cpp:165] Memory required for data: 78758200
I0523 01:53:52.652303  8024 layer_factory.hpp:77] Creating layer ip1
I0523 01:53:52.652323  8024 net.cpp:106] Creating Layer ip1
I0523 01:53:52.652334  8024 net.cpp:454] ip1 <- pool4
I0523 01:53:52.652346  8024 net.cpp:411] ip1 -> ip1
I0523 01:53:52.667791  8024 net.cpp:150] Setting up ip1
I0523 01:53:52.667819  8024 net.cpp:157] Top shape: 50 196 (9800)
I0523 01:53:52.667832  8024 net.cpp:165] Memory required for data: 78797400
I0523 01:53:52.667855  8024 layer_factory.hpp:77] Creating layer relu5
I0523 01:53:52.667868  8024 net.cpp:106] Creating Layer relu5
I0523 01:53:52.667879  8024 net.cpp:454] relu5 <- ip1
I0523 01:53:52.667892  8024 net.cpp:397] relu5 -> ip1 (in-place)
I0523 01:53:52.668234  8024 net.cpp:150] Setting up relu5
I0523 01:53:52.668248  8024 net.cpp:157] Top shape: 50 196 (9800)
I0523 01:53:52.668258  8024 net.cpp:165] Memory required for data: 78836600
I0523 01:53:52.668268  8024 layer_factory.hpp:77] Creating layer drop1
I0523 01:53:52.668290  8024 net.cpp:106] Creating Layer drop1
I0523 01:53:52.668300  8024 net.cpp:454] drop1 <- ip1
I0523 01:53:52.668313  8024 net.cpp:397] drop1 -> ip1 (in-place)
I0523 01:53:52.668371  8024 net.cpp:150] Setting up drop1
I0523 01:53:52.668385  8024 net.cpp:157] Top shape: 50 196 (9800)
I0523 01:53:52.668395  8024 net.cpp:165] Memory required for data: 78875800
I0523 01:53:52.668406  8024 layer_factory.hpp:77] Creating layer ip2
I0523 01:53:52.668424  8024 net.cpp:106] Creating Layer ip2
I0523 01:53:52.668436  8024 net.cpp:454] ip2 <- ip1
I0523 01:53:52.668448  8024 net.cpp:411] ip2 -> ip2
I0523 01:53:52.668908  8024 net.cpp:150] Setting up ip2
I0523 01:53:52.668922  8024 net.cpp:157] Top shape: 50 98 (4900)
I0523 01:53:52.668932  8024 net.cpp:165] Memory required for data: 78895400
I0523 01:53:52.668947  8024 layer_factory.hpp:77] Creating layer relu6
I0523 01:53:52.668961  8024 net.cpp:106] Creating Layer relu6
I0523 01:53:52.668970  8024 net.cpp:454] relu6 <- ip2
I0523 01:53:52.668983  8024 net.cpp:397] relu6 -> ip2 (in-place)
I0523 01:53:52.669502  8024 net.cpp:150] Setting up relu6
I0523 01:53:52.669518  8024 net.cpp:157] Top shape: 50 98 (4900)
I0523 01:53:52.669529  8024 net.cpp:165] Memory required for data: 78915000
I0523 01:53:52.669539  8024 layer_factory.hpp:77] Creating layer drop2
I0523 01:53:52.669553  8024 net.cpp:106] Creating Layer drop2
I0523 01:53:52.669562  8024 net.cpp:454] drop2 <- ip2
I0523 01:53:52.669574  8024 net.cpp:397] drop2 -> ip2 (in-place)
I0523 01:53:52.669616  8024 net.cpp:150] Setting up drop2
I0523 01:53:52.669630  8024 net.cpp:157] Top shape: 50 98 (4900)
I0523 01:53:52.669641  8024 net.cpp:165] Memory required for data: 78934600
I0523 01:53:52.669651  8024 layer_factory.hpp:77] Creating layer ip3
I0523 01:53:52.669664  8024 net.cpp:106] Creating Layer ip3
I0523 01:53:52.669673  8024 net.cpp:454] ip3 <- ip2
I0523 01:53:52.669687  8024 net.cpp:411] ip3 -> ip3
I0523 01:53:52.669896  8024 net.cpp:150] Setting up ip3
I0523 01:53:52.669909  8024 net.cpp:157] Top shape: 50 11 (550)
I0523 01:53:52.669919  8024 net.cpp:165] Memory required for data: 78936800
I0523 01:53:52.669934  8024 layer_factory.hpp:77] Creating layer drop3
I0523 01:53:52.669946  8024 net.cpp:106] Creating Layer drop3
I0523 01:53:52.669955  8024 net.cpp:454] drop3 <- ip3
I0523 01:53:52.669967  8024 net.cpp:397] drop3 -> ip3 (in-place)
I0523 01:53:52.670007  8024 net.cpp:150] Setting up drop3
I0523 01:53:52.670019  8024 net.cpp:157] Top shape: 50 11 (550)
I0523 01:53:52.670029  8024 net.cpp:165] Memory required for data: 78939000
I0523 01:53:52.670039  8024 layer_factory.hpp:77] Creating layer loss
I0523 01:53:52.670058  8024 net.cpp:106] Creating Layer loss
I0523 01:53:52.670068  8024 net.cpp:454] loss <- ip3
I0523 01:53:52.670079  8024 net.cpp:454] loss <- label
I0523 01:53:52.670091  8024 net.cpp:411] loss -> loss
I0523 01:53:52.670109  8024 layer_factory.hpp:77] Creating layer loss
I0523 01:53:52.670759  8024 net.cpp:150] Setting up loss
I0523 01:53:52.670780  8024 net.cpp:157] Top shape: (1)
I0523 01:53:52.670794  8024 net.cpp:160]     with loss weight 1
I0523 01:53:52.670836  8024 net.cpp:165] Memory required for data: 78939004
I0523 01:53:52.670847  8024 net.cpp:226] loss needs backward computation.
I0523 01:53:52.670858  8024 net.cpp:226] drop3 needs backward computation.
I0523 01:53:52.670868  8024 net.cpp:226] ip3 needs backward computation.
I0523 01:53:52.670879  8024 net.cpp:226] drop2 needs backward computation.
I0523 01:53:52.670888  8024 net.cpp:226] relu6 needs backward computation.
I0523 01:53:52.670898  8024 net.cpp:226] ip2 needs backward computation.
I0523 01:53:52.670908  8024 net.cpp:226] drop1 needs backward computation.
I0523 01:53:52.670918  8024 net.cpp:226] relu5 needs backward computation.
I0523 01:53:52.670928  8024 net.cpp:226] ip1 needs backward computation.
I0523 01:53:52.670938  8024 net.cpp:226] pool4 needs backward computation.
I0523 01:53:52.670949  8024 net.cpp:226] relu4 needs backward computation.
I0523 01:53:52.670958  8024 net.cpp:226] conv4 needs backward computation.
I0523 01:53:52.670969  8024 net.cpp:226] pool3 needs backward computation.
I0523 01:53:52.670979  8024 net.cpp:226] relu3 needs backward computation.
I0523 01:53:52.670989  8024 net.cpp:226] conv3 needs backward computation.
I0523 01:53:52.671010  8024 net.cpp:226] pool2 needs backward computation.
I0523 01:53:52.671020  8024 net.cpp:226] relu2 needs backward computation.
I0523 01:53:52.671031  8024 net.cpp:226] conv2 needs backward computation.
I0523 01:53:52.671042  8024 net.cpp:226] pool1 needs backward computation.
I0523 01:53:52.671054  8024 net.cpp:226] relu1 needs backward computation.
I0523 01:53:52.671064  8024 net.cpp:226] conv1 needs backward computation.
I0523 01:53:52.671075  8024 net.cpp:228] data_hdf5 does not need backward computation.
I0523 01:53:52.671085  8024 net.cpp:270] This network produces output loss
I0523 01:53:52.671108  8024 net.cpp:283] Network initialization done.
I0523 01:53:52.672705  8024 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731.prototxt
I0523 01:53:52.672776  8024 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 01:53:52.673133  8024 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 01:53:52.673322  8024 layer_factory.hpp:77] Creating layer data_hdf5
I0523 01:53:52.673337  8024 net.cpp:106] Creating Layer data_hdf5
I0523 01:53:52.673349  8024 net.cpp:411] data_hdf5 -> data
I0523 01:53:52.673365  8024 net.cpp:411] data_hdf5 -> label
I0523 01:53:52.673382  8024 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 01:53:52.691712  8024 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 01:54:14.166846  8024 net.cpp:150] Setting up data_hdf5
I0523 01:54:14.167011  8024 net.cpp:157] Top shape: 50 1 127 50 (317500)
I0523 01:54:14.167026  8024 net.cpp:157] Top shape: 50 (50)
I0523 01:54:14.167037  8024 net.cpp:165] Memory required for data: 1270200
I0523 01:54:14.167050  8024 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 01:54:14.167078  8024 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 01:54:14.167089  8024 net.cpp:454] label_data_hdf5_1_split <- label
I0523 01:54:14.167104  8024 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 01:54:14.167125  8024 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 01:54:14.167197  8024 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 01:54:14.167212  8024 net.cpp:157] Top shape: 50 (50)
I0523 01:54:14.167222  8024 net.cpp:157] Top shape: 50 (50)
I0523 01:54:14.167232  8024 net.cpp:165] Memory required for data: 1270600
I0523 01:54:14.167243  8024 layer_factory.hpp:77] Creating layer conv1
I0523 01:54:14.167264  8024 net.cpp:106] Creating Layer conv1
I0523 01:54:14.167274  8024 net.cpp:454] conv1 <- data
I0523 01:54:14.167289  8024 net.cpp:411] conv1 -> conv1
I0523 01:54:14.169229  8024 net.cpp:150] Setting up conv1
I0523 01:54:14.169255  8024 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 01:54:14.169265  8024 net.cpp:165] Memory required for data: 15094600
I0523 01:54:14.169286  8024 layer_factory.hpp:77] Creating layer relu1
I0523 01:54:14.169301  8024 net.cpp:106] Creating Layer relu1
I0523 01:54:14.169312  8024 net.cpp:454] relu1 <- conv1
I0523 01:54:14.169325  8024 net.cpp:397] relu1 -> conv1 (in-place)
I0523 01:54:14.169826  8024 net.cpp:150] Setting up relu1
I0523 01:54:14.169843  8024 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 01:54:14.169853  8024 net.cpp:165] Memory required for data: 28918600
I0523 01:54:14.169863  8024 layer_factory.hpp:77] Creating layer pool1
I0523 01:54:14.169880  8024 net.cpp:106] Creating Layer pool1
I0523 01:54:14.169890  8024 net.cpp:454] pool1 <- conv1
I0523 01:54:14.169903  8024 net.cpp:411] pool1 -> pool1
I0523 01:54:14.169977  8024 net.cpp:150] Setting up pool1
I0523 01:54:14.169991  8024 net.cpp:157] Top shape: 50 12 60 48 (1728000)
I0523 01:54:14.170001  8024 net.cpp:165] Memory required for data: 35830600
I0523 01:54:14.170009  8024 layer_factory.hpp:77] Creating layer conv2
I0523 01:54:14.170027  8024 net.cpp:106] Creating Layer conv2
I0523 01:54:14.170038  8024 net.cpp:454] conv2 <- pool1
I0523 01:54:14.170052  8024 net.cpp:411] conv2 -> conv2
I0523 01:54:14.171969  8024 net.cpp:150] Setting up conv2
I0523 01:54:14.171991  8024 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 01:54:14.172004  8024 net.cpp:165] Memory required for data: 45766600
I0523 01:54:14.172021  8024 layer_factory.hpp:77] Creating layer relu2
I0523 01:54:14.172035  8024 net.cpp:106] Creating Layer relu2
I0523 01:54:14.172045  8024 net.cpp:454] relu2 <- conv2
I0523 01:54:14.172057  8024 net.cpp:397] relu2 -> conv2 (in-place)
I0523 01:54:14.172389  8024 net.cpp:150] Setting up relu2
I0523 01:54:14.172407  8024 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 01:54:14.172417  8024 net.cpp:165] Memory required for data: 55702600
I0523 01:54:14.172428  8024 layer_factory.hpp:77] Creating layer pool2
I0523 01:54:14.172441  8024 net.cpp:106] Creating Layer pool2
I0523 01:54:14.172451  8024 net.cpp:454] pool2 <- conv2
I0523 01:54:14.172463  8024 net.cpp:411] pool2 -> pool2
I0523 01:54:14.172534  8024 net.cpp:150] Setting up pool2
I0523 01:54:14.172547  8024 net.cpp:157] Top shape: 50 20 27 46 (1242000)
I0523 01:54:14.172557  8024 net.cpp:165] Memory required for data: 60670600
I0523 01:54:14.172569  8024 layer_factory.hpp:77] Creating layer conv3
I0523 01:54:14.172587  8024 net.cpp:106] Creating Layer conv3
I0523 01:54:14.172598  8024 net.cpp:454] conv3 <- pool2
I0523 01:54:14.172612  8024 net.cpp:411] conv3 -> conv3
I0523 01:54:14.174595  8024 net.cpp:150] Setting up conv3
I0523 01:54:14.174618  8024 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 01:54:14.174630  8024 net.cpp:165] Memory required for data: 66091400
I0523 01:54:14.174664  8024 layer_factory.hpp:77] Creating layer relu3
I0523 01:54:14.174677  8024 net.cpp:106] Creating Layer relu3
I0523 01:54:14.174687  8024 net.cpp:454] relu3 <- conv3
I0523 01:54:14.174700  8024 net.cpp:397] relu3 -> conv3 (in-place)
I0523 01:54:14.175173  8024 net.cpp:150] Setting up relu3
I0523 01:54:14.175189  8024 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 01:54:14.175199  8024 net.cpp:165] Memory required for data: 71512200
I0523 01:54:14.175209  8024 layer_factory.hpp:77] Creating layer pool3
I0523 01:54:14.175221  8024 net.cpp:106] Creating Layer pool3
I0523 01:54:14.175231  8024 net.cpp:454] pool3 <- conv3
I0523 01:54:14.175245  8024 net.cpp:411] pool3 -> pool3
I0523 01:54:14.175315  8024 net.cpp:150] Setting up pool3
I0523 01:54:14.175329  8024 net.cpp:157] Top shape: 50 28 11 44 (677600)
I0523 01:54:14.175338  8024 net.cpp:165] Memory required for data: 74222600
I0523 01:54:14.175348  8024 layer_factory.hpp:77] Creating layer conv4
I0523 01:54:14.175366  8024 net.cpp:106] Creating Layer conv4
I0523 01:54:14.175376  8024 net.cpp:454] conv4 <- pool3
I0523 01:54:14.175390  8024 net.cpp:411] conv4 -> conv4
I0523 01:54:14.177446  8024 net.cpp:150] Setting up conv4
I0523 01:54:14.177469  8024 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 01:54:14.177481  8024 net.cpp:165] Memory required for data: 76037000
I0523 01:54:14.177496  8024 layer_factory.hpp:77] Creating layer relu4
I0523 01:54:14.177510  8024 net.cpp:106] Creating Layer relu4
I0523 01:54:14.177520  8024 net.cpp:454] relu4 <- conv4
I0523 01:54:14.177532  8024 net.cpp:397] relu4 -> conv4 (in-place)
I0523 01:54:14.178002  8024 net.cpp:150] Setting up relu4
I0523 01:54:14.178019  8024 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 01:54:14.178028  8024 net.cpp:165] Memory required for data: 77851400
I0523 01:54:14.178038  8024 layer_factory.hpp:77] Creating layer pool4
I0523 01:54:14.178051  8024 net.cpp:106] Creating Layer pool4
I0523 01:54:14.178061  8024 net.cpp:454] pool4 <- conv4
I0523 01:54:14.178074  8024 net.cpp:411] pool4 -> pool4
I0523 01:54:14.178146  8024 net.cpp:150] Setting up pool4
I0523 01:54:14.178160  8024 net.cpp:157] Top shape: 50 36 3 42 (226800)
I0523 01:54:14.178169  8024 net.cpp:165] Memory required for data: 78758600
I0523 01:54:14.178179  8024 layer_factory.hpp:77] Creating layer ip1
I0523 01:54:14.178195  8024 net.cpp:106] Creating Layer ip1
I0523 01:54:14.178205  8024 net.cpp:454] ip1 <- pool4
I0523 01:54:14.178220  8024 net.cpp:411] ip1 -> ip1
I0523 01:54:14.193689  8024 net.cpp:150] Setting up ip1
I0523 01:54:14.193717  8024 net.cpp:157] Top shape: 50 196 (9800)
I0523 01:54:14.193728  8024 net.cpp:165] Memory required for data: 78797800
I0523 01:54:14.193750  8024 layer_factory.hpp:77] Creating layer relu5
I0523 01:54:14.193765  8024 net.cpp:106] Creating Layer relu5
I0523 01:54:14.193776  8024 net.cpp:454] relu5 <- ip1
I0523 01:54:14.193789  8024 net.cpp:397] relu5 -> ip1 (in-place)
I0523 01:54:14.194138  8024 net.cpp:150] Setting up relu5
I0523 01:54:14.194151  8024 net.cpp:157] Top shape: 50 196 (9800)
I0523 01:54:14.194161  8024 net.cpp:165] Memory required for data: 78837000
I0523 01:54:14.194171  8024 layer_factory.hpp:77] Creating layer drop1
I0523 01:54:14.194190  8024 net.cpp:106] Creating Layer drop1
I0523 01:54:14.194200  8024 net.cpp:454] drop1 <- ip1
I0523 01:54:14.194213  8024 net.cpp:397] drop1 -> ip1 (in-place)
I0523 01:54:14.194258  8024 net.cpp:150] Setting up drop1
I0523 01:54:14.194272  8024 net.cpp:157] Top shape: 50 196 (9800)
I0523 01:54:14.194283  8024 net.cpp:165] Memory required for data: 78876200
I0523 01:54:14.194291  8024 layer_factory.hpp:77] Creating layer ip2
I0523 01:54:14.194306  8024 net.cpp:106] Creating Layer ip2
I0523 01:54:14.194316  8024 net.cpp:454] ip2 <- ip1
I0523 01:54:14.194329  8024 net.cpp:411] ip2 -> ip2
I0523 01:54:14.194814  8024 net.cpp:150] Setting up ip2
I0523 01:54:14.194828  8024 net.cpp:157] Top shape: 50 98 (4900)
I0523 01:54:14.194838  8024 net.cpp:165] Memory required for data: 78895800
I0523 01:54:14.194854  8024 layer_factory.hpp:77] Creating layer relu6
I0523 01:54:14.194878  8024 net.cpp:106] Creating Layer relu6
I0523 01:54:14.194890  8024 net.cpp:454] relu6 <- ip2
I0523 01:54:14.194901  8024 net.cpp:397] relu6 -> ip2 (in-place)
I0523 01:54:14.195441  8024 net.cpp:150] Setting up relu6
I0523 01:54:14.195462  8024 net.cpp:157] Top shape: 50 98 (4900)
I0523 01:54:14.195472  8024 net.cpp:165] Memory required for data: 78915400
I0523 01:54:14.195482  8024 layer_factory.hpp:77] Creating layer drop2
I0523 01:54:14.195497  8024 net.cpp:106] Creating Layer drop2
I0523 01:54:14.195507  8024 net.cpp:454] drop2 <- ip2
I0523 01:54:14.195519  8024 net.cpp:397] drop2 -> ip2 (in-place)
I0523 01:54:14.195564  8024 net.cpp:150] Setting up drop2
I0523 01:54:14.195575  8024 net.cpp:157] Top shape: 50 98 (4900)
I0523 01:54:14.195585  8024 net.cpp:165] Memory required for data: 78935000
I0523 01:54:14.195596  8024 layer_factory.hpp:77] Creating layer ip3
I0523 01:54:14.195611  8024 net.cpp:106] Creating Layer ip3
I0523 01:54:14.195621  8024 net.cpp:454] ip3 <- ip2
I0523 01:54:14.195634  8024 net.cpp:411] ip3 -> ip3
I0523 01:54:14.195855  8024 net.cpp:150] Setting up ip3
I0523 01:54:14.195868  8024 net.cpp:157] Top shape: 50 11 (550)
I0523 01:54:14.195879  8024 net.cpp:165] Memory required for data: 78937200
I0523 01:54:14.195894  8024 layer_factory.hpp:77] Creating layer drop3
I0523 01:54:14.195907  8024 net.cpp:106] Creating Layer drop3
I0523 01:54:14.195917  8024 net.cpp:454] drop3 <- ip3
I0523 01:54:14.195930  8024 net.cpp:397] drop3 -> ip3 (in-place)
I0523 01:54:14.195971  8024 net.cpp:150] Setting up drop3
I0523 01:54:14.195984  8024 net.cpp:157] Top shape: 50 11 (550)
I0523 01:54:14.195994  8024 net.cpp:165] Memory required for data: 78939400
I0523 01:54:14.196004  8024 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 01:54:14.196017  8024 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 01:54:14.196027  8024 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 01:54:14.196040  8024 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 01:54:14.196055  8024 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 01:54:14.196128  8024 net.cpp:150] Setting up ip3_drop3_0_split
I0523 01:54:14.196141  8024 net.cpp:157] Top shape: 50 11 (550)
I0523 01:54:14.196153  8024 net.cpp:157] Top shape: 50 11 (550)
I0523 01:54:14.196163  8024 net.cpp:165] Memory required for data: 78943800
I0523 01:54:14.196173  8024 layer_factory.hpp:77] Creating layer accuracy
I0523 01:54:14.196195  8024 net.cpp:106] Creating Layer accuracy
I0523 01:54:14.196208  8024 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 01:54:14.196218  8024 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 01:54:14.196231  8024 net.cpp:411] accuracy -> accuracy
I0523 01:54:14.196255  8024 net.cpp:150] Setting up accuracy
I0523 01:54:14.196267  8024 net.cpp:157] Top shape: (1)
I0523 01:54:14.196277  8024 net.cpp:165] Memory required for data: 78943804
I0523 01:54:14.196287  8024 layer_factory.hpp:77] Creating layer loss
I0523 01:54:14.196301  8024 net.cpp:106] Creating Layer loss
I0523 01:54:14.196311  8024 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 01:54:14.196322  8024 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 01:54:14.196336  8024 net.cpp:411] loss -> loss
I0523 01:54:14.196353  8024 layer_factory.hpp:77] Creating layer loss
I0523 01:54:14.196837  8024 net.cpp:150] Setting up loss
I0523 01:54:14.196851  8024 net.cpp:157] Top shape: (1)
I0523 01:54:14.196861  8024 net.cpp:160]     with loss weight 1
I0523 01:54:14.196878  8024 net.cpp:165] Memory required for data: 78943808
I0523 01:54:14.196888  8024 net.cpp:226] loss needs backward computation.
I0523 01:54:14.196900  8024 net.cpp:228] accuracy does not need backward computation.
I0523 01:54:14.196912  8024 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 01:54:14.196921  8024 net.cpp:226] drop3 needs backward computation.
I0523 01:54:14.196933  8024 net.cpp:226] ip3 needs backward computation.
I0523 01:54:14.196944  8024 net.cpp:226] drop2 needs backward computation.
I0523 01:54:14.196954  8024 net.cpp:226] relu6 needs backward computation.
I0523 01:54:14.196971  8024 net.cpp:226] ip2 needs backward computation.
I0523 01:54:14.196982  8024 net.cpp:226] drop1 needs backward computation.
I0523 01:54:14.196991  8024 net.cpp:226] relu5 needs backward computation.
I0523 01:54:14.197001  8024 net.cpp:226] ip1 needs backward computation.
I0523 01:54:14.197011  8024 net.cpp:226] pool4 needs backward computation.
I0523 01:54:14.197021  8024 net.cpp:226] relu4 needs backward computation.
I0523 01:54:14.197031  8024 net.cpp:226] conv4 needs backward computation.
I0523 01:54:14.197041  8024 net.cpp:226] pool3 needs backward computation.
I0523 01:54:14.197052  8024 net.cpp:226] relu3 needs backward computation.
I0523 01:54:14.197062  8024 net.cpp:226] conv3 needs backward computation.
I0523 01:54:14.197072  8024 net.cpp:226] pool2 needs backward computation.
I0523 01:54:14.197083  8024 net.cpp:226] relu2 needs backward computation.
I0523 01:54:14.197093  8024 net.cpp:226] conv2 needs backward computation.
I0523 01:54:14.197103  8024 net.cpp:226] pool1 needs backward computation.
I0523 01:54:14.197113  8024 net.cpp:226] relu1 needs backward computation.
I0523 01:54:14.197124  8024 net.cpp:226] conv1 needs backward computation.
I0523 01:54:14.197135  8024 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 01:54:14.197146  8024 net.cpp:228] data_hdf5 does not need backward computation.
I0523 01:54:14.197156  8024 net.cpp:270] This network produces output accuracy
I0523 01:54:14.197165  8024 net.cpp:270] This network produces output loss
I0523 01:54:14.197193  8024 net.cpp:283] Network initialization done.
I0523 01:54:14.197326  8024 solver.cpp:60] Solver scaffolding done.
I0523 01:54:14.198459  8024 caffe.cpp:212] Starting Optimization
I0523 01:54:14.198478  8024 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 01:54:14.198492  8024 solver.cpp:289] Learning Rate Policy: fixed
I0523 01:54:14.199723  8024 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 01:55:03.000880  8024 solver.cpp:409]     Test net output #0: accuracy = 0.11468
I0523 01:55:03.001041  8024 solver.cpp:409]     Test net output #1: loss = 2.39546 (* 1 = 2.39546 loss)
I0523 01:55:03.025209  8024 solver.cpp:237] Iteration 0, loss = 2.39558
I0523 01:55:03.025246  8024 solver.cpp:253]     Train net output #0: loss = 2.39558 (* 1 = 2.39558 loss)
I0523 01:55:03.025264  8024 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0523 01:55:12.316750  8024 solver.cpp:237] Iteration 300, loss = 2.32255
I0523 01:55:12.316792  8024 solver.cpp:253]     Train net output #0: loss = 2.32255 (* 1 = 2.32255 loss)
I0523 01:55:12.316812  8024 sgd_solver.cpp:106] Iteration 300, lr = 0.0005
I0523 01:55:21.606035  8024 solver.cpp:237] Iteration 600, loss = 2.3606
I0523 01:55:21.606070  8024 solver.cpp:253]     Train net output #0: loss = 2.3606 (* 1 = 2.3606 loss)
I0523 01:55:21.606083  8024 sgd_solver.cpp:106] Iteration 600, lr = 0.0005
I0523 01:55:30.899724  8024 solver.cpp:237] Iteration 900, loss = 2.26966
I0523 01:55:30.899760  8024 solver.cpp:253]     Train net output #0: loss = 2.26966 (* 1 = 2.26966 loss)
I0523 01:55:30.899772  8024 sgd_solver.cpp:106] Iteration 900, lr = 0.0005
I0523 01:55:40.193886  8024 solver.cpp:237] Iteration 1200, loss = 2.23478
I0523 01:55:40.194043  8024 solver.cpp:253]     Train net output #0: loss = 2.23478 (* 1 = 2.23478 loss)
I0523 01:55:40.194057  8024 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0523 01:55:49.487558  8024 solver.cpp:237] Iteration 1500, loss = 2.2546
I0523 01:55:49.487592  8024 solver.cpp:253]     Train net output #0: loss = 2.2546 (* 1 = 2.2546 loss)
I0523 01:55:49.487612  8024 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0523 01:55:58.777973  8024 solver.cpp:237] Iteration 1800, loss = 2.15435
I0523 01:55:58.778023  8024 solver.cpp:253]     Train net output #0: loss = 2.15435 (* 1 = 2.15435 loss)
I0523 01:55:58.778039  8024 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0523 01:56:30.291654  8024 solver.cpp:237] Iteration 2100, loss = 2.06312
I0523 01:56:30.291816  8024 solver.cpp:253]     Train net output #0: loss = 2.06312 (* 1 = 2.06312 loss)
I0523 01:56:30.291832  8024 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0523 01:56:39.590626  8024 solver.cpp:237] Iteration 2400, loss = 1.97198
I0523 01:56:39.590662  8024 solver.cpp:253]     Train net output #0: loss = 1.97198 (* 1 = 1.97198 loss)
I0523 01:56:39.590679  8024 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0523 01:56:48.882298  8024 solver.cpp:237] Iteration 2700, loss = 2.04497
I0523 01:56:48.882335  8024 solver.cpp:253]     Train net output #0: loss = 2.04497 (* 1 = 2.04497 loss)
I0523 01:56:48.882356  8024 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0523 01:56:58.142477  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_3000.caffemodel
I0523 01:56:58.205106  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_3000.solverstate
I0523 01:56:58.239754  8024 solver.cpp:237] Iteration 3000, loss = 1.92699
I0523 01:56:58.239799  8024 solver.cpp:253]     Train net output #0: loss = 1.92699 (* 1 = 1.92699 loss)
I0523 01:56:58.239812  8024 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0523 01:57:07.537313  8024 solver.cpp:237] Iteration 3300, loss = 2.01129
I0523 01:57:07.537454  8024 solver.cpp:253]     Train net output #0: loss = 2.01129 (* 1 = 2.01129 loss)
I0523 01:57:07.537467  8024 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0523 01:57:16.834028  8024 solver.cpp:237] Iteration 3600, loss = 1.93488
I0523 01:57:16.834064  8024 solver.cpp:253]     Train net output #0: loss = 1.93488 (* 1 = 1.93488 loss)
I0523 01:57:16.834084  8024 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0523 01:57:26.128702  8024 solver.cpp:237] Iteration 3900, loss = 1.88752
I0523 01:57:26.128738  8024 solver.cpp:253]     Train net output #0: loss = 1.88752 (* 1 = 1.88752 loss)
I0523 01:57:26.128754  8024 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0523 01:57:57.621362  8024 solver.cpp:237] Iteration 4200, loss = 1.53513
I0523 01:57:57.621520  8024 solver.cpp:253]     Train net output #0: loss = 1.53513 (* 1 = 1.53513 loss)
I0523 01:57:57.621533  8024 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0523 01:58:06.916141  8024 solver.cpp:237] Iteration 4500, loss = 1.82907
I0523 01:58:06.916185  8024 solver.cpp:253]     Train net output #0: loss = 1.82907 (* 1 = 1.82907 loss)
I0523 01:58:06.916203  8024 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0523 01:58:16.213196  8024 solver.cpp:237] Iteration 4800, loss = 1.85936
I0523 01:58:16.213230  8024 solver.cpp:253]     Train net output #0: loss = 1.85936 (* 1 = 1.85936 loss)
I0523 01:58:16.213248  8024 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0523 01:58:25.505187  8024 solver.cpp:237] Iteration 5100, loss = 1.64862
I0523 01:58:25.505223  8024 solver.cpp:253]     Train net output #0: loss = 1.64862 (* 1 = 1.64862 loss)
I0523 01:58:25.505239  8024 sgd_solver.cpp:106] Iteration 5100, lr = 0.0005
I0523 01:58:34.804008  8024 solver.cpp:237] Iteration 5400, loss = 1.86823
I0523 01:58:34.804169  8024 solver.cpp:253]     Train net output #0: loss = 1.86823 (* 1 = 1.86823 loss)
I0523 01:58:34.804183  8024 sgd_solver.cpp:106] Iteration 5400, lr = 0.0005
I0523 01:58:44.097955  8024 solver.cpp:237] Iteration 5700, loss = 1.60625
I0523 01:58:44.097990  8024 solver.cpp:253]     Train net output #0: loss = 1.60625 (* 1 = 1.60625 loss)
I0523 01:58:44.098007  8024 sgd_solver.cpp:106] Iteration 5700, lr = 0.0005
I0523 01:58:53.365106  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_6000.caffemodel
I0523 01:58:53.424435  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_6000.solverstate
I0523 01:58:53.449476  8024 solver.cpp:341] Iteration 6000, Testing net (#0)
I0523 01:59:41.264509  8024 solver.cpp:409]     Test net output #0: accuracy = 0.635654
I0523 01:59:41.264685  8024 solver.cpp:409]     Test net output #1: loss = 1.2734 (* 1 = 1.2734 loss)
I0523 02:00:03.545651  8024 solver.cpp:237] Iteration 6000, loss = 1.62917
I0523 02:00:03.545706  8024 solver.cpp:253]     Train net output #0: loss = 1.62917 (* 1 = 1.62917 loss)
I0523 02:00:03.545722  8024 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0523 02:00:12.838131  8024 solver.cpp:237] Iteration 6300, loss = 1.73305
I0523 02:00:12.838295  8024 solver.cpp:253]     Train net output #0: loss = 1.73305 (* 1 = 1.73305 loss)
I0523 02:00:12.838310  8024 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0523 02:00:22.129173  8024 solver.cpp:237] Iteration 6600, loss = 1.62308
I0523 02:00:22.129209  8024 solver.cpp:253]     Train net output #0: loss = 1.62308 (* 1 = 1.62308 loss)
I0523 02:00:22.129225  8024 sgd_solver.cpp:106] Iteration 6600, lr = 0.0005
I0523 02:00:31.415009  8024 solver.cpp:237] Iteration 6900, loss = 1.64301
I0523 02:00:31.415043  8024 solver.cpp:253]     Train net output #0: loss = 1.64301 (* 1 = 1.64301 loss)
I0523 02:00:31.415057  8024 sgd_solver.cpp:106] Iteration 6900, lr = 0.0005
I0523 02:00:40.705405  8024 solver.cpp:237] Iteration 7200, loss = 1.6766
I0523 02:00:40.705453  8024 solver.cpp:253]     Train net output #0: loss = 1.6766 (* 1 = 1.6766 loss)
I0523 02:00:40.705467  8024 sgd_solver.cpp:106] Iteration 7200, lr = 0.0005
I0523 02:00:49.993885  8024 solver.cpp:237] Iteration 7500, loss = 1.53288
I0523 02:00:49.994024  8024 solver.cpp:253]     Train net output #0: loss = 1.53288 (* 1 = 1.53288 loss)
I0523 02:00:49.994040  8024 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0523 02:00:59.282335  8024 solver.cpp:237] Iteration 7800, loss = 1.37852
I0523 02:00:59.282376  8024 solver.cpp:253]     Train net output #0: loss = 1.37852 (* 1 = 1.37852 loss)
I0523 02:00:59.282394  8024 sgd_solver.cpp:106] Iteration 7800, lr = 0.0005
I0523 02:01:30.792387  8024 solver.cpp:237] Iteration 8100, loss = 1.61931
I0523 02:01:30.792548  8024 solver.cpp:253]     Train net output #0: loss = 1.61931 (* 1 = 1.61931 loss)
I0523 02:01:30.792564  8024 sgd_solver.cpp:106] Iteration 8100, lr = 0.0005
I0523 02:01:40.084249  8024 solver.cpp:237] Iteration 8400, loss = 1.43927
I0523 02:01:40.084283  8024 solver.cpp:253]     Train net output #0: loss = 1.43927 (* 1 = 1.43927 loss)
I0523 02:01:40.084297  8024 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0523 02:01:49.367581  8024 solver.cpp:237] Iteration 8700, loss = 1.88573
I0523 02:01:49.367627  8024 solver.cpp:253]     Train net output #0: loss = 1.88573 (* 1 = 1.88573 loss)
I0523 02:01:49.367645  8024 sgd_solver.cpp:106] Iteration 8700, lr = 0.0005
I0523 02:01:58.623491  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_9000.caffemodel
I0523 02:01:58.684564  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_9000.solverstate
I0523 02:01:58.721179  8024 solver.cpp:237] Iteration 9000, loss = 1.62963
I0523 02:01:58.721225  8024 solver.cpp:253]     Train net output #0: loss = 1.62963 (* 1 = 1.62963 loss)
I0523 02:01:58.721242  8024 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0523 02:02:08.008033  8024 solver.cpp:237] Iteration 9300, loss = 1.50664
I0523 02:02:08.008188  8024 solver.cpp:253]     Train net output #0: loss = 1.50664 (* 1 = 1.50664 loss)
I0523 02:02:08.008203  8024 sgd_solver.cpp:106] Iteration 9300, lr = 0.0005
I0523 02:02:17.294759  8024 solver.cpp:237] Iteration 9600, loss = 1.71236
I0523 02:02:17.294807  8024 solver.cpp:253]     Train net output #0: loss = 1.71236 (* 1 = 1.71236 loss)
I0523 02:02:17.294824  8024 sgd_solver.cpp:106] Iteration 9600, lr = 0.0005
I0523 02:02:26.580449  8024 solver.cpp:237] Iteration 9900, loss = 1.56584
I0523 02:02:26.580485  8024 solver.cpp:253]     Train net output #0: loss = 1.56584 (* 1 = 1.56584 loss)
I0523 02:02:26.580502  8024 sgd_solver.cpp:106] Iteration 9900, lr = 0.0005
I0523 02:02:58.112226  8024 solver.cpp:237] Iteration 10200, loss = 1.43709
I0523 02:02:58.112390  8024 solver.cpp:253]     Train net output #0: loss = 1.43709 (* 1 = 1.43709 loss)
I0523 02:02:58.112403  8024 sgd_solver.cpp:106] Iteration 10200, lr = 0.0005
I0523 02:03:07.400771  8024 solver.cpp:237] Iteration 10500, loss = 1.8716
I0523 02:03:07.400815  8024 solver.cpp:253]     Train net output #0: loss = 1.8716 (* 1 = 1.8716 loss)
I0523 02:03:07.400832  8024 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0523 02:03:16.688478  8024 solver.cpp:237] Iteration 10800, loss = 1.70311
I0523 02:03:16.688514  8024 solver.cpp:253]     Train net output #0: loss = 1.70311 (* 1 = 1.70311 loss)
I0523 02:03:16.688531  8024 sgd_solver.cpp:106] Iteration 10800, lr = 0.0005
I0523 02:03:25.979320  8024 solver.cpp:237] Iteration 11100, loss = 1.60975
I0523 02:03:25.979354  8024 solver.cpp:253]     Train net output #0: loss = 1.60975 (* 1 = 1.60975 loss)
I0523 02:03:25.979370  8024 sgd_solver.cpp:106] Iteration 11100, lr = 0.0005
I0523 02:03:35.266763  8024 solver.cpp:237] Iteration 11400, loss = 1.46362
I0523 02:03:35.266911  8024 solver.cpp:253]     Train net output #0: loss = 1.46362 (* 1 = 1.46362 loss)
I0523 02:03:35.266927  8024 sgd_solver.cpp:106] Iteration 11400, lr = 0.0005
I0523 02:03:44.556591  8024 solver.cpp:237] Iteration 11700, loss = 1.55743
I0523 02:03:44.556627  8024 solver.cpp:253]     Train net output #0: loss = 1.55743 (* 1 = 1.55743 loss)
I0523 02:03:44.556643  8024 sgd_solver.cpp:106] Iteration 11700, lr = 0.0005
I0523 02:03:53.812156  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_12000.caffemodel
I0523 02:03:53.882496  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_12000.solverstate
I0523 02:03:53.909826  8024 solver.cpp:341] Iteration 12000, Testing net (#0)
I0523 02:05:02.649870  8024 solver.cpp:409]     Test net output #0: accuracy = 0.686913
I0523 02:05:02.650027  8024 solver.cpp:409]     Test net output #1: loss = 1.09751 (* 1 = 1.09751 loss)
I0523 02:05:24.883363  8024 solver.cpp:237] Iteration 12000, loss = 1.66506
I0523 02:05:24.883416  8024 solver.cpp:253]     Train net output #0: loss = 1.66506 (* 1 = 1.66506 loss)
I0523 02:05:24.883433  8024 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0523 02:05:34.191215  8024 solver.cpp:237] Iteration 12300, loss = 1.18067
I0523 02:05:34.191385  8024 solver.cpp:253]     Train net output #0: loss = 1.18067 (* 1 = 1.18067 loss)
I0523 02:05:34.191398  8024 sgd_solver.cpp:106] Iteration 12300, lr = 0.0005
I0523 02:05:43.495822  8024 solver.cpp:237] Iteration 12600, loss = 1.50712
I0523 02:05:43.495857  8024 solver.cpp:253]     Train net output #0: loss = 1.50712 (* 1 = 1.50712 loss)
I0523 02:05:43.495874  8024 sgd_solver.cpp:106] Iteration 12600, lr = 0.0005
I0523 02:05:52.798440  8024 solver.cpp:237] Iteration 12900, loss = 1.63933
I0523 02:05:52.798476  8024 solver.cpp:253]     Train net output #0: loss = 1.63933 (* 1 = 1.63933 loss)
I0523 02:05:52.798492  8024 sgd_solver.cpp:106] Iteration 12900, lr = 0.0005
I0523 02:06:02.103957  8024 solver.cpp:237] Iteration 13200, loss = 1.61041
I0523 02:06:02.104002  8024 solver.cpp:253]     Train net output #0: loss = 1.61041 (* 1 = 1.61041 loss)
I0523 02:06:02.104019  8024 sgd_solver.cpp:106] Iteration 13200, lr = 0.0005
I0523 02:06:11.410604  8024 solver.cpp:237] Iteration 13500, loss = 1.4861
I0523 02:06:11.410744  8024 solver.cpp:253]     Train net output #0: loss = 1.4861 (* 1 = 1.4861 loss)
I0523 02:06:11.410758  8024 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0523 02:06:20.707556  8024 solver.cpp:237] Iteration 13800, loss = 1.72562
I0523 02:06:20.707589  8024 solver.cpp:253]     Train net output #0: loss = 1.72562 (* 1 = 1.72562 loss)
I0523 02:06:20.707608  8024 sgd_solver.cpp:106] Iteration 13800, lr = 0.0005
I0523 02:06:52.241433  8024 solver.cpp:237] Iteration 14100, loss = 1.53476
I0523 02:06:52.241595  8024 solver.cpp:253]     Train net output #0: loss = 1.53476 (* 1 = 1.53476 loss)
I0523 02:06:52.241610  8024 sgd_solver.cpp:106] Iteration 14100, lr = 0.0005
I0523 02:07:01.543272  8024 solver.cpp:237] Iteration 14400, loss = 1.80103
I0523 02:07:01.543308  8024 solver.cpp:253]     Train net output #0: loss = 1.80103 (* 1 = 1.80103 loss)
I0523 02:07:01.543320  8024 sgd_solver.cpp:106] Iteration 14400, lr = 0.0005
I0523 02:07:10.846828  8024 solver.cpp:237] Iteration 14700, loss = 1.99398
I0523 02:07:10.846863  8024 solver.cpp:253]     Train net output #0: loss = 1.99398 (* 1 = 1.99398 loss)
I0523 02:07:10.846879  8024 sgd_solver.cpp:106] Iteration 14700, lr = 0.0005
I0523 02:07:20.118304  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_15000.caffemodel
I0523 02:07:20.179680  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_15000.solverstate
I0523 02:07:20.216655  8024 solver.cpp:237] Iteration 15000, loss = 1.51377
I0523 02:07:20.216706  8024 solver.cpp:253]     Train net output #0: loss = 1.51377 (* 1 = 1.51377 loss)
I0523 02:07:20.216720  8024 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0523 02:07:29.526772  8024 solver.cpp:237] Iteration 15300, loss = 1.71152
I0523 02:07:29.526918  8024 solver.cpp:253]     Train net output #0: loss = 1.71152 (* 1 = 1.71152 loss)
I0523 02:07:29.526932  8024 sgd_solver.cpp:106] Iteration 15300, lr = 0.0005
I0523 02:07:38.833226  8024 solver.cpp:237] Iteration 15600, loss = 1.61272
I0523 02:07:38.833276  8024 solver.cpp:253]     Train net output #0: loss = 1.61272 (* 1 = 1.61272 loss)
I0523 02:07:38.833289  8024 sgd_solver.cpp:106] Iteration 15600, lr = 0.0005
I0523 02:07:48.140209  8024 solver.cpp:237] Iteration 15900, loss = 1.78825
I0523 02:07:48.140244  8024 solver.cpp:253]     Train net output #0: loss = 1.78825 (* 1 = 1.78825 loss)
I0523 02:07:48.140260  8024 sgd_solver.cpp:106] Iteration 15900, lr = 0.0005
I0523 02:08:19.688832  8024 solver.cpp:237] Iteration 16200, loss = 1.47259
I0523 02:08:19.689026  8024 solver.cpp:253]     Train net output #0: loss = 1.47259 (* 1 = 1.47259 loss)
I0523 02:08:19.689041  8024 sgd_solver.cpp:106] Iteration 16200, lr = 0.0005
I0523 02:08:28.994343  8024 solver.cpp:237] Iteration 16500, loss = 1.52651
I0523 02:08:28.994387  8024 solver.cpp:253]     Train net output #0: loss = 1.52651 (* 1 = 1.52651 loss)
I0523 02:08:28.994402  8024 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0523 02:08:38.299521  8024 solver.cpp:237] Iteration 16800, loss = 1.29889
I0523 02:08:38.299558  8024 solver.cpp:253]     Train net output #0: loss = 1.29889 (* 1 = 1.29889 loss)
I0523 02:08:38.299574  8024 sgd_solver.cpp:106] Iteration 16800, lr = 0.0005
I0523 02:08:47.604195  8024 solver.cpp:237] Iteration 17100, loss = 1.46193
I0523 02:08:47.604231  8024 solver.cpp:253]     Train net output #0: loss = 1.46193 (* 1 = 1.46193 loss)
I0523 02:08:47.604246  8024 sgd_solver.cpp:106] Iteration 17100, lr = 0.0005
I0523 02:08:56.907945  8024 solver.cpp:237] Iteration 17400, loss = 1.27689
I0523 02:08:56.908104  8024 solver.cpp:253]     Train net output #0: loss = 1.27689 (* 1 = 1.27689 loss)
I0523 02:08:56.908119  8024 sgd_solver.cpp:106] Iteration 17400, lr = 0.0005
I0523 02:09:06.209936  8024 solver.cpp:237] Iteration 17700, loss = 1.39023
I0523 02:09:06.209971  8024 solver.cpp:253]     Train net output #0: loss = 1.39023 (* 1 = 1.39023 loss)
I0523 02:09:06.209988  8024 sgd_solver.cpp:106] Iteration 17700, lr = 0.0005
I0523 02:09:15.485035  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_18000.caffemodel
I0523 02:09:15.544258  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_18000.solverstate
I0523 02:09:15.570219  8024 solver.cpp:341] Iteration 18000, Testing net (#0)
I0523 02:10:03.058374  8024 solver.cpp:409]     Test net output #0: accuracy = 0.74922
I0523 02:10:03.058539  8024 solver.cpp:409]     Test net output #1: loss = 0.918784 (* 1 = 0.918784 loss)
I0523 02:10:25.267333  8024 solver.cpp:237] Iteration 18000, loss = 1.17019
I0523 02:10:25.267386  8024 solver.cpp:253]     Train net output #0: loss = 1.17019 (* 1 = 1.17019 loss)
I0523 02:10:25.267405  8024 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0523 02:10:34.555966  8024 solver.cpp:237] Iteration 18300, loss = 1.21364
I0523 02:10:34.556126  8024 solver.cpp:253]     Train net output #0: loss = 1.21364 (* 1 = 1.21364 loss)
I0523 02:10:34.556140  8024 sgd_solver.cpp:106] Iteration 18300, lr = 0.0005
I0523 02:10:43.842563  8024 solver.cpp:237] Iteration 18600, loss = 1.65023
I0523 02:10:43.842598  8024 solver.cpp:253]     Train net output #0: loss = 1.65023 (* 1 = 1.65023 loss)
I0523 02:10:43.842617  8024 sgd_solver.cpp:106] Iteration 18600, lr = 0.0005
I0523 02:10:53.127784  8024 solver.cpp:237] Iteration 18900, loss = 1.76693
I0523 02:10:53.127820  8024 solver.cpp:253]     Train net output #0: loss = 1.76693 (* 1 = 1.76693 loss)
I0523 02:10:53.127832  8024 sgd_solver.cpp:106] Iteration 18900, lr = 0.0005
I0523 02:11:02.415207  8024 solver.cpp:237] Iteration 19200, loss = 1.38399
I0523 02:11:02.415246  8024 solver.cpp:253]     Train net output #0: loss = 1.38399 (* 1 = 1.38399 loss)
I0523 02:11:02.415266  8024 sgd_solver.cpp:106] Iteration 19200, lr = 0.0005
I0523 02:11:11.704670  8024 solver.cpp:237] Iteration 19500, loss = 1.53648
I0523 02:11:11.704809  8024 solver.cpp:253]     Train net output #0: loss = 1.53648 (* 1 = 1.53648 loss)
I0523 02:11:11.704823  8024 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0523 02:11:20.989284  8024 solver.cpp:237] Iteration 19800, loss = 1.41747
I0523 02:11:20.989317  8024 solver.cpp:253]     Train net output #0: loss = 1.41747 (* 1 = 1.41747 loss)
I0523 02:11:20.989336  8024 sgd_solver.cpp:106] Iteration 19800, lr = 0.0005
I0523 02:11:52.495682  8024 solver.cpp:237] Iteration 20100, loss = 1.29103
I0523 02:11:52.495857  8024 solver.cpp:253]     Train net output #0: loss = 1.29103 (* 1 = 1.29103 loss)
I0523 02:11:52.495872  8024 sgd_solver.cpp:106] Iteration 20100, lr = 0.0005
I0523 02:12:01.779247  8024 solver.cpp:237] Iteration 20400, loss = 1.71522
I0523 02:12:01.779280  8024 solver.cpp:253]     Train net output #0: loss = 1.71522 (* 1 = 1.71522 loss)
I0523 02:12:01.779297  8024 sgd_solver.cpp:106] Iteration 20400, lr = 0.0005
I0523 02:12:11.066805  8024 solver.cpp:237] Iteration 20700, loss = 1.23521
I0523 02:12:11.066840  8024 solver.cpp:253]     Train net output #0: loss = 1.23521 (* 1 = 1.23521 loss)
I0523 02:12:11.066857  8024 sgd_solver.cpp:106] Iteration 20700, lr = 0.0005
I0523 02:12:20.323597  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_21000.caffemodel
I0523 02:12:20.382719  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_21000.solverstate
I0523 02:12:20.418737  8024 solver.cpp:237] Iteration 21000, loss = 1.45891
I0523 02:12:20.418782  8024 solver.cpp:253]     Train net output #0: loss = 1.45891 (* 1 = 1.45891 loss)
I0523 02:12:20.418797  8024 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0523 02:12:29.704432  8024 solver.cpp:237] Iteration 21300, loss = 1.51692
I0523 02:12:29.704581  8024 solver.cpp:253]     Train net output #0: loss = 1.51692 (* 1 = 1.51692 loss)
I0523 02:12:29.704596  8024 sgd_solver.cpp:106] Iteration 21300, lr = 0.0005
I0523 02:12:38.995996  8024 solver.cpp:237] Iteration 21600, loss = 1.57577
I0523 02:12:38.996044  8024 solver.cpp:253]     Train net output #0: loss = 1.57577 (* 1 = 1.57577 loss)
I0523 02:12:38.996062  8024 sgd_solver.cpp:106] Iteration 21600, lr = 0.0005
I0523 02:12:48.298339  8024 solver.cpp:237] Iteration 21900, loss = 1.52944
I0523 02:12:48.298375  8024 solver.cpp:253]     Train net output #0: loss = 1.52944 (* 1 = 1.52944 loss)
I0523 02:12:48.298391  8024 sgd_solver.cpp:106] Iteration 21900, lr = 0.0005
I0523 02:13:19.831635  8024 solver.cpp:237] Iteration 22200, loss = 1.06364
I0523 02:13:19.831821  8024 solver.cpp:253]     Train net output #0: loss = 1.06364 (* 1 = 1.06364 loss)
I0523 02:13:19.831835  8024 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005
I0523 02:13:29.133582  8024 solver.cpp:237] Iteration 22500, loss = 1.63714
I0523 02:13:29.133625  8024 solver.cpp:253]     Train net output #0: loss = 1.63714 (* 1 = 1.63714 loss)
I0523 02:13:29.133640  8024 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0523 02:13:38.438313  8024 solver.cpp:237] Iteration 22800, loss = 1.52122
I0523 02:13:38.438349  8024 solver.cpp:253]     Train net output #0: loss = 1.52122 (* 1 = 1.52122 loss)
I0523 02:13:38.438364  8024 sgd_solver.cpp:106] Iteration 22800, lr = 0.0005
I0523 02:13:47.742358  8024 solver.cpp:237] Iteration 23100, loss = 1.63904
I0523 02:13:47.742393  8024 solver.cpp:253]     Train net output #0: loss = 1.63904 (* 1 = 1.63904 loss)
I0523 02:13:47.742409  8024 sgd_solver.cpp:106] Iteration 23100, lr = 0.0005
I0523 02:13:57.047615  8024 solver.cpp:237] Iteration 23400, loss = 1.56815
I0523 02:13:57.047773  8024 solver.cpp:253]     Train net output #0: loss = 1.56815 (* 1 = 1.56815 loss)
I0523 02:13:57.047787  8024 sgd_solver.cpp:106] Iteration 23400, lr = 0.0005
I0523 02:14:06.351533  8024 solver.cpp:237] Iteration 23700, loss = 1.30988
I0523 02:14:06.351568  8024 solver.cpp:253]     Train net output #0: loss = 1.30988 (* 1 = 1.30988 loss)
I0523 02:14:06.351584  8024 sgd_solver.cpp:106] Iteration 23700, lr = 0.0005
I0523 02:14:15.623209  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_24000.caffemodel
I0523 02:14:15.682416  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_24000.solverstate
I0523 02:14:15.708901  8024 solver.cpp:341] Iteration 24000, Testing net (#0)
I0523 02:15:24.297755  8024 solver.cpp:409]     Test net output #0: accuracy = 0.791069
I0523 02:15:24.297925  8024 solver.cpp:409]     Test net output #1: loss = 0.761155 (* 1 = 0.761155 loss)
I0523 02:15:46.557042  8024 solver.cpp:237] Iteration 24000, loss = 1.39042
I0523 02:15:46.557096  8024 solver.cpp:253]     Train net output #0: loss = 1.39042 (* 1 = 1.39042 loss)
I0523 02:15:46.557111  8024 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0523 02:15:55.852320  8024 solver.cpp:237] Iteration 24300, loss = 1.33569
I0523 02:15:55.852478  8024 solver.cpp:253]     Train net output #0: loss = 1.33569 (* 1 = 1.33569 loss)
I0523 02:15:55.852491  8024 sgd_solver.cpp:106] Iteration 24300, lr = 0.0005
I0523 02:16:05.147078  8024 solver.cpp:237] Iteration 24600, loss = 1.48395
I0523 02:16:05.147120  8024 solver.cpp:253]     Train net output #0: loss = 1.48395 (* 1 = 1.48395 loss)
I0523 02:16:05.147135  8024 sgd_solver.cpp:106] Iteration 24600, lr = 0.0005
I0523 02:16:14.441422  8024 solver.cpp:237] Iteration 24900, loss = 1.33455
I0523 02:16:14.441457  8024 solver.cpp:253]     Train net output #0: loss = 1.33455 (* 1 = 1.33455 loss)
I0523 02:16:14.441471  8024 sgd_solver.cpp:106] Iteration 24900, lr = 0.0005
I0523 02:16:23.737112  8024 solver.cpp:237] Iteration 25200, loss = 1.27234
I0523 02:16:23.737155  8024 solver.cpp:253]     Train net output #0: loss = 1.27234 (* 1 = 1.27234 loss)
I0523 02:16:23.737171  8024 sgd_solver.cpp:106] Iteration 25200, lr = 0.0005
I0523 02:16:33.028643  8024 solver.cpp:237] Iteration 25500, loss = 1.59179
I0523 02:16:33.028789  8024 solver.cpp:253]     Train net output #0: loss = 1.59179 (* 1 = 1.59179 loss)
I0523 02:16:33.028803  8024 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0523 02:16:42.327339  8024 solver.cpp:237] Iteration 25800, loss = 1.31922
I0523 02:16:42.327374  8024 solver.cpp:253]     Train net output #0: loss = 1.31922 (* 1 = 1.31922 loss)
I0523 02:16:42.327389  8024 sgd_solver.cpp:106] Iteration 25800, lr = 0.0005
I0523 02:17:13.852627  8024 solver.cpp:237] Iteration 26100, loss = 1.38754
I0523 02:17:13.852813  8024 solver.cpp:253]     Train net output #0: loss = 1.38754 (* 1 = 1.38754 loss)
I0523 02:17:13.852828  8024 sgd_solver.cpp:106] Iteration 26100, lr = 0.0005
I0523 02:17:23.144533  8024 solver.cpp:237] Iteration 26400, loss = 1.48539
I0523 02:17:23.144567  8024 solver.cpp:253]     Train net output #0: loss = 1.48539 (* 1 = 1.48539 loss)
I0523 02:17:23.144582  8024 sgd_solver.cpp:106] Iteration 26400, lr = 0.0005
I0523 02:17:32.437422  8024 solver.cpp:237] Iteration 26700, loss = 1.53221
I0523 02:17:32.437455  8024 solver.cpp:253]     Train net output #0: loss = 1.53221 (* 1 = 1.53221 loss)
I0523 02:17:32.437471  8024 sgd_solver.cpp:106] Iteration 26700, lr = 0.0005
I0523 02:17:41.704222  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_27000.caffemodel
I0523 02:17:41.770270  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_27000.solverstate
I0523 02:17:41.808290  8024 solver.cpp:237] Iteration 27000, loss = 1.56636
I0523 02:17:41.808336  8024 solver.cpp:253]     Train net output #0: loss = 1.56636 (* 1 = 1.56636 loss)
I0523 02:17:41.808351  8024 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0523 02:17:51.106019  8024 solver.cpp:237] Iteration 27300, loss = 1.40684
I0523 02:17:51.106169  8024 solver.cpp:253]     Train net output #0: loss = 1.40684 (* 1 = 1.40684 loss)
I0523 02:17:51.106184  8024 sgd_solver.cpp:106] Iteration 27300, lr = 0.0005
I0523 02:18:00.400832  8024 solver.cpp:237] Iteration 27600, loss = 1.48017
I0523 02:18:00.400867  8024 solver.cpp:253]     Train net output #0: loss = 1.48017 (* 1 = 1.48017 loss)
I0523 02:18:00.400882  8024 sgd_solver.cpp:106] Iteration 27600, lr = 0.0005
I0523 02:18:09.699393  8024 solver.cpp:237] Iteration 27900, loss = 1.5098
I0523 02:18:09.699440  8024 solver.cpp:253]     Train net output #0: loss = 1.5098 (* 1 = 1.5098 loss)
I0523 02:18:09.699455  8024 sgd_solver.cpp:106] Iteration 27900, lr = 0.0005
I0523 02:18:41.199903  8024 solver.cpp:237] Iteration 28200, loss = 1.26789
I0523 02:18:41.200101  8024 solver.cpp:253]     Train net output #0: loss = 1.26789 (* 1 = 1.26789 loss)
I0523 02:18:41.200115  8024 sgd_solver.cpp:106] Iteration 28200, lr = 0.0005
I0523 02:18:50.494539  8024 solver.cpp:237] Iteration 28500, loss = 1.69145
I0523 02:18:50.494573  8024 solver.cpp:253]     Train net output #0: loss = 1.69145 (* 1 = 1.69145 loss)
I0523 02:18:50.494590  8024 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0523 02:18:59.788769  8024 solver.cpp:237] Iteration 28800, loss = 1.51459
I0523 02:18:59.788810  8024 solver.cpp:253]     Train net output #0: loss = 1.51459 (* 1 = 1.51459 loss)
I0523 02:18:59.788827  8024 sgd_solver.cpp:106] Iteration 28800, lr = 0.0005
I0523 02:19:09.084317  8024 solver.cpp:237] Iteration 29100, loss = 1.68861
I0523 02:19:09.084352  8024 solver.cpp:253]     Train net output #0: loss = 1.68861 (* 1 = 1.68861 loss)
I0523 02:19:09.084367  8024 sgd_solver.cpp:106] Iteration 29100, lr = 0.0005
I0523 02:19:18.377406  8024 solver.cpp:237] Iteration 29400, loss = 1.40197
I0523 02:19:18.377564  8024 solver.cpp:253]     Train net output #0: loss = 1.40197 (* 1 = 1.40197 loss)
I0523 02:19:18.377578  8024 sgd_solver.cpp:106] Iteration 29400, lr = 0.0005
I0523 02:19:27.672184  8024 solver.cpp:237] Iteration 29700, loss = 1.33148
I0523 02:19:27.672219  8024 solver.cpp:253]     Train net output #0: loss = 1.33148 (* 1 = 1.33148 loss)
I0523 02:19:27.672233  8024 sgd_solver.cpp:106] Iteration 29700, lr = 0.0005
I0523 02:19:36.935022  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_30000.caffemodel
I0523 02:19:36.996217  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_30000.solverstate
I0523 02:19:37.024710  8024 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 02:20:24.829509  8024 solver.cpp:409]     Test net output #0: accuracy = 0.814691
I0523 02:20:24.829679  8024 solver.cpp:409]     Test net output #1: loss = 0.702578 (* 1 = 0.702578 loss)
I0523 02:20:45.745646  8024 solver.cpp:237] Iteration 30000, loss = 1.31875
I0523 02:20:45.745699  8024 solver.cpp:253]     Train net output #0: loss = 1.31875 (* 1 = 1.31875 loss)
I0523 02:20:45.745714  8024 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0523 02:20:55.036841  8024 solver.cpp:237] Iteration 30300, loss = 1.28605
I0523 02:20:55.037000  8024 solver.cpp:253]     Train net output #0: loss = 1.28605 (* 1 = 1.28605 loss)
I0523 02:20:55.037014  8024 sgd_solver.cpp:106] Iteration 30300, lr = 0.0005
I0523 02:21:04.326742  8024 solver.cpp:237] Iteration 30600, loss = 1.52047
I0523 02:21:04.326791  8024 solver.cpp:253]     Train net output #0: loss = 1.52047 (* 1 = 1.52047 loss)
I0523 02:21:04.326804  8024 sgd_solver.cpp:106] Iteration 30600, lr = 0.0005
I0523 02:21:13.619891  8024 solver.cpp:237] Iteration 30900, loss = 1.4675
I0523 02:21:13.619926  8024 solver.cpp:253]     Train net output #0: loss = 1.4675 (* 1 = 1.4675 loss)
I0523 02:21:13.619941  8024 sgd_solver.cpp:106] Iteration 30900, lr = 0.0005
I0523 02:21:22.914095  8024 solver.cpp:237] Iteration 31200, loss = 1.54896
I0523 02:21:22.914140  8024 solver.cpp:253]     Train net output #0: loss = 1.54896 (* 1 = 1.54896 loss)
I0523 02:21:22.914155  8024 sgd_solver.cpp:106] Iteration 31200, lr = 0.0005
I0523 02:21:32.206212  8024 solver.cpp:237] Iteration 31500, loss = 1.40028
I0523 02:21:32.206357  8024 solver.cpp:253]     Train net output #0: loss = 1.40028 (* 1 = 1.40028 loss)
I0523 02:21:32.206370  8024 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0523 02:21:41.498404  8024 solver.cpp:237] Iteration 31800, loss = 1.36879
I0523 02:21:41.498438  8024 solver.cpp:253]     Train net output #0: loss = 1.36879 (* 1 = 1.36879 loss)
I0523 02:21:41.498453  8024 sgd_solver.cpp:106] Iteration 31800, lr = 0.0005
I0523 02:22:11.688877  8024 solver.cpp:237] Iteration 32100, loss = 1.71801
I0523 02:22:11.689057  8024 solver.cpp:253]     Train net output #0: loss = 1.71801 (* 1 = 1.71801 loss)
I0523 02:22:11.689071  8024 sgd_solver.cpp:106] Iteration 32100, lr = 0.0005
I0523 02:22:20.982331  8024 solver.cpp:237] Iteration 32400, loss = 1.32629
I0523 02:22:20.982377  8024 solver.cpp:253]     Train net output #0: loss = 1.32629 (* 1 = 1.32629 loss)
I0523 02:22:20.982391  8024 sgd_solver.cpp:106] Iteration 32400, lr = 0.0005
I0523 02:22:30.278832  8024 solver.cpp:237] Iteration 32700, loss = 1.59539
I0523 02:22:30.278867  8024 solver.cpp:253]     Train net output #0: loss = 1.59539 (* 1 = 1.59539 loss)
I0523 02:22:30.278882  8024 sgd_solver.cpp:106] Iteration 32700, lr = 0.0005
I0523 02:22:39.541790  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_33000.caffemodel
I0523 02:22:39.601397  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_33000.solverstate
I0523 02:22:39.637107  8024 solver.cpp:237] Iteration 33000, loss = 1.0609
I0523 02:22:39.637152  8024 solver.cpp:253]     Train net output #0: loss = 1.0609 (* 1 = 1.0609 loss)
I0523 02:22:39.637169  8024 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0523 02:22:48.929913  8024 solver.cpp:237] Iteration 33300, loss = 1.49091
I0523 02:22:48.930068  8024 solver.cpp:253]     Train net output #0: loss = 1.49091 (* 1 = 1.49091 loss)
I0523 02:22:48.930081  8024 sgd_solver.cpp:106] Iteration 33300, lr = 0.0005
I0523 02:22:58.221812  8024 solver.cpp:237] Iteration 33600, loss = 1.43409
I0523 02:22:58.221846  8024 solver.cpp:253]     Train net output #0: loss = 1.43409 (* 1 = 1.43409 loss)
I0523 02:22:58.221861  8024 sgd_solver.cpp:106] Iteration 33600, lr = 0.0005
I0523 02:23:07.518604  8024 solver.cpp:237] Iteration 33900, loss = 1.14191
I0523 02:23:07.518643  8024 solver.cpp:253]     Train net output #0: loss = 1.14191 (* 1 = 1.14191 loss)
I0523 02:23:07.518662  8024 sgd_solver.cpp:106] Iteration 33900, lr = 0.0005
I0523 02:23:37.685499  8024 solver.cpp:237] Iteration 34200, loss = 1.33371
I0523 02:23:37.685672  8024 solver.cpp:253]     Train net output #0: loss = 1.33371 (* 1 = 1.33371 loss)
I0523 02:23:37.685688  8024 sgd_solver.cpp:106] Iteration 34200, lr = 0.0005
I0523 02:23:46.978689  8024 solver.cpp:237] Iteration 34500, loss = 1.20174
I0523 02:23:46.978724  8024 solver.cpp:253]     Train net output #0: loss = 1.20174 (* 1 = 1.20174 loss)
I0523 02:23:46.978739  8024 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0523 02:23:56.273077  8024 solver.cpp:237] Iteration 34800, loss = 1.4831
I0523 02:23:56.273118  8024 solver.cpp:253]     Train net output #0: loss = 1.4831 (* 1 = 1.4831 loss)
I0523 02:23:56.273135  8024 sgd_solver.cpp:106] Iteration 34800, lr = 0.0005
I0523 02:24:05.564877  8024 solver.cpp:237] Iteration 35100, loss = 1.28996
I0523 02:24:05.564913  8024 solver.cpp:253]     Train net output #0: loss = 1.28996 (* 1 = 1.28996 loss)
I0523 02:24:05.564925  8024 sgd_solver.cpp:106] Iteration 35100, lr = 0.0005
I0523 02:24:14.858351  8024 solver.cpp:237] Iteration 35400, loss = 1.2603
I0523 02:24:14.858496  8024 solver.cpp:253]     Train net output #0: loss = 1.2603 (* 1 = 1.2603 loss)
I0523 02:24:14.858510  8024 sgd_solver.cpp:106] Iteration 35400, lr = 0.0005
I0523 02:24:24.153064  8024 solver.cpp:237] Iteration 35700, loss = 1.3181
I0523 02:24:24.153106  8024 solver.cpp:253]     Train net output #0: loss = 1.3181 (* 1 = 1.3181 loss)
I0523 02:24:24.153121  8024 sgd_solver.cpp:106] Iteration 35700, lr = 0.0005
I0523 02:24:33.413985  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_36000.caffemodel
I0523 02:24:33.473170  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_36000.solverstate
I0523 02:24:33.499368  8024 solver.cpp:341] Iteration 36000, Testing net (#0)
I0523 02:25:42.132768  8024 solver.cpp:409]     Test net output #0: accuracy = 0.820752
I0523 02:25:42.132946  8024 solver.cpp:409]     Test net output #1: loss = 0.648054 (* 1 = 0.648054 loss)
I0523 02:26:03.018977  8024 solver.cpp:237] Iteration 36000, loss = 1.49483
I0523 02:26:03.019031  8024 solver.cpp:253]     Train net output #0: loss = 1.49483 (* 1 = 1.49483 loss)
I0523 02:26:03.019045  8024 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0523 02:26:12.316347  8024 solver.cpp:237] Iteration 36300, loss = 1.36453
I0523 02:26:12.316504  8024 solver.cpp:253]     Train net output #0: loss = 1.36453 (* 1 = 1.36453 loss)
I0523 02:26:12.316517  8024 sgd_solver.cpp:106] Iteration 36300, lr = 0.0005
I0523 02:26:21.613283  8024 solver.cpp:237] Iteration 36600, loss = 1.34239
I0523 02:26:21.613317  8024 solver.cpp:253]     Train net output #0: loss = 1.34239 (* 1 = 1.34239 loss)
I0523 02:26:21.613332  8024 sgd_solver.cpp:106] Iteration 36600, lr = 0.0005
I0523 02:26:30.907341  8024 solver.cpp:237] Iteration 36900, loss = 1.22952
I0523 02:26:30.907387  8024 solver.cpp:253]     Train net output #0: loss = 1.22952 (* 1 = 1.22952 loss)
I0523 02:26:30.907402  8024 sgd_solver.cpp:106] Iteration 36900, lr = 0.0005
I0523 02:26:40.205404  8024 solver.cpp:237] Iteration 37200, loss = 1.3727
I0523 02:26:40.205440  8024 solver.cpp:253]     Train net output #0: loss = 1.3727 (* 1 = 1.3727 loss)
I0523 02:26:40.205454  8024 sgd_solver.cpp:106] Iteration 37200, lr = 0.0005
I0523 02:26:49.503931  8024 solver.cpp:237] Iteration 37500, loss = 1.4623
I0523 02:26:49.504086  8024 solver.cpp:253]     Train net output #0: loss = 1.4623 (* 1 = 1.4623 loss)
I0523 02:26:49.504099  8024 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0523 02:26:58.801280  8024 solver.cpp:237] Iteration 37800, loss = 1.33899
I0523 02:26:58.801314  8024 solver.cpp:253]     Train net output #0: loss = 1.33899 (* 1 = 1.33899 loss)
I0523 02:26:58.801329  8024 sgd_solver.cpp:106] Iteration 37800, lr = 0.0005
I0523 02:27:28.984199  8024 solver.cpp:237] Iteration 38100, loss = 1.45691
I0523 02:27:28.984369  8024 solver.cpp:253]     Train net output #0: loss = 1.45691 (* 1 = 1.45691 loss)
I0523 02:27:28.984385  8024 sgd_solver.cpp:106] Iteration 38100, lr = 0.0005
I0523 02:27:38.281354  8024 solver.cpp:237] Iteration 38400, loss = 1.15781
I0523 02:27:38.281395  8024 solver.cpp:253]     Train net output #0: loss = 1.15781 (* 1 = 1.15781 loss)
I0523 02:27:38.281414  8024 sgd_solver.cpp:106] Iteration 38400, lr = 0.0005
I0523 02:27:47.578497  8024 solver.cpp:237] Iteration 38700, loss = 1.55153
I0523 02:27:47.578538  8024 solver.cpp:253]     Train net output #0: loss = 1.55153 (* 1 = 1.55153 loss)
I0523 02:27:47.578552  8024 sgd_solver.cpp:106] Iteration 38700, lr = 0.0005
I0523 02:27:56.841564  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_39000.caffemodel
I0523 02:27:56.900895  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_39000.solverstate
I0523 02:27:56.936648  8024 solver.cpp:237] Iteration 39000, loss = 1.49863
I0523 02:27:56.936687  8024 solver.cpp:253]     Train net output #0: loss = 1.49863 (* 1 = 1.49863 loss)
I0523 02:27:56.936702  8024 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0523 02:28:06.235903  8024 solver.cpp:237] Iteration 39300, loss = 1.67251
I0523 02:28:06.236078  8024 solver.cpp:253]     Train net output #0: loss = 1.67251 (* 1 = 1.67251 loss)
I0523 02:28:06.236090  8024 sgd_solver.cpp:106] Iteration 39300, lr = 0.0005
I0523 02:28:15.532323  8024 solver.cpp:237] Iteration 39600, loss = 1.42439
I0523 02:28:15.532358  8024 solver.cpp:253]     Train net output #0: loss = 1.42439 (* 1 = 1.42439 loss)
I0523 02:28:15.532374  8024 sgd_solver.cpp:106] Iteration 39600, lr = 0.0005
I0523 02:28:24.832444  8024 solver.cpp:237] Iteration 39900, loss = 1.38563
I0523 02:28:24.832479  8024 solver.cpp:253]     Train net output #0: loss = 1.38563 (* 1 = 1.38563 loss)
I0523 02:28:24.832494  8024 sgd_solver.cpp:106] Iteration 39900, lr = 0.0005
I0523 02:28:55.059741  8024 solver.cpp:237] Iteration 40200, loss = 1.41673
I0523 02:28:55.059913  8024 solver.cpp:253]     Train net output #0: loss = 1.41673 (* 1 = 1.41673 loss)
I0523 02:28:55.059931  8024 sgd_solver.cpp:106] Iteration 40200, lr = 0.0005
I0523 02:29:04.356348  8024 solver.cpp:237] Iteration 40500, loss = 1.23683
I0523 02:29:04.356382  8024 solver.cpp:253]     Train net output #0: loss = 1.23683 (* 1 = 1.23683 loss)
I0523 02:29:04.356398  8024 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0523 02:29:13.649464  8024 solver.cpp:237] Iteration 40800, loss = 1.1507
I0523 02:29:13.649498  8024 solver.cpp:253]     Train net output #0: loss = 1.1507 (* 1 = 1.1507 loss)
I0523 02:29:13.649514  8024 sgd_solver.cpp:106] Iteration 40800, lr = 0.0005
I0523 02:29:22.948117  8024 solver.cpp:237] Iteration 41100, loss = 1.35355
I0523 02:29:22.948159  8024 solver.cpp:253]     Train net output #0: loss = 1.35355 (* 1 = 1.35355 loss)
I0523 02:29:22.948175  8024 sgd_solver.cpp:106] Iteration 41100, lr = 0.0005
I0523 02:29:32.243696  8024 solver.cpp:237] Iteration 41400, loss = 1.44499
I0523 02:29:32.243844  8024 solver.cpp:253]     Train net output #0: loss = 1.44499 (* 1 = 1.44499 loss)
I0523 02:29:32.243857  8024 sgd_solver.cpp:106] Iteration 41400, lr = 0.0005
I0523 02:29:41.538606  8024 solver.cpp:237] Iteration 41700, loss = 0.963872
I0523 02:29:41.538641  8024 solver.cpp:253]     Train net output #0: loss = 0.963872 (* 1 = 0.963872 loss)
I0523 02:29:41.538656  8024 sgd_solver.cpp:106] Iteration 41700, lr = 0.0005
I0523 02:29:50.807467  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_42000.caffemodel
I0523 02:29:50.866921  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_42000.solverstate
I0523 02:29:50.892966  8024 solver.cpp:341] Iteration 42000, Testing net (#0)
I0523 02:30:38.387938  8024 solver.cpp:409]     Test net output #0: accuracy = 0.828643
I0523 02:30:38.388104  8024 solver.cpp:409]     Test net output #1: loss = 0.63043 (* 1 = 0.63043 loss)
I0523 02:30:59.304342  8024 solver.cpp:237] Iteration 42000, loss = 1.35853
I0523 02:30:59.304394  8024 solver.cpp:253]     Train net output #0: loss = 1.35853 (* 1 = 1.35853 loss)
I0523 02:30:59.304419  8024 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0523 02:31:08.605681  8024 solver.cpp:237] Iteration 42300, loss = 1.14668
I0523 02:31:08.605835  8024 solver.cpp:253]     Train net output #0: loss = 1.14668 (* 1 = 1.14668 loss)
I0523 02:31:08.605850  8024 sgd_solver.cpp:106] Iteration 42300, lr = 0.0005
I0523 02:31:17.906723  8024 solver.cpp:237] Iteration 42600, loss = 1.38652
I0523 02:31:17.906757  8024 solver.cpp:253]     Train net output #0: loss = 1.38652 (* 1 = 1.38652 loss)
I0523 02:31:17.906771  8024 sgd_solver.cpp:106] Iteration 42600, lr = 0.0005
I0523 02:31:27.210240  8024 solver.cpp:237] Iteration 42900, loss = 1.29389
I0523 02:31:27.210279  8024 solver.cpp:253]     Train net output #0: loss = 1.29389 (* 1 = 1.29389 loss)
I0523 02:31:27.210297  8024 sgd_solver.cpp:106] Iteration 42900, lr = 0.0005
I0523 02:31:36.513981  8024 solver.cpp:237] Iteration 43200, loss = 1.35019
I0523 02:31:36.514016  8024 solver.cpp:253]     Train net output #0: loss = 1.35019 (* 1 = 1.35019 loss)
I0523 02:31:36.514030  8024 sgd_solver.cpp:106] Iteration 43200, lr = 0.0005
I0523 02:31:45.823247  8024 solver.cpp:237] Iteration 43500, loss = 1.39574
I0523 02:31:45.823408  8024 solver.cpp:253]     Train net output #0: loss = 1.39574 (* 1 = 1.39574 loss)
I0523 02:31:45.823422  8024 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0523 02:31:55.126405  8024 solver.cpp:237] Iteration 43800, loss = 1.10051
I0523 02:31:55.126441  8024 solver.cpp:253]     Train net output #0: loss = 1.10051 (* 1 = 1.10051 loss)
I0523 02:31:55.126461  8024 sgd_solver.cpp:106] Iteration 43800, lr = 0.0005
I0523 02:32:25.392509  8024 solver.cpp:237] Iteration 44100, loss = 1.47724
I0523 02:32:25.392689  8024 solver.cpp:253]     Train net output #0: loss = 1.47724 (* 1 = 1.47724 loss)
I0523 02:32:25.392705  8024 sgd_solver.cpp:106] Iteration 44100, lr = 0.0005
I0523 02:32:34.697329  8024 solver.cpp:237] Iteration 44400, loss = 1.32988
I0523 02:32:34.697365  8024 solver.cpp:253]     Train net output #0: loss = 1.32988 (* 1 = 1.32988 loss)
I0523 02:32:34.697379  8024 sgd_solver.cpp:106] Iteration 44400, lr = 0.0005
I0523 02:32:44.006175  8024 solver.cpp:237] Iteration 44700, loss = 1.37506
I0523 02:32:44.006213  8024 solver.cpp:253]     Train net output #0: loss = 1.37506 (* 1 = 1.37506 loss)
I0523 02:32:44.006225  8024 sgd_solver.cpp:106] Iteration 44700, lr = 0.0005
I0523 02:32:53.280886  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_45000.caffemodel
I0523 02:32:53.342464  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_45000.solverstate
I0523 02:32:53.380324  8024 solver.cpp:237] Iteration 45000, loss = 1.41475
I0523 02:32:53.380370  8024 solver.cpp:253]     Train net output #0: loss = 1.41475 (* 1 = 1.41475 loss)
I0523 02:32:53.380384  8024 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0523 02:33:02.691256  8024 solver.cpp:237] Iteration 45300, loss = 1.17045
I0523 02:33:02.691424  8024 solver.cpp:253]     Train net output #0: loss = 1.17045 (* 1 = 1.17045 loss)
I0523 02:33:02.691438  8024 sgd_solver.cpp:106] Iteration 45300, lr = 0.0005
I0523 02:33:12.000391  8024 solver.cpp:237] Iteration 45600, loss = 1.13753
I0523 02:33:12.000425  8024 solver.cpp:253]     Train net output #0: loss = 1.13753 (* 1 = 1.13753 loss)
I0523 02:33:12.000440  8024 sgd_solver.cpp:106] Iteration 45600, lr = 0.0005
I0523 02:33:21.305217  8024 solver.cpp:237] Iteration 45900, loss = 1.3481
I0523 02:33:21.305251  8024 solver.cpp:253]     Train net output #0: loss = 1.3481 (* 1 = 1.3481 loss)
I0523 02:33:21.305266  8024 sgd_solver.cpp:106] Iteration 45900, lr = 0.0005
I0523 02:33:51.519362  8024 solver.cpp:237] Iteration 46200, loss = 1.29908
I0523 02:33:51.519537  8024 solver.cpp:253]     Train net output #0: loss = 1.29908 (* 1 = 1.29908 loss)
I0523 02:33:51.519553  8024 sgd_solver.cpp:106] Iteration 46200, lr = 0.0005
I0523 02:34:00.826293  8024 solver.cpp:237] Iteration 46500, loss = 1.22979
I0523 02:34:00.826333  8024 solver.cpp:253]     Train net output #0: loss = 1.22979 (* 1 = 1.22979 loss)
I0523 02:34:00.826352  8024 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0523 02:34:10.125927  8024 solver.cpp:237] Iteration 46800, loss = 1.20174
I0523 02:34:10.125963  8024 solver.cpp:253]     Train net output #0: loss = 1.20174 (* 1 = 1.20174 loss)
I0523 02:34:10.125978  8024 sgd_solver.cpp:106] Iteration 46800, lr = 0.0005
I0523 02:34:19.427069  8024 solver.cpp:237] Iteration 47100, loss = 1.336
I0523 02:34:19.427116  8024 solver.cpp:253]     Train net output #0: loss = 1.336 (* 1 = 1.336 loss)
I0523 02:34:19.427130  8024 sgd_solver.cpp:106] Iteration 47100, lr = 0.0005
I0523 02:34:28.733173  8024 solver.cpp:237] Iteration 47400, loss = 1.22608
I0523 02:34:28.733340  8024 solver.cpp:253]     Train net output #0: loss = 1.22608 (* 1 = 1.22608 loss)
I0523 02:34:28.733352  8024 sgd_solver.cpp:106] Iteration 47400, lr = 0.0005
I0523 02:34:38.038101  8024 solver.cpp:237] Iteration 47700, loss = 1.13929
I0523 02:34:38.038136  8024 solver.cpp:253]     Train net output #0: loss = 1.13929 (* 1 = 1.13929 loss)
I0523 02:34:38.038152  8024 sgd_solver.cpp:106] Iteration 47700, lr = 0.0005
I0523 02:34:47.311257  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_48000.caffemodel
I0523 02:34:47.371172  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_48000.solverstate
I0523 02:34:47.397369  8024 solver.cpp:341] Iteration 48000, Testing net (#0)
I0523 02:35:56.129088  8024 solver.cpp:409]     Test net output #0: accuracy = 0.828924
I0523 02:35:56.129264  8024 solver.cpp:409]     Test net output #1: loss = 0.59019 (* 1 = 0.59019 loss)
I0523 02:36:17.064422  8024 solver.cpp:237] Iteration 48000, loss = 1.02114
I0523 02:36:17.064476  8024 solver.cpp:253]     Train net output #0: loss = 1.02114 (* 1 = 1.02114 loss)
I0523 02:36:17.064491  8024 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0523 02:36:26.357578  8024 solver.cpp:237] Iteration 48300, loss = 1.20647
I0523 02:36:26.357744  8024 solver.cpp:253]     Train net output #0: loss = 1.20647 (* 1 = 1.20647 loss)
I0523 02:36:26.357758  8024 sgd_solver.cpp:106] Iteration 48300, lr = 0.0005
I0523 02:36:35.652616  8024 solver.cpp:237] Iteration 48600, loss = 1.25007
I0523 02:36:35.652652  8024 solver.cpp:253]     Train net output #0: loss = 1.25007 (* 1 = 1.25007 loss)
I0523 02:36:35.652667  8024 sgd_solver.cpp:106] Iteration 48600, lr = 0.0005
I0523 02:36:44.944483  8024 solver.cpp:237] Iteration 48900, loss = 1.5651
I0523 02:36:44.944519  8024 solver.cpp:253]     Train net output #0: loss = 1.5651 (* 1 = 1.5651 loss)
I0523 02:36:44.944532  8024 sgd_solver.cpp:106] Iteration 48900, lr = 0.0005
I0523 02:36:54.242004  8024 solver.cpp:237] Iteration 49200, loss = 1.16788
I0523 02:36:54.242044  8024 solver.cpp:253]     Train net output #0: loss = 1.16788 (* 1 = 1.16788 loss)
I0523 02:36:54.242064  8024 sgd_solver.cpp:106] Iteration 49200, lr = 0.0005
I0523 02:37:03.530706  8024 solver.cpp:237] Iteration 49500, loss = 1.35187
I0523 02:37:03.530858  8024 solver.cpp:253]     Train net output #0: loss = 1.35187 (* 1 = 1.35187 loss)
I0523 02:37:03.530872  8024 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0523 02:37:12.827280  8024 solver.cpp:237] Iteration 49800, loss = 1.19139
I0523 02:37:12.827329  8024 solver.cpp:253]     Train net output #0: loss = 1.19139 (* 1 = 1.19139 loss)
I0523 02:37:12.827345  8024 sgd_solver.cpp:106] Iteration 49800, lr = 0.0005
I0523 02:37:43.067953  8024 solver.cpp:237] Iteration 50100, loss = 1.31997
I0523 02:37:43.068173  8024 solver.cpp:253]     Train net output #0: loss = 1.31997 (* 1 = 1.31997 loss)
I0523 02:37:43.068189  8024 sgd_solver.cpp:106] Iteration 50100, lr = 0.0005
I0523 02:37:52.358427  8024 solver.cpp:237] Iteration 50400, loss = 1.42727
I0523 02:37:52.358461  8024 solver.cpp:253]     Train net output #0: loss = 1.42727 (* 1 = 1.42727 loss)
I0523 02:37:52.358477  8024 sgd_solver.cpp:106] Iteration 50400, lr = 0.0005
I0523 02:38:01.650563  8024 solver.cpp:237] Iteration 50700, loss = 1.37464
I0523 02:38:01.650599  8024 solver.cpp:253]     Train net output #0: loss = 1.37464 (* 1 = 1.37464 loss)
I0523 02:38:01.650612  8024 sgd_solver.cpp:106] Iteration 50700, lr = 0.0005
I0523 02:38:10.913624  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_51000.caffemodel
I0523 02:38:10.978755  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_51000.solverstate
I0523 02:38:11.014967  8024 solver.cpp:237] Iteration 51000, loss = 1.27928
I0523 02:38:11.015013  8024 solver.cpp:253]     Train net output #0: loss = 1.27928 (* 1 = 1.27928 loss)
I0523 02:38:11.015029  8024 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0523 02:38:20.310398  8024 solver.cpp:237] Iteration 51300, loss = 1.36085
I0523 02:38:20.310572  8024 solver.cpp:253]     Train net output #0: loss = 1.36085 (* 1 = 1.36085 loss)
I0523 02:38:20.310586  8024 sgd_solver.cpp:106] Iteration 51300, lr = 0.0005
I0523 02:38:29.603729  8024 solver.cpp:237] Iteration 51600, loss = 1.33576
I0523 02:38:29.603766  8024 solver.cpp:253]     Train net output #0: loss = 1.33576 (* 1 = 1.33576 loss)
I0523 02:38:29.603780  8024 sgd_solver.cpp:106] Iteration 51600, lr = 0.0005
I0523 02:38:38.901196  8024 solver.cpp:237] Iteration 51900, loss = 1.52091
I0523 02:38:38.901231  8024 solver.cpp:253]     Train net output #0: loss = 1.52091 (* 1 = 1.52091 loss)
I0523 02:38:38.901244  8024 sgd_solver.cpp:106] Iteration 51900, lr = 0.0005
I0523 02:39:09.071454  8024 solver.cpp:237] Iteration 52200, loss = 1.01668
I0523 02:39:09.071635  8024 solver.cpp:253]     Train net output #0: loss = 1.01668 (* 1 = 1.01668 loss)
I0523 02:39:09.071650  8024 sgd_solver.cpp:106] Iteration 52200, lr = 0.0005
I0523 02:39:18.366529  8024 solver.cpp:237] Iteration 52500, loss = 1.34983
I0523 02:39:18.366571  8024 solver.cpp:253]     Train net output #0: loss = 1.34983 (* 1 = 1.34983 loss)
I0523 02:39:18.366590  8024 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0523 02:39:27.656998  8024 solver.cpp:237] Iteration 52800, loss = 1.53275
I0523 02:39:27.657034  8024 solver.cpp:253]     Train net output #0: loss = 1.53275 (* 1 = 1.53275 loss)
I0523 02:39:27.657048  8024 sgd_solver.cpp:106] Iteration 52800, lr = 0.0005
I0523 02:39:36.949463  8024 solver.cpp:237] Iteration 53100, loss = 1.50983
I0523 02:39:36.949498  8024 solver.cpp:253]     Train net output #0: loss = 1.50983 (* 1 = 1.50983 loss)
I0523 02:39:36.949512  8024 sgd_solver.cpp:106] Iteration 53100, lr = 0.0005
I0523 02:39:46.243649  8024 solver.cpp:237] Iteration 53400, loss = 1.31148
I0523 02:39:46.243819  8024 solver.cpp:253]     Train net output #0: loss = 1.31148 (* 1 = 1.31148 loss)
I0523 02:39:46.243834  8024 sgd_solver.cpp:106] Iteration 53400, lr = 0.0005
I0523 02:39:55.537859  8024 solver.cpp:237] Iteration 53700, loss = 1.29905
I0523 02:39:55.537895  8024 solver.cpp:253]     Train net output #0: loss = 1.29905 (* 1 = 1.29905 loss)
I0523 02:39:55.537909  8024 sgd_solver.cpp:106] Iteration 53700, lr = 0.0005
I0523 02:40:04.797579  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_54000.caffemodel
I0523 02:40:04.857080  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_54000.solverstate
I0523 02:40:04.883280  8024 solver.cpp:341] Iteration 54000, Testing net (#0)
I0523 02:40:52.672670  8024 solver.cpp:409]     Test net output #0: accuracy = 0.840968
I0523 02:40:52.672854  8024 solver.cpp:409]     Test net output #1: loss = 0.558319 (* 1 = 0.558319 loss)
I0523 02:41:13.616101  8024 solver.cpp:237] Iteration 54000, loss = 1.38521
I0523 02:41:13.616153  8024 solver.cpp:253]     Train net output #0: loss = 1.38521 (* 1 = 1.38521 loss)
I0523 02:41:13.616168  8024 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0523 02:41:22.909051  8024 solver.cpp:237] Iteration 54300, loss = 1.21594
I0523 02:41:22.909224  8024 solver.cpp:253]     Train net output #0: loss = 1.21594 (* 1 = 1.21594 loss)
I0523 02:41:22.909237  8024 sgd_solver.cpp:106] Iteration 54300, lr = 0.0005
I0523 02:41:32.199079  8024 solver.cpp:237] Iteration 54600, loss = 0.995711
I0523 02:41:32.199115  8024 solver.cpp:253]     Train net output #0: loss = 0.995711 (* 1 = 0.995711 loss)
I0523 02:41:32.199131  8024 sgd_solver.cpp:106] Iteration 54600, lr = 0.0005
I0523 02:41:41.492409  8024 solver.cpp:237] Iteration 54900, loss = 1.19347
I0523 02:41:41.492444  8024 solver.cpp:253]     Train net output #0: loss = 1.19347 (* 1 = 1.19347 loss)
I0523 02:41:41.492460  8024 sgd_solver.cpp:106] Iteration 54900, lr = 0.0005
I0523 02:41:50.788193  8024 solver.cpp:237] Iteration 55200, loss = 1.29935
I0523 02:41:50.788233  8024 solver.cpp:253]     Train net output #0: loss = 1.29935 (* 1 = 1.29935 loss)
I0523 02:41:50.788254  8024 sgd_solver.cpp:106] Iteration 55200, lr = 0.0005
I0523 02:42:00.081651  8024 solver.cpp:237] Iteration 55500, loss = 1.44046
I0523 02:42:00.081815  8024 solver.cpp:253]     Train net output #0: loss = 1.44046 (* 1 = 1.44046 loss)
I0523 02:42:00.081828  8024 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0523 02:42:09.375219  8024 solver.cpp:237] Iteration 55800, loss = 1.12063
I0523 02:42:09.375253  8024 solver.cpp:253]     Train net output #0: loss = 1.12063 (* 1 = 1.12063 loss)
I0523 02:42:09.375268  8024 sgd_solver.cpp:106] Iteration 55800, lr = 0.0005
I0523 02:42:39.576724  8024 solver.cpp:237] Iteration 56100, loss = 1.54166
I0523 02:42:39.576905  8024 solver.cpp:253]     Train net output #0: loss = 1.54166 (* 1 = 1.54166 loss)
I0523 02:42:39.576920  8024 sgd_solver.cpp:106] Iteration 56100, lr = 0.0005
I0523 02:42:48.867125  8024 solver.cpp:237] Iteration 56400, loss = 1.10849
I0523 02:42:48.867159  8024 solver.cpp:253]     Train net output #0: loss = 1.10849 (* 1 = 1.10849 loss)
I0523 02:42:48.867173  8024 sgd_solver.cpp:106] Iteration 56400, lr = 0.0005
I0523 02:42:58.157553  8024 solver.cpp:237] Iteration 56700, loss = 1.11693
I0523 02:42:58.157589  8024 solver.cpp:253]     Train net output #0: loss = 1.11693 (* 1 = 1.11693 loss)
I0523 02:42:58.157603  8024 sgd_solver.cpp:106] Iteration 56700, lr = 0.0005
I0523 02:43:07.418895  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_57000.caffemodel
I0523 02:43:07.480396  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_57000.solverstate
I0523 02:43:07.518555  8024 solver.cpp:237] Iteration 57000, loss = 1.26562
I0523 02:43:07.518602  8024 solver.cpp:253]     Train net output #0: loss = 1.26562 (* 1 = 1.26562 loss)
I0523 02:43:07.518620  8024 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0523 02:43:16.808377  8024 solver.cpp:237] Iteration 57300, loss = 1.26186
I0523 02:43:16.808537  8024 solver.cpp:253]     Train net output #0: loss = 1.26186 (* 1 = 1.26186 loss)
I0523 02:43:16.808552  8024 sgd_solver.cpp:106] Iteration 57300, lr = 0.0005
I0523 02:43:26.098256  8024 solver.cpp:237] Iteration 57600, loss = 1.57082
I0523 02:43:26.098291  8024 solver.cpp:253]     Train net output #0: loss = 1.57082 (* 1 = 1.57082 loss)
I0523 02:43:26.098306  8024 sgd_solver.cpp:106] Iteration 57600, lr = 0.0005
I0523 02:43:35.388451  8024 solver.cpp:237] Iteration 57900, loss = 1.39952
I0523 02:43:35.388496  8024 solver.cpp:253]     Train net output #0: loss = 1.39952 (* 1 = 1.39952 loss)
I0523 02:43:35.388510  8024 sgd_solver.cpp:106] Iteration 57900, lr = 0.0005
I0523 02:44:05.558373  8024 solver.cpp:237] Iteration 58200, loss = 1.53177
I0523 02:44:05.558564  8024 solver.cpp:253]     Train net output #0: loss = 1.53177 (* 1 = 1.53177 loss)
I0523 02:44:05.558579  8024 sgd_solver.cpp:106] Iteration 58200, lr = 0.0005
I0523 02:44:14.848465  8024 solver.cpp:237] Iteration 58500, loss = 1.18325
I0523 02:44:14.848501  8024 solver.cpp:253]     Train net output #0: loss = 1.18325 (* 1 = 1.18325 loss)
I0523 02:44:14.848516  8024 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0523 02:44:24.140319  8024 solver.cpp:237] Iteration 58800, loss = 1.41643
I0523 02:44:24.140360  8024 solver.cpp:253]     Train net output #0: loss = 1.41643 (* 1 = 1.41643 loss)
I0523 02:44:24.140382  8024 sgd_solver.cpp:106] Iteration 58800, lr = 0.0005
I0523 02:44:33.432153  8024 solver.cpp:237] Iteration 59100, loss = 1.30535
I0523 02:44:33.432188  8024 solver.cpp:253]     Train net output #0: loss = 1.30535 (* 1 = 1.30535 loss)
I0523 02:44:33.432202  8024 sgd_solver.cpp:106] Iteration 59100, lr = 0.0005
I0523 02:44:42.726261  8024 solver.cpp:237] Iteration 59400, loss = 1.61947
I0523 02:44:42.726436  8024 solver.cpp:253]     Train net output #0: loss = 1.61947 (* 1 = 1.61947 loss)
I0523 02:44:42.726450  8024 sgd_solver.cpp:106] Iteration 59400, lr = 0.0005
I0523 02:44:52.018059  8024 solver.cpp:237] Iteration 59700, loss = 1.41489
I0523 02:44:52.018092  8024 solver.cpp:253]     Train net output #0: loss = 1.41489 (* 1 = 1.41489 loss)
I0523 02:44:52.018107  8024 sgd_solver.cpp:106] Iteration 59700, lr = 0.0005
I0523 02:45:01.279270  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_60000.caffemodel
I0523 02:45:01.410549  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_60000.solverstate
I0523 02:45:01.447270  8024 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 02:46:10.151474  8024 solver.cpp:409]     Test net output #0: accuracy = 0.843782
I0523 02:46:10.151651  8024 solver.cpp:409]     Test net output #1: loss = 0.534473 (* 1 = 0.534473 loss)
I0523 02:46:31.020674  8024 solver.cpp:237] Iteration 60000, loss = 1.13354
I0523 02:46:31.020727  8024 solver.cpp:253]     Train net output #0: loss = 1.13354 (* 1 = 1.13354 loss)
I0523 02:46:31.020742  8024 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0523 02:46:40.317482  8024 solver.cpp:237] Iteration 60300, loss = 1.16632
I0523 02:46:40.317644  8024 solver.cpp:253]     Train net output #0: loss = 1.16632 (* 1 = 1.16632 loss)
I0523 02:46:40.317657  8024 sgd_solver.cpp:106] Iteration 60300, lr = 0.0005
I0523 02:46:49.618252  8024 solver.cpp:237] Iteration 60600, loss = 1.39157
I0523 02:46:49.618299  8024 solver.cpp:253]     Train net output #0: loss = 1.39157 (* 1 = 1.39157 loss)
I0523 02:46:49.618314  8024 sgd_solver.cpp:106] Iteration 60600, lr = 0.0005
I0523 02:46:58.913579  8024 solver.cpp:237] Iteration 60900, loss = 1.52846
I0523 02:46:58.913614  8024 solver.cpp:253]     Train net output #0: loss = 1.52846 (* 1 = 1.52846 loss)
I0523 02:46:58.913628  8024 sgd_solver.cpp:106] Iteration 60900, lr = 0.0005
I0523 02:47:08.208596  8024 solver.cpp:237] Iteration 61200, loss = 1.13029
I0523 02:47:08.208631  8024 solver.cpp:253]     Train net output #0: loss = 1.13029 (* 1 = 1.13029 loss)
I0523 02:47:08.208645  8024 sgd_solver.cpp:106] Iteration 61200, lr = 0.0005
I0523 02:47:17.506441  8024 solver.cpp:237] Iteration 61500, loss = 1.31866
I0523 02:47:17.506614  8024 solver.cpp:253]     Train net output #0: loss = 1.31866 (* 1 = 1.31866 loss)
I0523 02:47:17.506628  8024 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0523 02:47:26.802054  8024 solver.cpp:237] Iteration 61800, loss = 1.43319
I0523 02:47:26.802089  8024 solver.cpp:253]     Train net output #0: loss = 1.43319 (* 1 = 1.43319 loss)
I0523 02:47:26.802104  8024 sgd_solver.cpp:106] Iteration 61800, lr = 0.0005
I0523 02:47:56.988788  8024 solver.cpp:237] Iteration 62100, loss = 1.31758
I0523 02:47:56.988967  8024 solver.cpp:253]     Train net output #0: loss = 1.31758 (* 1 = 1.31758 loss)
I0523 02:47:56.988984  8024 sgd_solver.cpp:106] Iteration 62100, lr = 0.0005
I0523 02:48:06.287034  8024 solver.cpp:237] Iteration 62400, loss = 1.48946
I0523 02:48:06.287075  8024 solver.cpp:253]     Train net output #0: loss = 1.48946 (* 1 = 1.48946 loss)
I0523 02:48:06.287091  8024 sgd_solver.cpp:106] Iteration 62400, lr = 0.0005
I0523 02:48:15.588127  8024 solver.cpp:237] Iteration 62700, loss = 1.91981
I0523 02:48:15.588163  8024 solver.cpp:253]     Train net output #0: loss = 1.91981 (* 1 = 1.91981 loss)
I0523 02:48:15.588177  8024 sgd_solver.cpp:106] Iteration 62700, lr = 0.0005
I0523 02:48:24.853204  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_63000.caffemodel
I0523 02:48:24.912118  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_63000.solverstate
I0523 02:48:24.948057  8024 solver.cpp:237] Iteration 63000, loss = 1.13088
I0523 02:48:24.948096  8024 solver.cpp:253]     Train net output #0: loss = 1.13088 (* 1 = 1.13088 loss)
I0523 02:48:24.948119  8024 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0523 02:48:34.245524  8024 solver.cpp:237] Iteration 63300, loss = 1.48198
I0523 02:48:34.245705  8024 solver.cpp:253]     Train net output #0: loss = 1.48198 (* 1 = 1.48198 loss)
I0523 02:48:34.245719  8024 sgd_solver.cpp:106] Iteration 63300, lr = 0.0005
I0523 02:48:43.545752  8024 solver.cpp:237] Iteration 63600, loss = 1.16471
I0523 02:48:43.545788  8024 solver.cpp:253]     Train net output #0: loss = 1.16471 (* 1 = 1.16471 loss)
I0523 02:48:43.545800  8024 sgd_solver.cpp:106] Iteration 63600, lr = 0.0005
I0523 02:48:52.845736  8024 solver.cpp:237] Iteration 63900, loss = 1.26626
I0523 02:48:52.845777  8024 solver.cpp:253]     Train net output #0: loss = 1.26626 (* 1 = 1.26626 loss)
I0523 02:48:52.845795  8024 sgd_solver.cpp:106] Iteration 63900, lr = 0.0005
I0523 02:49:23.014926  8024 solver.cpp:237] Iteration 64200, loss = 1.01432
I0523 02:49:23.015106  8024 solver.cpp:253]     Train net output #0: loss = 1.01432 (* 1 = 1.01432 loss)
I0523 02:49:23.015123  8024 sgd_solver.cpp:106] Iteration 64200, lr = 0.0005
I0523 02:49:32.310943  8024 solver.cpp:237] Iteration 64500, loss = 0.895765
I0523 02:49:32.310978  8024 solver.cpp:253]     Train net output #0: loss = 0.895765 (* 1 = 0.895765 loss)
I0523 02:49:32.310994  8024 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0523 02:49:41.608376  8024 solver.cpp:237] Iteration 64800, loss = 1.43753
I0523 02:49:41.608410  8024 solver.cpp:253]     Train net output #0: loss = 1.43753 (* 1 = 1.43753 loss)
I0523 02:49:41.608424  8024 sgd_solver.cpp:106] Iteration 64800, lr = 0.0005
I0523 02:49:50.903657  8024 solver.cpp:237] Iteration 65100, loss = 1.18204
I0523 02:49:50.903695  8024 solver.cpp:253]     Train net output #0: loss = 1.18204 (* 1 = 1.18204 loss)
I0523 02:49:50.903712  8024 sgd_solver.cpp:106] Iteration 65100, lr = 0.0005
I0523 02:50:00.204972  8024 solver.cpp:237] Iteration 65400, loss = 1.41173
I0523 02:50:00.205127  8024 solver.cpp:253]     Train net output #0: loss = 1.41173 (* 1 = 1.41173 loss)
I0523 02:50:00.205139  8024 sgd_solver.cpp:106] Iteration 65400, lr = 0.0005
I0523 02:50:09.499441  8024 solver.cpp:237] Iteration 65700, loss = 1.21635
I0523 02:50:09.499480  8024 solver.cpp:253]     Train net output #0: loss = 1.21635 (* 1 = 1.21635 loss)
I0523 02:50:09.499497  8024 sgd_solver.cpp:106] Iteration 65700, lr = 0.0005
I0523 02:50:18.765913  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_66000.caffemodel
I0523 02:50:18.825287  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_66000.solverstate
I0523 02:50:18.851333  8024 solver.cpp:341] Iteration 66000, Testing net (#0)
I0523 02:51:06.341927  8024 solver.cpp:409]     Test net output #0: accuracy = 0.846269
I0523 02:51:06.342102  8024 solver.cpp:409]     Test net output #1: loss = 0.498961 (* 1 = 0.498961 loss)
I0523 02:51:27.217480  8024 solver.cpp:237] Iteration 66000, loss = 1.18269
I0523 02:51:27.217535  8024 solver.cpp:253]     Train net output #0: loss = 1.18269 (* 1 = 1.18269 loss)
I0523 02:51:27.217550  8024 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0523 02:51:36.522210  8024 solver.cpp:237] Iteration 66300, loss = 1.30391
I0523 02:51:36.522387  8024 solver.cpp:253]     Train net output #0: loss = 1.30391 (* 1 = 1.30391 loss)
I0523 02:51:36.522399  8024 sgd_solver.cpp:106] Iteration 66300, lr = 0.0005
I0523 02:51:45.822834  8024 solver.cpp:237] Iteration 66600, loss = 1.29817
I0523 02:51:45.822870  8024 solver.cpp:253]     Train net output #0: loss = 1.29817 (* 1 = 1.29817 loss)
I0523 02:51:45.822885  8024 sgd_solver.cpp:106] Iteration 66600, lr = 0.0005
I0523 02:51:55.123767  8024 solver.cpp:237] Iteration 66900, loss = 1.24465
I0523 02:51:55.123814  8024 solver.cpp:253]     Train net output #0: loss = 1.24465 (* 1 = 1.24465 loss)
I0523 02:51:55.123831  8024 sgd_solver.cpp:106] Iteration 66900, lr = 0.0005
I0523 02:52:04.429400  8024 solver.cpp:237] Iteration 67200, loss = 1.471
I0523 02:52:04.429436  8024 solver.cpp:253]     Train net output #0: loss = 1.471 (* 1 = 1.471 loss)
I0523 02:52:04.429450  8024 sgd_solver.cpp:106] Iteration 67200, lr = 0.0005
I0523 02:52:13.732695  8024 solver.cpp:237] Iteration 67500, loss = 1.39987
I0523 02:52:13.732868  8024 solver.cpp:253]     Train net output #0: loss = 1.39987 (* 1 = 1.39987 loss)
I0523 02:52:13.732883  8024 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0523 02:52:23.036530  8024 solver.cpp:237] Iteration 67800, loss = 1.19386
I0523 02:52:23.036564  8024 solver.cpp:253]     Train net output #0: loss = 1.19386 (* 1 = 1.19386 loss)
I0523 02:52:23.036579  8024 sgd_solver.cpp:106] Iteration 67800, lr = 0.0005
I0523 02:52:53.244426  8024 solver.cpp:237] Iteration 68100, loss = 1.32849
I0523 02:52:53.244611  8024 solver.cpp:253]     Train net output #0: loss = 1.32849 (* 1 = 1.32849 loss)
I0523 02:52:53.244626  8024 sgd_solver.cpp:106] Iteration 68100, lr = 0.0005
I0523 02:53:02.549314  8024 solver.cpp:237] Iteration 68400, loss = 1.27867
I0523 02:53:02.549350  8024 solver.cpp:253]     Train net output #0: loss = 1.27867 (* 1 = 1.27867 loss)
I0523 02:53:02.549363  8024 sgd_solver.cpp:106] Iteration 68400, lr = 0.0005
I0523 02:53:11.855228  8024 solver.cpp:237] Iteration 68700, loss = 1.27902
I0523 02:53:11.855263  8024 solver.cpp:253]     Train net output #0: loss = 1.27902 (* 1 = 1.27902 loss)
I0523 02:53:11.855278  8024 sgd_solver.cpp:106] Iteration 68700, lr = 0.0005
I0523 02:53:21.125984  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_69000.caffemodel
I0523 02:53:21.186692  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_69000.solverstate
I0523 02:53:21.222331  8024 solver.cpp:237] Iteration 69000, loss = 1.47439
I0523 02:53:21.222375  8024 solver.cpp:253]     Train net output #0: loss = 1.47439 (* 1 = 1.47439 loss)
I0523 02:53:21.222390  8024 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0523 02:53:30.523937  8024 solver.cpp:237] Iteration 69300, loss = 1.35972
I0523 02:53:30.524106  8024 solver.cpp:253]     Train net output #0: loss = 1.35972 (* 1 = 1.35972 loss)
I0523 02:53:30.524121  8024 sgd_solver.cpp:106] Iteration 69300, lr = 0.0005
I0523 02:53:39.828997  8024 solver.cpp:237] Iteration 69600, loss = 1.54421
I0523 02:53:39.829031  8024 solver.cpp:253]     Train net output #0: loss = 1.54421 (* 1 = 1.54421 loss)
I0523 02:53:39.829046  8024 sgd_solver.cpp:106] Iteration 69600, lr = 0.0005
I0523 02:53:49.136694  8024 solver.cpp:237] Iteration 69900, loss = 1.48662
I0523 02:53:49.136729  8024 solver.cpp:253]     Train net output #0: loss = 1.48662 (* 1 = 1.48662 loss)
I0523 02:53:49.136744  8024 sgd_solver.cpp:106] Iteration 69900, lr = 0.0005
I0523 02:54:19.328069  8024 solver.cpp:237] Iteration 70200, loss = 1.18231
I0523 02:54:19.328248  8024 solver.cpp:253]     Train net output #0: loss = 1.18231 (* 1 = 1.18231 loss)
I0523 02:54:19.328264  8024 sgd_solver.cpp:106] Iteration 70200, lr = 0.0005
I0523 02:54:28.628334  8024 solver.cpp:237] Iteration 70500, loss = 1.3073
I0523 02:54:28.628368  8024 solver.cpp:253]     Train net output #0: loss = 1.3073 (* 1 = 1.3073 loss)
I0523 02:54:28.628383  8024 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0523 02:54:37.934343  8024 solver.cpp:237] Iteration 70800, loss = 1.2987
I0523 02:54:37.934379  8024 solver.cpp:253]     Train net output #0: loss = 1.2987 (* 1 = 1.2987 loss)
I0523 02:54:37.934392  8024 sgd_solver.cpp:106] Iteration 70800, lr = 0.0005
I0523 02:54:47.233340  8024 solver.cpp:237] Iteration 71100, loss = 1.39089
I0523 02:54:47.233381  8024 solver.cpp:253]     Train net output #0: loss = 1.39089 (* 1 = 1.39089 loss)
I0523 02:54:47.233402  8024 sgd_solver.cpp:106] Iteration 71100, lr = 0.0005
I0523 02:54:56.531785  8024 solver.cpp:237] Iteration 71400, loss = 1.10584
I0523 02:54:56.531954  8024 solver.cpp:253]     Train net output #0: loss = 1.10584 (* 1 = 1.10584 loss)
I0523 02:54:56.531967  8024 sgd_solver.cpp:106] Iteration 71400, lr = 0.0005
I0523 02:55:05.836544  8024 solver.cpp:237] Iteration 71700, loss = 1.07879
I0523 02:55:05.836578  8024 solver.cpp:253]     Train net output #0: loss = 1.07879 (* 1 = 1.07879 loss)
I0523 02:55:05.836594  8024 sgd_solver.cpp:106] Iteration 71700, lr = 0.0005
I0523 02:55:15.107839  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_72000.caffemodel
I0523 02:55:15.167529  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_72000.solverstate
I0523 02:55:15.193841  8024 solver.cpp:341] Iteration 72000, Testing net (#0)
I0523 02:56:23.882788  8024 solver.cpp:409]     Test net output #0: accuracy = 0.850094
I0523 02:56:23.882966  8024 solver.cpp:409]     Test net output #1: loss = 0.512899 (* 1 = 0.512899 loss)
I0523 02:56:44.786110  8024 solver.cpp:237] Iteration 72000, loss = 1.34045
I0523 02:56:44.786162  8024 solver.cpp:253]     Train net output #0: loss = 1.34045 (* 1 = 1.34045 loss)
I0523 02:56:44.786178  8024 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0523 02:56:54.080283  8024 solver.cpp:237] Iteration 72300, loss = 1.26803
I0523 02:56:54.080456  8024 solver.cpp:253]     Train net output #0: loss = 1.26803 (* 1 = 1.26803 loss)
I0523 02:56:54.080469  8024 sgd_solver.cpp:106] Iteration 72300, lr = 0.0005
I0523 02:57:03.376585  8024 solver.cpp:237] Iteration 72600, loss = 1.39878
I0523 02:57:03.376619  8024 solver.cpp:253]     Train net output #0: loss = 1.39878 (* 1 = 1.39878 loss)
I0523 02:57:03.376636  8024 sgd_solver.cpp:106] Iteration 72600, lr = 0.0005
I0523 02:57:12.670652  8024 solver.cpp:237] Iteration 72900, loss = 1.22174
I0523 02:57:12.670691  8024 solver.cpp:253]     Train net output #0: loss = 1.22174 (* 1 = 1.22174 loss)
I0523 02:57:12.670713  8024 sgd_solver.cpp:106] Iteration 72900, lr = 0.0005
I0523 02:57:21.966866  8024 solver.cpp:237] Iteration 73200, loss = 1.56283
I0523 02:57:21.966902  8024 solver.cpp:253]     Train net output #0: loss = 1.56283 (* 1 = 1.56283 loss)
I0523 02:57:21.966919  8024 sgd_solver.cpp:106] Iteration 73200, lr = 0.0005
I0523 02:57:31.259608  8024 solver.cpp:237] Iteration 73500, loss = 1.34486
I0523 02:57:31.259768  8024 solver.cpp:253]     Train net output #0: loss = 1.34486 (* 1 = 1.34486 loss)
I0523 02:57:31.259783  8024 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I0523 02:57:40.556874  8024 solver.cpp:237] Iteration 73800, loss = 1.20983
I0523 02:57:40.556912  8024 solver.cpp:253]     Train net output #0: loss = 1.20983 (* 1 = 1.20983 loss)
I0523 02:57:40.556931  8024 sgd_solver.cpp:106] Iteration 73800, lr = 0.0005
I0523 02:58:10.760079  8024 solver.cpp:237] Iteration 74100, loss = 1.11483
I0523 02:58:10.760262  8024 solver.cpp:253]     Train net output #0: loss = 1.11483 (* 1 = 1.11483 loss)
I0523 02:58:10.760278  8024 sgd_solver.cpp:106] Iteration 74100, lr = 0.0005
I0523 02:58:20.052928  8024 solver.cpp:237] Iteration 74400, loss = 1.01737
I0523 02:58:20.052963  8024 solver.cpp:253]     Train net output #0: loss = 1.01737 (* 1 = 1.01737 loss)
I0523 02:58:20.052978  8024 sgd_solver.cpp:106] Iteration 74400, lr = 0.0005
I0523 02:58:29.344563  8024 solver.cpp:237] Iteration 74700, loss = 1.34853
I0523 02:58:29.344609  8024 solver.cpp:253]     Train net output #0: loss = 1.34853 (* 1 = 1.34853 loss)
I0523 02:58:29.344627  8024 sgd_solver.cpp:106] Iteration 74700, lr = 0.0005
I0523 02:58:38.609171  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_75000.caffemodel
I0523 02:58:38.670702  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_75000.solverstate
I0523 02:58:38.708750  8024 solver.cpp:237] Iteration 75000, loss = 1.52523
I0523 02:58:38.708801  8024 solver.cpp:253]     Train net output #0: loss = 1.52523 (* 1 = 1.52523 loss)
I0523 02:58:38.708817  8024 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I0523 02:58:48.001360  8024 solver.cpp:237] Iteration 75300, loss = 1.26186
I0523 02:58:48.001534  8024 solver.cpp:253]     Train net output #0: loss = 1.26186 (* 1 = 1.26186 loss)
I0523 02:58:48.001549  8024 sgd_solver.cpp:106] Iteration 75300, lr = 0.0005
I0523 02:58:57.294586  8024 solver.cpp:237] Iteration 75600, loss = 1.55475
I0523 02:58:57.294632  8024 solver.cpp:253]     Train net output #0: loss = 1.55475 (* 1 = 1.55475 loss)
I0523 02:58:57.294649  8024 sgd_solver.cpp:106] Iteration 75600, lr = 0.0005
I0523 02:59:06.585935  8024 solver.cpp:237] Iteration 75900, loss = 1.14059
I0523 02:59:06.585971  8024 solver.cpp:253]     Train net output #0: loss = 1.14059 (* 1 = 1.14059 loss)
I0523 02:59:06.585986  8024 sgd_solver.cpp:106] Iteration 75900, lr = 0.0005
I0523 02:59:36.782543  8024 solver.cpp:237] Iteration 76200, loss = 1.34028
I0523 02:59:36.782728  8024 solver.cpp:253]     Train net output #0: loss = 1.34028 (* 1 = 1.34028 loss)
I0523 02:59:36.782744  8024 sgd_solver.cpp:106] Iteration 76200, lr = 0.0005
I0523 02:59:46.074465  8024 solver.cpp:237] Iteration 76500, loss = 1.2708
I0523 02:59:46.074512  8024 solver.cpp:253]     Train net output #0: loss = 1.2708 (* 1 = 1.2708 loss)
I0523 02:59:46.074537  8024 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I0523 02:59:55.367620  8024 solver.cpp:237] Iteration 76800, loss = 1.17565
I0523 02:59:55.367655  8024 solver.cpp:253]     Train net output #0: loss = 1.17565 (* 1 = 1.17565 loss)
I0523 02:59:55.367672  8024 sgd_solver.cpp:106] Iteration 76800, lr = 0.0005
I0523 03:00:04.661223  8024 solver.cpp:237] Iteration 77100, loss = 1.33198
I0523 03:00:04.661258  8024 solver.cpp:253]     Train net output #0: loss = 1.33198 (* 1 = 1.33198 loss)
I0523 03:00:04.661275  8024 sgd_solver.cpp:106] Iteration 77100, lr = 0.0005
I0523 03:00:13.954753  8024 solver.cpp:237] Iteration 77400, loss = 1.13605
I0523 03:00:13.954926  8024 solver.cpp:253]     Train net output #0: loss = 1.13605 (* 1 = 1.13605 loss)
I0523 03:00:13.954939  8024 sgd_solver.cpp:106] Iteration 77400, lr = 0.0005
I0523 03:00:23.246327  8024 solver.cpp:237] Iteration 77700, loss = 1.05303
I0523 03:00:23.246362  8024 solver.cpp:253]     Train net output #0: loss = 1.05303 (* 1 = 1.05303 loss)
I0523 03:00:23.246381  8024 sgd_solver.cpp:106] Iteration 77700, lr = 0.0005
I0523 03:00:32.507876  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_78000.caffemodel
I0523 03:00:32.566905  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_78000.solverstate
I0523 03:00:32.593032  8024 solver.cpp:341] Iteration 78000, Testing net (#0)
I0523 03:01:20.395366  8024 solver.cpp:409]     Test net output #0: accuracy = 0.854907
I0523 03:01:20.395558  8024 solver.cpp:409]     Test net output #1: loss = 0.499174 (* 1 = 0.499174 loss)
I0523 03:01:41.258246  8024 solver.cpp:237] Iteration 78000, loss = 1.24884
I0523 03:01:41.258301  8024 solver.cpp:253]     Train net output #0: loss = 1.24884 (* 1 = 1.24884 loss)
I0523 03:01:41.258316  8024 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I0523 03:01:50.548120  8024 solver.cpp:237] Iteration 78300, loss = 0.949006
I0523 03:01:50.548298  8024 solver.cpp:253]     Train net output #0: loss = 0.949006 (* 1 = 0.949006 loss)
I0523 03:01:50.548312  8024 sgd_solver.cpp:106] Iteration 78300, lr = 0.0005
I0523 03:01:59.836369  8024 solver.cpp:237] Iteration 78600, loss = 1.34957
I0523 03:01:59.836406  8024 solver.cpp:253]     Train net output #0: loss = 1.34957 (* 1 = 1.34957 loss)
I0523 03:01:59.836426  8024 sgd_solver.cpp:106] Iteration 78600, lr = 0.0005
I0523 03:02:09.126323  8024 solver.cpp:237] Iteration 78900, loss = 1.46075
I0523 03:02:09.126359  8024 solver.cpp:253]     Train net output #0: loss = 1.46075 (* 1 = 1.46075 loss)
I0523 03:02:09.126375  8024 sgd_solver.cpp:106] Iteration 78900, lr = 0.0005
I0523 03:02:18.415997  8024 solver.cpp:237] Iteration 79200, loss = 1.16458
I0523 03:02:18.416043  8024 solver.cpp:253]     Train net output #0: loss = 1.16458 (* 1 = 1.16458 loss)
I0523 03:02:18.416057  8024 sgd_solver.cpp:106] Iteration 79200, lr = 0.0005
I0523 03:02:27.709414  8024 solver.cpp:237] Iteration 79500, loss = 1.28383
I0523 03:02:27.709578  8024 solver.cpp:253]     Train net output #0: loss = 1.28383 (* 1 = 1.28383 loss)
I0523 03:02:27.709591  8024 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I0523 03:02:37.000458  8024 solver.cpp:237] Iteration 79800, loss = 1.0226
I0523 03:02:37.000489  8024 solver.cpp:253]     Train net output #0: loss = 1.0226 (* 1 = 1.0226 loss)
I0523 03:02:37.000501  8024 sgd_solver.cpp:106] Iteration 79800, lr = 0.0005
I0523 03:03:07.168186  8024 solver.cpp:237] Iteration 80100, loss = 1.43806
I0523 03:03:07.168375  8024 solver.cpp:253]     Train net output #0: loss = 1.43806 (* 1 = 1.43806 loss)
I0523 03:03:07.168390  8024 sgd_solver.cpp:106] Iteration 80100, lr = 0.0005
I0523 03:03:16.461622  8024 solver.cpp:237] Iteration 80400, loss = 1.22265
I0523 03:03:16.461658  8024 solver.cpp:253]     Train net output #0: loss = 1.22265 (* 1 = 1.22265 loss)
I0523 03:03:16.461676  8024 sgd_solver.cpp:106] Iteration 80400, lr = 0.0005
I0523 03:03:25.753046  8024 solver.cpp:237] Iteration 80700, loss = 1.01176
I0523 03:03:25.753082  8024 solver.cpp:253]     Train net output #0: loss = 1.01176 (* 1 = 1.01176 loss)
I0523 03:03:25.753098  8024 sgd_solver.cpp:106] Iteration 80700, lr = 0.0005
I0523 03:03:35.013350  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_81000.caffemodel
I0523 03:03:35.072965  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_81000.solverstate
I0523 03:03:35.109001  8024 solver.cpp:237] Iteration 81000, loss = 1.26628
I0523 03:03:35.109042  8024 solver.cpp:253]     Train net output #0: loss = 1.26628 (* 1 = 1.26628 loss)
I0523 03:03:35.109064  8024 sgd_solver.cpp:106] Iteration 81000, lr = 0.0005
I0523 03:03:44.403059  8024 solver.cpp:237] Iteration 81300, loss = 1.18475
I0523 03:03:44.403226  8024 solver.cpp:253]     Train net output #0: loss = 1.18475 (* 1 = 1.18475 loss)
I0523 03:03:44.403239  8024 sgd_solver.cpp:106] Iteration 81300, lr = 0.0005
I0523 03:03:53.697610  8024 solver.cpp:237] Iteration 81600, loss = 1.25813
I0523 03:03:53.697659  8024 solver.cpp:253]     Train net output #0: loss = 1.25813 (* 1 = 1.25813 loss)
I0523 03:03:53.697674  8024 sgd_solver.cpp:106] Iteration 81600, lr = 0.0005
I0523 03:04:02.990216  8024 solver.cpp:237] Iteration 81900, loss = 1.37026
I0523 03:04:02.990252  8024 solver.cpp:253]     Train net output #0: loss = 1.37026 (* 1 = 1.37026 loss)
I0523 03:04:02.990267  8024 sgd_solver.cpp:106] Iteration 81900, lr = 0.0005
I0523 03:04:33.188516  8024 solver.cpp:237] Iteration 82200, loss = 1.05521
I0523 03:04:33.188711  8024 solver.cpp:253]     Train net output #0: loss = 1.05521 (* 1 = 1.05521 loss)
I0523 03:04:33.188726  8024 sgd_solver.cpp:106] Iteration 82200, lr = 0.0005
I0523 03:04:42.484478  8024 solver.cpp:237] Iteration 82500, loss = 1.51329
I0523 03:04:42.484520  8024 solver.cpp:253]     Train net output #0: loss = 1.51329 (* 1 = 1.51329 loss)
I0523 03:04:42.484534  8024 sgd_solver.cpp:106] Iteration 82500, lr = 0.0005
I0523 03:04:51.778079  8024 solver.cpp:237] Iteration 82800, loss = 1.47931
I0523 03:04:51.778115  8024 solver.cpp:253]     Train net output #0: loss = 1.47931 (* 1 = 1.47931 loss)
I0523 03:04:51.778129  8024 sgd_solver.cpp:106] Iteration 82800, lr = 0.0005
I0523 03:05:01.070693  8024 solver.cpp:237] Iteration 83100, loss = 1.06519
I0523 03:05:01.070729  8024 solver.cpp:253]     Train net output #0: loss = 1.06519 (* 1 = 1.06519 loss)
I0523 03:05:01.070745  8024 sgd_solver.cpp:106] Iteration 83100, lr = 0.0005
I0523 03:05:10.363488  8024 solver.cpp:237] Iteration 83400, loss = 1.32445
I0523 03:05:10.363659  8024 solver.cpp:253]     Train net output #0: loss = 1.32445 (* 1 = 1.32445 loss)
I0523 03:05:10.363673  8024 sgd_solver.cpp:106] Iteration 83400, lr = 0.0005
I0523 03:05:19.653425  8024 solver.cpp:237] Iteration 83700, loss = 1.13808
I0523 03:05:19.653456  8024 solver.cpp:253]     Train net output #0: loss = 1.13808 (* 1 = 1.13808 loss)
I0523 03:05:19.653475  8024 sgd_solver.cpp:106] Iteration 83700, lr = 0.0005
I0523 03:05:28.917433  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_84000.caffemodel
I0523 03:05:28.976655  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_84000.solverstate
I0523 03:05:29.002874  8024 solver.cpp:341] Iteration 84000, Testing net (#0)
I0523 03:06:37.712395  8024 solver.cpp:409]     Test net output #0: accuracy = 0.858671
I0523 03:06:37.712579  8024 solver.cpp:409]     Test net output #1: loss = 0.470186 (* 1 = 0.470186 loss)
I0523 03:06:58.645953  8024 solver.cpp:237] Iteration 84000, loss = 1.34158
I0523 03:06:58.646008  8024 solver.cpp:253]     Train net output #0: loss = 1.34158 (* 1 = 1.34158 loss)
I0523 03:06:58.646023  8024 sgd_solver.cpp:106] Iteration 84000, lr = 0.0005
I0523 03:07:07.941305  8024 solver.cpp:237] Iteration 84300, loss = 1.37438
I0523 03:07:07.941475  8024 solver.cpp:253]     Train net output #0: loss = 1.37438 (* 1 = 1.37438 loss)
I0523 03:07:07.941488  8024 sgd_solver.cpp:106] Iteration 84300, lr = 0.0005
I0523 03:07:17.240165  8024 solver.cpp:237] Iteration 84600, loss = 1.07812
I0523 03:07:17.240207  8024 solver.cpp:253]     Train net output #0: loss = 1.07812 (* 1 = 1.07812 loss)
I0523 03:07:17.240226  8024 sgd_solver.cpp:106] Iteration 84600, lr = 0.0005
I0523 03:07:26.538007  8024 solver.cpp:237] Iteration 84900, loss = 1.15689
I0523 03:07:26.538043  8024 solver.cpp:253]     Train net output #0: loss = 1.15689 (* 1 = 1.15689 loss)
I0523 03:07:26.538058  8024 sgd_solver.cpp:106] Iteration 84900, lr = 0.0005
I0523 03:07:35.834950  8024 solver.cpp:237] Iteration 85200, loss = 1.31537
I0523 03:07:35.834986  8024 solver.cpp:253]     Train net output #0: loss = 1.31537 (* 1 = 1.31537 loss)
I0523 03:07:35.835002  8024 sgd_solver.cpp:106] Iteration 85200, lr = 0.0005
I0523 03:07:45.130528  8024 solver.cpp:237] Iteration 85500, loss = 0.978701
I0523 03:07:45.130707  8024 solver.cpp:253]     Train net output #0: loss = 0.978701 (* 1 = 0.978701 loss)
I0523 03:07:45.130722  8024 sgd_solver.cpp:106] Iteration 85500, lr = 0.0005
I0523 03:07:54.430769  8024 solver.cpp:237] Iteration 85800, loss = 1.13395
I0523 03:07:54.430804  8024 solver.cpp:253]     Train net output #0: loss = 1.13395 (* 1 = 1.13395 loss)
I0523 03:07:54.430820  8024 sgd_solver.cpp:106] Iteration 85800, lr = 0.0005
I0523 03:08:24.672513  8024 solver.cpp:237] Iteration 86100, loss = 1.36836
I0523 03:08:24.672713  8024 solver.cpp:253]     Train net output #0: loss = 1.36836 (* 1 = 1.36836 loss)
I0523 03:08:24.672729  8024 sgd_solver.cpp:106] Iteration 86100, lr = 0.0005
I0523 03:08:33.970887  8024 solver.cpp:237] Iteration 86400, loss = 1.2473
I0523 03:08:33.970928  8024 solver.cpp:253]     Train net output #0: loss = 1.2473 (* 1 = 1.2473 loss)
I0523 03:08:33.970949  8024 sgd_solver.cpp:106] Iteration 86400, lr = 0.0005
I0523 03:08:43.269256  8024 solver.cpp:237] Iteration 86700, loss = 1.03198
I0523 03:08:43.269291  8024 solver.cpp:253]     Train net output #0: loss = 1.03198 (* 1 = 1.03198 loss)
I0523 03:08:43.269309  8024 sgd_solver.cpp:106] Iteration 86700, lr = 0.0005
I0523 03:08:52.538403  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_87000.caffemodel
I0523 03:08:52.600141  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_87000.solverstate
I0523 03:08:52.638020  8024 solver.cpp:237] Iteration 87000, loss = 1.50574
I0523 03:08:52.638069  8024 solver.cpp:253]     Train net output #0: loss = 1.50574 (* 1 = 1.50574 loss)
I0523 03:08:52.638084  8024 sgd_solver.cpp:106] Iteration 87000, lr = 0.0005
I0523 03:09:01.936936  8024 solver.cpp:237] Iteration 87300, loss = 0.976986
I0523 03:09:01.937108  8024 solver.cpp:253]     Train net output #0: loss = 0.976986 (* 1 = 0.976986 loss)
I0523 03:09:01.937121  8024 sgd_solver.cpp:106] Iteration 87300, lr = 0.0005
I0523 03:09:11.238932  8024 solver.cpp:237] Iteration 87600, loss = 1.83885
I0523 03:09:11.238966  8024 solver.cpp:253]     Train net output #0: loss = 1.83885 (* 1 = 1.83885 loss)
I0523 03:09:11.238984  8024 sgd_solver.cpp:106] Iteration 87600, lr = 0.0005
I0523 03:09:20.536664  8024 solver.cpp:237] Iteration 87900, loss = 1.34761
I0523 03:09:20.536711  8024 solver.cpp:253]     Train net output #0: loss = 1.34761 (* 1 = 1.34761 loss)
I0523 03:09:20.536728  8024 sgd_solver.cpp:106] Iteration 87900, lr = 0.0005
I0523 03:09:50.739766  8024 solver.cpp:237] Iteration 88200, loss = 1.21173
I0523 03:09:50.739949  8024 solver.cpp:253]     Train net output #0: loss = 1.21173 (* 1 = 1.21173 loss)
I0523 03:09:50.739965  8024 sgd_solver.cpp:106] Iteration 88200, lr = 0.0005
I0523 03:10:00.036911  8024 solver.cpp:237] Iteration 88500, loss = 1.55249
I0523 03:10:00.036945  8024 solver.cpp:253]     Train net output #0: loss = 1.55249 (* 1 = 1.55249 loss)
I0523 03:10:00.036959  8024 sgd_solver.cpp:106] Iteration 88500, lr = 0.0005
I0523 03:10:09.335870  8024 solver.cpp:237] Iteration 88800, loss = 1.24978
I0523 03:10:09.335913  8024 solver.cpp:253]     Train net output #0: loss = 1.24978 (* 1 = 1.24978 loss)
I0523 03:10:09.335933  8024 sgd_solver.cpp:106] Iteration 88800, lr = 0.0005
I0523 03:10:18.634915  8024 solver.cpp:237] Iteration 89100, loss = 1.46069
I0523 03:10:18.634950  8024 solver.cpp:253]     Train net output #0: loss = 1.46069 (* 1 = 1.46069 loss)
I0523 03:10:18.634968  8024 sgd_solver.cpp:106] Iteration 89100, lr = 0.0005
I0523 03:10:27.930544  8024 solver.cpp:237] Iteration 89400, loss = 1.55825
I0523 03:10:27.930713  8024 solver.cpp:253]     Train net output #0: loss = 1.55825 (* 1 = 1.55825 loss)
I0523 03:10:27.930727  8024 sgd_solver.cpp:106] Iteration 89400, lr = 0.0005
I0523 03:10:37.230789  8024 solver.cpp:237] Iteration 89700, loss = 1.26132
I0523 03:10:37.230834  8024 solver.cpp:253]     Train net output #0: loss = 1.26132 (* 1 = 1.26132 loss)
I0523 03:10:37.230849  8024 sgd_solver.cpp:106] Iteration 89700, lr = 0.0005
I0523 03:10:46.496892  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_90000.caffemodel
I0523 03:10:46.558696  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_90000.solverstate
I0523 03:10:46.587039  8024 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 03:11:34.071954  8024 solver.cpp:409]     Test net output #0: accuracy = 0.862925
I0523 03:11:34.072156  8024 solver.cpp:409]     Test net output #1: loss = 0.48275 (* 1 = 0.48275 loss)
I0523 03:11:55.017981  8024 solver.cpp:237] Iteration 90000, loss = 1.36388
I0523 03:11:55.018031  8024 solver.cpp:253]     Train net output #0: loss = 1.36388 (* 1 = 1.36388 loss)
I0523 03:11:55.018049  8024 sgd_solver.cpp:106] Iteration 90000, lr = 0.0005
I0523 03:12:04.322435  8024 solver.cpp:237] Iteration 90300, loss = 1.00547
I0523 03:12:04.322618  8024 solver.cpp:253]     Train net output #0: loss = 1.00547 (* 1 = 1.00547 loss)
I0523 03:12:04.322631  8024 sgd_solver.cpp:106] Iteration 90300, lr = 0.0005
I0523 03:12:13.626332  8024 solver.cpp:237] Iteration 90600, loss = 1.34223
I0523 03:12:13.626380  8024 solver.cpp:253]     Train net output #0: loss = 1.34223 (* 1 = 1.34223 loss)
I0523 03:12:13.626396  8024 sgd_solver.cpp:106] Iteration 90600, lr = 0.0005
I0523 03:12:22.929987  8024 solver.cpp:237] Iteration 90900, loss = 1.48982
I0523 03:12:22.930025  8024 solver.cpp:253]     Train net output #0: loss = 1.48982 (* 1 = 1.48982 loss)
I0523 03:12:22.930042  8024 sgd_solver.cpp:106] Iteration 90900, lr = 0.0005
I0523 03:12:32.233479  8024 solver.cpp:237] Iteration 91200, loss = 1.16159
I0523 03:12:32.233515  8024 solver.cpp:253]     Train net output #0: loss = 1.16159 (* 1 = 1.16159 loss)
I0523 03:12:32.233532  8024 sgd_solver.cpp:106] Iteration 91200, lr = 0.0005
I0523 03:12:41.539748  8024 solver.cpp:237] Iteration 91500, loss = 1.0994
I0523 03:12:41.539928  8024 solver.cpp:253]     Train net output #0: loss = 1.0994 (* 1 = 1.0994 loss)
I0523 03:12:41.539942  8024 sgd_solver.cpp:106] Iteration 91500, lr = 0.0005
I0523 03:12:50.842627  8024 solver.cpp:237] Iteration 91800, loss = 1.45204
I0523 03:12:50.842660  8024 solver.cpp:253]     Train net output #0: loss = 1.45204 (* 1 = 1.45204 loss)
I0523 03:12:50.842675  8024 sgd_solver.cpp:106] Iteration 91800, lr = 0.0005
I0523 03:13:21.072664  8024 solver.cpp:237] Iteration 92100, loss = 1.3929
I0523 03:13:21.072850  8024 solver.cpp:253]     Train net output #0: loss = 1.3929 (* 1 = 1.3929 loss)
I0523 03:13:21.072865  8024 sgd_solver.cpp:106] Iteration 92100, lr = 0.0005
I0523 03:13:30.379163  8024 solver.cpp:237] Iteration 92400, loss = 1.12926
I0523 03:13:30.379209  8024 solver.cpp:253]     Train net output #0: loss = 1.12926 (* 1 = 1.12926 loss)
I0523 03:13:30.379225  8024 sgd_solver.cpp:106] Iteration 92400, lr = 0.0005
I0523 03:13:39.684540  8024 solver.cpp:237] Iteration 92700, loss = 1.60238
I0523 03:13:39.684576  8024 solver.cpp:253]     Train net output #0: loss = 1.60238 (* 1 = 1.60238 loss)
I0523 03:13:39.684592  8024 sgd_solver.cpp:106] Iteration 92700, lr = 0.0005
I0523 03:13:48.959265  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_93000.caffemodel
I0523 03:13:49.018811  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_93000.solverstate
I0523 03:13:49.054982  8024 solver.cpp:237] Iteration 93000, loss = 1.38665
I0523 03:13:49.055022  8024 solver.cpp:253]     Train net output #0: loss = 1.38665 (* 1 = 1.38665 loss)
I0523 03:13:49.055040  8024 sgd_solver.cpp:106] Iteration 93000, lr = 0.0005
I0523 03:13:58.358767  8024 solver.cpp:237] Iteration 93300, loss = 1.11387
I0523 03:13:58.358947  8024 solver.cpp:253]     Train net output #0: loss = 1.11387 (* 1 = 1.11387 loss)
I0523 03:13:58.358961  8024 sgd_solver.cpp:106] Iteration 93300, lr = 0.0005
I0523 03:14:07.663352  8024 solver.cpp:237] Iteration 93600, loss = 1.07985
I0523 03:14:07.663386  8024 solver.cpp:253]     Train net output #0: loss = 1.07985 (* 1 = 1.07985 loss)
I0523 03:14:07.663403  8024 sgd_solver.cpp:106] Iteration 93600, lr = 0.0005
I0523 03:14:16.971459  8024 solver.cpp:237] Iteration 93900, loss = 1.13491
I0523 03:14:16.971494  8024 solver.cpp:253]     Train net output #0: loss = 1.13491 (* 1 = 1.13491 loss)
I0523 03:14:16.971511  8024 sgd_solver.cpp:106] Iteration 93900, lr = 0.0005
I0523 03:14:47.234001  8024 solver.cpp:237] Iteration 94200, loss = 1.24626
I0523 03:14:47.234202  8024 solver.cpp:253]     Train net output #0: loss = 1.24626 (* 1 = 1.24626 loss)
I0523 03:14:47.234218  8024 sgd_solver.cpp:106] Iteration 94200, lr = 0.0005
I0523 03:14:56.542331  8024 solver.cpp:237] Iteration 94500, loss = 1.06932
I0523 03:14:56.542366  8024 solver.cpp:253]     Train net output #0: loss = 1.06932 (* 1 = 1.06932 loss)
I0523 03:14:56.542383  8024 sgd_solver.cpp:106] Iteration 94500, lr = 0.0005
I0523 03:15:05.845434  8024 solver.cpp:237] Iteration 94800, loss = 1.36135
I0523 03:15:05.845470  8024 solver.cpp:253]     Train net output #0: loss = 1.36135 (* 1 = 1.36135 loss)
I0523 03:15:05.845486  8024 sgd_solver.cpp:106] Iteration 94800, lr = 0.0005
I0523 03:15:15.150554  8024 solver.cpp:237] Iteration 95100, loss = 1.10541
I0523 03:15:15.150594  8024 solver.cpp:253]     Train net output #0: loss = 1.10541 (* 1 = 1.10541 loss)
I0523 03:15:15.150612  8024 sgd_solver.cpp:106] Iteration 95100, lr = 0.0005
I0523 03:15:24.452078  8024 solver.cpp:237] Iteration 95400, loss = 1.36624
I0523 03:15:24.452246  8024 solver.cpp:253]     Train net output #0: loss = 1.36624 (* 1 = 1.36624 loss)
I0523 03:15:24.452261  8024 sgd_solver.cpp:106] Iteration 95400, lr = 0.0005
I0523 03:15:33.755754  8024 solver.cpp:237] Iteration 95700, loss = 1.23259
I0523 03:15:33.755794  8024 solver.cpp:253]     Train net output #0: loss = 1.23259 (* 1 = 1.23259 loss)
I0523 03:15:33.755811  8024 sgd_solver.cpp:106] Iteration 95700, lr = 0.0005
I0523 03:15:43.027184  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_96000.caffemodel
I0523 03:15:43.086321  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_96000.solverstate
I0523 03:15:43.112419  8024 solver.cpp:341] Iteration 96000, Testing net (#0)
I0523 03:16:51.897743  8024 solver.cpp:409]     Test net output #0: accuracy = 0.860386
I0523 03:16:51.897929  8024 solver.cpp:409]     Test net output #1: loss = 0.438167 (* 1 = 0.438167 loss)
I0523 03:17:12.852707  8024 solver.cpp:237] Iteration 96000, loss = 1.15064
I0523 03:17:12.852762  8024 solver.cpp:253]     Train net output #0: loss = 1.15064 (* 1 = 1.15064 loss)
I0523 03:17:12.852777  8024 sgd_solver.cpp:106] Iteration 96000, lr = 0.0005
I0523 03:17:22.146713  8024 solver.cpp:237] Iteration 96300, loss = 1.27725
I0523 03:17:22.146884  8024 solver.cpp:253]     Train net output #0: loss = 1.27725 (* 1 = 1.27725 loss)
I0523 03:17:22.146898  8024 sgd_solver.cpp:106] Iteration 96300, lr = 0.0005
I0523 03:17:31.442095  8024 solver.cpp:237] Iteration 96600, loss = 1.26499
I0523 03:17:31.442131  8024 solver.cpp:253]     Train net output #0: loss = 1.26499 (* 1 = 1.26499 loss)
I0523 03:17:31.442147  8024 sgd_solver.cpp:106] Iteration 96600, lr = 0.0005
I0523 03:17:40.733572  8024 solver.cpp:237] Iteration 96900, loss = 1.20475
I0523 03:17:40.733618  8024 solver.cpp:253]     Train net output #0: loss = 1.20475 (* 1 = 1.20475 loss)
I0523 03:17:40.733635  8024 sgd_solver.cpp:106] Iteration 96900, lr = 0.0005
I0523 03:17:50.029549  8024 solver.cpp:237] Iteration 97200, loss = 1.19153
I0523 03:17:50.029585  8024 solver.cpp:253]     Train net output #0: loss = 1.19153 (* 1 = 1.19153 loss)
I0523 03:17:50.029598  8024 sgd_solver.cpp:106] Iteration 97200, lr = 0.0005
I0523 03:17:59.318377  8024 solver.cpp:237] Iteration 97500, loss = 1.48082
I0523 03:17:59.318572  8024 solver.cpp:253]     Train net output #0: loss = 1.48082 (* 1 = 1.48082 loss)
I0523 03:17:59.318586  8024 sgd_solver.cpp:106] Iteration 97500, lr = 0.0005
I0523 03:18:08.612746  8024 solver.cpp:237] Iteration 97800, loss = 1.17768
I0523 03:18:08.612792  8024 solver.cpp:253]     Train net output #0: loss = 1.17768 (* 1 = 1.17768 loss)
I0523 03:18:08.612808  8024 sgd_solver.cpp:106] Iteration 97800, lr = 0.0005
I0523 03:18:38.865703  8024 solver.cpp:237] Iteration 98100, loss = 1.40494
I0523 03:18:38.865897  8024 solver.cpp:253]     Train net output #0: loss = 1.40494 (* 1 = 1.40494 loss)
I0523 03:18:38.865912  8024 sgd_solver.cpp:106] Iteration 98100, lr = 0.0005
I0523 03:18:48.158440  8024 solver.cpp:237] Iteration 98400, loss = 1.10254
I0523 03:18:48.158474  8024 solver.cpp:253]     Train net output #0: loss = 1.10254 (* 1 = 1.10254 loss)
I0523 03:18:48.158490  8024 sgd_solver.cpp:106] Iteration 98400, lr = 0.0005
I0523 03:18:57.449084  8024 solver.cpp:237] Iteration 98700, loss = 1.19139
I0523 03:18:57.449126  8024 solver.cpp:253]     Train net output #0: loss = 1.19139 (* 1 = 1.19139 loss)
I0523 03:18:57.449144  8024 sgd_solver.cpp:106] Iteration 98700, lr = 0.0005
I0523 03:19:06.709708  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_99000.caffemodel
I0523 03:19:06.769165  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_99000.solverstate
I0523 03:19:06.805100  8024 solver.cpp:237] Iteration 99000, loss = 1.22179
I0523 03:19:06.805141  8024 solver.cpp:253]     Train net output #0: loss = 1.22179 (* 1 = 1.22179 loss)
I0523 03:19:06.805158  8024 sgd_solver.cpp:106] Iteration 99000, lr = 0.0005
I0523 03:19:16.096652  8024 solver.cpp:237] Iteration 99300, loss = 1.45269
I0523 03:19:16.096825  8024 solver.cpp:253]     Train net output #0: loss = 1.45269 (* 1 = 1.45269 loss)
I0523 03:19:16.096839  8024 sgd_solver.cpp:106] Iteration 99300, lr = 0.0005
I0523 03:19:25.388604  8024 solver.cpp:237] Iteration 99600, loss = 1.53693
I0523 03:19:25.388651  8024 solver.cpp:253]     Train net output #0: loss = 1.53693 (* 1 = 1.53693 loss)
I0523 03:19:25.388666  8024 sgd_solver.cpp:106] Iteration 99600, lr = 0.0005
I0523 03:19:34.683372  8024 solver.cpp:237] Iteration 99900, loss = 1.24997
I0523 03:19:34.683406  8024 solver.cpp:253]     Train net output #0: loss = 1.24997 (* 1 = 1.24997 loss)
I0523 03:19:34.683420  8024 sgd_solver.cpp:106] Iteration 99900, lr = 0.0005
I0523 03:20:04.899752  8024 solver.cpp:237] Iteration 100200, loss = 1.24185
I0523 03:20:04.899942  8024 solver.cpp:253]     Train net output #0: loss = 1.24185 (* 1 = 1.24185 loss)
I0523 03:20:04.899957  8024 sgd_solver.cpp:106] Iteration 100200, lr = 0.0005
I0523 03:20:14.194569  8024 solver.cpp:237] Iteration 100500, loss = 1.29981
I0523 03:20:14.194607  8024 solver.cpp:253]     Train net output #0: loss = 1.29981 (* 1 = 1.29981 loss)
I0523 03:20:14.194630  8024 sgd_solver.cpp:106] Iteration 100500, lr = 0.0005
I0523 03:20:23.491255  8024 solver.cpp:237] Iteration 100800, loss = 1.22956
I0523 03:20:23.491291  8024 solver.cpp:253]     Train net output #0: loss = 1.22956 (* 1 = 1.22956 loss)
I0523 03:20:23.491307  8024 sgd_solver.cpp:106] Iteration 100800, lr = 0.0005
I0523 03:20:32.785044  8024 solver.cpp:237] Iteration 101100, loss = 1.06432
I0523 03:20:32.785092  8024 solver.cpp:253]     Train net output #0: loss = 1.06432 (* 1 = 1.06432 loss)
I0523 03:20:32.785106  8024 sgd_solver.cpp:106] Iteration 101100, lr = 0.0005
I0523 03:20:42.081532  8024 solver.cpp:237] Iteration 101400, loss = 1.23205
I0523 03:20:42.081704  8024 solver.cpp:253]     Train net output #0: loss = 1.23205 (* 1 = 1.23205 loss)
I0523 03:20:42.081717  8024 sgd_solver.cpp:106] Iteration 101400, lr = 0.0005
I0523 03:20:51.373383  8024 solver.cpp:237] Iteration 101700, loss = 0.929338
I0523 03:20:51.373419  8024 solver.cpp:253]     Train net output #0: loss = 0.929338 (* 1 = 0.929338 loss)
I0523 03:20:51.373435  8024 sgd_solver.cpp:106] Iteration 101700, lr = 0.0005
I0523 03:21:00.638484  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_102000.caffemodel
I0523 03:21:00.698086  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_102000.solverstate
I0523 03:21:00.723590  8024 solver.cpp:341] Iteration 102000, Testing net (#0)
I0523 03:21:48.576442  8024 solver.cpp:409]     Test net output #0: accuracy = 0.864851
I0523 03:21:48.576640  8024 solver.cpp:409]     Test net output #1: loss = 0.473191 (* 1 = 0.473191 loss)
I0523 03:22:09.521229  8024 solver.cpp:237] Iteration 102000, loss = 1.32341
I0523 03:22:09.521282  8024 solver.cpp:253]     Train net output #0: loss = 1.32341 (* 1 = 1.32341 loss)
I0523 03:22:09.521297  8024 sgd_solver.cpp:106] Iteration 102000, lr = 0.0005
I0523 03:22:18.812727  8024 solver.cpp:237] Iteration 102300, loss = 0.852825
I0523 03:22:18.812922  8024 solver.cpp:253]     Train net output #0: loss = 0.852825 (* 1 = 0.852825 loss)
I0523 03:22:18.812937  8024 sgd_solver.cpp:106] Iteration 102300, lr = 0.0005
I0523 03:22:28.105083  8024 solver.cpp:237] Iteration 102600, loss = 1.27958
I0523 03:22:28.105119  8024 solver.cpp:253]     Train net output #0: loss = 1.27958 (* 1 = 1.27958 loss)
I0523 03:22:28.105135  8024 sgd_solver.cpp:106] Iteration 102600, lr = 0.0005
I0523 03:22:37.394261  8024 solver.cpp:237] Iteration 102900, loss = 1.1699
I0523 03:22:37.394309  8024 solver.cpp:253]     Train net output #0: loss = 1.1699 (* 1 = 1.1699 loss)
I0523 03:22:37.394322  8024 sgd_solver.cpp:106] Iteration 102900, lr = 0.0005
I0523 03:22:46.687476  8024 solver.cpp:237] Iteration 103200, loss = 1.32294
I0523 03:22:46.687512  8024 solver.cpp:253]     Train net output #0: loss = 1.32294 (* 1 = 1.32294 loss)
I0523 03:22:46.687525  8024 sgd_solver.cpp:106] Iteration 103200, lr = 0.0005
I0523 03:22:55.980196  8024 solver.cpp:237] Iteration 103500, loss = 1.316
I0523 03:22:55.980367  8024 solver.cpp:253]     Train net output #0: loss = 1.316 (* 1 = 1.316 loss)
I0523 03:22:55.980381  8024 sgd_solver.cpp:106] Iteration 103500, lr = 0.0005
I0523 03:23:05.274042  8024 solver.cpp:237] Iteration 103800, loss = 1.26318
I0523 03:23:05.274085  8024 solver.cpp:253]     Train net output #0: loss = 1.26318 (* 1 = 1.26318 loss)
I0523 03:23:05.274101  8024 sgd_solver.cpp:106] Iteration 103800, lr = 0.0005
I0523 03:23:35.474402  8024 solver.cpp:237] Iteration 104100, loss = 1.17509
I0523 03:23:35.474601  8024 solver.cpp:253]     Train net output #0: loss = 1.17509 (* 1 = 1.17509 loss)
I0523 03:23:35.474617  8024 sgd_solver.cpp:106] Iteration 104100, lr = 0.0005
I0523 03:23:44.766227  8024 solver.cpp:237] Iteration 104400, loss = 1.11104
I0523 03:23:44.766260  8024 solver.cpp:253]     Train net output #0: loss = 1.11104 (* 1 = 1.11104 loss)
I0523 03:23:44.766274  8024 sgd_solver.cpp:106] Iteration 104400, lr = 0.0005
I0523 03:23:54.058498  8024 solver.cpp:237] Iteration 104700, loss = 0.951118
I0523 03:23:54.058547  8024 solver.cpp:253]     Train net output #0: loss = 0.951118 (* 1 = 0.951118 loss)
I0523 03:23:54.058568  8024 sgd_solver.cpp:106] Iteration 104700, lr = 0.0005
I0523 03:24:03.318737  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_105000.caffemodel
I0523 03:24:03.379701  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_105000.solverstate
I0523 03:24:03.416429  8024 solver.cpp:237] Iteration 105000, loss = 0.953683
I0523 03:24:03.416479  8024 solver.cpp:253]     Train net output #0: loss = 0.953683 (* 1 = 0.953683 loss)
I0523 03:24:03.416496  8024 sgd_solver.cpp:106] Iteration 105000, lr = 0.0005
I0523 03:24:12.705317  8024 solver.cpp:237] Iteration 105300, loss = 1.24878
I0523 03:24:12.705503  8024 solver.cpp:253]     Train net output #0: loss = 1.24878 (* 1 = 1.24878 loss)
I0523 03:24:12.705518  8024 sgd_solver.cpp:106] Iteration 105300, lr = 0.0005
I0523 03:24:21.999198  8024 solver.cpp:237] Iteration 105600, loss = 1.39249
I0523 03:24:21.999246  8024 solver.cpp:253]     Train net output #0: loss = 1.39249 (* 1 = 1.39249 loss)
I0523 03:24:21.999264  8024 sgd_solver.cpp:106] Iteration 105600, lr = 0.0005
I0523 03:24:31.288077  8024 solver.cpp:237] Iteration 105900, loss = 1.15166
I0523 03:24:31.288113  8024 solver.cpp:253]     Train net output #0: loss = 1.15166 (* 1 = 1.15166 loss)
I0523 03:24:31.288127  8024 sgd_solver.cpp:106] Iteration 105900, lr = 0.0005
I0523 03:25:01.549401  8024 solver.cpp:237] Iteration 106200, loss = 1.14506
I0523 03:25:01.549593  8024 solver.cpp:253]     Train net output #0: loss = 1.14506 (* 1 = 1.14506 loss)
I0523 03:25:01.549607  8024 sgd_solver.cpp:106] Iteration 106200, lr = 0.0005
I0523 03:25:10.842138  8024 solver.cpp:237] Iteration 106500, loss = 1.20955
I0523 03:25:10.842181  8024 solver.cpp:253]     Train net output #0: loss = 1.20955 (* 1 = 1.20955 loss)
I0523 03:25:10.842198  8024 sgd_solver.cpp:106] Iteration 106500, lr = 0.0005
I0523 03:25:20.134917  8024 solver.cpp:237] Iteration 106800, loss = 1.14824
I0523 03:25:20.134953  8024 solver.cpp:253]     Train net output #0: loss = 1.14824 (* 1 = 1.14824 loss)
I0523 03:25:20.134968  8024 sgd_solver.cpp:106] Iteration 106800, lr = 0.0005
I0523 03:25:29.426820  8024 solver.cpp:237] Iteration 107100, loss = 1.08097
I0523 03:25:29.426851  8024 solver.cpp:253]     Train net output #0: loss = 1.08097 (* 1 = 1.08097 loss)
I0523 03:25:29.426863  8024 sgd_solver.cpp:106] Iteration 107100, lr = 0.0005
I0523 03:25:38.718904  8024 solver.cpp:237] Iteration 107400, loss = 1.42442
I0523 03:25:38.719089  8024 solver.cpp:253]     Train net output #0: loss = 1.42442 (* 1 = 1.42442 loss)
I0523 03:25:38.719102  8024 sgd_solver.cpp:106] Iteration 107400, lr = 0.0005
I0523 03:25:48.010642  8024 solver.cpp:237] Iteration 107700, loss = 0.982524
I0523 03:25:48.010676  8024 solver.cpp:253]     Train net output #0: loss = 0.982524 (* 1 = 0.982524 loss)
I0523 03:25:48.010692  8024 sgd_solver.cpp:106] Iteration 107700, lr = 0.0005
I0523 03:25:57.271760  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_108000.caffemodel
I0523 03:25:57.338629  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_108000.solverstate
I0523 03:25:57.365768  8024 solver.cpp:341] Iteration 108000, Testing net (#0)
I0523 03:27:06.094183  8024 solver.cpp:409]     Test net output #0: accuracy = 0.865767
I0523 03:27:06.094377  8024 solver.cpp:409]     Test net output #1: loss = 0.441638 (* 1 = 0.441638 loss)
I0523 03:27:27.010063  8024 solver.cpp:237] Iteration 108000, loss = 1.19194
I0523 03:27:27.010116  8024 solver.cpp:253]     Train net output #0: loss = 1.19194 (* 1 = 1.19194 loss)
I0523 03:27:27.010131  8024 sgd_solver.cpp:106] Iteration 108000, lr = 0.0005
I0523 03:27:36.305546  8024 solver.cpp:237] Iteration 108300, loss = 1.14192
I0523 03:27:36.305723  8024 solver.cpp:253]     Train net output #0: loss = 1.14192 (* 1 = 1.14192 loss)
I0523 03:27:36.305737  8024 sgd_solver.cpp:106] Iteration 108300, lr = 0.0005
I0523 03:27:45.603189  8024 solver.cpp:237] Iteration 108600, loss = 1.276
I0523 03:27:45.603229  8024 solver.cpp:253]     Train net output #0: loss = 1.276 (* 1 = 1.276 loss)
I0523 03:27:45.603246  8024 sgd_solver.cpp:106] Iteration 108600, lr = 0.0005
I0523 03:27:54.899765  8024 solver.cpp:237] Iteration 108900, loss = 1.29592
I0523 03:27:54.899801  8024 solver.cpp:253]     Train net output #0: loss = 1.29592 (* 1 = 1.29592 loss)
I0523 03:27:54.899816  8024 sgd_solver.cpp:106] Iteration 108900, lr = 0.0005
I0523 03:28:04.195946  8024 solver.cpp:237] Iteration 109200, loss = 1.66459
I0523 03:28:04.195992  8024 solver.cpp:253]     Train net output #0: loss = 1.66459 (* 1 = 1.66459 loss)
I0523 03:28:04.196007  8024 sgd_solver.cpp:106] Iteration 109200, lr = 0.0005
I0523 03:28:13.494336  8024 solver.cpp:237] Iteration 109500, loss = 0.810125
I0523 03:28:13.494534  8024 solver.cpp:253]     Train net output #0: loss = 0.810125 (* 1 = 0.810125 loss)
I0523 03:28:13.494549  8024 sgd_solver.cpp:106] Iteration 109500, lr = 0.0005
I0523 03:28:22.789450  8024 solver.cpp:237] Iteration 109800, loss = 1.03952
I0523 03:28:22.789485  8024 solver.cpp:253]     Train net output #0: loss = 1.03952 (* 1 = 1.03952 loss)
I0523 03:28:22.789502  8024 sgd_solver.cpp:106] Iteration 109800, lr = 0.0005
I0523 03:28:52.972371  8024 solver.cpp:237] Iteration 110100, loss = 1.36982
I0523 03:28:52.972558  8024 solver.cpp:253]     Train net output #0: loss = 1.36982 (* 1 = 1.36982 loss)
I0523 03:28:52.972574  8024 sgd_solver.cpp:106] Iteration 110100, lr = 0.0005
I0523 03:29:02.269423  8024 solver.cpp:237] Iteration 110400, loss = 1.07832
I0523 03:29:02.269457  8024 solver.cpp:253]     Train net output #0: loss = 1.07832 (* 1 = 1.07832 loss)
I0523 03:29:02.269474  8024 sgd_solver.cpp:106] Iteration 110400, lr = 0.0005
I0523 03:29:11.568086  8024 solver.cpp:237] Iteration 110700, loss = 1.17652
I0523 03:29:11.568121  8024 solver.cpp:253]     Train net output #0: loss = 1.17652 (* 1 = 1.17652 loss)
I0523 03:29:11.568137  8024 sgd_solver.cpp:106] Iteration 110700, lr = 0.0005
I0523 03:29:20.837116  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_111000.caffemodel
I0523 03:29:20.896391  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_111000.solverstate
I0523 03:29:20.931608  8024 solver.cpp:237] Iteration 111000, loss = 1.01238
I0523 03:29:20.931649  8024 solver.cpp:253]     Train net output #0: loss = 1.01238 (* 1 = 1.01238 loss)
I0523 03:29:20.931669  8024 sgd_solver.cpp:106] Iteration 111000, lr = 0.0005
I0523 03:29:30.230792  8024 solver.cpp:237] Iteration 111300, loss = 1.25161
I0523 03:29:30.230968  8024 solver.cpp:253]     Train net output #0: loss = 1.25161 (* 1 = 1.25161 loss)
I0523 03:29:30.230981  8024 sgd_solver.cpp:106] Iteration 111300, lr = 0.0005
I0523 03:29:39.529341  8024 solver.cpp:237] Iteration 111600, loss = 1.08965
I0523 03:29:39.529376  8024 solver.cpp:253]     Train net output #0: loss = 1.08965 (* 1 = 1.08965 loss)
I0523 03:29:39.529393  8024 sgd_solver.cpp:106] Iteration 111600, lr = 0.0005
I0523 03:29:48.827178  8024 solver.cpp:237] Iteration 111900, loss = 0.994249
I0523 03:29:48.827220  8024 solver.cpp:253]     Train net output #0: loss = 0.994249 (* 1 = 0.994249 loss)
I0523 03:29:48.827239  8024 sgd_solver.cpp:106] Iteration 111900, lr = 0.0005
I0523 03:30:19.067867  8024 solver.cpp:237] Iteration 112200, loss = 1.15062
I0523 03:30:19.068073  8024 solver.cpp:253]     Train net output #0: loss = 1.15062 (* 1 = 1.15062 loss)
I0523 03:30:19.068089  8024 sgd_solver.cpp:106] Iteration 112200, lr = 0.0005
I0523 03:30:28.369935  8024 solver.cpp:237] Iteration 112500, loss = 1.41158
I0523 03:30:28.369971  8024 solver.cpp:253]     Train net output #0: loss = 1.41158 (* 1 = 1.41158 loss)
I0523 03:30:28.369987  8024 sgd_solver.cpp:106] Iteration 112500, lr = 0.0005
I0523 03:30:37.667927  8024 solver.cpp:237] Iteration 112800, loss = 1.15731
I0523 03:30:37.667968  8024 solver.cpp:253]     Train net output #0: loss = 1.15731 (* 1 = 1.15731 loss)
I0523 03:30:37.667984  8024 sgd_solver.cpp:106] Iteration 112800, lr = 0.0005
I0523 03:30:46.966694  8024 solver.cpp:237] Iteration 113100, loss = 1.23551
I0523 03:30:46.966732  8024 solver.cpp:253]     Train net output #0: loss = 1.23551 (* 1 = 1.23551 loss)
I0523 03:30:46.966747  8024 sgd_solver.cpp:106] Iteration 113100, lr = 0.0005
I0523 03:30:56.262104  8024 solver.cpp:237] Iteration 113400, loss = 1.27091
I0523 03:30:56.262285  8024 solver.cpp:253]     Train net output #0: loss = 1.27091 (* 1 = 1.27091 loss)
I0523 03:30:56.262300  8024 sgd_solver.cpp:106] Iteration 113400, lr = 0.0005
I0523 03:31:05.561307  8024 solver.cpp:237] Iteration 113700, loss = 1.21619
I0523 03:31:05.561353  8024 solver.cpp:253]     Train net output #0: loss = 1.21619 (* 1 = 1.21619 loss)
I0523 03:31:05.561369  8024 sgd_solver.cpp:106] Iteration 113700, lr = 0.0005
I0523 03:31:14.826418  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_114000.caffemodel
I0523 03:31:14.886303  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_114000.solverstate
I0523 03:31:14.911301  8024 solver.cpp:341] Iteration 114000, Testing net (#0)
I0523 03:32:02.435928  8024 solver.cpp:409]     Test net output #0: accuracy = 0.867144
I0523 03:32:02.436123  8024 solver.cpp:409]     Test net output #1: loss = 0.437895 (* 1 = 0.437895 loss)
I0523 03:32:23.382231  8024 solver.cpp:237] Iteration 114000, loss = 1.08879
I0523 03:32:23.382285  8024 solver.cpp:253]     Train net output #0: loss = 1.08879 (* 1 = 1.08879 loss)
I0523 03:32:23.382302  8024 sgd_solver.cpp:106] Iteration 114000, lr = 0.0005
I0523 03:32:32.690965  8024 solver.cpp:237] Iteration 114300, loss = 1.26679
I0523 03:32:32.691146  8024 solver.cpp:253]     Train net output #0: loss = 1.26679 (* 1 = 1.26679 loss)
I0523 03:32:32.691160  8024 sgd_solver.cpp:106] Iteration 114300, lr = 0.0005
I0523 03:32:41.995638  8024 solver.cpp:237] Iteration 114600, loss = 1.22107
I0523 03:32:41.995678  8024 solver.cpp:253]     Train net output #0: loss = 1.22107 (* 1 = 1.22107 loss)
I0523 03:32:41.995695  8024 sgd_solver.cpp:106] Iteration 114600, lr = 0.0005
I0523 03:32:51.297603  8024 solver.cpp:237] Iteration 114900, loss = 1.14452
I0523 03:32:51.297639  8024 solver.cpp:253]     Train net output #0: loss = 1.14452 (* 1 = 1.14452 loss)
I0523 03:32:51.297657  8024 sgd_solver.cpp:106] Iteration 114900, lr = 0.0005
I0523 03:33:00.605412  8024 solver.cpp:237] Iteration 115200, loss = 1.2908
I0523 03:33:00.605448  8024 solver.cpp:253]     Train net output #0: loss = 1.2908 (* 1 = 1.2908 loss)
I0523 03:33:00.605464  8024 sgd_solver.cpp:106] Iteration 115200, lr = 0.0005
I0523 03:33:09.909927  8024 solver.cpp:237] Iteration 115500, loss = 1.19225
I0523 03:33:09.910109  8024 solver.cpp:253]     Train net output #0: loss = 1.19225 (* 1 = 1.19225 loss)
I0523 03:33:09.910122  8024 sgd_solver.cpp:106] Iteration 115500, lr = 0.0005
I0523 03:33:19.214480  8024 solver.cpp:237] Iteration 115800, loss = 1.00233
I0523 03:33:19.214525  8024 solver.cpp:253]     Train net output #0: loss = 1.00233 (* 1 = 1.00233 loss)
I0523 03:33:19.214540  8024 sgd_solver.cpp:106] Iteration 115800, lr = 0.0005
I0523 03:33:49.460065  8024 solver.cpp:237] Iteration 116100, loss = 1.33631
I0523 03:33:49.460263  8024 solver.cpp:253]     Train net output #0: loss = 1.33631 (* 1 = 1.33631 loss)
I0523 03:33:49.460276  8024 sgd_solver.cpp:106] Iteration 116100, lr = 0.0005
I0523 03:33:58.766633  8024 solver.cpp:237] Iteration 116400, loss = 1.23989
I0523 03:33:58.766674  8024 solver.cpp:253]     Train net output #0: loss = 1.23989 (* 1 = 1.23989 loss)
I0523 03:33:58.766693  8024 sgd_solver.cpp:106] Iteration 116400, lr = 0.0005
I0523 03:34:08.067894  8024 solver.cpp:237] Iteration 116700, loss = 1.16558
I0523 03:34:08.067930  8024 solver.cpp:253]     Train net output #0: loss = 1.16558 (* 1 = 1.16558 loss)
I0523 03:34:08.067947  8024 sgd_solver.cpp:106] Iteration 116700, lr = 0.0005
I0523 03:34:17.341848  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_117000.caffemodel
I0523 03:34:17.400688  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_117000.solverstate
I0523 03:34:17.435432  8024 solver.cpp:237] Iteration 117000, loss = 1.19511
I0523 03:34:17.435478  8024 solver.cpp:253]     Train net output #0: loss = 1.19511 (* 1 = 1.19511 loss)
I0523 03:34:17.435495  8024 sgd_solver.cpp:106] Iteration 117000, lr = 0.0005
I0523 03:34:26.736505  8024 solver.cpp:237] Iteration 117300, loss = 1.41701
I0523 03:34:26.736692  8024 solver.cpp:253]     Train net output #0: loss = 1.41701 (* 1 = 1.41701 loss)
I0523 03:34:26.736706  8024 sgd_solver.cpp:106] Iteration 117300, lr = 0.0005
I0523 03:34:36.039742  8024 solver.cpp:237] Iteration 117600, loss = 1.3523
I0523 03:34:36.039777  8024 solver.cpp:253]     Train net output #0: loss = 1.3523 (* 1 = 1.3523 loss)
I0523 03:34:36.039795  8024 sgd_solver.cpp:106] Iteration 117600, lr = 0.0005
I0523 03:34:45.340441  8024 solver.cpp:237] Iteration 117900, loss = 1.14686
I0523 03:34:45.340483  8024 solver.cpp:253]     Train net output #0: loss = 1.14686 (* 1 = 1.14686 loss)
I0523 03:34:45.340503  8024 sgd_solver.cpp:106] Iteration 117900, lr = 0.0005
I0523 03:35:15.571642  8024 solver.cpp:237] Iteration 118200, loss = 1.29689
I0523 03:35:15.571841  8024 solver.cpp:253]     Train net output #0: loss = 1.29689 (* 1 = 1.29689 loss)
I0523 03:35:15.571856  8024 sgd_solver.cpp:106] Iteration 118200, lr = 0.0005
I0523 03:35:24.875537  8024 solver.cpp:237] Iteration 118500, loss = 1.3135
I0523 03:35:24.875572  8024 solver.cpp:253]     Train net output #0: loss = 1.3135 (* 1 = 1.3135 loss)
I0523 03:35:24.875589  8024 sgd_solver.cpp:106] Iteration 118500, lr = 0.0005
I0523 03:35:34.181514  8024 solver.cpp:237] Iteration 118800, loss = 1.08542
I0523 03:35:34.181565  8024 solver.cpp:253]     Train net output #0: loss = 1.08542 (* 1 = 1.08542 loss)
I0523 03:35:34.181578  8024 sgd_solver.cpp:106] Iteration 118800, lr = 0.0005
I0523 03:35:43.475289  8024 solver.cpp:237] Iteration 119100, loss = 1.66372
I0523 03:35:43.475325  8024 solver.cpp:253]     Train net output #0: loss = 1.66372 (* 1 = 1.66372 loss)
I0523 03:35:43.475339  8024 sgd_solver.cpp:106] Iteration 119100, lr = 0.0005
I0523 03:35:52.770212  8024 solver.cpp:237] Iteration 119400, loss = 1.24632
I0523 03:35:52.770390  8024 solver.cpp:253]     Train net output #0: loss = 1.24632 (* 1 = 1.24632 loss)
I0523 03:35:52.770403  8024 sgd_solver.cpp:106] Iteration 119400, lr = 0.0005
I0523 03:36:02.065855  8024 solver.cpp:237] Iteration 119700, loss = 1.21488
I0523 03:36:02.065901  8024 solver.cpp:253]     Train net output #0: loss = 1.21488 (* 1 = 1.21488 loss)
I0523 03:36:02.065917  8024 sgd_solver.cpp:106] Iteration 119700, lr = 0.0005
I0523 03:36:11.330344  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_120000.caffemodel
I0523 03:36:11.391875  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_120000.solverstate
I0523 03:36:11.419353  8024 solver.cpp:341] Iteration 120000, Testing net (#0)
I0523 03:37:20.244693  8024 solver.cpp:409]     Test net output #0: accuracy = 0.872103
I0523 03:37:20.244889  8024 solver.cpp:409]     Test net output #1: loss = 0.412278 (* 1 = 0.412278 loss)
I0523 03:37:41.162348  8024 solver.cpp:237] Iteration 120000, loss = 1.23532
I0523 03:37:41.162402  8024 solver.cpp:253]     Train net output #0: loss = 1.23532 (* 1 = 1.23532 loss)
I0523 03:37:41.162420  8024 sgd_solver.cpp:106] Iteration 120000, lr = 0.0005
I0523 03:37:50.447309  8024 solver.cpp:237] Iteration 120300, loss = 1.11873
I0523 03:37:50.447490  8024 solver.cpp:253]     Train net output #0: loss = 1.11873 (* 1 = 1.11873 loss)
I0523 03:37:50.447504  8024 sgd_solver.cpp:106] Iteration 120300, lr = 0.0005
I0523 03:37:59.728893  8024 solver.cpp:237] Iteration 120600, loss = 1.05091
I0523 03:37:59.728929  8024 solver.cpp:253]     Train net output #0: loss = 1.05091 (* 1 = 1.05091 loss)
I0523 03:37:59.728945  8024 sgd_solver.cpp:106] Iteration 120600, lr = 0.0005
I0523 03:38:09.017304  8024 solver.cpp:237] Iteration 120900, loss = 1.02052
I0523 03:38:09.017343  8024 solver.cpp:253]     Train net output #0: loss = 1.02052 (* 1 = 1.02052 loss)
I0523 03:38:09.017365  8024 sgd_solver.cpp:106] Iteration 120900, lr = 0.0005
I0523 03:38:18.301818  8024 solver.cpp:237] Iteration 121200, loss = 1.11403
I0523 03:38:18.301854  8024 solver.cpp:253]     Train net output #0: loss = 1.11403 (* 1 = 1.11403 loss)
I0523 03:38:18.301869  8024 sgd_solver.cpp:106] Iteration 121200, lr = 0.0005
I0523 03:38:27.585965  8024 solver.cpp:237] Iteration 121500, loss = 1.46501
I0523 03:38:27.586161  8024 solver.cpp:253]     Train net output #0: loss = 1.46501 (* 1 = 1.46501 loss)
I0523 03:38:27.586175  8024 sgd_solver.cpp:106] Iteration 121500, lr = 0.0005
I0523 03:38:36.868223  8024 solver.cpp:237] Iteration 121800, loss = 1.20677
I0523 03:38:36.868257  8024 solver.cpp:253]     Train net output #0: loss = 1.20677 (* 1 = 1.20677 loss)
I0523 03:38:36.868275  8024 sgd_solver.cpp:106] Iteration 121800, lr = 0.0005
I0523 03:39:07.105034  8024 solver.cpp:237] Iteration 122100, loss = 1.07362
I0523 03:39:07.105235  8024 solver.cpp:253]     Train net output #0: loss = 1.07362 (* 1 = 1.07362 loss)
I0523 03:39:07.105252  8024 sgd_solver.cpp:106] Iteration 122100, lr = 0.0005
I0523 03:39:16.389231  8024 solver.cpp:237] Iteration 122400, loss = 1.01036
I0523 03:39:16.389267  8024 solver.cpp:253]     Train net output #0: loss = 1.01036 (* 1 = 1.01036 loss)
I0523 03:39:16.389283  8024 sgd_solver.cpp:106] Iteration 122400, lr = 0.0005
I0523 03:39:25.674527  8024 solver.cpp:237] Iteration 122700, loss = 1.39422
I0523 03:39:25.674564  8024 solver.cpp:253]     Train net output #0: loss = 1.39422 (* 1 = 1.39422 loss)
I0523 03:39:25.674588  8024 sgd_solver.cpp:106] Iteration 122700, lr = 0.0005
I0523 03:39:34.929683  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_123000.caffemodel
I0523 03:39:34.988802  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_123000.solverstate
I0523 03:39:35.024071  8024 solver.cpp:237] Iteration 123000, loss = 1.04504
I0523 03:39:35.024116  8024 solver.cpp:253]     Train net output #0: loss = 1.04504 (* 1 = 1.04504 loss)
I0523 03:39:35.024129  8024 sgd_solver.cpp:106] Iteration 123000, lr = 0.0005
I0523 03:39:44.308784  8024 solver.cpp:237] Iteration 123300, loss = 1.27582
I0523 03:39:44.308979  8024 solver.cpp:253]     Train net output #0: loss = 1.27582 (* 1 = 1.27582 loss)
I0523 03:39:44.308992  8024 sgd_solver.cpp:106] Iteration 123300, lr = 0.0005
I0523 03:39:53.593998  8024 solver.cpp:237] Iteration 123600, loss = 1.19353
I0523 03:39:53.594033  8024 solver.cpp:253]     Train net output #0: loss = 1.19353 (* 1 = 1.19353 loss)
I0523 03:39:53.594050  8024 sgd_solver.cpp:106] Iteration 123600, lr = 0.0005
I0523 03:40:02.879323  8024 solver.cpp:237] Iteration 123900, loss = 1.0855
I0523 03:40:02.879357  8024 solver.cpp:253]     Train net output #0: loss = 1.0855 (* 1 = 1.0855 loss)
I0523 03:40:02.879374  8024 sgd_solver.cpp:106] Iteration 123900, lr = 0.0005
I0523 03:40:33.079145  8024 solver.cpp:237] Iteration 124200, loss = 1.43664
I0523 03:40:33.079350  8024 solver.cpp:253]     Train net output #0: loss = 1.43664 (* 1 = 1.43664 loss)
I0523 03:40:33.079367  8024 sgd_solver.cpp:106] Iteration 124200, lr = 0.0005
I0523 03:40:42.364722  8024 solver.cpp:237] Iteration 124500, loss = 1.14307
I0523 03:40:42.364758  8024 solver.cpp:253]     Train net output #0: loss = 1.14307 (* 1 = 1.14307 loss)
I0523 03:40:42.364774  8024 sgd_solver.cpp:106] Iteration 124500, lr = 0.0005
I0523 03:40:51.652839  8024 solver.cpp:237] Iteration 124800, loss = 1.44138
I0523 03:40:51.652874  8024 solver.cpp:253]     Train net output #0: loss = 1.44138 (* 1 = 1.44138 loss)
I0523 03:40:51.652891  8024 sgd_solver.cpp:106] Iteration 124800, lr = 0.0005
I0523 03:41:00.933930  8024 solver.cpp:237] Iteration 125100, loss = 1.04864
I0523 03:41:00.933979  8024 solver.cpp:253]     Train net output #0: loss = 1.04864 (* 1 = 1.04864 loss)
I0523 03:41:00.933993  8024 sgd_solver.cpp:106] Iteration 125100, lr = 0.0005
I0523 03:41:10.219244  8024 solver.cpp:237] Iteration 125400, loss = 1.27341
I0523 03:41:10.219429  8024 solver.cpp:253]     Train net output #0: loss = 1.27341 (* 1 = 1.27341 loss)
I0523 03:41:10.219442  8024 sgd_solver.cpp:106] Iteration 125400, lr = 0.0005
I0523 03:41:19.505645  8024 solver.cpp:237] Iteration 125700, loss = 1.12018
I0523 03:41:19.505681  8024 solver.cpp:253]     Train net output #0: loss = 1.12018 (* 1 = 1.12018 loss)
I0523 03:41:19.505697  8024 sgd_solver.cpp:106] Iteration 125700, lr = 0.0005
I0523 03:41:28.760015  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_126000.caffemodel
I0523 03:41:28.818975  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_126000.solverstate
I0523 03:41:28.843925  8024 solver.cpp:341] Iteration 126000, Testing net (#0)
I0523 03:42:16.696049  8024 solver.cpp:409]     Test net output #0: accuracy = 0.871903
I0523 03:42:16.696244  8024 solver.cpp:409]     Test net output #1: loss = 0.403409 (* 1 = 0.403409 loss)
I0523 03:42:37.617454  8024 solver.cpp:237] Iteration 126000, loss = 1.06641
I0523 03:42:37.617507  8024 solver.cpp:253]     Train net output #0: loss = 1.06641 (* 1 = 1.06641 loss)
I0523 03:42:37.617522  8024 sgd_solver.cpp:106] Iteration 126000, lr = 0.0005
I0523 03:42:46.896692  8024 solver.cpp:237] Iteration 126300, loss = 1.18651
I0523 03:42:46.896875  8024 solver.cpp:253]     Train net output #0: loss = 1.18651 (* 1 = 1.18651 loss)
I0523 03:42:46.896889  8024 sgd_solver.cpp:106] Iteration 126300, lr = 0.0005
I0523 03:42:56.178357  8024 solver.cpp:237] Iteration 126600, loss = 1.23681
I0523 03:42:56.178392  8024 solver.cpp:253]     Train net output #0: loss = 1.23681 (* 1 = 1.23681 loss)
I0523 03:42:56.178409  8024 sgd_solver.cpp:106] Iteration 126600, lr = 0.0005
I0523 03:43:05.457226  8024 solver.cpp:237] Iteration 126900, loss = 1.12328
I0523 03:43:05.457268  8024 solver.cpp:253]     Train net output #0: loss = 1.12328 (* 1 = 1.12328 loss)
I0523 03:43:05.457284  8024 sgd_solver.cpp:106] Iteration 126900, lr = 0.0005
I0523 03:43:14.738530  8024 solver.cpp:237] Iteration 127200, loss = 1.23768
I0523 03:43:14.738566  8024 solver.cpp:253]     Train net output #0: loss = 1.23768 (* 1 = 1.23768 loss)
I0523 03:43:14.738584  8024 sgd_solver.cpp:106] Iteration 127200, lr = 0.0005
I0523 03:43:24.018775  8024 solver.cpp:237] Iteration 127500, loss = 1.4031
I0523 03:43:24.018954  8024 solver.cpp:253]     Train net output #0: loss = 1.4031 (* 1 = 1.4031 loss)
I0523 03:43:24.018967  8024 sgd_solver.cpp:106] Iteration 127500, lr = 0.0005
I0523 03:43:33.301046  8024 solver.cpp:237] Iteration 127800, loss = 1.15116
I0523 03:43:33.301091  8024 solver.cpp:253]     Train net output #0: loss = 1.15116 (* 1 = 1.15116 loss)
I0523 03:43:33.301110  8024 sgd_solver.cpp:106] Iteration 127800, lr = 0.0005
I0523 03:44:03.520915  8024 solver.cpp:237] Iteration 128100, loss = 1.16748
I0523 03:44:03.521122  8024 solver.cpp:253]     Train net output #0: loss = 1.16748 (* 1 = 1.16748 loss)
I0523 03:44:03.521138  8024 sgd_solver.cpp:106] Iteration 128100, lr = 0.0005
I0523 03:44:12.800745  8024 solver.cpp:237] Iteration 128400, loss = 1.17661
I0523 03:44:12.800779  8024 solver.cpp:253]     Train net output #0: loss = 1.17661 (* 1 = 1.17661 loss)
I0523 03:44:12.800793  8024 sgd_solver.cpp:106] Iteration 128400, lr = 0.0005
I0523 03:44:22.080490  8024 solver.cpp:237] Iteration 128700, loss = 1.09768
I0523 03:44:22.080533  8024 solver.cpp:253]     Train net output #0: loss = 1.09768 (* 1 = 1.09768 loss)
I0523 03:44:22.080550  8024 sgd_solver.cpp:106] Iteration 128700, lr = 0.0005
I0523 03:44:31.331755  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_129000.caffemodel
I0523 03:44:31.391329  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_129000.solverstate
I0523 03:44:31.426702  8024 solver.cpp:237] Iteration 129000, loss = 1.20652
I0523 03:44:31.426743  8024 solver.cpp:253]     Train net output #0: loss = 1.20652 (* 1 = 1.20652 loss)
I0523 03:44:31.426758  8024 sgd_solver.cpp:106] Iteration 129000, lr = 0.0005
I0523 03:44:40.709745  8024 solver.cpp:237] Iteration 129300, loss = 1.2621
I0523 03:44:40.709934  8024 solver.cpp:253]     Train net output #0: loss = 1.2621 (* 1 = 1.2621 loss)
I0523 03:44:40.709949  8024 sgd_solver.cpp:106] Iteration 129300, lr = 0.0005
I0523 03:44:49.993829  8024 solver.cpp:237] Iteration 129600, loss = 1.27383
I0523 03:44:49.993875  8024 solver.cpp:253]     Train net output #0: loss = 1.27383 (* 1 = 1.27383 loss)
I0523 03:44:49.993890  8024 sgd_solver.cpp:106] Iteration 129600, lr = 0.0005
I0523 03:44:59.274286  8024 solver.cpp:237] Iteration 129900, loss = 1.30824
I0523 03:44:59.274322  8024 solver.cpp:253]     Train net output #0: loss = 1.30824 (* 1 = 1.30824 loss)
I0523 03:44:59.274338  8024 sgd_solver.cpp:106] Iteration 129900, lr = 0.0005
I0523 03:45:29.456338  8024 solver.cpp:237] Iteration 130200, loss = 1.20103
I0523 03:45:29.456542  8024 solver.cpp:253]     Train net output #0: loss = 1.20103 (* 1 = 1.20103 loss)
I0523 03:45:29.456557  8024 sgd_solver.cpp:106] Iteration 130200, lr = 0.0005
I0523 03:45:38.737965  8024 solver.cpp:237] Iteration 130500, loss = 1.27281
I0523 03:45:38.738009  8024 solver.cpp:253]     Train net output #0: loss = 1.27281 (* 1 = 1.27281 loss)
I0523 03:45:38.738026  8024 sgd_solver.cpp:106] Iteration 130500, lr = 0.0005
I0523 03:45:48.020287  8024 solver.cpp:237] Iteration 130800, loss = 0.909506
I0523 03:45:48.020323  8024 solver.cpp:253]     Train net output #0: loss = 0.909506 (* 1 = 0.909506 loss)
I0523 03:45:48.020339  8024 sgd_solver.cpp:106] Iteration 130800, lr = 0.0005
I0523 03:45:57.301507  8024 solver.cpp:237] Iteration 131100, loss = 1.1525
I0523 03:45:57.301540  8024 solver.cpp:253]     Train net output #0: loss = 1.1525 (* 1 = 1.1525 loss)
I0523 03:45:57.301554  8024 sgd_solver.cpp:106] Iteration 131100, lr = 0.0005
I0523 03:46:06.583528  8024 solver.cpp:237] Iteration 131400, loss = 1.04386
I0523 03:46:06.583709  8024 solver.cpp:253]     Train net output #0: loss = 1.04386 (* 1 = 1.04386 loss)
I0523 03:46:06.583722  8024 sgd_solver.cpp:106] Iteration 131400, lr = 0.0005
I0523 03:46:15.861908  8024 solver.cpp:237] Iteration 131700, loss = 1.12546
I0523 03:46:15.861943  8024 solver.cpp:253]     Train net output #0: loss = 1.12546 (* 1 = 1.12546 loss)
I0523 03:46:15.861958  8024 sgd_solver.cpp:106] Iteration 131700, lr = 0.0005
I0523 03:46:25.112843  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_132000.caffemodel
I0523 03:46:25.172202  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_132000.solverstate
I0523 03:46:25.197324  8024 solver.cpp:341] Iteration 132000, Testing net (#0)
I0523 03:47:33.944517  8024 solver.cpp:409]     Test net output #0: accuracy = 0.873897
I0523 03:47:33.944715  8024 solver.cpp:409]     Test net output #1: loss = 0.418014 (* 1 = 0.418014 loss)
I0523 03:47:54.881286  8024 solver.cpp:237] Iteration 132000, loss = 1.28177
I0523 03:47:54.881340  8024 solver.cpp:253]     Train net output #0: loss = 1.28177 (* 1 = 1.28177 loss)
I0523 03:47:54.881355  8024 sgd_solver.cpp:106] Iteration 132000, lr = 0.0005
I0523 03:48:04.180409  8024 solver.cpp:237] Iteration 132300, loss = 1.01505
I0523 03:48:04.180613  8024 solver.cpp:253]     Train net output #0: loss = 1.01505 (* 1 = 1.01505 loss)
I0523 03:48:04.180627  8024 sgd_solver.cpp:106] Iteration 132300, lr = 0.0005
I0523 03:48:13.480625  8024 solver.cpp:237] Iteration 132600, loss = 1.1033
I0523 03:48:13.480660  8024 solver.cpp:253]     Train net output #0: loss = 1.1033 (* 1 = 1.1033 loss)
I0523 03:48:13.480675  8024 sgd_solver.cpp:106] Iteration 132600, lr = 0.0005
I0523 03:48:22.779912  8024 solver.cpp:237] Iteration 132900, loss = 1.11327
I0523 03:48:22.779948  8024 solver.cpp:253]     Train net output #0: loss = 1.11327 (* 1 = 1.11327 loss)
I0523 03:48:22.779961  8024 sgd_solver.cpp:106] Iteration 132900, lr = 0.0005
I0523 03:48:32.082123  8024 solver.cpp:237] Iteration 133200, loss = 1.17235
I0523 03:48:32.082171  8024 solver.cpp:253]     Train net output #0: loss = 1.17235 (* 1 = 1.17235 loss)
I0523 03:48:32.082185  8024 sgd_solver.cpp:106] Iteration 133200, lr = 0.0005
I0523 03:48:41.383430  8024 solver.cpp:237] Iteration 133500, loss = 1.28436
I0523 03:48:41.383610  8024 solver.cpp:253]     Train net output #0: loss = 1.28436 (* 1 = 1.28436 loss)
I0523 03:48:41.383623  8024 sgd_solver.cpp:106] Iteration 133500, lr = 0.0005
I0523 03:48:50.682867  8024 solver.cpp:237] Iteration 133800, loss = 1.02254
I0523 03:48:50.682901  8024 solver.cpp:253]     Train net output #0: loss = 1.02254 (* 1 = 1.02254 loss)
I0523 03:48:50.682915  8024 sgd_solver.cpp:106] Iteration 133800, lr = 0.0005
I0523 03:49:20.907477  8024 solver.cpp:237] Iteration 134100, loss = 0.969622
I0523 03:49:20.907682  8024 solver.cpp:253]     Train net output #0: loss = 0.969622 (* 1 = 0.969622 loss)
I0523 03:49:20.907697  8024 sgd_solver.cpp:106] Iteration 134100, lr = 0.0005
I0523 03:49:30.207408  8024 solver.cpp:237] Iteration 134400, loss = 1.09495
I0523 03:49:30.207442  8024 solver.cpp:253]     Train net output #0: loss = 1.09495 (* 1 = 1.09495 loss)
I0523 03:49:30.207458  8024 sgd_solver.cpp:106] Iteration 134400, lr = 0.0005
I0523 03:49:39.508309  8024 solver.cpp:237] Iteration 134700, loss = 1.22231
I0523 03:49:39.508345  8024 solver.cpp:253]     Train net output #0: loss = 1.22231 (* 1 = 1.22231 loss)
I0523 03:49:39.508358  8024 sgd_solver.cpp:106] Iteration 134700, lr = 0.0005
I0523 03:49:48.775238  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_135000.caffemodel
I0523 03:49:48.836175  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_135000.solverstate
I0523 03:49:48.873170  8024 solver.cpp:237] Iteration 135000, loss = 1.20716
I0523 03:49:48.873219  8024 solver.cpp:253]     Train net output #0: loss = 1.20716 (* 1 = 1.20716 loss)
I0523 03:49:48.873235  8024 sgd_solver.cpp:106] Iteration 135000, lr = 0.0005
I0523 03:49:58.169076  8024 solver.cpp:237] Iteration 135300, loss = 1.46212
I0523 03:49:58.169263  8024 solver.cpp:253]     Train net output #0: loss = 1.46212 (* 1 = 1.46212 loss)
I0523 03:49:58.169277  8024 sgd_solver.cpp:106] Iteration 135300, lr = 0.0005
I0523 03:50:07.472322  8024 solver.cpp:237] Iteration 135600, loss = 1.20386
I0523 03:50:07.472368  8024 solver.cpp:253]     Train net output #0: loss = 1.20386 (* 1 = 1.20386 loss)
I0523 03:50:07.472383  8024 sgd_solver.cpp:106] Iteration 135600, lr = 0.0005
I0523 03:50:16.773579  8024 solver.cpp:237] Iteration 135900, loss = 1.2198
I0523 03:50:16.773615  8024 solver.cpp:253]     Train net output #0: loss = 1.2198 (* 1 = 1.2198 loss)
I0523 03:50:16.773629  8024 sgd_solver.cpp:106] Iteration 135900, lr = 0.0005
I0523 03:50:47.009496  8024 solver.cpp:237] Iteration 136200, loss = 1.44416
I0523 03:50:47.009708  8024 solver.cpp:253]     Train net output #0: loss = 1.44416 (* 1 = 1.44416 loss)
I0523 03:50:47.009726  8024 sgd_solver.cpp:106] Iteration 136200, lr = 0.0005
I0523 03:50:56.310238  8024 solver.cpp:237] Iteration 136500, loss = 1.1865
I0523 03:50:56.310272  8024 solver.cpp:253]     Train net output #0: loss = 1.1865 (* 1 = 1.1865 loss)
I0523 03:50:56.310288  8024 sgd_solver.cpp:106] Iteration 136500, lr = 0.0005
I0523 03:51:05.606462  8024 solver.cpp:237] Iteration 136800, loss = 1.22326
I0523 03:51:05.606500  8024 solver.cpp:253]     Train net output #0: loss = 1.22326 (* 1 = 1.22326 loss)
I0523 03:51:05.606526  8024 sgd_solver.cpp:106] Iteration 136800, lr = 0.0005
I0523 03:51:14.905766  8024 solver.cpp:237] Iteration 137100, loss = 1.27703
I0523 03:51:14.905802  8024 solver.cpp:253]     Train net output #0: loss = 1.27703 (* 1 = 1.27703 loss)
I0523 03:51:14.905815  8024 sgd_solver.cpp:106] Iteration 137100, lr = 0.0005
I0523 03:51:24.200705  8024 solver.cpp:237] Iteration 137400, loss = 1.12083
I0523 03:51:24.200903  8024 solver.cpp:253]     Train net output #0: loss = 1.12083 (* 1 = 1.12083 loss)
I0523 03:51:24.200918  8024 sgd_solver.cpp:106] Iteration 137400, lr = 0.0005
I0523 03:51:33.500980  8024 solver.cpp:237] Iteration 137700, loss = 1.08466
I0523 03:51:33.501015  8024 solver.cpp:253]     Train net output #0: loss = 1.08466 (* 1 = 1.08466 loss)
I0523 03:51:33.501029  8024 sgd_solver.cpp:106] Iteration 137700, lr = 0.0005
I0523 03:51:42.767305  8024 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_138000.caffemodel
I0523 03:51:42.826346  8024 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0005_2016-05-20T15.49.04.864731_iter_138000.solverstate
I0523 03:51:42.851896  8024 solver.cpp:341] Iteration 138000, Testing net (#0)
I0523 03:52:30.372501  8024 solver.cpp:409]     Test net output #0: accuracy = 0.87291
I0523 03:52:30.372704  8024 solver.cpp:409]     Test net output #1: loss = 0.415961 (* 1 = 0.415961 loss)
I0523 03:52:51.297680  8024 solver.cpp:237] Iteration 138000, loss = 1.07494
I0523 03:52:51.297734  8024 solver.cpp:253]     Train net output #0: loss = 1.07494 (* 1 = 1.07494 loss)
I0523 03:52:51.297749  8024 sgd_solver.cpp:106] Iteration 138000, lr = 0.0005
I0523 03:53:00.592703  8024 solver.cpp:237] Iteration 138300, loss = 0.954292
I0523 03:53:00.592911  8024 solver.cpp:253]     Train net output #0: loss = 0.954292 (* 1 = 0.954292 loss)
I0523 03:53:00.592924  8024 sgd_solver.cpp:106] Iteration 138300, lr = 0.0005
I0523 03:53:09.881839  8024 solver.cpp:237] Iteration 138600, loss = 1.37917
I0523 03:53:09.881880  8024 solver.cpp:253]     Train net output #0: loss = 1.37917 (* 1 = 1.37917 loss)
I0523 03:53:09.881897  8024 sgd_solver.cpp:106] Iteration 138600, lr = 0.0005
I0523 03:53:19.180147  8024 solver.cpp:237] Iteration 138900, loss = 1.45338
I0523 03:53:19.180182  8024 solver.cpp:253]     Train net output #0: loss = 1.45338 (* 1 = 1.45338 loss)
I0523 03:53:19.180197  8024 sgd_solver.cpp:106] Iteration 138900, lr = 0.0005
aprun: Apid 11252541: Caught signal Terminated, sending to application
*** Aborted at 1463990008 (unix time) try "date -d @1463990008" if you are using GNU date ***
PC: @     0x2aaab9276640 (unknown)
*** SIGTERM (@0x1f55) received by PID 8024 (TID 0x2aaac746f900) from PID 8021; stack trace: ***
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7213 exceeded limit 7200
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @     0x2aaab9276640 (unknown)
    @     0x2aaab930eb7d (unknown)
    @     0x2aaab928a3b8 (unknown)
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11252541: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
aprun: Apid 11252541: Caught signal Terminated, sending to application
