2807136
I0522 02:04:50.863147  6507 caffe.cpp:184] Using GPUs 0
I0522 02:04:51.292811  6507 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0035
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925.prototxt"
I0522 02:04:51.294847  6507 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925.prototxt
I0522 02:04:51.308753  6507 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 02:04:51.308812  6507 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 02:04:51.309161  6507 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 02:04:51.309342  6507 layer_factory.hpp:77] Creating layer data_hdf5
I0522 02:04:51.309365  6507 net.cpp:106] Creating Layer data_hdf5
I0522 02:04:51.309381  6507 net.cpp:411] data_hdf5 -> data
I0522 02:04:51.309412  6507 net.cpp:411] data_hdf5 -> label
I0522 02:04:51.309444  6507 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 02:04:51.324364  6507 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 02:04:51.326668  6507 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 02:05:12.824453  6507 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 02:05:12.829614  6507 net.cpp:150] Setting up data_hdf5
I0522 02:05:12.829651  6507 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 02:05:12.829666  6507 net.cpp:157] Top shape: 20 (20)
I0522 02:05:12.829676  6507 net.cpp:165] Memory required for data: 508080
I0522 02:05:12.829690  6507 layer_factory.hpp:77] Creating layer conv1
I0522 02:05:12.829725  6507 net.cpp:106] Creating Layer conv1
I0522 02:05:12.829744  6507 net.cpp:454] conv1 <- data
I0522 02:05:12.829767  6507 net.cpp:411] conv1 -> conv1
I0522 02:05:15.588238  6507 net.cpp:150] Setting up conv1
I0522 02:05:15.588286  6507 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 02:05:15.588297  6507 net.cpp:165] Memory required for data: 6037680
I0522 02:05:15.588327  6507 layer_factory.hpp:77] Creating layer relu1
I0522 02:05:15.588347  6507 net.cpp:106] Creating Layer relu1
I0522 02:05:15.588358  6507 net.cpp:454] relu1 <- conv1
I0522 02:05:15.588372  6507 net.cpp:397] relu1 -> conv1 (in-place)
I0522 02:05:15.588889  6507 net.cpp:150] Setting up relu1
I0522 02:05:15.588906  6507 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 02:05:15.588917  6507 net.cpp:165] Memory required for data: 11567280
I0522 02:05:15.588927  6507 layer_factory.hpp:77] Creating layer pool1
I0522 02:05:15.588943  6507 net.cpp:106] Creating Layer pool1
I0522 02:05:15.588953  6507 net.cpp:454] pool1 <- conv1
I0522 02:05:15.588966  6507 net.cpp:411] pool1 -> pool1
I0522 02:05:15.589046  6507 net.cpp:150] Setting up pool1
I0522 02:05:15.589059  6507 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 02:05:15.589069  6507 net.cpp:165] Memory required for data: 14332080
I0522 02:05:15.589079  6507 layer_factory.hpp:77] Creating layer conv2
I0522 02:05:15.589100  6507 net.cpp:106] Creating Layer conv2
I0522 02:05:15.589112  6507 net.cpp:454] conv2 <- pool1
I0522 02:05:15.589124  6507 net.cpp:411] conv2 -> conv2
I0522 02:05:15.591822  6507 net.cpp:150] Setting up conv2
I0522 02:05:15.591845  6507 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 02:05:15.591856  6507 net.cpp:165] Memory required for data: 18306480
I0522 02:05:15.591876  6507 layer_factory.hpp:77] Creating layer relu2
I0522 02:05:15.591889  6507 net.cpp:106] Creating Layer relu2
I0522 02:05:15.591899  6507 net.cpp:454] relu2 <- conv2
I0522 02:05:15.591912  6507 net.cpp:397] relu2 -> conv2 (in-place)
I0522 02:05:15.592243  6507 net.cpp:150] Setting up relu2
I0522 02:05:15.592257  6507 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 02:05:15.592267  6507 net.cpp:165] Memory required for data: 22280880
I0522 02:05:15.592278  6507 layer_factory.hpp:77] Creating layer pool2
I0522 02:05:15.592289  6507 net.cpp:106] Creating Layer pool2
I0522 02:05:15.592299  6507 net.cpp:454] pool2 <- conv2
I0522 02:05:15.592311  6507 net.cpp:411] pool2 -> pool2
I0522 02:05:15.592392  6507 net.cpp:150] Setting up pool2
I0522 02:05:15.592406  6507 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 02:05:15.592417  6507 net.cpp:165] Memory required for data: 24268080
I0522 02:05:15.592425  6507 layer_factory.hpp:77] Creating layer conv3
I0522 02:05:15.592444  6507 net.cpp:106] Creating Layer conv3
I0522 02:05:15.592454  6507 net.cpp:454] conv3 <- pool2
I0522 02:05:15.592468  6507 net.cpp:411] conv3 -> conv3
I0522 02:05:15.594429  6507 net.cpp:150] Setting up conv3
I0522 02:05:15.594451  6507 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 02:05:15.594466  6507 net.cpp:165] Memory required for data: 26436400
I0522 02:05:15.594485  6507 layer_factory.hpp:77] Creating layer relu3
I0522 02:05:15.594501  6507 net.cpp:106] Creating Layer relu3
I0522 02:05:15.594511  6507 net.cpp:454] relu3 <- conv3
I0522 02:05:15.594523  6507 net.cpp:397] relu3 -> conv3 (in-place)
I0522 02:05:15.594990  6507 net.cpp:150] Setting up relu3
I0522 02:05:15.595007  6507 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 02:05:15.595017  6507 net.cpp:165] Memory required for data: 28604720
I0522 02:05:15.595027  6507 layer_factory.hpp:77] Creating layer pool3
I0522 02:05:15.595041  6507 net.cpp:106] Creating Layer pool3
I0522 02:05:15.595051  6507 net.cpp:454] pool3 <- conv3
I0522 02:05:15.595063  6507 net.cpp:411] pool3 -> pool3
I0522 02:05:15.595130  6507 net.cpp:150] Setting up pool3
I0522 02:05:15.595144  6507 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 02:05:15.595154  6507 net.cpp:165] Memory required for data: 29688880
I0522 02:05:15.595163  6507 layer_factory.hpp:77] Creating layer conv4
I0522 02:05:15.595177  6507 net.cpp:106] Creating Layer conv4
I0522 02:05:15.595188  6507 net.cpp:454] conv4 <- pool3
I0522 02:05:15.595202  6507 net.cpp:411] conv4 -> conv4
I0522 02:05:15.597919  6507 net.cpp:150] Setting up conv4
I0522 02:05:15.597946  6507 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 02:05:15.597957  6507 net.cpp:165] Memory required for data: 30414640
I0522 02:05:15.597973  6507 layer_factory.hpp:77] Creating layer relu4
I0522 02:05:15.597987  6507 net.cpp:106] Creating Layer relu4
I0522 02:05:15.597997  6507 net.cpp:454] relu4 <- conv4
I0522 02:05:15.598011  6507 net.cpp:397] relu4 -> conv4 (in-place)
I0522 02:05:15.598475  6507 net.cpp:150] Setting up relu4
I0522 02:05:15.598492  6507 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 02:05:15.598502  6507 net.cpp:165] Memory required for data: 31140400
I0522 02:05:15.598512  6507 layer_factory.hpp:77] Creating layer pool4
I0522 02:05:15.598526  6507 net.cpp:106] Creating Layer pool4
I0522 02:05:15.598536  6507 net.cpp:454] pool4 <- conv4
I0522 02:05:15.598548  6507 net.cpp:411] pool4 -> pool4
I0522 02:05:15.598615  6507 net.cpp:150] Setting up pool4
I0522 02:05:15.598628  6507 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 02:05:15.598639  6507 net.cpp:165] Memory required for data: 31503280
I0522 02:05:15.598649  6507 layer_factory.hpp:77] Creating layer ip1
I0522 02:05:15.598667  6507 net.cpp:106] Creating Layer ip1
I0522 02:05:15.598678  6507 net.cpp:454] ip1 <- pool4
I0522 02:05:15.598691  6507 net.cpp:411] ip1 -> ip1
I0522 02:05:15.614119  6507 net.cpp:150] Setting up ip1
I0522 02:05:15.614146  6507 net.cpp:157] Top shape: 20 196 (3920)
I0522 02:05:15.614158  6507 net.cpp:165] Memory required for data: 31518960
I0522 02:05:15.614181  6507 layer_factory.hpp:77] Creating layer relu5
I0522 02:05:15.614195  6507 net.cpp:106] Creating Layer relu5
I0522 02:05:15.614205  6507 net.cpp:454] relu5 <- ip1
I0522 02:05:15.614218  6507 net.cpp:397] relu5 -> ip1 (in-place)
I0522 02:05:15.614558  6507 net.cpp:150] Setting up relu5
I0522 02:05:15.614573  6507 net.cpp:157] Top shape: 20 196 (3920)
I0522 02:05:15.614583  6507 net.cpp:165] Memory required for data: 31534640
I0522 02:05:15.614593  6507 layer_factory.hpp:77] Creating layer drop1
I0522 02:05:15.614614  6507 net.cpp:106] Creating Layer drop1
I0522 02:05:15.614624  6507 net.cpp:454] drop1 <- ip1
I0522 02:05:15.614636  6507 net.cpp:397] drop1 -> ip1 (in-place)
I0522 02:05:15.614696  6507 net.cpp:150] Setting up drop1
I0522 02:05:15.614708  6507 net.cpp:157] Top shape: 20 196 (3920)
I0522 02:05:15.614719  6507 net.cpp:165] Memory required for data: 31550320
I0522 02:05:15.614728  6507 layer_factory.hpp:77] Creating layer ip2
I0522 02:05:15.614748  6507 net.cpp:106] Creating Layer ip2
I0522 02:05:15.614758  6507 net.cpp:454] ip2 <- ip1
I0522 02:05:15.614769  6507 net.cpp:411] ip2 -> ip2
I0522 02:05:15.615231  6507 net.cpp:150] Setting up ip2
I0522 02:05:15.615244  6507 net.cpp:157] Top shape: 20 98 (1960)
I0522 02:05:15.615253  6507 net.cpp:165] Memory required for data: 31558160
I0522 02:05:15.615268  6507 layer_factory.hpp:77] Creating layer relu6
I0522 02:05:15.615281  6507 net.cpp:106] Creating Layer relu6
I0522 02:05:15.615291  6507 net.cpp:454] relu6 <- ip2
I0522 02:05:15.615303  6507 net.cpp:397] relu6 -> ip2 (in-place)
I0522 02:05:15.615823  6507 net.cpp:150] Setting up relu6
I0522 02:05:15.615839  6507 net.cpp:157] Top shape: 20 98 (1960)
I0522 02:05:15.615849  6507 net.cpp:165] Memory required for data: 31566000
I0522 02:05:15.615860  6507 layer_factory.hpp:77] Creating layer drop2
I0522 02:05:15.615874  6507 net.cpp:106] Creating Layer drop2
I0522 02:05:15.615882  6507 net.cpp:454] drop2 <- ip2
I0522 02:05:15.615895  6507 net.cpp:397] drop2 -> ip2 (in-place)
I0522 02:05:15.615937  6507 net.cpp:150] Setting up drop2
I0522 02:05:15.615952  6507 net.cpp:157] Top shape: 20 98 (1960)
I0522 02:05:15.615962  6507 net.cpp:165] Memory required for data: 31573840
I0522 02:05:15.615972  6507 layer_factory.hpp:77] Creating layer ip3
I0522 02:05:15.615985  6507 net.cpp:106] Creating Layer ip3
I0522 02:05:15.615994  6507 net.cpp:454] ip3 <- ip2
I0522 02:05:15.616006  6507 net.cpp:411] ip3 -> ip3
I0522 02:05:15.616217  6507 net.cpp:150] Setting up ip3
I0522 02:05:15.616230  6507 net.cpp:157] Top shape: 20 11 (220)
I0522 02:05:15.616240  6507 net.cpp:165] Memory required for data: 31574720
I0522 02:05:15.616255  6507 layer_factory.hpp:77] Creating layer drop3
I0522 02:05:15.616268  6507 net.cpp:106] Creating Layer drop3
I0522 02:05:15.616277  6507 net.cpp:454] drop3 <- ip3
I0522 02:05:15.616289  6507 net.cpp:397] drop3 -> ip3 (in-place)
I0522 02:05:15.616329  6507 net.cpp:150] Setting up drop3
I0522 02:05:15.616343  6507 net.cpp:157] Top shape: 20 11 (220)
I0522 02:05:15.616353  6507 net.cpp:165] Memory required for data: 31575600
I0522 02:05:15.616363  6507 layer_factory.hpp:77] Creating layer loss
I0522 02:05:15.616380  6507 net.cpp:106] Creating Layer loss
I0522 02:05:15.616390  6507 net.cpp:454] loss <- ip3
I0522 02:05:15.616401  6507 net.cpp:454] loss <- label
I0522 02:05:15.616415  6507 net.cpp:411] loss -> loss
I0522 02:05:15.616431  6507 layer_factory.hpp:77] Creating layer loss
I0522 02:05:15.617069  6507 net.cpp:150] Setting up loss
I0522 02:05:15.617089  6507 net.cpp:157] Top shape: (1)
I0522 02:05:15.617102  6507 net.cpp:160]     with loss weight 1
I0522 02:05:15.617144  6507 net.cpp:165] Memory required for data: 31575604
I0522 02:05:15.617154  6507 net.cpp:226] loss needs backward computation.
I0522 02:05:15.617166  6507 net.cpp:226] drop3 needs backward computation.
I0522 02:05:15.617175  6507 net.cpp:226] ip3 needs backward computation.
I0522 02:05:15.617184  6507 net.cpp:226] drop2 needs backward computation.
I0522 02:05:15.617195  6507 net.cpp:226] relu6 needs backward computation.
I0522 02:05:15.617204  6507 net.cpp:226] ip2 needs backward computation.
I0522 02:05:15.617214  6507 net.cpp:226] drop1 needs backward computation.
I0522 02:05:15.617224  6507 net.cpp:226] relu5 needs backward computation.
I0522 02:05:15.617234  6507 net.cpp:226] ip1 needs backward computation.
I0522 02:05:15.617244  6507 net.cpp:226] pool4 needs backward computation.
I0522 02:05:15.617254  6507 net.cpp:226] relu4 needs backward computation.
I0522 02:05:15.617264  6507 net.cpp:226] conv4 needs backward computation.
I0522 02:05:15.617274  6507 net.cpp:226] pool3 needs backward computation.
I0522 02:05:15.617285  6507 net.cpp:226] relu3 needs backward computation.
I0522 02:05:15.617293  6507 net.cpp:226] conv3 needs backward computation.
I0522 02:05:15.617312  6507 net.cpp:226] pool2 needs backward computation.
I0522 02:05:15.617323  6507 net.cpp:226] relu2 needs backward computation.
I0522 02:05:15.617336  6507 net.cpp:226] conv2 needs backward computation.
I0522 02:05:15.617346  6507 net.cpp:226] pool1 needs backward computation.
I0522 02:05:15.617355  6507 net.cpp:226] relu1 needs backward computation.
I0522 02:05:15.617365  6507 net.cpp:226] conv1 needs backward computation.
I0522 02:05:15.617377  6507 net.cpp:228] data_hdf5 does not need backward computation.
I0522 02:05:15.617385  6507 net.cpp:270] This network produces output loss
I0522 02:05:15.617410  6507 net.cpp:283] Network initialization done.
I0522 02:05:15.619175  6507 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925.prototxt
I0522 02:05:15.619246  6507 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 02:05:15.619602  6507 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 02:05:15.619792  6507 layer_factory.hpp:77] Creating layer data_hdf5
I0522 02:05:15.619808  6507 net.cpp:106] Creating Layer data_hdf5
I0522 02:05:15.619820  6507 net.cpp:411] data_hdf5 -> data
I0522 02:05:15.619838  6507 net.cpp:411] data_hdf5 -> label
I0522 02:05:15.619854  6507 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 02:05:15.633443  6507 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 02:05:37.012912  6507 net.cpp:150] Setting up data_hdf5
I0522 02:05:37.013077  6507 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 02:05:37.013092  6507 net.cpp:157] Top shape: 20 (20)
I0522 02:05:37.013101  6507 net.cpp:165] Memory required for data: 508080
I0522 02:05:37.013115  6507 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 02:05:37.013144  6507 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 02:05:37.013155  6507 net.cpp:454] label_data_hdf5_1_split <- label
I0522 02:05:37.013170  6507 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 02:05:37.013191  6507 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 02:05:37.013264  6507 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 02:05:37.013278  6507 net.cpp:157] Top shape: 20 (20)
I0522 02:05:37.013290  6507 net.cpp:157] Top shape: 20 (20)
I0522 02:05:37.013299  6507 net.cpp:165] Memory required for data: 508240
I0522 02:05:37.013309  6507 layer_factory.hpp:77] Creating layer conv1
I0522 02:05:37.013331  6507 net.cpp:106] Creating Layer conv1
I0522 02:05:37.013342  6507 net.cpp:454] conv1 <- data
I0522 02:05:37.013357  6507 net.cpp:411] conv1 -> conv1
I0522 02:05:37.015314  6507 net.cpp:150] Setting up conv1
I0522 02:05:37.015338  6507 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 02:05:37.015349  6507 net.cpp:165] Memory required for data: 6037840
I0522 02:05:37.015372  6507 layer_factory.hpp:77] Creating layer relu1
I0522 02:05:37.015386  6507 net.cpp:106] Creating Layer relu1
I0522 02:05:37.015396  6507 net.cpp:454] relu1 <- conv1
I0522 02:05:37.015409  6507 net.cpp:397] relu1 -> conv1 (in-place)
I0522 02:05:37.015905  6507 net.cpp:150] Setting up relu1
I0522 02:05:37.015921  6507 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 02:05:37.015933  6507 net.cpp:165] Memory required for data: 11567440
I0522 02:05:37.015943  6507 layer_factory.hpp:77] Creating layer pool1
I0522 02:05:37.015959  6507 net.cpp:106] Creating Layer pool1
I0522 02:05:37.015969  6507 net.cpp:454] pool1 <- conv1
I0522 02:05:37.015981  6507 net.cpp:411] pool1 -> pool1
I0522 02:05:37.016057  6507 net.cpp:150] Setting up pool1
I0522 02:05:37.016069  6507 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 02:05:37.016078  6507 net.cpp:165] Memory required for data: 14332240
I0522 02:05:37.016090  6507 layer_factory.hpp:77] Creating layer conv2
I0522 02:05:37.016108  6507 net.cpp:106] Creating Layer conv2
I0522 02:05:37.016119  6507 net.cpp:454] conv2 <- pool1
I0522 02:05:37.016132  6507 net.cpp:411] conv2 -> conv2
I0522 02:05:37.018056  6507 net.cpp:150] Setting up conv2
I0522 02:05:37.018079  6507 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 02:05:37.018092  6507 net.cpp:165] Memory required for data: 18306640
I0522 02:05:37.018110  6507 layer_factory.hpp:77] Creating layer relu2
I0522 02:05:37.018123  6507 net.cpp:106] Creating Layer relu2
I0522 02:05:37.018133  6507 net.cpp:454] relu2 <- conv2
I0522 02:05:37.018146  6507 net.cpp:397] relu2 -> conv2 (in-place)
I0522 02:05:37.018478  6507 net.cpp:150] Setting up relu2
I0522 02:05:37.018492  6507 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 02:05:37.018502  6507 net.cpp:165] Memory required for data: 22281040
I0522 02:05:37.018512  6507 layer_factory.hpp:77] Creating layer pool2
I0522 02:05:37.018525  6507 net.cpp:106] Creating Layer pool2
I0522 02:05:37.018535  6507 net.cpp:454] pool2 <- conv2
I0522 02:05:37.018548  6507 net.cpp:411] pool2 -> pool2
I0522 02:05:37.018618  6507 net.cpp:150] Setting up pool2
I0522 02:05:37.018632  6507 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 02:05:37.018641  6507 net.cpp:165] Memory required for data: 24268240
I0522 02:05:37.018652  6507 layer_factory.hpp:77] Creating layer conv3
I0522 02:05:37.018671  6507 net.cpp:106] Creating Layer conv3
I0522 02:05:37.018682  6507 net.cpp:454] conv3 <- pool2
I0522 02:05:37.018695  6507 net.cpp:411] conv3 -> conv3
I0522 02:05:37.020771  6507 net.cpp:150] Setting up conv3
I0522 02:05:37.020789  6507 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 02:05:37.020804  6507 net.cpp:165] Memory required for data: 26436560
I0522 02:05:37.020823  6507 layer_factory.hpp:77] Creating layer relu3
I0522 02:05:37.020849  6507 net.cpp:106] Creating Layer relu3
I0522 02:05:37.020859  6507 net.cpp:454] relu3 <- conv3
I0522 02:05:37.020872  6507 net.cpp:397] relu3 -> conv3 (in-place)
I0522 02:05:37.021347  6507 net.cpp:150] Setting up relu3
I0522 02:05:37.021364  6507 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 02:05:37.021375  6507 net.cpp:165] Memory required for data: 28604880
I0522 02:05:37.021385  6507 layer_factory.hpp:77] Creating layer pool3
I0522 02:05:37.021399  6507 net.cpp:106] Creating Layer pool3
I0522 02:05:37.021409  6507 net.cpp:454] pool3 <- conv3
I0522 02:05:37.021421  6507 net.cpp:411] pool3 -> pool3
I0522 02:05:37.021493  6507 net.cpp:150] Setting up pool3
I0522 02:05:37.021507  6507 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 02:05:37.021515  6507 net.cpp:165] Memory required for data: 29689040
I0522 02:05:37.021525  6507 layer_factory.hpp:77] Creating layer conv4
I0522 02:05:37.021543  6507 net.cpp:106] Creating Layer conv4
I0522 02:05:37.021553  6507 net.cpp:454] conv4 <- pool3
I0522 02:05:37.021569  6507 net.cpp:411] conv4 -> conv4
I0522 02:05:37.023633  6507 net.cpp:150] Setting up conv4
I0522 02:05:37.023651  6507 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 02:05:37.023661  6507 net.cpp:165] Memory required for data: 30414800
I0522 02:05:37.023676  6507 layer_factory.hpp:77] Creating layer relu4
I0522 02:05:37.023689  6507 net.cpp:106] Creating Layer relu4
I0522 02:05:37.023699  6507 net.cpp:454] relu4 <- conv4
I0522 02:05:37.023712  6507 net.cpp:397] relu4 -> conv4 (in-place)
I0522 02:05:37.024181  6507 net.cpp:150] Setting up relu4
I0522 02:05:37.024197  6507 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 02:05:37.024207  6507 net.cpp:165] Memory required for data: 31140560
I0522 02:05:37.024217  6507 layer_factory.hpp:77] Creating layer pool4
I0522 02:05:37.024230  6507 net.cpp:106] Creating Layer pool4
I0522 02:05:37.024240  6507 net.cpp:454] pool4 <- conv4
I0522 02:05:37.024253  6507 net.cpp:411] pool4 -> pool4
I0522 02:05:37.024325  6507 net.cpp:150] Setting up pool4
I0522 02:05:37.024338  6507 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 02:05:37.024348  6507 net.cpp:165] Memory required for data: 31503440
I0522 02:05:37.024358  6507 layer_factory.hpp:77] Creating layer ip1
I0522 02:05:37.024374  6507 net.cpp:106] Creating Layer ip1
I0522 02:05:37.024384  6507 net.cpp:454] ip1 <- pool4
I0522 02:05:37.024397  6507 net.cpp:411] ip1 -> ip1
I0522 02:05:37.039870  6507 net.cpp:150] Setting up ip1
I0522 02:05:37.039894  6507 net.cpp:157] Top shape: 20 196 (3920)
I0522 02:05:37.039904  6507 net.cpp:165] Memory required for data: 31519120
I0522 02:05:37.039927  6507 layer_factory.hpp:77] Creating layer relu5
I0522 02:05:37.039942  6507 net.cpp:106] Creating Layer relu5
I0522 02:05:37.039952  6507 net.cpp:454] relu5 <- ip1
I0522 02:05:37.039965  6507 net.cpp:397] relu5 -> ip1 (in-place)
I0522 02:05:37.040313  6507 net.cpp:150] Setting up relu5
I0522 02:05:37.040326  6507 net.cpp:157] Top shape: 20 196 (3920)
I0522 02:05:37.040336  6507 net.cpp:165] Memory required for data: 31534800
I0522 02:05:37.040347  6507 layer_factory.hpp:77] Creating layer drop1
I0522 02:05:37.040366  6507 net.cpp:106] Creating Layer drop1
I0522 02:05:37.040375  6507 net.cpp:454] drop1 <- ip1
I0522 02:05:37.040390  6507 net.cpp:397] drop1 -> ip1 (in-place)
I0522 02:05:37.040434  6507 net.cpp:150] Setting up drop1
I0522 02:05:37.040447  6507 net.cpp:157] Top shape: 20 196 (3920)
I0522 02:05:37.040457  6507 net.cpp:165] Memory required for data: 31550480
I0522 02:05:37.040467  6507 layer_factory.hpp:77] Creating layer ip2
I0522 02:05:37.040480  6507 net.cpp:106] Creating Layer ip2
I0522 02:05:37.040491  6507 net.cpp:454] ip2 <- ip1
I0522 02:05:37.040505  6507 net.cpp:411] ip2 -> ip2
I0522 02:05:37.040982  6507 net.cpp:150] Setting up ip2
I0522 02:05:37.040995  6507 net.cpp:157] Top shape: 20 98 (1960)
I0522 02:05:37.041005  6507 net.cpp:165] Memory required for data: 31558320
I0522 02:05:37.041021  6507 layer_factory.hpp:77] Creating layer relu6
I0522 02:05:37.041046  6507 net.cpp:106] Creating Layer relu6
I0522 02:05:37.041056  6507 net.cpp:454] relu6 <- ip2
I0522 02:05:37.041069  6507 net.cpp:397] relu6 -> ip2 (in-place)
I0522 02:05:37.041601  6507 net.cpp:150] Setting up relu6
I0522 02:05:37.041617  6507 net.cpp:157] Top shape: 20 98 (1960)
I0522 02:05:37.041626  6507 net.cpp:165] Memory required for data: 31566160
I0522 02:05:37.041637  6507 layer_factory.hpp:77] Creating layer drop2
I0522 02:05:37.041651  6507 net.cpp:106] Creating Layer drop2
I0522 02:05:37.041661  6507 net.cpp:454] drop2 <- ip2
I0522 02:05:37.041673  6507 net.cpp:397] drop2 -> ip2 (in-place)
I0522 02:05:37.041718  6507 net.cpp:150] Setting up drop2
I0522 02:05:37.041738  6507 net.cpp:157] Top shape: 20 98 (1960)
I0522 02:05:37.041749  6507 net.cpp:165] Memory required for data: 31574000
I0522 02:05:37.041759  6507 layer_factory.hpp:77] Creating layer ip3
I0522 02:05:37.041772  6507 net.cpp:106] Creating Layer ip3
I0522 02:05:37.041782  6507 net.cpp:454] ip3 <- ip2
I0522 02:05:37.041795  6507 net.cpp:411] ip3 -> ip3
I0522 02:05:37.042019  6507 net.cpp:150] Setting up ip3
I0522 02:05:37.042032  6507 net.cpp:157] Top shape: 20 11 (220)
I0522 02:05:37.042042  6507 net.cpp:165] Memory required for data: 31574880
I0522 02:05:37.042057  6507 layer_factory.hpp:77] Creating layer drop3
I0522 02:05:37.042070  6507 net.cpp:106] Creating Layer drop3
I0522 02:05:37.042080  6507 net.cpp:454] drop3 <- ip3
I0522 02:05:37.042093  6507 net.cpp:397] drop3 -> ip3 (in-place)
I0522 02:05:37.042134  6507 net.cpp:150] Setting up drop3
I0522 02:05:37.042146  6507 net.cpp:157] Top shape: 20 11 (220)
I0522 02:05:37.042156  6507 net.cpp:165] Memory required for data: 31575760
I0522 02:05:37.042166  6507 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 02:05:37.042181  6507 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 02:05:37.042189  6507 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 02:05:37.042202  6507 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 02:05:37.042217  6507 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 02:05:37.042291  6507 net.cpp:150] Setting up ip3_drop3_0_split
I0522 02:05:37.042304  6507 net.cpp:157] Top shape: 20 11 (220)
I0522 02:05:37.042316  6507 net.cpp:157] Top shape: 20 11 (220)
I0522 02:05:37.042326  6507 net.cpp:165] Memory required for data: 31577520
I0522 02:05:37.042336  6507 layer_factory.hpp:77] Creating layer accuracy
I0522 02:05:37.042358  6507 net.cpp:106] Creating Layer accuracy
I0522 02:05:37.042368  6507 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 02:05:37.042379  6507 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 02:05:37.042393  6507 net.cpp:411] accuracy -> accuracy
I0522 02:05:37.042417  6507 net.cpp:150] Setting up accuracy
I0522 02:05:37.042429  6507 net.cpp:157] Top shape: (1)
I0522 02:05:37.042439  6507 net.cpp:165] Memory required for data: 31577524
I0522 02:05:37.042449  6507 layer_factory.hpp:77] Creating layer loss
I0522 02:05:37.042464  6507 net.cpp:106] Creating Layer loss
I0522 02:05:37.042474  6507 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 02:05:37.042484  6507 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 02:05:37.042497  6507 net.cpp:411] loss -> loss
I0522 02:05:37.042515  6507 layer_factory.hpp:77] Creating layer loss
I0522 02:05:37.042994  6507 net.cpp:150] Setting up loss
I0522 02:05:37.043009  6507 net.cpp:157] Top shape: (1)
I0522 02:05:37.043017  6507 net.cpp:160]     with loss weight 1
I0522 02:05:37.043035  6507 net.cpp:165] Memory required for data: 31577528
I0522 02:05:37.043045  6507 net.cpp:226] loss needs backward computation.
I0522 02:05:37.043057  6507 net.cpp:228] accuracy does not need backward computation.
I0522 02:05:37.043068  6507 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 02:05:37.043078  6507 net.cpp:226] drop3 needs backward computation.
I0522 02:05:37.043088  6507 net.cpp:226] ip3 needs backward computation.
I0522 02:05:37.043098  6507 net.cpp:226] drop2 needs backward computation.
I0522 02:05:37.043108  6507 net.cpp:226] relu6 needs backward computation.
I0522 02:05:37.043126  6507 net.cpp:226] ip2 needs backward computation.
I0522 02:05:37.043136  6507 net.cpp:226] drop1 needs backward computation.
I0522 02:05:37.043145  6507 net.cpp:226] relu5 needs backward computation.
I0522 02:05:37.043155  6507 net.cpp:226] ip1 needs backward computation.
I0522 02:05:37.043165  6507 net.cpp:226] pool4 needs backward computation.
I0522 02:05:37.043175  6507 net.cpp:226] relu4 needs backward computation.
I0522 02:05:37.043185  6507 net.cpp:226] conv4 needs backward computation.
I0522 02:05:37.043196  6507 net.cpp:226] pool3 needs backward computation.
I0522 02:05:37.043207  6507 net.cpp:226] relu3 needs backward computation.
I0522 02:05:37.043217  6507 net.cpp:226] conv3 needs backward computation.
I0522 02:05:37.043227  6507 net.cpp:226] pool2 needs backward computation.
I0522 02:05:37.043239  6507 net.cpp:226] relu2 needs backward computation.
I0522 02:05:37.043249  6507 net.cpp:226] conv2 needs backward computation.
I0522 02:05:37.043259  6507 net.cpp:226] pool1 needs backward computation.
I0522 02:05:37.043269  6507 net.cpp:226] relu1 needs backward computation.
I0522 02:05:37.043279  6507 net.cpp:226] conv1 needs backward computation.
I0522 02:05:37.043290  6507 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 02:05:37.043303  6507 net.cpp:228] data_hdf5 does not need backward computation.
I0522 02:05:37.043311  6507 net.cpp:270] This network produces output accuracy
I0522 02:05:37.043321  6507 net.cpp:270] This network produces output loss
I0522 02:05:37.043350  6507 net.cpp:283] Network initialization done.
I0522 02:05:37.043483  6507 solver.cpp:60] Solver scaffolding done.
I0522 02:05:37.044615  6507 caffe.cpp:212] Starting Optimization
I0522 02:05:37.044633  6507 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 02:05:37.044647  6507 solver.cpp:289] Learning Rate Policy: fixed
I0522 02:05:37.045898  6507 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 02:06:29.817838  6507 solver.cpp:409]     Test net output #0: accuracy = 0.111985
I0522 02:06:29.818011  6507 solver.cpp:409]     Test net output #1: loss = 2.39734 (* 1 = 2.39734 loss)
I0522 02:06:29.837064  6507 solver.cpp:237] Iteration 0, loss = 2.41395
I0522 02:06:29.837100  6507 solver.cpp:253]     Train net output #0: loss = 2.41395 (* 1 = 2.41395 loss)
I0522 02:06:29.837118  6507 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0522 02:06:42.010690  6507 solver.cpp:237] Iteration 750, loss = 2.07075
I0522 02:06:42.010730  6507 solver.cpp:253]     Train net output #0: loss = 2.07075 (* 1 = 2.07075 loss)
I0522 02:06:42.010746  6507 sgd_solver.cpp:106] Iteration 750, lr = 0.0035
I0522 02:06:54.161181  6507 solver.cpp:237] Iteration 1500, loss = 1.72921
I0522 02:06:54.161232  6507 solver.cpp:253]     Train net output #0: loss = 1.72921 (* 1 = 1.72921 loss)
I0522 02:06:54.161247  6507 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0522 02:07:06.271664  6507 solver.cpp:237] Iteration 2250, loss = 1.61469
I0522 02:07:06.271808  6507 solver.cpp:253]     Train net output #0: loss = 1.61469 (* 1 = 1.61469 loss)
I0522 02:07:06.271822  6507 sgd_solver.cpp:106] Iteration 2250, lr = 0.0035
I0522 02:07:18.417889  6507 solver.cpp:237] Iteration 3000, loss = 1.32853
I0522 02:07:18.417940  6507 solver.cpp:253]     Train net output #0: loss = 1.32853 (* 1 = 1.32853 loss)
I0522 02:07:18.417954  6507 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0522 02:07:30.565541  6507 solver.cpp:237] Iteration 3750, loss = 1.24616
I0522 02:07:30.565579  6507 solver.cpp:253]     Train net output #0: loss = 1.24616 (* 1 = 1.24616 loss)
I0522 02:07:30.565595  6507 sgd_solver.cpp:106] Iteration 3750, lr = 0.0035
I0522 02:07:42.723320  6507 solver.cpp:237] Iteration 4500, loss = 1.53524
I0522 02:07:42.723471  6507 solver.cpp:253]     Train net output #0: loss = 1.53524 (* 1 = 1.53524 loss)
I0522 02:07:42.723486  6507 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0522 02:08:17.001435  6507 solver.cpp:237] Iteration 5250, loss = 1.43893
I0522 02:08:17.001593  6507 solver.cpp:253]     Train net output #0: loss = 1.43893 (* 1 = 1.43893 loss)
I0522 02:08:17.001608  6507 sgd_solver.cpp:106] Iteration 5250, lr = 0.0035
I0522 02:08:29.117036  6507 solver.cpp:237] Iteration 6000, loss = 1.38027
I0522 02:08:29.117082  6507 solver.cpp:253]     Train net output #0: loss = 1.38027 (* 1 = 1.38027 loss)
I0522 02:08:29.117100  6507 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0522 02:08:41.231305  6507 solver.cpp:237] Iteration 6750, loss = 1.88025
I0522 02:08:41.231340  6507 solver.cpp:253]     Train net output #0: loss = 1.88025 (* 1 = 1.88025 loss)
I0522 02:08:41.231359  6507 sgd_solver.cpp:106] Iteration 6750, lr = 0.0035
I0522 02:08:53.354828  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_7500.caffemodel
I0522 02:08:53.407263  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_7500.solverstate
I0522 02:08:53.440207  6507 solver.cpp:237] Iteration 7500, loss = 1.42948
I0522 02:08:53.440256  6507 solver.cpp:253]     Train net output #0: loss = 1.42948 (* 1 = 1.42948 loss)
I0522 02:08:53.440273  6507 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0522 02:09:05.558219  6507 solver.cpp:237] Iteration 8250, loss = 1.98403
I0522 02:09:05.558255  6507 solver.cpp:253]     Train net output #0: loss = 1.98403 (* 1 = 1.98403 loss)
I0522 02:09:05.558269  6507 sgd_solver.cpp:106] Iteration 8250, lr = 0.0035
I0522 02:09:17.702545  6507 solver.cpp:237] Iteration 9000, loss = 0.939196
I0522 02:09:17.702589  6507 solver.cpp:253]     Train net output #0: loss = 0.939196 (* 1 = 0.939196 loss)
I0522 02:09:17.702605  6507 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0522 02:09:29.818508  6507 solver.cpp:237] Iteration 9750, loss = 0.746589
I0522 02:09:29.818655  6507 solver.cpp:253]     Train net output #0: loss = 0.746589 (* 1 = 0.746589 loss)
I0522 02:09:29.818670  6507 sgd_solver.cpp:106] Iteration 9750, lr = 0.0035
I0522 02:10:04.032673  6507 solver.cpp:237] Iteration 10500, loss = 1.21104
I0522 02:10:04.032835  6507 solver.cpp:253]     Train net output #0: loss = 1.21104 (* 1 = 1.21104 loss)
I0522 02:10:04.032850  6507 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0522 02:10:16.147944  6507 solver.cpp:237] Iteration 11250, loss = 1.21293
I0522 02:10:16.147991  6507 solver.cpp:253]     Train net output #0: loss = 1.21293 (* 1 = 1.21293 loss)
I0522 02:10:16.148005  6507 sgd_solver.cpp:106] Iteration 11250, lr = 0.0035
I0522 02:10:28.258864  6507 solver.cpp:237] Iteration 12000, loss = 1.45351
I0522 02:10:28.258900  6507 solver.cpp:253]     Train net output #0: loss = 1.45351 (* 1 = 1.45351 loss)
I0522 02:10:28.258916  6507 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0522 02:10:40.383376  6507 solver.cpp:237] Iteration 12750, loss = 1.31929
I0522 02:10:40.383539  6507 solver.cpp:253]     Train net output #0: loss = 1.31929 (* 1 = 1.31929 loss)
I0522 02:10:40.383554  6507 sgd_solver.cpp:106] Iteration 12750, lr = 0.0035
I0522 02:10:52.536931  6507 solver.cpp:237] Iteration 13500, loss = 1.87867
I0522 02:10:52.536967  6507 solver.cpp:253]     Train net output #0: loss = 1.87867 (* 1 = 1.87867 loss)
I0522 02:10:52.536981  6507 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0522 02:11:04.702138  6507 solver.cpp:237] Iteration 14250, loss = 1.24267
I0522 02:11:04.702189  6507 solver.cpp:253]     Train net output #0: loss = 1.24267 (* 1 = 1.24267 loss)
I0522 02:11:04.702203  6507 sgd_solver.cpp:106] Iteration 14250, lr = 0.0035
I0522 02:11:16.860785  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_15000.caffemodel
I0522 02:11:16.911311  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_15000.solverstate
I0522 02:11:16.937711  6507 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 02:12:08.878770  6507 solver.cpp:409]     Test net output #0: accuracy = 0.851039
I0522 02:12:08.878928  6507 solver.cpp:409]     Test net output #1: loss = 0.517389 (* 1 = 0.517389 loss)
I0522 02:12:30.999804  6507 solver.cpp:237] Iteration 15000, loss = 1.395
I0522 02:12:30.999853  6507 solver.cpp:253]     Train net output #0: loss = 1.395 (* 1 = 1.395 loss)
I0522 02:12:30.999868  6507 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0522 02:12:43.072185  6507 solver.cpp:237] Iteration 15750, loss = 1.30138
I0522 02:12:43.072343  6507 solver.cpp:253]     Train net output #0: loss = 1.30138 (* 1 = 1.30138 loss)
I0522 02:12:43.072360  6507 sgd_solver.cpp:106] Iteration 15750, lr = 0.0035
I0522 02:12:55.137984  6507 solver.cpp:237] Iteration 16500, loss = 1.72548
I0522 02:12:55.138020  6507 solver.cpp:253]     Train net output #0: loss = 1.72548 (* 1 = 1.72548 loss)
I0522 02:12:55.138036  6507 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0522 02:13:07.260938  6507 solver.cpp:237] Iteration 17250, loss = 1.65753
I0522 02:13:07.260985  6507 solver.cpp:253]     Train net output #0: loss = 1.65753 (* 1 = 1.65753 loss)
I0522 02:13:07.261001  6507 sgd_solver.cpp:106] Iteration 17250, lr = 0.0035
I0522 02:13:19.390619  6507 solver.cpp:237] Iteration 18000, loss = 1.40193
I0522 02:13:19.390770  6507 solver.cpp:253]     Train net output #0: loss = 1.40193 (* 1 = 1.40193 loss)
I0522 02:13:19.390785  6507 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0522 02:13:31.523803  6507 solver.cpp:237] Iteration 18750, loss = 1.42923
I0522 02:13:31.523852  6507 solver.cpp:253]     Train net output #0: loss = 1.42923 (* 1 = 1.42923 loss)
I0522 02:13:31.523867  6507 sgd_solver.cpp:106] Iteration 18750, lr = 0.0035
I0522 02:13:43.645675  6507 solver.cpp:237] Iteration 19500, loss = 1.1421
I0522 02:13:43.645712  6507 solver.cpp:253]     Train net output #0: loss = 1.1421 (* 1 = 1.1421 loss)
I0522 02:13:43.645726  6507 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0522 02:14:17.911773  6507 solver.cpp:237] Iteration 20250, loss = 1.86111
I0522 02:14:17.911947  6507 solver.cpp:253]     Train net output #0: loss = 1.86111 (* 1 = 1.86111 loss)
I0522 02:14:17.911960  6507 sgd_solver.cpp:106] Iteration 20250, lr = 0.0035
I0522 02:14:30.023332  6507 solver.cpp:237] Iteration 21000, loss = 1.24451
I0522 02:14:30.023367  6507 solver.cpp:253]     Train net output #0: loss = 1.24451 (* 1 = 1.24451 loss)
I0522 02:14:30.023381  6507 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0522 02:14:42.098081  6507 solver.cpp:237] Iteration 21750, loss = 1.15343
I0522 02:14:42.098116  6507 solver.cpp:253]     Train net output #0: loss = 1.15343 (* 1 = 1.15343 loss)
I0522 02:14:42.098132  6507 sgd_solver.cpp:106] Iteration 21750, lr = 0.0035
I0522 02:14:54.149029  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_22500.caffemodel
I0522 02:14:54.200556  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_22500.solverstate
I0522 02:14:54.234063  6507 solver.cpp:237] Iteration 22500, loss = 1.46864
I0522 02:14:54.234113  6507 solver.cpp:253]     Train net output #0: loss = 1.46864 (* 1 = 1.46864 loss)
I0522 02:14:54.234129  6507 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0522 02:15:06.298077  6507 solver.cpp:237] Iteration 23250, loss = 1.07614
I0522 02:15:06.298113  6507 solver.cpp:253]     Train net output #0: loss = 1.07614 (* 1 = 1.07614 loss)
I0522 02:15:06.298128  6507 sgd_solver.cpp:106] Iteration 23250, lr = 0.0035
I0522 02:15:18.368762  6507 solver.cpp:237] Iteration 24000, loss = 1.15074
I0522 02:15:18.368810  6507 solver.cpp:253]     Train net output #0: loss = 1.15074 (* 1 = 1.15074 loss)
I0522 02:15:18.368824  6507 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0522 02:15:30.434576  6507 solver.cpp:237] Iteration 24750, loss = 1.27075
I0522 02:15:30.434718  6507 solver.cpp:253]     Train net output #0: loss = 1.27075 (* 1 = 1.27075 loss)
I0522 02:15:30.434733  6507 sgd_solver.cpp:106] Iteration 24750, lr = 0.0035
I0522 02:16:04.620841  6507 solver.cpp:237] Iteration 25500, loss = 1.25166
I0522 02:16:04.621013  6507 solver.cpp:253]     Train net output #0: loss = 1.25167 (* 1 = 1.25167 loss)
I0522 02:16:04.621028  6507 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0522 02:16:16.721947  6507 solver.cpp:237] Iteration 26250, loss = 1.44917
I0522 02:16:16.721983  6507 solver.cpp:253]     Train net output #0: loss = 1.44917 (* 1 = 1.44917 loss)
I0522 02:16:16.721999  6507 sgd_solver.cpp:106] Iteration 26250, lr = 0.0035
I0522 02:16:28.844760  6507 solver.cpp:237] Iteration 27000, loss = 1.00328
I0522 02:16:28.844810  6507 solver.cpp:253]     Train net output #0: loss = 1.00329 (* 1 = 1.00329 loss)
I0522 02:16:28.844825  6507 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0522 02:16:40.983335  6507 solver.cpp:237] Iteration 27750, loss = 1.23183
I0522 02:16:40.983476  6507 solver.cpp:253]     Train net output #0: loss = 1.23183 (* 1 = 1.23183 loss)
I0522 02:16:40.983491  6507 sgd_solver.cpp:106] Iteration 27750, lr = 0.0035
I0522 02:16:53.122445  6507 solver.cpp:237] Iteration 28500, loss = 1.24827
I0522 02:16:53.122494  6507 solver.cpp:253]     Train net output #0: loss = 1.24827 (* 1 = 1.24827 loss)
I0522 02:16:53.122509  6507 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0522 02:17:05.277398  6507 solver.cpp:237] Iteration 29250, loss = 1.10502
I0522 02:17:05.277434  6507 solver.cpp:253]     Train net output #0: loss = 1.10503 (* 1 = 1.10503 loss)
I0522 02:17:05.277451  6507 sgd_solver.cpp:106] Iteration 29250, lr = 0.0035
I0522 02:17:17.441687  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_30000.caffemodel
I0522 02:17:17.493532  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_30000.solverstate
I0522 02:17:17.522227  6507 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 02:18:30.337013  6507 solver.cpp:409]     Test net output #0: accuracy = 0.862234
I0522 02:18:30.337179  6507 solver.cpp:409]     Test net output #1: loss = 0.477718 (* 1 = 0.477718 loss)
I0522 02:18:52.481271  6507 solver.cpp:237] Iteration 30000, loss = 1.0018
I0522 02:18:52.481325  6507 solver.cpp:253]     Train net output #0: loss = 1.0018 (* 1 = 1.0018 loss)
I0522 02:18:52.481343  6507 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0522 02:19:04.690915  6507 solver.cpp:237] Iteration 30750, loss = 1.23053
I0522 02:19:04.691082  6507 solver.cpp:253]     Train net output #0: loss = 1.23053 (* 1 = 1.23053 loss)
I0522 02:19:04.691095  6507 sgd_solver.cpp:106] Iteration 30750, lr = 0.0035
I0522 02:19:16.904049  6507 solver.cpp:237] Iteration 31500, loss = 1.26213
I0522 02:19:16.904085  6507 solver.cpp:253]     Train net output #0: loss = 1.26213 (* 1 = 1.26213 loss)
I0522 02:19:16.904101  6507 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0522 02:19:29.067903  6507 solver.cpp:237] Iteration 32250, loss = 1.14361
I0522 02:19:29.067946  6507 solver.cpp:253]     Train net output #0: loss = 1.14361 (* 1 = 1.14361 loss)
I0522 02:19:29.067961  6507 sgd_solver.cpp:106] Iteration 32250, lr = 0.0035
I0522 02:19:41.224791  6507 solver.cpp:237] Iteration 33000, loss = 1.28844
I0522 02:19:41.224928  6507 solver.cpp:253]     Train net output #0: loss = 1.28844 (* 1 = 1.28844 loss)
I0522 02:19:41.224943  6507 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0522 02:19:53.432888  6507 solver.cpp:237] Iteration 33750, loss = 0.55353
I0522 02:19:53.432939  6507 solver.cpp:253]     Train net output #0: loss = 0.553531 (* 1 = 0.553531 loss)
I0522 02:19:53.432952  6507 sgd_solver.cpp:106] Iteration 33750, lr = 0.0035
I0522 02:20:05.647579  6507 solver.cpp:237] Iteration 34500, loss = 1.3777
I0522 02:20:05.647614  6507 solver.cpp:253]     Train net output #0: loss = 1.3777 (* 1 = 1.3777 loss)
I0522 02:20:05.647631  6507 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0522 02:20:39.995059  6507 solver.cpp:237] Iteration 35250, loss = 0.815899
I0522 02:20:39.995228  6507 solver.cpp:253]     Train net output #0: loss = 0.8159 (* 1 = 0.8159 loss)
I0522 02:20:39.995242  6507 sgd_solver.cpp:106] Iteration 35250, lr = 0.0035
I0522 02:20:52.153673  6507 solver.cpp:237] Iteration 36000, loss = 1.14808
I0522 02:20:52.153709  6507 solver.cpp:253]     Train net output #0: loss = 1.14808 (* 1 = 1.14808 loss)
I0522 02:20:52.153725  6507 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0522 02:21:04.313495  6507 solver.cpp:237] Iteration 36750, loss = 0.889619
I0522 02:21:04.313546  6507 solver.cpp:253]     Train net output #0: loss = 0.88962 (* 1 = 0.88962 loss)
I0522 02:21:04.313560  6507 sgd_solver.cpp:106] Iteration 36750, lr = 0.0035
I0522 02:21:16.457094  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_37500.caffemodel
I0522 02:21:16.508558  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_37500.solverstate
I0522 02:21:16.541931  6507 solver.cpp:237] Iteration 37500, loss = 1.17686
I0522 02:21:16.541981  6507 solver.cpp:253]     Train net output #0: loss = 1.17687 (* 1 = 1.17687 loss)
I0522 02:21:16.541997  6507 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0522 02:21:28.661782  6507 solver.cpp:237] Iteration 38250, loss = 1.23866
I0522 02:21:28.661833  6507 solver.cpp:253]     Train net output #0: loss = 1.23866 (* 1 = 1.23866 loss)
I0522 02:21:28.661846  6507 sgd_solver.cpp:106] Iteration 38250, lr = 0.0035
I0522 02:21:40.779408  6507 solver.cpp:237] Iteration 39000, loss = 1.00848
I0522 02:21:40.779443  6507 solver.cpp:253]     Train net output #0: loss = 1.00848 (* 1 = 1.00848 loss)
I0522 02:21:40.779460  6507 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0522 02:21:52.944895  6507 solver.cpp:237] Iteration 39750, loss = 1.45659
I0522 02:21:52.945065  6507 solver.cpp:253]     Train net output #0: loss = 1.45659 (* 1 = 1.45659 loss)
I0522 02:21:52.945081  6507 sgd_solver.cpp:106] Iteration 39750, lr = 0.0035
I0522 02:22:27.254990  6507 solver.cpp:237] Iteration 40500, loss = 1.12664
I0522 02:22:27.255157  6507 solver.cpp:253]     Train net output #0: loss = 1.12665 (* 1 = 1.12665 loss)
I0522 02:22:27.255173  6507 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0522 02:22:39.470154  6507 solver.cpp:237] Iteration 41250, loss = 1.33361
I0522 02:22:39.470199  6507 solver.cpp:253]     Train net output #0: loss = 1.33362 (* 1 = 1.33362 loss)
I0522 02:22:39.470214  6507 sgd_solver.cpp:106] Iteration 41250, lr = 0.0035
I0522 02:22:51.654078  6507 solver.cpp:237] Iteration 42000, loss = 1.36303
I0522 02:22:51.654114  6507 solver.cpp:253]     Train net output #0: loss = 1.36303 (* 1 = 1.36303 loss)
I0522 02:22:51.654130  6507 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0522 02:23:03.823727  6507 solver.cpp:237] Iteration 42750, loss = 1.49237
I0522 02:23:03.823885  6507 solver.cpp:253]     Train net output #0: loss = 1.49237 (* 1 = 1.49237 loss)
I0522 02:23:03.823899  6507 sgd_solver.cpp:106] Iteration 42750, lr = 0.0035
I0522 02:23:16.027241  6507 solver.cpp:237] Iteration 43500, loss = 0.911643
I0522 02:23:16.027278  6507 solver.cpp:253]     Train net output #0: loss = 0.911643 (* 1 = 0.911643 loss)
I0522 02:23:16.027294  6507 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0522 02:23:28.229089  6507 solver.cpp:237] Iteration 44250, loss = 0.982449
I0522 02:23:28.229135  6507 solver.cpp:253]     Train net output #0: loss = 0.982449 (* 1 = 0.982449 loss)
I0522 02:23:28.229152  6507 sgd_solver.cpp:106] Iteration 44250, lr = 0.0035
I0522 02:23:40.409929  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_45000.caffemodel
I0522 02:23:40.459152  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_45000.solverstate
I0522 02:23:40.485679  6507 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 02:24:32.113560  6507 solver.cpp:409]     Test net output #0: accuracy = 0.872755
I0522 02:24:32.113719  6507 solver.cpp:409]     Test net output #1: loss = 0.427074 (* 1 = 0.427074 loss)
I0522 02:24:54.232905  6507 solver.cpp:237] Iteration 45000, loss = 1.12066
I0522 02:24:54.232956  6507 solver.cpp:253]     Train net output #0: loss = 1.12066 (* 1 = 1.12066 loss)
I0522 02:24:54.232972  6507 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0522 02:25:06.415215  6507 solver.cpp:237] Iteration 45750, loss = 1.12502
I0522 02:25:06.415365  6507 solver.cpp:253]     Train net output #0: loss = 1.12502 (* 1 = 1.12502 loss)
I0522 02:25:06.415380  6507 sgd_solver.cpp:106] Iteration 45750, lr = 0.0035
I0522 02:25:18.575707  6507 solver.cpp:237] Iteration 46500, loss = 1.64054
I0522 02:25:18.575757  6507 solver.cpp:253]     Train net output #0: loss = 1.64055 (* 1 = 1.64055 loss)
I0522 02:25:18.575772  6507 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0522 02:25:30.768859  6507 solver.cpp:237] Iteration 47250, loss = 1.3297
I0522 02:25:30.768896  6507 solver.cpp:253]     Train net output #0: loss = 1.3297 (* 1 = 1.3297 loss)
I0522 02:25:30.768913  6507 sgd_solver.cpp:106] Iteration 47250, lr = 0.0035
I0522 02:25:42.994820  6507 solver.cpp:237] Iteration 48000, loss = 0.941619
I0522 02:25:42.994971  6507 solver.cpp:253]     Train net output #0: loss = 0.94162 (* 1 = 0.94162 loss)
I0522 02:25:42.994987  6507 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0522 02:25:55.208652  6507 solver.cpp:237] Iteration 48750, loss = 0.918284
I0522 02:25:55.208688  6507 solver.cpp:253]     Train net output #0: loss = 0.918284 (* 1 = 0.918284 loss)
I0522 02:25:55.208704  6507 sgd_solver.cpp:106] Iteration 48750, lr = 0.0035
I0522 02:26:07.414438  6507 solver.cpp:237] Iteration 49500, loss = 1.12921
I0522 02:26:07.414479  6507 solver.cpp:253]     Train net output #0: loss = 1.12921 (* 1 = 1.12921 loss)
I0522 02:26:07.414496  6507 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0522 02:26:41.807157  6507 solver.cpp:237] Iteration 50250, loss = 1.37611
I0522 02:26:41.807333  6507 solver.cpp:253]     Train net output #0: loss = 1.37611 (* 1 = 1.37611 loss)
I0522 02:26:41.807349  6507 sgd_solver.cpp:106] Iteration 50250, lr = 0.0035
I0522 02:26:54.011087  6507 solver.cpp:237] Iteration 51000, loss = 0.704771
I0522 02:26:54.011135  6507 solver.cpp:253]     Train net output #0: loss = 0.704772 (* 1 = 0.704772 loss)
I0522 02:26:54.011152  6507 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0522 02:27:06.234568  6507 solver.cpp:237] Iteration 51750, loss = 1.40252
I0522 02:27:06.234604  6507 solver.cpp:253]     Train net output #0: loss = 1.40252 (* 1 = 1.40252 loss)
I0522 02:27:06.234622  6507 sgd_solver.cpp:106] Iteration 51750, lr = 0.0035
I0522 02:27:18.399698  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_52500.caffemodel
I0522 02:27:18.449753  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_52500.solverstate
I0522 02:27:18.481266  6507 solver.cpp:237] Iteration 52500, loss = 1.09406
I0522 02:27:18.481309  6507 solver.cpp:253]     Train net output #0: loss = 1.09406 (* 1 = 1.09406 loss)
I0522 02:27:18.481323  6507 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0522 02:27:30.627598  6507 solver.cpp:237] Iteration 53250, loss = 1.07115
I0522 02:27:30.627635  6507 solver.cpp:253]     Train net output #0: loss = 1.07115 (* 1 = 1.07115 loss)
I0522 02:27:30.627650  6507 sgd_solver.cpp:106] Iteration 53250, lr = 0.0035
I0522 02:27:42.799312  6507 solver.cpp:237] Iteration 54000, loss = 1.3261
I0522 02:27:42.799362  6507 solver.cpp:253]     Train net output #0: loss = 1.3261 (* 1 = 1.3261 loss)
I0522 02:27:42.799376  6507 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0522 02:27:55.004263  6507 solver.cpp:237] Iteration 54750, loss = 1.07166
I0522 02:27:55.004412  6507 solver.cpp:253]     Train net output #0: loss = 1.07166 (* 1 = 1.07166 loss)
I0522 02:27:55.004428  6507 sgd_solver.cpp:106] Iteration 54750, lr = 0.0035
I0522 02:28:29.357656  6507 solver.cpp:237] Iteration 55500, loss = 0.914923
I0522 02:28:29.357848  6507 solver.cpp:253]     Train net output #0: loss = 0.914923 (* 1 = 0.914923 loss)
I0522 02:28:29.357863  6507 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0522 02:28:41.541302  6507 solver.cpp:237] Iteration 56250, loss = 1.5224
I0522 02:28:41.541339  6507 solver.cpp:253]     Train net output #0: loss = 1.5224 (* 1 = 1.5224 loss)
I0522 02:28:41.541354  6507 sgd_solver.cpp:106] Iteration 56250, lr = 0.0035
I0522 02:28:53.719378  6507 solver.cpp:237] Iteration 57000, loss = 1.45888
I0522 02:28:53.719419  6507 solver.cpp:253]     Train net output #0: loss = 1.45888 (* 1 = 1.45888 loss)
I0522 02:28:53.719439  6507 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0522 02:29:05.893405  6507 solver.cpp:237] Iteration 57750, loss = 1.04566
I0522 02:29:05.893548  6507 solver.cpp:253]     Train net output #0: loss = 1.04566 (* 1 = 1.04566 loss)
I0522 02:29:05.893563  6507 sgd_solver.cpp:106] Iteration 57750, lr = 0.0035
I0522 02:29:18.069886  6507 solver.cpp:237] Iteration 58500, loss = 1.10667
I0522 02:29:18.069931  6507 solver.cpp:253]     Train net output #0: loss = 1.10667 (* 1 = 1.10667 loss)
I0522 02:29:18.069949  6507 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0522 02:29:30.259938  6507 solver.cpp:237] Iteration 59250, loss = 1.67989
I0522 02:29:30.259974  6507 solver.cpp:253]     Train net output #0: loss = 1.67989 (* 1 = 1.67989 loss)
I0522 02:29:30.259989  6507 sgd_solver.cpp:106] Iteration 59250, lr = 0.0035
I0522 02:29:42.428262  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_60000.caffemodel
I0522 02:29:42.477283  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_60000.solverstate
I0522 02:29:42.503403  6507 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 02:30:55.356735  6507 solver.cpp:409]     Test net output #0: accuracy = 0.877034
I0522 02:30:55.356901  6507 solver.cpp:409]     Test net output #1: loss = 0.392388 (* 1 = 0.392388 loss)
I0522 02:31:17.527878  6507 solver.cpp:237] Iteration 60000, loss = 1.50286
I0522 02:31:17.527927  6507 solver.cpp:253]     Train net output #0: loss = 1.50286 (* 1 = 1.50286 loss)
I0522 02:31:17.527945  6507 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0522 02:31:29.749773  6507 solver.cpp:237] Iteration 60750, loss = 1.09776
I0522 02:31:29.749941  6507 solver.cpp:253]     Train net output #0: loss = 1.09776 (* 1 = 1.09776 loss)
I0522 02:31:29.749956  6507 sgd_solver.cpp:106] Iteration 60750, lr = 0.0035
I0522 02:31:41.966665  6507 solver.cpp:237] Iteration 61500, loss = 0.908108
I0522 02:31:41.966701  6507 solver.cpp:253]     Train net output #0: loss = 0.908109 (* 1 = 0.908109 loss)
I0522 02:31:41.966716  6507 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0522 02:31:54.151933  6507 solver.cpp:237] Iteration 62250, loss = 1.07386
I0522 02:31:54.151980  6507 solver.cpp:253]     Train net output #0: loss = 1.07386 (* 1 = 1.07386 loss)
I0522 02:31:54.151994  6507 sgd_solver.cpp:106] Iteration 62250, lr = 0.0035
I0522 02:32:06.336616  6507 solver.cpp:237] Iteration 63000, loss = 1.36585
I0522 02:32:06.336760  6507 solver.cpp:253]     Train net output #0: loss = 1.36586 (* 1 = 1.36586 loss)
I0522 02:32:06.336776  6507 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0522 02:32:18.453670  6507 solver.cpp:237] Iteration 63750, loss = 1.39488
I0522 02:32:18.453717  6507 solver.cpp:253]     Train net output #0: loss = 1.39488 (* 1 = 1.39488 loss)
I0522 02:32:18.453740  6507 sgd_solver.cpp:106] Iteration 63750, lr = 0.0035
I0522 02:32:30.555755  6507 solver.cpp:237] Iteration 64500, loss = 1.11338
I0522 02:32:30.555791  6507 solver.cpp:253]     Train net output #0: loss = 1.11338 (* 1 = 1.11338 loss)
I0522 02:32:30.555807  6507 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0522 02:33:04.808892  6507 solver.cpp:237] Iteration 65250, loss = 0.852033
I0522 02:33:04.809057  6507 solver.cpp:253]     Train net output #0: loss = 0.852035 (* 1 = 0.852035 loss)
I0522 02:33:04.809072  6507 sgd_solver.cpp:106] Iteration 65250, lr = 0.0035
I0522 02:33:17.007246  6507 solver.cpp:237] Iteration 66000, loss = 1.39866
I0522 02:33:17.007283  6507 solver.cpp:253]     Train net output #0: loss = 1.39867 (* 1 = 1.39867 loss)
I0522 02:33:17.007298  6507 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0522 02:33:29.196971  6507 solver.cpp:237] Iteration 66750, loss = 1.05485
I0522 02:33:29.197016  6507 solver.cpp:253]     Train net output #0: loss = 1.05485 (* 1 = 1.05485 loss)
I0522 02:33:29.197033  6507 sgd_solver.cpp:106] Iteration 66750, lr = 0.0035
I0522 02:33:41.350602  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_67500.caffemodel
I0522 02:33:41.401665  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_67500.solverstate
I0522 02:33:41.435554  6507 solver.cpp:237] Iteration 67500, loss = 1.52947
I0522 02:33:41.435603  6507 solver.cpp:253]     Train net output #0: loss = 1.52947 (* 1 = 1.52947 loss)
I0522 02:33:41.435623  6507 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0522 02:33:53.589567  6507 solver.cpp:237] Iteration 68250, loss = 1.06171
I0522 02:33:53.589615  6507 solver.cpp:253]     Train net output #0: loss = 1.06172 (* 1 = 1.06172 loss)
I0522 02:33:53.589632  6507 sgd_solver.cpp:106] Iteration 68250, lr = 0.0035
I0522 02:34:05.819113  6507 solver.cpp:237] Iteration 69000, loss = 3.20356
I0522 02:34:05.819149  6507 solver.cpp:253]     Train net output #0: loss = 3.20356 (* 1 = 3.20356 loss)
I0522 02:34:05.819164  6507 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0522 02:34:18.001472  6507 solver.cpp:237] Iteration 69750, loss = 1.26071
I0522 02:34:18.001639  6507 solver.cpp:253]     Train net output #0: loss = 1.26071 (* 1 = 1.26071 loss)
I0522 02:34:18.001653  6507 sgd_solver.cpp:106] Iteration 69750, lr = 0.0035
I0522 02:34:52.326670  6507 solver.cpp:237] Iteration 70500, loss = 1.23794
I0522 02:34:52.326843  6507 solver.cpp:253]     Train net output #0: loss = 1.23794 (* 1 = 1.23794 loss)
I0522 02:34:52.326858  6507 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0522 02:35:04.499100  6507 solver.cpp:237] Iteration 71250, loss = 1.03612
I0522 02:35:04.499137  6507 solver.cpp:253]     Train net output #0: loss = 1.03612 (* 1 = 1.03612 loss)
I0522 02:35:04.499153  6507 sgd_solver.cpp:106] Iteration 71250, lr = 0.0035
I0522 02:35:16.661221  6507 solver.cpp:237] Iteration 72000, loss = 1.06377
I0522 02:35:16.661272  6507 solver.cpp:253]     Train net output #0: loss = 1.06377 (* 1 = 1.06377 loss)
I0522 02:35:16.661284  6507 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0522 02:35:28.807986  6507 solver.cpp:237] Iteration 72750, loss = 1.62821
I0522 02:35:28.808133  6507 solver.cpp:253]     Train net output #0: loss = 1.62821 (* 1 = 1.62821 loss)
I0522 02:35:28.808147  6507 sgd_solver.cpp:106] Iteration 72750, lr = 0.0035
I0522 02:35:40.995864  6507 solver.cpp:237] Iteration 73500, loss = 1.0243
I0522 02:35:40.995906  6507 solver.cpp:253]     Train net output #0: loss = 1.02431 (* 1 = 1.02431 loss)
I0522 02:35:40.995920  6507 sgd_solver.cpp:106] Iteration 73500, lr = 0.0035
I0522 02:35:53.163760  6507 solver.cpp:237] Iteration 74250, loss = 1.8514
I0522 02:35:53.163796  6507 solver.cpp:253]     Train net output #0: loss = 1.8514 (* 1 = 1.8514 loss)
I0522 02:35:53.163812  6507 sgd_solver.cpp:106] Iteration 74250, lr = 0.0035
I0522 02:36:05.327771  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_75000.caffemodel
I0522 02:36:05.379233  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_75000.solverstate
I0522 02:36:05.407783  6507 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 02:36:57.297137  6507 solver.cpp:409]     Test net output #0: accuracy = 0.877807
I0522 02:36:57.297300  6507 solver.cpp:409]     Test net output #1: loss = 0.406409 (* 1 = 0.406409 loss)
I0522 02:37:18.200913  6507 solver.cpp:237] Iteration 75000, loss = 1.04586
I0522 02:37:18.200964  6507 solver.cpp:253]     Train net output #0: loss = 1.04586 (* 1 = 1.04586 loss)
I0522 02:37:18.200981  6507 sgd_solver.cpp:106] Iteration 75000, lr = 0.0035
I0522 02:37:30.364981  6507 solver.cpp:237] Iteration 75750, loss = 1.35387
I0522 02:37:30.365135  6507 solver.cpp:253]     Train net output #0: loss = 1.35387 (* 1 = 1.35387 loss)
I0522 02:37:30.365149  6507 sgd_solver.cpp:106] Iteration 75750, lr = 0.0035
I0522 02:37:42.523555  6507 solver.cpp:237] Iteration 76500, loss = 1.28001
I0522 02:37:42.523604  6507 solver.cpp:253]     Train net output #0: loss = 1.28001 (* 1 = 1.28001 loss)
I0522 02:37:42.523617  6507 sgd_solver.cpp:106] Iteration 76500, lr = 0.0035
I0522 02:37:54.660954  6507 solver.cpp:237] Iteration 77250, loss = 1.55088
I0522 02:37:54.660990  6507 solver.cpp:253]     Train net output #0: loss = 1.55088 (* 1 = 1.55088 loss)
I0522 02:37:54.661006  6507 sgd_solver.cpp:106] Iteration 77250, lr = 0.0035
I0522 02:38:06.766856  6507 solver.cpp:237] Iteration 78000, loss = 1.18904
I0522 02:38:06.767014  6507 solver.cpp:253]     Train net output #0: loss = 1.18904 (* 1 = 1.18904 loss)
I0522 02:38:06.767029  6507 sgd_solver.cpp:106] Iteration 78000, lr = 0.0035
I0522 02:38:18.857632  6507 solver.cpp:237] Iteration 78750, loss = 1.39838
I0522 02:38:18.857668  6507 solver.cpp:253]     Train net output #0: loss = 1.39838 (* 1 = 1.39838 loss)
I0522 02:38:18.857686  6507 sgd_solver.cpp:106] Iteration 78750, lr = 0.0035
I0522 02:38:30.948314  6507 solver.cpp:237] Iteration 79500, loss = 1.52357
I0522 02:38:30.948360  6507 solver.cpp:253]     Train net output #0: loss = 1.52357 (* 1 = 1.52357 loss)
I0522 02:38:30.948374  6507 sgd_solver.cpp:106] Iteration 79500, lr = 0.0035
I0522 02:39:03.955983  6507 solver.cpp:237] Iteration 80250, loss = 1.05319
I0522 02:39:03.956159  6507 solver.cpp:253]     Train net output #0: loss = 1.05319 (* 1 = 1.05319 loss)
I0522 02:39:03.956176  6507 sgd_solver.cpp:106] Iteration 80250, lr = 0.0035
I0522 02:39:16.091583  6507 solver.cpp:237] Iteration 81000, loss = 1.10881
I0522 02:39:16.091619  6507 solver.cpp:253]     Train net output #0: loss = 1.10881 (* 1 = 1.10881 loss)
I0522 02:39:16.091634  6507 sgd_solver.cpp:106] Iteration 81000, lr = 0.0035
I0522 02:39:28.211673  6507 solver.cpp:237] Iteration 81750, loss = 2.09377
I0522 02:39:28.211721  6507 solver.cpp:253]     Train net output #0: loss = 2.09377 (* 1 = 2.09377 loss)
I0522 02:39:28.211737  6507 sgd_solver.cpp:106] Iteration 81750, lr = 0.0035
I0522 02:39:40.337111  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_82500.caffemodel
I0522 02:39:40.390699  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_82500.solverstate
I0522 02:39:40.422070  6507 solver.cpp:237] Iteration 82500, loss = 0.755225
I0522 02:39:40.422117  6507 solver.cpp:253]     Train net output #0: loss = 0.755227 (* 1 = 0.755227 loss)
I0522 02:39:40.422134  6507 sgd_solver.cpp:106] Iteration 82500, lr = 0.0035
I0522 02:39:52.564195  6507 solver.cpp:237] Iteration 83250, loss = 1.19993
I0522 02:39:52.564244  6507 solver.cpp:253]     Train net output #0: loss = 1.19993 (* 1 = 1.19993 loss)
I0522 02:39:52.564257  6507 sgd_solver.cpp:106] Iteration 83250, lr = 0.0035
I0522 02:40:04.703261  6507 solver.cpp:237] Iteration 84000, loss = 0.807376
I0522 02:40:04.703299  6507 solver.cpp:253]     Train net output #0: loss = 0.807378 (* 1 = 0.807378 loss)
I0522 02:40:04.703313  6507 sgd_solver.cpp:106] Iteration 84000, lr = 0.0035
I0522 02:40:16.868475  6507 solver.cpp:237] Iteration 84750, loss = 1.05128
I0522 02:40:16.868638  6507 solver.cpp:253]     Train net output #0: loss = 1.05129 (* 1 = 1.05129 loss)
I0522 02:40:16.868654  6507 sgd_solver.cpp:106] Iteration 84750, lr = 0.0035
I0522 02:40:49.821538  6507 solver.cpp:237] Iteration 85500, loss = 0.794065
I0522 02:40:49.821710  6507 solver.cpp:253]     Train net output #0: loss = 0.794067 (* 1 = 0.794067 loss)
I0522 02:40:49.821734  6507 sgd_solver.cpp:106] Iteration 85500, lr = 0.0035
I0522 02:41:02.054756  6507 solver.cpp:237] Iteration 86250, loss = 1.1543
I0522 02:41:02.054801  6507 solver.cpp:253]     Train net output #0: loss = 1.1543 (* 1 = 1.1543 loss)
I0522 02:41:02.054816  6507 sgd_solver.cpp:106] Iteration 86250, lr = 0.0035
I0522 02:41:14.263643  6507 solver.cpp:237] Iteration 87000, loss = 1.22621
I0522 02:41:14.263679  6507 solver.cpp:253]     Train net output #0: loss = 1.22622 (* 1 = 1.22622 loss)
I0522 02:41:14.263695  6507 sgd_solver.cpp:106] Iteration 87000, lr = 0.0035
I0522 02:41:26.470688  6507 solver.cpp:237] Iteration 87750, loss = 1.4333
I0522 02:41:26.470844  6507 solver.cpp:253]     Train net output #0: loss = 1.4333 (* 1 = 1.4333 loss)
I0522 02:41:26.470859  6507 sgd_solver.cpp:106] Iteration 87750, lr = 0.0035
I0522 02:41:38.689524  6507 solver.cpp:237] Iteration 88500, loss = 1.67215
I0522 02:41:38.689560  6507 solver.cpp:253]     Train net output #0: loss = 1.67215 (* 1 = 1.67215 loss)
I0522 02:41:38.689575  6507 sgd_solver.cpp:106] Iteration 88500, lr = 0.0035
I0522 02:41:50.910257  6507 solver.cpp:237] Iteration 89250, loss = 1.34835
I0522 02:41:50.910305  6507 solver.cpp:253]     Train net output #0: loss = 1.34835 (* 1 = 1.34835 loss)
I0522 02:41:50.910320  6507 sgd_solver.cpp:106] Iteration 89250, lr = 0.0035
I0522 02:42:03.124533  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_90000.caffemodel
I0522 02:42:03.173705  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_90000.solverstate
I0522 02:42:03.200104  6507 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 02:43:16.043468  6507 solver.cpp:409]     Test net output #0: accuracy = 0.884361
I0522 02:43:16.043635  6507 solver.cpp:409]     Test net output #1: loss = 0.364765 (* 1 = 0.364765 loss)
I0522 02:43:36.908411  6507 solver.cpp:237] Iteration 90000, loss = 0.751425
I0522 02:43:36.908463  6507 solver.cpp:253]     Train net output #0: loss = 0.751428 (* 1 = 0.751428 loss)
I0522 02:43:36.908479  6507 sgd_solver.cpp:106] Iteration 90000, lr = 0.0035
I0522 02:43:49.044831  6507 solver.cpp:237] Iteration 90750, loss = 1.0822
I0522 02:43:49.044987  6507 solver.cpp:253]     Train net output #0: loss = 1.0822 (* 1 = 1.0822 loss)
I0522 02:43:49.045001  6507 sgd_solver.cpp:106] Iteration 90750, lr = 0.0035
I0522 02:44:01.181040  6507 solver.cpp:237] Iteration 91500, loss = 0.680954
I0522 02:44:01.181092  6507 solver.cpp:253]     Train net output #0: loss = 0.680957 (* 1 = 0.680957 loss)
I0522 02:44:01.181104  6507 sgd_solver.cpp:106] Iteration 91500, lr = 0.0035
I0522 02:44:13.261570  6507 solver.cpp:237] Iteration 92250, loss = 1.25746
I0522 02:44:13.261606  6507 solver.cpp:253]     Train net output #0: loss = 1.25746 (* 1 = 1.25746 loss)
I0522 02:44:13.261621  6507 sgd_solver.cpp:106] Iteration 92250, lr = 0.0035
I0522 02:44:25.377069  6507 solver.cpp:237] Iteration 93000, loss = 1.01379
I0522 02:44:25.377228  6507 solver.cpp:253]     Train net output #0: loss = 1.01379 (* 1 = 1.01379 loss)
I0522 02:44:25.377241  6507 sgd_solver.cpp:106] Iteration 93000, lr = 0.0035
I0522 02:44:37.467526  6507 solver.cpp:237] Iteration 93750, loss = 1.03656
I0522 02:44:37.467562  6507 solver.cpp:253]     Train net output #0: loss = 1.03657 (* 1 = 1.03657 loss)
I0522 02:44:37.467577  6507 sgd_solver.cpp:106] Iteration 93750, lr = 0.0035
I0522 02:44:49.576282  6507 solver.cpp:237] Iteration 94500, loss = 1.02948
I0522 02:44:49.576333  6507 solver.cpp:253]     Train net output #0: loss = 1.02948 (* 1 = 1.02948 loss)
I0522 02:44:49.576346  6507 sgd_solver.cpp:106] Iteration 94500, lr = 0.0035
I0522 02:45:22.560401  6507 solver.cpp:237] Iteration 95250, loss = 1.71336
I0522 02:45:22.560569  6507 solver.cpp:253]     Train net output #0: loss = 1.71336 (* 1 = 1.71336 loss)
I0522 02:45:22.560583  6507 sgd_solver.cpp:106] Iteration 95250, lr = 0.0035
I0522 02:45:34.697193  6507 solver.cpp:237] Iteration 96000, loss = 1.11253
I0522 02:45:34.697243  6507 solver.cpp:253]     Train net output #0: loss = 1.11253 (* 1 = 1.11253 loss)
I0522 02:45:34.697257  6507 sgd_solver.cpp:106] Iteration 96000, lr = 0.0035
I0522 02:45:46.812120  6507 solver.cpp:237] Iteration 96750, loss = 1.07873
I0522 02:45:46.812156  6507 solver.cpp:253]     Train net output #0: loss = 1.07873 (* 1 = 1.07873 loss)
I0522 02:45:46.812170  6507 sgd_solver.cpp:106] Iteration 96750, lr = 0.0035
I0522 02:45:58.890821  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_97500.caffemodel
I0522 02:45:58.939620  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_97500.solverstate
I0522 02:45:58.973680  6507 solver.cpp:237] Iteration 97500, loss = 1.04537
I0522 02:45:58.973724  6507 solver.cpp:253]     Train net output #0: loss = 1.04537 (* 1 = 1.04537 loss)
I0522 02:45:58.973745  6507 sgd_solver.cpp:106] Iteration 97500, lr = 0.0035
I0522 02:46:11.051355  6507 solver.cpp:237] Iteration 98250, loss = 1.11425
I0522 02:46:11.051393  6507 solver.cpp:253]     Train net output #0: loss = 1.11425 (* 1 = 1.11425 loss)
I0522 02:46:11.051406  6507 sgd_solver.cpp:106] Iteration 98250, lr = 0.0035
I0522 02:46:23.140983  6507 solver.cpp:237] Iteration 99000, loss = 0.849325
I0522 02:46:23.141033  6507 solver.cpp:253]     Train net output #0: loss = 0.849327 (* 1 = 0.849327 loss)
I0522 02:46:23.141047  6507 sgd_solver.cpp:106] Iteration 99000, lr = 0.0035
I0522 02:46:35.294667  6507 solver.cpp:237] Iteration 99750, loss = 1.00498
I0522 02:46:35.294831  6507 solver.cpp:253]     Train net output #0: loss = 1.00498 (* 1 = 1.00498 loss)
I0522 02:46:35.294844  6507 sgd_solver.cpp:106] Iteration 99750, lr = 0.0035
I0522 02:47:08.338440  6507 solver.cpp:237] Iteration 100500, loss = 1.19007
I0522 02:47:08.338614  6507 solver.cpp:253]     Train net output #0: loss = 1.19007 (* 1 = 1.19007 loss)
I0522 02:47:08.338627  6507 sgd_solver.cpp:106] Iteration 100500, lr = 0.0035
I0522 02:47:20.505826  6507 solver.cpp:237] Iteration 101250, loss = 1.62117
I0522 02:47:20.505873  6507 solver.cpp:253]     Train net output #0: loss = 1.62117 (* 1 = 1.62117 loss)
I0522 02:47:20.505887  6507 sgd_solver.cpp:106] Iteration 101250, lr = 0.0035
I0522 02:47:32.666328  6507 solver.cpp:237] Iteration 102000, loss = 1.18356
I0522 02:47:32.666364  6507 solver.cpp:253]     Train net output #0: loss = 1.18356 (* 1 = 1.18356 loss)
I0522 02:47:32.666378  6507 sgd_solver.cpp:106] Iteration 102000, lr = 0.0035
I0522 02:47:44.778949  6507 solver.cpp:237] Iteration 102750, loss = 0.990841
I0522 02:47:44.779120  6507 solver.cpp:253]     Train net output #0: loss = 0.990843 (* 1 = 0.990843 loss)
I0522 02:47:44.779137  6507 sgd_solver.cpp:106] Iteration 102750, lr = 0.0035
I0522 02:47:56.917495  6507 solver.cpp:237] Iteration 103500, loss = 1.11125
I0522 02:47:56.917531  6507 solver.cpp:253]     Train net output #0: loss = 1.11125 (* 1 = 1.11125 loss)
I0522 02:47:56.917546  6507 sgd_solver.cpp:106] Iteration 103500, lr = 0.0035
I0522 02:48:09.018265  6507 solver.cpp:237] Iteration 104250, loss = 1.50887
I0522 02:48:09.018314  6507 solver.cpp:253]     Train net output #0: loss = 1.50887 (* 1 = 1.50887 loss)
I0522 02:48:09.018328  6507 sgd_solver.cpp:106] Iteration 104250, lr = 0.0035
I0522 02:48:21.101024  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_105000.caffemodel
I0522 02:48:21.153091  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_105000.solverstate
I0522 02:48:21.179877  6507 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 02:49:12.696990  6507 solver.cpp:409]     Test net output #0: accuracy = 0.885216
I0522 02:49:12.697157  6507 solver.cpp:409]     Test net output #1: loss = 0.371023 (* 1 = 0.371023 loss)
I0522 02:49:33.603168  6507 solver.cpp:237] Iteration 105000, loss = 1.06701
I0522 02:49:33.603222  6507 solver.cpp:253]     Train net output #0: loss = 1.06701 (* 1 = 1.06701 loss)
I0522 02:49:33.603237  6507 sgd_solver.cpp:106] Iteration 105000, lr = 0.0035
I0522 02:49:45.817679  6507 solver.cpp:237] Iteration 105750, loss = 0.963377
I0522 02:49:45.817854  6507 solver.cpp:253]     Train net output #0: loss = 0.963378 (* 1 = 0.963378 loss)
I0522 02:49:45.817873  6507 sgd_solver.cpp:106] Iteration 105750, lr = 0.0035
I0522 02:49:58.005631  6507 solver.cpp:237] Iteration 106500, loss = 1.2969
I0522 02:49:58.005667  6507 solver.cpp:253]     Train net output #0: loss = 1.2969 (* 1 = 1.2969 loss)
I0522 02:49:58.005681  6507 sgd_solver.cpp:106] Iteration 106500, lr = 0.0035
I0522 02:50:10.173524  6507 solver.cpp:237] Iteration 107250, loss = 0.967863
I0522 02:50:10.173571  6507 solver.cpp:253]     Train net output #0: loss = 0.967865 (* 1 = 0.967865 loss)
I0522 02:50:10.173585  6507 sgd_solver.cpp:106] Iteration 107250, lr = 0.0035
I0522 02:50:22.355747  6507 solver.cpp:237] Iteration 108000, loss = 1.53048
I0522 02:50:22.355916  6507 solver.cpp:253]     Train net output #0: loss = 1.53048 (* 1 = 1.53048 loss)
I0522 02:50:22.355931  6507 sgd_solver.cpp:106] Iteration 108000, lr = 0.0035
I0522 02:50:34.547116  6507 solver.cpp:237] Iteration 108750, loss = 0.857674
I0522 02:50:34.547163  6507 solver.cpp:253]     Train net output #0: loss = 0.857676 (* 1 = 0.857676 loss)
I0522 02:50:34.547178  6507 sgd_solver.cpp:106] Iteration 108750, lr = 0.0035
I0522 02:50:46.729953  6507 solver.cpp:237] Iteration 109500, loss = 1.4529
I0522 02:50:46.729987  6507 solver.cpp:253]     Train net output #0: loss = 1.45291 (* 1 = 1.45291 loss)
I0522 02:50:46.730001  6507 sgd_solver.cpp:106] Iteration 109500, lr = 0.0035
I0522 02:51:19.797062  6507 solver.cpp:237] Iteration 110250, loss = 0.945875
I0522 02:51:19.797241  6507 solver.cpp:253]     Train net output #0: loss = 0.945876 (* 1 = 0.945876 loss)
I0522 02:51:19.797258  6507 sgd_solver.cpp:106] Iteration 110250, lr = 0.0035
I0522 02:51:31.966717  6507 solver.cpp:237] Iteration 111000, loss = 1.09673
I0522 02:51:31.966758  6507 solver.cpp:253]     Train net output #0: loss = 1.09673 (* 1 = 1.09673 loss)
I0522 02:51:31.966773  6507 sgd_solver.cpp:106] Iteration 111000, lr = 0.0035
I0522 02:51:44.150324  6507 solver.cpp:237] Iteration 111750, loss = 1.21367
I0522 02:51:44.150360  6507 solver.cpp:253]     Train net output #0: loss = 1.21367 (* 1 = 1.21367 loss)
I0522 02:51:44.150374  6507 sgd_solver.cpp:106] Iteration 111750, lr = 0.0035
I0522 02:51:56.325757  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_112500.caffemodel
I0522 02:51:56.377178  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_112500.solverstate
I0522 02:51:56.409101  6507 solver.cpp:237] Iteration 112500, loss = 1.35784
I0522 02:51:56.409150  6507 solver.cpp:253]     Train net output #0: loss = 1.35784 (* 1 = 1.35784 loss)
I0522 02:51:56.409167  6507 sgd_solver.cpp:106] Iteration 112500, lr = 0.0035
I0522 02:52:08.593802  6507 solver.cpp:237] Iteration 113250, loss = 1.4812
I0522 02:52:08.593837  6507 solver.cpp:253]     Train net output #0: loss = 1.4812 (* 1 = 1.4812 loss)
I0522 02:52:08.593852  6507 sgd_solver.cpp:106] Iteration 113250, lr = 0.0035
I0522 02:52:20.768975  6507 solver.cpp:237] Iteration 114000, loss = 1.00287
I0522 02:52:20.769026  6507 solver.cpp:253]     Train net output #0: loss = 1.00288 (* 1 = 1.00288 loss)
I0522 02:52:20.769039  6507 sgd_solver.cpp:106] Iteration 114000, lr = 0.0035
I0522 02:52:32.963434  6507 solver.cpp:237] Iteration 114750, loss = 0.414936
I0522 02:52:32.963592  6507 solver.cpp:253]     Train net output #0: loss = 0.414937 (* 1 = 0.414937 loss)
I0522 02:52:32.963605  6507 sgd_solver.cpp:106] Iteration 114750, lr = 0.0035
I0522 02:53:06.057597  6507 solver.cpp:237] Iteration 115500, loss = 1.14236
I0522 02:53:06.057776  6507 solver.cpp:253]     Train net output #0: loss = 1.14236 (* 1 = 1.14236 loss)
I0522 02:53:06.057795  6507 sgd_solver.cpp:106] Iteration 115500, lr = 0.0035
I0522 02:53:18.254319  6507 solver.cpp:237] Iteration 116250, loss = 0.903396
I0522 02:53:18.254356  6507 solver.cpp:253]     Train net output #0: loss = 0.903398 (* 1 = 0.903398 loss)
I0522 02:53:18.254369  6507 sgd_solver.cpp:106] Iteration 116250, lr = 0.0035
I0522 02:53:30.453300  6507 solver.cpp:237] Iteration 117000, loss = 1.34588
I0522 02:53:30.453346  6507 solver.cpp:253]     Train net output #0: loss = 1.34588 (* 1 = 1.34588 loss)
I0522 02:53:30.453361  6507 sgd_solver.cpp:106] Iteration 117000, lr = 0.0035
I0522 02:53:42.673110  6507 solver.cpp:237] Iteration 117750, loss = 1.39938
I0522 02:53:42.673260  6507 solver.cpp:253]     Train net output #0: loss = 1.39938 (* 1 = 1.39938 loss)
I0522 02:53:42.673274  6507 sgd_solver.cpp:106] Iteration 117750, lr = 0.0035
I0522 02:53:54.862386  6507 solver.cpp:237] Iteration 118500, loss = 1.07418
I0522 02:53:54.862434  6507 solver.cpp:253]     Train net output #0: loss = 1.07419 (* 1 = 1.07419 loss)
I0522 02:53:54.862448  6507 sgd_solver.cpp:106] Iteration 118500, lr = 0.0035
I0522 02:54:07.045404  6507 solver.cpp:237] Iteration 119250, loss = 0.992595
I0522 02:54:07.045441  6507 solver.cpp:253]     Train net output #0: loss = 0.992596 (* 1 = 0.992596 loss)
I0522 02:54:07.045455  6507 sgd_solver.cpp:106] Iteration 119250, lr = 0.0035
I0522 02:54:19.204314  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_120000.caffemodel
I0522 02:54:19.253805  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_120000.solverstate
I0522 02:54:19.279024  6507 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 02:55:32.015545  6507 solver.cpp:409]     Test net output #0: accuracy = 0.888204
I0522 02:55:32.015717  6507 solver.cpp:409]     Test net output #1: loss = 0.361212 (* 1 = 0.361212 loss)
I0522 02:55:52.887054  6507 solver.cpp:237] Iteration 120000, loss = 1.35004
I0522 02:55:52.887106  6507 solver.cpp:253]     Train net output #0: loss = 1.35004 (* 1 = 1.35004 loss)
I0522 02:55:52.887121  6507 sgd_solver.cpp:106] Iteration 120000, lr = 0.0035
I0522 02:56:05.014917  6507 solver.cpp:237] Iteration 120750, loss = 1.46505
I0522 02:56:05.015086  6507 solver.cpp:253]     Train net output #0: loss = 1.46505 (* 1 = 1.46505 loss)
I0522 02:56:05.015100  6507 sgd_solver.cpp:106] Iteration 120750, lr = 0.0035
I0522 02:56:17.167387  6507 solver.cpp:237] Iteration 121500, loss = 1.22343
I0522 02:56:17.167423  6507 solver.cpp:253]     Train net output #0: loss = 1.22343 (* 1 = 1.22343 loss)
I0522 02:56:17.167438  6507 sgd_solver.cpp:106] Iteration 121500, lr = 0.0035
I0522 02:56:29.328351  6507 solver.cpp:237] Iteration 122250, loss = 1.54162
I0522 02:56:29.328395  6507 solver.cpp:253]     Train net output #0: loss = 1.54163 (* 1 = 1.54163 loss)
I0522 02:56:29.328409  6507 sgd_solver.cpp:106] Iteration 122250, lr = 0.0035
I0522 02:56:41.482761  6507 solver.cpp:237] Iteration 123000, loss = 1.15333
I0522 02:56:41.482911  6507 solver.cpp:253]     Train net output #0: loss = 1.15333 (* 1 = 1.15333 loss)
I0522 02:56:41.482925  6507 sgd_solver.cpp:106] Iteration 123000, lr = 0.0035
I0522 02:56:53.639221  6507 solver.cpp:237] Iteration 123750, loss = 1.1083
I0522 02:56:53.639268  6507 solver.cpp:253]     Train net output #0: loss = 1.1083 (* 1 = 1.1083 loss)
I0522 02:56:53.639282  6507 sgd_solver.cpp:106] Iteration 123750, lr = 0.0035
I0522 02:57:05.807328  6507 solver.cpp:237] Iteration 124500, loss = 1.02174
I0522 02:57:05.807364  6507 solver.cpp:253]     Train net output #0: loss = 1.02174 (* 1 = 1.02174 loss)
I0522 02:57:05.807379  6507 sgd_solver.cpp:106] Iteration 124500, lr = 0.0035
I0522 02:57:38.814857  6507 solver.cpp:237] Iteration 125250, loss = 1.48171
I0522 02:57:38.815038  6507 solver.cpp:253]     Train net output #0: loss = 1.48171 (* 1 = 1.48171 loss)
I0522 02:57:38.815053  6507 sgd_solver.cpp:106] Iteration 125250, lr = 0.0035
I0522 02:57:50.959590  6507 solver.cpp:237] Iteration 126000, loss = 1.01342
I0522 02:57:50.959626  6507 solver.cpp:253]     Train net output #0: loss = 1.01342 (* 1 = 1.01342 loss)
I0522 02:57:50.959640  6507 sgd_solver.cpp:106] Iteration 126000, lr = 0.0035
I0522 02:58:03.116549  6507 solver.cpp:237] Iteration 126750, loss = 1.06367
I0522 02:58:03.116596  6507 solver.cpp:253]     Train net output #0: loss = 1.06367 (* 1 = 1.06367 loss)
I0522 02:58:03.116611  6507 sgd_solver.cpp:106] Iteration 126750, lr = 0.0035
I0522 02:58:15.242677  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_127500.caffemodel
I0522 02:58:15.296422  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_127500.solverstate
I0522 02:58:15.329092  6507 solver.cpp:237] Iteration 127500, loss = 1.92622
I0522 02:58:15.329135  6507 solver.cpp:253]     Train net output #0: loss = 1.92622 (* 1 = 1.92622 loss)
I0522 02:58:15.329154  6507 sgd_solver.cpp:106] Iteration 127500, lr = 0.0035
I0522 02:58:27.478377  6507 solver.cpp:237] Iteration 128250, loss = 0.867966
I0522 02:58:27.478426  6507 solver.cpp:253]     Train net output #0: loss = 0.867967 (* 1 = 0.867967 loss)
I0522 02:58:27.478442  6507 sgd_solver.cpp:106] Iteration 128250, lr = 0.0035
I0522 02:58:39.619319  6507 solver.cpp:237] Iteration 129000, loss = 1.43477
I0522 02:58:39.619356  6507 solver.cpp:253]     Train net output #0: loss = 1.43477 (* 1 = 1.43477 loss)
I0522 02:58:39.619370  6507 sgd_solver.cpp:106] Iteration 129000, lr = 0.0035
I0522 02:58:51.758843  6507 solver.cpp:237] Iteration 129750, loss = 1.17573
I0522 02:58:51.759003  6507 solver.cpp:253]     Train net output #0: loss = 1.17573 (* 1 = 1.17573 loss)
I0522 02:58:51.759016  6507 sgd_solver.cpp:106] Iteration 129750, lr = 0.0035
I0522 02:59:24.789921  6507 solver.cpp:237] Iteration 130500, loss = 1.31983
I0522 02:59:24.790096  6507 solver.cpp:253]     Train net output #0: loss = 1.31984 (* 1 = 1.31984 loss)
I0522 02:59:24.790109  6507 sgd_solver.cpp:106] Iteration 130500, lr = 0.0035
I0522 02:59:36.939798  6507 solver.cpp:237] Iteration 131250, loss = 1.65169
I0522 02:59:36.939833  6507 solver.cpp:253]     Train net output #0: loss = 1.65169 (* 1 = 1.65169 loss)
I0522 02:59:36.939848  6507 sgd_solver.cpp:106] Iteration 131250, lr = 0.0035
I0522 02:59:49.061055  6507 solver.cpp:237] Iteration 132000, loss = 1.43923
I0522 02:59:49.061105  6507 solver.cpp:253]     Train net output #0: loss = 1.43923 (* 1 = 1.43923 loss)
I0522 02:59:49.061120  6507 sgd_solver.cpp:106] Iteration 132000, lr = 0.0035
I0522 03:00:01.222349  6507 solver.cpp:237] Iteration 132750, loss = 1.03021
I0522 03:00:01.222513  6507 solver.cpp:253]     Train net output #0: loss = 1.03021 (* 1 = 1.03021 loss)
I0522 03:00:01.222527  6507 sgd_solver.cpp:106] Iteration 132750, lr = 0.0035
I0522 03:00:13.349167  6507 solver.cpp:237] Iteration 133500, loss = 0.784228
I0522 03:00:13.349220  6507 solver.cpp:253]     Train net output #0: loss = 0.784229 (* 1 = 0.784229 loss)
I0522 03:00:13.349233  6507 sgd_solver.cpp:106] Iteration 133500, lr = 0.0035
I0522 03:00:25.462909  6507 solver.cpp:237] Iteration 134250, loss = 1.59485
I0522 03:00:25.462944  6507 solver.cpp:253]     Train net output #0: loss = 1.59485 (* 1 = 1.59485 loss)
I0522 03:00:25.462960  6507 sgd_solver.cpp:106] Iteration 134250, lr = 0.0035
I0522 03:00:37.580593  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_135000.caffemodel
I0522 03:00:37.629724  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_135000.solverstate
I0522 03:00:37.655028  6507 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 03:01:29.571873  6507 solver.cpp:409]     Test net output #0: accuracy = 0.892089
I0522 03:01:29.572043  6507 solver.cpp:409]     Test net output #1: loss = 0.35116 (* 1 = 0.35116 loss)
I0522 03:01:50.431818  6507 solver.cpp:237] Iteration 135000, loss = 1.44585
I0522 03:01:50.431872  6507 solver.cpp:253]     Train net output #0: loss = 1.44585 (* 1 = 1.44585 loss)
I0522 03:01:50.431888  6507 sgd_solver.cpp:106] Iteration 135000, lr = 0.0035
I0522 03:02:02.571207  6507 solver.cpp:237] Iteration 135750, loss = 1.31093
I0522 03:02:02.571365  6507 solver.cpp:253]     Train net output #0: loss = 1.31093 (* 1 = 1.31093 loss)
I0522 03:02:02.571379  6507 sgd_solver.cpp:106] Iteration 135750, lr = 0.0035
I0522 03:02:14.765799  6507 solver.cpp:237] Iteration 136500, loss = 0.917987
I0522 03:02:14.765846  6507 solver.cpp:253]     Train net output #0: loss = 0.917988 (* 1 = 0.917988 loss)
I0522 03:02:14.765859  6507 sgd_solver.cpp:106] Iteration 136500, lr = 0.0035
I0522 03:02:26.946390  6507 solver.cpp:237] Iteration 137250, loss = 1.04406
I0522 03:02:26.946425  6507 solver.cpp:253]     Train net output #0: loss = 1.04406 (* 1 = 1.04406 loss)
I0522 03:02:26.946440  6507 sgd_solver.cpp:106] Iteration 137250, lr = 0.0035
I0522 03:02:39.077921  6507 solver.cpp:237] Iteration 138000, loss = 1.04436
I0522 03:02:39.078099  6507 solver.cpp:253]     Train net output #0: loss = 1.04436 (* 1 = 1.04436 loss)
I0522 03:02:39.078112  6507 sgd_solver.cpp:106] Iteration 138000, lr = 0.0035
I0522 03:02:51.324125  6507 solver.cpp:237] Iteration 138750, loss = 1.19499
I0522 03:02:51.324161  6507 solver.cpp:253]     Train net output #0: loss = 1.19499 (* 1 = 1.19499 loss)
I0522 03:02:51.324174  6507 sgd_solver.cpp:106] Iteration 138750, lr = 0.0035
I0522 03:03:03.557371  6507 solver.cpp:237] Iteration 139500, loss = 1.19117
I0522 03:03:03.557416  6507 solver.cpp:253]     Train net output #0: loss = 1.19117 (* 1 = 1.19117 loss)
I0522 03:03:03.557430  6507 sgd_solver.cpp:106] Iteration 139500, lr = 0.0035
I0522 03:03:36.598757  6507 solver.cpp:237] Iteration 140250, loss = 0.814466
I0522 03:03:36.598934  6507 solver.cpp:253]     Train net output #0: loss = 0.814467 (* 1 = 0.814467 loss)
I0522 03:03:36.598950  6507 sgd_solver.cpp:106] Iteration 140250, lr = 0.0035
I0522 03:03:48.776397  6507 solver.cpp:237] Iteration 141000, loss = 0.997208
I0522 03:03:48.776434  6507 solver.cpp:253]     Train net output #0: loss = 0.99721 (* 1 = 0.99721 loss)
I0522 03:03:48.776448  6507 sgd_solver.cpp:106] Iteration 141000, lr = 0.0035
I0522 03:04:00.929548  6507 solver.cpp:237] Iteration 141750, loss = 0.927066
I0522 03:04:00.929600  6507 solver.cpp:253]     Train net output #0: loss = 0.927067 (* 1 = 0.927067 loss)
I0522 03:04:00.929615  6507 sgd_solver.cpp:106] Iteration 141750, lr = 0.0035
I0522 03:04:13.070900  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_142500.caffemodel
I0522 03:04:13.123800  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_142500.solverstate
I0522 03:04:13.156441  6507 solver.cpp:237] Iteration 142500, loss = 1.40078
I0522 03:04:13.156491  6507 solver.cpp:253]     Train net output #0: loss = 1.40078 (* 1 = 1.40078 loss)
I0522 03:04:13.156505  6507 sgd_solver.cpp:106] Iteration 142500, lr = 0.0035
I0522 03:04:25.361098  6507 solver.cpp:237] Iteration 143250, loss = 1.09523
I0522 03:04:25.361145  6507 solver.cpp:253]     Train net output #0: loss = 1.09523 (* 1 = 1.09523 loss)
I0522 03:04:25.361158  6507 sgd_solver.cpp:106] Iteration 143250, lr = 0.0035
I0522 03:04:37.570442  6507 solver.cpp:237] Iteration 144000, loss = 1.42019
I0522 03:04:37.570478  6507 solver.cpp:253]     Train net output #0: loss = 1.42019 (* 1 = 1.42019 loss)
I0522 03:04:37.570492  6507 sgd_solver.cpp:106] Iteration 144000, lr = 0.0035
I0522 03:04:49.797456  6507 solver.cpp:237] Iteration 144750, loss = 1.36271
I0522 03:04:49.797629  6507 solver.cpp:253]     Train net output #0: loss = 1.36272 (* 1 = 1.36272 loss)
I0522 03:04:49.797646  6507 sgd_solver.cpp:106] Iteration 144750, lr = 0.0035
I0522 03:05:22.888085  6507 solver.cpp:237] Iteration 145500, loss = 0.834265
I0522 03:05:22.888262  6507 solver.cpp:253]     Train net output #0: loss = 0.834266 (* 1 = 0.834266 loss)
I0522 03:05:22.888275  6507 sgd_solver.cpp:106] Iteration 145500, lr = 0.0035
I0522 03:05:35.090299  6507 solver.cpp:237] Iteration 146250, loss = 1.32892
I0522 03:05:35.090345  6507 solver.cpp:253]     Train net output #0: loss = 1.32892 (* 1 = 1.32892 loss)
I0522 03:05:35.090359  6507 sgd_solver.cpp:106] Iteration 146250, lr = 0.0035
I0522 03:05:47.289516  6507 solver.cpp:237] Iteration 147000, loss = 1.25939
I0522 03:05:47.289552  6507 solver.cpp:253]     Train net output #0: loss = 1.25939 (* 1 = 1.25939 loss)
I0522 03:05:47.289566  6507 sgd_solver.cpp:106] Iteration 147000, lr = 0.0035
I0522 03:05:59.486491  6507 solver.cpp:237] Iteration 147750, loss = 0.952098
I0522 03:05:59.486682  6507 solver.cpp:253]     Train net output #0: loss = 0.9521 (* 1 = 0.9521 loss)
I0522 03:05:59.486698  6507 sgd_solver.cpp:106] Iteration 147750, lr = 0.0035
I0522 03:06:11.555786  6507 solver.cpp:237] Iteration 148500, loss = 0.997694
I0522 03:06:11.555824  6507 solver.cpp:253]     Train net output #0: loss = 0.997695 (* 1 = 0.997695 loss)
I0522 03:06:11.555836  6507 sgd_solver.cpp:106] Iteration 148500, lr = 0.0035
I0522 03:06:23.645462  6507 solver.cpp:237] Iteration 149250, loss = 1.05231
I0522 03:06:23.645503  6507 solver.cpp:253]     Train net output #0: loss = 1.05231 (* 1 = 1.05231 loss)
I0522 03:06:23.645520  6507 sgd_solver.cpp:106] Iteration 149250, lr = 0.0035
I0522 03:06:35.721678  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_150000.caffemodel
I0522 03:06:35.772609  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_150000.solverstate
I0522 03:06:35.800151  6507 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 03:07:48.571578  6507 solver.cpp:409]     Test net output #0: accuracy = 0.890804
I0522 03:07:48.571751  6507 solver.cpp:409]     Test net output #1: loss = 0.348738 (* 1 = 0.348738 loss)
I0522 03:08:09.411816  6507 solver.cpp:237] Iteration 150000, loss = 1.2982
I0522 03:08:09.411867  6507 solver.cpp:253]     Train net output #0: loss = 1.2982 (* 1 = 1.2982 loss)
I0522 03:08:09.411883  6507 sgd_solver.cpp:106] Iteration 150000, lr = 0.0035
I0522 03:08:21.562650  6507 solver.cpp:237] Iteration 150750, loss = 1.5435
I0522 03:08:21.562810  6507 solver.cpp:253]     Train net output #0: loss = 1.5435 (* 1 = 1.5435 loss)
I0522 03:08:21.562824  6507 sgd_solver.cpp:106] Iteration 150750, lr = 0.0035
I0522 03:08:33.678180  6507 solver.cpp:237] Iteration 151500, loss = 1.18717
I0522 03:08:33.678227  6507 solver.cpp:253]     Train net output #0: loss = 1.18718 (* 1 = 1.18718 loss)
I0522 03:08:33.678241  6507 sgd_solver.cpp:106] Iteration 151500, lr = 0.0035
I0522 03:08:45.858389  6507 solver.cpp:237] Iteration 152250, loss = 0.961517
I0522 03:08:45.858427  6507 solver.cpp:253]     Train net output #0: loss = 0.961518 (* 1 = 0.961518 loss)
I0522 03:08:45.858440  6507 sgd_solver.cpp:106] Iteration 152250, lr = 0.0035
I0522 03:08:58.039552  6507 solver.cpp:237] Iteration 153000, loss = 1.03692
I0522 03:08:58.039721  6507 solver.cpp:253]     Train net output #0: loss = 1.03692 (* 1 = 1.03692 loss)
I0522 03:08:58.039737  6507 sgd_solver.cpp:106] Iteration 153000, lr = 0.0035
I0522 03:09:10.216318  6507 solver.cpp:237] Iteration 153750, loss = 1.42718
I0522 03:09:10.216354  6507 solver.cpp:253]     Train net output #0: loss = 1.42718 (* 1 = 1.42718 loss)
I0522 03:09:10.216369  6507 sgd_solver.cpp:106] Iteration 153750, lr = 0.0035
I0522 03:09:22.358405  6507 solver.cpp:237] Iteration 154500, loss = 1.13726
I0522 03:09:22.358455  6507 solver.cpp:253]     Train net output #0: loss = 1.13726 (* 1 = 1.13726 loss)
I0522 03:09:22.358469  6507 sgd_solver.cpp:106] Iteration 154500, lr = 0.0035
I0522 03:09:55.334410  6507 solver.cpp:237] Iteration 155250, loss = 1.56961
I0522 03:09:55.334589  6507 solver.cpp:253]     Train net output #0: loss = 1.56961 (* 1 = 1.56961 loss)
I0522 03:09:55.334602  6507 sgd_solver.cpp:106] Iteration 155250, lr = 0.0035
I0522 03:10:07.436880  6507 solver.cpp:237] Iteration 156000, loss = 0.982934
I0522 03:10:07.436924  6507 solver.cpp:253]     Train net output #0: loss = 0.982935 (* 1 = 0.982935 loss)
I0522 03:10:07.436944  6507 sgd_solver.cpp:106] Iteration 156000, lr = 0.0035
I0522 03:10:19.531322  6507 solver.cpp:237] Iteration 156750, loss = 2.41586
I0522 03:10:19.531358  6507 solver.cpp:253]     Train net output #0: loss = 2.41586 (* 1 = 2.41586 loss)
I0522 03:10:19.531373  6507 sgd_solver.cpp:106] Iteration 156750, lr = 0.0035
I0522 03:10:31.617497  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_157500.caffemodel
I0522 03:10:31.667181  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_157500.solverstate
I0522 03:10:31.697434  6507 solver.cpp:237] Iteration 157500, loss = 1.08636
I0522 03:10:31.697476  6507 solver.cpp:253]     Train net output #0: loss = 1.08636 (* 1 = 1.08636 loss)
I0522 03:10:31.697496  6507 sgd_solver.cpp:106] Iteration 157500, lr = 0.0035
I0522 03:10:43.780829  6507 solver.cpp:237] Iteration 158250, loss = 1.17642
I0522 03:10:43.780879  6507 solver.cpp:253]     Train net output #0: loss = 1.17642 (* 1 = 1.17642 loss)
I0522 03:10:43.780892  6507 sgd_solver.cpp:106] Iteration 158250, lr = 0.0035
I0522 03:10:55.858443  6507 solver.cpp:237] Iteration 159000, loss = 1.10565
I0522 03:10:55.858479  6507 solver.cpp:253]     Train net output #0: loss = 1.10565 (* 1 = 1.10565 loss)
I0522 03:10:55.858494  6507 sgd_solver.cpp:106] Iteration 159000, lr = 0.0035
I0522 03:11:07.947518  6507 solver.cpp:237] Iteration 159750, loss = 1.43825
I0522 03:11:07.947695  6507 solver.cpp:253]     Train net output #0: loss = 1.43825 (* 1 = 1.43825 loss)
I0522 03:11:07.947710  6507 sgd_solver.cpp:106] Iteration 159750, lr = 0.0035
I0522 03:11:40.960078  6507 solver.cpp:237] Iteration 160500, loss = 1.10651
I0522 03:11:40.960255  6507 solver.cpp:253]     Train net output #0: loss = 1.10651 (* 1 = 1.10651 loss)
I0522 03:11:40.960269  6507 sgd_solver.cpp:106] Iteration 160500, lr = 0.0035
I0522 03:11:53.152897  6507 solver.cpp:237] Iteration 161250, loss = 0.852666
I0522 03:11:53.152946  6507 solver.cpp:253]     Train net output #0: loss = 0.852667 (* 1 = 0.852667 loss)
I0522 03:11:53.152961  6507 sgd_solver.cpp:106] Iteration 161250, lr = 0.0035
I0522 03:12:05.341357  6507 solver.cpp:237] Iteration 162000, loss = 1.19971
I0522 03:12:05.341393  6507 solver.cpp:253]     Train net output #0: loss = 1.19971 (* 1 = 1.19971 loss)
I0522 03:12:05.341408  6507 sgd_solver.cpp:106] Iteration 162000, lr = 0.0035
I0522 03:12:17.548367  6507 solver.cpp:237] Iteration 162750, loss = 1.26395
I0522 03:12:17.548528  6507 solver.cpp:253]     Train net output #0: loss = 1.26395 (* 1 = 1.26395 loss)
I0522 03:12:17.548542  6507 sgd_solver.cpp:106] Iteration 162750, lr = 0.0035
I0522 03:12:29.685333  6507 solver.cpp:237] Iteration 163500, loss = 1.28357
I0522 03:12:29.685369  6507 solver.cpp:253]     Train net output #0: loss = 1.28357 (* 1 = 1.28357 loss)
I0522 03:12:29.685384  6507 sgd_solver.cpp:106] Iteration 163500, lr = 0.0035
I0522 03:12:41.804765  6507 solver.cpp:237] Iteration 164250, loss = 1.41765
I0522 03:12:41.804812  6507 solver.cpp:253]     Train net output #0: loss = 1.41765 (* 1 = 1.41765 loss)
I0522 03:12:41.804826  6507 sgd_solver.cpp:106] Iteration 164250, lr = 0.0035
I0522 03:12:53.915242  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_165000.caffemodel
I0522 03:12:53.964135  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_165000.solverstate
I0522 03:12:53.989096  6507 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 03:13:45.550400  6507 solver.cpp:409]     Test net output #0: accuracy = 0.891428
I0522 03:13:45.550581  6507 solver.cpp:409]     Test net output #1: loss = 0.350266 (* 1 = 0.350266 loss)
I0522 03:14:06.400974  6507 solver.cpp:237] Iteration 165000, loss = 1.21775
I0522 03:14:06.401028  6507 solver.cpp:253]     Train net output #0: loss = 1.21775 (* 1 = 1.21775 loss)
I0522 03:14:06.401043  6507 sgd_solver.cpp:106] Iteration 165000, lr = 0.0035
I0522 03:14:18.612552  6507 solver.cpp:237] Iteration 165750, loss = 1.17749
I0522 03:14:18.612736  6507 solver.cpp:253]     Train net output #0: loss = 1.17749 (* 1 = 1.17749 loss)
I0522 03:14:18.612751  6507 sgd_solver.cpp:106] Iteration 165750, lr = 0.0035
I0522 03:14:30.777129  6507 solver.cpp:237] Iteration 166500, loss = 1.21406
I0522 03:14:30.777165  6507 solver.cpp:253]     Train net output #0: loss = 1.21406 (* 1 = 1.21406 loss)
I0522 03:14:30.777179  6507 sgd_solver.cpp:106] Iteration 166500, lr = 0.0035
I0522 03:14:42.940424  6507 solver.cpp:237] Iteration 167250, loss = 1.22031
I0522 03:14:42.940476  6507 solver.cpp:253]     Train net output #0: loss = 1.22031 (* 1 = 1.22031 loss)
I0522 03:14:42.940490  6507 sgd_solver.cpp:106] Iteration 167250, lr = 0.0035
I0522 03:14:55.090172  6507 solver.cpp:237] Iteration 168000, loss = 1.44424
I0522 03:14:55.090332  6507 solver.cpp:253]     Train net output #0: loss = 1.44424 (* 1 = 1.44424 loss)
I0522 03:14:55.090348  6507 sgd_solver.cpp:106] Iteration 168000, lr = 0.0035
I0522 03:15:07.288475  6507 solver.cpp:237] Iteration 168750, loss = 1.08934
I0522 03:15:07.288511  6507 solver.cpp:253]     Train net output #0: loss = 1.08935 (* 1 = 1.08935 loss)
I0522 03:15:07.288525  6507 sgd_solver.cpp:106] Iteration 168750, lr = 0.0035
I0522 03:15:19.462834  6507 solver.cpp:237] Iteration 169500, loss = 1.49855
I0522 03:15:19.462879  6507 solver.cpp:253]     Train net output #0: loss = 1.49855 (* 1 = 1.49855 loss)
I0522 03:15:19.462893  6507 sgd_solver.cpp:106] Iteration 169500, lr = 0.0035
I0522 03:15:52.525177  6507 solver.cpp:237] Iteration 170250, loss = 1.26823
I0522 03:15:52.525357  6507 solver.cpp:253]     Train net output #0: loss = 1.26824 (* 1 = 1.26824 loss)
I0522 03:15:52.525370  6507 sgd_solver.cpp:106] Iteration 170250, lr = 0.0035
I0522 03:16:04.707579  6507 solver.cpp:237] Iteration 171000, loss = 0.903527
I0522 03:16:04.707630  6507 solver.cpp:253]     Train net output #0: loss = 0.903528 (* 1 = 0.903528 loss)
I0522 03:16:04.707644  6507 sgd_solver.cpp:106] Iteration 171000, lr = 0.0035
I0522 03:16:16.856037  6507 solver.cpp:237] Iteration 171750, loss = 1.45792
I0522 03:16:16.856075  6507 solver.cpp:253]     Train net output #0: loss = 1.45793 (* 1 = 1.45793 loss)
I0522 03:16:16.856088  6507 sgd_solver.cpp:106] Iteration 171750, lr = 0.0035
I0522 03:16:29.003803  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_172500.caffemodel
I0522 03:16:29.053174  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_172500.solverstate
I0522 03:16:29.083431  6507 solver.cpp:237] Iteration 172500, loss = 1.39931
I0522 03:16:29.083474  6507 solver.cpp:253]     Train net output #0: loss = 1.39932 (* 1 = 1.39932 loss)
I0522 03:16:29.083494  6507 sgd_solver.cpp:106] Iteration 172500, lr = 0.0035
I0522 03:16:41.245368  6507 solver.cpp:237] Iteration 173250, loss = 0.813195
I0522 03:16:41.245404  6507 solver.cpp:253]     Train net output #0: loss = 0.813196 (* 1 = 0.813196 loss)
I0522 03:16:41.245419  6507 sgd_solver.cpp:106] Iteration 173250, lr = 0.0035
I0522 03:16:53.418334  6507 solver.cpp:237] Iteration 174000, loss = 1.00784
I0522 03:16:53.418378  6507 solver.cpp:253]     Train net output #0: loss = 1.00784 (* 1 = 1.00784 loss)
I0522 03:16:53.418393  6507 sgd_solver.cpp:106] Iteration 174000, lr = 0.0035
I0522 03:17:05.613637  6507 solver.cpp:237] Iteration 174750, loss = 1.17961
I0522 03:17:05.613804  6507 solver.cpp:253]     Train net output #0: loss = 1.17962 (* 1 = 1.17962 loss)
I0522 03:17:05.613818  6507 sgd_solver.cpp:106] Iteration 174750, lr = 0.0035
I0522 03:17:38.592978  6507 solver.cpp:237] Iteration 175500, loss = 1.19699
I0522 03:17:38.593168  6507 solver.cpp:253]     Train net output #0: loss = 1.19699 (* 1 = 1.19699 loss)
I0522 03:17:38.593183  6507 sgd_solver.cpp:106] Iteration 175500, lr = 0.0035
I0522 03:17:50.747563  6507 solver.cpp:237] Iteration 176250, loss = 1.54229
I0522 03:17:50.747599  6507 solver.cpp:253]     Train net output #0: loss = 1.54229 (* 1 = 1.54229 loss)
I0522 03:17:50.747613  6507 sgd_solver.cpp:106] Iteration 176250, lr = 0.0035
I0522 03:18:02.897449  6507 solver.cpp:237] Iteration 177000, loss = 0.978924
I0522 03:18:02.897495  6507 solver.cpp:253]     Train net output #0: loss = 0.978924 (* 1 = 0.978924 loss)
I0522 03:18:02.897508  6507 sgd_solver.cpp:106] Iteration 177000, lr = 0.0035
I0522 03:18:15.032439  6507 solver.cpp:237] Iteration 177750, loss = 1.16658
I0522 03:18:15.032595  6507 solver.cpp:253]     Train net output #0: loss = 1.16658 (* 1 = 1.16658 loss)
I0522 03:18:15.032609  6507 sgd_solver.cpp:106] Iteration 177750, lr = 0.0035
I0522 03:18:27.162663  6507 solver.cpp:237] Iteration 178500, loss = 1.24334
I0522 03:18:27.162699  6507 solver.cpp:253]     Train net output #0: loss = 1.24334 (* 1 = 1.24334 loss)
I0522 03:18:27.162714  6507 sgd_solver.cpp:106] Iteration 178500, lr = 0.0035
I0522 03:18:39.312312  6507 solver.cpp:237] Iteration 179250, loss = 1.03519
I0522 03:18:39.312356  6507 solver.cpp:253]     Train net output #0: loss = 1.03519 (* 1 = 1.03519 loss)
I0522 03:18:39.312371  6507 sgd_solver.cpp:106] Iteration 179250, lr = 0.0035
I0522 03:18:51.452601  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_180000.caffemodel
I0522 03:18:51.504351  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_180000.solverstate
I0522 03:18:51.531239  6507 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 03:20:04.394457  6507 solver.cpp:409]     Test net output #0: accuracy = 0.890705
I0522 03:20:04.394635  6507 solver.cpp:409]     Test net output #1: loss = 0.38373 (* 1 = 0.38373 loss)
I0522 03:20:25.225987  6507 solver.cpp:237] Iteration 180000, loss = 1.53738
I0522 03:20:25.226039  6507 solver.cpp:253]     Train net output #0: loss = 1.53738 (* 1 = 1.53738 loss)
I0522 03:20:25.226055  6507 sgd_solver.cpp:106] Iteration 180000, lr = 0.0035
I0522 03:20:37.281301  6507 solver.cpp:237] Iteration 180750, loss = 1.14952
I0522 03:20:37.281471  6507 solver.cpp:253]     Train net output #0: loss = 1.14952 (* 1 = 1.14952 loss)
I0522 03:20:37.281484  6507 sgd_solver.cpp:106] Iteration 180750, lr = 0.0035
I0522 03:20:49.431972  6507 solver.cpp:237] Iteration 181500, loss = 1.28935
I0522 03:20:49.432008  6507 solver.cpp:253]     Train net output #0: loss = 1.28935 (* 1 = 1.28935 loss)
I0522 03:20:49.432021  6507 sgd_solver.cpp:106] Iteration 181500, lr = 0.0035
I0522 03:21:01.578892  6507 solver.cpp:237] Iteration 182250, loss = 1.50809
I0522 03:21:01.578943  6507 solver.cpp:253]     Train net output #0: loss = 1.50809 (* 1 = 1.50809 loss)
I0522 03:21:01.578956  6507 sgd_solver.cpp:106] Iteration 182250, lr = 0.0035
I0522 03:21:13.692961  6507 solver.cpp:237] Iteration 183000, loss = 0.976544
I0522 03:21:13.693122  6507 solver.cpp:253]     Train net output #0: loss = 0.976545 (* 1 = 0.976545 loss)
I0522 03:21:13.693136  6507 sgd_solver.cpp:106] Iteration 183000, lr = 0.0035
I0522 03:21:25.804935  6507 solver.cpp:237] Iteration 183750, loss = 1.08503
I0522 03:21:25.804981  6507 solver.cpp:253]     Train net output #0: loss = 1.08503 (* 1 = 1.08503 loss)
I0522 03:21:25.804996  6507 sgd_solver.cpp:106] Iteration 183750, lr = 0.0035
I0522 03:21:37.926807  6507 solver.cpp:237] Iteration 184500, loss = 1.32781
I0522 03:21:37.926842  6507 solver.cpp:253]     Train net output #0: loss = 1.32781 (* 1 = 1.32781 loss)
I0522 03:21:37.926856  6507 sgd_solver.cpp:106] Iteration 184500, lr = 0.0035
I0522 03:22:10.985151  6507 solver.cpp:237] Iteration 185250, loss = 1.4768
I0522 03:22:10.985342  6507 solver.cpp:253]     Train net output #0: loss = 1.4768 (* 1 = 1.4768 loss)
I0522 03:22:10.985357  6507 sgd_solver.cpp:106] Iteration 185250, lr = 0.0035
I0522 03:22:23.107980  6507 solver.cpp:237] Iteration 186000, loss = 1.41897
I0522 03:22:23.108026  6507 solver.cpp:253]     Train net output #0: loss = 1.41897 (* 1 = 1.41897 loss)
I0522 03:22:23.108041  6507 sgd_solver.cpp:106] Iteration 186000, lr = 0.0035
I0522 03:22:35.200335  6507 solver.cpp:237] Iteration 186750, loss = 1.22478
I0522 03:22:35.200371  6507 solver.cpp:253]     Train net output #0: loss = 1.22478 (* 1 = 1.22478 loss)
I0522 03:22:35.200386  6507 sgd_solver.cpp:106] Iteration 186750, lr = 0.0035
I0522 03:22:47.298193  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_187500.caffemodel
I0522 03:22:47.349166  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_187500.solverstate
I0522 03:22:47.381494  6507 solver.cpp:237] Iteration 187500, loss = 1.03551
I0522 03:22:47.381544  6507 solver.cpp:253]     Train net output #0: loss = 1.03551 (* 1 = 1.03551 loss)
I0522 03:22:47.381559  6507 sgd_solver.cpp:106] Iteration 187500, lr = 0.0035
I0522 03:22:59.480931  6507 solver.cpp:237] Iteration 188250, loss = 1.32311
I0522 03:22:59.480967  6507 solver.cpp:253]     Train net output #0: loss = 1.32311 (* 1 = 1.32311 loss)
I0522 03:22:59.480981  6507 sgd_solver.cpp:106] Iteration 188250, lr = 0.0035
I0522 03:23:11.594619  6507 solver.cpp:237] Iteration 189000, loss = 1.47183
I0522 03:23:11.594667  6507 solver.cpp:253]     Train net output #0: loss = 1.47183 (* 1 = 1.47183 loss)
I0522 03:23:11.594681  6507 sgd_solver.cpp:106] Iteration 189000, lr = 0.0035
I0522 03:23:23.760282  6507 solver.cpp:237] Iteration 189750, loss = 1.02004
I0522 03:23:23.760444  6507 solver.cpp:253]     Train net output #0: loss = 1.02004 (* 1 = 1.02004 loss)
I0522 03:23:23.760457  6507 sgd_solver.cpp:106] Iteration 189750, lr = 0.0035
I0522 03:23:56.754561  6507 solver.cpp:237] Iteration 190500, loss = 1.01793
I0522 03:23:56.754742  6507 solver.cpp:253]     Train net output #0: loss = 1.01793 (* 1 = 1.01793 loss)
I0522 03:23:56.754756  6507 sgd_solver.cpp:106] Iteration 190500, lr = 0.0035
I0522 03:24:08.912942  6507 solver.cpp:237] Iteration 191250, loss = 0.821845
I0522 03:24:08.912978  6507 solver.cpp:253]     Train net output #0: loss = 0.821846 (* 1 = 0.821846 loss)
I0522 03:24:08.912992  6507 sgd_solver.cpp:106] Iteration 191250, lr = 0.0035
I0522 03:24:21.067147  6507 solver.cpp:237] Iteration 192000, loss = 1.55827
I0522 03:24:21.067191  6507 solver.cpp:253]     Train net output #0: loss = 1.55827 (* 1 = 1.55827 loss)
I0522 03:24:21.067204  6507 sgd_solver.cpp:106] Iteration 192000, lr = 0.0035
I0522 03:24:33.182308  6507 solver.cpp:237] Iteration 192750, loss = 1.29026
I0522 03:24:33.182459  6507 solver.cpp:253]     Train net output #0: loss = 1.29026 (* 1 = 1.29026 loss)
I0522 03:24:33.182473  6507 sgd_solver.cpp:106] Iteration 192750, lr = 0.0035
I0522 03:24:45.306572  6507 solver.cpp:237] Iteration 193500, loss = 1.09284
I0522 03:24:45.306619  6507 solver.cpp:253]     Train net output #0: loss = 1.09285 (* 1 = 1.09285 loss)
I0522 03:24:45.306633  6507 sgd_solver.cpp:106] Iteration 193500, lr = 0.0035
I0522 03:24:57.411671  6507 solver.cpp:237] Iteration 194250, loss = 1.01446
I0522 03:24:57.411708  6507 solver.cpp:253]     Train net output #0: loss = 1.01446 (* 1 = 1.01446 loss)
I0522 03:24:57.411722  6507 sgd_solver.cpp:106] Iteration 194250, lr = 0.0035
I0522 03:25:09.500356  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_195000.caffemodel
I0522 03:25:09.548985  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_195000.solverstate
I0522 03:25:09.573930  6507 solver.cpp:341] Iteration 195000, Testing net (#0)
I0522 03:26:01.530088  6507 solver.cpp:409]     Test net output #0: accuracy = 0.892737
I0522 03:26:01.530274  6507 solver.cpp:409]     Test net output #1: loss = 0.340477 (* 1 = 0.340477 loss)
I0522 03:26:22.435583  6507 solver.cpp:237] Iteration 195000, loss = 1.12025
I0522 03:26:22.435632  6507 solver.cpp:253]     Train net output #0: loss = 1.12025 (* 1 = 1.12025 loss)
I0522 03:26:22.435647  6507 sgd_solver.cpp:106] Iteration 195000, lr = 0.0035
I0522 03:26:34.544502  6507 solver.cpp:237] Iteration 195750, loss = 0.979153
I0522 03:26:34.544669  6507 solver.cpp:253]     Train net output #0: loss = 0.979154 (* 1 = 0.979154 loss)
I0522 03:26:34.544682  6507 sgd_solver.cpp:106] Iteration 195750, lr = 0.0035
I0522 03:26:46.654858  6507 solver.cpp:237] Iteration 196500, loss = 1.29508
I0522 03:26:46.654893  6507 solver.cpp:253]     Train net output #0: loss = 1.29508 (* 1 = 1.29508 loss)
I0522 03:26:46.654908  6507 sgd_solver.cpp:106] Iteration 196500, lr = 0.0035
I0522 03:26:58.762208  6507 solver.cpp:237] Iteration 197250, loss = 0.716631
I0522 03:26:58.762253  6507 solver.cpp:253]     Train net output #0: loss = 0.716632 (* 1 = 0.716632 loss)
I0522 03:26:58.762267  6507 sgd_solver.cpp:106] Iteration 197250, lr = 0.0035
I0522 03:27:10.867233  6507 solver.cpp:237] Iteration 198000, loss = 0.882766
I0522 03:27:10.867396  6507 solver.cpp:253]     Train net output #0: loss = 0.882767 (* 1 = 0.882767 loss)
I0522 03:27:10.867410  6507 sgd_solver.cpp:106] Iteration 198000, lr = 0.0035
I0522 03:27:22.972579  6507 solver.cpp:237] Iteration 198750, loss = 1.36028
I0522 03:27:22.972627  6507 solver.cpp:253]     Train net output #0: loss = 1.36028 (* 1 = 1.36028 loss)
I0522 03:27:22.972640  6507 sgd_solver.cpp:106] Iteration 198750, lr = 0.0035
I0522 03:27:35.083276  6507 solver.cpp:237] Iteration 199500, loss = 0.984756
I0522 03:27:35.083313  6507 solver.cpp:253]     Train net output #0: loss = 0.984757 (* 1 = 0.984757 loss)
I0522 03:27:35.083326  6507 sgd_solver.cpp:106] Iteration 199500, lr = 0.0035
I0522 03:28:08.119287  6507 solver.cpp:237] Iteration 200250, loss = 1.30629
I0522 03:28:08.119467  6507 solver.cpp:253]     Train net output #0: loss = 1.30629 (* 1 = 1.30629 loss)
I0522 03:28:08.119483  6507 sgd_solver.cpp:106] Iteration 200250, lr = 0.0035
I0522 03:28:20.283272  6507 solver.cpp:237] Iteration 201000, loss = 1.07574
I0522 03:28:20.283308  6507 solver.cpp:253]     Train net output #0: loss = 1.07574 (* 1 = 1.07574 loss)
I0522 03:28:20.283323  6507 sgd_solver.cpp:106] Iteration 201000, lr = 0.0035
I0522 03:28:32.449684  6507 solver.cpp:237] Iteration 201750, loss = 1.35222
I0522 03:28:32.449738  6507 solver.cpp:253]     Train net output #0: loss = 1.35222 (* 1 = 1.35222 loss)
I0522 03:28:32.449753  6507 sgd_solver.cpp:106] Iteration 201750, lr = 0.0035
I0522 03:28:44.594141  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_202500.caffemodel
I0522 03:28:44.643388  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_202500.solverstate
I0522 03:28:44.673233  6507 solver.cpp:237] Iteration 202500, loss = 1.01697
I0522 03:28:44.673277  6507 solver.cpp:253]     Train net output #0: loss = 1.01697 (* 1 = 1.01697 loss)
I0522 03:28:44.673293  6507 sgd_solver.cpp:106] Iteration 202500, lr = 0.0035
I0522 03:28:56.837163  6507 solver.cpp:237] Iteration 203250, loss = 1.23529
I0522 03:28:56.837208  6507 solver.cpp:253]     Train net output #0: loss = 1.23529 (* 1 = 1.23529 loss)
I0522 03:28:56.837222  6507 sgd_solver.cpp:106] Iteration 203250, lr = 0.0035
I0522 03:29:08.988445  6507 solver.cpp:237] Iteration 204000, loss = 0.925061
I0522 03:29:08.988482  6507 solver.cpp:253]     Train net output #0: loss = 0.925062 (* 1 = 0.925062 loss)
I0522 03:29:08.988495  6507 sgd_solver.cpp:106] Iteration 204000, lr = 0.0035
I0522 03:29:21.054888  6507 solver.cpp:237] Iteration 204750, loss = 0.874439
I0522 03:29:21.055073  6507 solver.cpp:253]     Train net output #0: loss = 0.87444 (* 1 = 0.87444 loss)
I0522 03:29:21.055088  6507 sgd_solver.cpp:106] Iteration 204750, lr = 0.0035
I0522 03:29:53.991657  6507 solver.cpp:237] Iteration 205500, loss = 1.43863
I0522 03:29:53.991842  6507 solver.cpp:253]     Train net output #0: loss = 1.43863 (* 1 = 1.43863 loss)
I0522 03:29:53.991857  6507 sgd_solver.cpp:106] Iteration 205500, lr = 0.0035
I0522 03:30:06.056251  6507 solver.cpp:237] Iteration 206250, loss = 1.17722
I0522 03:30:06.056287  6507 solver.cpp:253]     Train net output #0: loss = 1.17722 (* 1 = 1.17722 loss)
I0522 03:30:06.056300  6507 sgd_solver.cpp:106] Iteration 206250, lr = 0.0035
I0522 03:30:18.126857  6507 solver.cpp:237] Iteration 207000, loss = 1.31292
I0522 03:30:18.126902  6507 solver.cpp:253]     Train net output #0: loss = 1.31293 (* 1 = 1.31293 loss)
I0522 03:30:18.126916  6507 sgd_solver.cpp:106] Iteration 207000, lr = 0.0035
I0522 03:30:30.279423  6507 solver.cpp:237] Iteration 207750, loss = 0.942336
I0522 03:30:30.279582  6507 solver.cpp:253]     Train net output #0: loss = 0.942337 (* 1 = 0.942337 loss)
I0522 03:30:30.279598  6507 sgd_solver.cpp:106] Iteration 207750, lr = 0.0035
I0522 03:30:42.431560  6507 solver.cpp:237] Iteration 208500, loss = 1.38503
I0522 03:30:42.431603  6507 solver.cpp:253]     Train net output #0: loss = 1.38503 (* 1 = 1.38503 loss)
I0522 03:30:42.431615  6507 sgd_solver.cpp:106] Iteration 208500, lr = 0.0035
I0522 03:30:54.558568  6507 solver.cpp:237] Iteration 209250, loss = 1.10357
I0522 03:30:54.558604  6507 solver.cpp:253]     Train net output #0: loss = 1.10357 (* 1 = 1.10357 loss)
I0522 03:30:54.558617  6507 sgd_solver.cpp:106] Iteration 209250, lr = 0.0035
I0522 03:31:06.674644  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_210000.caffemodel
I0522 03:31:06.724182  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_210000.solverstate
I0522 03:31:06.749315  6507 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 03:32:19.586133  6507 solver.cpp:409]     Test net output #0: accuracy = 0.890384
I0522 03:32:19.586314  6507 solver.cpp:409]     Test net output #1: loss = 0.332078 (* 1 = 0.332078 loss)
I0522 03:32:40.489436  6507 solver.cpp:237] Iteration 210000, loss = 1.04343
I0522 03:32:40.489488  6507 solver.cpp:253]     Train net output #0: loss = 1.04343 (* 1 = 1.04343 loss)
I0522 03:32:40.489505  6507 sgd_solver.cpp:106] Iteration 210000, lr = 0.0035
I0522 03:32:52.589547  6507 solver.cpp:237] Iteration 210750, loss = 1.06713
I0522 03:32:52.589715  6507 solver.cpp:253]     Train net output #0: loss = 1.06713 (* 1 = 1.06713 loss)
I0522 03:32:52.589733  6507 sgd_solver.cpp:106] Iteration 210750, lr = 0.0035
I0522 03:33:04.710821  6507 solver.cpp:237] Iteration 211500, loss = 1.27315
I0522 03:33:04.710868  6507 solver.cpp:253]     Train net output #0: loss = 1.27316 (* 1 = 1.27316 loss)
I0522 03:33:04.710882  6507 sgd_solver.cpp:106] Iteration 211500, lr = 0.0035
I0522 03:33:16.837208  6507 solver.cpp:237] Iteration 212250, loss = 0.968664
I0522 03:33:16.837245  6507 solver.cpp:253]     Train net output #0: loss = 0.968665 (* 1 = 0.968665 loss)
I0522 03:33:16.837260  6507 sgd_solver.cpp:106] Iteration 212250, lr = 0.0035
I0522 03:33:28.955844  6507 solver.cpp:237] Iteration 213000, loss = 1.25177
I0522 03:33:28.956023  6507 solver.cpp:253]     Train net output #0: loss = 1.25177 (* 1 = 1.25177 loss)
I0522 03:33:28.956038  6507 sgd_solver.cpp:106] Iteration 213000, lr = 0.0035
I0522 03:33:41.081666  6507 solver.cpp:237] Iteration 213750, loss = 0.917285
I0522 03:33:41.081702  6507 solver.cpp:253]     Train net output #0: loss = 0.917286 (* 1 = 0.917286 loss)
I0522 03:33:41.081717  6507 sgd_solver.cpp:106] Iteration 213750, lr = 0.0035
I0522 03:33:53.205600  6507 solver.cpp:237] Iteration 214500, loss = 0.756302
I0522 03:33:53.205651  6507 solver.cpp:253]     Train net output #0: loss = 0.756303 (* 1 = 0.756303 loss)
I0522 03:33:53.205665  6507 sgd_solver.cpp:106] Iteration 214500, lr = 0.0035
I0522 03:34:26.253113  6507 solver.cpp:237] Iteration 215250, loss = 1.17484
I0522 03:34:26.253309  6507 solver.cpp:253]     Train net output #0: loss = 1.17484 (* 1 = 1.17484 loss)
I0522 03:34:26.253322  6507 sgd_solver.cpp:106] Iteration 215250, lr = 0.0035
I0522 03:34:38.386291  6507 solver.cpp:237] Iteration 216000, loss = 1.45589
I0522 03:34:38.386327  6507 solver.cpp:253]     Train net output #0: loss = 1.45589 (* 1 = 1.45589 loss)
I0522 03:34:38.386343  6507 sgd_solver.cpp:106] Iteration 216000, lr = 0.0035
I0522 03:34:50.545255  6507 solver.cpp:237] Iteration 216750, loss = 1.03067
I0522 03:34:50.545300  6507 solver.cpp:253]     Train net output #0: loss = 1.03067 (* 1 = 1.03067 loss)
I0522 03:34:50.545315  6507 sgd_solver.cpp:106] Iteration 216750, lr = 0.0035
I0522 03:35:02.689246  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_217500.caffemodel
I0522 03:35:02.740316  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_217500.solverstate
I0522 03:35:02.772709  6507 solver.cpp:237] Iteration 217500, loss = 1.52577
I0522 03:35:02.772758  6507 solver.cpp:253]     Train net output #0: loss = 1.52577 (* 1 = 1.52577 loss)
I0522 03:35:02.772775  6507 sgd_solver.cpp:106] Iteration 217500, lr = 0.0035
I0522 03:35:14.932953  6507 solver.cpp:237] Iteration 218250, loss = 1.16977
I0522 03:35:14.933001  6507 solver.cpp:253]     Train net output #0: loss = 1.16977 (* 1 = 1.16977 loss)
I0522 03:35:14.933014  6507 sgd_solver.cpp:106] Iteration 218250, lr = 0.0035
I0522 03:35:27.055671  6507 solver.cpp:237] Iteration 219000, loss = 1.25558
I0522 03:35:27.055707  6507 solver.cpp:253]     Train net output #0: loss = 1.25558 (* 1 = 1.25558 loss)
I0522 03:35:27.055721  6507 sgd_solver.cpp:106] Iteration 219000, lr = 0.0035
I0522 03:35:39.196138  6507 solver.cpp:237] Iteration 219750, loss = 1.30169
I0522 03:35:39.196321  6507 solver.cpp:253]     Train net output #0: loss = 1.30169 (* 1 = 1.30169 loss)
I0522 03:35:39.196334  6507 sgd_solver.cpp:106] Iteration 219750, lr = 0.0035
I0522 03:36:12.207875  6507 solver.cpp:237] Iteration 220500, loss = 0.955297
I0522 03:36:12.208061  6507 solver.cpp:253]     Train net output #0: loss = 0.955297 (* 1 = 0.955297 loss)
I0522 03:36:12.208078  6507 sgd_solver.cpp:106] Iteration 220500, lr = 0.0035
I0522 03:36:24.372072  6507 solver.cpp:237] Iteration 221250, loss = 0.953544
I0522 03:36:24.372115  6507 solver.cpp:253]     Train net output #0: loss = 0.953544 (* 1 = 0.953544 loss)
I0522 03:36:24.372133  6507 sgd_solver.cpp:106] Iteration 221250, lr = 0.0035
I0522 03:36:36.535248  6507 solver.cpp:237] Iteration 222000, loss = 0.959249
I0522 03:36:36.535285  6507 solver.cpp:253]     Train net output #0: loss = 0.959249 (* 1 = 0.959249 loss)
I0522 03:36:36.535300  6507 sgd_solver.cpp:106] Iteration 222000, lr = 0.0035
I0522 03:36:48.697057  6507 solver.cpp:237] Iteration 222750, loss = 1.29593
I0522 03:36:48.697227  6507 solver.cpp:253]     Train net output #0: loss = 1.29593 (* 1 = 1.29593 loss)
I0522 03:36:48.697242  6507 sgd_solver.cpp:106] Iteration 222750, lr = 0.0035
I0522 03:37:00.852022  6507 solver.cpp:237] Iteration 223500, loss = 1.19545
I0522 03:37:00.852058  6507 solver.cpp:253]     Train net output #0: loss = 1.19545 (* 1 = 1.19545 loss)
I0522 03:37:00.852072  6507 sgd_solver.cpp:106] Iteration 223500, lr = 0.0035
I0522 03:37:12.970304  6507 solver.cpp:237] Iteration 224250, loss = 1.19541
I0522 03:37:12.970345  6507 solver.cpp:253]     Train net output #0: loss = 1.19541 (* 1 = 1.19541 loss)
I0522 03:37:12.970361  6507 sgd_solver.cpp:106] Iteration 224250, lr = 0.0035
I0522 03:37:25.091202  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_225000.caffemodel
I0522 03:37:25.142519  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_225000.solverstate
I0522 03:37:25.169491  6507 solver.cpp:341] Iteration 225000, Testing net (#0)
I0522 03:38:16.790824  6507 solver.cpp:409]     Test net output #0: accuracy = 0.894043
I0522 03:38:16.791004  6507 solver.cpp:409]     Test net output #1: loss = 0.362595 (* 1 = 0.362595 loss)
I0522 03:38:37.665828  6507 solver.cpp:237] Iteration 225000, loss = 1.07364
I0522 03:38:37.665880  6507 solver.cpp:253]     Train net output #0: loss = 1.07364 (* 1 = 1.07364 loss)
I0522 03:38:37.665896  6507 sgd_solver.cpp:106] Iteration 225000, lr = 0.0035
I0522 03:38:49.844039  6507 solver.cpp:237] Iteration 225750, loss = 1.12012
I0522 03:38:49.844210  6507 solver.cpp:253]     Train net output #0: loss = 1.12012 (* 1 = 1.12012 loss)
I0522 03:38:49.844224  6507 sgd_solver.cpp:106] Iteration 225750, lr = 0.0035
I0522 03:39:02.039959  6507 solver.cpp:237] Iteration 226500, loss = 1.1234
I0522 03:39:02.040009  6507 solver.cpp:253]     Train net output #0: loss = 1.1234 (* 1 = 1.1234 loss)
I0522 03:39:02.040022  6507 sgd_solver.cpp:106] Iteration 226500, lr = 0.0035
I0522 03:39:14.164805  6507 solver.cpp:237] Iteration 227250, loss = 0.979426
I0522 03:39:14.164842  6507 solver.cpp:253]     Train net output #0: loss = 0.979426 (* 1 = 0.979426 loss)
I0522 03:39:14.164856  6507 sgd_solver.cpp:106] Iteration 227250, lr = 0.0035
I0522 03:39:26.279711  6507 solver.cpp:237] Iteration 228000, loss = 0.726796
I0522 03:39:26.279889  6507 solver.cpp:253]     Train net output #0: loss = 0.726796 (* 1 = 0.726796 loss)
I0522 03:39:26.279906  6507 sgd_solver.cpp:106] Iteration 228000, lr = 0.0035
I0522 03:39:38.381868  6507 solver.cpp:237] Iteration 228750, loss = 0.907913
I0522 03:39:38.381906  6507 solver.cpp:253]     Train net output #0: loss = 0.907913 (* 1 = 0.907913 loss)
I0522 03:39:38.381919  6507 sgd_solver.cpp:106] Iteration 228750, lr = 0.0035
I0522 03:39:50.500542  6507 solver.cpp:237] Iteration 229500, loss = 1.53077
I0522 03:39:50.500584  6507 solver.cpp:253]     Train net output #0: loss = 1.53077 (* 1 = 1.53077 loss)
I0522 03:39:50.500599  6507 sgd_solver.cpp:106] Iteration 229500, lr = 0.0035
I0522 03:40:23.487540  6507 solver.cpp:237] Iteration 230250, loss = 1.45862
I0522 03:40:23.487727  6507 solver.cpp:253]     Train net output #0: loss = 1.45862 (* 1 = 1.45862 loss)
I0522 03:40:23.487741  6507 sgd_solver.cpp:106] Iteration 230250, lr = 0.0035
I0522 03:40:35.619422  6507 solver.cpp:237] Iteration 231000, loss = 0.960592
I0522 03:40:35.619468  6507 solver.cpp:253]     Train net output #0: loss = 0.960592 (* 1 = 0.960592 loss)
I0522 03:40:35.619482  6507 sgd_solver.cpp:106] Iteration 231000, lr = 0.0035
I0522 03:40:47.795758  6507 solver.cpp:237] Iteration 231750, loss = 1.92834
I0522 03:40:47.795794  6507 solver.cpp:253]     Train net output #0: loss = 1.92834 (* 1 = 1.92834 loss)
I0522 03:40:47.795809  6507 sgd_solver.cpp:106] Iteration 231750, lr = 0.0035
I0522 03:40:59.943097  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_232500.caffemodel
I0522 03:40:59.991691  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_232500.solverstate
I0522 03:41:00.021769  6507 solver.cpp:237] Iteration 232500, loss = 0.763855
I0522 03:41:00.021813  6507 solver.cpp:253]     Train net output #0: loss = 0.763855 (* 1 = 0.763855 loss)
I0522 03:41:00.021828  6507 sgd_solver.cpp:106] Iteration 232500, lr = 0.0035
I0522 03:41:12.161146  6507 solver.cpp:237] Iteration 233250, loss = 1.49854
I0522 03:41:12.161182  6507 solver.cpp:253]     Train net output #0: loss = 1.49854 (* 1 = 1.49854 loss)
I0522 03:41:12.161196  6507 sgd_solver.cpp:106] Iteration 233250, lr = 0.0035
I0522 03:41:24.305119  6507 solver.cpp:237] Iteration 234000, loss = 1.19891
I0522 03:41:24.305167  6507 solver.cpp:253]     Train net output #0: loss = 1.19891 (* 1 = 1.19891 loss)
I0522 03:41:24.305181  6507 sgd_solver.cpp:106] Iteration 234000, lr = 0.0035
I0522 03:41:36.418789  6507 solver.cpp:237] Iteration 234750, loss = 1.09902
I0522 03:41:36.418965  6507 solver.cpp:253]     Train net output #0: loss = 1.09902 (* 1 = 1.09902 loss)
I0522 03:41:36.418979  6507 sgd_solver.cpp:106] Iteration 234750, lr = 0.0035
I0522 03:42:09.403901  6507 solver.cpp:237] Iteration 235500, loss = 0.919212
I0522 03:42:09.404093  6507 solver.cpp:253]     Train net output #0: loss = 0.919213 (* 1 = 0.919213 loss)
I0522 03:42:09.404108  6507 sgd_solver.cpp:106] Iteration 235500, lr = 0.0035
I0522 03:42:21.520781  6507 solver.cpp:237] Iteration 236250, loss = 0.96437
I0522 03:42:21.520831  6507 solver.cpp:253]     Train net output #0: loss = 0.96437 (* 1 = 0.96437 loss)
I0522 03:42:21.520845  6507 sgd_solver.cpp:106] Iteration 236250, lr = 0.0035
I0522 03:42:33.661345  6507 solver.cpp:237] Iteration 237000, loss = 1.02894
I0522 03:42:33.661381  6507 solver.cpp:253]     Train net output #0: loss = 1.02894 (* 1 = 1.02894 loss)
I0522 03:42:33.661396  6507 sgd_solver.cpp:106] Iteration 237000, lr = 0.0035
I0522 03:42:45.787716  6507 solver.cpp:237] Iteration 237750, loss = 1.29911
I0522 03:42:45.787895  6507 solver.cpp:253]     Train net output #0: loss = 1.29911 (* 1 = 1.29911 loss)
I0522 03:42:45.787909  6507 sgd_solver.cpp:106] Iteration 237750, lr = 0.0035
I0522 03:42:57.904191  6507 solver.cpp:237] Iteration 238500, loss = 1.12758
I0522 03:42:57.904227  6507 solver.cpp:253]     Train net output #0: loss = 1.12758 (* 1 = 1.12758 loss)
I0522 03:42:57.904242  6507 sgd_solver.cpp:106] Iteration 238500, lr = 0.0035
I0522 03:43:10.016232  6507 solver.cpp:237] Iteration 239250, loss = 1.36164
I0522 03:43:10.016281  6507 solver.cpp:253]     Train net output #0: loss = 1.36164 (* 1 = 1.36164 loss)
I0522 03:43:10.016296  6507 sgd_solver.cpp:106] Iteration 239250, lr = 0.0035
I0522 03:43:22.118979  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_240000.caffemodel
I0522 03:43:22.168005  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_240000.solverstate
I0522 03:43:22.193231  6507 solver.cpp:341] Iteration 240000, Testing net (#0)
I0522 03:44:34.989598  6507 solver.cpp:409]     Test net output #0: accuracy = 0.89941
I0522 03:44:34.989792  6507 solver.cpp:409]     Test net output #1: loss = 0.311087 (* 1 = 0.311087 loss)
I0522 03:44:55.837618  6507 solver.cpp:237] Iteration 240000, loss = 0.817107
I0522 03:44:55.837672  6507 solver.cpp:253]     Train net output #0: loss = 0.817108 (* 1 = 0.817108 loss)
I0522 03:44:55.837687  6507 sgd_solver.cpp:106] Iteration 240000, lr = 0.0035
I0522 03:45:07.977103  6507 solver.cpp:237] Iteration 240750, loss = 1.26607
I0522 03:45:07.977286  6507 solver.cpp:253]     Train net output #0: loss = 1.26607 (* 1 = 1.26607 loss)
I0522 03:45:07.977300  6507 sgd_solver.cpp:106] Iteration 240750, lr = 0.0035
I0522 03:45:20.129513  6507 solver.cpp:237] Iteration 241500, loss = 0.91997
I0522 03:45:20.129549  6507 solver.cpp:253]     Train net output #0: loss = 0.919971 (* 1 = 0.919971 loss)
I0522 03:45:20.129562  6507 sgd_solver.cpp:106] Iteration 241500, lr = 0.0035
I0522 03:45:32.285991  6507 solver.cpp:237] Iteration 242250, loss = 1.426
I0522 03:45:32.286027  6507 solver.cpp:253]     Train net output #0: loss = 1.426 (* 1 = 1.426 loss)
I0522 03:45:32.286041  6507 sgd_solver.cpp:106] Iteration 242250, lr = 0.0035
I0522 03:45:44.472501  6507 solver.cpp:237] Iteration 243000, loss = 1.10388
I0522 03:45:44.472690  6507 solver.cpp:253]     Train net output #0: loss = 1.10388 (* 1 = 1.10388 loss)
I0522 03:45:44.472707  6507 sgd_solver.cpp:106] Iteration 243000, lr = 0.0035
I0522 03:45:56.652110  6507 solver.cpp:237] Iteration 243750, loss = 1.01023
I0522 03:45:56.652145  6507 solver.cpp:253]     Train net output #0: loss = 1.01023 (* 1 = 1.01023 loss)
I0522 03:45:56.652159  6507 sgd_solver.cpp:106] Iteration 243750, lr = 0.0035
I0522 03:46:08.841640  6507 solver.cpp:237] Iteration 244500, loss = 1.12718
I0522 03:46:08.841688  6507 solver.cpp:253]     Train net output #0: loss = 1.12718 (* 1 = 1.12718 loss)
I0522 03:46:08.841702  6507 sgd_solver.cpp:106] Iteration 244500, lr = 0.0035
I0522 03:46:41.860895  6507 solver.cpp:237] Iteration 245250, loss = 1.3707
I0522 03:46:41.861084  6507 solver.cpp:253]     Train net output #0: loss = 1.3707 (* 1 = 1.3707 loss)
I0522 03:46:41.861099  6507 sgd_solver.cpp:106] Iteration 245250, lr = 0.0035
I0522 03:46:54.083412  6507 solver.cpp:237] Iteration 246000, loss = 1.14567
I0522 03:46:54.083456  6507 solver.cpp:253]     Train net output #0: loss = 1.14568 (* 1 = 1.14568 loss)
I0522 03:46:54.083469  6507 sgd_solver.cpp:106] Iteration 246000, lr = 0.0035
I0522 03:47:06.297411  6507 solver.cpp:237] Iteration 246750, loss = 1.14021
I0522 03:47:06.297447  6507 solver.cpp:253]     Train net output #0: loss = 1.14022 (* 1 = 1.14022 loss)
I0522 03:47:06.297461  6507 sgd_solver.cpp:106] Iteration 246750, lr = 0.0035
I0522 03:47:18.496181  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_247500.caffemodel
I0522 03:47:18.548125  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_247500.solverstate
I0522 03:47:18.579634  6507 solver.cpp:237] Iteration 247500, loss = 1.0775
I0522 03:47:18.579679  6507 solver.cpp:253]     Train net output #0: loss = 1.0775 (* 1 = 1.0775 loss)
I0522 03:47:18.579694  6507 sgd_solver.cpp:106] Iteration 247500, lr = 0.0035
I0522 03:47:30.764601  6507 solver.cpp:237] Iteration 248250, loss = 1.15161
I0522 03:47:30.764637  6507 solver.cpp:253]     Train net output #0: loss = 1.15161 (* 1 = 1.15161 loss)
I0522 03:47:30.764652  6507 sgd_solver.cpp:106] Iteration 248250, lr = 0.0035
I0522 03:47:42.943200  6507 solver.cpp:237] Iteration 249000, loss = 0.768747
I0522 03:47:42.943251  6507 solver.cpp:253]     Train net output #0: loss = 0.768749 (* 1 = 0.768749 loss)
I0522 03:47:42.943264  6507 sgd_solver.cpp:106] Iteration 249000, lr = 0.0035
I0522 03:47:55.125123  6507 solver.cpp:237] Iteration 249750, loss = 1.22041
I0522 03:47:55.125295  6507 solver.cpp:253]     Train net output #0: loss = 1.22041 (* 1 = 1.22041 loss)
I0522 03:47:55.125309  6507 sgd_solver.cpp:106] Iteration 249750, lr = 0.0035
I0522 03:48:28.228394  6507 solver.cpp:237] Iteration 250500, loss = 1.02242
I0522 03:48:28.228580  6507 solver.cpp:253]     Train net output #0: loss = 1.02243 (* 1 = 1.02243 loss)
I0522 03:48:28.228595  6507 sgd_solver.cpp:106] Iteration 250500, lr = 0.0035
I0522 03:48:40.431327  6507 solver.cpp:237] Iteration 251250, loss = 1.47029
I0522 03:48:40.431363  6507 solver.cpp:253]     Train net output #0: loss = 1.47029 (* 1 = 1.47029 loss)
I0522 03:48:40.431378  6507 sgd_solver.cpp:106] Iteration 251250, lr = 0.0035
I0522 03:48:52.628792  6507 solver.cpp:237] Iteration 252000, loss = 1.33099
I0522 03:48:52.628831  6507 solver.cpp:253]     Train net output #0: loss = 1.33099 (* 1 = 1.33099 loss)
I0522 03:48:52.628844  6507 sgd_solver.cpp:106] Iteration 252000, lr = 0.0035
I0522 03:49:04.838918  6507 solver.cpp:237] Iteration 252750, loss = 1.44604
I0522 03:49:04.839097  6507 solver.cpp:253]     Train net output #0: loss = 1.44604 (* 1 = 1.44604 loss)
I0522 03:49:04.839109  6507 sgd_solver.cpp:106] Iteration 252750, lr = 0.0035
I0522 03:49:17.071169  6507 solver.cpp:237] Iteration 253500, loss = 1.11817
I0522 03:49:17.071205  6507 solver.cpp:253]     Train net output #0: loss = 1.11817 (* 1 = 1.11817 loss)
I0522 03:49:17.071220  6507 sgd_solver.cpp:106] Iteration 253500, lr = 0.0035
I0522 03:49:29.244666  6507 solver.cpp:237] Iteration 254250, loss = 1.11735
I0522 03:49:29.244711  6507 solver.cpp:253]     Train net output #0: loss = 1.11735 (* 1 = 1.11735 loss)
I0522 03:49:29.244725  6507 sgd_solver.cpp:106] Iteration 254250, lr = 0.0035
I0522 03:49:41.421250  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_255000.caffemodel
I0522 03:49:41.471446  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_255000.solverstate
I0522 03:49:41.497689  6507 solver.cpp:341] Iteration 255000, Testing net (#0)
I0522 03:50:33.492774  6507 solver.cpp:409]     Test net output #0: accuracy = 0.894366
I0522 03:50:33.492966  6507 solver.cpp:409]     Test net output #1: loss = 0.350645 (* 1 = 0.350645 loss)
I0522 03:50:54.349620  6507 solver.cpp:237] Iteration 255000, loss = 1.5044
I0522 03:50:54.349674  6507 solver.cpp:253]     Train net output #0: loss = 1.5044 (* 1 = 1.5044 loss)
I0522 03:50:54.349690  6507 sgd_solver.cpp:106] Iteration 255000, lr = 0.0035
I0522 03:51:06.480762  6507 solver.cpp:237] Iteration 255750, loss = 1.29201
I0522 03:51:06.480947  6507 solver.cpp:253]     Train net output #0: loss = 1.29201 (* 1 = 1.29201 loss)
I0522 03:51:06.480960  6507 sgd_solver.cpp:106] Iteration 255750, lr = 0.0035
I0522 03:51:18.602193  6507 solver.cpp:237] Iteration 256500, loss = 1.47461
I0522 03:51:18.602229  6507 solver.cpp:253]     Train net output #0: loss = 1.47461 (* 1 = 1.47461 loss)
I0522 03:51:18.602243  6507 sgd_solver.cpp:106] Iteration 256500, lr = 0.0035
I0522 03:51:30.730479  6507 solver.cpp:237] Iteration 257250, loss = 1.02176
I0522 03:51:30.730530  6507 solver.cpp:253]     Train net output #0: loss = 1.02176 (* 1 = 1.02176 loss)
I0522 03:51:30.730542  6507 sgd_solver.cpp:106] Iteration 257250, lr = 0.0035
I0522 03:51:42.868675  6507 solver.cpp:237] Iteration 258000, loss = 0.907971
I0522 03:51:42.868845  6507 solver.cpp:253]     Train net output #0: loss = 0.907972 (* 1 = 0.907972 loss)
I0522 03:51:42.868860  6507 sgd_solver.cpp:106] Iteration 258000, lr = 0.0035
I0522 03:51:55.003093  6507 solver.cpp:237] Iteration 258750, loss = 0.814835
I0522 03:51:55.003144  6507 solver.cpp:253]     Train net output #0: loss = 0.814836 (* 1 = 0.814836 loss)
I0522 03:51:55.003157  6507 sgd_solver.cpp:106] Iteration 258750, lr = 0.0035
I0522 03:52:07.122581  6507 solver.cpp:237] Iteration 259500, loss = 1.39207
I0522 03:52:07.122616  6507 solver.cpp:253]     Train net output #0: loss = 1.39207 (* 1 = 1.39207 loss)
I0522 03:52:07.122630  6507 sgd_solver.cpp:106] Iteration 259500, lr = 0.0035
I0522 03:52:40.085942  6507 solver.cpp:237] Iteration 260250, loss = 0.894471
I0522 03:52:40.086130  6507 solver.cpp:253]     Train net output #0: loss = 0.894472 (* 1 = 0.894472 loss)
I0522 03:52:40.086145  6507 sgd_solver.cpp:106] Iteration 260250, lr = 0.0035
I0522 03:52:52.204740  6507 solver.cpp:237] Iteration 261000, loss = 1.08709
I0522 03:52:52.204776  6507 solver.cpp:253]     Train net output #0: loss = 1.08709 (* 1 = 1.08709 loss)
I0522 03:52:52.204790  6507 sgd_solver.cpp:106] Iteration 261000, lr = 0.0035
I0522 03:53:04.333005  6507 solver.cpp:237] Iteration 261750, loss = 1.4558
I0522 03:53:04.333050  6507 solver.cpp:253]     Train net output #0: loss = 1.4558 (* 1 = 1.4558 loss)
I0522 03:53:04.333063  6507 sgd_solver.cpp:106] Iteration 261750, lr = 0.0035
I0522 03:53:16.436944  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_262500.caffemodel
I0522 03:53:42.887727  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_262500.solverstate
I0522 03:53:43.074770  6507 solver.cpp:237] Iteration 262500, loss = 1.14067
I0522 03:53:43.074826  6507 solver.cpp:253]     Train net output #0: loss = 1.14067 (* 1 = 1.14067 loss)
I0522 03:53:43.074841  6507 sgd_solver.cpp:106] Iteration 262500, lr = 0.0035
I0522 03:53:55.206194  6507 solver.cpp:237] Iteration 263250, loss = 1.01596
I0522 03:53:55.206382  6507 solver.cpp:253]     Train net output #0: loss = 1.01596 (* 1 = 1.01596 loss)
I0522 03:53:55.206395  6507 sgd_solver.cpp:106] Iteration 263250, lr = 0.0035
I0522 03:54:07.368017  6507 solver.cpp:237] Iteration 264000, loss = 1.08542
I0522 03:54:07.368054  6507 solver.cpp:253]     Train net output #0: loss = 1.08542 (* 1 = 1.08542 loss)
I0522 03:54:07.368068  6507 sgd_solver.cpp:106] Iteration 264000, lr = 0.0035
I0522 03:54:19.514587  6507 solver.cpp:237] Iteration 264750, loss = 1.12007
I0522 03:54:19.514636  6507 solver.cpp:253]     Train net output #0: loss = 1.12007 (* 1 = 1.12007 loss)
I0522 03:54:19.514652  6507 sgd_solver.cpp:106] Iteration 264750, lr = 0.0035
I0522 03:54:52.552372  6507 solver.cpp:237] Iteration 265500, loss = 0.631426
I0522 03:54:52.552563  6507 solver.cpp:253]     Train net output #0: loss = 0.631427 (* 1 = 0.631427 loss)
I0522 03:54:52.552577  6507 sgd_solver.cpp:106] Iteration 265500, lr = 0.0035
I0522 03:55:04.668184  6507 solver.cpp:237] Iteration 266250, loss = 0.937211
I0522 03:55:04.668221  6507 solver.cpp:253]     Train net output #0: loss = 0.937212 (* 1 = 0.937212 loss)
I0522 03:55:04.668236  6507 sgd_solver.cpp:106] Iteration 266250, lr = 0.0035
I0522 03:55:16.800663  6507 solver.cpp:237] Iteration 267000, loss = 1.68964
I0522 03:55:16.800710  6507 solver.cpp:253]     Train net output #0: loss = 1.68964 (* 1 = 1.68964 loss)
I0522 03:55:16.800724  6507 sgd_solver.cpp:106] Iteration 267000, lr = 0.0035
I0522 03:55:28.944265  6507 solver.cpp:237] Iteration 267750, loss = 1.06718
I0522 03:55:28.944437  6507 solver.cpp:253]     Train net output #0: loss = 1.06718 (* 1 = 1.06718 loss)
I0522 03:55:28.944449  6507 sgd_solver.cpp:106] Iteration 267750, lr = 0.0035
I0522 03:55:41.089390  6507 solver.cpp:237] Iteration 268500, loss = 0.896053
I0522 03:55:41.089434  6507 solver.cpp:253]     Train net output #0: loss = 0.896054 (* 1 = 0.896054 loss)
I0522 03:55:41.089448  6507 sgd_solver.cpp:106] Iteration 268500, lr = 0.0035
I0522 03:55:53.232637  6507 solver.cpp:237] Iteration 269250, loss = 0.726619
I0522 03:55:53.232674  6507 solver.cpp:253]     Train net output #0: loss = 0.72662 (* 1 = 0.72662 loss)
I0522 03:55:53.232688  6507 sgd_solver.cpp:106] Iteration 269250, lr = 0.0035
I0522 03:56:05.342365  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_270000.caffemodel
I0522 03:56:05.393968  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_270000.solverstate
I0522 03:56:05.421244  6507 solver.cpp:341] Iteration 270000, Testing net (#0)
I0522 03:57:18.330366  6507 solver.cpp:409]     Test net output #0: accuracy = 0.900733
I0522 03:57:18.330554  6507 solver.cpp:409]     Test net output #1: loss = 0.342191 (* 1 = 0.342191 loss)
I0522 03:57:39.199126  6507 solver.cpp:237] Iteration 270000, loss = 1.10978
I0522 03:57:39.199179  6507 solver.cpp:253]     Train net output #0: loss = 1.10978 (* 1 = 1.10978 loss)
I0522 03:57:39.199195  6507 sgd_solver.cpp:106] Iteration 270000, lr = 0.0035
I0522 03:57:51.377560  6507 solver.cpp:237] Iteration 270750, loss = 0.903028
I0522 03:57:51.377749  6507 solver.cpp:253]     Train net output #0: loss = 0.903028 (* 1 = 0.903028 loss)
I0522 03:57:51.377764  6507 sgd_solver.cpp:106] Iteration 270750, lr = 0.0035
I0522 03:58:03.572525  6507 solver.cpp:237] Iteration 271500, loss = 1.63937
I0522 03:58:03.572564  6507 solver.cpp:253]     Train net output #0: loss = 1.63937 (* 1 = 1.63937 loss)
I0522 03:58:03.572579  6507 sgd_solver.cpp:106] Iteration 271500, lr = 0.0035
I0522 03:58:15.802989  6507 solver.cpp:237] Iteration 272250, loss = 1.07611
I0522 03:58:15.803025  6507 solver.cpp:253]     Train net output #0: loss = 1.07611 (* 1 = 1.07611 loss)
I0522 03:58:15.803040  6507 sgd_solver.cpp:106] Iteration 272250, lr = 0.0035
I0522 03:58:27.993458  6507 solver.cpp:237] Iteration 273000, loss = 1.27347
I0522 03:58:27.993638  6507 solver.cpp:253]     Train net output #0: loss = 1.27347 (* 1 = 1.27347 loss)
I0522 03:58:27.993651  6507 sgd_solver.cpp:106] Iteration 273000, lr = 0.0035
I0522 03:58:40.217792  6507 solver.cpp:237] Iteration 273750, loss = 1.09281
I0522 03:58:40.217828  6507 solver.cpp:253]     Train net output #0: loss = 1.09281 (* 1 = 1.09281 loss)
I0522 03:58:40.217844  6507 sgd_solver.cpp:106] Iteration 273750, lr = 0.0035
I0522 03:58:52.471734  6507 solver.cpp:237] Iteration 274500, loss = 1.36703
I0522 03:58:52.471778  6507 solver.cpp:253]     Train net output #0: loss = 1.36703 (* 1 = 1.36703 loss)
I0522 03:58:52.471792  6507 sgd_solver.cpp:106] Iteration 274500, lr = 0.0035
I0522 03:59:25.538038  6507 solver.cpp:237] Iteration 275250, loss = 1.20772
I0522 03:59:25.538228  6507 solver.cpp:253]     Train net output #0: loss = 1.20772 (* 1 = 1.20772 loss)
I0522 03:59:25.538241  6507 sgd_solver.cpp:106] Iteration 275250, lr = 0.0035
I0522 03:59:37.708051  6507 solver.cpp:237] Iteration 276000, loss = 0.728864
I0522 03:59:37.708087  6507 solver.cpp:253]     Train net output #0: loss = 0.728865 (* 1 = 0.728865 loss)
I0522 03:59:37.708102  6507 sgd_solver.cpp:106] Iteration 276000, lr = 0.0035
I0522 03:59:49.889606  6507 solver.cpp:237] Iteration 276750, loss = 1.21982
I0522 03:59:49.889652  6507 solver.cpp:253]     Train net output #0: loss = 1.21982 (* 1 = 1.21982 loss)
I0522 03:59:49.889665  6507 sgd_solver.cpp:106] Iteration 276750, lr = 0.0035
I0522 04:00:02.056783  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_277500.caffemodel
I0522 04:00:02.105805  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_277500.solverstate
I0522 04:00:02.135784  6507 solver.cpp:237] Iteration 277500, loss = 1.88187
I0522 04:00:02.135826  6507 solver.cpp:253]     Train net output #0: loss = 1.88187 (* 1 = 1.88187 loss)
I0522 04:00:02.135840  6507 sgd_solver.cpp:106] Iteration 277500, lr = 0.0035
I0522 04:00:14.330493  6507 solver.cpp:237] Iteration 278250, loss = 1.35291
I0522 04:00:14.330541  6507 solver.cpp:253]     Train net output #0: loss = 1.35291 (* 1 = 1.35291 loss)
I0522 04:00:14.330555  6507 sgd_solver.cpp:106] Iteration 278250, lr = 0.0035
I0522 04:00:26.516077  6507 solver.cpp:237] Iteration 279000, loss = 1.07727
I0522 04:00:26.516113  6507 solver.cpp:253]     Train net output #0: loss = 1.07727 (* 1 = 1.07727 loss)
I0522 04:00:26.516127  6507 sgd_solver.cpp:106] Iteration 279000, lr = 0.0035
I0522 04:00:38.718742  6507 solver.cpp:237] Iteration 279750, loss = 1.01975
I0522 04:00:38.718933  6507 solver.cpp:253]     Train net output #0: loss = 1.01975 (* 1 = 1.01975 loss)
I0522 04:00:38.718948  6507 sgd_solver.cpp:106] Iteration 279750, lr = 0.0035
I0522 04:01:11.800060  6507 solver.cpp:237] Iteration 280500, loss = 1.47384
I0522 04:01:11.800252  6507 solver.cpp:253]     Train net output #0: loss = 1.47384 (* 1 = 1.47384 loss)
I0522 04:01:11.800266  6507 sgd_solver.cpp:106] Iteration 280500, lr = 0.0035
I0522 04:01:23.991096  6507 solver.cpp:237] Iteration 281250, loss = 1.14614
I0522 04:01:23.991137  6507 solver.cpp:253]     Train net output #0: loss = 1.14614 (* 1 = 1.14614 loss)
I0522 04:01:23.991156  6507 sgd_solver.cpp:106] Iteration 281250, lr = 0.0035
I0522 04:01:36.143923  6507 solver.cpp:237] Iteration 282000, loss = 0.899361
I0522 04:01:36.143960  6507 solver.cpp:253]     Train net output #0: loss = 0.899361 (* 1 = 0.899361 loss)
I0522 04:01:36.143975  6507 sgd_solver.cpp:106] Iteration 282000, lr = 0.0035
I0522 04:01:48.314514  6507 solver.cpp:237] Iteration 282750, loss = 1.12386
I0522 04:01:48.314710  6507 solver.cpp:253]     Train net output #0: loss = 1.12386 (* 1 = 1.12386 loss)
I0522 04:01:48.314724  6507 sgd_solver.cpp:106] Iteration 282750, lr = 0.0035
I0522 04:02:00.479368  6507 solver.cpp:237] Iteration 283500, loss = 0.994752
I0522 04:02:00.479405  6507 solver.cpp:253]     Train net output #0: loss = 0.994753 (* 1 = 0.994753 loss)
I0522 04:02:00.479420  6507 sgd_solver.cpp:106] Iteration 283500, lr = 0.0035
I0522 04:02:12.642141  6507 solver.cpp:237] Iteration 284250, loss = 1.6053
I0522 04:02:12.642184  6507 solver.cpp:253]     Train net output #0: loss = 1.6053 (* 1 = 1.6053 loss)
I0522 04:02:12.642199  6507 sgd_solver.cpp:106] Iteration 284250, lr = 0.0035
I0522 04:02:24.773826  6507 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_285000.caffemodel
I0522 04:02:24.822875  6507 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0035_2016-05-20T15.48.55.766925_iter_285000.solverstate
I0522 04:02:24.848192  6507 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 04:03:16.480029  6507 solver.cpp:409]     Test net output #0: accuracy = 0.895017
I0522 04:03:16.480219  6507 solver.cpp:409]     Test net output #1: loss = 0.344424 (* 1 = 0.344424 loss)
I0522 04:03:37.369566  6507 solver.cpp:237] Iteration 285000, loss = 1.11928
I0522 04:03:37.369621  6507 solver.cpp:253]     Train net output #0: loss = 1.11928 (* 1 = 1.11928 loss)
I0522 04:03:37.369635  6507 sgd_solver.cpp:106] Iteration 285000, lr = 0.0035
I0522 04:03:49.528033  6507 solver.cpp:237] Iteration 285750, loss = 0.751889
I0522 04:03:49.528214  6507 solver.cpp:253]     Train net output #0: loss = 0.751889 (* 1 = 0.751889 loss)
I0522 04:03:49.528229  6507 sgd_solver.cpp:106] Iteration 285750, lr = 0.0035
I0522 04:04:01.693531  6507 solver.cpp:237] Iteration 286500, loss = 0.899823
I0522 04:04:01.693578  6507 solver.cpp:253]     Train net output #0: loss = 0.899823 (* 1 = 0.899823 loss)
I0522 04:04:01.693593  6507 sgd_solver.cpp:106] Iteration 286500, lr = 0.0035
I0522 04:04:13.801178  6507 solver.cpp:237] Iteration 287250, loss = 0.740171
I0522 04:04:13.801215  6507 solver.cpp:253]     Train net output #0: loss = 0.740172 (* 1 = 0.740172 loss)
I0522 04:04:13.801230  6507 sgd_solver.cpp:106] Iteration 287250, lr = 0.0035
I0522 04:04:25.944471  6507 solver.cpp:237] Iteration 288000, loss = 1.45555
I0522 04:04:25.944658  6507 solver.cpp:253]     Train net output #0: loss = 1.45555 (* 1 = 1.45555 loss)
I0522 04:04:25.944671  6507 sgd_solver.cpp:106] Iteration 288000, lr = 0.0035
I0522 04:04:38.073673  6507 solver.cpp:237] Iteration 288750, loss = 1.13105
I0522 04:04:38.073709  6507 solver.cpp:253]     Train net output #0: loss = 1.13105 (* 1 = 1.13105 loss)
I0522 04:04:38.073724  6507 sgd_solver.cpp:106] Iteration 288750, lr = 0.0035
I0522 04:04:50.223529  6507 solver.cpp:237] Iteration 289500, loss = 0.971583
I0522 04:04:50.223577  6507 solver.cpp:253]     Train net output #0: loss = 0.971583 (* 1 = 0.971583 loss)
I0522 04:04:50.223590  6507 sgd_solver.cpp:106] Iteration 289500, lr = 0.0035
aprun: Apid 11244392: Caught signal Terminated, sending to application
*** Aborted at 1463904301 (unix time) try "date -d @1463904301" if you are using GNU date ***
aprun: Apid 11244392: Caught signal Terminated, sending to application
PC: @     0x2aaab12a30c6 H5D__select_io
aprun: Apid 11244392: Caught signal Terminated, sending to application
*** SIGTERM (@0x1968) received by PID 6507 (TID 0x2aaac746f900) from PID 6504; stack trace: ***
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @     0x2aaab12a30c6 H5D__select_io
    @     0x2aaab12a38cd H5D__select_read
    @     0x2aaab128be3d H5D__chunk_read
=>> PBS: job killed: walltime 7222 exceeded limit 7200
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11244392: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
aprun: Apid 11244392: Caught signal Terminated, sending to application
