2808439
I0523 12:18:44.585938  1495 caffe.cpp:184] Using GPUs 0
I0523 12:18:45.012213  1495 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.001
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977.prototxt"
I0523 12:18:45.014521  1495 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977.prototxt
I0523 12:18:45.031131  1495 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 12:18:45.031189  1495 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 12:18:45.031535  1495 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 12:18:45.031723  1495 layer_factory.hpp:77] Creating layer data_hdf5
I0523 12:18:45.031747  1495 net.cpp:106] Creating Layer data_hdf5
I0523 12:18:45.031762  1495 net.cpp:411] data_hdf5 -> data
I0523 12:18:45.031795  1495 net.cpp:411] data_hdf5 -> label
I0523 12:18:45.031827  1495 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 12:18:45.046922  1495 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 12:18:45.049290  1495 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 12:19:06.622313  1495 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 12:19:06.627565  1495 net.cpp:150] Setting up data_hdf5
I0523 12:19:06.627605  1495 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 12:19:06.627620  1495 net.cpp:157] Top shape: 60 (60)
I0523 12:19:06.627632  1495 net.cpp:165] Memory required for data: 1524240
I0523 12:19:06.627645  1495 layer_factory.hpp:77] Creating layer conv1
I0523 12:19:06.627679  1495 net.cpp:106] Creating Layer conv1
I0523 12:19:06.627691  1495 net.cpp:454] conv1 <- data
I0523 12:19:06.627712  1495 net.cpp:411] conv1 -> conv1
I0523 12:19:08.076745  1495 net.cpp:150] Setting up conv1
I0523 12:19:08.076786  1495 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 12:19:08.076797  1495 net.cpp:165] Memory required for data: 18113040
I0523 12:19:08.076825  1495 layer_factory.hpp:77] Creating layer relu1
I0523 12:19:08.076848  1495 net.cpp:106] Creating Layer relu1
I0523 12:19:08.076858  1495 net.cpp:454] relu1 <- conv1
I0523 12:19:08.076871  1495 net.cpp:397] relu1 -> conv1 (in-place)
I0523 12:19:08.077389  1495 net.cpp:150] Setting up relu1
I0523 12:19:08.077406  1495 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 12:19:08.077416  1495 net.cpp:165] Memory required for data: 34701840
I0523 12:19:08.077426  1495 layer_factory.hpp:77] Creating layer pool1
I0523 12:19:08.077443  1495 net.cpp:106] Creating Layer pool1
I0523 12:19:08.077453  1495 net.cpp:454] pool1 <- conv1
I0523 12:19:08.077466  1495 net.cpp:411] pool1 -> pool1
I0523 12:19:08.077558  1495 net.cpp:150] Setting up pool1
I0523 12:19:08.077572  1495 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 12:19:08.077582  1495 net.cpp:165] Memory required for data: 42996240
I0523 12:19:08.077594  1495 layer_factory.hpp:77] Creating layer conv2
I0523 12:19:08.077615  1495 net.cpp:106] Creating Layer conv2
I0523 12:19:08.077625  1495 net.cpp:454] conv2 <- pool1
I0523 12:19:08.077639  1495 net.cpp:411] conv2 -> conv2
I0523 12:19:08.080391  1495 net.cpp:150] Setting up conv2
I0523 12:19:08.080420  1495 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 12:19:08.080430  1495 net.cpp:165] Memory required for data: 54919440
I0523 12:19:08.080448  1495 layer_factory.hpp:77] Creating layer relu2
I0523 12:19:08.080463  1495 net.cpp:106] Creating Layer relu2
I0523 12:19:08.080473  1495 net.cpp:454] relu2 <- conv2
I0523 12:19:08.080485  1495 net.cpp:397] relu2 -> conv2 (in-place)
I0523 12:19:08.080816  1495 net.cpp:150] Setting up relu2
I0523 12:19:08.080831  1495 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 12:19:08.080842  1495 net.cpp:165] Memory required for data: 66842640
I0523 12:19:08.080852  1495 layer_factory.hpp:77] Creating layer pool2
I0523 12:19:08.080864  1495 net.cpp:106] Creating Layer pool2
I0523 12:19:08.080874  1495 net.cpp:454] pool2 <- conv2
I0523 12:19:08.080886  1495 net.cpp:411] pool2 -> pool2
I0523 12:19:08.080967  1495 net.cpp:150] Setting up pool2
I0523 12:19:08.080981  1495 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 12:19:08.080991  1495 net.cpp:165] Memory required for data: 72804240
I0523 12:19:08.080998  1495 layer_factory.hpp:77] Creating layer conv3
I0523 12:19:08.081017  1495 net.cpp:106] Creating Layer conv3
I0523 12:19:08.081027  1495 net.cpp:454] conv3 <- pool2
I0523 12:19:08.081042  1495 net.cpp:411] conv3 -> conv3
I0523 12:19:08.082993  1495 net.cpp:150] Setting up conv3
I0523 12:19:08.083015  1495 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 12:19:08.083029  1495 net.cpp:165] Memory required for data: 79309200
I0523 12:19:08.083046  1495 layer_factory.hpp:77] Creating layer relu3
I0523 12:19:08.083063  1495 net.cpp:106] Creating Layer relu3
I0523 12:19:08.083073  1495 net.cpp:454] relu3 <- conv3
I0523 12:19:08.083086  1495 net.cpp:397] relu3 -> conv3 (in-place)
I0523 12:19:08.083554  1495 net.cpp:150] Setting up relu3
I0523 12:19:08.083572  1495 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 12:19:08.083582  1495 net.cpp:165] Memory required for data: 85814160
I0523 12:19:08.083595  1495 layer_factory.hpp:77] Creating layer pool3
I0523 12:19:08.083607  1495 net.cpp:106] Creating Layer pool3
I0523 12:19:08.083617  1495 net.cpp:454] pool3 <- conv3
I0523 12:19:08.083631  1495 net.cpp:411] pool3 -> pool3
I0523 12:19:08.083698  1495 net.cpp:150] Setting up pool3
I0523 12:19:08.083711  1495 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 12:19:08.083720  1495 net.cpp:165] Memory required for data: 89066640
I0523 12:19:08.083729  1495 layer_factory.hpp:77] Creating layer conv4
I0523 12:19:08.083746  1495 net.cpp:106] Creating Layer conv4
I0523 12:19:08.083756  1495 net.cpp:454] conv4 <- pool3
I0523 12:19:08.083770  1495 net.cpp:411] conv4 -> conv4
I0523 12:19:08.086539  1495 net.cpp:150] Setting up conv4
I0523 12:19:08.086567  1495 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 12:19:08.086580  1495 net.cpp:165] Memory required for data: 91243920
I0523 12:19:08.086596  1495 layer_factory.hpp:77] Creating layer relu4
I0523 12:19:08.086609  1495 net.cpp:106] Creating Layer relu4
I0523 12:19:08.086621  1495 net.cpp:454] relu4 <- conv4
I0523 12:19:08.086633  1495 net.cpp:397] relu4 -> conv4 (in-place)
I0523 12:19:08.087102  1495 net.cpp:150] Setting up relu4
I0523 12:19:08.087119  1495 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 12:19:08.087129  1495 net.cpp:165] Memory required for data: 93421200
I0523 12:19:08.087141  1495 layer_factory.hpp:77] Creating layer pool4
I0523 12:19:08.087154  1495 net.cpp:106] Creating Layer pool4
I0523 12:19:08.087164  1495 net.cpp:454] pool4 <- conv4
I0523 12:19:08.087177  1495 net.cpp:411] pool4 -> pool4
I0523 12:19:08.087245  1495 net.cpp:150] Setting up pool4
I0523 12:19:08.087260  1495 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 12:19:08.087270  1495 net.cpp:165] Memory required for data: 94509840
I0523 12:19:08.087280  1495 layer_factory.hpp:77] Creating layer ip1
I0523 12:19:08.087298  1495 net.cpp:106] Creating Layer ip1
I0523 12:19:08.087308  1495 net.cpp:454] ip1 <- pool4
I0523 12:19:08.087322  1495 net.cpp:411] ip1 -> ip1
I0523 12:19:08.102746  1495 net.cpp:150] Setting up ip1
I0523 12:19:08.102774  1495 net.cpp:157] Top shape: 60 196 (11760)
I0523 12:19:08.102787  1495 net.cpp:165] Memory required for data: 94556880
I0523 12:19:08.102809  1495 layer_factory.hpp:77] Creating layer relu5
I0523 12:19:08.102824  1495 net.cpp:106] Creating Layer relu5
I0523 12:19:08.102835  1495 net.cpp:454] relu5 <- ip1
I0523 12:19:08.102849  1495 net.cpp:397] relu5 -> ip1 (in-place)
I0523 12:19:08.103191  1495 net.cpp:150] Setting up relu5
I0523 12:19:08.103205  1495 net.cpp:157] Top shape: 60 196 (11760)
I0523 12:19:08.103216  1495 net.cpp:165] Memory required for data: 94603920
I0523 12:19:08.103226  1495 layer_factory.hpp:77] Creating layer drop1
I0523 12:19:08.103250  1495 net.cpp:106] Creating Layer drop1
I0523 12:19:08.103260  1495 net.cpp:454] drop1 <- ip1
I0523 12:19:08.103273  1495 net.cpp:397] drop1 -> ip1 (in-place)
I0523 12:19:08.103332  1495 net.cpp:150] Setting up drop1
I0523 12:19:08.103345  1495 net.cpp:157] Top shape: 60 196 (11760)
I0523 12:19:08.103355  1495 net.cpp:165] Memory required for data: 94650960
I0523 12:19:08.103366  1495 layer_factory.hpp:77] Creating layer ip2
I0523 12:19:08.103384  1495 net.cpp:106] Creating Layer ip2
I0523 12:19:08.103394  1495 net.cpp:454] ip2 <- ip1
I0523 12:19:08.103409  1495 net.cpp:411] ip2 -> ip2
I0523 12:19:08.103870  1495 net.cpp:150] Setting up ip2
I0523 12:19:08.103883  1495 net.cpp:157] Top shape: 60 98 (5880)
I0523 12:19:08.103893  1495 net.cpp:165] Memory required for data: 94674480
I0523 12:19:08.103909  1495 layer_factory.hpp:77] Creating layer relu6
I0523 12:19:08.103921  1495 net.cpp:106] Creating Layer relu6
I0523 12:19:08.103930  1495 net.cpp:454] relu6 <- ip2
I0523 12:19:08.103943  1495 net.cpp:397] relu6 -> ip2 (in-place)
I0523 12:19:08.104460  1495 net.cpp:150] Setting up relu6
I0523 12:19:08.104475  1495 net.cpp:157] Top shape: 60 98 (5880)
I0523 12:19:08.104485  1495 net.cpp:165] Memory required for data: 94698000
I0523 12:19:08.104496  1495 layer_factory.hpp:77] Creating layer drop2
I0523 12:19:08.104509  1495 net.cpp:106] Creating Layer drop2
I0523 12:19:08.104518  1495 net.cpp:454] drop2 <- ip2
I0523 12:19:08.104532  1495 net.cpp:397] drop2 -> ip2 (in-place)
I0523 12:19:08.104573  1495 net.cpp:150] Setting up drop2
I0523 12:19:08.104586  1495 net.cpp:157] Top shape: 60 98 (5880)
I0523 12:19:08.104598  1495 net.cpp:165] Memory required for data: 94721520
I0523 12:19:08.104607  1495 layer_factory.hpp:77] Creating layer ip3
I0523 12:19:08.104621  1495 net.cpp:106] Creating Layer ip3
I0523 12:19:08.104630  1495 net.cpp:454] ip3 <- ip2
I0523 12:19:08.104643  1495 net.cpp:411] ip3 -> ip3
I0523 12:19:08.104853  1495 net.cpp:150] Setting up ip3
I0523 12:19:08.104866  1495 net.cpp:157] Top shape: 60 11 (660)
I0523 12:19:08.104877  1495 net.cpp:165] Memory required for data: 94724160
I0523 12:19:08.104892  1495 layer_factory.hpp:77] Creating layer drop3
I0523 12:19:08.104905  1495 net.cpp:106] Creating Layer drop3
I0523 12:19:08.104914  1495 net.cpp:454] drop3 <- ip3
I0523 12:19:08.104926  1495 net.cpp:397] drop3 -> ip3 (in-place)
I0523 12:19:08.104966  1495 net.cpp:150] Setting up drop3
I0523 12:19:08.104979  1495 net.cpp:157] Top shape: 60 11 (660)
I0523 12:19:08.104990  1495 net.cpp:165] Memory required for data: 94726800
I0523 12:19:08.105000  1495 layer_factory.hpp:77] Creating layer loss
I0523 12:19:08.105018  1495 net.cpp:106] Creating Layer loss
I0523 12:19:08.105028  1495 net.cpp:454] loss <- ip3
I0523 12:19:08.105039  1495 net.cpp:454] loss <- label
I0523 12:19:08.105051  1495 net.cpp:411] loss -> loss
I0523 12:19:08.105067  1495 layer_factory.hpp:77] Creating layer loss
I0523 12:19:08.105718  1495 net.cpp:150] Setting up loss
I0523 12:19:08.105739  1495 net.cpp:157] Top shape: (1)
I0523 12:19:08.105753  1495 net.cpp:160]     with loss weight 1
I0523 12:19:08.105797  1495 net.cpp:165] Memory required for data: 94726804
I0523 12:19:08.105808  1495 net.cpp:226] loss needs backward computation.
I0523 12:19:08.105818  1495 net.cpp:226] drop3 needs backward computation.
I0523 12:19:08.105828  1495 net.cpp:226] ip3 needs backward computation.
I0523 12:19:08.105840  1495 net.cpp:226] drop2 needs backward computation.
I0523 12:19:08.105850  1495 net.cpp:226] relu6 needs backward computation.
I0523 12:19:08.105859  1495 net.cpp:226] ip2 needs backward computation.
I0523 12:19:08.105870  1495 net.cpp:226] drop1 needs backward computation.
I0523 12:19:08.105880  1495 net.cpp:226] relu5 needs backward computation.
I0523 12:19:08.105890  1495 net.cpp:226] ip1 needs backward computation.
I0523 12:19:08.105900  1495 net.cpp:226] pool4 needs backward computation.
I0523 12:19:08.105911  1495 net.cpp:226] relu4 needs backward computation.
I0523 12:19:08.105919  1495 net.cpp:226] conv4 needs backward computation.
I0523 12:19:08.105931  1495 net.cpp:226] pool3 needs backward computation.
I0523 12:19:08.105940  1495 net.cpp:226] relu3 needs backward computation.
I0523 12:19:08.105950  1495 net.cpp:226] conv3 needs backward computation.
I0523 12:19:08.105970  1495 net.cpp:226] pool2 needs backward computation.
I0523 12:19:08.105981  1495 net.cpp:226] relu2 needs backward computation.
I0523 12:19:08.105991  1495 net.cpp:226] conv2 needs backward computation.
I0523 12:19:08.106001  1495 net.cpp:226] pool1 needs backward computation.
I0523 12:19:08.106011  1495 net.cpp:226] relu1 needs backward computation.
I0523 12:19:08.106021  1495 net.cpp:226] conv1 needs backward computation.
I0523 12:19:08.106032  1495 net.cpp:228] data_hdf5 does not need backward computation.
I0523 12:19:08.106042  1495 net.cpp:270] This network produces output loss
I0523 12:19:08.106066  1495 net.cpp:283] Network initialization done.
I0523 12:19:08.107774  1495 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977.prototxt
I0523 12:19:08.107846  1495 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 12:19:08.108203  1495 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 12:19:08.108392  1495 layer_factory.hpp:77] Creating layer data_hdf5
I0523 12:19:08.108407  1495 net.cpp:106] Creating Layer data_hdf5
I0523 12:19:08.108418  1495 net.cpp:411] data_hdf5 -> data
I0523 12:19:08.108434  1495 net.cpp:411] data_hdf5 -> label
I0523 12:19:08.108450  1495 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 12:19:08.109685  1495 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 12:19:29.521983  1495 net.cpp:150] Setting up data_hdf5
I0523 12:19:29.522148  1495 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 12:19:29.522162  1495 net.cpp:157] Top shape: 60 (60)
I0523 12:19:29.522172  1495 net.cpp:165] Memory required for data: 1524240
I0523 12:19:29.522186  1495 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 12:19:29.522215  1495 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 12:19:29.522227  1495 net.cpp:454] label_data_hdf5_1_split <- label
I0523 12:19:29.522240  1495 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 12:19:29.522263  1495 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 12:19:29.522335  1495 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 12:19:29.522348  1495 net.cpp:157] Top shape: 60 (60)
I0523 12:19:29.522359  1495 net.cpp:157] Top shape: 60 (60)
I0523 12:19:29.522369  1495 net.cpp:165] Memory required for data: 1524720
I0523 12:19:29.522379  1495 layer_factory.hpp:77] Creating layer conv1
I0523 12:19:29.522402  1495 net.cpp:106] Creating Layer conv1
I0523 12:19:29.522411  1495 net.cpp:454] conv1 <- data
I0523 12:19:29.522425  1495 net.cpp:411] conv1 -> conv1
I0523 12:19:29.524364  1495 net.cpp:150] Setting up conv1
I0523 12:19:29.524389  1495 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 12:19:29.524399  1495 net.cpp:165] Memory required for data: 18113520
I0523 12:19:29.524420  1495 layer_factory.hpp:77] Creating layer relu1
I0523 12:19:29.524435  1495 net.cpp:106] Creating Layer relu1
I0523 12:19:29.524444  1495 net.cpp:454] relu1 <- conv1
I0523 12:19:29.524457  1495 net.cpp:397] relu1 -> conv1 (in-place)
I0523 12:19:29.524951  1495 net.cpp:150] Setting up relu1
I0523 12:19:29.524967  1495 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 12:19:29.524977  1495 net.cpp:165] Memory required for data: 34702320
I0523 12:19:29.524986  1495 layer_factory.hpp:77] Creating layer pool1
I0523 12:19:29.525003  1495 net.cpp:106] Creating Layer pool1
I0523 12:19:29.525012  1495 net.cpp:454] pool1 <- conv1
I0523 12:19:29.525025  1495 net.cpp:411] pool1 -> pool1
I0523 12:19:29.525099  1495 net.cpp:150] Setting up pool1
I0523 12:19:29.525112  1495 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 12:19:29.525122  1495 net.cpp:165] Memory required for data: 42996720
I0523 12:19:29.525132  1495 layer_factory.hpp:77] Creating layer conv2
I0523 12:19:29.525151  1495 net.cpp:106] Creating Layer conv2
I0523 12:19:29.525161  1495 net.cpp:454] conv2 <- pool1
I0523 12:19:29.525176  1495 net.cpp:411] conv2 -> conv2
I0523 12:19:29.527089  1495 net.cpp:150] Setting up conv2
I0523 12:19:29.527112  1495 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 12:19:29.527123  1495 net.cpp:165] Memory required for data: 54919920
I0523 12:19:29.527140  1495 layer_factory.hpp:77] Creating layer relu2
I0523 12:19:29.527153  1495 net.cpp:106] Creating Layer relu2
I0523 12:19:29.527163  1495 net.cpp:454] relu2 <- conv2
I0523 12:19:29.527176  1495 net.cpp:397] relu2 -> conv2 (in-place)
I0523 12:19:29.527506  1495 net.cpp:150] Setting up relu2
I0523 12:19:29.527520  1495 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 12:19:29.527530  1495 net.cpp:165] Memory required for data: 66843120
I0523 12:19:29.527539  1495 layer_factory.hpp:77] Creating layer pool2
I0523 12:19:29.527552  1495 net.cpp:106] Creating Layer pool2
I0523 12:19:29.527562  1495 net.cpp:454] pool2 <- conv2
I0523 12:19:29.527575  1495 net.cpp:411] pool2 -> pool2
I0523 12:19:29.527645  1495 net.cpp:150] Setting up pool2
I0523 12:19:29.527658  1495 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 12:19:29.527667  1495 net.cpp:165] Memory required for data: 72804720
I0523 12:19:29.527678  1495 layer_factory.hpp:77] Creating layer conv3
I0523 12:19:29.527696  1495 net.cpp:106] Creating Layer conv3
I0523 12:19:29.527706  1495 net.cpp:454] conv3 <- pool2
I0523 12:19:29.527717  1495 net.cpp:411] conv3 -> conv3
I0523 12:19:29.529685  1495 net.cpp:150] Setting up conv3
I0523 12:19:29.529707  1495 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 12:19:29.529717  1495 net.cpp:165] Memory required for data: 79309680
I0523 12:19:29.529749  1495 layer_factory.hpp:77] Creating layer relu3
I0523 12:19:29.529762  1495 net.cpp:106] Creating Layer relu3
I0523 12:19:29.529772  1495 net.cpp:454] relu3 <- conv3
I0523 12:19:29.529785  1495 net.cpp:397] relu3 -> conv3 (in-place)
I0523 12:19:29.530253  1495 net.cpp:150] Setting up relu3
I0523 12:19:29.530269  1495 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 12:19:29.530280  1495 net.cpp:165] Memory required for data: 85814640
I0523 12:19:29.530289  1495 layer_factory.hpp:77] Creating layer pool3
I0523 12:19:29.530303  1495 net.cpp:106] Creating Layer pool3
I0523 12:19:29.530311  1495 net.cpp:454] pool3 <- conv3
I0523 12:19:29.530324  1495 net.cpp:411] pool3 -> pool3
I0523 12:19:29.530395  1495 net.cpp:150] Setting up pool3
I0523 12:19:29.530408  1495 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 12:19:29.530417  1495 net.cpp:165] Memory required for data: 89067120
I0523 12:19:29.530427  1495 layer_factory.hpp:77] Creating layer conv4
I0523 12:19:29.530443  1495 net.cpp:106] Creating Layer conv4
I0523 12:19:29.530453  1495 net.cpp:454] conv4 <- pool3
I0523 12:19:29.530465  1495 net.cpp:411] conv4 -> conv4
I0523 12:19:29.532552  1495 net.cpp:150] Setting up conv4
I0523 12:19:29.532568  1495 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 12:19:29.532578  1495 net.cpp:165] Memory required for data: 91244400
I0523 12:19:29.532595  1495 layer_factory.hpp:77] Creating layer relu4
I0523 12:19:29.532608  1495 net.cpp:106] Creating Layer relu4
I0523 12:19:29.532618  1495 net.cpp:454] relu4 <- conv4
I0523 12:19:29.532631  1495 net.cpp:397] relu4 -> conv4 (in-place)
I0523 12:19:29.533102  1495 net.cpp:150] Setting up relu4
I0523 12:19:29.533118  1495 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 12:19:29.533128  1495 net.cpp:165] Memory required for data: 93421680
I0523 12:19:29.533138  1495 layer_factory.hpp:77] Creating layer pool4
I0523 12:19:29.533150  1495 net.cpp:106] Creating Layer pool4
I0523 12:19:29.533160  1495 net.cpp:454] pool4 <- conv4
I0523 12:19:29.533174  1495 net.cpp:411] pool4 -> pool4
I0523 12:19:29.533243  1495 net.cpp:150] Setting up pool4
I0523 12:19:29.533257  1495 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 12:19:29.533265  1495 net.cpp:165] Memory required for data: 94510320
I0523 12:19:29.533275  1495 layer_factory.hpp:77] Creating layer ip1
I0523 12:19:29.533290  1495 net.cpp:106] Creating Layer ip1
I0523 12:19:29.533300  1495 net.cpp:454] ip1 <- pool4
I0523 12:19:29.533313  1495 net.cpp:411] ip1 -> ip1
I0523 12:19:29.548719  1495 net.cpp:150] Setting up ip1
I0523 12:19:29.548748  1495 net.cpp:157] Top shape: 60 196 (11760)
I0523 12:19:29.548763  1495 net.cpp:165] Memory required for data: 94557360
I0523 12:19:29.548784  1495 layer_factory.hpp:77] Creating layer relu5
I0523 12:19:29.548799  1495 net.cpp:106] Creating Layer relu5
I0523 12:19:29.548810  1495 net.cpp:454] relu5 <- ip1
I0523 12:19:29.548825  1495 net.cpp:397] relu5 -> ip1 (in-place)
I0523 12:19:29.549171  1495 net.cpp:150] Setting up relu5
I0523 12:19:29.549186  1495 net.cpp:157] Top shape: 60 196 (11760)
I0523 12:19:29.549196  1495 net.cpp:165] Memory required for data: 94604400
I0523 12:19:29.549206  1495 layer_factory.hpp:77] Creating layer drop1
I0523 12:19:29.549224  1495 net.cpp:106] Creating Layer drop1
I0523 12:19:29.549234  1495 net.cpp:454] drop1 <- ip1
I0523 12:19:29.549247  1495 net.cpp:397] drop1 -> ip1 (in-place)
I0523 12:19:29.549293  1495 net.cpp:150] Setting up drop1
I0523 12:19:29.549305  1495 net.cpp:157] Top shape: 60 196 (11760)
I0523 12:19:29.549315  1495 net.cpp:165] Memory required for data: 94651440
I0523 12:19:29.549325  1495 layer_factory.hpp:77] Creating layer ip2
I0523 12:19:29.549340  1495 net.cpp:106] Creating Layer ip2
I0523 12:19:29.549348  1495 net.cpp:454] ip2 <- ip1
I0523 12:19:29.549362  1495 net.cpp:411] ip2 -> ip2
I0523 12:19:29.549846  1495 net.cpp:150] Setting up ip2
I0523 12:19:29.549860  1495 net.cpp:157] Top shape: 60 98 (5880)
I0523 12:19:29.549870  1495 net.cpp:165] Memory required for data: 94674960
I0523 12:19:29.549883  1495 layer_factory.hpp:77] Creating layer relu6
I0523 12:19:29.549908  1495 net.cpp:106] Creating Layer relu6
I0523 12:19:29.549918  1495 net.cpp:454] relu6 <- ip2
I0523 12:19:29.549931  1495 net.cpp:397] relu6 -> ip2 (in-place)
I0523 12:19:29.550462  1495 net.cpp:150] Setting up relu6
I0523 12:19:29.550477  1495 net.cpp:157] Top shape: 60 98 (5880)
I0523 12:19:29.550487  1495 net.cpp:165] Memory required for data: 94698480
I0523 12:19:29.550499  1495 layer_factory.hpp:77] Creating layer drop2
I0523 12:19:29.550513  1495 net.cpp:106] Creating Layer drop2
I0523 12:19:29.550523  1495 net.cpp:454] drop2 <- ip2
I0523 12:19:29.550535  1495 net.cpp:397] drop2 -> ip2 (in-place)
I0523 12:19:29.550578  1495 net.cpp:150] Setting up drop2
I0523 12:19:29.550591  1495 net.cpp:157] Top shape: 60 98 (5880)
I0523 12:19:29.550601  1495 net.cpp:165] Memory required for data: 94722000
I0523 12:19:29.550611  1495 layer_factory.hpp:77] Creating layer ip3
I0523 12:19:29.550624  1495 net.cpp:106] Creating Layer ip3
I0523 12:19:29.550634  1495 net.cpp:454] ip3 <- ip2
I0523 12:19:29.550648  1495 net.cpp:411] ip3 -> ip3
I0523 12:19:29.550868  1495 net.cpp:150] Setting up ip3
I0523 12:19:29.550881  1495 net.cpp:157] Top shape: 60 11 (660)
I0523 12:19:29.550890  1495 net.cpp:165] Memory required for data: 94724640
I0523 12:19:29.550907  1495 layer_factory.hpp:77] Creating layer drop3
I0523 12:19:29.550920  1495 net.cpp:106] Creating Layer drop3
I0523 12:19:29.550930  1495 net.cpp:454] drop3 <- ip3
I0523 12:19:29.550942  1495 net.cpp:397] drop3 -> ip3 (in-place)
I0523 12:19:29.550983  1495 net.cpp:150] Setting up drop3
I0523 12:19:29.550997  1495 net.cpp:157] Top shape: 60 11 (660)
I0523 12:19:29.551005  1495 net.cpp:165] Memory required for data: 94727280
I0523 12:19:29.551015  1495 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 12:19:29.551028  1495 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 12:19:29.551038  1495 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 12:19:29.551053  1495 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 12:19:29.551066  1495 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 12:19:29.551138  1495 net.cpp:150] Setting up ip3_drop3_0_split
I0523 12:19:29.551151  1495 net.cpp:157] Top shape: 60 11 (660)
I0523 12:19:29.551163  1495 net.cpp:157] Top shape: 60 11 (660)
I0523 12:19:29.551173  1495 net.cpp:165] Memory required for data: 94732560
I0523 12:19:29.551182  1495 layer_factory.hpp:77] Creating layer accuracy
I0523 12:19:29.551203  1495 net.cpp:106] Creating Layer accuracy
I0523 12:19:29.551213  1495 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 12:19:29.551225  1495 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 12:19:29.551237  1495 net.cpp:411] accuracy -> accuracy
I0523 12:19:29.551262  1495 net.cpp:150] Setting up accuracy
I0523 12:19:29.551275  1495 net.cpp:157] Top shape: (1)
I0523 12:19:29.551283  1495 net.cpp:165] Memory required for data: 94732564
I0523 12:19:29.551292  1495 layer_factory.hpp:77] Creating layer loss
I0523 12:19:29.551306  1495 net.cpp:106] Creating Layer loss
I0523 12:19:29.551316  1495 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 12:19:29.551326  1495 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 12:19:29.551340  1495 net.cpp:411] loss -> loss
I0523 12:19:29.551358  1495 layer_factory.hpp:77] Creating layer loss
I0523 12:19:29.551842  1495 net.cpp:150] Setting up loss
I0523 12:19:29.551856  1495 net.cpp:157] Top shape: (1)
I0523 12:19:29.551867  1495 net.cpp:160]     with loss weight 1
I0523 12:19:29.551884  1495 net.cpp:165] Memory required for data: 94732568
I0523 12:19:29.551894  1495 net.cpp:226] loss needs backward computation.
I0523 12:19:29.551905  1495 net.cpp:228] accuracy does not need backward computation.
I0523 12:19:29.551916  1495 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 12:19:29.551926  1495 net.cpp:226] drop3 needs backward computation.
I0523 12:19:29.551935  1495 net.cpp:226] ip3 needs backward computation.
I0523 12:19:29.551944  1495 net.cpp:226] drop2 needs backward computation.
I0523 12:19:29.551954  1495 net.cpp:226] relu6 needs backward computation.
I0523 12:19:29.551971  1495 net.cpp:226] ip2 needs backward computation.
I0523 12:19:29.551981  1495 net.cpp:226] drop1 needs backward computation.
I0523 12:19:29.551991  1495 net.cpp:226] relu5 needs backward computation.
I0523 12:19:29.552000  1495 net.cpp:226] ip1 needs backward computation.
I0523 12:19:29.552011  1495 net.cpp:226] pool4 needs backward computation.
I0523 12:19:29.552021  1495 net.cpp:226] relu4 needs backward computation.
I0523 12:19:29.552031  1495 net.cpp:226] conv4 needs backward computation.
I0523 12:19:29.552039  1495 net.cpp:226] pool3 needs backward computation.
I0523 12:19:29.552050  1495 net.cpp:226] relu3 needs backward computation.
I0523 12:19:29.552059  1495 net.cpp:226] conv3 needs backward computation.
I0523 12:19:29.552069  1495 net.cpp:226] pool2 needs backward computation.
I0523 12:19:29.552079  1495 net.cpp:226] relu2 needs backward computation.
I0523 12:19:29.552089  1495 net.cpp:226] conv2 needs backward computation.
I0523 12:19:29.552099  1495 net.cpp:226] pool1 needs backward computation.
I0523 12:19:29.552108  1495 net.cpp:226] relu1 needs backward computation.
I0523 12:19:29.552117  1495 net.cpp:226] conv1 needs backward computation.
I0523 12:19:29.552129  1495 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 12:19:29.552140  1495 net.cpp:228] data_hdf5 does not need backward computation.
I0523 12:19:29.552150  1495 net.cpp:270] This network produces output accuracy
I0523 12:19:29.552161  1495 net.cpp:270] This network produces output loss
I0523 12:19:29.552191  1495 net.cpp:283] Network initialization done.
I0523 12:19:29.552323  1495 solver.cpp:60] Solver scaffolding done.
I0523 12:19:29.553447  1495 caffe.cpp:212] Starting Optimization
I0523 12:19:29.553465  1495 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 12:19:29.553480  1495 solver.cpp:289] Learning Rate Policy: fixed
I0523 12:19:29.554702  1495 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 12:20:17.765612  1495 solver.cpp:409]     Test net output #0: accuracy = 0.049307
I0523 12:20:17.765771  1495 solver.cpp:409]     Test net output #1: loss = 2.39905 (* 1 = 2.39905 loss)
I0523 12:20:17.791689  1495 solver.cpp:237] Iteration 0, loss = 2.39839
I0523 12:20:17.791721  1495 solver.cpp:253]     Train net output #0: loss = 2.39839 (* 1 = 2.39839 loss)
I0523 12:20:17.791739  1495 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0523 12:20:26.893595  1495 solver.cpp:237] Iteration 250, loss = 2.30825
I0523 12:20:26.893630  1495 solver.cpp:253]     Train net output #0: loss = 2.30825 (* 1 = 2.30825 loss)
I0523 12:20:26.893645  1495 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0523 12:20:35.994407  1495 solver.cpp:237] Iteration 500, loss = 2.35514
I0523 12:20:35.994451  1495 solver.cpp:253]     Train net output #0: loss = 2.35514 (* 1 = 2.35514 loss)
I0523 12:20:35.994467  1495 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0523 12:20:45.091651  1495 solver.cpp:237] Iteration 750, loss = 2.31529
I0523 12:20:45.091686  1495 solver.cpp:253]     Train net output #0: loss = 2.31529 (* 1 = 2.31529 loss)
I0523 12:20:45.091701  1495 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0523 12:20:54.184706  1495 solver.cpp:237] Iteration 1000, loss = 2.09211
I0523 12:20:54.184850  1495 solver.cpp:253]     Train net output #0: loss = 2.09211 (* 1 = 2.09211 loss)
I0523 12:20:54.184864  1495 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0523 12:21:03.275652  1495 solver.cpp:237] Iteration 1250, loss = 1.97348
I0523 12:21:03.275692  1495 solver.cpp:253]     Train net output #0: loss = 1.97348 (* 1 = 1.97348 loss)
I0523 12:21:03.275707  1495 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0523 12:21:12.371824  1495 solver.cpp:237] Iteration 1500, loss = 2.19516
I0523 12:21:12.371860  1495 solver.cpp:253]     Train net output #0: loss = 2.19516 (* 1 = 2.19516 loss)
I0523 12:21:12.371873  1495 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0523 12:21:43.653507  1495 solver.cpp:237] Iteration 1750, loss = 1.8984
I0523 12:21:43.653674  1495 solver.cpp:253]     Train net output #0: loss = 1.8984 (* 1 = 1.8984 loss)
I0523 12:21:43.653689  1495 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0523 12:21:52.770218  1495 solver.cpp:237] Iteration 2000, loss = 1.84944
I0523 12:21:52.770264  1495 solver.cpp:253]     Train net output #0: loss = 1.84944 (* 1 = 1.84944 loss)
I0523 12:21:52.770279  1495 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0523 12:22:01.870409  1495 solver.cpp:237] Iteration 2250, loss = 1.88581
I0523 12:22:01.870445  1495 solver.cpp:253]     Train net output #0: loss = 1.88581 (* 1 = 1.88581 loss)
I0523 12:22:01.870460  1495 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0523 12:22:10.939374  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_2500.caffemodel
I0523 12:22:11.005324  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_2500.solverstate
I0523 12:22:11.041769  1495 solver.cpp:237] Iteration 2500, loss = 1.78009
I0523 12:22:11.041813  1495 solver.cpp:253]     Train net output #0: loss = 1.78009 (* 1 = 1.78009 loss)
I0523 12:22:11.041829  1495 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0523 12:22:20.132436  1495 solver.cpp:237] Iteration 2750, loss = 1.63726
I0523 12:22:20.132591  1495 solver.cpp:253]     Train net output #0: loss = 1.63726 (* 1 = 1.63726 loss)
I0523 12:22:20.132604  1495 sgd_solver.cpp:106] Iteration 2750, lr = 0.001
I0523 12:22:29.236053  1495 solver.cpp:237] Iteration 3000, loss = 1.62468
I0523 12:22:29.236088  1495 solver.cpp:253]     Train net output #0: loss = 1.62468 (* 1 = 1.62468 loss)
I0523 12:22:29.236104  1495 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0523 12:22:38.336788  1495 solver.cpp:237] Iteration 3250, loss = 1.93871
I0523 12:22:38.336824  1495 solver.cpp:253]     Train net output #0: loss = 1.93871 (* 1 = 1.93871 loss)
I0523 12:22:38.336838  1495 sgd_solver.cpp:106] Iteration 3250, lr = 0.001
I0523 12:23:09.641829  1495 solver.cpp:237] Iteration 3500, loss = 1.6688
I0523 12:23:09.641995  1495 solver.cpp:253]     Train net output #0: loss = 1.6688 (* 1 = 1.6688 loss)
I0523 12:23:09.642011  1495 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0523 12:23:18.740532  1495 solver.cpp:237] Iteration 3750, loss = 1.92499
I0523 12:23:18.740568  1495 solver.cpp:253]     Train net output #0: loss = 1.92499 (* 1 = 1.92499 loss)
I0523 12:23:18.740582  1495 sgd_solver.cpp:106] Iteration 3750, lr = 0.001
I0523 12:23:27.853003  1495 solver.cpp:237] Iteration 4000, loss = 1.67492
I0523 12:23:27.853039  1495 solver.cpp:253]     Train net output #0: loss = 1.67492 (* 1 = 1.67492 loss)
I0523 12:23:27.853054  1495 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0523 12:23:36.957046  1495 solver.cpp:237] Iteration 4250, loss = 1.57586
I0523 12:23:36.957087  1495 solver.cpp:253]     Train net output #0: loss = 1.57586 (* 1 = 1.57586 loss)
I0523 12:23:36.957103  1495 sgd_solver.cpp:106] Iteration 4250, lr = 0.001
I0523 12:23:46.057267  1495 solver.cpp:237] Iteration 4500, loss = 1.84147
I0523 12:23:46.057423  1495 solver.cpp:253]     Train net output #0: loss = 1.84147 (* 1 = 1.84147 loss)
I0523 12:23:46.057437  1495 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0523 12:23:55.163631  1495 solver.cpp:237] Iteration 4750, loss = 1.70437
I0523 12:23:55.163676  1495 solver.cpp:253]     Train net output #0: loss = 1.70437 (* 1 = 1.70437 loss)
I0523 12:23:55.163692  1495 sgd_solver.cpp:106] Iteration 4750, lr = 0.001
I0523 12:24:04.224815  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_5000.caffemodel
I0523 12:24:04.288646  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_5000.solverstate
I0523 12:24:04.313676  1495 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 12:24:51.619392  1495 solver.cpp:409]     Test net output #0: accuracy = 0.671833
I0523 12:24:51.619567  1495 solver.cpp:409]     Test net output #1: loss = 1.08743 (* 1 = 1.08743 loss)
I0523 12:25:13.790724  1495 solver.cpp:237] Iteration 5000, loss = 1.66294
I0523 12:25:13.790776  1495 solver.cpp:253]     Train net output #0: loss = 1.66294 (* 1 = 1.66294 loss)
I0523 12:25:13.790791  1495 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0523 12:25:22.861541  1495 solver.cpp:237] Iteration 5250, loss = 1.8414
I0523 12:25:22.861685  1495 solver.cpp:253]     Train net output #0: loss = 1.8414 (* 1 = 1.8414 loss)
I0523 12:25:22.861697  1495 sgd_solver.cpp:106] Iteration 5250, lr = 0.001
I0523 12:25:31.942950  1495 solver.cpp:237] Iteration 5500, loss = 1.85166
I0523 12:25:31.942983  1495 solver.cpp:253]     Train net output #0: loss = 1.85166 (* 1 = 1.85166 loss)
I0523 12:25:31.942998  1495 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0523 12:25:41.015301  1495 solver.cpp:237] Iteration 5750, loss = 1.80487
I0523 12:25:41.015349  1495 solver.cpp:253]     Train net output #0: loss = 1.80487 (* 1 = 1.80487 loss)
I0523 12:25:41.015364  1495 sgd_solver.cpp:106] Iteration 5750, lr = 0.001
I0523 12:25:50.094975  1495 solver.cpp:237] Iteration 6000, loss = 1.61818
I0523 12:25:50.095010  1495 solver.cpp:253]     Train net output #0: loss = 1.61818 (* 1 = 1.61818 loss)
I0523 12:25:50.095026  1495 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0523 12:25:59.171293  1495 solver.cpp:237] Iteration 6250, loss = 1.62696
I0523 12:25:59.171430  1495 solver.cpp:253]     Train net output #0: loss = 1.62696 (* 1 = 1.62696 loss)
I0523 12:25:59.171443  1495 sgd_solver.cpp:106] Iteration 6250, lr = 0.001
I0523 12:26:08.247025  1495 solver.cpp:237] Iteration 6500, loss = 1.671
I0523 12:26:08.247071  1495 solver.cpp:253]     Train net output #0: loss = 1.671 (* 1 = 1.671 loss)
I0523 12:26:08.247086  1495 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0523 12:26:39.518548  1495 solver.cpp:237] Iteration 6750, loss = 1.58809
I0523 12:26:39.518707  1495 solver.cpp:253]     Train net output #0: loss = 1.58809 (* 1 = 1.58809 loss)
I0523 12:26:39.518721  1495 sgd_solver.cpp:106] Iteration 6750, lr = 0.001
I0523 12:26:48.595141  1495 solver.cpp:237] Iteration 7000, loss = 1.48702
I0523 12:26:48.595177  1495 solver.cpp:253]     Train net output #0: loss = 1.48702 (* 1 = 1.48702 loss)
I0523 12:26:48.595191  1495 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0523 12:26:57.668455  1495 solver.cpp:237] Iteration 7250, loss = 1.86888
I0523 12:26:57.668498  1495 solver.cpp:253]     Train net output #0: loss = 1.86888 (* 1 = 1.86888 loss)
I0523 12:26:57.668514  1495 sgd_solver.cpp:106] Iteration 7250, lr = 0.001
I0523 12:27:06.703240  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_7500.caffemodel
I0523 12:27:06.768957  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_7500.solverstate
I0523 12:27:06.807941  1495 solver.cpp:237] Iteration 7500, loss = 1.66276
I0523 12:27:06.807992  1495 solver.cpp:253]     Train net output #0: loss = 1.66276 (* 1 = 1.66276 loss)
I0523 12:27:06.808007  1495 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0523 12:27:15.884948  1495 solver.cpp:237] Iteration 7750, loss = 1.54523
I0523 12:27:15.885119  1495 solver.cpp:253]     Train net output #0: loss = 1.54523 (* 1 = 1.54523 loss)
I0523 12:27:15.885133  1495 sgd_solver.cpp:106] Iteration 7750, lr = 0.001
I0523 12:27:24.959764  1495 solver.cpp:237] Iteration 8000, loss = 1.66494
I0523 12:27:24.959800  1495 solver.cpp:253]     Train net output #0: loss = 1.66494 (* 1 = 1.66494 loss)
I0523 12:27:24.959815  1495 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0523 12:27:34.027837  1495 solver.cpp:237] Iteration 8250, loss = 1.45623
I0523 12:27:34.027868  1495 solver.cpp:253]     Train net output #0: loss = 1.45623 (* 1 = 1.45623 loss)
I0523 12:27:34.027883  1495 sgd_solver.cpp:106] Iteration 8250, lr = 0.001
I0523 12:28:05.337687  1495 solver.cpp:237] Iteration 8500, loss = 1.48485
I0523 12:28:05.337851  1495 solver.cpp:253]     Train net output #0: loss = 1.48485 (* 1 = 1.48485 loss)
I0523 12:28:05.337865  1495 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0523 12:28:14.405133  1495 solver.cpp:237] Iteration 8750, loss = 1.51671
I0523 12:28:14.405169  1495 solver.cpp:253]     Train net output #0: loss = 1.51671 (* 1 = 1.51671 loss)
I0523 12:28:14.405184  1495 sgd_solver.cpp:106] Iteration 8750, lr = 0.001
I0523 12:28:23.479574  1495 solver.cpp:237] Iteration 9000, loss = 1.65828
I0523 12:28:23.479609  1495 solver.cpp:253]     Train net output #0: loss = 1.65828 (* 1 = 1.65828 loss)
I0523 12:28:23.479624  1495 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0523 12:28:32.551822  1495 solver.cpp:237] Iteration 9250, loss = 1.53165
I0523 12:28:32.551862  1495 solver.cpp:253]     Train net output #0: loss = 1.53165 (* 1 = 1.53165 loss)
I0523 12:28:32.551875  1495 sgd_solver.cpp:106] Iteration 9250, lr = 0.001
I0523 12:28:41.626752  1495 solver.cpp:237] Iteration 9500, loss = 1.59626
I0523 12:28:41.626893  1495 solver.cpp:253]     Train net output #0: loss = 1.59626 (* 1 = 1.59626 loss)
I0523 12:28:41.626905  1495 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0523 12:28:50.701516  1495 solver.cpp:237] Iteration 9750, loss = 1.15963
I0523 12:28:50.701557  1495 solver.cpp:253]     Train net output #0: loss = 1.15963 (* 1 = 1.15963 loss)
I0523 12:28:50.701571  1495 sgd_solver.cpp:106] Iteration 9750, lr = 0.001
I0523 12:28:59.738039  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_10000.caffemodel
I0523 12:28:59.803102  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_10000.solverstate
I0523 12:28:59.830483  1495 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 12:30:07.953141  1495 solver.cpp:409]     Test net output #0: accuracy = 0.770567
I0523 12:30:07.953300  1495 solver.cpp:409]     Test net output #1: loss = 0.787164 (* 1 = 0.787164 loss)
I0523 12:30:30.258949  1495 solver.cpp:237] Iteration 10000, loss = 1.45294
I0523 12:30:30.259002  1495 solver.cpp:253]     Train net output #0: loss = 1.45294 (* 1 = 1.45294 loss)
I0523 12:30:30.259017  1495 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0523 12:30:39.371788  1495 solver.cpp:237] Iteration 10250, loss = 1.39612
I0523 12:30:39.371949  1495 solver.cpp:253]     Train net output #0: loss = 1.39612 (* 1 = 1.39612 loss)
I0523 12:30:39.371963  1495 sgd_solver.cpp:106] Iteration 10250, lr = 0.001
I0523 12:30:48.484936  1495 solver.cpp:237] Iteration 10500, loss = 1.6137
I0523 12:30:48.484972  1495 solver.cpp:253]     Train net output #0: loss = 1.6137 (* 1 = 1.6137 loss)
I0523 12:30:48.484985  1495 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0523 12:30:57.595198  1495 solver.cpp:237] Iteration 10750, loss = 1.71438
I0523 12:30:57.595233  1495 solver.cpp:253]     Train net output #0: loss = 1.71438 (* 1 = 1.71438 loss)
I0523 12:30:57.595247  1495 sgd_solver.cpp:106] Iteration 10750, lr = 0.001
I0523 12:31:06.704463  1495 solver.cpp:237] Iteration 11000, loss = 1.4235
I0523 12:31:06.704507  1495 solver.cpp:253]     Train net output #0: loss = 1.4235 (* 1 = 1.4235 loss)
I0523 12:31:06.704524  1495 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0523 12:31:15.815687  1495 solver.cpp:237] Iteration 11250, loss = 1.25401
I0523 12:31:15.815830  1495 solver.cpp:253]     Train net output #0: loss = 1.25401 (* 1 = 1.25401 loss)
I0523 12:31:15.815845  1495 sgd_solver.cpp:106] Iteration 11250, lr = 0.001
I0523 12:31:24.938432  1495 solver.cpp:237] Iteration 11500, loss = 1.36516
I0523 12:31:24.938482  1495 solver.cpp:253]     Train net output #0: loss = 1.36516 (* 1 = 1.36516 loss)
I0523 12:31:24.938496  1495 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0523 12:31:56.248458  1495 solver.cpp:237] Iteration 11750, loss = 1.56665
I0523 12:31:56.248618  1495 solver.cpp:253]     Train net output #0: loss = 1.56665 (* 1 = 1.56665 loss)
I0523 12:31:56.248633  1495 sgd_solver.cpp:106] Iteration 11750, lr = 0.001
I0523 12:32:05.362718  1495 solver.cpp:237] Iteration 12000, loss = 1.40886
I0523 12:32:05.362753  1495 solver.cpp:253]     Train net output #0: loss = 1.40886 (* 1 = 1.40886 loss)
I0523 12:32:05.362767  1495 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0523 12:32:14.474048  1495 solver.cpp:237] Iteration 12250, loss = 1.77721
I0523 12:32:14.474084  1495 solver.cpp:253]     Train net output #0: loss = 1.77721 (* 1 = 1.77721 loss)
I0523 12:32:14.474098  1495 sgd_solver.cpp:106] Iteration 12250, lr = 0.001
I0523 12:32:23.553344  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_12500.caffemodel
I0523 12:32:23.617924  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_12500.solverstate
I0523 12:32:23.656951  1495 solver.cpp:237] Iteration 12500, loss = 1.50138
I0523 12:32:23.657001  1495 solver.cpp:253]     Train net output #0: loss = 1.50138 (* 1 = 1.50138 loss)
I0523 12:32:23.657016  1495 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0523 12:32:32.770887  1495 solver.cpp:237] Iteration 12750, loss = 1.55703
I0523 12:32:32.771033  1495 solver.cpp:253]     Train net output #0: loss = 1.55703 (* 1 = 1.55703 loss)
I0523 12:32:32.771045  1495 sgd_solver.cpp:106] Iteration 12750, lr = 0.001
I0523 12:32:41.887441  1495 solver.cpp:237] Iteration 13000, loss = 1.40902
I0523 12:32:41.887490  1495 solver.cpp:253]     Train net output #0: loss = 1.40902 (* 1 = 1.40902 loss)
I0523 12:32:41.887506  1495 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0523 12:32:50.997809  1495 solver.cpp:237] Iteration 13250, loss = 1.9198
I0523 12:32:50.997843  1495 solver.cpp:253]     Train net output #0: loss = 1.9198 (* 1 = 1.9198 loss)
I0523 12:32:50.997859  1495 sgd_solver.cpp:106] Iteration 13250, lr = 0.001
I0523 12:33:22.362912  1495 solver.cpp:237] Iteration 13500, loss = 1.41297
I0523 12:33:22.363090  1495 solver.cpp:253]     Train net output #0: loss = 1.41297 (* 1 = 1.41297 loss)
I0523 12:33:22.363106  1495 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0523 12:33:31.479569  1495 solver.cpp:237] Iteration 13750, loss = 1.48373
I0523 12:33:31.479611  1495 solver.cpp:253]     Train net output #0: loss = 1.48373 (* 1 = 1.48373 loss)
I0523 12:33:31.479627  1495 sgd_solver.cpp:106] Iteration 13750, lr = 0.001
I0523 12:33:40.590867  1495 solver.cpp:237] Iteration 14000, loss = 1.31025
I0523 12:33:40.590901  1495 solver.cpp:253]     Train net output #0: loss = 1.31025 (* 1 = 1.31025 loss)
I0523 12:33:40.590914  1495 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0523 12:33:49.710324  1495 solver.cpp:237] Iteration 14250, loss = 1.29704
I0523 12:33:49.710360  1495 solver.cpp:253]     Train net output #0: loss = 1.29704 (* 1 = 1.29704 loss)
I0523 12:33:49.710373  1495 sgd_solver.cpp:106] Iteration 14250, lr = 0.001
I0523 12:33:58.822549  1495 solver.cpp:237] Iteration 14500, loss = 1.42306
I0523 12:33:58.822713  1495 solver.cpp:253]     Train net output #0: loss = 1.42306 (* 1 = 1.42306 loss)
I0523 12:33:58.822727  1495 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0523 12:34:07.933573  1495 solver.cpp:237] Iteration 14750, loss = 1.01115
I0523 12:34:07.933607  1495 solver.cpp:253]     Train net output #0: loss = 1.01115 (* 1 = 1.01115 loss)
I0523 12:34:07.933621  1495 sgd_solver.cpp:106] Iteration 14750, lr = 0.001
I0523 12:34:17.011454  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_15000.caffemodel
I0523 12:34:17.075219  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_15000.solverstate
I0523 12:34:17.100625  1495 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 12:35:04.090226  1495 solver.cpp:409]     Test net output #0: accuracy = 0.809535
I0523 12:35:04.090385  1495 solver.cpp:409]     Test net output #1: loss = 0.720978 (* 1 = 0.720978 loss)
I0523 12:35:26.322054  1495 solver.cpp:237] Iteration 15000, loss = 1.31496
I0523 12:35:26.322108  1495 solver.cpp:253]     Train net output #0: loss = 1.31496 (* 1 = 1.31496 loss)
I0523 12:35:26.322124  1495 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0523 12:35:35.352512  1495 solver.cpp:237] Iteration 15250, loss = 1.43891
I0523 12:35:35.352675  1495 solver.cpp:253]     Train net output #0: loss = 1.43891 (* 1 = 1.43891 loss)
I0523 12:35:35.352689  1495 sgd_solver.cpp:106] Iteration 15250, lr = 0.001
I0523 12:35:44.386021  1495 solver.cpp:237] Iteration 15500, loss = 1.53686
I0523 12:35:44.386056  1495 solver.cpp:253]     Train net output #0: loss = 1.53686 (* 1 = 1.53686 loss)
I0523 12:35:44.386072  1495 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I0523 12:35:53.418046  1495 solver.cpp:237] Iteration 15750, loss = 1.40304
I0523 12:35:53.418082  1495 solver.cpp:253]     Train net output #0: loss = 1.40304 (* 1 = 1.40304 loss)
I0523 12:35:53.418097  1495 sgd_solver.cpp:106] Iteration 15750, lr = 0.001
I0523 12:36:02.439846  1495 solver.cpp:237] Iteration 16000, loss = 1.59699
I0523 12:36:02.439893  1495 solver.cpp:253]     Train net output #0: loss = 1.59699 (* 1 = 1.59699 loss)
I0523 12:36:02.439906  1495 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0523 12:36:11.471257  1495 solver.cpp:237] Iteration 16250, loss = 1.56157
I0523 12:36:11.471413  1495 solver.cpp:253]     Train net output #0: loss = 1.56157 (* 1 = 1.56157 loss)
I0523 12:36:11.471427  1495 sgd_solver.cpp:106] Iteration 16250, lr = 0.001
I0523 12:36:20.498040  1495 solver.cpp:237] Iteration 16500, loss = 1.41575
I0523 12:36:20.498075  1495 solver.cpp:253]     Train net output #0: loss = 1.41575 (* 1 = 1.41575 loss)
I0523 12:36:20.498090  1495 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0523 12:36:51.715730  1495 solver.cpp:237] Iteration 16750, loss = 1.1061
I0523 12:36:51.715905  1495 solver.cpp:253]     Train net output #0: loss = 1.1061 (* 1 = 1.1061 loss)
I0523 12:36:51.715922  1495 sgd_solver.cpp:106] Iteration 16750, lr = 0.001
I0523 12:37:00.750885  1495 solver.cpp:237] Iteration 17000, loss = 1.1049
I0523 12:37:00.750919  1495 solver.cpp:253]     Train net output #0: loss = 1.1049 (* 1 = 1.1049 loss)
I0523 12:37:00.750936  1495 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0523 12:37:09.775910  1495 solver.cpp:237] Iteration 17250, loss = 1.19751
I0523 12:37:09.775945  1495 solver.cpp:253]     Train net output #0: loss = 1.19751 (* 1 = 1.19751 loss)
I0523 12:37:09.775960  1495 sgd_solver.cpp:106] Iteration 17250, lr = 0.001
I0523 12:37:18.765579  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_17500.caffemodel
I0523 12:37:18.828830  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_17500.solverstate
I0523 12:37:18.866633  1495 solver.cpp:237] Iteration 17500, loss = 1.41858
I0523 12:37:18.866680  1495 solver.cpp:253]     Train net output #0: loss = 1.41858 (* 1 = 1.41858 loss)
I0523 12:37:18.866694  1495 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I0523 12:37:27.910089  1495 solver.cpp:237] Iteration 17750, loss = 1.45339
I0523 12:37:27.910238  1495 solver.cpp:253]     Train net output #0: loss = 1.45339 (* 1 = 1.45339 loss)
I0523 12:37:27.910250  1495 sgd_solver.cpp:106] Iteration 17750, lr = 0.001
I0523 12:37:36.945214  1495 solver.cpp:237] Iteration 18000, loss = 1.38375
I0523 12:37:36.945250  1495 solver.cpp:253]     Train net output #0: loss = 1.38375 (* 1 = 1.38375 loss)
I0523 12:37:36.945264  1495 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0523 12:37:45.977913  1495 solver.cpp:237] Iteration 18250, loss = 1.39978
I0523 12:37:45.977954  1495 solver.cpp:253]     Train net output #0: loss = 1.39978 (* 1 = 1.39978 loss)
I0523 12:37:45.977969  1495 sgd_solver.cpp:106] Iteration 18250, lr = 0.001
I0523 12:38:17.208551  1495 solver.cpp:237] Iteration 18500, loss = 1.09966
I0523 12:38:17.208719  1495 solver.cpp:253]     Train net output #0: loss = 1.09966 (* 1 = 1.09966 loss)
I0523 12:38:17.208734  1495 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I0523 12:38:26.240500  1495 solver.cpp:237] Iteration 18750, loss = 1.44166
I0523 12:38:26.240535  1495 solver.cpp:253]     Train net output #0: loss = 1.44166 (* 1 = 1.44166 loss)
I0523 12:38:26.240550  1495 sgd_solver.cpp:106] Iteration 18750, lr = 0.001
I0523 12:38:35.271363  1495 solver.cpp:237] Iteration 19000, loss = 1.30691
I0523 12:38:35.271410  1495 solver.cpp:253]     Train net output #0: loss = 1.30691 (* 1 = 1.30691 loss)
I0523 12:38:35.271425  1495 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0523 12:38:44.301821  1495 solver.cpp:237] Iteration 19250, loss = 1.39393
I0523 12:38:44.301857  1495 solver.cpp:253]     Train net output #0: loss = 1.39393 (* 1 = 1.39393 loss)
I0523 12:38:44.301872  1495 sgd_solver.cpp:106] Iteration 19250, lr = 0.001
I0523 12:38:53.333185  1495 solver.cpp:237] Iteration 19500, loss = 1.5904
I0523 12:38:53.333328  1495 solver.cpp:253]     Train net output #0: loss = 1.5904 (* 1 = 1.5904 loss)
I0523 12:38:53.333341  1495 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0523 12:39:02.359649  1495 solver.cpp:237] Iteration 19750, loss = 1.41542
I0523 12:39:02.359695  1495 solver.cpp:253]     Train net output #0: loss = 1.41542 (* 1 = 1.41542 loss)
I0523 12:39:02.359709  1495 sgd_solver.cpp:106] Iteration 19750, lr = 0.001
I0523 12:39:11.360298  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_20000.caffemodel
I0523 12:39:11.422968  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_20000.solverstate
I0523 12:39:11.449329  1495 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 12:40:19.585415  1495 solver.cpp:409]     Test net output #0: accuracy = 0.821948
I0523 12:40:19.585628  1495 solver.cpp:409]     Test net output #1: loss = 0.661088 (* 1 = 0.661088 loss)
I0523 12:40:41.780098  1495 solver.cpp:237] Iteration 20000, loss = 1.30382
I0523 12:40:41.780150  1495 solver.cpp:253]     Train net output #0: loss = 1.30382 (* 1 = 1.30382 loss)
I0523 12:40:41.780165  1495 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0523 12:40:50.850702  1495 solver.cpp:237] Iteration 20250, loss = 1.21361
I0523 12:40:50.850872  1495 solver.cpp:253]     Train net output #0: loss = 1.21361 (* 1 = 1.21361 loss)
I0523 12:40:50.850886  1495 sgd_solver.cpp:106] Iteration 20250, lr = 0.001
I0523 12:40:59.918500  1495 solver.cpp:237] Iteration 20500, loss = 1.25624
I0523 12:40:59.918546  1495 solver.cpp:253]     Train net output #0: loss = 1.25624 (* 1 = 1.25624 loss)
I0523 12:40:59.918561  1495 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0523 12:41:08.983186  1495 solver.cpp:237] Iteration 20750, loss = 1.08176
I0523 12:41:08.983222  1495 solver.cpp:253]     Train net output #0: loss = 1.08176 (* 1 = 1.08176 loss)
I0523 12:41:08.983237  1495 sgd_solver.cpp:106] Iteration 20750, lr = 0.001
I0523 12:41:18.048975  1495 solver.cpp:237] Iteration 21000, loss = 1.12095
I0523 12:41:18.049011  1495 solver.cpp:253]     Train net output #0: loss = 1.12095 (* 1 = 1.12095 loss)
I0523 12:41:18.049026  1495 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0523 12:41:27.100486  1495 solver.cpp:237] Iteration 21250, loss = 1.53314
I0523 12:41:27.100654  1495 solver.cpp:253]     Train net output #0: loss = 1.53314 (* 1 = 1.53314 loss)
I0523 12:41:27.100668  1495 sgd_solver.cpp:106] Iteration 21250, lr = 0.001
I0523 12:41:36.156307  1495 solver.cpp:237] Iteration 21500, loss = 1.01064
I0523 12:41:36.156342  1495 solver.cpp:253]     Train net output #0: loss = 1.01064 (* 1 = 1.01064 loss)
I0523 12:41:36.156358  1495 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0523 12:42:07.370183  1495 solver.cpp:237] Iteration 21750, loss = 1.44833
I0523 12:42:07.370349  1495 solver.cpp:253]     Train net output #0: loss = 1.44833 (* 1 = 1.44833 loss)
I0523 12:42:07.370363  1495 sgd_solver.cpp:106] Iteration 21750, lr = 0.001
I0523 12:42:16.424454  1495 solver.cpp:237] Iteration 22000, loss = 1.43381
I0523 12:42:16.424500  1495 solver.cpp:253]     Train net output #0: loss = 1.43381 (* 1 = 1.43381 loss)
I0523 12:42:16.424515  1495 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0523 12:42:25.479694  1495 solver.cpp:237] Iteration 22250, loss = 1.13361
I0523 12:42:25.479730  1495 solver.cpp:253]     Train net output #0: loss = 1.13361 (* 1 = 1.13361 loss)
I0523 12:42:25.479744  1495 sgd_solver.cpp:106] Iteration 22250, lr = 0.001
I0523 12:42:34.500644  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_22500.caffemodel
I0523 12:42:34.566736  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_22500.solverstate
I0523 12:42:34.606536  1495 solver.cpp:237] Iteration 22500, loss = 1.6077
I0523 12:42:34.606585  1495 solver.cpp:253]     Train net output #0: loss = 1.6077 (* 1 = 1.6077 loss)
I0523 12:42:34.606600  1495 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0523 12:42:43.669924  1495 solver.cpp:237] Iteration 22750, loss = 1.1389
I0523 12:42:43.670084  1495 solver.cpp:253]     Train net output #0: loss = 1.1389 (* 1 = 1.1389 loss)
I0523 12:42:43.670099  1495 sgd_solver.cpp:106] Iteration 22750, lr = 0.001
I0523 12:42:52.739502  1495 solver.cpp:237] Iteration 23000, loss = 1.43085
I0523 12:42:52.739537  1495 solver.cpp:253]     Train net output #0: loss = 1.43085 (* 1 = 1.43085 loss)
I0523 12:42:52.739552  1495 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0523 12:43:01.790549  1495 solver.cpp:237] Iteration 23250, loss = 1.41694
I0523 12:43:01.790585  1495 solver.cpp:253]     Train net output #0: loss = 1.41694 (* 1 = 1.41694 loss)
I0523 12:43:01.790598  1495 sgd_solver.cpp:106] Iteration 23250, lr = 0.001
I0523 12:43:33.103349  1495 solver.cpp:237] Iteration 23500, loss = 1.21796
I0523 12:43:33.103526  1495 solver.cpp:253]     Train net output #0: loss = 1.21796 (* 1 = 1.21796 loss)
I0523 12:43:33.103540  1495 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0523 12:43:42.162315  1495 solver.cpp:237] Iteration 23750, loss = 1.54281
I0523 12:43:42.162350  1495 solver.cpp:253]     Train net output #0: loss = 1.54281 (* 1 = 1.54281 loss)
I0523 12:43:42.162366  1495 sgd_solver.cpp:106] Iteration 23750, lr = 0.001
I0523 12:43:51.221268  1495 solver.cpp:237] Iteration 24000, loss = 1.30431
I0523 12:43:51.221305  1495 solver.cpp:253]     Train net output #0: loss = 1.30431 (* 1 = 1.30431 loss)
I0523 12:43:51.221319  1495 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0523 12:44:00.277055  1495 solver.cpp:237] Iteration 24250, loss = 1.5432
I0523 12:44:00.277096  1495 solver.cpp:253]     Train net output #0: loss = 1.5432 (* 1 = 1.5432 loss)
I0523 12:44:00.277112  1495 sgd_solver.cpp:106] Iteration 24250, lr = 0.001
I0523 12:44:09.340077  1495 solver.cpp:237] Iteration 24500, loss = 1.18913
I0523 12:44:09.340224  1495 solver.cpp:253]     Train net output #0: loss = 1.18913 (* 1 = 1.18913 loss)
I0523 12:44:09.340236  1495 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0523 12:44:18.402101  1495 solver.cpp:237] Iteration 24750, loss = 1.46436
I0523 12:44:18.402135  1495 solver.cpp:253]     Train net output #0: loss = 1.46436 (* 1 = 1.46436 loss)
I0523 12:44:18.402150  1495 sgd_solver.cpp:106] Iteration 24750, lr = 0.001
I0523 12:44:27.433393  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_25000.caffemodel
I0523 12:44:27.499222  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_25000.solverstate
I0523 12:44:27.528270  1495 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 12:45:14.805224  1495 solver.cpp:409]     Test net output #0: accuracy = 0.836495
I0523 12:45:14.805387  1495 solver.cpp:409]     Test net output #1: loss = 0.561517 (* 1 = 0.561517 loss)
I0523 12:45:35.659838  1495 solver.cpp:237] Iteration 25000, loss = 1.29373
I0523 12:45:35.659890  1495 solver.cpp:253]     Train net output #0: loss = 1.29373 (* 1 = 1.29373 loss)
I0523 12:45:35.659906  1495 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0523 12:45:44.667860  1495 solver.cpp:237] Iteration 25250, loss = 1.13626
I0523 12:45:44.667894  1495 solver.cpp:253]     Train net output #0: loss = 1.13626 (* 1 = 1.13626 loss)
I0523 12:45:44.667911  1495 sgd_solver.cpp:106] Iteration 25250, lr = 0.001
I0523 12:45:53.675885  1495 solver.cpp:237] Iteration 25500, loss = 1.39336
I0523 12:45:53.676038  1495 solver.cpp:253]     Train net output #0: loss = 1.39336 (* 1 = 1.39336 loss)
I0523 12:45:53.676053  1495 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0523 12:46:02.681637  1495 solver.cpp:237] Iteration 25750, loss = 1.12008
I0523 12:46:02.681681  1495 solver.cpp:253]     Train net output #0: loss = 1.12008 (* 1 = 1.12008 loss)
I0523 12:46:02.681697  1495 sgd_solver.cpp:106] Iteration 25750, lr = 0.001
I0523 12:46:11.694751  1495 solver.cpp:237] Iteration 26000, loss = 1.24448
I0523 12:46:11.694785  1495 solver.cpp:253]     Train net output #0: loss = 1.24448 (* 1 = 1.24448 loss)
I0523 12:46:11.694800  1495 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0523 12:46:20.702424  1495 solver.cpp:237] Iteration 26250, loss = 1.27533
I0523 12:46:20.702458  1495 solver.cpp:253]     Train net output #0: loss = 1.27533 (* 1 = 1.27533 loss)
I0523 12:46:20.702473  1495 sgd_solver.cpp:106] Iteration 26250, lr = 0.001
I0523 12:46:29.705826  1495 solver.cpp:237] Iteration 26500, loss = 1.33128
I0523 12:46:29.705989  1495 solver.cpp:253]     Train net output #0: loss = 1.33128 (* 1 = 1.33128 loss)
I0523 12:46:29.706003  1495 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0523 12:46:59.592468  1495 solver.cpp:237] Iteration 26750, loss = 1.09272
I0523 12:46:59.592517  1495 solver.cpp:253]     Train net output #0: loss = 1.09272 (* 1 = 1.09272 loss)
I0523 12:46:59.592533  1495 sgd_solver.cpp:106] Iteration 26750, lr = 0.001
I0523 12:47:08.605901  1495 solver.cpp:237] Iteration 27000, loss = 1.21633
I0523 12:47:08.606056  1495 solver.cpp:253]     Train net output #0: loss = 1.21633 (* 1 = 1.21633 loss)
I0523 12:47:08.606070  1495 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0523 12:47:17.615304  1495 solver.cpp:237] Iteration 27250, loss = 1.52394
I0523 12:47:17.615347  1495 solver.cpp:253]     Train net output #0: loss = 1.52394 (* 1 = 1.52394 loss)
I0523 12:47:17.615365  1495 sgd_solver.cpp:106] Iteration 27250, lr = 0.001
I0523 12:47:26.588865  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_27500.caffemodel
I0523 12:47:26.652075  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_27500.solverstate
I0523 12:47:26.689643  1495 solver.cpp:237] Iteration 27500, loss = 1.28422
I0523 12:47:26.689684  1495 solver.cpp:253]     Train net output #0: loss = 1.28422 (* 1 = 1.28422 loss)
I0523 12:47:26.689707  1495 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0523 12:47:35.701159  1495 solver.cpp:237] Iteration 27750, loss = 1.11585
I0523 12:47:35.701194  1495 solver.cpp:253]     Train net output #0: loss = 1.11585 (* 1 = 1.11585 loss)
I0523 12:47:35.701208  1495 sgd_solver.cpp:106] Iteration 27750, lr = 0.001
I0523 12:47:44.706806  1495 solver.cpp:237] Iteration 28000, loss = 1.07768
I0523 12:47:44.706966  1495 solver.cpp:253]     Train net output #0: loss = 1.07768 (* 1 = 1.07768 loss)
I0523 12:47:44.706980  1495 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0523 12:47:53.723047  1495 solver.cpp:237] Iteration 28250, loss = 1.10872
I0523 12:47:53.723081  1495 solver.cpp:253]     Train net output #0: loss = 1.10872 (* 1 = 1.10872 loss)
I0523 12:47:53.723098  1495 sgd_solver.cpp:106] Iteration 28250, lr = 0.001
I0523 12:48:23.676267  1495 solver.cpp:237] Iteration 28500, loss = 1.32147
I0523 12:48:23.676439  1495 solver.cpp:253]     Train net output #0: loss = 1.32147 (* 1 = 1.32147 loss)
I0523 12:48:23.676452  1495 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0523 12:48:32.687398  1495 solver.cpp:237] Iteration 28750, loss = 1.21354
I0523 12:48:32.687440  1495 solver.cpp:253]     Train net output #0: loss = 1.21354 (* 1 = 1.21354 loss)
I0523 12:48:32.687458  1495 sgd_solver.cpp:106] Iteration 28750, lr = 0.001
I0523 12:48:41.702997  1495 solver.cpp:237] Iteration 29000, loss = 1.36423
I0523 12:48:41.703032  1495 solver.cpp:253]     Train net output #0: loss = 1.36423 (* 1 = 1.36423 loss)
I0523 12:48:41.703048  1495 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0523 12:48:50.718919  1495 solver.cpp:237] Iteration 29250, loss = 1.35044
I0523 12:48:50.718955  1495 solver.cpp:253]     Train net output #0: loss = 1.35044 (* 1 = 1.35044 loss)
I0523 12:48:50.718969  1495 sgd_solver.cpp:106] Iteration 29250, lr = 0.001
I0523 12:48:59.720427  1495 solver.cpp:237] Iteration 29500, loss = 1.10279
I0523 12:48:59.720582  1495 solver.cpp:253]     Train net output #0: loss = 1.10279 (* 1 = 1.10279 loss)
I0523 12:48:59.720597  1495 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0523 12:49:08.734405  1495 solver.cpp:237] Iteration 29750, loss = 1.25425
I0523 12:49:08.734438  1495 solver.cpp:253]     Train net output #0: loss = 1.25425 (* 1 = 1.25425 loss)
I0523 12:49:08.734453  1495 sgd_solver.cpp:106] Iteration 29750, lr = 0.001
I0523 12:49:17.709658  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_30000.caffemodel
I0523 12:49:17.772441  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_30000.solverstate
I0523 12:49:17.799072  1495 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 12:50:25.865070  1495 solver.cpp:409]     Test net output #0: accuracy = 0.844342
I0523 12:50:25.865244  1495 solver.cpp:409]     Test net output #1: loss = 0.521697 (* 1 = 0.521697 loss)
I0523 12:50:46.742182  1495 solver.cpp:237] Iteration 30000, loss = 1.13743
I0523 12:50:46.742235  1495 solver.cpp:253]     Train net output #0: loss = 1.13743 (* 1 = 1.13743 loss)
I0523 12:50:46.742250  1495 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0523 12:50:55.851069  1495 solver.cpp:237] Iteration 30250, loss = 1.09513
I0523 12:50:55.851105  1495 solver.cpp:253]     Train net output #0: loss = 1.09513 (* 1 = 1.09513 loss)
I0523 12:50:55.851120  1495 sgd_solver.cpp:106] Iteration 30250, lr = 0.001
I0523 12:51:04.958945  1495 solver.cpp:237] Iteration 30500, loss = 1.23902
I0523 12:51:04.959110  1495 solver.cpp:253]     Train net output #0: loss = 1.23902 (* 1 = 1.23902 loss)
I0523 12:51:04.959125  1495 sgd_solver.cpp:106] Iteration 30500, lr = 0.001
I0523 12:51:14.059640  1495 solver.cpp:237] Iteration 30750, loss = 1.26086
I0523 12:51:14.059675  1495 solver.cpp:253]     Train net output #0: loss = 1.26086 (* 1 = 1.26086 loss)
I0523 12:51:14.059691  1495 sgd_solver.cpp:106] Iteration 30750, lr = 0.001
I0523 12:51:23.159523  1495 solver.cpp:237] Iteration 31000, loss = 1.26419
I0523 12:51:23.159559  1495 solver.cpp:253]     Train net output #0: loss = 1.26419 (* 1 = 1.26419 loss)
I0523 12:51:23.159572  1495 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I0523 12:51:32.259150  1495 solver.cpp:237] Iteration 31250, loss = 1.169
I0523 12:51:32.259191  1495 solver.cpp:253]     Train net output #0: loss = 1.169 (* 1 = 1.169 loss)
I0523 12:51:32.259208  1495 sgd_solver.cpp:106] Iteration 31250, lr = 0.001
I0523 12:51:41.366312  1495 solver.cpp:237] Iteration 31500, loss = 1.32918
I0523 12:51:41.366461  1495 solver.cpp:253]     Train net output #0: loss = 1.32918 (* 1 = 1.32918 loss)
I0523 12:51:41.366473  1495 sgd_solver.cpp:106] Iteration 31500, lr = 0.001
I0523 12:52:11.346089  1495 solver.cpp:237] Iteration 31750, loss = 1.31341
I0523 12:52:11.346139  1495 solver.cpp:253]     Train net output #0: loss = 1.31341 (* 1 = 1.31341 loss)
I0523 12:52:11.346154  1495 sgd_solver.cpp:106] Iteration 31750, lr = 0.001
I0523 12:52:20.452843  1495 solver.cpp:237] Iteration 32000, loss = 1.17045
I0523 12:52:20.453006  1495 solver.cpp:253]     Train net output #0: loss = 1.17045 (* 1 = 1.17045 loss)
I0523 12:52:20.453019  1495 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0523 12:52:29.553481  1495 solver.cpp:237] Iteration 32250, loss = 1.13414
I0523 12:52:29.553516  1495 solver.cpp:253]     Train net output #0: loss = 1.13414 (* 1 = 1.13414 loss)
I0523 12:52:29.553531  1495 sgd_solver.cpp:106] Iteration 32250, lr = 0.001
I0523 12:52:38.619650  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_32500.caffemodel
I0523 12:52:38.682734  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_32500.solverstate
I0523 12:52:38.720542  1495 solver.cpp:237] Iteration 32500, loss = 1.33392
I0523 12:52:38.720588  1495 solver.cpp:253]     Train net output #0: loss = 1.33392 (* 1 = 1.33392 loss)
I0523 12:52:38.720603  1495 sgd_solver.cpp:106] Iteration 32500, lr = 0.001
I0523 12:52:47.826066  1495 solver.cpp:237] Iteration 32750, loss = 1.20465
I0523 12:52:47.826110  1495 solver.cpp:253]     Train net output #0: loss = 1.20465 (* 1 = 1.20465 loss)
I0523 12:52:47.826127  1495 sgd_solver.cpp:106] Iteration 32750, lr = 0.001
I0523 12:52:56.926689  1495 solver.cpp:237] Iteration 33000, loss = 1.57653
I0523 12:52:56.926851  1495 solver.cpp:253]     Train net output #0: loss = 1.57653 (* 1 = 1.57653 loss)
I0523 12:52:56.926865  1495 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0523 12:53:06.032330  1495 solver.cpp:237] Iteration 33250, loss = 1.27808
I0523 12:53:06.032378  1495 solver.cpp:253]     Train net output #0: loss = 1.27808 (* 1 = 1.27808 loss)
I0523 12:53:06.032392  1495 sgd_solver.cpp:106] Iteration 33250, lr = 0.001
I0523 12:53:35.974174  1495 solver.cpp:237] Iteration 33500, loss = 1.07962
I0523 12:53:35.974347  1495 solver.cpp:253]     Train net output #0: loss = 1.07962 (* 1 = 1.07962 loss)
I0523 12:53:35.974361  1495 sgd_solver.cpp:106] Iteration 33500, lr = 0.001
I0523 12:53:45.072885  1495 solver.cpp:237] Iteration 33750, loss = 1.48496
I0523 12:53:45.072919  1495 solver.cpp:253]     Train net output #0: loss = 1.48496 (* 1 = 1.48496 loss)
I0523 12:53:45.072935  1495 sgd_solver.cpp:106] Iteration 33750, lr = 0.001
I0523 12:53:54.167208  1495 solver.cpp:237] Iteration 34000, loss = 1.36694
I0523 12:53:54.167243  1495 solver.cpp:253]     Train net output #0: loss = 1.36694 (* 1 = 1.36694 loss)
I0523 12:53:54.167258  1495 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0523 12:54:03.271569  1495 solver.cpp:237] Iteration 34250, loss = 1.4131
I0523 12:54:03.271606  1495 solver.cpp:253]     Train net output #0: loss = 1.4131 (* 1 = 1.4131 loss)
I0523 12:54:03.271620  1495 sgd_solver.cpp:106] Iteration 34250, lr = 0.001
I0523 12:54:12.376238  1495 solver.cpp:237] Iteration 34500, loss = 1.30004
I0523 12:54:12.376385  1495 solver.cpp:253]     Train net output #0: loss = 1.30004 (* 1 = 1.30004 loss)
I0523 12:54:12.376399  1495 sgd_solver.cpp:106] Iteration 34500, lr = 0.001
I0523 12:54:21.477051  1495 solver.cpp:237] Iteration 34750, loss = 1.17604
I0523 12:54:21.477092  1495 solver.cpp:253]     Train net output #0: loss = 1.17604 (* 1 = 1.17604 loss)
I0523 12:54:21.477109  1495 sgd_solver.cpp:106] Iteration 34750, lr = 0.001
I0523 12:54:30.541074  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_35000.caffemodel
I0523 12:54:30.604882  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_35000.solverstate
I0523 12:54:30.631455  1495 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 12:55:17.610935  1495 solver.cpp:409]     Test net output #0: accuracy = 0.848721
I0523 12:55:17.611102  1495 solver.cpp:409]     Test net output #1: loss = 0.515041 (* 1 = 0.515041 loss)
I0523 12:55:38.484330  1495 solver.cpp:237] Iteration 35000, loss = 1.11464
I0523 12:55:38.484383  1495 solver.cpp:253]     Train net output #0: loss = 1.11464 (* 1 = 1.11464 loss)
I0523 12:55:38.484398  1495 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0523 12:55:47.563385  1495 solver.cpp:237] Iteration 35250, loss = 1.22146
I0523 12:55:47.563421  1495 solver.cpp:253]     Train net output #0: loss = 1.22146 (* 1 = 1.22146 loss)
I0523 12:55:47.563432  1495 sgd_solver.cpp:106] Iteration 35250, lr = 0.001
I0523 12:55:56.640580  1495 solver.cpp:237] Iteration 35500, loss = 1.59161
I0523 12:55:56.640733  1495 solver.cpp:253]     Train net output #0: loss = 1.59161 (* 1 = 1.59161 loss)
I0523 12:55:56.640748  1495 sgd_solver.cpp:106] Iteration 35500, lr = 0.001
I0523 12:56:05.712028  1495 solver.cpp:237] Iteration 35750, loss = 1.33443
I0523 12:56:05.712069  1495 solver.cpp:253]     Train net output #0: loss = 1.33443 (* 1 = 1.33443 loss)
I0523 12:56:05.712086  1495 sgd_solver.cpp:106] Iteration 35750, lr = 0.001
I0523 12:56:14.791522  1495 solver.cpp:237] Iteration 36000, loss = 1.45602
I0523 12:56:14.791558  1495 solver.cpp:253]     Train net output #0: loss = 1.45602 (* 1 = 1.45602 loss)
I0523 12:56:14.791571  1495 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0523 12:56:23.865058  1495 solver.cpp:237] Iteration 36250, loss = 1.36597
I0523 12:56:23.865094  1495 solver.cpp:253]     Train net output #0: loss = 1.36597 (* 1 = 1.36597 loss)
I0523 12:56:23.865109  1495 sgd_solver.cpp:106] Iteration 36250, lr = 0.001
I0523 12:56:32.950359  1495 solver.cpp:237] Iteration 36500, loss = 1.28655
I0523 12:56:32.950531  1495 solver.cpp:253]     Train net output #0: loss = 1.28655 (* 1 = 1.28655 loss)
I0523 12:56:32.950546  1495 sgd_solver.cpp:106] Iteration 36500, lr = 0.001
I0523 12:57:02.884135  1495 solver.cpp:237] Iteration 36750, loss = 1.09855
I0523 12:57:02.884186  1495 solver.cpp:253]     Train net output #0: loss = 1.09855 (* 1 = 1.09855 loss)
I0523 12:57:02.884201  1495 sgd_solver.cpp:106] Iteration 36750, lr = 0.001
I0523 12:57:11.959233  1495 solver.cpp:237] Iteration 37000, loss = 1.14028
I0523 12:57:11.959388  1495 solver.cpp:253]     Train net output #0: loss = 1.14028 (* 1 = 1.14028 loss)
I0523 12:57:11.959400  1495 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0523 12:57:21.033610  1495 solver.cpp:237] Iteration 37250, loss = 1.27944
I0523 12:57:21.033656  1495 solver.cpp:253]     Train net output #0: loss = 1.27944 (* 1 = 1.27944 loss)
I0523 12:57:21.033673  1495 sgd_solver.cpp:106] Iteration 37250, lr = 0.001
I0523 12:57:30.073781  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_37500.caffemodel
I0523 12:57:30.139967  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_37500.solverstate
I0523 12:57:30.179939  1495 solver.cpp:237] Iteration 37500, loss = 1.33886
I0523 12:57:30.179988  1495 solver.cpp:253]     Train net output #0: loss = 1.33886 (* 1 = 1.33886 loss)
I0523 12:57:30.180003  1495 sgd_solver.cpp:106] Iteration 37500, lr = 0.001
I0523 12:57:39.253695  1495 solver.cpp:237] Iteration 37750, loss = 1.22189
I0523 12:57:39.253731  1495 solver.cpp:253]     Train net output #0: loss = 1.22189 (* 1 = 1.22189 loss)
I0523 12:57:39.253746  1495 sgd_solver.cpp:106] Iteration 37750, lr = 0.001
I0523 12:57:48.332737  1495 solver.cpp:237] Iteration 38000, loss = 1.22064
I0523 12:57:48.332912  1495 solver.cpp:253]     Train net output #0: loss = 1.22064 (* 1 = 1.22064 loss)
I0523 12:57:48.332926  1495 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0523 12:57:57.405186  1495 solver.cpp:237] Iteration 38250, loss = 1.49658
I0523 12:57:57.405222  1495 solver.cpp:253]     Train net output #0: loss = 1.49658 (* 1 = 1.49658 loss)
I0523 12:57:57.405236  1495 sgd_solver.cpp:106] Iteration 38250, lr = 0.001
I0523 12:58:27.347638  1495 solver.cpp:237] Iteration 38500, loss = 1.21407
I0523 12:58:27.347813  1495 solver.cpp:253]     Train net output #0: loss = 1.21407 (* 1 = 1.21407 loss)
I0523 12:58:27.347827  1495 sgd_solver.cpp:106] Iteration 38500, lr = 0.001
I0523 12:58:36.420660  1495 solver.cpp:237] Iteration 38750, loss = 1.3182
I0523 12:58:36.420706  1495 solver.cpp:253]     Train net output #0: loss = 1.3182 (* 1 = 1.3182 loss)
I0523 12:58:36.420719  1495 sgd_solver.cpp:106] Iteration 38750, lr = 0.001
I0523 12:58:45.492400  1495 solver.cpp:237] Iteration 39000, loss = 1.0823
I0523 12:58:45.492435  1495 solver.cpp:253]     Train net output #0: loss = 1.0823 (* 1 = 1.0823 loss)
I0523 12:58:45.492449  1495 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0523 12:58:54.564246  1495 solver.cpp:237] Iteration 39250, loss = 1.36832
I0523 12:58:54.564282  1495 solver.cpp:253]     Train net output #0: loss = 1.36832 (* 1 = 1.36832 loss)
I0523 12:58:54.564296  1495 sgd_solver.cpp:106] Iteration 39250, lr = 0.001
I0523 12:59:03.628523  1495 solver.cpp:237] Iteration 39500, loss = 1.15657
I0523 12:59:03.628684  1495 solver.cpp:253]     Train net output #0: loss = 1.15657 (* 1 = 1.15657 loss)
I0523 12:59:03.628697  1495 sgd_solver.cpp:106] Iteration 39500, lr = 0.001
I0523 12:59:12.705363  1495 solver.cpp:237] Iteration 39750, loss = 1.14297
I0523 12:59:12.705396  1495 solver.cpp:253]     Train net output #0: loss = 1.14297 (* 1 = 1.14297 loss)
I0523 12:59:12.705412  1495 sgd_solver.cpp:106] Iteration 39750, lr = 0.001
I0523 12:59:21.752133  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_40000.caffemodel
I0523 12:59:21.814600  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_40000.solverstate
I0523 12:59:21.841544  1495 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 13:00:29.959019  1495 solver.cpp:409]     Test net output #0: accuracy = 0.85634
I0523 13:00:29.959200  1495 solver.cpp:409]     Test net output #1: loss = 0.48599 (* 1 = 0.48599 loss)
I0523 13:00:50.836925  1495 solver.cpp:237] Iteration 40000, loss = 0.912074
I0523 13:00:50.836977  1495 solver.cpp:253]     Train net output #0: loss = 0.912074 (* 1 = 0.912074 loss)
I0523 13:00:50.836992  1495 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0523 13:00:59.948031  1495 solver.cpp:237] Iteration 40250, loss = 1.44869
I0523 13:00:59.948081  1495 solver.cpp:253]     Train net output #0: loss = 1.44869 (* 1 = 1.44869 loss)
I0523 13:00:59.948094  1495 sgd_solver.cpp:106] Iteration 40250, lr = 0.001
I0523 13:01:09.064513  1495 solver.cpp:237] Iteration 40500, loss = 1.23507
I0523 13:01:09.064667  1495 solver.cpp:253]     Train net output #0: loss = 1.23507 (* 1 = 1.23507 loss)
I0523 13:01:09.064682  1495 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0523 13:01:18.177353  1495 solver.cpp:237] Iteration 40750, loss = 1.4375
I0523 13:01:18.177387  1495 solver.cpp:253]     Train net output #0: loss = 1.4375 (* 1 = 1.4375 loss)
I0523 13:01:18.177402  1495 sgd_solver.cpp:106] Iteration 40750, lr = 0.001
I0523 13:01:27.291837  1495 solver.cpp:237] Iteration 41000, loss = 1.14973
I0523 13:01:27.291879  1495 solver.cpp:253]     Train net output #0: loss = 1.14973 (* 1 = 1.14973 loss)
I0523 13:01:27.291896  1495 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0523 13:01:36.400394  1495 solver.cpp:237] Iteration 41250, loss = 1.24989
I0523 13:01:36.400429  1495 solver.cpp:253]     Train net output #0: loss = 1.24989 (* 1 = 1.24989 loss)
I0523 13:01:36.400444  1495 sgd_solver.cpp:106] Iteration 41250, lr = 0.001
I0523 13:01:45.513245  1495 solver.cpp:237] Iteration 41500, loss = 1.09014
I0523 13:01:45.513394  1495 solver.cpp:253]     Train net output #0: loss = 1.09014 (* 1 = 1.09014 loss)
I0523 13:01:45.513407  1495 sgd_solver.cpp:106] Iteration 41500, lr = 0.001
I0523 13:02:15.482892  1495 solver.cpp:237] Iteration 41750, loss = 1.39327
I0523 13:02:15.482942  1495 solver.cpp:253]     Train net output #0: loss = 1.39327 (* 1 = 1.39327 loss)
I0523 13:02:15.482957  1495 sgd_solver.cpp:106] Iteration 41750, lr = 0.001
I0523 13:02:24.593394  1495 solver.cpp:237] Iteration 42000, loss = 1.05757
I0523 13:02:24.593564  1495 solver.cpp:253]     Train net output #0: loss = 1.05757 (* 1 = 1.05757 loss)
I0523 13:02:24.593578  1495 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0523 13:02:33.704144  1495 solver.cpp:237] Iteration 42250, loss = 1.2796
I0523 13:02:33.704180  1495 solver.cpp:253]     Train net output #0: loss = 1.2796 (* 1 = 1.2796 loss)
I0523 13:02:33.704195  1495 sgd_solver.cpp:106] Iteration 42250, lr = 0.001
I0523 13:02:42.790227  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_42500.caffemodel
I0523 13:02:42.853404  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_42500.solverstate
I0523 13:02:42.891217  1495 solver.cpp:237] Iteration 42500, loss = 0.981298
I0523 13:02:42.891264  1495 solver.cpp:253]     Train net output #0: loss = 0.981298 (* 1 = 0.981298 loss)
I0523 13:02:42.891278  1495 sgd_solver.cpp:106] Iteration 42500, lr = 0.001
I0523 13:02:52.006510  1495 solver.cpp:237] Iteration 42750, loss = 1.19775
I0523 13:02:52.006544  1495 solver.cpp:253]     Train net output #0: loss = 1.19775 (* 1 = 1.19775 loss)
I0523 13:02:52.006561  1495 sgd_solver.cpp:106] Iteration 42750, lr = 0.001
I0523 13:03:01.121464  1495 solver.cpp:237] Iteration 43000, loss = 1.16808
I0523 13:03:01.121633  1495 solver.cpp:253]     Train net output #0: loss = 1.16808 (* 1 = 1.16808 loss)
I0523 13:03:01.121646  1495 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0523 13:03:10.229753  1495 solver.cpp:237] Iteration 43250, loss = 1.16605
I0523 13:03:10.229796  1495 solver.cpp:253]     Train net output #0: loss = 1.16605 (* 1 = 1.16605 loss)
I0523 13:03:10.229814  1495 sgd_solver.cpp:106] Iteration 43250, lr = 0.001
I0523 13:03:40.186594  1495 solver.cpp:237] Iteration 43500, loss = 1.15495
I0523 13:03:40.186769  1495 solver.cpp:253]     Train net output #0: loss = 1.15495 (* 1 = 1.15495 loss)
I0523 13:03:40.186782  1495 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0523 13:03:49.295338  1495 solver.cpp:237] Iteration 43750, loss = 1.1319
I0523 13:03:49.295372  1495 solver.cpp:253]     Train net output #0: loss = 1.1319 (* 1 = 1.1319 loss)
I0523 13:03:49.295387  1495 sgd_solver.cpp:106] Iteration 43750, lr = 0.001
I0523 13:03:58.412885  1495 solver.cpp:237] Iteration 44000, loss = 1.35238
I0523 13:03:58.412933  1495 solver.cpp:253]     Train net output #0: loss = 1.35238 (* 1 = 1.35238 loss)
I0523 13:03:58.412947  1495 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0523 13:04:07.528573  1495 solver.cpp:237] Iteration 44250, loss = 1.33281
I0523 13:04:07.528609  1495 solver.cpp:253]     Train net output #0: loss = 1.33281 (* 1 = 1.33281 loss)
I0523 13:04:07.528623  1495 sgd_solver.cpp:106] Iteration 44250, lr = 0.001
I0523 13:04:16.634449  1495 solver.cpp:237] Iteration 44500, loss = 1.46407
I0523 13:04:16.634601  1495 solver.cpp:253]     Train net output #0: loss = 1.46407 (* 1 = 1.46407 loss)
I0523 13:04:16.634614  1495 sgd_solver.cpp:106] Iteration 44500, lr = 0.001
I0523 13:04:25.746872  1495 solver.cpp:237] Iteration 44750, loss = 1.37032
I0523 13:04:25.746913  1495 solver.cpp:253]     Train net output #0: loss = 1.37032 (* 1 = 1.37032 loss)
I0523 13:04:25.746934  1495 sgd_solver.cpp:106] Iteration 44750, lr = 0.001
I0523 13:04:34.830602  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_45000.caffemodel
I0523 13:04:34.894289  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_45000.solverstate
I0523 13:04:34.920734  1495 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 13:05:22.198911  1495 solver.cpp:409]     Test net output #0: accuracy = 0.858206
I0523 13:05:22.199082  1495 solver.cpp:409]     Test net output #1: loss = 0.463495 (* 1 = 0.463495 loss)
I0523 13:05:43.081084  1495 solver.cpp:237] Iteration 45000, loss = 1.20473
I0523 13:05:43.081138  1495 solver.cpp:253]     Train net output #0: loss = 1.20473 (* 1 = 1.20473 loss)
I0523 13:05:43.081154  1495 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0523 13:05:52.103689  1495 solver.cpp:237] Iteration 45250, loss = 1.09122
I0523 13:05:52.103725  1495 solver.cpp:253]     Train net output #0: loss = 1.09122 (* 1 = 1.09122 loss)
I0523 13:05:52.103741  1495 sgd_solver.cpp:106] Iteration 45250, lr = 0.001
I0523 13:06:01.134826  1495 solver.cpp:237] Iteration 45500, loss = 1.32491
I0523 13:06:01.134995  1495 solver.cpp:253]     Train net output #0: loss = 1.32491 (* 1 = 1.32491 loss)
I0523 13:06:01.135010  1495 sgd_solver.cpp:106] Iteration 45500, lr = 0.001
I0523 13:06:10.161993  1495 solver.cpp:237] Iteration 45750, loss = 1.2633
I0523 13:06:10.162029  1495 solver.cpp:253]     Train net output #0: loss = 1.2633 (* 1 = 1.2633 loss)
I0523 13:06:10.162045  1495 sgd_solver.cpp:106] Iteration 45750, lr = 0.001
I0523 13:06:19.196179  1495 solver.cpp:237] Iteration 46000, loss = 1.16583
I0523 13:06:19.196215  1495 solver.cpp:253]     Train net output #0: loss = 1.16583 (* 1 = 1.16583 loss)
I0523 13:06:19.196229  1495 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0523 13:06:28.228691  1495 solver.cpp:237] Iteration 46250, loss = 1.28485
I0523 13:06:28.228731  1495 solver.cpp:253]     Train net output #0: loss = 1.28485 (* 1 = 1.28485 loss)
I0523 13:06:28.228751  1495 sgd_solver.cpp:106] Iteration 46250, lr = 0.001
I0523 13:06:37.259518  1495 solver.cpp:237] Iteration 46500, loss = 1.1692
I0523 13:06:37.259680  1495 solver.cpp:253]     Train net output #0: loss = 1.1692 (* 1 = 1.1692 loss)
I0523 13:06:37.259693  1495 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0523 13:07:07.187757  1495 solver.cpp:237] Iteration 46750, loss = 1.22721
I0523 13:07:07.187808  1495 solver.cpp:253]     Train net output #0: loss = 1.22721 (* 1 = 1.22721 loss)
I0523 13:07:07.187824  1495 sgd_solver.cpp:106] Iteration 46750, lr = 0.001
I0523 13:07:16.221631  1495 solver.cpp:237] Iteration 47000, loss = 1.52309
I0523 13:07:16.221799  1495 solver.cpp:253]     Train net output #0: loss = 1.52309 (* 1 = 1.52309 loss)
I0523 13:07:16.221813  1495 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0523 13:07:25.255697  1495 solver.cpp:237] Iteration 47250, loss = 1.31772
I0523 13:07:25.255730  1495 solver.cpp:253]     Train net output #0: loss = 1.31772 (* 1 = 1.31772 loss)
I0523 13:07:25.255746  1495 sgd_solver.cpp:106] Iteration 47250, lr = 0.001
I0523 13:07:34.254875  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_47500.caffemodel
I0523 13:07:34.476125  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_47500.solverstate
I0523 13:07:34.515928  1495 solver.cpp:237] Iteration 47500, loss = 1.38938
I0523 13:07:34.515980  1495 solver.cpp:253]     Train net output #0: loss = 1.38938 (* 1 = 1.38938 loss)
I0523 13:07:34.515995  1495 sgd_solver.cpp:106] Iteration 47500, lr = 0.001
I0523 13:07:43.542376  1495 solver.cpp:237] Iteration 47750, loss = 1.16085
I0523 13:07:43.542423  1495 solver.cpp:253]     Train net output #0: loss = 1.16085 (* 1 = 1.16085 loss)
I0523 13:07:43.542436  1495 sgd_solver.cpp:106] Iteration 47750, lr = 0.001
I0523 13:07:52.581115  1495 solver.cpp:237] Iteration 48000, loss = 1.32696
I0523 13:07:52.581274  1495 solver.cpp:253]     Train net output #0: loss = 1.32696 (* 1 = 1.32696 loss)
I0523 13:07:52.581287  1495 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0523 13:08:01.611237  1495 solver.cpp:237] Iteration 48250, loss = 1.34241
I0523 13:08:01.611270  1495 solver.cpp:253]     Train net output #0: loss = 1.34241 (* 1 = 1.34241 loss)
I0523 13:08:01.611285  1495 sgd_solver.cpp:106] Iteration 48250, lr = 0.001
I0523 13:08:31.530843  1495 solver.cpp:237] Iteration 48500, loss = 1.49922
I0523 13:08:31.531028  1495 solver.cpp:253]     Train net output #0: loss = 1.49922 (* 1 = 1.49922 loss)
I0523 13:08:31.531043  1495 sgd_solver.cpp:106] Iteration 48500, lr = 0.001
I0523 13:08:40.561002  1495 solver.cpp:237] Iteration 48750, loss = 1.263
I0523 13:08:40.561038  1495 solver.cpp:253]     Train net output #0: loss = 1.263 (* 1 = 1.263 loss)
I0523 13:08:40.561053  1495 sgd_solver.cpp:106] Iteration 48750, lr = 0.001
I0523 13:08:49.590764  1495 solver.cpp:237] Iteration 49000, loss = 1.14722
I0523 13:08:49.590798  1495 solver.cpp:253]     Train net output #0: loss = 1.14722 (* 1 = 1.14722 loss)
I0523 13:08:49.590812  1495 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0523 13:08:58.621906  1495 solver.cpp:237] Iteration 49250, loss = 1.16352
I0523 13:08:58.621949  1495 solver.cpp:253]     Train net output #0: loss = 1.16352 (* 1 = 1.16352 loss)
I0523 13:08:58.621966  1495 sgd_solver.cpp:106] Iteration 49250, lr = 0.001
I0523 13:09:07.662593  1495 solver.cpp:237] Iteration 49500, loss = 1.08347
I0523 13:09:07.662758  1495 solver.cpp:253]     Train net output #0: loss = 1.08347 (* 1 = 1.08347 loss)
I0523 13:09:07.662771  1495 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I0523 13:09:16.690366  1495 solver.cpp:237] Iteration 49750, loss = 1.27808
I0523 13:09:16.690400  1495 solver.cpp:253]     Train net output #0: loss = 1.27808 (* 1 = 1.27808 loss)
I0523 13:09:16.690415  1495 sgd_solver.cpp:106] Iteration 49750, lr = 0.001
I0523 13:09:25.692427  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_50000.caffemodel
I0523 13:09:25.758276  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_50000.solverstate
I0523 13:09:25.786945  1495 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 13:10:33.922893  1495 solver.cpp:409]     Test net output #0: accuracy = 0.864421
I0523 13:10:33.923071  1495 solver.cpp:409]     Test net output #1: loss = 0.473998 (* 1 = 0.473998 loss)
I0523 13:10:54.824285  1495 solver.cpp:237] Iteration 50000, loss = 1.32506
I0523 13:10:54.824338  1495 solver.cpp:253]     Train net output #0: loss = 1.32506 (* 1 = 1.32506 loss)
I0523 13:10:54.824354  1495 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0523 13:11:03.876231  1495 solver.cpp:237] Iteration 50250, loss = 1.07255
I0523 13:11:03.876272  1495 solver.cpp:253]     Train net output #0: loss = 1.07255 (* 1 = 1.07255 loss)
I0523 13:11:03.876289  1495 sgd_solver.cpp:106] Iteration 50250, lr = 0.001
I0523 13:11:12.924095  1495 solver.cpp:237] Iteration 50500, loss = 1.2818
I0523 13:11:12.924252  1495 solver.cpp:253]     Train net output #0: loss = 1.2818 (* 1 = 1.2818 loss)
I0523 13:11:12.924266  1495 sgd_solver.cpp:106] Iteration 50500, lr = 0.001
I0523 13:11:21.987623  1495 solver.cpp:237] Iteration 50750, loss = 1.16309
I0523 13:11:21.987658  1495 solver.cpp:253]     Train net output #0: loss = 1.16309 (* 1 = 1.16309 loss)
I0523 13:11:21.987673  1495 sgd_solver.cpp:106] Iteration 50750, lr = 0.001
I0523 13:11:31.051144  1495 solver.cpp:237] Iteration 51000, loss = 1.26886
I0523 13:11:31.051187  1495 solver.cpp:253]     Train net output #0: loss = 1.26886 (* 1 = 1.26886 loss)
I0523 13:11:31.051204  1495 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0523 13:11:40.114681  1495 solver.cpp:237] Iteration 51250, loss = 1.03807
I0523 13:11:40.114717  1495 solver.cpp:253]     Train net output #0: loss = 1.03807 (* 1 = 1.03807 loss)
I0523 13:11:40.114729  1495 sgd_solver.cpp:106] Iteration 51250, lr = 0.001
I0523 13:11:49.174757  1495 solver.cpp:237] Iteration 51500, loss = 1.19137
I0523 13:11:49.174927  1495 solver.cpp:253]     Train net output #0: loss = 1.19137 (* 1 = 1.19137 loss)
I0523 13:11:49.174942  1495 sgd_solver.cpp:106] Iteration 51500, lr = 0.001
I0523 13:12:19.120301  1495 solver.cpp:237] Iteration 51750, loss = 1.35025
I0523 13:12:19.120350  1495 solver.cpp:253]     Train net output #0: loss = 1.35025 (* 1 = 1.35025 loss)
I0523 13:12:19.120367  1495 sgd_solver.cpp:106] Iteration 51750, lr = 0.001
I0523 13:12:28.176172  1495 solver.cpp:237] Iteration 52000, loss = 1.25086
I0523 13:12:28.176331  1495 solver.cpp:253]     Train net output #0: loss = 1.25086 (* 1 = 1.25086 loss)
I0523 13:12:28.176344  1495 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0523 13:12:37.246006  1495 solver.cpp:237] Iteration 52250, loss = 1.0805
I0523 13:12:37.246040  1495 solver.cpp:253]     Train net output #0: loss = 1.0805 (* 1 = 1.0805 loss)
I0523 13:12:37.246057  1495 sgd_solver.cpp:106] Iteration 52250, lr = 0.001
I0523 13:12:46.275765  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_52500.caffemodel
I0523 13:12:46.339855  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_52500.solverstate
I0523 13:12:46.377218  1495 solver.cpp:237] Iteration 52500, loss = 1.20634
I0523 13:12:46.377262  1495 solver.cpp:253]     Train net output #0: loss = 1.20634 (* 1 = 1.20634 loss)
I0523 13:12:46.377279  1495 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I0523 13:12:55.435250  1495 solver.cpp:237] Iteration 52750, loss = 1.32645
I0523 13:12:55.435286  1495 solver.cpp:253]     Train net output #0: loss = 1.32645 (* 1 = 1.32645 loss)
I0523 13:12:55.435300  1495 sgd_solver.cpp:106] Iteration 52750, lr = 0.001
I0523 13:13:04.501061  1495 solver.cpp:237] Iteration 53000, loss = 1.34345
I0523 13:13:04.501225  1495 solver.cpp:253]     Train net output #0: loss = 1.34345 (* 1 = 1.34345 loss)
I0523 13:13:04.501240  1495 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0523 13:13:13.570296  1495 solver.cpp:237] Iteration 53250, loss = 1.19533
I0523 13:13:13.570336  1495 solver.cpp:253]     Train net output #0: loss = 1.19533 (* 1 = 1.19533 loss)
I0523 13:13:13.570353  1495 sgd_solver.cpp:106] Iteration 53250, lr = 0.001
I0523 13:13:43.524801  1495 solver.cpp:237] Iteration 53500, loss = 1.05127
I0523 13:13:43.524976  1495 solver.cpp:253]     Train net output #0: loss = 1.05127 (* 1 = 1.05127 loss)
I0523 13:13:43.524991  1495 sgd_solver.cpp:106] Iteration 53500, lr = 0.001
I0523 13:13:52.583421  1495 solver.cpp:237] Iteration 53750, loss = 1.25735
I0523 13:13:52.583456  1495 solver.cpp:253]     Train net output #0: loss = 1.25735 (* 1 = 1.25735 loss)
I0523 13:13:52.583472  1495 sgd_solver.cpp:106] Iteration 53750, lr = 0.001
I0523 13:14:01.632014  1495 solver.cpp:237] Iteration 54000, loss = 1.30646
I0523 13:14:01.632053  1495 solver.cpp:253]     Train net output #0: loss = 1.30646 (* 1 = 1.30646 loss)
I0523 13:14:01.632066  1495 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0523 13:14:10.688031  1495 solver.cpp:237] Iteration 54250, loss = 1.38547
I0523 13:14:10.688066  1495 solver.cpp:253]     Train net output #0: loss = 1.38547 (* 1 = 1.38547 loss)
I0523 13:14:10.688081  1495 sgd_solver.cpp:106] Iteration 54250, lr = 0.001
I0523 13:14:19.764003  1495 solver.cpp:237] Iteration 54500, loss = 1.25583
I0523 13:14:19.764158  1495 solver.cpp:253]     Train net output #0: loss = 1.25583 (* 1 = 1.25583 loss)
I0523 13:14:19.764170  1495 sgd_solver.cpp:106] Iteration 54500, lr = 0.001
I0523 13:14:28.829429  1495 solver.cpp:237] Iteration 54750, loss = 1.49015
I0523 13:14:28.829469  1495 solver.cpp:253]     Train net output #0: loss = 1.49015 (* 1 = 1.49015 loss)
I0523 13:14:28.829486  1495 sgd_solver.cpp:106] Iteration 54750, lr = 0.001
I0523 13:14:37.864202  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_55000.caffemodel
I0523 13:14:37.927469  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_55000.solverstate
I0523 13:14:37.953912  1495 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 13:15:24.904392  1495 solver.cpp:409]     Test net output #0: accuracy = 0.866767
I0523 13:15:24.904567  1495 solver.cpp:409]     Test net output #1: loss = 0.439766 (* 1 = 0.439766 loss)
I0523 13:15:45.770421  1495 solver.cpp:237] Iteration 55000, loss = 0.953405
I0523 13:15:45.770474  1495 solver.cpp:253]     Train net output #0: loss = 0.953405 (* 1 = 0.953405 loss)
I0523 13:15:45.770490  1495 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0523 13:15:54.785145  1495 solver.cpp:237] Iteration 55250, loss = 1.21672
I0523 13:15:54.785179  1495 solver.cpp:253]     Train net output #0: loss = 1.21672 (* 1 = 1.21672 loss)
I0523 13:15:54.785197  1495 sgd_solver.cpp:106] Iteration 55250, lr = 0.001
I0523 13:16:03.796026  1495 solver.cpp:237] Iteration 55500, loss = 1.24877
I0523 13:16:03.796210  1495 solver.cpp:253]     Train net output #0: loss = 1.24877 (* 1 = 1.24877 loss)
I0523 13:16:03.796224  1495 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0523 13:16:12.809310  1495 solver.cpp:237] Iteration 55750, loss = 1.22386
I0523 13:16:12.809345  1495 solver.cpp:253]     Train net output #0: loss = 1.22386 (* 1 = 1.22386 loss)
I0523 13:16:12.809361  1495 sgd_solver.cpp:106] Iteration 55750, lr = 0.001
I0523 13:16:21.822605  1495 solver.cpp:237] Iteration 56000, loss = 1.17917
I0523 13:16:21.822640  1495 solver.cpp:253]     Train net output #0: loss = 1.17917 (* 1 = 1.17917 loss)
I0523 13:16:21.822656  1495 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0523 13:16:30.837703  1495 solver.cpp:237] Iteration 56250, loss = 1.36155
I0523 13:16:30.837744  1495 solver.cpp:253]     Train net output #0: loss = 1.36155 (* 1 = 1.36155 loss)
I0523 13:16:30.837757  1495 sgd_solver.cpp:106] Iteration 56250, lr = 0.001
I0523 13:16:39.848691  1495 solver.cpp:237] Iteration 56500, loss = 1.18228
I0523 13:16:39.848848  1495 solver.cpp:253]     Train net output #0: loss = 1.18228 (* 1 = 1.18228 loss)
I0523 13:16:39.848862  1495 sgd_solver.cpp:106] Iteration 56500, lr = 0.001
I0523 13:17:09.780568  1495 solver.cpp:237] Iteration 56750, loss = 1.32983
I0523 13:17:09.780619  1495 solver.cpp:253]     Train net output #0: loss = 1.32983 (* 1 = 1.32983 loss)
I0523 13:17:09.780633  1495 sgd_solver.cpp:106] Iteration 56750, lr = 0.001
I0523 13:17:18.789717  1495 solver.cpp:237] Iteration 57000, loss = 0.990251
I0523 13:17:18.789890  1495 solver.cpp:253]     Train net output #0: loss = 0.990251 (* 1 = 0.990251 loss)
I0523 13:17:18.789903  1495 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0523 13:17:27.796412  1495 solver.cpp:237] Iteration 57250, loss = 1.3267
I0523 13:17:27.796448  1495 solver.cpp:253]     Train net output #0: loss = 1.3267 (* 1 = 1.3267 loss)
I0523 13:17:27.796463  1495 sgd_solver.cpp:106] Iteration 57250, lr = 0.001
I0523 13:17:36.775455  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_57500.caffemodel
I0523 13:17:36.838779  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_57500.solverstate
I0523 13:17:36.876407  1495 solver.cpp:237] Iteration 57500, loss = 1.22047
I0523 13:17:36.876452  1495 solver.cpp:253]     Train net output #0: loss = 1.22047 (* 1 = 1.22047 loss)
I0523 13:17:36.876467  1495 sgd_solver.cpp:106] Iteration 57500, lr = 0.001
I0523 13:17:45.892395  1495 solver.cpp:237] Iteration 57750, loss = 1.33432
I0523 13:17:45.892439  1495 solver.cpp:253]     Train net output #0: loss = 1.33432 (* 1 = 1.33432 loss)
I0523 13:17:45.892454  1495 sgd_solver.cpp:106] Iteration 57750, lr = 0.001
I0523 13:17:54.897708  1495 solver.cpp:237] Iteration 58000, loss = 1.29309
I0523 13:17:54.897874  1495 solver.cpp:253]     Train net output #0: loss = 1.29309 (* 1 = 1.29309 loss)
I0523 13:17:54.897887  1495 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0523 13:18:03.909276  1495 solver.cpp:237] Iteration 58250, loss = 1.105
I0523 13:18:03.909312  1495 solver.cpp:253]     Train net output #0: loss = 1.105 (* 1 = 1.105 loss)
I0523 13:18:03.909324  1495 sgd_solver.cpp:106] Iteration 58250, lr = 0.001
I0523 13:18:33.869346  1495 solver.cpp:237] Iteration 58500, loss = 1.35127
I0523 13:18:33.869524  1495 solver.cpp:253]     Train net output #0: loss = 1.35127 (* 1 = 1.35127 loss)
I0523 13:18:33.869539  1495 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0523 13:18:42.889961  1495 solver.cpp:237] Iteration 58750, loss = 1.24838
I0523 13:18:42.889996  1495 solver.cpp:253]     Train net output #0: loss = 1.24838 (* 1 = 1.24838 loss)
I0523 13:18:42.890010  1495 sgd_solver.cpp:106] Iteration 58750, lr = 0.001
I0523 13:18:51.899806  1495 solver.cpp:237] Iteration 59000, loss = 1.20494
I0523 13:18:51.899840  1495 solver.cpp:253]     Train net output #0: loss = 1.20494 (* 1 = 1.20494 loss)
I0523 13:18:51.899854  1495 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0523 13:19:00.913117  1495 solver.cpp:237] Iteration 59250, loss = 1.08243
I0523 13:19:00.913162  1495 solver.cpp:253]     Train net output #0: loss = 1.08243 (* 1 = 1.08243 loss)
I0523 13:19:00.913178  1495 sgd_solver.cpp:106] Iteration 59250, lr = 0.001
I0523 13:19:09.921754  1495 solver.cpp:237] Iteration 59500, loss = 1.28589
I0523 13:19:09.921922  1495 solver.cpp:253]     Train net output #0: loss = 1.28589 (* 1 = 1.28589 loss)
I0523 13:19:09.921936  1495 sgd_solver.cpp:106] Iteration 59500, lr = 0.001
I0523 13:19:18.934702  1495 solver.cpp:237] Iteration 59750, loss = 0.960982
I0523 13:19:18.934737  1495 solver.cpp:253]     Train net output #0: loss = 0.960982 (* 1 = 0.960982 loss)
I0523 13:19:18.934752  1495 sgd_solver.cpp:106] Iteration 59750, lr = 0.001
I0523 13:19:27.908702  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_60000.caffemodel
I0523 13:19:27.972292  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_60000.solverstate
I0523 13:19:27.998601  1495 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 13:20:36.149046  1495 solver.cpp:409]     Test net output #0: accuracy = 0.869054
I0523 13:20:36.149232  1495 solver.cpp:409]     Test net output #1: loss = 0.444451 (* 1 = 0.444451 loss)
I0523 13:20:57.042356  1495 solver.cpp:237] Iteration 60000, loss = 1.27354
I0523 13:20:57.042408  1495 solver.cpp:253]     Train net output #0: loss = 1.27354 (* 1 = 1.27354 loss)
I0523 13:20:57.042423  1495 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0523 13:21:06.152992  1495 solver.cpp:237] Iteration 60250, loss = 0.997651
I0523 13:21:06.153168  1495 solver.cpp:253]     Train net output #0: loss = 0.997651 (* 1 = 0.997651 loss)
I0523 13:21:06.153183  1495 sgd_solver.cpp:106] Iteration 60250, lr = 0.001
I0523 13:21:15.251883  1495 solver.cpp:237] Iteration 60500, loss = 1.49755
I0523 13:21:15.251919  1495 solver.cpp:253]     Train net output #0: loss = 1.49755 (* 1 = 1.49755 loss)
I0523 13:21:15.251934  1495 sgd_solver.cpp:106] Iteration 60500, lr = 0.001
I0523 13:21:24.360925  1495 solver.cpp:237] Iteration 60750, loss = 1.29079
I0523 13:21:24.360961  1495 solver.cpp:253]     Train net output #0: loss = 1.29079 (* 1 = 1.29079 loss)
I0523 13:21:24.360975  1495 sgd_solver.cpp:106] Iteration 60750, lr = 0.001
I0523 13:21:33.473034  1495 solver.cpp:237] Iteration 61000, loss = 1.37898
I0523 13:21:33.473072  1495 solver.cpp:253]     Train net output #0: loss = 1.37898 (* 1 = 1.37898 loss)
I0523 13:21:33.473084  1495 sgd_solver.cpp:106] Iteration 61000, lr = 0.001
I0523 13:21:42.569763  1495 solver.cpp:237] Iteration 61250, loss = 1.18767
I0523 13:21:42.569928  1495 solver.cpp:253]     Train net output #0: loss = 1.18767 (* 1 = 1.18767 loss)
I0523 13:21:42.569941  1495 sgd_solver.cpp:106] Iteration 61250, lr = 0.001
I0523 13:21:51.673295  1495 solver.cpp:237] Iteration 61500, loss = 1.14895
I0523 13:21:51.673342  1495 solver.cpp:253]     Train net output #0: loss = 1.14895 (* 1 = 1.14895 loss)
I0523 13:21:51.673357  1495 sgd_solver.cpp:106] Iteration 61500, lr = 0.001
I0523 13:22:21.672230  1495 solver.cpp:237] Iteration 61750, loss = 1.23767
I0523 13:22:21.672408  1495 solver.cpp:253]     Train net output #0: loss = 1.23767 (* 1 = 1.23767 loss)
I0523 13:22:21.672422  1495 sgd_solver.cpp:106] Iteration 61750, lr = 0.001
I0523 13:22:30.776196  1495 solver.cpp:237] Iteration 62000, loss = 1.22289
I0523 13:22:30.776231  1495 solver.cpp:253]     Train net output #0: loss = 1.22289 (* 1 = 1.22289 loss)
I0523 13:22:30.776247  1495 sgd_solver.cpp:106] Iteration 62000, lr = 0.001
I0523 13:22:39.879240  1495 solver.cpp:237] Iteration 62250, loss = 1.18351
I0523 13:22:39.879292  1495 solver.cpp:253]     Train net output #0: loss = 1.18351 (* 1 = 1.18351 loss)
I0523 13:22:39.879305  1495 sgd_solver.cpp:106] Iteration 62250, lr = 0.001
I0523 13:22:48.955324  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_62500.caffemodel
I0523 13:22:49.020939  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_62500.solverstate
I0523 13:22:49.060735  1495 solver.cpp:237] Iteration 62500, loss = 1.31431
I0523 13:22:49.060781  1495 solver.cpp:253]     Train net output #0: loss = 1.31431 (* 1 = 1.31431 loss)
I0523 13:22:49.060803  1495 sgd_solver.cpp:106] Iteration 62500, lr = 0.001
I0523 13:22:58.172308  1495 solver.cpp:237] Iteration 62750, loss = 1.31554
I0523 13:22:58.172492  1495 solver.cpp:253]     Train net output #0: loss = 1.31554 (* 1 = 1.31554 loss)
I0523 13:22:58.172507  1495 sgd_solver.cpp:106] Iteration 62750, lr = 0.001
I0523 13:23:07.269981  1495 solver.cpp:237] Iteration 63000, loss = 1.20378
I0523 13:23:07.270025  1495 solver.cpp:253]     Train net output #0: loss = 1.20378 (* 1 = 1.20378 loss)
I0523 13:23:07.270041  1495 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0523 13:23:16.362828  1495 solver.cpp:237] Iteration 63250, loss = 1.61958
I0523 13:23:16.362864  1495 solver.cpp:253]     Train net output #0: loss = 1.61958 (* 1 = 1.61958 loss)
I0523 13:23:16.362877  1495 sgd_solver.cpp:106] Iteration 63250, lr = 0.001
I0523 13:23:46.367172  1495 solver.cpp:237] Iteration 63500, loss = 1.41603
I0523 13:23:46.367357  1495 solver.cpp:253]     Train net output #0: loss = 1.41603 (* 1 = 1.41603 loss)
I0523 13:23:46.367370  1495 sgd_solver.cpp:106] Iteration 63500, lr = 0.001
I0523 13:23:55.472065  1495 solver.cpp:237] Iteration 63750, loss = 1.08954
I0523 13:23:55.472107  1495 solver.cpp:253]     Train net output #0: loss = 1.08954 (* 1 = 1.08954 loss)
I0523 13:23:55.472124  1495 sgd_solver.cpp:106] Iteration 63750, lr = 0.001
I0523 13:24:04.578544  1495 solver.cpp:237] Iteration 64000, loss = 1.03934
I0523 13:24:04.578580  1495 solver.cpp:253]     Train net output #0: loss = 1.03934 (* 1 = 1.03934 loss)
I0523 13:24:04.578595  1495 sgd_solver.cpp:106] Iteration 64000, lr = 0.001
I0523 13:24:13.680650  1495 solver.cpp:237] Iteration 64250, loss = 1.16351
I0523 13:24:13.680685  1495 solver.cpp:253]     Train net output #0: loss = 1.16351 (* 1 = 1.16351 loss)
I0523 13:24:13.680699  1495 sgd_solver.cpp:106] Iteration 64250, lr = 0.001
I0523 13:24:22.784045  1495 solver.cpp:237] Iteration 64500, loss = 1.18442
I0523 13:24:22.784216  1495 solver.cpp:253]     Train net output #0: loss = 1.18442 (* 1 = 1.18442 loss)
I0523 13:24:22.784230  1495 sgd_solver.cpp:106] Iteration 64500, lr = 0.001
I0523 13:24:31.880473  1495 solver.cpp:237] Iteration 64750, loss = 1.01179
I0523 13:24:31.880508  1495 solver.cpp:253]     Train net output #0: loss = 1.01179 (* 1 = 1.01179 loss)
I0523 13:24:31.880523  1495 sgd_solver.cpp:106] Iteration 64750, lr = 0.001
I0523 13:24:40.952074  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_65000.caffemodel
I0523 13:24:41.015547  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_65000.solverstate
I0523 13:24:41.041770  1495 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 13:25:28.343309  1495 solver.cpp:409]     Test net output #0: accuracy = 0.866741
I0523 13:25:28.343487  1495 solver.cpp:409]     Test net output #1: loss = 0.441035 (* 1 = 0.441035 loss)
I0523 13:25:49.270222  1495 solver.cpp:237] Iteration 65000, loss = 1.08258
I0523 13:25:49.270275  1495 solver.cpp:253]     Train net output #0: loss = 1.08258 (* 1 = 1.08258 loss)
I0523 13:25:49.270290  1495 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I0523 13:25:58.347939  1495 solver.cpp:237] Iteration 65250, loss = 1.14337
I0523 13:25:58.348109  1495 solver.cpp:253]     Train net output #0: loss = 1.14337 (* 1 = 1.14337 loss)
I0523 13:25:58.348122  1495 sgd_solver.cpp:106] Iteration 65250, lr = 0.001
I0523 13:26:07.428555  1495 solver.cpp:237] Iteration 65500, loss = 1.24584
I0523 13:26:07.428598  1495 solver.cpp:253]     Train net output #0: loss = 1.24584 (* 1 = 1.24584 loss)
I0523 13:26:07.428616  1495 sgd_solver.cpp:106] Iteration 65500, lr = 0.001
I0523 13:26:16.510910  1495 solver.cpp:237] Iteration 65750, loss = 1.3074
I0523 13:26:16.510946  1495 solver.cpp:253]     Train net output #0: loss = 1.3074 (* 1 = 1.3074 loss)
I0523 13:26:16.510960  1495 sgd_solver.cpp:106] Iteration 65750, lr = 0.001
I0523 13:26:25.587208  1495 solver.cpp:237] Iteration 66000, loss = 1.33716
I0523 13:26:25.587254  1495 solver.cpp:253]     Train net output #0: loss = 1.33716 (* 1 = 1.33716 loss)
I0523 13:26:25.587267  1495 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0523 13:26:34.665954  1495 solver.cpp:237] Iteration 66250, loss = 1.17114
I0523 13:26:34.666117  1495 solver.cpp:253]     Train net output #0: loss = 1.17114 (* 1 = 1.17114 loss)
I0523 13:26:34.666131  1495 sgd_solver.cpp:106] Iteration 66250, lr = 0.001
I0523 13:26:43.737015  1495 solver.cpp:237] Iteration 66500, loss = 1.08521
I0523 13:26:43.737049  1495 solver.cpp:253]     Train net output #0: loss = 1.08521 (* 1 = 1.08521 loss)
I0523 13:26:43.737066  1495 sgd_solver.cpp:106] Iteration 66500, lr = 0.001
I0523 13:27:13.759510  1495 solver.cpp:237] Iteration 66750, loss = 1.23327
I0523 13:27:13.759693  1495 solver.cpp:253]     Train net output #0: loss = 1.23327 (* 1 = 1.23327 loss)
I0523 13:27:13.759707  1495 sgd_solver.cpp:106] Iteration 66750, lr = 0.001
I0523 13:27:22.835042  1495 solver.cpp:237] Iteration 67000, loss = 1.07532
I0523 13:27:22.835088  1495 solver.cpp:253]     Train net output #0: loss = 1.07532 (* 1 = 1.07532 loss)
I0523 13:27:22.835103  1495 sgd_solver.cpp:106] Iteration 67000, lr = 0.001
I0523 13:27:31.915963  1495 solver.cpp:237] Iteration 67250, loss = 1.30593
I0523 13:27:31.915998  1495 solver.cpp:253]     Train net output #0: loss = 1.30593 (* 1 = 1.30593 loss)
I0523 13:27:31.916014  1495 sgd_solver.cpp:106] Iteration 67250, lr = 0.001
I0523 13:27:40.958081  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_67500.caffemodel
I0523 13:27:41.021363  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_67500.solverstate
I0523 13:27:41.058979  1495 solver.cpp:237] Iteration 67500, loss = 1.07626
I0523 13:27:41.059020  1495 solver.cpp:253]     Train net output #0: loss = 1.07626 (* 1 = 1.07626 loss)
I0523 13:27:41.059033  1495 sgd_solver.cpp:106] Iteration 67500, lr = 0.001
I0523 13:27:50.138893  1495 solver.cpp:237] Iteration 67750, loss = 1.45924
I0523 13:27:50.139057  1495 solver.cpp:253]     Train net output #0: loss = 1.45924 (* 1 = 1.45924 loss)
I0523 13:27:50.139070  1495 sgd_solver.cpp:106] Iteration 67750, lr = 0.001
I0523 13:27:59.211748  1495 solver.cpp:237] Iteration 68000, loss = 1.15315
I0523 13:27:59.211783  1495 solver.cpp:253]     Train net output #0: loss = 1.15315 (* 1 = 1.15315 loss)
I0523 13:27:59.211798  1495 sgd_solver.cpp:106] Iteration 68000, lr = 0.001
I0523 13:28:08.297993  1495 solver.cpp:237] Iteration 68250, loss = 1.12538
I0523 13:28:08.298040  1495 solver.cpp:253]     Train net output #0: loss = 1.12538 (* 1 = 1.12538 loss)
I0523 13:28:08.298054  1495 sgd_solver.cpp:106] Iteration 68250, lr = 0.001
I0523 13:28:38.279366  1495 solver.cpp:237] Iteration 68500, loss = 0.997232
I0523 13:28:38.279551  1495 solver.cpp:253]     Train net output #0: loss = 0.997232 (* 1 = 0.997232 loss)
I0523 13:28:38.279566  1495 sgd_solver.cpp:106] Iteration 68500, lr = 0.001
I0523 13:28:47.351922  1495 solver.cpp:237] Iteration 68750, loss = 1.39509
I0523 13:28:47.351956  1495 solver.cpp:253]     Train net output #0: loss = 1.39509 (* 1 = 1.39509 loss)
I0523 13:28:47.351971  1495 sgd_solver.cpp:106] Iteration 68750, lr = 0.001
I0523 13:28:56.431676  1495 solver.cpp:237] Iteration 69000, loss = 1.11136
I0523 13:28:56.431722  1495 solver.cpp:253]     Train net output #0: loss = 1.11136 (* 1 = 1.11136 loss)
I0523 13:28:56.431737  1495 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0523 13:29:05.509132  1495 solver.cpp:237] Iteration 69250, loss = 1.28225
I0523 13:29:05.509167  1495 solver.cpp:253]     Train net output #0: loss = 1.28225 (* 1 = 1.28225 loss)
I0523 13:29:05.509182  1495 sgd_solver.cpp:106] Iteration 69250, lr = 0.001
I0523 13:29:14.587761  1495 solver.cpp:237] Iteration 69500, loss = 1.0757
I0523 13:29:14.587931  1495 solver.cpp:253]     Train net output #0: loss = 1.0757 (* 1 = 1.0757 loss)
I0523 13:29:14.587944  1495 sgd_solver.cpp:106] Iteration 69500, lr = 0.001
I0523 13:29:23.659984  1495 solver.cpp:237] Iteration 69750, loss = 1.16273
I0523 13:29:23.660032  1495 solver.cpp:253]     Train net output #0: loss = 1.16273 (* 1 = 1.16273 loss)
I0523 13:29:23.660046  1495 sgd_solver.cpp:106] Iteration 69750, lr = 0.001
I0523 13:29:32.713614  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_70000.caffemodel
I0523 13:29:32.776007  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_70000.solverstate
I0523 13:29:32.802209  1495 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 13:30:40.938400  1495 solver.cpp:409]     Test net output #0: accuracy = 0.875007
I0523 13:30:40.938586  1495 solver.cpp:409]     Test net output #1: loss = 0.424257 (* 1 = 0.424257 loss)
I0523 13:31:01.799058  1495 solver.cpp:237] Iteration 70000, loss = 1.36308
I0523 13:31:01.799113  1495 solver.cpp:253]     Train net output #0: loss = 1.36308 (* 1 = 1.36308 loss)
I0523 13:31:01.799134  1495 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I0523 13:31:10.916815  1495 solver.cpp:237] Iteration 70250, loss = 1.11344
I0523 13:31:10.916851  1495 solver.cpp:253]     Train net output #0: loss = 1.11344 (* 1 = 1.11344 loss)
I0523 13:31:10.916864  1495 sgd_solver.cpp:106] Iteration 70250, lr = 0.001
I0523 13:31:20.032560  1495 solver.cpp:237] Iteration 70500, loss = 1.12698
I0523 13:31:20.032727  1495 solver.cpp:253]     Train net output #0: loss = 1.12698 (* 1 = 1.12698 loss)
I0523 13:31:20.032742  1495 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I0523 13:31:29.149436  1495 solver.cpp:237] Iteration 70750, loss = 1.11248
I0523 13:31:29.149480  1495 solver.cpp:253]     Train net output #0: loss = 1.11248 (* 1 = 1.11248 loss)
I0523 13:31:29.149497  1495 sgd_solver.cpp:106] Iteration 70750, lr = 0.001
I0523 13:31:38.267273  1495 solver.cpp:237] Iteration 71000, loss = 1.39824
I0523 13:31:38.267309  1495 solver.cpp:253]     Train net output #0: loss = 1.39824 (* 1 = 1.39824 loss)
I0523 13:31:38.267323  1495 sgd_solver.cpp:106] Iteration 71000, lr = 0.001
I0523 13:31:47.378123  1495 solver.cpp:237] Iteration 71250, loss = 1.30178
I0523 13:31:47.378159  1495 solver.cpp:253]     Train net output #0: loss = 1.30178 (* 1 = 1.30178 loss)
I0523 13:31:47.378173  1495 sgd_solver.cpp:106] Iteration 71250, lr = 0.001
I0523 13:31:56.491024  1495 solver.cpp:237] Iteration 71500, loss = 1.13543
I0523 13:31:56.491190  1495 solver.cpp:253]     Train net output #0: loss = 1.13543 (* 1 = 1.13543 loss)
I0523 13:31:56.491204  1495 sgd_solver.cpp:106] Iteration 71500, lr = 0.001
I0523 13:32:26.500329  1495 solver.cpp:237] Iteration 71750, loss = 1.29428
I0523 13:32:26.500510  1495 solver.cpp:253]     Train net output #0: loss = 1.29428 (* 1 = 1.29428 loss)
I0523 13:32:26.500524  1495 sgd_solver.cpp:106] Iteration 71750, lr = 0.001
I0523 13:32:35.611026  1495 solver.cpp:237] Iteration 72000, loss = 1.30574
I0523 13:32:35.611059  1495 solver.cpp:253]     Train net output #0: loss = 1.30574 (* 1 = 1.30574 loss)
I0523 13:32:35.611075  1495 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I0523 13:32:44.719616  1495 solver.cpp:237] Iteration 72250, loss = 1.39373
I0523 13:32:44.719666  1495 solver.cpp:253]     Train net output #0: loss = 1.39373 (* 1 = 1.39373 loss)
I0523 13:32:44.719681  1495 sgd_solver.cpp:106] Iteration 72250, lr = 0.001
I0523 13:32:53.797440  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_72500.caffemodel
I0523 13:32:53.862632  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_72500.solverstate
I0523 13:32:53.903369  1495 solver.cpp:237] Iteration 72500, loss = 1.56676
I0523 13:32:53.903415  1495 solver.cpp:253]     Train net output #0: loss = 1.56676 (* 1 = 1.56676 loss)
I0523 13:32:53.903430  1495 sgd_solver.cpp:106] Iteration 72500, lr = 0.001
I0523 13:33:03.024966  1495 solver.cpp:237] Iteration 72750, loss = 1.09878
I0523 13:33:03.025146  1495 solver.cpp:253]     Train net output #0: loss = 1.09878 (* 1 = 1.09878 loss)
I0523 13:33:03.025161  1495 sgd_solver.cpp:106] Iteration 72750, lr = 0.001
I0523 13:33:12.140208  1495 solver.cpp:237] Iteration 73000, loss = 1.31865
I0523 13:33:12.140255  1495 solver.cpp:253]     Train net output #0: loss = 1.31865 (* 1 = 1.31865 loss)
I0523 13:33:12.140272  1495 sgd_solver.cpp:106] Iteration 73000, lr = 0.001
I0523 13:33:21.255997  1495 solver.cpp:237] Iteration 73250, loss = 1.13006
I0523 13:33:21.256033  1495 solver.cpp:253]     Train net output #0: loss = 1.13006 (* 1 = 1.13006 loss)
I0523 13:33:21.256048  1495 sgd_solver.cpp:106] Iteration 73250, lr = 0.001
I0523 13:33:51.276157  1495 solver.cpp:237] Iteration 73500, loss = 1.14629
I0523 13:33:51.276342  1495 solver.cpp:253]     Train net output #0: loss = 1.14629 (* 1 = 1.14629 loss)
I0523 13:33:51.276356  1495 sgd_solver.cpp:106] Iteration 73500, lr = 0.001
I0523 13:34:00.386826  1495 solver.cpp:237] Iteration 73750, loss = 1.04869
I0523 13:34:00.386873  1495 solver.cpp:253]     Train net output #0: loss = 1.04869 (* 1 = 1.04869 loss)
I0523 13:34:00.386888  1495 sgd_solver.cpp:106] Iteration 73750, lr = 0.001
I0523 13:34:09.498150  1495 solver.cpp:237] Iteration 74000, loss = 1.37142
I0523 13:34:09.498184  1495 solver.cpp:253]     Train net output #0: loss = 1.37142 (* 1 = 1.37142 loss)
I0523 13:34:09.498199  1495 sgd_solver.cpp:106] Iteration 74000, lr = 0.001
I0523 13:34:18.605917  1495 solver.cpp:237] Iteration 74250, loss = 1.38153
I0523 13:34:18.605953  1495 solver.cpp:253]     Train net output #0: loss = 1.38153 (* 1 = 1.38153 loss)
I0523 13:34:18.605967  1495 sgd_solver.cpp:106] Iteration 74250, lr = 0.001
I0523 13:34:27.712278  1495 solver.cpp:237] Iteration 74500, loss = 1.10995
I0523 13:34:27.712452  1495 solver.cpp:253]     Train net output #0: loss = 1.10995 (* 1 = 1.10995 loss)
I0523 13:34:27.712466  1495 sgd_solver.cpp:106] Iteration 74500, lr = 0.001
I0523 13:34:36.821496  1495 solver.cpp:237] Iteration 74750, loss = 1.36474
I0523 13:34:36.821532  1495 solver.cpp:253]     Train net output #0: loss = 1.36474 (* 1 = 1.36474 loss)
I0523 13:34:36.821550  1495 sgd_solver.cpp:106] Iteration 74750, lr = 0.001
I0523 13:34:45.892302  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_75000.caffemodel
I0523 13:34:45.958462  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_75000.solverstate
I0523 13:34:45.986853  1495 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 13:35:32.994635  1495 solver.cpp:409]     Test net output #0: accuracy = 0.873974
I0523 13:35:32.994832  1495 solver.cpp:409]     Test net output #1: loss = 0.403983 (* 1 = 0.403983 loss)
I0523 13:35:53.900540  1495 solver.cpp:237] Iteration 75000, loss = 1.20542
I0523 13:35:53.900593  1495 solver.cpp:253]     Train net output #0: loss = 1.20542 (* 1 = 1.20542 loss)
I0523 13:35:53.900607  1495 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I0523 13:36:02.926887  1495 solver.cpp:237] Iteration 75250, loss = 1.03998
I0523 13:36:02.926931  1495 solver.cpp:253]     Train net output #0: loss = 1.03998 (* 1 = 1.03998 loss)
I0523 13:36:02.926947  1495 sgd_solver.cpp:106] Iteration 75250, lr = 0.001
I0523 13:36:11.955109  1495 solver.cpp:237] Iteration 75500, loss = 1.16819
I0523 13:36:11.955279  1495 solver.cpp:253]     Train net output #0: loss = 1.16819 (* 1 = 1.16819 loss)
I0523 13:36:11.955293  1495 sgd_solver.cpp:106] Iteration 75500, lr = 0.001
I0523 13:36:20.984673  1495 solver.cpp:237] Iteration 75750, loss = 1.2234
I0523 13:36:20.984707  1495 solver.cpp:253]     Train net output #0: loss = 1.2234 (* 1 = 1.2234 loss)
I0523 13:36:20.984724  1495 sgd_solver.cpp:106] Iteration 75750, lr = 0.001
I0523 13:36:30.020305  1495 solver.cpp:237] Iteration 76000, loss = 1.20111
I0523 13:36:30.020354  1495 solver.cpp:253]     Train net output #0: loss = 1.20111 (* 1 = 1.20111 loss)
I0523 13:36:30.020369  1495 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I0523 13:36:39.053617  1495 solver.cpp:237] Iteration 76250, loss = 1.17377
I0523 13:36:39.053652  1495 solver.cpp:253]     Train net output #0: loss = 1.17377 (* 1 = 1.17377 loss)
I0523 13:36:39.053668  1495 sgd_solver.cpp:106] Iteration 76250, lr = 0.001
I0523 13:36:48.078140  1495 solver.cpp:237] Iteration 76500, loss = 1.48386
I0523 13:36:48.078301  1495 solver.cpp:253]     Train net output #0: loss = 1.48386 (* 1 = 1.48386 loss)
I0523 13:36:48.078315  1495 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I0523 13:37:17.994101  1495 solver.cpp:237] Iteration 76750, loss = 1.32111
I0523 13:37:17.994151  1495 solver.cpp:253]     Train net output #0: loss = 1.32111 (* 1 = 1.32111 loss)
I0523 13:37:17.994165  1495 sgd_solver.cpp:106] Iteration 76750, lr = 0.001
I0523 13:37:27.025337  1495 solver.cpp:237] Iteration 77000, loss = 1.03235
I0523 13:37:27.025502  1495 solver.cpp:253]     Train net output #0: loss = 1.03235 (* 1 = 1.03235 loss)
I0523 13:37:27.025516  1495 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I0523 13:37:36.050426  1495 solver.cpp:237] Iteration 77250, loss = 1.47377
I0523 13:37:36.050460  1495 solver.cpp:253]     Train net output #0: loss = 1.47377 (* 1 = 1.47377 loss)
I0523 13:37:36.050477  1495 sgd_solver.cpp:106] Iteration 77250, lr = 0.001
I0523 13:37:45.047472  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_77500.caffemodel
I0523 13:37:45.110991  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_77500.solverstate
I0523 13:37:45.148663  1495 solver.cpp:237] Iteration 77500, loss = 1.06727
I0523 13:37:45.148707  1495 solver.cpp:253]     Train net output #0: loss = 1.06727 (* 1 = 1.06727 loss)
I0523 13:37:45.148723  1495 sgd_solver.cpp:106] Iteration 77500, lr = 0.001
I0523 13:37:54.178470  1495 solver.cpp:237] Iteration 77750, loss = 1.03511
I0523 13:37:54.178506  1495 solver.cpp:253]     Train net output #0: loss = 1.03511 (* 1 = 1.03511 loss)
I0523 13:37:54.178520  1495 sgd_solver.cpp:106] Iteration 77750, lr = 0.001
I0523 13:38:03.210470  1495 solver.cpp:237] Iteration 78000, loss = 1.21525
I0523 13:38:03.210635  1495 solver.cpp:253]     Train net output #0: loss = 1.21525 (* 1 = 1.21525 loss)
I0523 13:38:03.210649  1495 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I0523 13:38:12.240988  1495 solver.cpp:237] Iteration 78250, loss = 1.17414
I0523 13:38:12.241035  1495 solver.cpp:253]     Train net output #0: loss = 1.17414 (* 1 = 1.17414 loss)
I0523 13:38:12.241050  1495 sgd_solver.cpp:106] Iteration 78250, lr = 0.001
I0523 13:38:42.146667  1495 solver.cpp:237] Iteration 78500, loss = 1.02448
I0523 13:38:42.146858  1495 solver.cpp:253]     Train net output #0: loss = 1.02448 (* 1 = 1.02448 loss)
I0523 13:38:42.146872  1495 sgd_solver.cpp:106] Iteration 78500, lr = 0.001
I0523 13:38:51.170397  1495 solver.cpp:237] Iteration 78750, loss = 1.24357
I0523 13:38:51.170431  1495 solver.cpp:253]     Train net output #0: loss = 1.24357 (* 1 = 1.24357 loss)
I0523 13:38:51.170447  1495 sgd_solver.cpp:106] Iteration 78750, lr = 0.001
I0523 13:39:00.204030  1495 solver.cpp:237] Iteration 79000, loss = 1.39386
I0523 13:39:00.204071  1495 solver.cpp:253]     Train net output #0: loss = 1.39386 (* 1 = 1.39386 loss)
I0523 13:39:00.204089  1495 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I0523 13:39:09.232962  1495 solver.cpp:237] Iteration 79250, loss = 1.3308
I0523 13:39:09.232998  1495 solver.cpp:253]     Train net output #0: loss = 1.3308 (* 1 = 1.3308 loss)
I0523 13:39:09.233013  1495 sgd_solver.cpp:106] Iteration 79250, lr = 0.001
I0523 13:39:18.262146  1495 solver.cpp:237] Iteration 79500, loss = 1.11232
I0523 13:39:18.262311  1495 solver.cpp:253]     Train net output #0: loss = 1.11232 (* 1 = 1.11232 loss)
I0523 13:39:18.262325  1495 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I0523 13:39:27.290457  1495 solver.cpp:237] Iteration 79750, loss = 1.23672
I0523 13:39:27.290498  1495 solver.cpp:253]     Train net output #0: loss = 1.23672 (* 1 = 1.23672 loss)
I0523 13:39:27.290515  1495 sgd_solver.cpp:106] Iteration 79750, lr = 0.001
I0523 13:39:36.285763  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_80000.caffemodel
I0523 13:39:36.348115  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_80000.solverstate
I0523 13:39:36.374605  1495 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 13:40:44.546298  1495 solver.cpp:409]     Test net output #0: accuracy = 0.87622
I0523 13:40:44.546483  1495 solver.cpp:409]     Test net output #1: loss = 0.396699 (* 1 = 0.396699 loss)
I0523 13:41:05.462965  1495 solver.cpp:237] Iteration 80000, loss = 0.872499
I0523 13:41:05.463017  1495 solver.cpp:253]     Train net output #0: loss = 0.872499 (* 1 = 0.872499 loss)
I0523 13:41:05.463033  1495 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I0523 13:41:14.533097  1495 solver.cpp:237] Iteration 80250, loss = 1.305
I0523 13:41:14.533131  1495 solver.cpp:253]     Train net output #0: loss = 1.305 (* 1 = 1.305 loss)
I0523 13:41:14.533146  1495 sgd_solver.cpp:106] Iteration 80250, lr = 0.001
I0523 13:41:23.595578  1495 solver.cpp:237] Iteration 80500, loss = 1.05367
I0523 13:41:23.595746  1495 solver.cpp:253]     Train net output #0: loss = 1.05367 (* 1 = 1.05367 loss)
I0523 13:41:23.595759  1495 sgd_solver.cpp:106] Iteration 80500, lr = 0.001
I0523 13:41:32.657215  1495 solver.cpp:237] Iteration 80750, loss = 1.14465
I0523 13:41:32.657263  1495 solver.cpp:253]     Train net output #0: loss = 1.14465 (* 1 = 1.14465 loss)
I0523 13:41:32.657276  1495 sgd_solver.cpp:106] Iteration 80750, lr = 0.001
I0523 13:41:41.712952  1495 solver.cpp:237] Iteration 81000, loss = 1.10571
I0523 13:41:41.712987  1495 solver.cpp:253]     Train net output #0: loss = 1.10571 (* 1 = 1.10571 loss)
I0523 13:41:41.713003  1495 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I0523 13:41:50.777482  1495 solver.cpp:237] Iteration 81250, loss = 0.950154
I0523 13:41:50.777523  1495 solver.cpp:253]     Train net output #0: loss = 0.950154 (* 1 = 0.950154 loss)
I0523 13:41:50.777541  1495 sgd_solver.cpp:106] Iteration 81250, lr = 0.001
I0523 13:41:59.842344  1495 solver.cpp:237] Iteration 81500, loss = 1.30306
I0523 13:41:59.842510  1495 solver.cpp:253]     Train net output #0: loss = 1.30306 (* 1 = 1.30306 loss)
I0523 13:41:59.842524  1495 sgd_solver.cpp:106] Iteration 81500, lr = 0.001
I0523 13:42:29.795254  1495 solver.cpp:237] Iteration 81750, loss = 1.3355
I0523 13:42:29.795305  1495 solver.cpp:253]     Train net output #0: loss = 1.3355 (* 1 = 1.3355 loss)
I0523 13:42:29.795320  1495 sgd_solver.cpp:106] Iteration 81750, lr = 0.001
I0523 13:42:38.843277  1495 solver.cpp:237] Iteration 82000, loss = 1.04661
I0523 13:42:38.843472  1495 solver.cpp:253]     Train net output #0: loss = 1.04661 (* 1 = 1.04661 loss)
I0523 13:42:38.843485  1495 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I0523 13:42:47.904942  1495 solver.cpp:237] Iteration 82250, loss = 1.49621
I0523 13:42:47.904985  1495 solver.cpp:253]     Train net output #0: loss = 1.49621 (* 1 = 1.49621 loss)
I0523 13:42:47.905001  1495 sgd_solver.cpp:106] Iteration 82250, lr = 0.001
I0523 13:42:56.917424  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_82500.caffemodel
I0523 13:42:56.980747  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_82500.solverstate
I0523 13:42:57.018426  1495 solver.cpp:237] Iteration 82500, loss = 1.21987
I0523 13:42:57.018472  1495 solver.cpp:253]     Train net output #0: loss = 1.21987 (* 1 = 1.21987 loss)
I0523 13:42:57.018487  1495 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I0523 13:43:06.078371  1495 solver.cpp:237] Iteration 82750, loss = 1.12027
I0523 13:43:06.078415  1495 solver.cpp:253]     Train net output #0: loss = 1.12027 (* 1 = 1.12027 loss)
I0523 13:43:06.078431  1495 sgd_solver.cpp:106] Iteration 82750, lr = 0.001
I0523 13:43:15.147694  1495 solver.cpp:237] Iteration 83000, loss = 1.45854
I0523 13:43:15.147866  1495 solver.cpp:253]     Train net output #0: loss = 1.45854 (* 1 = 1.45854 loss)
I0523 13:43:15.147878  1495 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I0523 13:43:24.215912  1495 solver.cpp:237] Iteration 83250, loss = 1.10875
I0523 13:43:24.215945  1495 solver.cpp:253]     Train net output #0: loss = 1.10875 (* 1 = 1.10875 loss)
I0523 13:43:24.215961  1495 sgd_solver.cpp:106] Iteration 83250, lr = 0.001
I0523 13:43:54.167398  1495 solver.cpp:237] Iteration 83500, loss = 1.10072
I0523 13:43:54.167587  1495 solver.cpp:253]     Train net output #0: loss = 1.10072 (* 1 = 1.10072 loss)
I0523 13:43:54.167600  1495 sgd_solver.cpp:106] Iteration 83500, lr = 0.001
I0523 13:44:03.235347  1495 solver.cpp:237] Iteration 83750, loss = 0.995712
I0523 13:44:03.235395  1495 solver.cpp:253]     Train net output #0: loss = 0.995712 (* 1 = 0.995712 loss)
I0523 13:44:03.235410  1495 sgd_solver.cpp:106] Iteration 83750, lr = 0.001
I0523 13:44:12.290943  1495 solver.cpp:237] Iteration 84000, loss = 1.43829
I0523 13:44:12.290979  1495 solver.cpp:253]     Train net output #0: loss = 1.43829 (* 1 = 1.43829 loss)
I0523 13:44:12.290993  1495 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I0523 13:44:21.347625  1495 solver.cpp:237] Iteration 84250, loss = 0.988983
I0523 13:44:21.347673  1495 solver.cpp:253]     Train net output #0: loss = 0.988983 (* 1 = 0.988983 loss)
I0523 13:44:21.347687  1495 sgd_solver.cpp:106] Iteration 84250, lr = 0.001
I0523 13:44:30.412591  1495 solver.cpp:237] Iteration 84500, loss = 0.92918
I0523 13:44:30.412760  1495 solver.cpp:253]     Train net output #0: loss = 0.92918 (* 1 = 0.92918 loss)
I0523 13:44:30.412775  1495 sgd_solver.cpp:106] Iteration 84500, lr = 0.001
I0523 13:44:39.486837  1495 solver.cpp:237] Iteration 84750, loss = 1.10035
I0523 13:44:39.486872  1495 solver.cpp:253]     Train net output #0: loss = 1.10035 (* 1 = 1.10035 loss)
I0523 13:44:39.486887  1495 sgd_solver.cpp:106] Iteration 84750, lr = 0.001
I0523 13:44:48.518206  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_85000.caffemodel
I0523 13:44:48.583086  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_85000.solverstate
I0523 13:44:48.609830  1495 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 13:45:35.987745  1495 solver.cpp:409]     Test net output #0: accuracy = 0.880413
I0523 13:45:35.987937  1495 solver.cpp:409]     Test net output #1: loss = 0.408508 (* 1 = 0.408508 loss)
I0523 13:45:56.907518  1495 solver.cpp:237] Iteration 85000, loss = 1.32659
I0523 13:45:56.907572  1495 solver.cpp:253]     Train net output #0: loss = 1.32659 (* 1 = 1.32659 loss)
I0523 13:45:56.907588  1495 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I0523 13:46:05.919669  1495 solver.cpp:237] Iteration 85250, loss = 1.37577
I0523 13:46:05.919718  1495 solver.cpp:253]     Train net output #0: loss = 1.37577 (* 1 = 1.37577 loss)
I0523 13:46:05.919734  1495 sgd_solver.cpp:106] Iteration 85250, lr = 0.001
I0523 13:46:14.929141  1495 solver.cpp:237] Iteration 85500, loss = 1.13894
I0523 13:46:14.929313  1495 solver.cpp:253]     Train net output #0: loss = 1.13894 (* 1 = 1.13894 loss)
I0523 13:46:14.929327  1495 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I0523 13:46:23.941730  1495 solver.cpp:237] Iteration 85750, loss = 1.17707
I0523 13:46:23.941764  1495 solver.cpp:253]     Train net output #0: loss = 1.17707 (* 1 = 1.17707 loss)
I0523 13:46:23.941779  1495 sgd_solver.cpp:106] Iteration 85750, lr = 0.001
I0523 13:46:32.957376  1495 solver.cpp:237] Iteration 86000, loss = 1.15624
I0523 13:46:32.957420  1495 solver.cpp:253]     Train net output #0: loss = 1.15624 (* 1 = 1.15624 loss)
I0523 13:46:32.957435  1495 sgd_solver.cpp:106] Iteration 86000, lr = 0.001
I0523 13:46:41.966015  1495 solver.cpp:237] Iteration 86250, loss = 1.17621
I0523 13:46:41.966050  1495 solver.cpp:253]     Train net output #0: loss = 1.17621 (* 1 = 1.17621 loss)
I0523 13:46:41.966066  1495 sgd_solver.cpp:106] Iteration 86250, lr = 0.001
I0523 13:46:50.980414  1495 solver.cpp:237] Iteration 86500, loss = 1.07668
I0523 13:46:50.980589  1495 solver.cpp:253]     Train net output #0: loss = 1.07668 (* 1 = 1.07668 loss)
I0523 13:46:50.980603  1495 sgd_solver.cpp:106] Iteration 86500, lr = 0.001
I0523 13:47:20.907593  1495 solver.cpp:237] Iteration 86750, loss = 1.16428
I0523 13:47:20.907642  1495 solver.cpp:253]     Train net output #0: loss = 1.16428 (* 1 = 1.16428 loss)
I0523 13:47:20.907658  1495 sgd_solver.cpp:106] Iteration 86750, lr = 0.001
I0523 13:47:29.922734  1495 solver.cpp:237] Iteration 87000, loss = 1.19205
I0523 13:47:29.922909  1495 solver.cpp:253]     Train net output #0: loss = 1.19205 (* 1 = 1.19205 loss)
I0523 13:47:29.922921  1495 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I0523 13:47:38.940567  1495 solver.cpp:237] Iteration 87250, loss = 1.48406
I0523 13:47:38.940600  1495 solver.cpp:253]     Train net output #0: loss = 1.48406 (* 1 = 1.48406 loss)
I0523 13:47:38.940616  1495 sgd_solver.cpp:106] Iteration 87250, lr = 0.001
I0523 13:47:47.918534  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_87500.caffemodel
I0523 13:47:47.983597  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_87500.solverstate
I0523 13:47:48.023221  1495 solver.cpp:237] Iteration 87500, loss = 1.36043
I0523 13:47:48.023267  1495 solver.cpp:253]     Train net output #0: loss = 1.36043 (* 1 = 1.36043 loss)
I0523 13:47:48.023285  1495 sgd_solver.cpp:106] Iteration 87500, lr = 0.001
I0523 13:47:57.042839  1495 solver.cpp:237] Iteration 87750, loss = 1.23338
I0523 13:47:57.042873  1495 solver.cpp:253]     Train net output #0: loss = 1.23338 (* 1 = 1.23338 loss)
I0523 13:47:57.042888  1495 sgd_solver.cpp:106] Iteration 87750, lr = 0.001
I0523 13:48:06.053334  1495 solver.cpp:237] Iteration 88000, loss = 1.28867
I0523 13:48:06.053534  1495 solver.cpp:253]     Train net output #0: loss = 1.28867 (* 1 = 1.28867 loss)
I0523 13:48:06.053555  1495 sgd_solver.cpp:106] Iteration 88000, lr = 0.001
I0523 13:48:15.067646  1495 solver.cpp:237] Iteration 88250, loss = 1.32458
I0523 13:48:15.067679  1495 solver.cpp:253]     Train net output #0: loss = 1.32458 (* 1 = 1.32458 loss)
I0523 13:48:15.067695  1495 sgd_solver.cpp:106] Iteration 88250, lr = 0.001
I0523 13:48:44.985230  1495 solver.cpp:237] Iteration 88500, loss = 1.63433
I0523 13:48:44.985419  1495 solver.cpp:253]     Train net output #0: loss = 1.63433 (* 1 = 1.63433 loss)
I0523 13:48:44.985435  1495 sgd_solver.cpp:106] Iteration 88500, lr = 0.001
I0523 13:48:53.998689  1495 solver.cpp:237] Iteration 88750, loss = 1.24573
I0523 13:48:53.998724  1495 solver.cpp:253]     Train net output #0: loss = 1.24573 (* 1 = 1.24573 loss)
I0523 13:48:53.998739  1495 sgd_solver.cpp:106] Iteration 88750, lr = 0.001
I0523 13:49:03.010634  1495 solver.cpp:237] Iteration 89000, loss = 1.29005
I0523 13:49:03.010680  1495 solver.cpp:253]     Train net output #0: loss = 1.29005 (* 1 = 1.29005 loss)
I0523 13:49:03.010694  1495 sgd_solver.cpp:106] Iteration 89000, lr = 0.001
I0523 13:49:12.027616  1495 solver.cpp:237] Iteration 89250, loss = 1.13018
I0523 13:49:12.027650  1495 solver.cpp:253]     Train net output #0: loss = 1.13018 (* 1 = 1.13018 loss)
I0523 13:49:12.027665  1495 sgd_solver.cpp:106] Iteration 89250, lr = 0.001
I0523 13:49:21.040328  1495 solver.cpp:237] Iteration 89500, loss = 1.07829
I0523 13:49:21.040503  1495 solver.cpp:253]     Train net output #0: loss = 1.07829 (* 1 = 1.07829 loss)
I0523 13:49:21.040518  1495 sgd_solver.cpp:106] Iteration 89500, lr = 0.001
I0523 13:49:30.052881  1495 solver.cpp:237] Iteration 89750, loss = 1.16436
I0523 13:49:30.052916  1495 solver.cpp:253]     Train net output #0: loss = 1.16436 (* 1 = 1.16436 loss)
I0523 13:49:30.052932  1495 sgd_solver.cpp:106] Iteration 89750, lr = 0.001
I0523 13:49:39.027415  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_90000.caffemodel
I0523 13:54:51.273380  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_90000.solverstate
I0523 13:54:51.343127  1495 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 13:55:59.514906  1495 solver.cpp:409]     Test net output #0: accuracy = 0.8808
I0523 13:55:59.515102  1495 solver.cpp:409]     Test net output #1: loss = 0.404266 (* 1 = 0.404266 loss)
I0523 13:56:20.418460  1495 solver.cpp:237] Iteration 90000, loss = 1.09258
I0523 13:56:20.418514  1495 solver.cpp:253]     Train net output #0: loss = 1.09258 (* 1 = 1.09258 loss)
I0523 13:56:20.418529  1495 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I0523 13:56:29.524641  1495 solver.cpp:237] Iteration 90250, loss = 1.31045
I0523 13:56:29.524824  1495 solver.cpp:253]     Train net output #0: loss = 1.31045 (* 1 = 1.31045 loss)
I0523 13:56:29.524838  1495 sgd_solver.cpp:106] Iteration 90250, lr = 0.001
I0523 13:56:38.626266  1495 solver.cpp:237] Iteration 90500, loss = 1.22785
I0523 13:56:38.626302  1495 solver.cpp:253]     Train net output #0: loss = 1.22785 (* 1 = 1.22785 loss)
I0523 13:56:38.626317  1495 sgd_solver.cpp:106] Iteration 90500, lr = 0.001
I0523 13:56:47.730018  1495 solver.cpp:237] Iteration 90750, loss = 1.2472
I0523 13:56:47.730053  1495 solver.cpp:253]     Train net output #0: loss = 1.2472 (* 1 = 1.2472 loss)
I0523 13:56:47.730067  1495 sgd_solver.cpp:106] Iteration 90750, lr = 0.001
I0523 13:56:56.829777  1495 solver.cpp:237] Iteration 91000, loss = 1.23137
I0523 13:56:56.829823  1495 solver.cpp:253]     Train net output #0: loss = 1.23137 (* 1 = 1.23137 loss)
I0523 13:56:56.829836  1495 sgd_solver.cpp:106] Iteration 91000, lr = 0.001
I0523 13:57:05.939615  1495 solver.cpp:237] Iteration 91250, loss = 1.53101
I0523 13:57:05.939788  1495 solver.cpp:253]     Train net output #0: loss = 1.53101 (* 1 = 1.53101 loss)
I0523 13:57:05.939801  1495 sgd_solver.cpp:106] Iteration 91250, lr = 0.001
I0523 13:57:15.043365  1495 solver.cpp:237] Iteration 91500, loss = 0.973527
I0523 13:57:15.043411  1495 solver.cpp:253]     Train net output #0: loss = 0.973527 (* 1 = 0.973527 loss)
I0523 13:57:15.043427  1495 sgd_solver.cpp:106] Iteration 91500, lr = 0.001
I0523 13:57:45.019337  1495 solver.cpp:237] Iteration 91750, loss = 1.32746
I0523 13:57:45.019526  1495 solver.cpp:253]     Train net output #0: loss = 1.32746 (* 1 = 1.32746 loss)
I0523 13:57:45.019541  1495 sgd_solver.cpp:106] Iteration 91750, lr = 0.001
I0523 13:57:54.124807  1495 solver.cpp:237] Iteration 92000, loss = 1.12482
I0523 13:57:54.124841  1495 solver.cpp:253]     Train net output #0: loss = 1.12482 (* 1 = 1.12482 loss)
I0523 13:57:54.124856  1495 sgd_solver.cpp:106] Iteration 92000, lr = 0.001
I0523 13:58:03.167304  1495 solver.cpp:237] Iteration 92250, loss = 1.09028
I0523 13:58:03.167340  1495 solver.cpp:253]     Train net output #0: loss = 1.09028 (* 1 = 1.09028 loss)
I0523 13:58:03.167354  1495 sgd_solver.cpp:106] Iteration 92250, lr = 0.001
I0523 13:58:12.175572  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_92500.caffemodel
I0523 13:58:12.238776  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_92500.solverstate
I0523 13:58:12.276666  1495 solver.cpp:237] Iteration 92500, loss = 1.11844
I0523 13:58:12.276711  1495 solver.cpp:253]     Train net output #0: loss = 1.11844 (* 1 = 1.11844 loss)
I0523 13:58:12.276727  1495 sgd_solver.cpp:106] Iteration 92500, lr = 0.001
I0523 13:58:21.310466  1495 solver.cpp:237] Iteration 92750, loss = 1.32761
I0523 13:58:21.310637  1495 solver.cpp:253]     Train net output #0: loss = 1.32761 (* 1 = 1.32761 loss)
I0523 13:58:21.310650  1495 sgd_solver.cpp:106] Iteration 92750, lr = 0.001
I0523 13:58:30.339236  1495 solver.cpp:237] Iteration 93000, loss = 1.36018
I0523 13:58:30.339280  1495 solver.cpp:253]     Train net output #0: loss = 1.36018 (* 1 = 1.36018 loss)
I0523 13:58:30.339296  1495 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I0523 13:58:39.386564  1495 solver.cpp:237] Iteration 93250, loss = 1.21208
I0523 13:58:39.386600  1495 solver.cpp:253]     Train net output #0: loss = 1.21208 (* 1 = 1.21208 loss)
I0523 13:58:39.386615  1495 sgd_solver.cpp:106] Iteration 93250, lr = 0.001
I0523 13:59:09.355418  1495 solver.cpp:237] Iteration 93500, loss = 1.17096
I0523 13:59:09.355612  1495 solver.cpp:253]     Train net output #0: loss = 1.17096 (* 1 = 1.17096 loss)
I0523 13:59:09.355625  1495 sgd_solver.cpp:106] Iteration 93500, lr = 0.001
I0523 13:59:18.398494  1495 solver.cpp:237] Iteration 93750, loss = 1.28066
I0523 13:59:18.398527  1495 solver.cpp:253]     Train net output #0: loss = 1.28066 (* 1 = 1.28066 loss)
I0523 13:59:18.398543  1495 sgd_solver.cpp:106] Iteration 93750, lr = 0.001
I0523 13:59:27.438550  1495 solver.cpp:237] Iteration 94000, loss = 1.01065
I0523 13:59:27.438593  1495 solver.cpp:253]     Train net output #0: loss = 1.01065 (* 1 = 1.01065 loss)
I0523 13:59:27.438607  1495 sgd_solver.cpp:106] Iteration 94000, lr = 0.001
I0523 13:59:36.475172  1495 solver.cpp:237] Iteration 94250, loss = 1.34586
I0523 13:59:36.475206  1495 solver.cpp:253]     Train net output #0: loss = 1.34586 (* 1 = 1.34586 loss)
I0523 13:59:36.475221  1495 sgd_solver.cpp:106] Iteration 94250, lr = 0.001
I0523 13:59:45.523339  1495 solver.cpp:237] Iteration 94500, loss = 1.29527
I0523 13:59:45.523522  1495 solver.cpp:253]     Train net output #0: loss = 1.29527 (* 1 = 1.29527 loss)
I0523 13:59:45.523536  1495 sgd_solver.cpp:106] Iteration 94500, lr = 0.001
I0523 13:59:54.558190  1495 solver.cpp:237] Iteration 94750, loss = 1.21683
I0523 13:59:54.558225  1495 solver.cpp:253]     Train net output #0: loss = 1.21683 (* 1 = 1.21683 loss)
I0523 13:59:54.558240  1495 sgd_solver.cpp:106] Iteration 94750, lr = 0.001
I0523 14:00:03.563868  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_95000.caffemodel
I0523 14:00:03.627980  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_95000.solverstate
I0523 14:00:03.654162  1495 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 14:00:50.646286  1495 solver.cpp:409]     Test net output #0: accuracy = 0.88204
I0523 14:00:50.646486  1495 solver.cpp:409]     Test net output #1: loss = 0.389614 (* 1 = 0.389614 loss)
I0523 14:01:11.566133  1495 solver.cpp:237] Iteration 95000, loss = 1.26629
I0523 14:01:11.566186  1495 solver.cpp:253]     Train net output #0: loss = 1.26629 (* 1 = 1.26629 loss)
I0523 14:01:11.566201  1495 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0523 14:01:20.525511  1495 solver.cpp:237] Iteration 95250, loss = 1.21359
I0523 14:01:20.525552  1495 solver.cpp:253]     Train net output #0: loss = 1.21359 (* 1 = 1.21359 loss)
I0523 14:01:20.525565  1495 sgd_solver.cpp:106] Iteration 95250, lr = 0.001
I0523 14:01:29.483198  1495 solver.cpp:237] Iteration 95500, loss = 1.25887
I0523 14:01:29.483382  1495 solver.cpp:253]     Train net output #0: loss = 1.25887 (* 1 = 1.25887 loss)
I0523 14:01:29.483397  1495 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I0523 14:01:38.447098  1495 solver.cpp:237] Iteration 95750, loss = 1.25305
I0523 14:01:38.447132  1495 solver.cpp:253]     Train net output #0: loss = 1.25305 (* 1 = 1.25305 loss)
I0523 14:01:38.447149  1495 sgd_solver.cpp:106] Iteration 95750, lr = 0.001
I0523 14:01:47.407284  1495 solver.cpp:237] Iteration 96000, loss = 0.993914
I0523 14:01:47.407321  1495 solver.cpp:253]     Train net output #0: loss = 0.993914 (* 1 = 0.993914 loss)
I0523 14:01:47.407335  1495 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0523 14:01:56.369858  1495 solver.cpp:237] Iteration 96250, loss = 1.17943
I0523 14:01:56.369904  1495 solver.cpp:253]     Train net output #0: loss = 1.17943 (* 1 = 1.17943 loss)
I0523 14:01:56.369920  1495 sgd_solver.cpp:106] Iteration 96250, lr = 0.001
I0523 14:02:05.336432  1495 solver.cpp:237] Iteration 96500, loss = 1.0975
I0523 14:02:05.336603  1495 solver.cpp:253]     Train net output #0: loss = 1.0975 (* 1 = 1.0975 loss)
I0523 14:02:05.336616  1495 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I0523 14:02:35.179343  1495 solver.cpp:237] Iteration 96750, loss = 1.32904
I0523 14:02:35.179394  1495 solver.cpp:253]     Train net output #0: loss = 1.32904 (* 1 = 1.32904 loss)
I0523 14:02:35.179409  1495 sgd_solver.cpp:106] Iteration 96750, lr = 0.001
I0523 14:02:44.144873  1495 solver.cpp:237] Iteration 97000, loss = 1.53445
I0523 14:02:44.145061  1495 solver.cpp:253]     Train net output #0: loss = 1.53445 (* 1 = 1.53445 loss)
I0523 14:02:44.145074  1495 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0523 14:02:53.098971  1495 solver.cpp:237] Iteration 97250, loss = 1.13326
I0523 14:02:53.099006  1495 solver.cpp:253]     Train net output #0: loss = 1.13326 (* 1 = 1.13326 loss)
I0523 14:02:53.099022  1495 sgd_solver.cpp:106] Iteration 97250, lr = 0.001
I0523 14:03:02.018556  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_97500.caffemodel
I0523 14:03:02.081117  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_97500.solverstate
I0523 14:03:02.123333  1495 solver.cpp:237] Iteration 97500, loss = 1.26679
I0523 14:03:02.123380  1495 solver.cpp:253]     Train net output #0: loss = 1.26679 (* 1 = 1.26679 loss)
I0523 14:03:02.123395  1495 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0523 14:03:11.084211  1495 solver.cpp:237] Iteration 97750, loss = 1.31687
I0523 14:03:11.084260  1495 solver.cpp:253]     Train net output #0: loss = 1.31687 (* 1 = 1.31687 loss)
I0523 14:03:11.084275  1495 sgd_solver.cpp:106] Iteration 97750, lr = 0.001
I0523 14:03:20.048005  1495 solver.cpp:237] Iteration 98000, loss = 1.257
I0523 14:03:20.048198  1495 solver.cpp:253]     Train net output #0: loss = 1.257 (* 1 = 1.257 loss)
I0523 14:03:20.048213  1495 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0523 14:03:28.996912  1495 solver.cpp:237] Iteration 98250, loss = 1.32422
I0523 14:03:28.996948  1495 solver.cpp:253]     Train net output #0: loss = 1.32422 (* 1 = 1.32422 loss)
I0523 14:03:28.996963  1495 sgd_solver.cpp:106] Iteration 98250, lr = 0.001
I0523 14:03:58.865509  1495 solver.cpp:237] Iteration 98500, loss = 1.17846
I0523 14:03:58.865697  1495 solver.cpp:253]     Train net output #0: loss = 1.17846 (* 1 = 1.17846 loss)
I0523 14:03:58.865711  1495 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I0523 14:04:07.833561  1495 solver.cpp:237] Iteration 98750, loss = 1.42581
I0523 14:04:07.833596  1495 solver.cpp:253]     Train net output #0: loss = 1.42581 (* 1 = 1.42581 loss)
I0523 14:04:07.833612  1495 sgd_solver.cpp:106] Iteration 98750, lr = 0.001
I0523 14:04:16.787336  1495 solver.cpp:237] Iteration 99000, loss = 1.24838
I0523 14:04:16.787372  1495 solver.cpp:253]     Train net output #0: loss = 1.24838 (* 1 = 1.24838 loss)
I0523 14:04:16.787386  1495 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0523 14:04:25.748790  1495 solver.cpp:237] Iteration 99250, loss = 1.57188
I0523 14:04:25.748832  1495 solver.cpp:253]     Train net output #0: loss = 1.57188 (* 1 = 1.57188 loss)
I0523 14:04:25.748852  1495 sgd_solver.cpp:106] Iteration 99250, lr = 0.001
I0523 14:04:34.714279  1495 solver.cpp:237] Iteration 99500, loss = 0.905014
I0523 14:04:34.714460  1495 solver.cpp:253]     Train net output #0: loss = 0.905014 (* 1 = 0.905014 loss)
I0523 14:04:34.714474  1495 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I0523 14:04:43.674391  1495 solver.cpp:237] Iteration 99750, loss = 1.2689
I0523 14:04:43.674425  1495 solver.cpp:253]     Train net output #0: loss = 1.2689 (* 1 = 1.2689 loss)
I0523 14:04:43.674440  1495 sgd_solver.cpp:106] Iteration 99750, lr = 0.001
I0523 14:04:52.598958  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_100000.caffemodel
I0523 14:04:52.663506  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_100000.solverstate
I0523 14:04:52.690912  1495 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 14:06:00.860338  1495 solver.cpp:409]     Test net output #0: accuracy = 0.883726
I0523 14:06:00.860525  1495 solver.cpp:409]     Test net output #1: loss = 0.393764 (* 1 = 0.393764 loss)
I0523 14:06:21.757262  1495 solver.cpp:237] Iteration 100000, loss = 1.26746
I0523 14:06:21.757315  1495 solver.cpp:253]     Train net output #0: loss = 1.26746 (* 1 = 1.26746 loss)
I0523 14:06:21.757330  1495 sgd_solver.cpp:106] Iteration 100000, lr = 0.001
I0523 14:06:30.874630  1495 solver.cpp:237] Iteration 100250, loss = 1.15775
I0523 14:06:30.874814  1495 solver.cpp:253]     Train net output #0: loss = 1.15775 (* 1 = 1.15775 loss)
I0523 14:06:30.874828  1495 sgd_solver.cpp:106] Iteration 100250, lr = 0.001
I0523 14:06:40.006808  1495 solver.cpp:237] Iteration 100500, loss = 1.05673
I0523 14:06:40.006842  1495 solver.cpp:253]     Train net output #0: loss = 1.05673 (* 1 = 1.05673 loss)
I0523 14:06:40.006858  1495 sgd_solver.cpp:106] Iteration 100500, lr = 0.001
I0523 14:06:49.124694  1495 solver.cpp:237] Iteration 100750, loss = 1.23774
I0523 14:06:49.124729  1495 solver.cpp:253]     Train net output #0: loss = 1.23774 (* 1 = 1.23774 loss)
I0523 14:06:49.124745  1495 sgd_solver.cpp:106] Iteration 100750, lr = 0.001
I0523 14:06:58.255926  1495 solver.cpp:237] Iteration 101000, loss = 1.17152
I0523 14:06:58.255966  1495 solver.cpp:253]     Train net output #0: loss = 1.17152 (* 1 = 1.17152 loss)
I0523 14:06:58.255986  1495 sgd_solver.cpp:106] Iteration 101000, lr = 0.001
I0523 14:07:07.385067  1495 solver.cpp:237] Iteration 101250, loss = 1.08517
I0523 14:07:07.385251  1495 solver.cpp:253]     Train net output #0: loss = 1.08517 (* 1 = 1.08517 loss)
I0523 14:07:07.385264  1495 sgd_solver.cpp:106] Iteration 101250, lr = 0.001
I0523 14:07:16.515959  1495 solver.cpp:237] Iteration 101500, loss = 1.34989
I0523 14:07:16.516007  1495 solver.cpp:253]     Train net output #0: loss = 1.34989 (* 1 = 1.34989 loss)
I0523 14:07:16.516022  1495 sgd_solver.cpp:106] Iteration 101500, lr = 0.001
I0523 14:07:46.540416  1495 solver.cpp:237] Iteration 101750, loss = 1.37292
I0523 14:07:46.540611  1495 solver.cpp:253]     Train net output #0: loss = 1.37292 (* 1 = 1.37292 loss)
I0523 14:07:46.540626  1495 sgd_solver.cpp:106] Iteration 101750, lr = 0.001
I0523 14:07:55.668728  1495 solver.cpp:237] Iteration 102000, loss = 1.05836
I0523 14:07:55.668762  1495 solver.cpp:253]     Train net output #0: loss = 1.05836 (* 1 = 1.05836 loss)
I0523 14:07:55.668778  1495 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I0523 14:08:04.807854  1495 solver.cpp:237] Iteration 102250, loss = 1.67463
I0523 14:08:04.807888  1495 solver.cpp:253]     Train net output #0: loss = 1.67463 (* 1 = 1.67463 loss)
I0523 14:08:04.807901  1495 sgd_solver.cpp:106] Iteration 102250, lr = 0.001
I0523 14:08:13.894182  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_102500.caffemodel
I0523 14:08:13.956477  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_102500.solverstate
I0523 14:08:13.993180  1495 solver.cpp:237] Iteration 102500, loss = 0.975082
I0523 14:08:13.993221  1495 solver.cpp:253]     Train net output #0: loss = 0.975082 (* 1 = 0.975082 loss)
I0523 14:08:13.993240  1495 sgd_solver.cpp:106] Iteration 102500, lr = 0.001
I0523 14:08:23.115381  1495 solver.cpp:237] Iteration 102750, loss = 0.913275
I0523 14:08:23.115558  1495 solver.cpp:253]     Train net output #0: loss = 0.913275 (* 1 = 0.913275 loss)
I0523 14:08:23.115572  1495 sgd_solver.cpp:106] Iteration 102750, lr = 0.001
I0523 14:08:32.246490  1495 solver.cpp:237] Iteration 103000, loss = 1.49264
I0523 14:08:32.246532  1495 solver.cpp:253]     Train net output #0: loss = 1.49264 (* 1 = 1.49264 loss)
I0523 14:08:32.246549  1495 sgd_solver.cpp:106] Iteration 103000, lr = 0.001
I0523 14:08:41.375445  1495 solver.cpp:237] Iteration 103250, loss = 1.07619
I0523 14:08:41.375479  1495 solver.cpp:253]     Train net output #0: loss = 1.07619 (* 1 = 1.07619 loss)
I0523 14:08:41.375495  1495 sgd_solver.cpp:106] Iteration 103250, lr = 0.001
I0523 14:09:11.392920  1495 solver.cpp:237] Iteration 103500, loss = 0.992512
I0523 14:09:11.393115  1495 solver.cpp:253]     Train net output #0: loss = 0.992512 (* 1 = 0.992512 loss)
I0523 14:09:11.393129  1495 sgd_solver.cpp:106] Iteration 103500, lr = 0.001
I0523 14:09:20.517228  1495 solver.cpp:237] Iteration 103750, loss = 1.0875
I0523 14:09:20.517272  1495 solver.cpp:253]     Train net output #0: loss = 1.0875 (* 1 = 1.0875 loss)
I0523 14:09:20.517287  1495 sgd_solver.cpp:106] Iteration 103750, lr = 0.001
I0523 14:09:29.645848  1495 solver.cpp:237] Iteration 104000, loss = 1.14961
I0523 14:09:29.645882  1495 solver.cpp:253]     Train net output #0: loss = 1.14961 (* 1 = 1.14961 loss)
I0523 14:09:29.645898  1495 sgd_solver.cpp:106] Iteration 104000, lr = 0.001
I0523 14:09:38.776257  1495 solver.cpp:237] Iteration 104250, loss = 1.35684
I0523 14:09:38.776291  1495 solver.cpp:253]     Train net output #0: loss = 1.35684 (* 1 = 1.35684 loss)
I0523 14:09:38.776306  1495 sgd_solver.cpp:106] Iteration 104250, lr = 0.001
I0523 14:09:47.905328  1495 solver.cpp:237] Iteration 104500, loss = 1.38411
I0523 14:09:47.905521  1495 solver.cpp:253]     Train net output #0: loss = 1.38411 (* 1 = 1.38411 loss)
I0523 14:09:47.905535  1495 sgd_solver.cpp:106] Iteration 104500, lr = 0.001
I0523 14:09:57.021888  1495 solver.cpp:237] Iteration 104750, loss = 1.29283
I0523 14:09:57.021922  1495 solver.cpp:253]     Train net output #0: loss = 1.29283 (* 1 = 1.29283 loss)
I0523 14:09:57.021939  1495 sgd_solver.cpp:106] Iteration 104750, lr = 0.001
I0523 14:10:06.114784  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_105000.caffemodel
I0523 14:10:06.179729  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_105000.solverstate
I0523 14:10:06.205730  1495 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 14:10:53.511498  1495 solver.cpp:409]     Test net output #0: accuracy = 0.88406
I0523 14:10:53.511689  1495 solver.cpp:409]     Test net output #1: loss = 0.370302 (* 1 = 0.370302 loss)
I0523 14:11:14.426229  1495 solver.cpp:237] Iteration 105000, loss = 1.16368
I0523 14:11:14.426281  1495 solver.cpp:253]     Train net output #0: loss = 1.16368 (* 1 = 1.16368 loss)
I0523 14:11:14.426297  1495 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I0523 14:11:23.469353  1495 solver.cpp:237] Iteration 105250, loss = 0.973182
I0523 14:11:23.469389  1495 solver.cpp:253]     Train net output #0: loss = 0.973182 (* 1 = 0.973182 loss)
I0523 14:11:23.469404  1495 sgd_solver.cpp:106] Iteration 105250, lr = 0.001
I0523 14:11:32.525637  1495 solver.cpp:237] Iteration 105500, loss = 1.08959
I0523 14:11:32.525823  1495 solver.cpp:253]     Train net output #0: loss = 1.08959 (* 1 = 1.08959 loss)
I0523 14:11:32.525837  1495 sgd_solver.cpp:106] Iteration 105500, lr = 0.001
I0523 14:11:41.568341  1495 solver.cpp:237] Iteration 105750, loss = 1.25012
I0523 14:11:41.568377  1495 solver.cpp:253]     Train net output #0: loss = 1.25012 (* 1 = 1.25012 loss)
I0523 14:11:41.568392  1495 sgd_solver.cpp:106] Iteration 105750, lr = 0.001
I0523 14:11:50.614141  1495 solver.cpp:237] Iteration 106000, loss = 1.5115
I0523 14:11:50.614181  1495 solver.cpp:253]     Train net output #0: loss = 1.5115 (* 1 = 1.5115 loss)
I0523 14:11:50.614199  1495 sgd_solver.cpp:106] Iteration 106000, lr = 0.001
I0523 14:11:59.667078  1495 solver.cpp:237] Iteration 106250, loss = 1.19779
I0523 14:11:59.667112  1495 solver.cpp:253]     Train net output #0: loss = 1.19779 (* 1 = 1.19779 loss)
I0523 14:11:59.667129  1495 sgd_solver.cpp:106] Iteration 106250, lr = 0.001
I0523 14:12:08.715606  1495 solver.cpp:237] Iteration 106500, loss = 1.17976
I0523 14:12:08.715776  1495 solver.cpp:253]     Train net output #0: loss = 1.17976 (* 1 = 1.17976 loss)
I0523 14:12:08.715790  1495 sgd_solver.cpp:106] Iteration 106500, lr = 0.001
I0523 14:12:38.674219  1495 solver.cpp:237] Iteration 106750, loss = 1.27836
I0523 14:12:38.674269  1495 solver.cpp:253]     Train net output #0: loss = 1.27836 (* 1 = 1.27836 loss)
I0523 14:12:38.674284  1495 sgd_solver.cpp:106] Iteration 106750, lr = 0.001
I0523 14:12:47.736678  1495 solver.cpp:237] Iteration 107000, loss = 1.06414
I0523 14:12:47.736863  1495 solver.cpp:253]     Train net output #0: loss = 1.06414 (* 1 = 1.06414 loss)
I0523 14:12:47.736877  1495 sgd_solver.cpp:106] Iteration 107000, lr = 0.001
I0523 14:12:56.787559  1495 solver.cpp:237] Iteration 107250, loss = 1.10047
I0523 14:12:56.787593  1495 solver.cpp:253]     Train net output #0: loss = 1.10047 (* 1 = 1.10047 loss)
I0523 14:12:56.787608  1495 sgd_solver.cpp:106] Iteration 107250, lr = 0.001
I0523 14:13:05.803297  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_107500.caffemodel
I0523 14:13:05.867750  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_107500.solverstate
I0523 14:13:05.904276  1495 solver.cpp:237] Iteration 107500, loss = 1.12986
I0523 14:13:05.904317  1495 solver.cpp:253]     Train net output #0: loss = 1.12986 (* 1 = 1.12986 loss)
I0523 14:13:05.904336  1495 sgd_solver.cpp:106] Iteration 107500, lr = 0.001
I0523 14:13:14.957118  1495 solver.cpp:237] Iteration 107750, loss = 1.1368
I0523 14:13:14.957154  1495 solver.cpp:253]     Train net output #0: loss = 1.1368 (* 1 = 1.1368 loss)
I0523 14:13:14.957168  1495 sgd_solver.cpp:106] Iteration 107750, lr = 0.001
I0523 14:13:24.008545  1495 solver.cpp:237] Iteration 108000, loss = 1.03811
I0523 14:13:24.008739  1495 solver.cpp:253]     Train net output #0: loss = 1.03811 (* 1 = 1.03811 loss)
I0523 14:13:24.008754  1495 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I0523 14:13:33.061837  1495 solver.cpp:237] Iteration 108250, loss = 1.22592
I0523 14:13:33.061882  1495 solver.cpp:253]     Train net output #0: loss = 1.22592 (* 1 = 1.22592 loss)
I0523 14:13:33.061898  1495 sgd_solver.cpp:106] Iteration 108250, lr = 0.001
I0523 14:14:03.002864  1495 solver.cpp:237] Iteration 108500, loss = 1.15291
I0523 14:14:03.003058  1495 solver.cpp:253]     Train net output #0: loss = 1.15291 (* 1 = 1.15291 loss)
I0523 14:14:03.003072  1495 sgd_solver.cpp:106] Iteration 108500, lr = 0.001
I0523 14:14:12.057008  1495 solver.cpp:237] Iteration 108750, loss = 1.12912
I0523 14:14:12.057042  1495 solver.cpp:253]     Train net output #0: loss = 1.12912 (* 1 = 1.12912 loss)
I0523 14:14:12.057059  1495 sgd_solver.cpp:106] Iteration 108750, lr = 0.001
I0523 14:14:21.114183  1495 solver.cpp:237] Iteration 109000, loss = 1.20444
I0523 14:14:21.114234  1495 solver.cpp:253]     Train net output #0: loss = 1.20444 (* 1 = 1.20444 loss)
I0523 14:14:21.114249  1495 sgd_solver.cpp:106] Iteration 109000, lr = 0.001
I0523 14:14:30.161849  1495 solver.cpp:237] Iteration 109250, loss = 1.02571
I0523 14:14:30.161885  1495 solver.cpp:253]     Train net output #0: loss = 1.02571 (* 1 = 1.02571 loss)
I0523 14:14:30.161900  1495 sgd_solver.cpp:106] Iteration 109250, lr = 0.001
I0523 14:14:39.216779  1495 solver.cpp:237] Iteration 109500, loss = 1.10633
I0523 14:14:39.216953  1495 solver.cpp:253]     Train net output #0: loss = 1.10633 (* 1 = 1.10633 loss)
I0523 14:14:39.216966  1495 sgd_solver.cpp:106] Iteration 109500, lr = 0.001
I0523 14:14:48.277146  1495 solver.cpp:237] Iteration 109750, loss = 0.948328
I0523 14:14:48.277194  1495 solver.cpp:253]     Train net output #0: loss = 0.948328 (* 1 = 0.948328 loss)
I0523 14:14:48.277207  1495 sgd_solver.cpp:106] Iteration 109750, lr = 0.001
I0523 14:14:57.299664  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_110000.caffemodel
I0523 14:14:57.378973  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_110000.solverstate
I0523 14:14:57.404969  1495 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 14:16:05.532392  1495 solver.cpp:409]     Test net output #0: accuracy = 0.88584
I0523 14:16:05.532584  1495 solver.cpp:409]     Test net output #1: loss = 0.389188 (* 1 = 0.389188 loss)
I0523 14:16:26.481271  1495 solver.cpp:237] Iteration 110000, loss = 0.804156
I0523 14:16:26.481324  1495 solver.cpp:253]     Train net output #0: loss = 0.804156 (* 1 = 0.804156 loss)
I0523 14:16:26.481340  1495 sgd_solver.cpp:106] Iteration 110000, lr = 0.001
I0523 14:16:35.581387  1495 solver.cpp:237] Iteration 110250, loss = 1.43041
I0523 14:16:35.581575  1495 solver.cpp:253]     Train net output #0: loss = 1.43041 (* 1 = 1.43041 loss)
I0523 14:16:35.581589  1495 sgd_solver.cpp:106] Iteration 110250, lr = 0.001
I0523 14:16:44.685325  1495 solver.cpp:237] Iteration 110500, loss = 1.11258
I0523 14:16:44.685360  1495 solver.cpp:253]     Train net output #0: loss = 1.11258 (* 1 = 1.11258 loss)
I0523 14:16:44.685376  1495 sgd_solver.cpp:106] Iteration 110500, lr = 0.001
I0523 14:16:53.789575  1495 solver.cpp:237] Iteration 110750, loss = 0.965832
I0523 14:16:53.789618  1495 solver.cpp:253]     Train net output #0: loss = 0.965832 (* 1 = 0.965832 loss)
I0523 14:16:53.789638  1495 sgd_solver.cpp:106] Iteration 110750, lr = 0.001
I0523 14:17:02.885489  1495 solver.cpp:237] Iteration 111000, loss = 1.25167
I0523 14:17:02.885524  1495 solver.cpp:253]     Train net output #0: loss = 1.25167 (* 1 = 1.25167 loss)
I0523 14:17:02.885538  1495 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I0523 14:17:11.980192  1495 solver.cpp:237] Iteration 111250, loss = 1.01166
I0523 14:17:11.980377  1495 solver.cpp:253]     Train net output #0: loss = 1.01166 (* 1 = 1.01166 loss)
I0523 14:17:11.980391  1495 sgd_solver.cpp:106] Iteration 111250, lr = 0.001
I0523 14:17:21.079673  1495 solver.cpp:237] Iteration 111500, loss = 1.04962
I0523 14:17:21.079720  1495 solver.cpp:253]     Train net output #0: loss = 1.04962 (* 1 = 1.04962 loss)
I0523 14:17:21.079736  1495 sgd_solver.cpp:106] Iteration 111500, lr = 0.001
I0523 14:17:51.062674  1495 solver.cpp:237] Iteration 111750, loss = 1.19761
I0523 14:17:51.062870  1495 solver.cpp:253]     Train net output #0: loss = 1.19761 (* 1 = 1.19761 loss)
I0523 14:17:51.062883  1495 sgd_solver.cpp:106] Iteration 111750, lr = 0.001
I0523 14:18:00.155267  1495 solver.cpp:237] Iteration 112000, loss = 1.22299
I0523 14:18:00.155302  1495 solver.cpp:253]     Train net output #0: loss = 1.22299 (* 1 = 1.22299 loss)
I0523 14:18:00.155318  1495 sgd_solver.cpp:106] Iteration 112000, lr = 0.001
I0523 14:18:09.251057  1495 solver.cpp:237] Iteration 112250, loss = 1.00835
I0523 14:18:09.251096  1495 solver.cpp:253]     Train net output #0: loss = 1.00835 (* 1 = 1.00835 loss)
I0523 14:18:09.251109  1495 sgd_solver.cpp:106] Iteration 112250, lr = 0.001
I0523 14:18:18.310148  1495 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_112500.caffemodel
I0523 14:18:18.375659  1495 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0010_2016-05-20T15.49.09.172977_iter_112500.solverstate
I0523 14:18:18.414199  1495 solver.cpp:237] Iteration 112500, loss = 1.36713
I0523 14:18:18.414245  1495 solver.cpp:253]     Train net output #0: loss = 1.36713 (* 1 = 1.36713 loss)
I0523 14:18:18.414265  1495 sgd_solver.cpp:106] Iteration 112500, lr = 0.001
I0523 14:18:27.505906  1495 solver.cpp:237] Iteration 112750, loss = 1.15674
I0523 14:18:27.506086  1495 solver.cpp:253]     Train net output #0: loss = 1.15674 (* 1 = 1.15674 loss)
I0523 14:18:27.506099  1495 sgd_solver.cpp:106] Iteration 112750, lr = 0.001
=>> PBS: job killed: walltime 7202 exceeded limit 7200
aprun: Apid 11255355: Caught signal Terminated, sending to application
*** Aborted at 1464027516 (unix time) try "date -d @1464027516" if you are using GNU date ***
PC: @     0x2aaab930eb63 (unknown)
*** SIGTERM (@0x5d4) received by PID 1495 (TID 0x2aaac746f900) from PID 1492; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab930eb63 (unknown)
    @     0x2aaab928a368 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11255355: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11255355: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11255355: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
aprun: Apid 11255355: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02349] [c6-1c0s6n3] [Mon May 23 14:18:38 2016] PE RANK 0 exit signal Terminated
Application 11255355 exit codes: 143
Application 11255355 resources: utime ~5959s, stime ~920s, Rss ~5329848, inblocks ~15410860, outblocks ~696233
