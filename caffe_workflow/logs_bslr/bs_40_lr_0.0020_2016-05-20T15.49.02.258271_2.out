2813203
I0527 09:16:04.799854 22103 caffe.cpp:184] Using GPUs 0
I0527 09:16:05.226411 22103 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.002
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271.prototxt"
I0527 09:16:05.228617 22103 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271.prototxt
I0527 09:16:05.250283 22103 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 09:16:05.250339 22103 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 09:16:05.250684 22103 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 09:16:05.250864 22103 layer_factory.hpp:77] Creating layer data_hdf5
I0527 09:16:05.250888 22103 net.cpp:106] Creating Layer data_hdf5
I0527 09:16:05.250902 22103 net.cpp:411] data_hdf5 -> data
I0527 09:16:05.250936 22103 net.cpp:411] data_hdf5 -> label
I0527 09:16:05.250968 22103 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 09:16:05.253054 22103 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 09:16:05.268751 22103 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 09:16:26.801836 22103 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 09:16:26.807029 22103 net.cpp:150] Setting up data_hdf5
I0527 09:16:26.807068 22103 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 09:16:26.807083 22103 net.cpp:157] Top shape: 40 (40)
I0527 09:16:26.807095 22103 net.cpp:165] Memory required for data: 1016160
I0527 09:16:26.807107 22103 layer_factory.hpp:77] Creating layer conv1
I0527 09:16:26.807140 22103 net.cpp:106] Creating Layer conv1
I0527 09:16:26.807152 22103 net.cpp:454] conv1 <- data
I0527 09:16:26.807173 22103 net.cpp:411] conv1 -> conv1
I0527 09:16:27.709892 22103 net.cpp:150] Setting up conv1
I0527 09:16:27.709938 22103 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:16:27.709949 22103 net.cpp:165] Memory required for data: 12075360
I0527 09:16:27.709976 22103 layer_factory.hpp:77] Creating layer relu1
I0527 09:16:27.710007 22103 net.cpp:106] Creating Layer relu1
I0527 09:16:27.710018 22103 net.cpp:454] relu1 <- conv1
I0527 09:16:27.710032 22103 net.cpp:397] relu1 -> conv1 (in-place)
I0527 09:16:27.710554 22103 net.cpp:150] Setting up relu1
I0527 09:16:27.710572 22103 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:16:27.710582 22103 net.cpp:165] Memory required for data: 23134560
I0527 09:16:27.710592 22103 layer_factory.hpp:77] Creating layer pool1
I0527 09:16:27.710608 22103 net.cpp:106] Creating Layer pool1
I0527 09:16:27.710618 22103 net.cpp:454] pool1 <- conv1
I0527 09:16:27.710631 22103 net.cpp:411] pool1 -> pool1
I0527 09:16:27.710711 22103 net.cpp:150] Setting up pool1
I0527 09:16:27.710726 22103 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 09:16:27.710736 22103 net.cpp:165] Memory required for data: 28664160
I0527 09:16:27.710747 22103 layer_factory.hpp:77] Creating layer conv2
I0527 09:16:27.710769 22103 net.cpp:106] Creating Layer conv2
I0527 09:16:27.710779 22103 net.cpp:454] conv2 <- pool1
I0527 09:16:27.710793 22103 net.cpp:411] conv2 -> conv2
I0527 09:16:27.713460 22103 net.cpp:150] Setting up conv2
I0527 09:16:27.713487 22103 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:16:27.713498 22103 net.cpp:165] Memory required for data: 36612960
I0527 09:16:27.713517 22103 layer_factory.hpp:77] Creating layer relu2
I0527 09:16:27.713531 22103 net.cpp:106] Creating Layer relu2
I0527 09:16:27.713541 22103 net.cpp:454] relu2 <- conv2
I0527 09:16:27.713554 22103 net.cpp:397] relu2 -> conv2 (in-place)
I0527 09:16:27.713883 22103 net.cpp:150] Setting up relu2
I0527 09:16:27.713897 22103 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:16:27.713907 22103 net.cpp:165] Memory required for data: 44561760
I0527 09:16:27.713917 22103 layer_factory.hpp:77] Creating layer pool2
I0527 09:16:27.713930 22103 net.cpp:106] Creating Layer pool2
I0527 09:16:27.713940 22103 net.cpp:454] pool2 <- conv2
I0527 09:16:27.713953 22103 net.cpp:411] pool2 -> pool2
I0527 09:16:27.714045 22103 net.cpp:150] Setting up pool2
I0527 09:16:27.714058 22103 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 09:16:27.714068 22103 net.cpp:165] Memory required for data: 48536160
I0527 09:16:27.714079 22103 layer_factory.hpp:77] Creating layer conv3
I0527 09:16:27.714097 22103 net.cpp:106] Creating Layer conv3
I0527 09:16:27.714107 22103 net.cpp:454] conv3 <- pool2
I0527 09:16:27.714121 22103 net.cpp:411] conv3 -> conv3
I0527 09:16:27.716059 22103 net.cpp:150] Setting up conv3
I0527 09:16:27.716078 22103 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:16:27.716089 22103 net.cpp:165] Memory required for data: 52872800
I0527 09:16:27.716107 22103 layer_factory.hpp:77] Creating layer relu3
I0527 09:16:27.716123 22103 net.cpp:106] Creating Layer relu3
I0527 09:16:27.716133 22103 net.cpp:454] relu3 <- conv3
I0527 09:16:27.716146 22103 net.cpp:397] relu3 -> conv3 (in-place)
I0527 09:16:27.716616 22103 net.cpp:150] Setting up relu3
I0527 09:16:27.716634 22103 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:16:27.716644 22103 net.cpp:165] Memory required for data: 57209440
I0527 09:16:27.716653 22103 layer_factory.hpp:77] Creating layer pool3
I0527 09:16:27.716666 22103 net.cpp:106] Creating Layer pool3
I0527 09:16:27.716676 22103 net.cpp:454] pool3 <- conv3
I0527 09:16:27.716689 22103 net.cpp:411] pool3 -> pool3
I0527 09:16:27.716755 22103 net.cpp:150] Setting up pool3
I0527 09:16:27.716769 22103 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 09:16:27.716778 22103 net.cpp:165] Memory required for data: 59377760
I0527 09:16:27.716789 22103 layer_factory.hpp:77] Creating layer conv4
I0527 09:16:27.716806 22103 net.cpp:106] Creating Layer conv4
I0527 09:16:27.716816 22103 net.cpp:454] conv4 <- pool3
I0527 09:16:27.716830 22103 net.cpp:411] conv4 -> conv4
I0527 09:16:27.719589 22103 net.cpp:150] Setting up conv4
I0527 09:16:27.719619 22103 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:16:27.719630 22103 net.cpp:165] Memory required for data: 60829280
I0527 09:16:27.719645 22103 layer_factory.hpp:77] Creating layer relu4
I0527 09:16:27.719660 22103 net.cpp:106] Creating Layer relu4
I0527 09:16:27.719669 22103 net.cpp:454] relu4 <- conv4
I0527 09:16:27.719682 22103 net.cpp:397] relu4 -> conv4 (in-place)
I0527 09:16:27.720157 22103 net.cpp:150] Setting up relu4
I0527 09:16:27.720173 22103 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:16:27.720185 22103 net.cpp:165] Memory required for data: 62280800
I0527 09:16:27.720194 22103 layer_factory.hpp:77] Creating layer pool4
I0527 09:16:27.720207 22103 net.cpp:106] Creating Layer pool4
I0527 09:16:27.720217 22103 net.cpp:454] pool4 <- conv4
I0527 09:16:27.720230 22103 net.cpp:411] pool4 -> pool4
I0527 09:16:27.720298 22103 net.cpp:150] Setting up pool4
I0527 09:16:27.720311 22103 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 09:16:27.720321 22103 net.cpp:165] Memory required for data: 63006560
I0527 09:16:27.720331 22103 layer_factory.hpp:77] Creating layer ip1
I0527 09:16:27.720350 22103 net.cpp:106] Creating Layer ip1
I0527 09:16:27.720360 22103 net.cpp:454] ip1 <- pool4
I0527 09:16:27.720373 22103 net.cpp:411] ip1 -> ip1
I0527 09:16:27.735821 22103 net.cpp:150] Setting up ip1
I0527 09:16:27.735849 22103 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:16:27.735862 22103 net.cpp:165] Memory required for data: 63037920
I0527 09:16:27.735888 22103 layer_factory.hpp:77] Creating layer relu5
I0527 09:16:27.735903 22103 net.cpp:106] Creating Layer relu5
I0527 09:16:27.735913 22103 net.cpp:454] relu5 <- ip1
I0527 09:16:27.735926 22103 net.cpp:397] relu5 -> ip1 (in-place)
I0527 09:16:27.736268 22103 net.cpp:150] Setting up relu5
I0527 09:16:27.736281 22103 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:16:27.736292 22103 net.cpp:165] Memory required for data: 63069280
I0527 09:16:27.736302 22103 layer_factory.hpp:77] Creating layer drop1
I0527 09:16:27.736325 22103 net.cpp:106] Creating Layer drop1
I0527 09:16:27.736335 22103 net.cpp:454] drop1 <- ip1
I0527 09:16:27.736347 22103 net.cpp:397] drop1 -> ip1 (in-place)
I0527 09:16:27.736407 22103 net.cpp:150] Setting up drop1
I0527 09:16:27.736420 22103 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:16:27.736429 22103 net.cpp:165] Memory required for data: 63100640
I0527 09:16:27.736440 22103 layer_factory.hpp:77] Creating layer ip2
I0527 09:16:27.736459 22103 net.cpp:106] Creating Layer ip2
I0527 09:16:27.736469 22103 net.cpp:454] ip2 <- ip1
I0527 09:16:27.736481 22103 net.cpp:411] ip2 -> ip2
I0527 09:16:27.736942 22103 net.cpp:150] Setting up ip2
I0527 09:16:27.736955 22103 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:16:27.736964 22103 net.cpp:165] Memory required for data: 63116320
I0527 09:16:27.736979 22103 layer_factory.hpp:77] Creating layer relu6
I0527 09:16:27.736992 22103 net.cpp:106] Creating Layer relu6
I0527 09:16:27.737001 22103 net.cpp:454] relu6 <- ip2
I0527 09:16:27.737013 22103 net.cpp:397] relu6 -> ip2 (in-place)
I0527 09:16:27.737532 22103 net.cpp:150] Setting up relu6
I0527 09:16:27.737548 22103 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:16:27.737560 22103 net.cpp:165] Memory required for data: 63132000
I0527 09:16:27.737570 22103 layer_factory.hpp:77] Creating layer drop2
I0527 09:16:27.737582 22103 net.cpp:106] Creating Layer drop2
I0527 09:16:27.737591 22103 net.cpp:454] drop2 <- ip2
I0527 09:16:27.737604 22103 net.cpp:397] drop2 -> ip2 (in-place)
I0527 09:16:27.737648 22103 net.cpp:150] Setting up drop2
I0527 09:16:27.737660 22103 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:16:27.737670 22103 net.cpp:165] Memory required for data: 63147680
I0527 09:16:27.737680 22103 layer_factory.hpp:77] Creating layer ip3
I0527 09:16:27.737694 22103 net.cpp:106] Creating Layer ip3
I0527 09:16:27.737704 22103 net.cpp:454] ip3 <- ip2
I0527 09:16:27.737716 22103 net.cpp:411] ip3 -> ip3
I0527 09:16:27.737927 22103 net.cpp:150] Setting up ip3
I0527 09:16:27.737941 22103 net.cpp:157] Top shape: 40 11 (440)
I0527 09:16:27.737951 22103 net.cpp:165] Memory required for data: 63149440
I0527 09:16:27.737965 22103 layer_factory.hpp:77] Creating layer drop3
I0527 09:16:27.737978 22103 net.cpp:106] Creating Layer drop3
I0527 09:16:27.737995 22103 net.cpp:454] drop3 <- ip3
I0527 09:16:27.738008 22103 net.cpp:397] drop3 -> ip3 (in-place)
I0527 09:16:27.738047 22103 net.cpp:150] Setting up drop3
I0527 09:16:27.738061 22103 net.cpp:157] Top shape: 40 11 (440)
I0527 09:16:27.738071 22103 net.cpp:165] Memory required for data: 63151200
I0527 09:16:27.738081 22103 layer_factory.hpp:77] Creating layer loss
I0527 09:16:27.738101 22103 net.cpp:106] Creating Layer loss
I0527 09:16:27.738109 22103 net.cpp:454] loss <- ip3
I0527 09:16:27.738121 22103 net.cpp:454] loss <- label
I0527 09:16:27.738133 22103 net.cpp:411] loss -> loss
I0527 09:16:27.738150 22103 layer_factory.hpp:77] Creating layer loss
I0527 09:16:27.738795 22103 net.cpp:150] Setting up loss
I0527 09:16:27.738816 22103 net.cpp:157] Top shape: (1)
I0527 09:16:27.738829 22103 net.cpp:160]     with loss weight 1
I0527 09:16:27.738872 22103 net.cpp:165] Memory required for data: 63151204
I0527 09:16:27.738883 22103 net.cpp:226] loss needs backward computation.
I0527 09:16:27.738893 22103 net.cpp:226] drop3 needs backward computation.
I0527 09:16:27.738903 22103 net.cpp:226] ip3 needs backward computation.
I0527 09:16:27.738914 22103 net.cpp:226] drop2 needs backward computation.
I0527 09:16:27.738924 22103 net.cpp:226] relu6 needs backward computation.
I0527 09:16:27.738934 22103 net.cpp:226] ip2 needs backward computation.
I0527 09:16:27.738943 22103 net.cpp:226] drop1 needs backward computation.
I0527 09:16:27.738953 22103 net.cpp:226] relu5 needs backward computation.
I0527 09:16:27.738963 22103 net.cpp:226] ip1 needs backward computation.
I0527 09:16:27.738973 22103 net.cpp:226] pool4 needs backward computation.
I0527 09:16:27.738983 22103 net.cpp:226] relu4 needs backward computation.
I0527 09:16:27.738993 22103 net.cpp:226] conv4 needs backward computation.
I0527 09:16:27.739004 22103 net.cpp:226] pool3 needs backward computation.
I0527 09:16:27.739014 22103 net.cpp:226] relu3 needs backward computation.
I0527 09:16:27.739024 22103 net.cpp:226] conv3 needs backward computation.
I0527 09:16:27.739044 22103 net.cpp:226] pool2 needs backward computation.
I0527 09:16:27.739056 22103 net.cpp:226] relu2 needs backward computation.
I0527 09:16:27.739066 22103 net.cpp:226] conv2 needs backward computation.
I0527 09:16:27.739076 22103 net.cpp:226] pool1 needs backward computation.
I0527 09:16:27.739087 22103 net.cpp:226] relu1 needs backward computation.
I0527 09:16:27.739097 22103 net.cpp:226] conv1 needs backward computation.
I0527 09:16:27.739109 22103 net.cpp:228] data_hdf5 does not need backward computation.
I0527 09:16:27.739117 22103 net.cpp:270] This network produces output loss
I0527 09:16:27.739141 22103 net.cpp:283] Network initialization done.
I0527 09:16:27.740855 22103 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271.prototxt
I0527 09:16:27.740926 22103 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 09:16:27.741282 22103 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 09:16:27.741472 22103 layer_factory.hpp:77] Creating layer data_hdf5
I0527 09:16:27.741487 22103 net.cpp:106] Creating Layer data_hdf5
I0527 09:16:27.741498 22103 net.cpp:411] data_hdf5 -> data
I0527 09:16:27.741515 22103 net.cpp:411] data_hdf5 -> label
I0527 09:16:27.741531 22103 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 09:16:27.742892 22103 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 09:16:49.153062 22103 net.cpp:150] Setting up data_hdf5
I0527 09:16:49.153228 22103 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 09:16:49.153242 22103 net.cpp:157] Top shape: 40 (40)
I0527 09:16:49.153252 22103 net.cpp:165] Memory required for data: 1016160
I0527 09:16:49.153266 22103 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 09:16:49.153295 22103 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 09:16:49.153306 22103 net.cpp:454] label_data_hdf5_1_split <- label
I0527 09:16:49.153321 22103 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 09:16:49.153342 22103 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 09:16:49.153414 22103 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 09:16:49.153429 22103 net.cpp:157] Top shape: 40 (40)
I0527 09:16:49.153440 22103 net.cpp:157] Top shape: 40 (40)
I0527 09:16:49.153450 22103 net.cpp:165] Memory required for data: 1016480
I0527 09:16:49.153460 22103 layer_factory.hpp:77] Creating layer conv1
I0527 09:16:49.153483 22103 net.cpp:106] Creating Layer conv1
I0527 09:16:49.153493 22103 net.cpp:454] conv1 <- data
I0527 09:16:49.153508 22103 net.cpp:411] conv1 -> conv1
I0527 09:16:49.155517 22103 net.cpp:150] Setting up conv1
I0527 09:16:49.155541 22103 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:16:49.155551 22103 net.cpp:165] Memory required for data: 12075680
I0527 09:16:49.155575 22103 layer_factory.hpp:77] Creating layer relu1
I0527 09:16:49.155589 22103 net.cpp:106] Creating Layer relu1
I0527 09:16:49.155599 22103 net.cpp:454] relu1 <- conv1
I0527 09:16:49.155612 22103 net.cpp:397] relu1 -> conv1 (in-place)
I0527 09:16:49.156108 22103 net.cpp:150] Setting up relu1
I0527 09:16:49.156126 22103 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:16:49.156136 22103 net.cpp:165] Memory required for data: 23134880
I0527 09:16:49.156146 22103 layer_factory.hpp:77] Creating layer pool1
I0527 09:16:49.156162 22103 net.cpp:106] Creating Layer pool1
I0527 09:16:49.156172 22103 net.cpp:454] pool1 <- conv1
I0527 09:16:49.156185 22103 net.cpp:411] pool1 -> pool1
I0527 09:16:49.156260 22103 net.cpp:150] Setting up pool1
I0527 09:16:49.156272 22103 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 09:16:49.156282 22103 net.cpp:165] Memory required for data: 28664480
I0527 09:16:49.156293 22103 layer_factory.hpp:77] Creating layer conv2
I0527 09:16:49.156311 22103 net.cpp:106] Creating Layer conv2
I0527 09:16:49.156321 22103 net.cpp:454] conv2 <- pool1
I0527 09:16:49.156334 22103 net.cpp:411] conv2 -> conv2
I0527 09:16:49.158337 22103 net.cpp:150] Setting up conv2
I0527 09:16:49.158360 22103 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:16:49.158373 22103 net.cpp:165] Memory required for data: 36613280
I0527 09:16:49.158391 22103 layer_factory.hpp:77] Creating layer relu2
I0527 09:16:49.158406 22103 net.cpp:106] Creating Layer relu2
I0527 09:16:49.158416 22103 net.cpp:454] relu2 <- conv2
I0527 09:16:49.158427 22103 net.cpp:397] relu2 -> conv2 (in-place)
I0527 09:16:49.158758 22103 net.cpp:150] Setting up relu2
I0527 09:16:49.158772 22103 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:16:49.158782 22103 net.cpp:165] Memory required for data: 44562080
I0527 09:16:49.158793 22103 layer_factory.hpp:77] Creating layer pool2
I0527 09:16:49.158807 22103 net.cpp:106] Creating Layer pool2
I0527 09:16:49.158817 22103 net.cpp:454] pool2 <- conv2
I0527 09:16:49.158829 22103 net.cpp:411] pool2 -> pool2
I0527 09:16:49.158900 22103 net.cpp:150] Setting up pool2
I0527 09:16:49.158913 22103 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 09:16:49.158923 22103 net.cpp:165] Memory required for data: 48536480
I0527 09:16:49.158933 22103 layer_factory.hpp:77] Creating layer conv3
I0527 09:16:49.158951 22103 net.cpp:106] Creating Layer conv3
I0527 09:16:49.158962 22103 net.cpp:454] conv3 <- pool2
I0527 09:16:49.158975 22103 net.cpp:411] conv3 -> conv3
I0527 09:16:49.160943 22103 net.cpp:150] Setting up conv3
I0527 09:16:49.160965 22103 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:16:49.160976 22103 net.cpp:165] Memory required for data: 52873120
I0527 09:16:49.161010 22103 layer_factory.hpp:77] Creating layer relu3
I0527 09:16:49.161023 22103 net.cpp:106] Creating Layer relu3
I0527 09:16:49.161033 22103 net.cpp:454] relu3 <- conv3
I0527 09:16:49.161046 22103 net.cpp:397] relu3 -> conv3 (in-place)
I0527 09:16:49.161519 22103 net.cpp:150] Setting up relu3
I0527 09:16:49.161535 22103 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:16:49.161545 22103 net.cpp:165] Memory required for data: 57209760
I0527 09:16:49.161556 22103 layer_factory.hpp:77] Creating layer pool3
I0527 09:16:49.161569 22103 net.cpp:106] Creating Layer pool3
I0527 09:16:49.161578 22103 net.cpp:454] pool3 <- conv3
I0527 09:16:49.161592 22103 net.cpp:411] pool3 -> pool3
I0527 09:16:49.161664 22103 net.cpp:150] Setting up pool3
I0527 09:16:49.161677 22103 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 09:16:49.161686 22103 net.cpp:165] Memory required for data: 59378080
I0527 09:16:49.161696 22103 layer_factory.hpp:77] Creating layer conv4
I0527 09:16:49.161715 22103 net.cpp:106] Creating Layer conv4
I0527 09:16:49.161725 22103 net.cpp:454] conv4 <- pool3
I0527 09:16:49.161739 22103 net.cpp:411] conv4 -> conv4
I0527 09:16:49.163805 22103 net.cpp:150] Setting up conv4
I0527 09:16:49.163828 22103 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:16:49.163838 22103 net.cpp:165] Memory required for data: 60829600
I0527 09:16:49.163854 22103 layer_factory.hpp:77] Creating layer relu4
I0527 09:16:49.163867 22103 net.cpp:106] Creating Layer relu4
I0527 09:16:49.163877 22103 net.cpp:454] relu4 <- conv4
I0527 09:16:49.163889 22103 net.cpp:397] relu4 -> conv4 (in-place)
I0527 09:16:49.164357 22103 net.cpp:150] Setting up relu4
I0527 09:16:49.164373 22103 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:16:49.164383 22103 net.cpp:165] Memory required for data: 62281120
I0527 09:16:49.164394 22103 layer_factory.hpp:77] Creating layer pool4
I0527 09:16:49.164407 22103 net.cpp:106] Creating Layer pool4
I0527 09:16:49.164417 22103 net.cpp:454] pool4 <- conv4
I0527 09:16:49.164430 22103 net.cpp:411] pool4 -> pool4
I0527 09:16:49.164501 22103 net.cpp:150] Setting up pool4
I0527 09:16:49.164515 22103 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 09:16:49.164525 22103 net.cpp:165] Memory required for data: 63006880
I0527 09:16:49.164535 22103 layer_factory.hpp:77] Creating layer ip1
I0527 09:16:49.164548 22103 net.cpp:106] Creating Layer ip1
I0527 09:16:49.164558 22103 net.cpp:454] ip1 <- pool4
I0527 09:16:49.164572 22103 net.cpp:411] ip1 -> ip1
I0527 09:16:49.179947 22103 net.cpp:150] Setting up ip1
I0527 09:16:49.179971 22103 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:16:49.179981 22103 net.cpp:165] Memory required for data: 63038240
I0527 09:16:49.180003 22103 layer_factory.hpp:77] Creating layer relu5
I0527 09:16:49.180019 22103 net.cpp:106] Creating Layer relu5
I0527 09:16:49.180029 22103 net.cpp:454] relu5 <- ip1
I0527 09:16:49.180043 22103 net.cpp:397] relu5 -> ip1 (in-place)
I0527 09:16:49.180387 22103 net.cpp:150] Setting up relu5
I0527 09:16:49.180402 22103 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:16:49.180411 22103 net.cpp:165] Memory required for data: 63069600
I0527 09:16:49.180421 22103 layer_factory.hpp:77] Creating layer drop1
I0527 09:16:49.180441 22103 net.cpp:106] Creating Layer drop1
I0527 09:16:49.180451 22103 net.cpp:454] drop1 <- ip1
I0527 09:16:49.180464 22103 net.cpp:397] drop1 -> ip1 (in-place)
I0527 09:16:49.180510 22103 net.cpp:150] Setting up drop1
I0527 09:16:49.180521 22103 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:16:49.180531 22103 net.cpp:165] Memory required for data: 63100960
I0527 09:16:49.180541 22103 layer_factory.hpp:77] Creating layer ip2
I0527 09:16:49.180555 22103 net.cpp:106] Creating Layer ip2
I0527 09:16:49.180565 22103 net.cpp:454] ip2 <- ip1
I0527 09:16:49.180579 22103 net.cpp:411] ip2 -> ip2
I0527 09:16:49.181059 22103 net.cpp:150] Setting up ip2
I0527 09:16:49.181072 22103 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:16:49.181082 22103 net.cpp:165] Memory required for data: 63116640
I0527 09:16:49.181097 22103 layer_factory.hpp:77] Creating layer relu6
I0527 09:16:49.181123 22103 net.cpp:106] Creating Layer relu6
I0527 09:16:49.181134 22103 net.cpp:454] relu6 <- ip2
I0527 09:16:49.181146 22103 net.cpp:397] relu6 -> ip2 (in-place)
I0527 09:16:49.181684 22103 net.cpp:150] Setting up relu6
I0527 09:16:49.181701 22103 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:16:49.181710 22103 net.cpp:165] Memory required for data: 63132320
I0527 09:16:49.181720 22103 layer_factory.hpp:77] Creating layer drop2
I0527 09:16:49.181733 22103 net.cpp:106] Creating Layer drop2
I0527 09:16:49.181743 22103 net.cpp:454] drop2 <- ip2
I0527 09:16:49.181756 22103 net.cpp:397] drop2 -> ip2 (in-place)
I0527 09:16:49.181800 22103 net.cpp:150] Setting up drop2
I0527 09:16:49.181813 22103 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:16:49.181823 22103 net.cpp:165] Memory required for data: 63148000
I0527 09:16:49.181833 22103 layer_factory.hpp:77] Creating layer ip3
I0527 09:16:49.181848 22103 net.cpp:106] Creating Layer ip3
I0527 09:16:49.181857 22103 net.cpp:454] ip3 <- ip2
I0527 09:16:49.181871 22103 net.cpp:411] ip3 -> ip3
I0527 09:16:49.182103 22103 net.cpp:150] Setting up ip3
I0527 09:16:49.182117 22103 net.cpp:157] Top shape: 40 11 (440)
I0527 09:16:49.182126 22103 net.cpp:165] Memory required for data: 63149760
I0527 09:16:49.182142 22103 layer_factory.hpp:77] Creating layer drop3
I0527 09:16:49.182155 22103 net.cpp:106] Creating Layer drop3
I0527 09:16:49.182165 22103 net.cpp:454] drop3 <- ip3
I0527 09:16:49.182178 22103 net.cpp:397] drop3 -> ip3 (in-place)
I0527 09:16:49.182219 22103 net.cpp:150] Setting up drop3
I0527 09:16:49.182232 22103 net.cpp:157] Top shape: 40 11 (440)
I0527 09:16:49.182241 22103 net.cpp:165] Memory required for data: 63151520
I0527 09:16:49.182251 22103 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 09:16:49.182265 22103 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 09:16:49.182276 22103 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 09:16:49.182288 22103 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 09:16:49.182303 22103 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 09:16:49.182379 22103 net.cpp:150] Setting up ip3_drop3_0_split
I0527 09:16:49.182391 22103 net.cpp:157] Top shape: 40 11 (440)
I0527 09:16:49.182404 22103 net.cpp:157] Top shape: 40 11 (440)
I0527 09:16:49.182413 22103 net.cpp:165] Memory required for data: 63155040
I0527 09:16:49.182422 22103 layer_factory.hpp:77] Creating layer accuracy
I0527 09:16:49.182443 22103 net.cpp:106] Creating Layer accuracy
I0527 09:16:49.182453 22103 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 09:16:49.182466 22103 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 09:16:49.182478 22103 net.cpp:411] accuracy -> accuracy
I0527 09:16:49.182502 22103 net.cpp:150] Setting up accuracy
I0527 09:16:49.182514 22103 net.cpp:157] Top shape: (1)
I0527 09:16:49.182524 22103 net.cpp:165] Memory required for data: 63155044
I0527 09:16:49.182534 22103 layer_factory.hpp:77] Creating layer loss
I0527 09:16:49.182548 22103 net.cpp:106] Creating Layer loss
I0527 09:16:49.182559 22103 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 09:16:49.182569 22103 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 09:16:49.182582 22103 net.cpp:411] loss -> loss
I0527 09:16:49.182600 22103 layer_factory.hpp:77] Creating layer loss
I0527 09:16:49.183086 22103 net.cpp:150] Setting up loss
I0527 09:16:49.183100 22103 net.cpp:157] Top shape: (1)
I0527 09:16:49.183109 22103 net.cpp:160]     with loss weight 1
I0527 09:16:49.183128 22103 net.cpp:165] Memory required for data: 63155048
I0527 09:16:49.183138 22103 net.cpp:226] loss needs backward computation.
I0527 09:16:49.183149 22103 net.cpp:228] accuracy does not need backward computation.
I0527 09:16:49.183161 22103 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 09:16:49.183171 22103 net.cpp:226] drop3 needs backward computation.
I0527 09:16:49.183182 22103 net.cpp:226] ip3 needs backward computation.
I0527 09:16:49.183192 22103 net.cpp:226] drop2 needs backward computation.
I0527 09:16:49.183202 22103 net.cpp:226] relu6 needs backward computation.
I0527 09:16:49.183220 22103 net.cpp:226] ip2 needs backward computation.
I0527 09:16:49.183230 22103 net.cpp:226] drop1 needs backward computation.
I0527 09:16:49.183240 22103 net.cpp:226] relu5 needs backward computation.
I0527 09:16:49.183249 22103 net.cpp:226] ip1 needs backward computation.
I0527 09:16:49.183259 22103 net.cpp:226] pool4 needs backward computation.
I0527 09:16:49.183269 22103 net.cpp:226] relu4 needs backward computation.
I0527 09:16:49.183279 22103 net.cpp:226] conv4 needs backward computation.
I0527 09:16:49.183290 22103 net.cpp:226] pool3 needs backward computation.
I0527 09:16:49.183300 22103 net.cpp:226] relu3 needs backward computation.
I0527 09:16:49.183311 22103 net.cpp:226] conv3 needs backward computation.
I0527 09:16:49.183322 22103 net.cpp:226] pool2 needs backward computation.
I0527 09:16:49.183332 22103 net.cpp:226] relu2 needs backward computation.
I0527 09:16:49.183342 22103 net.cpp:226] conv2 needs backward computation.
I0527 09:16:49.183352 22103 net.cpp:226] pool1 needs backward computation.
I0527 09:16:49.183362 22103 net.cpp:226] relu1 needs backward computation.
I0527 09:16:49.183372 22103 net.cpp:226] conv1 needs backward computation.
I0527 09:16:49.183383 22103 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 09:16:49.183395 22103 net.cpp:228] data_hdf5 does not need backward computation.
I0527 09:16:49.183405 22103 net.cpp:270] This network produces output accuracy
I0527 09:16:49.183414 22103 net.cpp:270] This network produces output loss
I0527 09:16:49.183442 22103 net.cpp:283] Network initialization done.
I0527 09:16:49.183575 22103 solver.cpp:60] Solver scaffolding done.
I0527 09:16:49.184738 22103 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_168750.solverstate
I0527 09:16:49.403589 22103 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 09:16:49.409065 22103 caffe.cpp:212] Starting Optimization
I0527 09:16:49.409106 22103 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 09:16:49.409116 22103 solver.cpp:289] Learning Rate Policy: fixed
I0527 09:16:49.436244 22103 solver.cpp:237] Iteration 168750, loss = 0.953029
I0527 09:16:49.436288 22103 solver.cpp:253]     Train net output #0: loss = 0.953029 (* 1 = 0.953029 loss)
I0527 09:16:49.436308 22103 sgd_solver.cpp:106] Iteration 168750, lr = 0.002
I0527 09:16:59.158047 22103 solver.cpp:237] Iteration 169125, loss = 0.92289
I0527 09:16:59.158085 22103 solver.cpp:253]     Train net output #0: loss = 0.92289 (* 1 = 0.92289 loss)
I0527 09:16:59.158102 22103 sgd_solver.cpp:106] Iteration 169125, lr = 0.002
I0527 09:17:08.869627 22103 solver.cpp:237] Iteration 169500, loss = 1.26892
I0527 09:17:08.869664 22103 solver.cpp:253]     Train net output #0: loss = 1.26892 (* 1 = 1.26892 loss)
I0527 09:17:08.869678 22103 sgd_solver.cpp:106] Iteration 169500, lr = 0.002
I0527 09:17:18.577008 22103 solver.cpp:237] Iteration 169875, loss = 1.22915
I0527 09:17:18.577049 22103 solver.cpp:253]     Train net output #0: loss = 1.22915 (* 1 = 1.22915 loss)
I0527 09:17:18.577066 22103 sgd_solver.cpp:106] Iteration 169875, lr = 0.002
I0527 09:17:28.304339 22103 solver.cpp:237] Iteration 170250, loss = 0.97325
I0527 09:17:28.304494 22103 solver.cpp:253]     Train net output #0: loss = 0.97325 (* 1 = 0.97325 loss)
I0527 09:17:28.304509 22103 sgd_solver.cpp:106] Iteration 170250, lr = 0.002
I0527 09:17:38.026713 22103 solver.cpp:237] Iteration 170625, loss = 1.29746
I0527 09:17:38.026748 22103 solver.cpp:253]     Train net output #0: loss = 1.29746 (* 1 = 1.29746 loss)
I0527 09:17:38.026767 22103 sgd_solver.cpp:106] Iteration 170625, lr = 0.002
I0527 09:17:47.743041 22103 solver.cpp:237] Iteration 171000, loss = 1.46286
I0527 09:17:47.743086 22103 solver.cpp:253]     Train net output #0: loss = 1.46286 (* 1 = 1.46286 loss)
I0527 09:17:47.743103 22103 sgd_solver.cpp:106] Iteration 171000, lr = 0.002
I0527 09:18:19.633247 22103 solver.cpp:237] Iteration 171375, loss = 1.31039
I0527 09:18:19.633426 22103 solver.cpp:253]     Train net output #0: loss = 1.31039 (* 1 = 1.31039 loss)
I0527 09:18:19.633442 22103 sgd_solver.cpp:106] Iteration 171375, lr = 0.002
I0527 09:18:29.355551 22103 solver.cpp:237] Iteration 171750, loss = 1.15831
I0527 09:18:29.355599 22103 solver.cpp:253]     Train net output #0: loss = 1.15831 (* 1 = 1.15831 loss)
I0527 09:18:29.355613 22103 sgd_solver.cpp:106] Iteration 171750, lr = 0.002
I0527 09:18:39.081701 22103 solver.cpp:237] Iteration 172125, loss = 1.53864
I0527 09:18:39.081739 22103 solver.cpp:253]     Train net output #0: loss = 1.53864 (* 1 = 1.53864 loss)
I0527 09:18:39.081754 22103 sgd_solver.cpp:106] Iteration 172125, lr = 0.002
I0527 09:18:48.781337 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_172500.caffemodel
I0527 09:18:48.837949 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_172500.solverstate
I0527 09:18:48.866171 22103 solver.cpp:341] Iteration 172500, Testing net (#0)
I0527 09:19:38.360627 22103 solver.cpp:409]     Test net output #0: accuracy = 0.895034
I0527 09:19:38.360787 22103 solver.cpp:409]     Test net output #1: loss = 0.311851 (* 1 = 0.311851 loss)
I0527 09:19:38.368870 22103 solver.cpp:237] Iteration 172500, loss = 0.914553
I0527 09:19:38.368897 22103 solver.cpp:253]     Train net output #0: loss = 0.914553 (* 1 = 0.914553 loss)
I0527 09:19:38.368911 22103 sgd_solver.cpp:106] Iteration 172500, lr = 0.002
I0527 09:19:48.256009 22103 solver.cpp:237] Iteration 172875, loss = 1.11635
I0527 09:19:48.256057 22103 solver.cpp:253]     Train net output #0: loss = 1.11635 (* 1 = 1.11635 loss)
I0527 09:19:48.256075 22103 sgd_solver.cpp:106] Iteration 172875, lr = 0.002
I0527 09:19:58.139981 22103 solver.cpp:237] Iteration 173250, loss = 0.930825
I0527 09:19:58.140017 22103 solver.cpp:253]     Train net output #0: loss = 0.930825 (* 1 = 0.930825 loss)
I0527 09:19:58.140031 22103 sgd_solver.cpp:106] Iteration 173250, lr = 0.002
I0527 09:20:08.023226 22103 solver.cpp:237] Iteration 173625, loss = 1.22254
I0527 09:20:08.023262 22103 solver.cpp:253]     Train net output #0: loss = 1.22254 (* 1 = 1.22254 loss)
I0527 09:20:08.023274 22103 sgd_solver.cpp:106] Iteration 173625, lr = 0.002
I0527 09:20:40.047379 22103 solver.cpp:237] Iteration 174000, loss = 1.0053
I0527 09:20:40.047549 22103 solver.cpp:253]     Train net output #0: loss = 1.0053 (* 1 = 1.0053 loss)
I0527 09:20:40.047564 22103 sgd_solver.cpp:106] Iteration 174000, lr = 0.002
I0527 09:20:49.927995 22103 solver.cpp:237] Iteration 174375, loss = 1.47604
I0527 09:20:49.928030 22103 solver.cpp:253]     Train net output #0: loss = 1.47604 (* 1 = 1.47604 loss)
I0527 09:20:49.928047 22103 sgd_solver.cpp:106] Iteration 174375, lr = 0.002
I0527 09:20:59.807926 22103 solver.cpp:237] Iteration 174750, loss = 1.22787
I0527 09:20:59.807965 22103 solver.cpp:253]     Train net output #0: loss = 1.22787 (* 1 = 1.22787 loss)
I0527 09:20:59.807977 22103 sgd_solver.cpp:106] Iteration 174750, lr = 0.002
I0527 09:21:09.691232 22103 solver.cpp:237] Iteration 175125, loss = 1.00369
I0527 09:21:09.691267 22103 solver.cpp:253]     Train net output #0: loss = 1.00369 (* 1 = 1.00369 loss)
I0527 09:21:09.691283 22103 sgd_solver.cpp:106] Iteration 175125, lr = 0.002
I0527 09:21:19.574149 22103 solver.cpp:237] Iteration 175500, loss = 1.18417
I0527 09:21:19.574286 22103 solver.cpp:253]     Train net output #0: loss = 1.18417 (* 1 = 1.18417 loss)
I0527 09:21:19.574301 22103 sgd_solver.cpp:106] Iteration 175500, lr = 0.002
I0527 09:21:29.451701 22103 solver.cpp:237] Iteration 175875, loss = 1.09381
I0527 09:21:29.451748 22103 solver.cpp:253]     Train net output #0: loss = 1.09381 (* 1 = 1.09381 loss)
I0527 09:21:29.451762 22103 sgd_solver.cpp:106] Iteration 175875, lr = 0.002
I0527 09:21:39.312137 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_176250.caffemodel
I0527 09:21:39.369982 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_176250.solverstate
I0527 09:22:01.536717 22103 solver.cpp:237] Iteration 176250, loss = 0.970009
I0527 09:22:01.536883 22103 solver.cpp:253]     Train net output #0: loss = 0.970009 (* 1 = 0.970009 loss)
I0527 09:22:01.536900 22103 sgd_solver.cpp:106] Iteration 176250, lr = 0.002
I0527 09:22:11.424801 22103 solver.cpp:237] Iteration 176625, loss = 1.41605
I0527 09:22:11.424836 22103 solver.cpp:253]     Train net output #0: loss = 1.41605 (* 1 = 1.41605 loss)
I0527 09:22:11.424854 22103 sgd_solver.cpp:106] Iteration 176625, lr = 0.002
I0527 09:22:21.310374 22103 solver.cpp:237] Iteration 177000, loss = 0.989195
I0527 09:22:21.310411 22103 solver.cpp:253]     Train net output #0: loss = 0.989195 (* 1 = 0.989195 loss)
I0527 09:22:21.310425 22103 sgd_solver.cpp:106] Iteration 177000, lr = 0.002
I0527 09:22:31.193446 22103 solver.cpp:237] Iteration 177375, loss = 1.13858
I0527 09:22:31.193483 22103 solver.cpp:253]     Train net output #0: loss = 1.13858 (* 1 = 1.13858 loss)
I0527 09:22:31.193498 22103 sgd_solver.cpp:106] Iteration 177375, lr = 0.002
I0527 09:22:41.069746 22103 solver.cpp:237] Iteration 177750, loss = 1.16493
I0527 09:22:41.069887 22103 solver.cpp:253]     Train net output #0: loss = 1.16493 (* 1 = 1.16493 loss)
I0527 09:22:41.069902 22103 sgd_solver.cpp:106] Iteration 177750, lr = 0.002
I0527 09:22:50.949098 22103 solver.cpp:237] Iteration 178125, loss = 1.34315
I0527 09:22:50.949132 22103 solver.cpp:253]     Train net output #0: loss = 1.34315 (* 1 = 1.34315 loss)
I0527 09:22:50.949151 22103 sgd_solver.cpp:106] Iteration 178125, lr = 0.002
I0527 09:23:00.839268 22103 solver.cpp:237] Iteration 178500, loss = 1.10716
I0527 09:23:00.839303 22103 solver.cpp:253]     Train net output #0: loss = 1.10716 (* 1 = 1.10716 loss)
I0527 09:23:00.839320 22103 sgd_solver.cpp:106] Iteration 178500, lr = 0.002
I0527 09:23:32.855490 22103 solver.cpp:237] Iteration 178875, loss = 1.4212
I0527 09:23:32.855650 22103 solver.cpp:253]     Train net output #0: loss = 1.4212 (* 1 = 1.4212 loss)
I0527 09:23:32.855667 22103 sgd_solver.cpp:106] Iteration 178875, lr = 0.002
I0527 09:23:42.744642 22103 solver.cpp:237] Iteration 179250, loss = 0.828575
I0527 09:23:42.744678 22103 solver.cpp:253]     Train net output #0: loss = 0.828575 (* 1 = 0.828575 loss)
I0527 09:23:42.744694 22103 sgd_solver.cpp:106] Iteration 179250, lr = 0.002
I0527 09:23:52.631584 22103 solver.cpp:237] Iteration 179625, loss = 1.00318
I0527 09:23:52.631620 22103 solver.cpp:253]     Train net output #0: loss = 1.00318 (* 1 = 1.00318 loss)
I0527 09:23:52.631636 22103 sgd_solver.cpp:106] Iteration 179625, lr = 0.002
I0527 09:24:02.507259 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_180000.caffemodel
I0527 09:24:02.566884 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_180000.solverstate
I0527 09:24:02.594828 22103 solver.cpp:341] Iteration 180000, Testing net (#0)
I0527 09:24:51.166000 22103 solver.cpp:409]     Test net output #0: accuracy = 0.896673
I0527 09:24:51.166170 22103 solver.cpp:409]     Test net output #1: loss = 0.321519 (* 1 = 0.321519 loss)
I0527 09:24:51.174268 22103 solver.cpp:237] Iteration 180000, loss = 1.27035
I0527 09:24:51.174296 22103 solver.cpp:253]     Train net output #0: loss = 1.27035 (* 1 = 1.27035 loss)
I0527 09:24:51.174312 22103 sgd_solver.cpp:106] Iteration 180000, lr = 0.002
I0527 09:25:00.935992 22103 solver.cpp:237] Iteration 180375, loss = 0.78303
I0527 09:25:00.936028 22103 solver.cpp:253]     Train net output #0: loss = 0.78303 (* 1 = 0.78303 loss)
I0527 09:25:00.936046 22103 sgd_solver.cpp:106] Iteration 180375, lr = 0.002
I0527 09:25:10.703330 22103 solver.cpp:237] Iteration 180750, loss = 0.970291
I0527 09:25:10.703373 22103 solver.cpp:253]     Train net output #0: loss = 0.970292 (* 1 = 0.970292 loss)
I0527 09:25:10.703389 22103 sgd_solver.cpp:106] Iteration 180750, lr = 0.002
I0527 09:25:20.463598 22103 solver.cpp:237] Iteration 181125, loss = 0.963188
I0527 09:25:20.463632 22103 solver.cpp:253]     Train net output #0: loss = 0.963188 (* 1 = 0.963188 loss)
I0527 09:25:20.463649 22103 sgd_solver.cpp:106] Iteration 181125, lr = 0.002
I0527 09:25:52.411890 22103 solver.cpp:237] Iteration 181500, loss = 0.812808
I0527 09:25:52.412056 22103 solver.cpp:253]     Train net output #0: loss = 0.812808 (* 1 = 0.812808 loss)
I0527 09:25:52.412071 22103 sgd_solver.cpp:106] Iteration 181500, lr = 0.002
I0527 09:26:02.175801 22103 solver.cpp:237] Iteration 181875, loss = 1.24239
I0527 09:26:02.175846 22103 solver.cpp:253]     Train net output #0: loss = 1.24239 (* 1 = 1.24239 loss)
I0527 09:26:02.175866 22103 sgd_solver.cpp:106] Iteration 181875, lr = 0.002
I0527 09:26:11.939390 22103 solver.cpp:237] Iteration 182250, loss = 1.24239
I0527 09:26:11.939426 22103 solver.cpp:253]     Train net output #0: loss = 1.24239 (* 1 = 1.24239 loss)
I0527 09:26:11.939445 22103 sgd_solver.cpp:106] Iteration 182250, lr = 0.002
I0527 09:26:21.700479 22103 solver.cpp:237] Iteration 182625, loss = 1.37037
I0527 09:26:21.700515 22103 solver.cpp:253]     Train net output #0: loss = 1.37037 (* 1 = 1.37037 loss)
I0527 09:26:21.700531 22103 sgd_solver.cpp:106] Iteration 182625, lr = 0.002
I0527 09:26:31.472712 22103 solver.cpp:237] Iteration 183000, loss = 1.19189
I0527 09:26:31.472875 22103 solver.cpp:253]     Train net output #0: loss = 1.19189 (* 1 = 1.19189 loss)
I0527 09:26:31.472890 22103 sgd_solver.cpp:106] Iteration 183000, lr = 0.002
I0527 09:26:41.239307 22103 solver.cpp:237] Iteration 183375, loss = 1.29314
I0527 09:26:41.239342 22103 solver.cpp:253]     Train net output #0: loss = 1.29314 (* 1 = 1.29314 loss)
I0527 09:26:41.239356 22103 sgd_solver.cpp:106] Iteration 183375, lr = 0.002
I0527 09:26:50.977769 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_183750.caffemodel
I0527 09:26:51.036131 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_183750.solverstate
I0527 09:27:13.212366 22103 solver.cpp:237] Iteration 183750, loss = 1.01351
I0527 09:27:13.212548 22103 solver.cpp:253]     Train net output #0: loss = 1.01351 (* 1 = 1.01351 loss)
I0527 09:27:13.212563 22103 sgd_solver.cpp:106] Iteration 183750, lr = 0.002
I0527 09:27:22.977286 22103 solver.cpp:237] Iteration 184125, loss = 1.1393
I0527 09:27:22.977327 22103 solver.cpp:253]     Train net output #0: loss = 1.1393 (* 1 = 1.1393 loss)
I0527 09:27:22.977344 22103 sgd_solver.cpp:106] Iteration 184125, lr = 0.002
I0527 09:27:32.733502 22103 solver.cpp:237] Iteration 184500, loss = 1.22921
I0527 09:27:32.733537 22103 solver.cpp:253]     Train net output #0: loss = 1.22921 (* 1 = 1.22921 loss)
I0527 09:27:32.733551 22103 sgd_solver.cpp:106] Iteration 184500, lr = 0.002
I0527 09:27:42.497287 22103 solver.cpp:237] Iteration 184875, loss = 0.814628
I0527 09:27:42.497330 22103 solver.cpp:253]     Train net output #0: loss = 0.814628 (* 1 = 0.814628 loss)
I0527 09:27:42.497352 22103 sgd_solver.cpp:106] Iteration 184875, lr = 0.002
I0527 09:27:52.260368 22103 solver.cpp:237] Iteration 185250, loss = 1.40043
I0527 09:27:52.260510 22103 solver.cpp:253]     Train net output #0: loss = 1.40043 (* 1 = 1.40043 loss)
I0527 09:27:52.260524 22103 sgd_solver.cpp:106] Iteration 185250, lr = 0.002
I0527 09:28:02.026424 22103 solver.cpp:237] Iteration 185625, loss = 1.1342
I0527 09:28:02.026458 22103 solver.cpp:253]     Train net output #0: loss = 1.1342 (* 1 = 1.1342 loss)
I0527 09:28:02.026476 22103 sgd_solver.cpp:106] Iteration 185625, lr = 0.002
I0527 09:28:11.800634 22103 solver.cpp:237] Iteration 186000, loss = 1.28153
I0527 09:28:11.800679 22103 solver.cpp:253]     Train net output #0: loss = 1.28153 (* 1 = 1.28153 loss)
I0527 09:28:11.800693 22103 sgd_solver.cpp:106] Iteration 186000, lr = 0.002
I0527 09:28:43.760656 22103 solver.cpp:237] Iteration 186375, loss = 1.20878
I0527 09:28:43.760823 22103 solver.cpp:253]     Train net output #0: loss = 1.20878 (* 1 = 1.20878 loss)
I0527 09:28:43.760838 22103 sgd_solver.cpp:106] Iteration 186375, lr = 0.002
I0527 09:28:53.530526 22103 solver.cpp:237] Iteration 186750, loss = 1.38974
I0527 09:28:53.530561 22103 solver.cpp:253]     Train net output #0: loss = 1.38974 (* 1 = 1.38974 loss)
I0527 09:28:53.530575 22103 sgd_solver.cpp:106] Iteration 186750, lr = 0.002
I0527 09:29:03.301653 22103 solver.cpp:237] Iteration 187125, loss = 1.11147
I0527 09:29:03.301686 22103 solver.cpp:253]     Train net output #0: loss = 1.11147 (* 1 = 1.11147 loss)
I0527 09:29:03.301712 22103 sgd_solver.cpp:106] Iteration 187125, lr = 0.002
I0527 09:29:13.034054 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_187500.caffemodel
I0527 09:29:13.092501 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_187500.solverstate
I0527 09:29:13.120302 22103 solver.cpp:341] Iteration 187500, Testing net (#0)
I0527 09:30:22.486901 22103 solver.cpp:409]     Test net output #0: accuracy = 0.897833
I0527 09:30:22.487063 22103 solver.cpp:409]     Test net output #1: loss = 0.322995 (* 1 = 0.322995 loss)
I0527 09:30:22.495111 22103 solver.cpp:237] Iteration 187500, loss = 1.469
I0527 09:30:22.495139 22103 solver.cpp:253]     Train net output #0: loss = 1.469 (* 1 = 1.469 loss)
I0527 09:30:22.495153 22103 sgd_solver.cpp:106] Iteration 187500, lr = 0.002
I0527 09:30:32.352877 22103 solver.cpp:237] Iteration 187875, loss = 1.20215
I0527 09:30:32.352911 22103 solver.cpp:253]     Train net output #0: loss = 1.20215 (* 1 = 1.20215 loss)
I0527 09:30:32.352926 22103 sgd_solver.cpp:106] Iteration 187875, lr = 0.002
I0527 09:30:42.198905 22103 solver.cpp:237] Iteration 188250, loss = 1.30977
I0527 09:30:42.198937 22103 solver.cpp:253]     Train net output #0: loss = 1.30977 (* 1 = 1.30977 loss)
I0527 09:30:42.198962 22103 sgd_solver.cpp:106] Iteration 188250, lr = 0.002
I0527 09:30:52.043033 22103 solver.cpp:237] Iteration 188625, loss = 1.04178
I0527 09:30:52.043068 22103 solver.cpp:253]     Train net output #0: loss = 1.04178 (* 1 = 1.04178 loss)
I0527 09:30:52.043081 22103 sgd_solver.cpp:106] Iteration 188625, lr = 0.002
I0527 09:31:23.990530 22103 solver.cpp:237] Iteration 189000, loss = 0.929471
I0527 09:31:23.990694 22103 solver.cpp:253]     Train net output #0: loss = 0.929471 (* 1 = 0.929471 loss)
I0527 09:31:23.990710 22103 sgd_solver.cpp:106] Iteration 189000, lr = 0.002
I0527 09:31:33.828582 22103 solver.cpp:237] Iteration 189375, loss = 1.05358
I0527 09:31:33.828616 22103 solver.cpp:253]     Train net output #0: loss = 1.05358 (* 1 = 1.05358 loss)
I0527 09:31:33.828630 22103 sgd_solver.cpp:106] Iteration 189375, lr = 0.002
I0527 09:31:43.663352 22103 solver.cpp:237] Iteration 189750, loss = 0.995444
I0527 09:31:43.663388 22103 solver.cpp:253]     Train net output #0: loss = 0.995444 (* 1 = 0.995444 loss)
I0527 09:31:43.663403 22103 sgd_solver.cpp:106] Iteration 189750, lr = 0.002
I0527 09:31:53.496546 22103 solver.cpp:237] Iteration 190125, loss = 1.14267
I0527 09:31:53.496592 22103 solver.cpp:253]     Train net output #0: loss = 1.14267 (* 1 = 1.14267 loss)
I0527 09:31:53.496608 22103 sgd_solver.cpp:106] Iteration 190125, lr = 0.002
I0527 09:32:03.340692 22103 solver.cpp:237] Iteration 190500, loss = 1.35236
I0527 09:32:03.340837 22103 solver.cpp:253]     Train net output #0: loss = 1.35236 (* 1 = 1.35236 loss)
I0527 09:32:03.340852 22103 sgd_solver.cpp:106] Iteration 190500, lr = 0.002
I0527 09:32:13.182930 22103 solver.cpp:237] Iteration 190875, loss = 0.81003
I0527 09:32:13.182965 22103 solver.cpp:253]     Train net output #0: loss = 0.81003 (* 1 = 0.81003 loss)
I0527 09:32:13.182983 22103 sgd_solver.cpp:106] Iteration 190875, lr = 0.002
I0527 09:32:23.000252 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_191250.caffemodel
I0527 09:32:23.057684 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_191250.solverstate
I0527 09:32:45.315763 22103 solver.cpp:237] Iteration 191250, loss = 0.869579
I0527 09:32:45.315942 22103 solver.cpp:253]     Train net output #0: loss = 0.869579 (* 1 = 0.869579 loss)
I0527 09:32:45.315958 22103 sgd_solver.cpp:106] Iteration 191250, lr = 0.002
I0527 09:32:55.158471 22103 solver.cpp:237] Iteration 191625, loss = 1.13044
I0527 09:32:55.158506 22103 solver.cpp:253]     Train net output #0: loss = 1.13044 (* 1 = 1.13044 loss)
I0527 09:32:55.158524 22103 sgd_solver.cpp:106] Iteration 191625, lr = 0.002
I0527 09:33:05.002177 22103 solver.cpp:237] Iteration 192000, loss = 1.12429
I0527 09:33:05.002219 22103 solver.cpp:253]     Train net output #0: loss = 1.12429 (* 1 = 1.12429 loss)
I0527 09:33:05.002241 22103 sgd_solver.cpp:106] Iteration 192000, lr = 0.002
I0527 09:33:14.840654 22103 solver.cpp:237] Iteration 192375, loss = 1.32819
I0527 09:33:14.840690 22103 solver.cpp:253]     Train net output #0: loss = 1.32819 (* 1 = 1.32819 loss)
I0527 09:33:14.840708 22103 sgd_solver.cpp:106] Iteration 192375, lr = 0.002
I0527 09:33:24.681002 22103 solver.cpp:237] Iteration 192750, loss = 1.35874
I0527 09:33:24.681146 22103 solver.cpp:253]     Train net output #0: loss = 1.35874 (* 1 = 1.35874 loss)
I0527 09:33:24.681159 22103 sgd_solver.cpp:106] Iteration 192750, lr = 0.002
I0527 09:33:34.516501 22103 solver.cpp:237] Iteration 193125, loss = 1.30454
I0527 09:33:34.516541 22103 solver.cpp:253]     Train net output #0: loss = 1.30454 (* 1 = 1.30454 loss)
I0527 09:33:34.516561 22103 sgd_solver.cpp:106] Iteration 193125, lr = 0.002
I0527 09:33:44.349227 22103 solver.cpp:237] Iteration 193500, loss = 0.885725
I0527 09:33:44.349263 22103 solver.cpp:253]     Train net output #0: loss = 0.885725 (* 1 = 0.885725 loss)
I0527 09:33:44.349279 22103 sgd_solver.cpp:106] Iteration 193500, lr = 0.002
I0527 09:34:16.411509 22103 solver.cpp:237] Iteration 193875, loss = 1.19875
I0527 09:34:16.411685 22103 solver.cpp:253]     Train net output #0: loss = 1.19875 (* 1 = 1.19875 loss)
I0527 09:34:16.411701 22103 sgd_solver.cpp:106] Iteration 193875, lr = 0.002
I0527 09:34:26.248634 22103 solver.cpp:237] Iteration 194250, loss = 1.13747
I0527 09:34:26.248679 22103 solver.cpp:253]     Train net output #0: loss = 1.13747 (* 1 = 1.13747 loss)
I0527 09:34:26.248697 22103 sgd_solver.cpp:106] Iteration 194250, lr = 0.002
I0527 09:34:36.085211 22103 solver.cpp:237] Iteration 194625, loss = 1.16811
I0527 09:34:36.085247 22103 solver.cpp:253]     Train net output #0: loss = 1.16811 (* 1 = 1.16811 loss)
I0527 09:34:36.085260 22103 sgd_solver.cpp:106] Iteration 194625, lr = 0.002
I0527 09:34:45.898558 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_195000.caffemodel
I0527 09:34:45.957067 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_195000.solverstate
I0527 09:34:45.983274 22103 solver.cpp:341] Iteration 195000, Testing net (#0)
I0527 09:35:34.184706 22103 solver.cpp:409]     Test net output #0: accuracy = 0.89766
I0527 09:35:34.184867 22103 solver.cpp:409]     Test net output #1: loss = 0.324858 (* 1 = 0.324858 loss)
I0527 09:35:34.192921 22103 solver.cpp:237] Iteration 195000, loss = 1.08563
I0527 09:35:34.192950 22103 solver.cpp:253]     Train net output #0: loss = 1.08563 (* 1 = 1.08563 loss)
I0527 09:35:34.192963 22103 sgd_solver.cpp:106] Iteration 195000, lr = 0.002
I0527 09:35:43.952256 22103 solver.cpp:237] Iteration 195375, loss = 1.22113
I0527 09:35:43.952291 22103 solver.cpp:253]     Train net output #0: loss = 1.22113 (* 1 = 1.22113 loss)
I0527 09:35:43.952309 22103 sgd_solver.cpp:106] Iteration 195375, lr = 0.002
I0527 09:35:53.718230 22103 solver.cpp:237] Iteration 195750, loss = 0.870438
I0527 09:35:53.718266 22103 solver.cpp:253]     Train net output #0: loss = 0.870438 (* 1 = 0.870438 loss)
I0527 09:35:53.718279 22103 sgd_solver.cpp:106] Iteration 195750, lr = 0.002
I0527 09:36:03.486671 22103 solver.cpp:237] Iteration 196125, loss = 1.12986
I0527 09:36:03.486709 22103 solver.cpp:253]     Train net output #0: loss = 1.12986 (* 1 = 1.12986 loss)
I0527 09:36:03.486732 22103 sgd_solver.cpp:106] Iteration 196125, lr = 0.002
I0527 09:36:35.374642 22103 solver.cpp:237] Iteration 196500, loss = 1.11123
I0527 09:36:35.374804 22103 solver.cpp:253]     Train net output #0: loss = 1.11123 (* 1 = 1.11123 loss)
I0527 09:36:35.374819 22103 sgd_solver.cpp:106] Iteration 196500, lr = 0.002
I0527 09:36:45.138679 22103 solver.cpp:237] Iteration 196875, loss = 1.58889
I0527 09:36:45.138713 22103 solver.cpp:253]     Train net output #0: loss = 1.58889 (* 1 = 1.58889 loss)
I0527 09:36:45.138731 22103 sgd_solver.cpp:106] Iteration 196875, lr = 0.002
I0527 09:36:54.902133 22103 solver.cpp:237] Iteration 197250, loss = 1.10675
I0527 09:36:54.902168 22103 solver.cpp:253]     Train net output #0: loss = 1.10675 (* 1 = 1.10675 loss)
I0527 09:36:54.902187 22103 sgd_solver.cpp:106] Iteration 197250, lr = 0.002
I0527 09:37:04.666347 22103 solver.cpp:237] Iteration 197625, loss = 1.29873
I0527 09:37:04.666383 22103 solver.cpp:253]     Train net output #0: loss = 1.29873 (* 1 = 1.29873 loss)
I0527 09:37:04.666399 22103 sgd_solver.cpp:106] Iteration 197625, lr = 0.002
I0527 09:37:14.435767 22103 solver.cpp:237] Iteration 198000, loss = 1.19663
I0527 09:37:14.435909 22103 solver.cpp:253]     Train net output #0: loss = 1.19663 (* 1 = 1.19663 loss)
I0527 09:37:14.435923 22103 sgd_solver.cpp:106] Iteration 198000, lr = 0.002
I0527 09:37:24.202803 22103 solver.cpp:237] Iteration 198375, loss = 1.31869
I0527 09:37:24.202837 22103 solver.cpp:253]     Train net output #0: loss = 1.31869 (* 1 = 1.31869 loss)
I0527 09:37:24.202855 22103 sgd_solver.cpp:106] Iteration 198375, lr = 0.002
I0527 09:37:33.935912 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_198750.caffemodel
I0527 09:37:33.992050 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_198750.solverstate
I0527 09:37:56.229214 22103 solver.cpp:237] Iteration 198750, loss = 1.07028
I0527 09:37:56.229401 22103 solver.cpp:253]     Train net output #0: loss = 1.07028 (* 1 = 1.07028 loss)
I0527 09:37:56.229416 22103 sgd_solver.cpp:106] Iteration 198750, lr = 0.002
I0527 09:38:05.998416 22103 solver.cpp:237] Iteration 199125, loss = 1.04378
I0527 09:38:05.998458 22103 solver.cpp:253]     Train net output #0: loss = 1.04378 (* 1 = 1.04378 loss)
I0527 09:38:05.998478 22103 sgd_solver.cpp:106] Iteration 199125, lr = 0.002
I0527 09:38:15.767336 22103 solver.cpp:237] Iteration 199500, loss = 1.07008
I0527 09:38:15.767369 22103 solver.cpp:253]     Train net output #0: loss = 1.07008 (* 1 = 1.07008 loss)
I0527 09:38:15.767388 22103 sgd_solver.cpp:106] Iteration 199500, lr = 0.002
I0527 09:38:25.530472 22103 solver.cpp:237] Iteration 199875, loss = 1.20828
I0527 09:38:25.530505 22103 solver.cpp:253]     Train net output #0: loss = 1.20828 (* 1 = 1.20828 loss)
I0527 09:38:25.530519 22103 sgd_solver.cpp:106] Iteration 199875, lr = 0.002
I0527 09:38:35.298550 22103 solver.cpp:237] Iteration 200250, loss = 1.23933
I0527 09:38:35.298708 22103 solver.cpp:253]     Train net output #0: loss = 1.23933 (* 1 = 1.23933 loss)
I0527 09:38:35.298722 22103 sgd_solver.cpp:106] Iteration 200250, lr = 0.002
I0527 09:38:45.061673 22103 solver.cpp:237] Iteration 200625, loss = 0.962013
I0527 09:38:45.061709 22103 solver.cpp:253]     Train net output #0: loss = 0.962013 (* 1 = 0.962013 loss)
I0527 09:38:45.061727 22103 sgd_solver.cpp:106] Iteration 200625, lr = 0.002
I0527 09:38:54.822607 22103 solver.cpp:237] Iteration 201000, loss = 0.814474
I0527 09:38:54.822652 22103 solver.cpp:253]     Train net output #0: loss = 0.814474 (* 1 = 0.814474 loss)
I0527 09:38:54.822667 22103 sgd_solver.cpp:106] Iteration 201000, lr = 0.002
I0527 09:39:26.725425 22103 solver.cpp:237] Iteration 201375, loss = 1.13452
I0527 09:39:26.725594 22103 solver.cpp:253]     Train net output #0: loss = 1.13452 (* 1 = 1.13452 loss)
I0527 09:39:26.725610 22103 sgd_solver.cpp:106] Iteration 201375, lr = 0.002
I0527 09:39:36.483149 22103 solver.cpp:237] Iteration 201750, loss = 1.21778
I0527 09:39:36.483182 22103 solver.cpp:253]     Train net output #0: loss = 1.21778 (* 1 = 1.21778 loss)
I0527 09:39:36.483196 22103 sgd_solver.cpp:106] Iteration 201750, lr = 0.002
I0527 09:39:46.257726 22103 solver.cpp:237] Iteration 202125, loss = 1.13316
I0527 09:39:46.257771 22103 solver.cpp:253]     Train net output #0: loss = 1.13316 (* 1 = 1.13316 loss)
I0527 09:39:46.257786 22103 sgd_solver.cpp:106] Iteration 202125, lr = 0.002
I0527 09:39:55.989812 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_202500.caffemodel
I0527 09:39:56.046797 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_202500.solverstate
I0527 09:39:56.073447 22103 solver.cpp:341] Iteration 202500, Testing net (#0)
I0527 09:41:05.451228 22103 solver.cpp:409]     Test net output #0: accuracy = 0.898933
I0527 09:41:05.451407 22103 solver.cpp:409]     Test net output #1: loss = 0.329134 (* 1 = 0.329134 loss)
I0527 09:41:05.459503 22103 solver.cpp:237] Iteration 202500, loss = 1.34525
I0527 09:41:05.459532 22103 solver.cpp:253]     Train net output #0: loss = 1.34525 (* 1 = 1.34525 loss)
I0527 09:41:05.459545 22103 sgd_solver.cpp:106] Iteration 202500, lr = 0.002
I0527 09:41:15.369165 22103 solver.cpp:237] Iteration 202875, loss = 1.20223
I0527 09:41:15.369199 22103 solver.cpp:253]     Train net output #0: loss = 1.20223 (* 1 = 1.20223 loss)
I0527 09:41:15.369216 22103 sgd_solver.cpp:106] Iteration 202875, lr = 0.002
I0527 09:41:25.276677 22103 solver.cpp:237] Iteration 203250, loss = 1.74587
I0527 09:41:25.276721 22103 solver.cpp:253]     Train net output #0: loss = 1.74587 (* 1 = 1.74587 loss)
I0527 09:41:25.276737 22103 sgd_solver.cpp:106] Iteration 203250, lr = 0.002
I0527 09:41:35.180610 22103 solver.cpp:237] Iteration 203625, loss = 1.02776
I0527 09:41:35.180645 22103 solver.cpp:253]     Train net output #0: loss = 1.02776 (* 1 = 1.02776 loss)
I0527 09:41:35.180663 22103 sgd_solver.cpp:106] Iteration 203625, lr = 0.002
I0527 09:42:07.250506 22103 solver.cpp:237] Iteration 204000, loss = 1.07506
I0527 09:42:07.250687 22103 solver.cpp:253]     Train net output #0: loss = 1.07506 (* 1 = 1.07506 loss)
I0527 09:42:07.250704 22103 sgd_solver.cpp:106] Iteration 204000, lr = 0.002
I0527 09:42:17.150964 22103 solver.cpp:237] Iteration 204375, loss = 1.2755
I0527 09:42:17.151006 22103 solver.cpp:253]     Train net output #0: loss = 1.2755 (* 1 = 1.2755 loss)
I0527 09:42:17.151026 22103 sgd_solver.cpp:106] Iteration 204375, lr = 0.002
I0527 09:42:27.048723 22103 solver.cpp:237] Iteration 204750, loss = 1.1496
I0527 09:42:27.048759 22103 solver.cpp:253]     Train net output #0: loss = 1.1496 (* 1 = 1.1496 loss)
I0527 09:42:27.048776 22103 sgd_solver.cpp:106] Iteration 204750, lr = 0.002
I0527 09:42:36.948364 22103 solver.cpp:237] Iteration 205125, loss = 1.11417
I0527 09:42:36.948398 22103 solver.cpp:253]     Train net output #0: loss = 1.11417 (* 1 = 1.11417 loss)
I0527 09:42:36.948415 22103 sgd_solver.cpp:106] Iteration 205125, lr = 0.002
I0527 09:42:46.859844 22103 solver.cpp:237] Iteration 205500, loss = 1.05274
I0527 09:42:46.860003 22103 solver.cpp:253]     Train net output #0: loss = 1.05274 (* 1 = 1.05274 loss)
I0527 09:42:46.860018 22103 sgd_solver.cpp:106] Iteration 205500, lr = 0.002
I0527 09:42:56.758832 22103 solver.cpp:237] Iteration 205875, loss = 1.24688
I0527 09:42:56.758867 22103 solver.cpp:253]     Train net output #0: loss = 1.24688 (* 1 = 1.24688 loss)
I0527 09:42:56.758880 22103 sgd_solver.cpp:106] Iteration 205875, lr = 0.002
I0527 09:43:06.637614 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_206250.caffemodel
I0527 09:43:06.696645 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_206250.solverstate
I0527 09:43:27.615128 22103 solver.cpp:237] Iteration 206250, loss = 0.993396
I0527 09:43:27.615308 22103 solver.cpp:253]     Train net output #0: loss = 0.993396 (* 1 = 0.993396 loss)
I0527 09:43:27.615324 22103 sgd_solver.cpp:106] Iteration 206250, lr = 0.002
I0527 09:43:37.516549 22103 solver.cpp:237] Iteration 206625, loss = 0.917008
I0527 09:43:37.516594 22103 solver.cpp:253]     Train net output #0: loss = 0.917008 (* 1 = 0.917008 loss)
I0527 09:43:37.516608 22103 sgd_solver.cpp:106] Iteration 206625, lr = 0.002
I0527 09:43:47.412690 22103 solver.cpp:237] Iteration 207000, loss = 1.5293
I0527 09:43:47.412725 22103 solver.cpp:253]     Train net output #0: loss = 1.5293 (* 1 = 1.5293 loss)
I0527 09:43:47.412739 22103 sgd_solver.cpp:106] Iteration 207000, lr = 0.002
I0527 09:43:57.313932 22103 solver.cpp:237] Iteration 207375, loss = 0.998968
I0527 09:43:57.313978 22103 solver.cpp:253]     Train net output #0: loss = 0.998968 (* 1 = 0.998968 loss)
I0527 09:43:57.313998 22103 sgd_solver.cpp:106] Iteration 207375, lr = 0.002
I0527 09:44:07.217800 22103 solver.cpp:237] Iteration 207750, loss = 0.892876
I0527 09:44:07.217948 22103 solver.cpp:253]     Train net output #0: loss = 0.892876 (* 1 = 0.892876 loss)
I0527 09:44:07.217963 22103 sgd_solver.cpp:106] Iteration 207750, lr = 0.002
I0527 09:44:17.115277 22103 solver.cpp:237] Iteration 208125, loss = 1.11548
I0527 09:44:17.115310 22103 solver.cpp:253]     Train net output #0: loss = 1.11548 (* 1 = 1.11548 loss)
I0527 09:44:17.115324 22103 sgd_solver.cpp:106] Iteration 208125, lr = 0.002
I0527 09:44:27.010767 22103 solver.cpp:237] Iteration 208500, loss = 1.22204
I0527 09:44:27.010803 22103 solver.cpp:253]     Train net output #0: loss = 1.22204 (* 1 = 1.22204 loss)
I0527 09:44:27.010825 22103 sgd_solver.cpp:106] Iteration 208500, lr = 0.002
I0527 09:44:57.793062 22103 solver.cpp:237] Iteration 208875, loss = 1.32234
I0527 09:44:57.793241 22103 solver.cpp:253]     Train net output #0: loss = 1.32234 (* 1 = 1.32234 loss)
I0527 09:44:57.793257 22103 sgd_solver.cpp:106] Iteration 208875, lr = 0.002
I0527 09:45:07.687369 22103 solver.cpp:237] Iteration 209250, loss = 0.938241
I0527 09:45:07.687404 22103 solver.cpp:253]     Train net output #0: loss = 0.938241 (* 1 = 0.938241 loss)
I0527 09:45:07.687422 22103 sgd_solver.cpp:106] Iteration 209250, lr = 0.002
I0527 09:45:17.580284 22103 solver.cpp:237] Iteration 209625, loss = 1.38293
I0527 09:45:17.580320 22103 solver.cpp:253]     Train net output #0: loss = 1.38293 (* 1 = 1.38293 loss)
I0527 09:45:17.580338 22103 sgd_solver.cpp:106] Iteration 209625, lr = 0.002
I0527 09:45:27.445009 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_210000.caffemodel
I0527 09:45:27.501829 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_210000.solverstate
I0527 09:45:27.527582 22103 solver.cpp:341] Iteration 210000, Testing net (#0)
I0527 09:46:16.044409 22103 solver.cpp:409]     Test net output #0: accuracy = 0.897746
I0527 09:46:16.044576 22103 solver.cpp:409]     Test net output #1: loss = 0.311159 (* 1 = 0.311159 loss)
I0527 09:46:16.052652 22103 solver.cpp:237] Iteration 210000, loss = 1.00436
I0527 09:46:16.052680 22103 solver.cpp:253]     Train net output #0: loss = 1.00436 (* 1 = 1.00436 loss)
I0527 09:46:16.052695 22103 sgd_solver.cpp:106] Iteration 210000, lr = 0.002
I0527 09:46:25.830521 22103 solver.cpp:237] Iteration 210375, loss = 1.24166
I0527 09:46:25.830566 22103 solver.cpp:253]     Train net output #0: loss = 1.24166 (* 1 = 1.24166 loss)
I0527 09:46:25.830585 22103 sgd_solver.cpp:106] Iteration 210375, lr = 0.002
I0527 09:46:35.608106 22103 solver.cpp:237] Iteration 210750, loss = 1.124
I0527 09:46:35.608142 22103 solver.cpp:253]     Train net output #0: loss = 1.124 (* 1 = 1.124 loss)
I0527 09:46:35.608155 22103 sgd_solver.cpp:106] Iteration 210750, lr = 0.002
I0527 09:46:45.386724 22103 solver.cpp:237] Iteration 211125, loss = 1.10422
I0527 09:46:45.386759 22103 solver.cpp:253]     Train net output #0: loss = 1.10422 (* 1 = 1.10422 loss)
I0527 09:46:45.386775 22103 sgd_solver.cpp:106] Iteration 211125, lr = 0.002
I0527 09:47:16.041992 22103 solver.cpp:237] Iteration 211500, loss = 0.962023
I0527 09:47:16.042160 22103 solver.cpp:253]     Train net output #0: loss = 0.962023 (* 1 = 0.962023 loss)
I0527 09:47:16.042176 22103 sgd_solver.cpp:106] Iteration 211500, lr = 0.002
I0527 09:47:25.813566 22103 solver.cpp:237] Iteration 211875, loss = 1.22899
I0527 09:47:25.813601 22103 solver.cpp:253]     Train net output #0: loss = 1.22899 (* 1 = 1.22899 loss)
I0527 09:47:25.813616 22103 sgd_solver.cpp:106] Iteration 211875, lr = 0.002
I0527 09:47:35.591290 22103 solver.cpp:237] Iteration 212250, loss = 1.4073
I0527 09:47:35.591326 22103 solver.cpp:253]     Train net output #0: loss = 1.4073 (* 1 = 1.4073 loss)
I0527 09:47:35.591339 22103 sgd_solver.cpp:106] Iteration 212250, lr = 0.002
I0527 09:47:45.366572 22103 solver.cpp:237] Iteration 212625, loss = 1.14467
I0527 09:47:45.366613 22103 solver.cpp:253]     Train net output #0: loss = 1.14467 (* 1 = 1.14467 loss)
I0527 09:47:45.366629 22103 sgd_solver.cpp:106] Iteration 212625, lr = 0.002
I0527 09:47:55.145092 22103 solver.cpp:237] Iteration 213000, loss = 0.982648
I0527 09:47:55.145252 22103 solver.cpp:253]     Train net output #0: loss = 0.982648 (* 1 = 0.982648 loss)
I0527 09:47:55.145267 22103 sgd_solver.cpp:106] Iteration 213000, lr = 0.002
I0527 09:48:04.917418 22103 solver.cpp:237] Iteration 213375, loss = 1.38239
I0527 09:48:04.917455 22103 solver.cpp:253]     Train net output #0: loss = 1.38239 (* 1 = 1.38239 loss)
I0527 09:48:04.917479 22103 sgd_solver.cpp:106] Iteration 213375, lr = 0.002
I0527 09:48:14.662216 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_213750.caffemodel
I0527 09:48:14.718135 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_213750.solverstate
I0527 09:48:35.611155 22103 solver.cpp:237] Iteration 213750, loss = 1.04674
I0527 09:48:35.611332 22103 solver.cpp:253]     Train net output #0: loss = 1.04674 (* 1 = 1.04674 loss)
I0527 09:48:35.611349 22103 sgd_solver.cpp:106] Iteration 213750, lr = 0.002
I0527 09:48:45.384202 22103 solver.cpp:237] Iteration 214125, loss = 1.24747
I0527 09:48:45.384238 22103 solver.cpp:253]     Train net output #0: loss = 1.24747 (* 1 = 1.24747 loss)
I0527 09:48:45.384254 22103 sgd_solver.cpp:106] Iteration 214125, lr = 0.002
I0527 09:48:55.160784 22103 solver.cpp:237] Iteration 214500, loss = 1.30425
I0527 09:48:55.160826 22103 solver.cpp:253]     Train net output #0: loss = 1.30425 (* 1 = 1.30425 loss)
I0527 09:48:55.160847 22103 sgd_solver.cpp:106] Iteration 214500, lr = 0.002
I0527 09:49:04.940485 22103 solver.cpp:237] Iteration 214875, loss = 1.34564
I0527 09:49:04.940521 22103 solver.cpp:253]     Train net output #0: loss = 1.34564 (* 1 = 1.34564 loss)
I0527 09:49:04.940534 22103 sgd_solver.cpp:106] Iteration 214875, lr = 0.002
I0527 09:49:14.711514 22103 solver.cpp:237] Iteration 215250, loss = 1.13576
I0527 09:49:14.711664 22103 solver.cpp:253]     Train net output #0: loss = 1.13576 (* 1 = 1.13576 loss)
I0527 09:49:14.711678 22103 sgd_solver.cpp:106] Iteration 215250, lr = 0.002
I0527 09:49:24.487409 22103 solver.cpp:237] Iteration 215625, loss = 1.0905
I0527 09:49:24.487450 22103 solver.cpp:253]     Train net output #0: loss = 1.0905 (* 1 = 1.0905 loss)
I0527 09:49:24.487468 22103 sgd_solver.cpp:106] Iteration 215625, lr = 0.002
I0527 09:49:34.263113 22103 solver.cpp:237] Iteration 216000, loss = 1.07198
I0527 09:49:34.263149 22103 solver.cpp:253]     Train net output #0: loss = 1.07198 (* 1 = 1.07198 loss)
I0527 09:49:34.263165 22103 sgd_solver.cpp:106] Iteration 216000, lr = 0.002
I0527 09:50:04.911375 22103 solver.cpp:237] Iteration 216375, loss = 1.26706
I0527 09:50:04.911542 22103 solver.cpp:253]     Train net output #0: loss = 1.26706 (* 1 = 1.26706 loss)
I0527 09:50:04.911557 22103 sgd_solver.cpp:106] Iteration 216375, lr = 0.002
I0527 09:50:14.762528 22103 solver.cpp:237] Iteration 216750, loss = 1.03985
I0527 09:50:14.762575 22103 solver.cpp:253]     Train net output #0: loss = 1.03985 (* 1 = 1.03985 loss)
I0527 09:50:14.762591 22103 sgd_solver.cpp:106] Iteration 216750, lr = 0.002
I0527 09:50:24.612663 22103 solver.cpp:237] Iteration 217125, loss = 1.47249
I0527 09:50:24.612699 22103 solver.cpp:253]     Train net output #0: loss = 1.47249 (* 1 = 1.47249 loss)
I0527 09:50:24.612712 22103 sgd_solver.cpp:106] Iteration 217125, lr = 0.002
I0527 09:50:34.434692 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_217500.caffemodel
I0527 09:50:34.490924 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_217500.solverstate
I0527 09:50:34.516310 22103 solver.cpp:341] Iteration 217500, Testing net (#0)
I0527 09:51:43.872382 22103 solver.cpp:409]     Test net output #0: accuracy = 0.8998
I0527 09:51:43.872565 22103 solver.cpp:409]     Test net output #1: loss = 0.306488 (* 1 = 0.306488 loss)
I0527 09:51:43.880648 22103 solver.cpp:237] Iteration 217500, loss = 1.19443
I0527 09:51:43.880676 22103 solver.cpp:253]     Train net output #0: loss = 1.19443 (* 1 = 1.19443 loss)
I0527 09:51:43.880689 22103 sgd_solver.cpp:106] Iteration 217500, lr = 0.002
I0527 09:51:53.677090 22103 solver.cpp:237] Iteration 217875, loss = 1.05109
I0527 09:51:53.677136 22103 solver.cpp:253]     Train net output #0: loss = 1.05109 (* 1 = 1.05109 loss)
I0527 09:51:53.677153 22103 sgd_solver.cpp:106] Iteration 217875, lr = 0.002
I0527 09:52:03.471683 22103 solver.cpp:237] Iteration 218250, loss = 0.918975
I0527 09:52:03.471719 22103 solver.cpp:253]     Train net output #0: loss = 0.918975 (* 1 = 0.918975 loss)
I0527 09:52:03.471735 22103 sgd_solver.cpp:106] Iteration 218250, lr = 0.002
I0527 09:52:13.273152 22103 solver.cpp:237] Iteration 218625, loss = 1.02261
I0527 09:52:13.273187 22103 solver.cpp:253]     Train net output #0: loss = 1.02261 (* 1 = 1.02261 loss)
I0527 09:52:13.273200 22103 sgd_solver.cpp:106] Iteration 218625, lr = 0.002
I0527 09:52:43.941367 22103 solver.cpp:237] Iteration 219000, loss = 1.20997
I0527 09:52:43.941547 22103 solver.cpp:253]     Train net output #0: loss = 1.20997 (* 1 = 1.20997 loss)
I0527 09:52:43.941562 22103 sgd_solver.cpp:106] Iteration 219000, lr = 0.002
I0527 09:52:53.739567 22103 solver.cpp:237] Iteration 219375, loss = 0.953808
I0527 09:52:53.739603 22103 solver.cpp:253]     Train net output #0: loss = 0.953808 (* 1 = 0.953808 loss)
I0527 09:52:53.739619 22103 sgd_solver.cpp:106] Iteration 219375, lr = 0.002
I0527 09:53:03.531106 22103 solver.cpp:237] Iteration 219750, loss = 0.911926
I0527 09:53:03.531143 22103 solver.cpp:253]     Train net output #0: loss = 0.911926 (* 1 = 0.911926 loss)
I0527 09:53:03.531157 22103 sgd_solver.cpp:106] Iteration 219750, lr = 0.002
I0527 09:53:13.331210 22103 solver.cpp:237] Iteration 220125, loss = 0.960532
I0527 09:53:13.331254 22103 solver.cpp:253]     Train net output #0: loss = 0.960532 (* 1 = 0.960532 loss)
I0527 09:53:13.331270 22103 sgd_solver.cpp:106] Iteration 220125, lr = 0.002
I0527 09:53:23.128684 22103 solver.cpp:237] Iteration 220500, loss = 1.20413
I0527 09:53:23.128832 22103 solver.cpp:253]     Train net output #0: loss = 1.20413 (* 1 = 1.20413 loss)
I0527 09:53:23.128847 22103 sgd_solver.cpp:106] Iteration 220500, lr = 0.002
I0527 09:53:32.921596 22103 solver.cpp:237] Iteration 220875, loss = 0.989163
I0527 09:53:32.921641 22103 solver.cpp:253]     Train net output #0: loss = 0.989163 (* 1 = 0.989163 loss)
I0527 09:53:32.921658 22103 sgd_solver.cpp:106] Iteration 220875, lr = 0.002
I0527 09:53:42.691267 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_221250.caffemodel
I0527 09:53:42.748657 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_221250.solverstate
I0527 09:54:03.691125 22103 solver.cpp:237] Iteration 221250, loss = 1.18099
I0527 09:54:03.691313 22103 solver.cpp:253]     Train net output #0: loss = 1.18099 (* 1 = 1.18099 loss)
I0527 09:54:03.691329 22103 sgd_solver.cpp:106] Iteration 221250, lr = 0.002
I0527 09:54:13.488528 22103 solver.cpp:237] Iteration 221625, loss = 0.963511
I0527 09:54:13.488559 22103 solver.cpp:253]     Train net output #0: loss = 0.963511 (* 1 = 0.963511 loss)
I0527 09:54:13.488580 22103 sgd_solver.cpp:106] Iteration 221625, lr = 0.002
I0527 09:54:23.281947 22103 solver.cpp:237] Iteration 222000, loss = 0.956217
I0527 09:54:23.281994 22103 solver.cpp:253]     Train net output #0: loss = 0.956217 (* 1 = 0.956217 loss)
I0527 09:54:23.282008 22103 sgd_solver.cpp:106] Iteration 222000, lr = 0.002
I0527 09:54:33.067850 22103 solver.cpp:237] Iteration 222375, loss = 1.21066
I0527 09:54:33.067886 22103 solver.cpp:253]     Train net output #0: loss = 1.21066 (* 1 = 1.21066 loss)
I0527 09:54:33.067903 22103 sgd_solver.cpp:106] Iteration 222375, lr = 0.002
I0527 09:54:42.865314 22103 solver.cpp:237] Iteration 222750, loss = 0.924484
I0527 09:54:42.865475 22103 solver.cpp:253]     Train net output #0: loss = 0.924484 (* 1 = 0.924484 loss)
I0527 09:54:42.865489 22103 sgd_solver.cpp:106] Iteration 222750, lr = 0.002
I0527 09:54:52.667069 22103 solver.cpp:237] Iteration 223125, loss = 1.22951
I0527 09:54:52.667106 22103 solver.cpp:253]     Train net output #0: loss = 1.22951 (* 1 = 1.22951 loss)
I0527 09:54:52.667124 22103 sgd_solver.cpp:106] Iteration 223125, lr = 0.002
I0527 09:55:02.451849 22103 solver.cpp:237] Iteration 223500, loss = 1.21217
I0527 09:55:02.451884 22103 solver.cpp:253]     Train net output #0: loss = 1.21217 (* 1 = 1.21217 loss)
I0527 09:55:02.451899 22103 sgd_solver.cpp:106] Iteration 223500, lr = 0.002
I0527 09:55:33.154371 22103 solver.cpp:237] Iteration 223875, loss = 1.1688
I0527 09:55:33.154548 22103 solver.cpp:253]     Train net output #0: loss = 1.16879 (* 1 = 1.16879 loss)
I0527 09:55:33.154563 22103 sgd_solver.cpp:106] Iteration 223875, lr = 0.002
I0527 09:55:42.953385 22103 solver.cpp:237] Iteration 224250, loss = 1.04328
I0527 09:55:42.953423 22103 solver.cpp:253]     Train net output #0: loss = 1.04328 (* 1 = 1.04328 loss)
I0527 09:55:42.953444 22103 sgd_solver.cpp:106] Iteration 224250, lr = 0.002
I0527 09:55:52.742311 22103 solver.cpp:237] Iteration 224625, loss = 0.905709
I0527 09:55:52.742347 22103 solver.cpp:253]     Train net output #0: loss = 0.905709 (* 1 = 0.905709 loss)
I0527 09:55:52.742362 22103 sgd_solver.cpp:106] Iteration 224625, lr = 0.002
I0527 09:56:02.506345 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_225000.caffemodel
I0527 09:56:02.564391 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_225000.solverstate
I0527 09:56:02.591806 22103 solver.cpp:341] Iteration 225000, Testing net (#0)
I0527 09:56:50.846772 22103 solver.cpp:409]     Test net output #0: accuracy = 0.901238
I0527 09:56:50.846951 22103 solver.cpp:409]     Test net output #1: loss = 0.31338 (* 1 = 0.31338 loss)
I0527 09:56:50.855029 22103 solver.cpp:237] Iteration 225000, loss = 0.903925
I0527 09:56:50.855058 22103 solver.cpp:253]     Train net output #0: loss = 0.903925 (* 1 = 0.903925 loss)
I0527 09:56:50.855072 22103 sgd_solver.cpp:106] Iteration 225000, lr = 0.002
I0527 09:57:00.643337 22103 solver.cpp:237] Iteration 225375, loss = 0.906269
I0527 09:57:00.643373 22103 solver.cpp:253]     Train net output #0: loss = 0.906268 (* 1 = 0.906268 loss)
I0527 09:57:00.643386 22103 sgd_solver.cpp:106] Iteration 225375, lr = 0.002
I0527 09:57:10.430696 22103 solver.cpp:237] Iteration 225750, loss = 1.32982
I0527 09:57:10.430732 22103 solver.cpp:253]     Train net output #0: loss = 1.32982 (* 1 = 1.32982 loss)
I0527 09:57:10.430748 22103 sgd_solver.cpp:106] Iteration 225750, lr = 0.002
I0527 09:57:20.222285 22103 solver.cpp:237] Iteration 226125, loss = 1.07817
I0527 09:57:20.222334 22103 solver.cpp:253]     Train net output #0: loss = 1.07817 (* 1 = 1.07817 loss)
I0527 09:57:20.222348 22103 sgd_solver.cpp:106] Iteration 226125, lr = 0.002
I0527 09:57:50.895711 22103 solver.cpp:237] Iteration 226500, loss = 0.997186
I0527 09:57:50.895884 22103 solver.cpp:253]     Train net output #0: loss = 0.997186 (* 1 = 0.997186 loss)
I0527 09:57:50.895900 22103 sgd_solver.cpp:106] Iteration 226500, lr = 0.002
I0527 09:58:00.684927 22103 solver.cpp:237] Iteration 226875, loss = 1.20157
I0527 09:58:00.684962 22103 solver.cpp:253]     Train net output #0: loss = 1.20157 (* 1 = 1.20157 loss)
I0527 09:58:00.684978 22103 sgd_solver.cpp:106] Iteration 226875, lr = 0.002
I0527 09:58:10.472592 22103 solver.cpp:237] Iteration 227250, loss = 1.14808
I0527 09:58:10.472641 22103 solver.cpp:253]     Train net output #0: loss = 1.14808 (* 1 = 1.14808 loss)
I0527 09:58:10.472656 22103 sgd_solver.cpp:106] Iteration 227250, lr = 0.002
I0527 09:58:20.265287 22103 solver.cpp:237] Iteration 227625, loss = 1.19742
I0527 09:58:20.265322 22103 solver.cpp:253]     Train net output #0: loss = 1.19742 (* 1 = 1.19742 loss)
I0527 09:58:20.265341 22103 sgd_solver.cpp:106] Iteration 227625, lr = 0.002
I0527 09:58:30.056905 22103 solver.cpp:237] Iteration 228000, loss = 1.44626
I0527 09:58:30.057088 22103 solver.cpp:253]     Train net output #0: loss = 1.44626 (* 1 = 1.44626 loss)
I0527 09:58:30.057103 22103 sgd_solver.cpp:106] Iteration 228000, lr = 0.002
I0527 09:58:39.840601 22103 solver.cpp:237] Iteration 228375, loss = 1.00548
I0527 09:58:39.840636 22103 solver.cpp:253]     Train net output #0: loss = 1.00548 (* 1 = 1.00548 loss)
I0527 09:58:39.840656 22103 sgd_solver.cpp:106] Iteration 228375, lr = 0.002
I0527 09:58:49.601624 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_228750.caffemodel
I0527 09:58:49.658463 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_228750.solverstate
I0527 09:59:10.587865 22103 solver.cpp:237] Iteration 228750, loss = 0.96448
I0527 09:59:10.588050 22103 solver.cpp:253]     Train net output #0: loss = 0.96448 (* 1 = 0.96448 loss)
I0527 09:59:10.588066 22103 sgd_solver.cpp:106] Iteration 228750, lr = 0.002
I0527 09:59:20.373961 22103 solver.cpp:237] Iteration 229125, loss = 1.04077
I0527 09:59:20.374013 22103 solver.cpp:253]     Train net output #0: loss = 1.04077 (* 1 = 1.04077 loss)
I0527 09:59:20.374028 22103 sgd_solver.cpp:106] Iteration 229125, lr = 0.002
I0527 09:59:30.100702 22103 solver.cpp:237] Iteration 229500, loss = 1.17373
I0527 09:59:30.100736 22103 solver.cpp:253]     Train net output #0: loss = 1.17373 (* 1 = 1.17373 loss)
I0527 09:59:30.100750 22103 sgd_solver.cpp:106] Iteration 229500, lr = 0.002
I0527 09:59:39.833158 22103 solver.cpp:237] Iteration 229875, loss = 1.07533
I0527 09:59:39.833192 22103 solver.cpp:253]     Train net output #0: loss = 1.07533 (* 1 = 1.07533 loss)
I0527 09:59:39.833206 22103 sgd_solver.cpp:106] Iteration 229875, lr = 0.002
I0527 09:59:49.566715 22103 solver.cpp:237] Iteration 230250, loss = 1.31365
I0527 09:59:49.566884 22103 solver.cpp:253]     Train net output #0: loss = 1.31365 (* 1 = 1.31365 loss)
I0527 09:59:49.566897 22103 sgd_solver.cpp:106] Iteration 230250, lr = 0.002
I0527 09:59:59.296283 22103 solver.cpp:237] Iteration 230625, loss = 1.2398
I0527 09:59:59.296317 22103 solver.cpp:253]     Train net output #0: loss = 1.2398 (* 1 = 1.2398 loss)
I0527 09:59:59.296335 22103 sgd_solver.cpp:106] Iteration 230625, lr = 0.002
I0527 10:00:09.024345 22103 solver.cpp:237] Iteration 231000, loss = 0.843467
I0527 10:00:09.024396 22103 solver.cpp:253]     Train net output #0: loss = 0.843467 (* 1 = 0.843467 loss)
I0527 10:00:09.024410 22103 sgd_solver.cpp:106] Iteration 231000, lr = 0.002
I0527 10:00:39.593720 22103 solver.cpp:237] Iteration 231375, loss = 1.23301
I0527 10:00:39.593910 22103 solver.cpp:253]     Train net output #0: loss = 1.23301 (* 1 = 1.23301 loss)
I0527 10:00:39.593925 22103 sgd_solver.cpp:106] Iteration 231375, lr = 0.002
I0527 10:00:49.324651 22103 solver.cpp:237] Iteration 231750, loss = 0.886667
I0527 10:00:49.324687 22103 solver.cpp:253]     Train net output #0: loss = 0.886667 (* 1 = 0.886667 loss)
I0527 10:00:49.324702 22103 sgd_solver.cpp:106] Iteration 231750, lr = 0.002
I0527 10:00:59.053407 22103 solver.cpp:237] Iteration 232125, loss = 1.17878
I0527 10:00:59.053452 22103 solver.cpp:253]     Train net output #0: loss = 1.17878 (* 1 = 1.17878 loss)
I0527 10:00:59.053467 22103 sgd_solver.cpp:106] Iteration 232125, lr = 0.002
I0527 10:01:08.763092 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_232500.caffemodel
I0527 10:01:08.818655 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_232500.solverstate
I0527 10:01:08.844117 22103 solver.cpp:341] Iteration 232500, Testing net (#0)
I0527 10:02:18.204668 22103 solver.cpp:409]     Test net output #0: accuracy = 0.899739
I0527 10:02:18.204855 22103 solver.cpp:409]     Test net output #1: loss = 0.309476 (* 1 = 0.309476 loss)
I0527 10:02:18.212918 22103 solver.cpp:237] Iteration 232500, loss = 0.97311
I0527 10:02:18.212947 22103 solver.cpp:253]     Train net output #0: loss = 0.97311 (* 1 = 0.97311 loss)
I0527 10:02:18.212961 22103 sgd_solver.cpp:106] Iteration 232500, lr = 0.002
I0527 10:02:28.051393 22103 solver.cpp:237] Iteration 232875, loss = 1.17339
I0527 10:02:28.051429 22103 solver.cpp:253]     Train net output #0: loss = 1.17339 (* 1 = 1.17339 loss)
I0527 10:02:28.051445 22103 sgd_solver.cpp:106] Iteration 232875, lr = 0.002
I0527 10:02:37.890866 22103 solver.cpp:237] Iteration 233250, loss = 1.01637
I0527 10:02:37.890902 22103 solver.cpp:253]     Train net output #0: loss = 1.01637 (* 1 = 1.01637 loss)
I0527 10:02:37.890918 22103 sgd_solver.cpp:106] Iteration 233250, lr = 0.002
I0527 10:02:47.726155 22103 solver.cpp:237] Iteration 233625, loss = 1.31963
I0527 10:02:47.726204 22103 solver.cpp:253]     Train net output #0: loss = 1.31963 (* 1 = 1.31963 loss)
I0527 10:02:47.726218 22103 sgd_solver.cpp:106] Iteration 233625, lr = 0.002
I0527 10:03:18.481340 22103 solver.cpp:237] Iteration 234000, loss = 1.20282
I0527 10:03:18.481518 22103 solver.cpp:253]     Train net output #0: loss = 1.20282 (* 1 = 1.20282 loss)
I0527 10:03:18.481534 22103 sgd_solver.cpp:106] Iteration 234000, lr = 0.002
I0527 10:03:28.320180 22103 solver.cpp:237] Iteration 234375, loss = 0.885614
I0527 10:03:28.320216 22103 solver.cpp:253]     Train net output #0: loss = 0.885614 (* 1 = 0.885614 loss)
I0527 10:03:28.320233 22103 sgd_solver.cpp:106] Iteration 234375, lr = 0.002
I0527 10:03:38.167331 22103 solver.cpp:237] Iteration 234750, loss = 1.42992
I0527 10:03:38.167372 22103 solver.cpp:253]     Train net output #0: loss = 1.42992 (* 1 = 1.42992 loss)
I0527 10:03:38.167392 22103 sgd_solver.cpp:106] Iteration 234750, lr = 0.002
I0527 10:03:48.012838 22103 solver.cpp:237] Iteration 235125, loss = 1.17942
I0527 10:03:48.012872 22103 solver.cpp:253]     Train net output #0: loss = 1.17942 (* 1 = 1.17942 loss)
I0527 10:03:48.012888 22103 sgd_solver.cpp:106] Iteration 235125, lr = 0.002
I0527 10:03:57.866004 22103 solver.cpp:237] Iteration 235500, loss = 0.979654
I0527 10:03:57.866174 22103 solver.cpp:253]     Train net output #0: loss = 0.979654 (* 1 = 0.979654 loss)
I0527 10:03:57.866189 22103 sgd_solver.cpp:106] Iteration 235500, lr = 0.002
I0527 10:04:07.711663 22103 solver.cpp:237] Iteration 235875, loss = 1.0328
I0527 10:04:07.711697 22103 solver.cpp:253]     Train net output #0: loss = 1.0328 (* 1 = 1.0328 loss)
I0527 10:04:07.711714 22103 sgd_solver.cpp:106] Iteration 235875, lr = 0.002
I0527 10:04:17.533303 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_236250.caffemodel
I0527 10:04:17.590572 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_236250.solverstate
I0527 10:04:38.550294 22103 solver.cpp:237] Iteration 236250, loss = 0.959822
I0527 10:04:38.550483 22103 solver.cpp:253]     Train net output #0: loss = 0.959821 (* 1 = 0.959821 loss)
I0527 10:04:38.550500 22103 sgd_solver.cpp:106] Iteration 236250, lr = 0.002
I0527 10:04:48.396921 22103 solver.cpp:237] Iteration 236625, loss = 1.27369
I0527 10:04:48.396966 22103 solver.cpp:253]     Train net output #0: loss = 1.27369 (* 1 = 1.27369 loss)
I0527 10:04:48.396981 22103 sgd_solver.cpp:106] Iteration 236625, lr = 0.002
I0527 10:04:58.233824 22103 solver.cpp:237] Iteration 237000, loss = 1.3116
I0527 10:04:58.233860 22103 solver.cpp:253]     Train net output #0: loss = 1.3116 (* 1 = 1.3116 loss)
I0527 10:04:58.233872 22103 sgd_solver.cpp:106] Iteration 237000, lr = 0.002
I0527 10:05:08.084540 22103 solver.cpp:237] Iteration 237375, loss = 1.01909
I0527 10:05:08.084576 22103 solver.cpp:253]     Train net output #0: loss = 1.01909 (* 1 = 1.01909 loss)
I0527 10:05:08.084592 22103 sgd_solver.cpp:106] Iteration 237375, lr = 0.002
I0527 10:05:17.930778 22103 solver.cpp:237] Iteration 237750, loss = 1.27463
I0527 10:05:17.930955 22103 solver.cpp:253]     Train net output #0: loss = 1.27463 (* 1 = 1.27463 loss)
I0527 10:05:17.930970 22103 sgd_solver.cpp:106] Iteration 237750, lr = 0.002
I0527 10:05:27.776684 22103 solver.cpp:237] Iteration 238125, loss = 1.08924
I0527 10:05:27.776718 22103 solver.cpp:253]     Train net output #0: loss = 1.08924 (* 1 = 1.08924 loss)
I0527 10:05:27.776736 22103 sgd_solver.cpp:106] Iteration 238125, lr = 0.002
I0527 10:05:37.622604 22103 solver.cpp:237] Iteration 238500, loss = 1.195
I0527 10:05:37.622642 22103 solver.cpp:253]     Train net output #0: loss = 1.195 (* 1 = 1.195 loss)
I0527 10:05:37.622663 22103 sgd_solver.cpp:106] Iteration 238500, lr = 0.002
I0527 10:06:08.354393 22103 solver.cpp:237] Iteration 238875, loss = 1.01629
I0527 10:06:08.354573 22103 solver.cpp:253]     Train net output #0: loss = 1.01629 (* 1 = 1.01629 loss)
I0527 10:06:08.354588 22103 sgd_solver.cpp:106] Iteration 238875, lr = 0.002
I0527 10:06:18.195469 22103 solver.cpp:237] Iteration 239250, loss = 1.06766
I0527 10:06:18.195504 22103 solver.cpp:253]     Train net output #0: loss = 1.06766 (* 1 = 1.06766 loss)
I0527 10:06:18.195518 22103 sgd_solver.cpp:106] Iteration 239250, lr = 0.002
I0527 10:06:28.042070 22103 solver.cpp:237] Iteration 239625, loss = 0.952859
I0527 10:06:28.042112 22103 solver.cpp:253]     Train net output #0: loss = 0.952858 (* 1 = 0.952858 loss)
I0527 10:06:28.042129 22103 sgd_solver.cpp:106] Iteration 239625, lr = 0.002
I0527 10:06:37.860306 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_240000.caffemodel
I0527 10:06:37.918820 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_240000.solverstate
I0527 10:06:37.945746 22103 solver.cpp:341] Iteration 240000, Testing net (#0)
I0527 10:07:26.577534 22103 solver.cpp:409]     Test net output #0: accuracy = 0.903992
I0527 10:07:26.577705 22103 solver.cpp:409]     Test net output #1: loss = 0.317574 (* 1 = 0.317574 loss)
I0527 10:07:26.585793 22103 solver.cpp:237] Iteration 240000, loss = 1.68372
I0527 10:07:26.585819 22103 solver.cpp:253]     Train net output #0: loss = 1.68372 (* 1 = 1.68372 loss)
I0527 10:07:26.585834 22103 sgd_solver.cpp:106] Iteration 240000, lr = 0.002
I0527 10:07:36.526298 22103 solver.cpp:237] Iteration 240375, loss = 1.18119
I0527 10:07:36.526334 22103 solver.cpp:253]     Train net output #0: loss = 1.18119 (* 1 = 1.18119 loss)
I0527 10:07:36.526350 22103 sgd_solver.cpp:106] Iteration 240375, lr = 0.002
I0527 10:07:46.486300 22103 solver.cpp:237] Iteration 240750, loss = 1.48499
I0527 10:07:46.486342 22103 solver.cpp:253]     Train net output #0: loss = 1.48499 (* 1 = 1.48499 loss)
I0527 10:07:46.486359 22103 sgd_solver.cpp:106] Iteration 240750, lr = 0.002
I0527 10:07:56.421807 22103 solver.cpp:237] Iteration 241125, loss = 1.18882
I0527 10:07:56.421840 22103 solver.cpp:253]     Train net output #0: loss = 1.18882 (* 1 = 1.18882 loss)
I0527 10:07:56.421854 22103 sgd_solver.cpp:106] Iteration 241125, lr = 0.002
I0527 10:08:27.326069 22103 solver.cpp:237] Iteration 241500, loss = 1.0846
I0527 10:08:27.326261 22103 solver.cpp:253]     Train net output #0: loss = 1.0846 (* 1 = 1.0846 loss)
I0527 10:08:27.326277 22103 sgd_solver.cpp:106] Iteration 241500, lr = 0.002
I0527 10:08:37.240494 22103 solver.cpp:237] Iteration 241875, loss = 1.3427
I0527 10:08:37.240537 22103 solver.cpp:253]     Train net output #0: loss = 1.3427 (* 1 = 1.3427 loss)
I0527 10:08:37.240552 22103 sgd_solver.cpp:106] Iteration 241875, lr = 0.002
I0527 10:08:47.147325 22103 solver.cpp:237] Iteration 242250, loss = 1.08371
I0527 10:08:47.147361 22103 solver.cpp:253]     Train net output #0: loss = 1.08371 (* 1 = 1.08371 loss)
I0527 10:08:47.147374 22103 sgd_solver.cpp:106] Iteration 242250, lr = 0.002
I0527 10:08:57.043975 22103 solver.cpp:237] Iteration 242625, loss = 1.26992
I0527 10:08:57.044019 22103 solver.cpp:253]     Train net output #0: loss = 1.26992 (* 1 = 1.26992 loss)
I0527 10:08:57.044037 22103 sgd_solver.cpp:106] Iteration 242625, lr = 0.002
I0527 10:09:06.950891 22103 solver.cpp:237] Iteration 243000, loss = 1.22172
I0527 10:09:06.951047 22103 solver.cpp:253]     Train net output #0: loss = 1.22172 (* 1 = 1.22172 loss)
I0527 10:09:06.951061 22103 sgd_solver.cpp:106] Iteration 243000, lr = 0.002
I0527 10:09:16.850849 22103 solver.cpp:237] Iteration 243375, loss = 1.21454
I0527 10:09:16.850884 22103 solver.cpp:253]     Train net output #0: loss = 1.21454 (* 1 = 1.21454 loss)
I0527 10:09:16.850903 22103 sgd_solver.cpp:106] Iteration 243375, lr = 0.002
I0527 10:09:26.722029 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_243750.caffemodel
I0527 10:09:26.780323 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_243750.solverstate
I0527 10:09:47.725201 22103 solver.cpp:237] Iteration 243750, loss = 1.3259
I0527 10:09:47.725394 22103 solver.cpp:253]     Train net output #0: loss = 1.3259 (* 1 = 1.3259 loss)
I0527 10:09:47.725410 22103 sgd_solver.cpp:106] Iteration 243750, lr = 0.002
I0527 10:09:57.624292 22103 solver.cpp:237] Iteration 244125, loss = 1.19928
I0527 10:09:57.624327 22103 solver.cpp:253]     Train net output #0: loss = 1.19928 (* 1 = 1.19928 loss)
I0527 10:09:57.624346 22103 sgd_solver.cpp:106] Iteration 244125, lr = 0.002
I0527 10:10:07.535771 22103 solver.cpp:237] Iteration 244500, loss = 1.32166
I0527 10:10:07.535807 22103 solver.cpp:253]     Train net output #0: loss = 1.32166 (* 1 = 1.32166 loss)
I0527 10:10:07.535825 22103 sgd_solver.cpp:106] Iteration 244500, lr = 0.002
I0527 10:10:17.444061 22103 solver.cpp:237] Iteration 244875, loss = 0.964879
I0527 10:10:17.444102 22103 solver.cpp:253]     Train net output #0: loss = 0.964879 (* 1 = 0.964879 loss)
I0527 10:10:17.444121 22103 sgd_solver.cpp:106] Iteration 244875, lr = 0.002
I0527 10:10:27.347189 22103 solver.cpp:237] Iteration 245250, loss = 0.913591
I0527 10:10:27.347347 22103 solver.cpp:253]     Train net output #0: loss = 0.913591 (* 1 = 0.913591 loss)
I0527 10:10:27.347360 22103 sgd_solver.cpp:106] Iteration 245250, lr = 0.002
I0527 10:10:37.264725 22103 solver.cpp:237] Iteration 245625, loss = 1.13764
I0527 10:10:37.264767 22103 solver.cpp:253]     Train net output #0: loss = 1.13764 (* 1 = 1.13764 loss)
I0527 10:10:37.264789 22103 sgd_solver.cpp:106] Iteration 245625, lr = 0.002
I0527 10:10:47.214706 22103 solver.cpp:237] Iteration 246000, loss = 1.30913
I0527 10:10:47.214741 22103 solver.cpp:253]     Train net output #0: loss = 1.30913 (* 1 = 1.30913 loss)
I0527 10:10:47.214758 22103 sgd_solver.cpp:106] Iteration 246000, lr = 0.002
I0527 10:11:18.039778 22103 solver.cpp:237] Iteration 246375, loss = 1.13337
I0527 10:11:18.039957 22103 solver.cpp:253]     Train net output #0: loss = 1.13337 (* 1 = 1.13337 loss)
I0527 10:11:18.039971 22103 sgd_solver.cpp:106] Iteration 246375, lr = 0.002
I0527 10:11:27.988016 22103 solver.cpp:237] Iteration 246750, loss = 0.917087
I0527 10:11:27.988057 22103 solver.cpp:253]     Train net output #0: loss = 0.917087 (* 1 = 0.917087 loss)
I0527 10:11:27.988078 22103 sgd_solver.cpp:106] Iteration 246750, lr = 0.002
I0527 10:11:37.925712 22103 solver.cpp:237] Iteration 247125, loss = 1.37879
I0527 10:11:37.925748 22103 solver.cpp:253]     Train net output #0: loss = 1.37879 (* 1 = 1.37879 loss)
I0527 10:11:37.925765 22103 sgd_solver.cpp:106] Iteration 247125, lr = 0.002
I0527 10:11:47.844291 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_247500.caffemodel
I0527 10:11:47.903708 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_247500.solverstate
I0527 10:11:47.931568 22103 solver.cpp:341] Iteration 247500, Testing net (#0)
I0527 10:12:57.369770 22103 solver.cpp:409]     Test net output #0: accuracy = 0.899679
I0527 10:12:57.369963 22103 solver.cpp:409]     Test net output #1: loss = 0.304542 (* 1 = 0.304542 loss)
I0527 10:12:57.378041 22103 solver.cpp:237] Iteration 247500, loss = 0.982057
I0527 10:12:57.378069 22103 solver.cpp:253]     Train net output #0: loss = 0.982057 (* 1 = 0.982057 loss)
I0527 10:12:57.378083 22103 sgd_solver.cpp:106] Iteration 247500, lr = 0.002
I0527 10:13:07.203119 22103 solver.cpp:237] Iteration 247875, loss = 1.26366
I0527 10:13:07.203158 22103 solver.cpp:253]     Train net output #0: loss = 1.26366 (* 1 = 1.26366 loss)
I0527 10:13:07.203179 22103 sgd_solver.cpp:106] Iteration 247875, lr = 0.002
I0527 10:13:17.036612 22103 solver.cpp:237] Iteration 248250, loss = 0.607601
I0527 10:13:17.036648 22103 solver.cpp:253]     Train net output #0: loss = 0.607601 (* 1 = 0.607601 loss)
I0527 10:13:17.036664 22103 sgd_solver.cpp:106] Iteration 248250, lr = 0.002
I0527 10:13:26.867223 22103 solver.cpp:237] Iteration 248625, loss = 1.00975
I0527 10:13:26.867257 22103 solver.cpp:253]     Train net output #0: loss = 1.00975 (* 1 = 1.00975 loss)
I0527 10:13:26.867274 22103 sgd_solver.cpp:106] Iteration 248625, lr = 0.002
I0527 10:13:57.571755 22103 solver.cpp:237] Iteration 249000, loss = 1.06823
I0527 10:13:57.571934 22103 solver.cpp:253]     Train net output #0: loss = 1.06823 (* 1 = 1.06823 loss)
I0527 10:13:57.571951 22103 sgd_solver.cpp:106] Iteration 249000, lr = 0.002
I0527 10:14:07.405060 22103 solver.cpp:237] Iteration 249375, loss = 1.0434
I0527 10:14:07.405093 22103 solver.cpp:253]     Train net output #0: loss = 1.0434 (* 1 = 1.0434 loss)
I0527 10:14:07.405107 22103 sgd_solver.cpp:106] Iteration 249375, lr = 0.002
I0527 10:14:17.233755 22103 solver.cpp:237] Iteration 249750, loss = 1.0956
I0527 10:14:17.233790 22103 solver.cpp:253]     Train net output #0: loss = 1.0956 (* 1 = 1.0956 loss)
I0527 10:14:17.233808 22103 sgd_solver.cpp:106] Iteration 249750, lr = 0.002
I0527 10:14:27.067333 22103 solver.cpp:237] Iteration 250125, loss = 0.900227
I0527 10:14:27.067380 22103 solver.cpp:253]     Train net output #0: loss = 0.900226 (* 1 = 0.900226 loss)
I0527 10:14:27.067397 22103 sgd_solver.cpp:106] Iteration 250125, lr = 0.002
I0527 10:14:36.900177 22103 solver.cpp:237] Iteration 250500, loss = 1.04589
I0527 10:14:36.900338 22103 solver.cpp:253]     Train net output #0: loss = 1.04589 (* 1 = 1.04589 loss)
I0527 10:14:36.900352 22103 sgd_solver.cpp:106] Iteration 250500, lr = 0.002
I0527 10:14:46.732990 22103 solver.cpp:237] Iteration 250875, loss = 1.07837
I0527 10:14:46.733026 22103 solver.cpp:253]     Train net output #0: loss = 1.07837 (* 1 = 1.07837 loss)
I0527 10:14:46.733047 22103 sgd_solver.cpp:106] Iteration 250875, lr = 0.002
I0527 10:14:56.542140 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_251250.caffemodel
I0527 10:14:56.598078 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_251250.solverstate
I0527 10:15:17.545938 22103 solver.cpp:237] Iteration 251250, loss = 0.928777
I0527 10:15:17.546136 22103 solver.cpp:253]     Train net output #0: loss = 0.928777 (* 1 = 0.928777 loss)
I0527 10:15:17.546154 22103 sgd_solver.cpp:106] Iteration 251250, lr = 0.002
I0527 10:15:27.372467 22103 solver.cpp:237] Iteration 251625, loss = 1.06411
I0527 10:15:27.372503 22103 solver.cpp:253]     Train net output #0: loss = 1.06411 (* 1 = 1.06411 loss)
I0527 10:15:27.372520 22103 sgd_solver.cpp:106] Iteration 251625, lr = 0.002
I0527 10:15:37.204098 22103 solver.cpp:237] Iteration 252000, loss = 0.919467
I0527 10:15:37.204139 22103 solver.cpp:253]     Train net output #0: loss = 0.919467 (* 1 = 0.919467 loss)
I0527 10:15:37.204160 22103 sgd_solver.cpp:106] Iteration 252000, lr = 0.002
I0527 10:15:47.035256 22103 solver.cpp:237] Iteration 252375, loss = 1.14901
I0527 10:15:47.035292 22103 solver.cpp:253]     Train net output #0: loss = 1.14901 (* 1 = 1.14901 loss)
I0527 10:15:47.035310 22103 sgd_solver.cpp:106] Iteration 252375, lr = 0.002
I0527 10:15:56.865306 22103 solver.cpp:237] Iteration 252750, loss = 1.19449
I0527 10:15:56.865468 22103 solver.cpp:253]     Train net output #0: loss = 1.19449 (* 1 = 1.19449 loss)
I0527 10:15:56.865481 22103 sgd_solver.cpp:106] Iteration 252750, lr = 0.002
I0527 10:16:06.693562 22103 solver.cpp:237] Iteration 253125, loss = 1.50611
I0527 10:16:06.693599 22103 solver.cpp:253]     Train net output #0: loss = 1.50611 (* 1 = 1.50611 loss)
I0527 10:16:06.693619 22103 sgd_solver.cpp:106] Iteration 253125, lr = 0.002
I0527 10:16:16.527248 22103 solver.cpp:237] Iteration 253500, loss = 1.00866
I0527 10:16:16.527284 22103 solver.cpp:253]     Train net output #0: loss = 1.00866 (* 1 = 1.00866 loss)
I0527 10:16:16.527298 22103 sgd_solver.cpp:106] Iteration 253500, lr = 0.002
I0527 10:16:47.304786 22103 solver.cpp:237] Iteration 253875, loss = 1.28193
I0527 10:16:47.304968 22103 solver.cpp:253]     Train net output #0: loss = 1.28193 (* 1 = 1.28193 loss)
I0527 10:16:47.304983 22103 sgd_solver.cpp:106] Iteration 253875, lr = 0.002
I0527 10:16:57.127714 22103 solver.cpp:237] Iteration 254250, loss = 1.0822
I0527 10:16:57.127763 22103 solver.cpp:253]     Train net output #0: loss = 1.0822 (* 1 = 1.0822 loss)
I0527 10:16:57.127779 22103 sgd_solver.cpp:106] Iteration 254250, lr = 0.002
I0527 10:17:06.960628 22103 solver.cpp:237] Iteration 254625, loss = 1.19724
I0527 10:17:06.960665 22103 solver.cpp:253]     Train net output #0: loss = 1.19724 (* 1 = 1.19724 loss)
I0527 10:17:06.960681 22103 sgd_solver.cpp:106] Iteration 254625, lr = 0.002
I0527 10:17:16.765220 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_255000.caffemodel
I0527 10:17:16.820750 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_255000.solverstate
I0527 10:17:16.846351 22103 solver.cpp:341] Iteration 255000, Testing net (#0)
I0527 10:18:05.098165 22103 solver.cpp:409]     Test net output #0: accuracy = 0.899893
I0527 10:18:05.098340 22103 solver.cpp:409]     Test net output #1: loss = 0.308571 (* 1 = 0.308571 loss)
I0527 10:18:05.106369 22103 solver.cpp:237] Iteration 255000, loss = 1.1285
I0527 10:18:05.106395 22103 solver.cpp:253]     Train net output #0: loss = 1.1285 (* 1 = 1.1285 loss)
I0527 10:18:05.106410 22103 sgd_solver.cpp:106] Iteration 255000, lr = 0.002
I0527 10:18:14.877779 22103 solver.cpp:237] Iteration 255375, loss = 1.09468
I0527 10:18:14.877813 22103 solver.cpp:253]     Train net output #0: loss = 1.09468 (* 1 = 1.09468 loss)
I0527 10:18:14.877831 22103 sgd_solver.cpp:106] Iteration 255375, lr = 0.002
I0527 10:18:24.658999 22103 solver.cpp:237] Iteration 255750, loss = 1.07329
I0527 10:18:24.659035 22103 solver.cpp:253]     Train net output #0: loss = 1.07329 (* 1 = 1.07329 loss)
I0527 10:18:24.659050 22103 sgd_solver.cpp:106] Iteration 255750, lr = 0.002
I0527 10:18:34.425027 22103 solver.cpp:237] Iteration 256125, loss = 1.23355
I0527 10:18:34.425067 22103 solver.cpp:253]     Train net output #0: loss = 1.23355 (* 1 = 1.23355 loss)
I0527 10:18:34.425084 22103 sgd_solver.cpp:106] Iteration 256125, lr = 0.002
I0527 10:19:05.116685 22103 solver.cpp:237] Iteration 256500, loss = 0.872081
I0527 10:19:05.116873 22103 solver.cpp:253]     Train net output #0: loss = 0.872081 (* 1 = 0.872081 loss)
I0527 10:19:05.116888 22103 sgd_solver.cpp:106] Iteration 256500, lr = 0.002
I0527 10:19:14.888530 22103 solver.cpp:237] Iteration 256875, loss = 0.911372
I0527 10:19:14.888566 22103 solver.cpp:253]     Train net output #0: loss = 0.911372 (* 1 = 0.911372 loss)
I0527 10:19:14.888583 22103 sgd_solver.cpp:106] Iteration 256875, lr = 0.002
I0527 10:19:24.631745 22103 solver.cpp:237] Iteration 257250, loss = 1.11938
I0527 10:19:24.631794 22103 solver.cpp:253]     Train net output #0: loss = 1.11938 (* 1 = 1.11938 loss)
I0527 10:19:24.631808 22103 sgd_solver.cpp:106] Iteration 257250, lr = 0.002
I0527 10:19:34.371114 22103 solver.cpp:237] Iteration 257625, loss = 1.0086
I0527 10:19:34.371148 22103 solver.cpp:253]     Train net output #0: loss = 1.0086 (* 1 = 1.0086 loss)
I0527 10:19:34.371163 22103 sgd_solver.cpp:106] Iteration 257625, lr = 0.002
I0527 10:19:44.098016 22103 solver.cpp:237] Iteration 258000, loss = 0.897424
I0527 10:19:44.098192 22103 solver.cpp:253]     Train net output #0: loss = 0.897424 (* 1 = 0.897424 loss)
I0527 10:19:44.098207 22103 sgd_solver.cpp:106] Iteration 258000, lr = 0.002
I0527 10:19:53.829121 22103 solver.cpp:237] Iteration 258375, loss = 1.11937
I0527 10:19:53.829156 22103 solver.cpp:253]     Train net output #0: loss = 1.11937 (* 1 = 1.11937 loss)
I0527 10:19:53.829170 22103 sgd_solver.cpp:106] Iteration 258375, lr = 0.002
I0527 10:20:03.538473 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_258750.caffemodel
I0527 10:20:03.594720 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_258750.solverstate
I0527 10:20:24.577525 22103 solver.cpp:237] Iteration 258750, loss = 0.982346
I0527 10:20:24.577718 22103 solver.cpp:253]     Train net output #0: loss = 0.982346 (* 1 = 0.982346 loss)
I0527 10:20:24.577734 22103 sgd_solver.cpp:106] Iteration 258750, lr = 0.002
I0527 10:20:34.310073 22103 solver.cpp:237] Iteration 259125, loss = 1.05286
I0527 10:20:34.310112 22103 solver.cpp:253]     Train net output #0: loss = 1.05286 (* 1 = 1.05286 loss)
I0527 10:20:34.310127 22103 sgd_solver.cpp:106] Iteration 259125, lr = 0.002
I0527 10:20:44.037472 22103 solver.cpp:237] Iteration 259500, loss = 1.33758
I0527 10:20:44.037508 22103 solver.cpp:253]     Train net output #0: loss = 1.33758 (* 1 = 1.33758 loss)
I0527 10:20:44.037520 22103 sgd_solver.cpp:106] Iteration 259500, lr = 0.002
I0527 10:20:53.766285 22103 solver.cpp:237] Iteration 259875, loss = 0.882866
I0527 10:20:53.766322 22103 solver.cpp:253]     Train net output #0: loss = 0.882866 (* 1 = 0.882866 loss)
I0527 10:20:53.766335 22103 sgd_solver.cpp:106] Iteration 259875, lr = 0.002
I0527 10:21:03.486058 22103 solver.cpp:237] Iteration 260250, loss = 1.20273
I0527 10:21:03.486243 22103 solver.cpp:253]     Train net output #0: loss = 1.20273 (* 1 = 1.20273 loss)
I0527 10:21:03.486256 22103 sgd_solver.cpp:106] Iteration 260250, lr = 0.002
I0527 10:21:13.208959 22103 solver.cpp:237] Iteration 260625, loss = 1.13776
I0527 10:21:13.208994 22103 solver.cpp:253]     Train net output #0: loss = 1.13776 (* 1 = 1.13776 loss)
I0527 10:21:13.209013 22103 sgd_solver.cpp:106] Iteration 260625, lr = 0.002
I0527 10:21:22.941567 22103 solver.cpp:237] Iteration 261000, loss = 1.15645
I0527 10:21:22.941601 22103 solver.cpp:253]     Train net output #0: loss = 1.15645 (* 1 = 1.15645 loss)
I0527 10:21:22.941615 22103 sgd_solver.cpp:106] Iteration 261000, lr = 0.002
I0527 10:21:53.556439 22103 solver.cpp:237] Iteration 261375, loss = 1.14818
I0527 10:21:53.556627 22103 solver.cpp:253]     Train net output #0: loss = 1.14818 (* 1 = 1.14818 loss)
I0527 10:21:53.556643 22103 sgd_solver.cpp:106] Iteration 261375, lr = 0.002
I0527 10:22:03.288203 22103 solver.cpp:237] Iteration 261750, loss = 1.13458
I0527 10:22:03.288239 22103 solver.cpp:253]     Train net output #0: loss = 1.13458 (* 1 = 1.13458 loss)
I0527 10:22:03.288256 22103 sgd_solver.cpp:106] Iteration 261750, lr = 0.002
I0527 10:22:13.024411 22103 solver.cpp:237] Iteration 262125, loss = 1.11549
I0527 10:22:13.024447 22103 solver.cpp:253]     Train net output #0: loss = 1.11549 (* 1 = 1.11549 loss)
I0527 10:22:13.024461 22103 sgd_solver.cpp:106] Iteration 262125, lr = 0.002
I0527 10:22:22.730468 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_262500.caffemodel
I0527 10:22:22.788702 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_262500.solverstate
I0527 10:22:22.817880 22103 solver.cpp:341] Iteration 262500, Testing net (#0)
I0527 10:23:32.281846 22103 solver.cpp:409]     Test net output #0: accuracy = 0.901993
I0527 10:23:32.282035 22103 solver.cpp:409]     Test net output #1: loss = 0.309543 (* 1 = 0.309543 loss)
I0527 10:23:32.290114 22103 solver.cpp:237] Iteration 262500, loss = 1.11744
I0527 10:23:32.290141 22103 solver.cpp:253]     Train net output #0: loss = 1.11744 (* 1 = 1.11744 loss)
I0527 10:23:32.290155 22103 sgd_solver.cpp:106] Iteration 262500, lr = 0.002
I0527 10:23:42.105667 22103 solver.cpp:237] Iteration 262875, loss = 1.27524
I0527 10:23:42.105702 22103 solver.cpp:253]     Train net output #0: loss = 1.27524 (* 1 = 1.27524 loss)
I0527 10:23:42.105716 22103 sgd_solver.cpp:106] Iteration 262875, lr = 0.002
I0527 10:23:51.925099 22103 solver.cpp:237] Iteration 263250, loss = 1.35181
I0527 10:23:51.925134 22103 solver.cpp:253]     Train net output #0: loss = 1.35181 (* 1 = 1.35181 loss)
I0527 10:23:51.925151 22103 sgd_solver.cpp:106] Iteration 263250, lr = 0.002
I0527 10:24:01.775040 22103 solver.cpp:237] Iteration 263625, loss = 1.02248
I0527 10:24:01.775084 22103 solver.cpp:253]     Train net output #0: loss = 1.02248 (* 1 = 1.02248 loss)
I0527 10:24:01.775102 22103 sgd_solver.cpp:106] Iteration 263625, lr = 0.002
I0527 10:24:32.545763 22103 solver.cpp:237] Iteration 264000, loss = 1.23957
I0527 10:24:32.545943 22103 solver.cpp:253]     Train net output #0: loss = 1.23957 (* 1 = 1.23957 loss)
I0527 10:24:32.545958 22103 sgd_solver.cpp:106] Iteration 264000, lr = 0.002
I0527 10:24:42.404677 22103 solver.cpp:237] Iteration 264375, loss = 1.30955
I0527 10:24:42.404712 22103 solver.cpp:253]     Train net output #0: loss = 1.30955 (* 1 = 1.30955 loss)
I0527 10:24:42.404729 22103 sgd_solver.cpp:106] Iteration 264375, lr = 0.002
I0527 10:24:52.258327 22103 solver.cpp:237] Iteration 264750, loss = 1.25489
I0527 10:24:52.258370 22103 solver.cpp:253]     Train net output #0: loss = 1.25489 (* 1 = 1.25489 loss)
I0527 10:24:52.258386 22103 sgd_solver.cpp:106] Iteration 264750, lr = 0.002
I0527 10:25:02.116961 22103 solver.cpp:237] Iteration 265125, loss = 1.34713
I0527 10:25:02.116996 22103 solver.cpp:253]     Train net output #0: loss = 1.34713 (* 1 = 1.34713 loss)
I0527 10:25:02.117009 22103 sgd_solver.cpp:106] Iteration 265125, lr = 0.002
I0527 10:25:11.976018 22103 solver.cpp:237] Iteration 265500, loss = 1.38233
I0527 10:25:11.976191 22103 solver.cpp:253]     Train net output #0: loss = 1.38233 (* 1 = 1.38233 loss)
I0527 10:25:11.976205 22103 sgd_solver.cpp:106] Iteration 265500, lr = 0.002
I0527 10:25:21.830070 22103 solver.cpp:237] Iteration 265875, loss = 0.91288
I0527 10:25:21.830106 22103 solver.cpp:253]     Train net output #0: loss = 0.91288 (* 1 = 0.91288 loss)
I0527 10:25:21.830123 22103 sgd_solver.cpp:106] Iteration 265875, lr = 0.002
I0527 10:25:31.660267 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_266250.caffemodel
I0527 10:25:31.716840 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_266250.solverstate
I0527 10:25:52.642179 22103 solver.cpp:237] Iteration 266250, loss = 0.77952
I0527 10:25:52.642381 22103 solver.cpp:253]     Train net output #0: loss = 0.77952 (* 1 = 0.77952 loss)
I0527 10:25:52.642397 22103 sgd_solver.cpp:106] Iteration 266250, lr = 0.002
I0527 10:26:02.502972 22103 solver.cpp:237] Iteration 266625, loss = 1.09779
I0527 10:26:02.503016 22103 solver.cpp:253]     Train net output #0: loss = 1.09779 (* 1 = 1.09779 loss)
I0527 10:26:02.503034 22103 sgd_solver.cpp:106] Iteration 266625, lr = 0.002
I0527 10:26:12.357884 22103 solver.cpp:237] Iteration 267000, loss = 1.14682
I0527 10:26:12.357919 22103 solver.cpp:253]     Train net output #0: loss = 1.14682 (* 1 = 1.14682 loss)
I0527 10:26:12.357935 22103 sgd_solver.cpp:106] Iteration 267000, lr = 0.002
I0527 10:26:22.210600 22103 solver.cpp:237] Iteration 267375, loss = 1.06784
I0527 10:26:22.210636 22103 solver.cpp:253]     Train net output #0: loss = 1.06784 (* 1 = 1.06784 loss)
I0527 10:26:22.210654 22103 sgd_solver.cpp:106] Iteration 267375, lr = 0.002
I0527 10:26:32.066964 22103 solver.cpp:237] Iteration 267750, loss = 1.55635
I0527 10:26:32.067133 22103 solver.cpp:253]     Train net output #0: loss = 1.55635 (* 1 = 1.55635 loss)
I0527 10:26:32.067148 22103 sgd_solver.cpp:106] Iteration 267750, lr = 0.002
I0527 10:26:41.929862 22103 solver.cpp:237] Iteration 268125, loss = 1.21335
I0527 10:26:41.929896 22103 solver.cpp:253]     Train net output #0: loss = 1.21335 (* 1 = 1.21335 loss)
I0527 10:26:41.929910 22103 sgd_solver.cpp:106] Iteration 268125, lr = 0.002
I0527 10:26:51.786978 22103 solver.cpp:237] Iteration 268500, loss = 1.22323
I0527 10:26:51.787014 22103 solver.cpp:253]     Train net output #0: loss = 1.22323 (* 1 = 1.22323 loss)
I0527 10:26:51.787032 22103 sgd_solver.cpp:106] Iteration 268500, lr = 0.002
I0527 10:27:22.558152 22103 solver.cpp:237] Iteration 268875, loss = 1.28955
I0527 10:27:22.558338 22103 solver.cpp:253]     Train net output #0: loss = 1.28955 (* 1 = 1.28955 loss)
I0527 10:27:22.558354 22103 sgd_solver.cpp:106] Iteration 268875, lr = 0.002
I0527 10:27:32.413355 22103 solver.cpp:237] Iteration 269250, loss = 0.9556
I0527 10:27:32.413390 22103 solver.cpp:253]     Train net output #0: loss = 0.9556 (* 1 = 0.9556 loss)
I0527 10:27:32.413404 22103 sgd_solver.cpp:106] Iteration 269250, lr = 0.002
I0527 10:27:42.271936 22103 solver.cpp:237] Iteration 269625, loss = 0.861921
I0527 10:27:42.271983 22103 solver.cpp:253]     Train net output #0: loss = 0.861921 (* 1 = 0.861921 loss)
I0527 10:27:42.271997 22103 sgd_solver.cpp:106] Iteration 269625, lr = 0.002
I0527 10:27:52.105523 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_270000.caffemodel
I0527 10:27:52.162117 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_270000.solverstate
I0527 10:27:52.187945 22103 solver.cpp:341] Iteration 270000, Testing net (#0)
I0527 10:28:40.802328 22103 solver.cpp:409]     Test net output #0: accuracy = 0.90224
I0527 10:28:40.802510 22103 solver.cpp:409]     Test net output #1: loss = 0.304328 (* 1 = 0.304328 loss)
I0527 10:28:40.810600 22103 solver.cpp:237] Iteration 270000, loss = 1.05578
I0527 10:28:40.810627 22103 solver.cpp:253]     Train net output #0: loss = 1.05578 (* 1 = 1.05578 loss)
I0527 10:28:40.810642 22103 sgd_solver.cpp:106] Iteration 270000, lr = 0.002
I0527 10:28:50.695785 22103 solver.cpp:237] Iteration 270375, loss = 0.917579
I0527 10:28:50.695821 22103 solver.cpp:253]     Train net output #0: loss = 0.917579 (* 1 = 0.917579 loss)
I0527 10:28:50.695834 22103 sgd_solver.cpp:106] Iteration 270375, lr = 0.002
I0527 10:29:00.579591 22103 solver.cpp:237] Iteration 270750, loss = 1.22182
I0527 10:29:00.579633 22103 solver.cpp:253]     Train net output #0: loss = 1.22182 (* 1 = 1.22182 loss)
I0527 10:29:00.579649 22103 sgd_solver.cpp:106] Iteration 270750, lr = 0.002
I0527 10:29:10.462991 22103 solver.cpp:237] Iteration 271125, loss = 1.10077
I0527 10:29:10.463027 22103 solver.cpp:253]     Train net output #0: loss = 1.10077 (* 1 = 1.10077 loss)
I0527 10:29:10.463040 22103 sgd_solver.cpp:106] Iteration 271125, lr = 0.002
I0527 10:29:41.251646 22103 solver.cpp:237] Iteration 271500, loss = 0.960432
I0527 10:29:41.251839 22103 solver.cpp:253]     Train net output #0: loss = 0.960432 (* 1 = 0.960432 loss)
I0527 10:29:41.251854 22103 sgd_solver.cpp:106] Iteration 271500, lr = 0.002
I0527 10:29:51.132663 22103 solver.cpp:237] Iteration 271875, loss = 1.2368
I0527 10:29:51.132707 22103 solver.cpp:253]     Train net output #0: loss = 1.2368 (* 1 = 1.2368 loss)
I0527 10:29:51.132726 22103 sgd_solver.cpp:106] Iteration 271875, lr = 0.002
I0527 10:30:01.013720 22103 solver.cpp:237] Iteration 272250, loss = 0.907517
I0527 10:30:01.013756 22103 solver.cpp:253]     Train net output #0: loss = 0.907517 (* 1 = 0.907517 loss)
I0527 10:30:01.013769 22103 sgd_solver.cpp:106] Iteration 272250, lr = 0.002
I0527 10:30:10.896808 22103 solver.cpp:237] Iteration 272625, loss = 1.1457
I0527 10:30:10.896852 22103 solver.cpp:253]     Train net output #0: loss = 1.1457 (* 1 = 1.1457 loss)
I0527 10:30:10.896864 22103 sgd_solver.cpp:106] Iteration 272625, lr = 0.002
I0527 10:30:20.781092 22103 solver.cpp:237] Iteration 273000, loss = 0.923067
I0527 10:30:20.781260 22103 solver.cpp:253]     Train net output #0: loss = 0.923067 (* 1 = 0.923067 loss)
I0527 10:30:20.781273 22103 sgd_solver.cpp:106] Iteration 273000, lr = 0.002
I0527 10:30:30.663388 22103 solver.cpp:237] Iteration 273375, loss = 1.0971
I0527 10:30:30.663421 22103 solver.cpp:253]     Train net output #0: loss = 1.0971 (* 1 = 1.0971 loss)
I0527 10:30:30.663439 22103 sgd_solver.cpp:106] Iteration 273375, lr = 0.002
I0527 10:30:40.512017 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_273750.caffemodel
I0527 10:30:40.568816 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_273750.solverstate
I0527 10:31:01.521489 22103 solver.cpp:237] Iteration 273750, loss = 0.979342
I0527 10:31:01.521683 22103 solver.cpp:253]     Train net output #0: loss = 0.979342 (* 1 = 0.979342 loss)
I0527 10:31:01.521700 22103 sgd_solver.cpp:106] Iteration 273750, lr = 0.002
I0527 10:31:11.401685 22103 solver.cpp:237] Iteration 274125, loss = 1.1599
I0527 10:31:11.401720 22103 solver.cpp:253]     Train net output #0: loss = 1.1599 (* 1 = 1.1599 loss)
I0527 10:31:11.401733 22103 sgd_solver.cpp:106] Iteration 274125, lr = 0.002
I0527 10:31:21.283416 22103 solver.cpp:237] Iteration 274500, loss = 1.27335
I0527 10:31:21.283452 22103 solver.cpp:253]     Train net output #0: loss = 1.27335 (* 1 = 1.27335 loss)
I0527 10:31:21.283468 22103 sgd_solver.cpp:106] Iteration 274500, lr = 0.002
I0527 10:31:31.138284 22103 solver.cpp:237] Iteration 274875, loss = 0.871937
I0527 10:31:31.138329 22103 solver.cpp:253]     Train net output #0: loss = 0.871937 (* 1 = 0.871937 loss)
I0527 10:31:31.138347 22103 sgd_solver.cpp:106] Iteration 274875, lr = 0.002
I0527 10:31:40.980106 22103 solver.cpp:237] Iteration 275250, loss = 1.03961
I0527 10:31:40.980278 22103 solver.cpp:253]     Train net output #0: loss = 1.03961 (* 1 = 1.03961 loss)
I0527 10:31:40.980293 22103 sgd_solver.cpp:106] Iteration 275250, lr = 0.002
I0527 10:31:50.822371 22103 solver.cpp:237] Iteration 275625, loss = 0.997111
I0527 10:31:50.822417 22103 solver.cpp:253]     Train net output #0: loss = 0.997111 (* 1 = 0.997111 loss)
I0527 10:31:50.822435 22103 sgd_solver.cpp:106] Iteration 275625, lr = 0.002
I0527 10:32:00.670874 22103 solver.cpp:237] Iteration 276000, loss = 1.00279
I0527 10:32:00.670909 22103 solver.cpp:253]     Train net output #0: loss = 1.00279 (* 1 = 1.00279 loss)
I0527 10:32:00.670924 22103 sgd_solver.cpp:106] Iteration 276000, lr = 0.002
I0527 10:32:31.414834 22103 solver.cpp:237] Iteration 276375, loss = 1.25609
I0527 10:32:31.415029 22103 solver.cpp:253]     Train net output #0: loss = 1.25609 (* 1 = 1.25609 loss)
I0527 10:32:31.415043 22103 sgd_solver.cpp:106] Iteration 276375, lr = 0.002
I0527 10:32:41.266625 22103 solver.cpp:237] Iteration 276750, loss = 1.11571
I0527 10:32:41.266665 22103 solver.cpp:253]     Train net output #0: loss = 1.11571 (* 1 = 1.11571 loss)
I0527 10:32:41.266685 22103 sgd_solver.cpp:106] Iteration 276750, lr = 0.002
I0527 10:32:51.113032 22103 solver.cpp:237] Iteration 277125, loss = 1.15891
I0527 10:32:51.113067 22103 solver.cpp:253]     Train net output #0: loss = 1.15891 (* 1 = 1.15891 loss)
I0527 10:32:51.113085 22103 sgd_solver.cpp:106] Iteration 277125, lr = 0.002
I0527 10:33:00.933442 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_277500.caffemodel
I0527 10:33:00.992753 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_277500.solverstate
I0527 10:33:01.019740 22103 solver.cpp:341] Iteration 277500, Testing net (#0)
I0527 10:34:10.494762 22103 solver.cpp:409]     Test net output #0: accuracy = 0.901718
I0527 10:34:10.494957 22103 solver.cpp:409]     Test net output #1: loss = 0.312199 (* 1 = 0.312199 loss)
I0527 10:34:10.503029 22103 solver.cpp:237] Iteration 277500, loss = 1.26118
I0527 10:34:10.503057 22103 solver.cpp:253]     Train net output #0: loss = 1.26118 (* 1 = 1.26118 loss)
I0527 10:34:10.503072 22103 sgd_solver.cpp:106] Iteration 277500, lr = 0.002
I0527 10:34:20.287315 22103 solver.cpp:237] Iteration 277875, loss = 0.971545
I0527 10:34:20.287363 22103 solver.cpp:253]     Train net output #0: loss = 0.971545 (* 1 = 0.971545 loss)
I0527 10:34:20.287376 22103 sgd_solver.cpp:106] Iteration 277875, lr = 0.002
I0527 10:34:30.081387 22103 solver.cpp:237] Iteration 278250, loss = 1.66371
I0527 10:34:30.081423 22103 solver.cpp:253]     Train net output #0: loss = 1.66371 (* 1 = 1.66371 loss)
I0527 10:34:30.081439 22103 sgd_solver.cpp:106] Iteration 278250, lr = 0.002
I0527 10:34:39.867828 22103 solver.cpp:237] Iteration 278625, loss = 1.27554
I0527 10:34:39.867863 22103 solver.cpp:253]     Train net output #0: loss = 1.27554 (* 1 = 1.27554 loss)
I0527 10:34:39.867882 22103 sgd_solver.cpp:106] Iteration 278625, lr = 0.002
I0527 10:35:10.576205 22103 solver.cpp:237] Iteration 279000, loss = 1.16613
I0527 10:35:10.576390 22103 solver.cpp:253]     Train net output #0: loss = 1.16613 (* 1 = 1.16613 loss)
I0527 10:35:10.576405 22103 sgd_solver.cpp:106] Iteration 279000, lr = 0.002
I0527 10:35:20.357033 22103 solver.cpp:237] Iteration 279375, loss = 1.28612
I0527 10:35:20.357066 22103 solver.cpp:253]     Train net output #0: loss = 1.28612 (* 1 = 1.28612 loss)
I0527 10:35:20.357080 22103 sgd_solver.cpp:106] Iteration 279375, lr = 0.002
I0527 10:35:30.146574 22103 solver.cpp:237] Iteration 279750, loss = 1.08853
I0527 10:35:30.146610 22103 solver.cpp:253]     Train net output #0: loss = 1.08853 (* 1 = 1.08853 loss)
I0527 10:35:30.146626 22103 sgd_solver.cpp:106] Iteration 279750, lr = 0.002
I0527 10:35:39.933215 22103 solver.cpp:237] Iteration 280125, loss = 1.18522
I0527 10:35:39.933262 22103 solver.cpp:253]     Train net output #0: loss = 1.18522 (* 1 = 1.18522 loss)
I0527 10:35:39.933276 22103 sgd_solver.cpp:106] Iteration 280125, lr = 0.002
I0527 10:35:49.723538 22103 solver.cpp:237] Iteration 280500, loss = 1.01278
I0527 10:35:49.723716 22103 solver.cpp:253]     Train net output #0: loss = 1.01278 (* 1 = 1.01278 loss)
I0527 10:35:49.723731 22103 sgd_solver.cpp:106] Iteration 280500, lr = 0.002
I0527 10:35:59.501507 22103 solver.cpp:237] Iteration 280875, loss = 1.20276
I0527 10:35:59.501548 22103 solver.cpp:253]     Train net output #0: loss = 1.20276 (* 1 = 1.20276 loss)
I0527 10:35:59.501565 22103 sgd_solver.cpp:106] Iteration 280875, lr = 0.002
I0527 10:36:09.274580 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_281250.caffemodel
I0527 10:36:09.333987 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_281250.solverstate
I0527 10:36:30.243837 22103 solver.cpp:237] Iteration 281250, loss = 0.919812
I0527 10:36:30.244038 22103 solver.cpp:253]     Train net output #0: loss = 0.919812 (* 1 = 0.919812 loss)
I0527 10:36:30.244055 22103 sgd_solver.cpp:106] Iteration 281250, lr = 0.002
I0527 10:36:40.032876 22103 solver.cpp:237] Iteration 281625, loss = 1.06474
I0527 10:36:40.032912 22103 solver.cpp:253]     Train net output #0: loss = 1.06474 (* 1 = 1.06474 loss)
I0527 10:36:40.032925 22103 sgd_solver.cpp:106] Iteration 281625, lr = 0.002
I0527 10:36:49.814332 22103 solver.cpp:237] Iteration 282000, loss = 1.48224
I0527 10:36:49.814374 22103 solver.cpp:253]     Train net output #0: loss = 1.48224 (* 1 = 1.48224 loss)
I0527 10:36:49.814389 22103 sgd_solver.cpp:106] Iteration 282000, lr = 0.002
I0527 10:36:59.610611 22103 solver.cpp:237] Iteration 282375, loss = 1.2739
I0527 10:36:59.610646 22103 solver.cpp:253]     Train net output #0: loss = 1.2739 (* 1 = 1.2739 loss)
I0527 10:36:59.610663 22103 sgd_solver.cpp:106] Iteration 282375, lr = 0.002
I0527 10:37:09.392459 22103 solver.cpp:237] Iteration 282750, loss = 0.972422
I0527 10:37:09.392626 22103 solver.cpp:253]     Train net output #0: loss = 0.972422 (* 1 = 0.972422 loss)
I0527 10:37:09.392640 22103 sgd_solver.cpp:106] Iteration 282750, lr = 0.002
I0527 10:37:19.164342 22103 solver.cpp:237] Iteration 283125, loss = 1.32813
I0527 10:37:19.164381 22103 solver.cpp:253]     Train net output #0: loss = 1.32813 (* 1 = 1.32813 loss)
I0527 10:37:19.164402 22103 sgd_solver.cpp:106] Iteration 283125, lr = 0.002
I0527 10:37:28.953351 22103 solver.cpp:237] Iteration 283500, loss = 1.36153
I0527 10:37:28.953387 22103 solver.cpp:253]     Train net output #0: loss = 1.36153 (* 1 = 1.36153 loss)
I0527 10:37:28.953403 22103 sgd_solver.cpp:106] Iteration 283500, lr = 0.002
I0527 10:37:59.599649 22103 solver.cpp:237] Iteration 283875, loss = 1.12505
I0527 10:37:59.599833 22103 solver.cpp:253]     Train net output #0: loss = 1.12505 (* 1 = 1.12505 loss)
I0527 10:37:59.599848 22103 sgd_solver.cpp:106] Iteration 283875, lr = 0.002
I0527 10:38:09.377917 22103 solver.cpp:237] Iteration 284250, loss = 1.00603
I0527 10:38:09.377959 22103 solver.cpp:253]     Train net output #0: loss = 1.00603 (* 1 = 1.00603 loss)
I0527 10:38:09.377979 22103 sgd_solver.cpp:106] Iteration 284250, lr = 0.002
I0527 10:38:19.152957 22103 solver.cpp:237] Iteration 284625, loss = 1.54025
I0527 10:38:19.152993 22103 solver.cpp:253]     Train net output #0: loss = 1.54025 (* 1 = 1.54025 loss)
I0527 10:38:19.153009 22103 sgd_solver.cpp:106] Iteration 284625, lr = 0.002
I0527 10:38:28.915766 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_285000.caffemodel
I0527 10:38:28.972980 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_285000.solverstate
I0527 10:38:28.999080 22103 solver.cpp:341] Iteration 285000, Testing net (#0)
I0527 10:39:17.243474 22103 solver.cpp:409]     Test net output #0: accuracy = 0.903346
I0527 10:39:17.243667 22103 solver.cpp:409]     Test net output #1: loss = 0.290375 (* 1 = 0.290375 loss)
I0527 10:39:17.251724 22103 solver.cpp:237] Iteration 285000, loss = 0.894796
I0527 10:39:17.251752 22103 solver.cpp:253]     Train net output #0: loss = 0.894796 (* 1 = 0.894796 loss)
I0527 10:39:17.251766 22103 sgd_solver.cpp:106] Iteration 285000, lr = 0.002
I0527 10:39:27.158426 22103 solver.cpp:237] Iteration 285375, loss = 1.35919
I0527 10:39:27.158473 22103 solver.cpp:253]     Train net output #0: loss = 1.35919 (* 1 = 1.35919 loss)
I0527 10:39:27.158490 22103 sgd_solver.cpp:106] Iteration 285375, lr = 0.002
I0527 10:39:37.062747 22103 solver.cpp:237] Iteration 285750, loss = 1.25111
I0527 10:39:37.062783 22103 solver.cpp:253]     Train net output #0: loss = 1.25111 (* 1 = 1.25111 loss)
I0527 10:39:37.062800 22103 sgd_solver.cpp:106] Iteration 285750, lr = 0.002
I0527 10:39:46.974798 22103 solver.cpp:237] Iteration 286125, loss = 0.815452
I0527 10:39:46.974843 22103 solver.cpp:253]     Train net output #0: loss = 0.815452 (* 1 = 0.815452 loss)
I0527 10:39:46.974864 22103 sgd_solver.cpp:106] Iteration 286125, lr = 0.002
I0527 10:40:17.772572 22103 solver.cpp:237] Iteration 286500, loss = 0.77099
I0527 10:40:17.772760 22103 solver.cpp:253]     Train net output #0: loss = 0.77099 (* 1 = 0.77099 loss)
I0527 10:40:17.772775 22103 sgd_solver.cpp:106] Iteration 286500, lr = 0.002
I0527 10:40:27.684552 22103 solver.cpp:237] Iteration 286875, loss = 1.11317
I0527 10:40:27.684587 22103 solver.cpp:253]     Train net output #0: loss = 1.11317 (* 1 = 1.11317 loss)
I0527 10:40:27.684605 22103 sgd_solver.cpp:106] Iteration 286875, lr = 0.002
I0527 10:40:37.554464 22103 solver.cpp:237] Iteration 287250, loss = 1.2055
I0527 10:40:37.554509 22103 solver.cpp:253]     Train net output #0: loss = 1.2055 (* 1 = 1.2055 loss)
I0527 10:40:37.554527 22103 sgd_solver.cpp:106] Iteration 287250, lr = 0.002
I0527 10:40:47.272166 22103 solver.cpp:237] Iteration 287625, loss = 1.14561
I0527 10:40:47.272202 22103 solver.cpp:253]     Train net output #0: loss = 1.14561 (* 1 = 1.14561 loss)
I0527 10:40:47.272220 22103 sgd_solver.cpp:106] Iteration 287625, lr = 0.002
I0527 10:40:57.000360 22103 solver.cpp:237] Iteration 288000, loss = 1.02851
I0527 10:40:57.000527 22103 solver.cpp:253]     Train net output #0: loss = 1.02851 (* 1 = 1.02851 loss)
I0527 10:40:57.000541 22103 sgd_solver.cpp:106] Iteration 288000, lr = 0.002
I0527 10:41:06.723142 22103 solver.cpp:237] Iteration 288375, loss = 1.34831
I0527 10:41:06.723182 22103 solver.cpp:253]     Train net output #0: loss = 1.34831 (* 1 = 1.34831 loss)
I0527 10:41:06.723201 22103 sgd_solver.cpp:106] Iteration 288375, lr = 0.002
I0527 10:41:16.415108 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_288750.caffemodel
I0527 10:41:16.472110 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_288750.solverstate
I0527 10:41:37.346632 22103 solver.cpp:237] Iteration 288750, loss = 1.10756
I0527 10:41:37.346827 22103 solver.cpp:253]     Train net output #0: loss = 1.10756 (* 1 = 1.10756 loss)
I0527 10:41:37.346843 22103 sgd_solver.cpp:106] Iteration 288750, lr = 0.002
I0527 10:41:47.062042 22103 solver.cpp:237] Iteration 289125, loss = 1.32113
I0527 10:41:47.062077 22103 solver.cpp:253]     Train net output #0: loss = 1.32113 (* 1 = 1.32113 loss)
I0527 10:41:47.062091 22103 sgd_solver.cpp:106] Iteration 289125, lr = 0.002
I0527 10:41:56.782680 22103 solver.cpp:237] Iteration 289500, loss = 0.996412
I0527 10:41:56.782722 22103 solver.cpp:253]     Train net output #0: loss = 0.996412 (* 1 = 0.996412 loss)
I0527 10:41:56.782743 22103 sgd_solver.cpp:106] Iteration 289500, lr = 0.002
I0527 10:42:06.504577 22103 solver.cpp:237] Iteration 289875, loss = 1.09368
I0527 10:42:06.504613 22103 solver.cpp:253]     Train net output #0: loss = 1.09368 (* 1 = 1.09368 loss)
I0527 10:42:06.504626 22103 sgd_solver.cpp:106] Iteration 289875, lr = 0.002
I0527 10:42:16.228504 22103 solver.cpp:237] Iteration 290250, loss = 0.94126
I0527 10:42:16.228703 22103 solver.cpp:253]     Train net output #0: loss = 0.94126 (* 1 = 0.94126 loss)
I0527 10:42:16.228718 22103 sgd_solver.cpp:106] Iteration 290250, lr = 0.002
I0527 10:42:25.947757 22103 solver.cpp:237] Iteration 290625, loss = 1.2135
I0527 10:42:25.947790 22103 solver.cpp:253]     Train net output #0: loss = 1.2135 (* 1 = 1.2135 loss)
I0527 10:42:25.947809 22103 sgd_solver.cpp:106] Iteration 290625, lr = 0.002
I0527 10:42:35.682119 22103 solver.cpp:237] Iteration 291000, loss = 0.819979
I0527 10:42:35.682155 22103 solver.cpp:253]     Train net output #0: loss = 0.819979 (* 1 = 0.819979 loss)
I0527 10:42:35.682169 22103 sgd_solver.cpp:106] Iteration 291000, lr = 0.002
I0527 10:43:06.294214 22103 solver.cpp:237] Iteration 291375, loss = 0.987646
I0527 10:43:06.294404 22103 solver.cpp:253]     Train net output #0: loss = 0.987646 (* 1 = 0.987646 loss)
I0527 10:43:06.294419 22103 sgd_solver.cpp:106] Iteration 291375, lr = 0.002
I0527 10:43:16.031321 22103 solver.cpp:237] Iteration 291750, loss = 1.05591
I0527 10:43:16.031355 22103 solver.cpp:253]     Train net output #0: loss = 1.05591 (* 1 = 1.05591 loss)
I0527 10:43:16.031369 22103 sgd_solver.cpp:106] Iteration 291750, lr = 0.002
I0527 10:43:25.767547 22103 solver.cpp:237] Iteration 292125, loss = 1.36364
I0527 10:43:25.767582 22103 solver.cpp:253]     Train net output #0: loss = 1.36364 (* 1 = 1.36364 loss)
I0527 10:43:25.767599 22103 sgd_solver.cpp:106] Iteration 292125, lr = 0.002
I0527 10:43:35.470217 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_292500.caffemodel
I0527 10:43:35.526856 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_292500.solverstate
I0527 10:43:35.552253 22103 solver.cpp:341] Iteration 292500, Testing net (#0)
I0527 10:44:45.053409 22103 solver.cpp:409]     Test net output #0: accuracy = 0.90308
I0527 10:44:45.053596 22103 solver.cpp:409]     Test net output #1: loss = 0.306551 (* 1 = 0.306551 loss)
I0527 10:44:45.061662 22103 solver.cpp:237] Iteration 292500, loss = 1.06793
I0527 10:44:45.061691 22103 solver.cpp:253]     Train net output #0: loss = 1.06793 (* 1 = 1.06793 loss)
I0527 10:44:45.061704 22103 sgd_solver.cpp:106] Iteration 292500, lr = 0.002
I0527 10:44:54.903311 22103 solver.cpp:237] Iteration 292875, loss = 1.10097
I0527 10:44:54.903344 22103 solver.cpp:253]     Train net output #0: loss = 1.10097 (* 1 = 1.10097 loss)
I0527 10:44:54.903362 22103 sgd_solver.cpp:106] Iteration 292875, lr = 0.002
I0527 10:45:04.742076 22103 solver.cpp:237] Iteration 293250, loss = 0.881078
I0527 10:45:04.742112 22103 solver.cpp:253]     Train net output #0: loss = 0.881078 (* 1 = 0.881078 loss)
I0527 10:45:04.742128 22103 sgd_solver.cpp:106] Iteration 293250, lr = 0.002
I0527 10:45:14.582015 22103 solver.cpp:237] Iteration 293625, loss = 1.11306
I0527 10:45:14.582056 22103 solver.cpp:253]     Train net output #0: loss = 1.11306 (* 1 = 1.11306 loss)
I0527 10:45:14.582072 22103 sgd_solver.cpp:106] Iteration 293625, lr = 0.002
I0527 10:45:45.317078 22103 solver.cpp:237] Iteration 294000, loss = 1.01462
I0527 10:45:45.317265 22103 solver.cpp:253]     Train net output #0: loss = 1.01462 (* 1 = 1.01462 loss)
I0527 10:45:45.317281 22103 sgd_solver.cpp:106] Iteration 294000, lr = 0.002
I0527 10:45:55.157636 22103 solver.cpp:237] Iteration 294375, loss = 1.31308
I0527 10:45:55.157671 22103 solver.cpp:253]     Train net output #0: loss = 1.31308 (* 1 = 1.31308 loss)
I0527 10:45:55.157688 22103 sgd_solver.cpp:106] Iteration 294375, lr = 0.002
I0527 10:46:05.000046 22103 solver.cpp:237] Iteration 294750, loss = 1.09197
I0527 10:46:05.000092 22103 solver.cpp:253]     Train net output #0: loss = 1.09197 (* 1 = 1.09197 loss)
I0527 10:46:05.000107 22103 sgd_solver.cpp:106] Iteration 294750, lr = 0.002
I0527 10:46:14.840819 22103 solver.cpp:237] Iteration 295125, loss = 0.87008
I0527 10:46:14.840854 22103 solver.cpp:253]     Train net output #0: loss = 0.87008 (* 1 = 0.87008 loss)
I0527 10:46:14.840873 22103 sgd_solver.cpp:106] Iteration 295125, lr = 0.002
I0527 10:46:24.687121 22103 solver.cpp:237] Iteration 295500, loss = 1.12286
I0527 10:46:24.687309 22103 solver.cpp:253]     Train net output #0: loss = 1.12286 (* 1 = 1.12286 loss)
I0527 10:46:24.687325 22103 sgd_solver.cpp:106] Iteration 295500, lr = 0.002
I0527 10:46:34.530169 22103 solver.cpp:237] Iteration 295875, loss = 0.863747
I0527 10:46:34.530200 22103 solver.cpp:253]     Train net output #0: loss = 0.863747 (* 1 = 0.863747 loss)
I0527 10:46:34.530220 22103 sgd_solver.cpp:106] Iteration 295875, lr = 0.002
I0527 10:46:44.346043 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_296250.caffemodel
I0527 10:46:44.404541 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_296250.solverstate
I0527 10:47:05.276597 22103 solver.cpp:237] Iteration 296250, loss = 1.08381
I0527 10:47:05.276798 22103 solver.cpp:253]     Train net output #0: loss = 1.08381 (* 1 = 1.08381 loss)
I0527 10:47:05.276815 22103 sgd_solver.cpp:106] Iteration 296250, lr = 0.002
I0527 10:47:15.120250 22103 solver.cpp:237] Iteration 296625, loss = 0.939842
I0527 10:47:15.120291 22103 solver.cpp:253]     Train net output #0: loss = 0.939842 (* 1 = 0.939842 loss)
I0527 10:47:15.120309 22103 sgd_solver.cpp:106] Iteration 296625, lr = 0.002
I0527 10:47:24.956377 22103 solver.cpp:237] Iteration 297000, loss = 1.3229
I0527 10:47:24.956411 22103 solver.cpp:253]     Train net output #0: loss = 1.3229 (* 1 = 1.3229 loss)
I0527 10:47:24.956424 22103 sgd_solver.cpp:106] Iteration 297000, lr = 0.002
I0527 10:47:34.795343 22103 solver.cpp:237] Iteration 297375, loss = 1.29434
I0527 10:47:34.795379 22103 solver.cpp:253]     Train net output #0: loss = 1.29434 (* 1 = 1.29434 loss)
I0527 10:47:34.795392 22103 sgd_solver.cpp:106] Iteration 297375, lr = 0.002
I0527 10:47:44.636260 22103 solver.cpp:237] Iteration 297750, loss = 1.25878
I0527 10:47:44.636440 22103 solver.cpp:253]     Train net output #0: loss = 1.25878 (* 1 = 1.25878 loss)
I0527 10:47:44.636454 22103 sgd_solver.cpp:106] Iteration 297750, lr = 0.002
I0527 10:47:54.481786 22103 solver.cpp:237] Iteration 298125, loss = 1.22247
I0527 10:47:54.481820 22103 solver.cpp:253]     Train net output #0: loss = 1.22247 (* 1 = 1.22247 loss)
I0527 10:47:54.481837 22103 sgd_solver.cpp:106] Iteration 298125, lr = 0.002
I0527 10:48:04.326318 22103 solver.cpp:237] Iteration 298500, loss = 1.18566
I0527 10:48:04.326362 22103 solver.cpp:253]     Train net output #0: loss = 1.18566 (* 1 = 1.18566 loss)
I0527 10:48:04.326376 22103 sgd_solver.cpp:106] Iteration 298500, lr = 0.002
I0527 10:48:35.061233 22103 solver.cpp:237] Iteration 298875, loss = 1.29656
I0527 10:48:35.061422 22103 solver.cpp:253]     Train net output #0: loss = 1.29656 (* 1 = 1.29656 loss)
I0527 10:48:35.061439 22103 sgd_solver.cpp:106] Iteration 298875, lr = 0.002
I0527 10:48:44.896575 22103 solver.cpp:237] Iteration 299250, loss = 0.973075
I0527 10:48:44.896610 22103 solver.cpp:253]     Train net output #0: loss = 0.973075 (* 1 = 0.973075 loss)
I0527 10:48:44.896628 22103 sgd_solver.cpp:106] Iteration 299250, lr = 0.002
I0527 10:48:54.738950 22103 solver.cpp:237] Iteration 299625, loss = 0.788433
I0527 10:48:54.738998 22103 solver.cpp:253]     Train net output #0: loss = 0.788433 (* 1 = 0.788433 loss)
I0527 10:48:54.739012 22103 sgd_solver.cpp:106] Iteration 299625, lr = 0.002
I0527 10:49:04.548732 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_300000.caffemodel
I0527 10:49:04.612514 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_300000.solverstate
I0527 10:49:04.640084 22103 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 10:49:53.265918 22103 solver.cpp:409]     Test net output #0: accuracy = 0.90266
I0527 10:49:53.266120 22103 solver.cpp:409]     Test net output #1: loss = 0.301193 (* 1 = 0.301193 loss)
I0527 10:49:53.274224 22103 solver.cpp:237] Iteration 300000, loss = 1.42946
I0527 10:49:53.274252 22103 solver.cpp:253]     Train net output #0: loss = 1.42946 (* 1 = 1.42946 loss)
I0527 10:49:53.274267 22103 sgd_solver.cpp:106] Iteration 300000, lr = 0.002
I0527 10:50:03.048923 22103 solver.cpp:237] Iteration 300375, loss = 0.968542
I0527 10:50:03.048959 22103 solver.cpp:253]     Train net output #0: loss = 0.968542 (* 1 = 0.968542 loss)
I0527 10:50:03.048976 22103 sgd_solver.cpp:106] Iteration 300375, lr = 0.002
I0527 10:50:12.840406 22103 solver.cpp:237] Iteration 300750, loss = 1.49534
I0527 10:50:12.840446 22103 solver.cpp:253]     Train net output #0: loss = 1.49534 (* 1 = 1.49534 loss)
I0527 10:50:12.840467 22103 sgd_solver.cpp:106] Iteration 300750, lr = 0.002
I0527 10:50:22.645165 22103 solver.cpp:237] Iteration 301125, loss = 1.22874
I0527 10:50:22.645200 22103 solver.cpp:253]     Train net output #0: loss = 1.22874 (* 1 = 1.22874 loss)
I0527 10:50:22.645213 22103 sgd_solver.cpp:106] Iteration 301125, lr = 0.002
I0527 10:50:53.364950 22103 solver.cpp:237] Iteration 301500, loss = 0.988641
I0527 10:50:53.365145 22103 solver.cpp:253]     Train net output #0: loss = 0.988641 (* 1 = 0.988641 loss)
I0527 10:50:53.365160 22103 sgd_solver.cpp:106] Iteration 301500, lr = 0.002
I0527 10:51:03.168081 22103 solver.cpp:237] Iteration 301875, loss = 1.19108
I0527 10:51:03.168123 22103 solver.cpp:253]     Train net output #0: loss = 1.19108 (* 1 = 1.19108 loss)
I0527 10:51:03.168143 22103 sgd_solver.cpp:106] Iteration 301875, lr = 0.002
I0527 10:51:12.966351 22103 solver.cpp:237] Iteration 302250, loss = 1.3158
I0527 10:51:12.966387 22103 solver.cpp:253]     Train net output #0: loss = 1.3158 (* 1 = 1.3158 loss)
I0527 10:51:12.966404 22103 sgd_solver.cpp:106] Iteration 302250, lr = 0.002
I0527 10:51:22.768977 22103 solver.cpp:237] Iteration 302625, loss = 0.992319
I0527 10:51:22.769013 22103 solver.cpp:253]     Train net output #0: loss = 0.992319 (* 1 = 0.992319 loss)
I0527 10:51:22.769027 22103 sgd_solver.cpp:106] Iteration 302625, lr = 0.002
I0527 10:51:32.571480 22103 solver.cpp:237] Iteration 303000, loss = 1.04185
I0527 10:51:32.571672 22103 solver.cpp:253]     Train net output #0: loss = 1.04185 (* 1 = 1.04185 loss)
I0527 10:51:32.571686 22103 sgd_solver.cpp:106] Iteration 303000, lr = 0.002
I0527 10:51:42.376260 22103 solver.cpp:237] Iteration 303375, loss = 0.955082
I0527 10:51:42.376296 22103 solver.cpp:253]     Train net output #0: loss = 0.955082 (* 1 = 0.955082 loss)
I0527 10:51:42.376312 22103 sgd_solver.cpp:106] Iteration 303375, lr = 0.002
I0527 10:51:52.148526 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_303750.caffemodel
I0527 10:51:52.210217 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_303750.solverstate
I0527 10:52:13.111590 22103 solver.cpp:237] Iteration 303750, loss = 0.850195
I0527 10:52:13.111794 22103 solver.cpp:253]     Train net output #0: loss = 0.850195 (* 1 = 0.850195 loss)
I0527 10:52:13.111810 22103 sgd_solver.cpp:106] Iteration 303750, lr = 0.002
I0527 10:52:22.911617 22103 solver.cpp:237] Iteration 304125, loss = 0.971389
I0527 10:52:22.911659 22103 solver.cpp:253]     Train net output #0: loss = 0.971389 (* 1 = 0.971389 loss)
I0527 10:52:22.911675 22103 sgd_solver.cpp:106] Iteration 304125, lr = 0.002
I0527 10:52:32.711930 22103 solver.cpp:237] Iteration 304500, loss = 1.40409
I0527 10:52:32.711964 22103 solver.cpp:253]     Train net output #0: loss = 1.40409 (* 1 = 1.40409 loss)
I0527 10:52:32.711982 22103 sgd_solver.cpp:106] Iteration 304500, lr = 0.002
I0527 10:52:42.517910 22103 solver.cpp:237] Iteration 304875, loss = 0.936498
I0527 10:52:42.517952 22103 solver.cpp:253]     Train net output #0: loss = 0.936498 (* 1 = 0.936498 loss)
I0527 10:52:42.517972 22103 sgd_solver.cpp:106] Iteration 304875, lr = 0.002
I0527 10:52:52.326671 22103 solver.cpp:237] Iteration 305250, loss = 1.13267
I0527 10:52:52.326864 22103 solver.cpp:253]     Train net output #0: loss = 1.13267 (* 1 = 1.13267 loss)
I0527 10:52:52.326877 22103 sgd_solver.cpp:106] Iteration 305250, lr = 0.002
I0527 10:53:02.122258 22103 solver.cpp:237] Iteration 305625, loss = 1.25197
I0527 10:53:02.122293 22103 solver.cpp:253]     Train net output #0: loss = 1.25197 (* 1 = 1.25197 loss)
I0527 10:53:02.122308 22103 sgd_solver.cpp:106] Iteration 305625, lr = 0.002
I0527 10:53:11.927543 22103 solver.cpp:237] Iteration 306000, loss = 1.05724
I0527 10:53:11.927582 22103 solver.cpp:253]     Train net output #0: loss = 1.05724 (* 1 = 1.05724 loss)
I0527 10:53:11.927600 22103 sgd_solver.cpp:106] Iteration 306000, lr = 0.002
I0527 10:53:42.584638 22103 solver.cpp:237] Iteration 306375, loss = 1.24259
I0527 10:53:42.584830 22103 solver.cpp:253]     Train net output #0: loss = 1.24259 (* 1 = 1.24259 loss)
I0527 10:53:42.584846 22103 sgd_solver.cpp:106] Iteration 306375, lr = 0.002
I0527 10:53:52.387657 22103 solver.cpp:237] Iteration 306750, loss = 0.986143
I0527 10:53:52.387692 22103 solver.cpp:253]     Train net output #0: loss = 0.986143 (* 1 = 0.986143 loss)
I0527 10:53:52.387706 22103 sgd_solver.cpp:106] Iteration 306750, lr = 0.002
I0527 10:54:02.190376 22103 solver.cpp:237] Iteration 307125, loss = 0.926003
I0527 10:54:02.190418 22103 solver.cpp:253]     Train net output #0: loss = 0.926003 (* 1 = 0.926003 loss)
I0527 10:54:02.190436 22103 sgd_solver.cpp:106] Iteration 307125, lr = 0.002
I0527 10:54:11.964638 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_307500.caffemodel
I0527 10:54:12.021124 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_307500.solverstate
I0527 10:54:12.046768 22103 solver.cpp:341] Iteration 307500, Testing net (#0)
I0527 10:55:21.543612 22103 solver.cpp:409]     Test net output #0: accuracy = 0.902853
I0527 10:55:21.543804 22103 solver.cpp:409]     Test net output #1: loss = 0.2934 (* 1 = 0.2934 loss)
I0527 10:55:21.551832 22103 solver.cpp:237] Iteration 307500, loss = 1.02413
I0527 10:55:21.551862 22103 solver.cpp:253]     Train net output #0: loss = 1.02413 (* 1 = 1.02413 loss)
I0527 10:55:21.551874 22103 sgd_solver.cpp:106] Iteration 307500, lr = 0.002
I0527 10:55:31.390141 22103 solver.cpp:237] Iteration 307875, loss = 1.36956
I0527 10:55:31.390174 22103 solver.cpp:253]     Train net output #0: loss = 1.36956 (* 1 = 1.36956 loss)
I0527 10:55:31.390189 22103 sgd_solver.cpp:106] Iteration 307875, lr = 0.002
I0527 10:55:41.221213 22103 solver.cpp:237] Iteration 308250, loss = 1.05106
I0527 10:55:41.221249 22103 solver.cpp:253]     Train net output #0: loss = 1.05106 (* 1 = 1.05106 loss)
I0527 10:55:41.221267 22103 sgd_solver.cpp:106] Iteration 308250, lr = 0.002
I0527 10:55:51.063210 22103 solver.cpp:237] Iteration 308625, loss = 1.04692
I0527 10:55:51.063244 22103 solver.cpp:253]     Train net output #0: loss = 1.04692 (* 1 = 1.04692 loss)
I0527 10:55:51.063261 22103 sgd_solver.cpp:106] Iteration 308625, lr = 0.002
I0527 10:56:21.824308 22103 solver.cpp:237] Iteration 309000, loss = 0.918435
I0527 10:56:21.824513 22103 solver.cpp:253]     Train net output #0: loss = 0.918435 (* 1 = 0.918435 loss)
I0527 10:56:21.824528 22103 sgd_solver.cpp:106] Iteration 309000, lr = 0.002
I0527 10:56:31.652109 22103 solver.cpp:237] Iteration 309375, loss = 1.29306
I0527 10:56:31.652153 22103 solver.cpp:253]     Train net output #0: loss = 1.29306 (* 1 = 1.29306 loss)
I0527 10:56:31.652171 22103 sgd_solver.cpp:106] Iteration 309375, lr = 0.002
I0527 10:56:41.493480 22103 solver.cpp:237] Iteration 309750, loss = 1.12758
I0527 10:56:41.493516 22103 solver.cpp:253]     Train net output #0: loss = 1.12758 (* 1 = 1.12758 loss)
I0527 10:56:41.493532 22103 sgd_solver.cpp:106] Iteration 309750, lr = 0.002
I0527 10:56:51.333739 22103 solver.cpp:237] Iteration 310125, loss = 0.926713
I0527 10:56:51.333781 22103 solver.cpp:253]     Train net output #0: loss = 0.926713 (* 1 = 0.926713 loss)
I0527 10:56:51.333797 22103 sgd_solver.cpp:106] Iteration 310125, lr = 0.002
I0527 10:57:01.178908 22103 solver.cpp:237] Iteration 310500, loss = 1.34318
I0527 10:57:01.179085 22103 solver.cpp:253]     Train net output #0: loss = 1.34318 (* 1 = 1.34318 loss)
I0527 10:57:01.179098 22103 sgd_solver.cpp:106] Iteration 310500, lr = 0.002
I0527 10:57:11.013986 22103 solver.cpp:237] Iteration 310875, loss = 0.982468
I0527 10:57:11.014026 22103 solver.cpp:253]     Train net output #0: loss = 0.982468 (* 1 = 0.982468 loss)
I0527 10:57:11.014044 22103 sgd_solver.cpp:106] Iteration 310875, lr = 0.002
I0527 10:57:20.823998 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_311250.caffemodel
I0527 10:57:20.880345 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_311250.solverstate
I0527 10:57:41.807385 22103 solver.cpp:237] Iteration 311250, loss = 1.26776
I0527 10:57:41.807586 22103 solver.cpp:253]     Train net output #0: loss = 1.26776 (* 1 = 1.26776 loss)
I0527 10:57:41.807603 22103 sgd_solver.cpp:106] Iteration 311250, lr = 0.002
I0527 10:57:51.648412 22103 solver.cpp:237] Iteration 311625, loss = 1.34877
I0527 10:57:51.648447 22103 solver.cpp:253]     Train net output #0: loss = 1.34877 (* 1 = 1.34877 loss)
I0527 10:57:51.648465 22103 sgd_solver.cpp:106] Iteration 311625, lr = 0.002
I0527 10:58:01.482359 22103 solver.cpp:237] Iteration 312000, loss = 0.920096
I0527 10:58:01.482395 22103 solver.cpp:253]     Train net output #0: loss = 0.920096 (* 1 = 0.920096 loss)
I0527 10:58:01.482411 22103 sgd_solver.cpp:106] Iteration 312000, lr = 0.002
I0527 10:58:11.322331 22103 solver.cpp:237] Iteration 312375, loss = 0.980271
I0527 10:58:11.322378 22103 solver.cpp:253]     Train net output #0: loss = 0.980271 (* 1 = 0.980271 loss)
I0527 10:58:11.322394 22103 sgd_solver.cpp:106] Iteration 312375, lr = 0.002
I0527 10:58:21.158223 22103 solver.cpp:237] Iteration 312750, loss = 1.06105
I0527 10:58:21.158396 22103 solver.cpp:253]     Train net output #0: loss = 1.06105 (* 1 = 1.06105 loss)
I0527 10:58:21.158409 22103 sgd_solver.cpp:106] Iteration 312750, lr = 0.002
I0527 10:58:30.992601 22103 solver.cpp:237] Iteration 313125, loss = 1.05371
I0527 10:58:30.992638 22103 solver.cpp:253]     Train net output #0: loss = 1.05371 (* 1 = 1.05371 loss)
I0527 10:58:30.992656 22103 sgd_solver.cpp:106] Iteration 313125, lr = 0.002
I0527 10:58:40.822998 22103 solver.cpp:237] Iteration 313500, loss = 0.848912
I0527 10:58:40.823035 22103 solver.cpp:253]     Train net output #0: loss = 0.848912 (* 1 = 0.848912 loss)
I0527 10:58:40.823050 22103 sgd_solver.cpp:106] Iteration 313500, lr = 0.002
I0527 10:59:11.600052 22103 solver.cpp:237] Iteration 313875, loss = 0.849981
I0527 10:59:11.600249 22103 solver.cpp:253]     Train net output #0: loss = 0.849981 (* 1 = 0.849981 loss)
I0527 10:59:11.600263 22103 sgd_solver.cpp:106] Iteration 313875, lr = 0.002
I0527 10:59:21.431879 22103 solver.cpp:237] Iteration 314250, loss = 1.24577
I0527 10:59:21.431918 22103 solver.cpp:253]     Train net output #0: loss = 1.24577 (* 1 = 1.24577 loss)
I0527 10:59:21.431933 22103 sgd_solver.cpp:106] Iteration 314250, lr = 0.002
I0527 10:59:31.269578 22103 solver.cpp:237] Iteration 314625, loss = 1.22278
I0527 10:59:31.269613 22103 solver.cpp:253]     Train net output #0: loss = 1.22278 (* 1 = 1.22278 loss)
I0527 10:59:31.269628 22103 sgd_solver.cpp:106] Iteration 314625, lr = 0.002
I0527 10:59:41.083709 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_315000.caffemodel
I0527 10:59:41.140600 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_315000.solverstate
I0527 10:59:41.169174 22103 solver.cpp:341] Iteration 315000, Testing net (#0)
I0527 11:00:29.397806 22103 solver.cpp:409]     Test net output #0: accuracy = 0.904034
I0527 11:00:29.398015 22103 solver.cpp:409]     Test net output #1: loss = 0.308121 (* 1 = 0.308121 loss)
I0527 11:00:29.406123 22103 solver.cpp:237] Iteration 315000, loss = 0.919757
I0527 11:00:29.406152 22103 solver.cpp:253]     Train net output #0: loss = 0.919757 (* 1 = 0.919757 loss)
I0527 11:00:29.406167 22103 sgd_solver.cpp:106] Iteration 315000, lr = 0.002
I0527 11:00:39.123023 22103 solver.cpp:237] Iteration 315375, loss = 0.960406
I0527 11:00:39.123071 22103 solver.cpp:253]     Train net output #0: loss = 0.960406 (* 1 = 0.960406 loss)
I0527 11:00:39.123090 22103 sgd_solver.cpp:106] Iteration 315375, lr = 0.002
I0527 11:00:48.821120 22103 solver.cpp:237] Iteration 315750, loss = 1.50123
I0527 11:00:48.821156 22103 solver.cpp:253]     Train net output #0: loss = 1.50123 (* 1 = 1.50123 loss)
I0527 11:00:48.821171 22103 sgd_solver.cpp:106] Iteration 315750, lr = 0.002
I0527 11:00:58.528267 22103 solver.cpp:237] Iteration 316125, loss = 1.18054
I0527 11:00:58.528302 22103 solver.cpp:253]     Train net output #0: loss = 1.18054 (* 1 = 1.18054 loss)
I0527 11:00:58.528319 22103 sgd_solver.cpp:106] Iteration 316125, lr = 0.002
I0527 11:01:29.138577 22103 solver.cpp:237] Iteration 316500, loss = 1.16475
I0527 11:01:29.138772 22103 solver.cpp:253]     Train net output #0: loss = 1.16475 (* 1 = 1.16475 loss)
I0527 11:01:29.138787 22103 sgd_solver.cpp:106] Iteration 316500, lr = 0.002
I0527 11:01:38.839867 22103 solver.cpp:237] Iteration 316875, loss = 1.2164
I0527 11:01:38.839901 22103 solver.cpp:253]     Train net output #0: loss = 1.2164 (* 1 = 1.2164 loss)
I0527 11:01:38.839920 22103 sgd_solver.cpp:106] Iteration 316875, lr = 0.002
I0527 11:01:48.545460 22103 solver.cpp:237] Iteration 317250, loss = 1.20125
I0527 11:01:48.545495 22103 solver.cpp:253]     Train net output #0: loss = 1.20125 (* 1 = 1.20125 loss)
I0527 11:01:48.545508 22103 sgd_solver.cpp:106] Iteration 317250, lr = 0.002
I0527 11:01:58.250613 22103 solver.cpp:237] Iteration 317625, loss = 1.08782
I0527 11:01:58.250648 22103 solver.cpp:253]     Train net output #0: loss = 1.08782 (* 1 = 1.08782 loss)
I0527 11:01:58.250666 22103 sgd_solver.cpp:106] Iteration 317625, lr = 0.002
I0527 11:02:07.949559 22103 solver.cpp:237] Iteration 318000, loss = 1.29958
I0527 11:02:07.949729 22103 solver.cpp:253]     Train net output #0: loss = 1.29958 (* 1 = 1.29958 loss)
I0527 11:02:07.949743 22103 sgd_solver.cpp:106] Iteration 318000, lr = 0.002
I0527 11:02:17.660517 22103 solver.cpp:237] Iteration 318375, loss = 1.1018
I0527 11:02:17.660560 22103 solver.cpp:253]     Train net output #0: loss = 1.1018 (* 1 = 1.1018 loss)
I0527 11:02:17.660575 22103 sgd_solver.cpp:106] Iteration 318375, lr = 0.002
I0527 11:02:27.333853 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_318750.caffemodel
I0527 11:02:27.391104 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_318750.solverstate
I0527 11:02:48.340682 22103 solver.cpp:237] Iteration 318750, loss = 0.889065
I0527 11:02:48.340898 22103 solver.cpp:253]     Train net output #0: loss = 0.889065 (* 1 = 0.889065 loss)
I0527 11:02:48.340915 22103 sgd_solver.cpp:106] Iteration 318750, lr = 0.002
I0527 11:02:58.042383 22103 solver.cpp:237] Iteration 319125, loss = 0.973921
I0527 11:02:58.042415 22103 solver.cpp:253]     Train net output #0: loss = 0.973921 (* 1 = 0.973921 loss)
I0527 11:02:58.042436 22103 sgd_solver.cpp:106] Iteration 319125, lr = 0.002
I0527 11:03:07.752794 22103 solver.cpp:237] Iteration 319500, loss = 1.14437
I0527 11:03:07.752837 22103 solver.cpp:253]     Train net output #0: loss = 1.14437 (* 1 = 1.14437 loss)
I0527 11:03:07.752858 22103 sgd_solver.cpp:106] Iteration 319500, lr = 0.002
I0527 11:03:17.448146 22103 solver.cpp:237] Iteration 319875, loss = 1.01196
I0527 11:03:17.448181 22103 solver.cpp:253]     Train net output #0: loss = 1.01196 (* 1 = 1.01196 loss)
I0527 11:03:17.448195 22103 sgd_solver.cpp:106] Iteration 319875, lr = 0.002
I0527 11:03:27.152101 22103 solver.cpp:237] Iteration 320250, loss = 1.02504
I0527 11:03:27.152289 22103 solver.cpp:253]     Train net output #0: loss = 1.02504 (* 1 = 1.02504 loss)
I0527 11:03:27.152303 22103 sgd_solver.cpp:106] Iteration 320250, lr = 0.002
I0527 11:03:36.849962 22103 solver.cpp:237] Iteration 320625, loss = 1.38147
I0527 11:03:36.850014 22103 solver.cpp:253]     Train net output #0: loss = 1.38147 (* 1 = 1.38147 loss)
I0527 11:03:36.850028 22103 sgd_solver.cpp:106] Iteration 320625, lr = 0.002
I0527 11:03:46.561444 22103 solver.cpp:237] Iteration 321000, loss = 1.31288
I0527 11:03:46.561473 22103 solver.cpp:253]     Train net output #0: loss = 1.31288 (* 1 = 1.31288 loss)
I0527 11:03:46.561491 22103 sgd_solver.cpp:106] Iteration 321000, lr = 0.002
I0527 11:04:17.203372 22103 solver.cpp:237] Iteration 321375, loss = 0.927383
I0527 11:04:17.203580 22103 solver.cpp:253]     Train net output #0: loss = 0.927383 (* 1 = 0.927383 loss)
I0527 11:04:17.203595 22103 sgd_solver.cpp:106] Iteration 321375, lr = 0.002
I0527 11:04:26.903028 22103 solver.cpp:237] Iteration 321750, loss = 1.22347
I0527 11:04:26.903069 22103 solver.cpp:253]     Train net output #0: loss = 1.22347 (* 1 = 1.22347 loss)
I0527 11:04:26.903089 22103 sgd_solver.cpp:106] Iteration 321750, lr = 0.002
I0527 11:04:36.612035 22103 solver.cpp:237] Iteration 322125, loss = 1.40221
I0527 11:04:36.612071 22103 solver.cpp:253]     Train net output #0: loss = 1.40221 (* 1 = 1.40221 loss)
I0527 11:04:36.612088 22103 sgd_solver.cpp:106] Iteration 322125, lr = 0.002
I0527 11:04:46.293251 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_322500.caffemodel
I0527 11:04:46.351086 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_322500.solverstate
I0527 11:04:46.378923 22103 solver.cpp:341] Iteration 322500, Testing net (#0)
I0527 11:05:55.872689 22103 solver.cpp:409]     Test net output #0: accuracy = 0.903365
I0527 11:05:55.872884 22103 solver.cpp:409]     Test net output #1: loss = 0.291649 (* 1 = 0.291649 loss)
I0527 11:05:55.880980 22103 solver.cpp:237] Iteration 322500, loss = 0.931417
I0527 11:05:55.881009 22103 solver.cpp:253]     Train net output #0: loss = 0.931417 (* 1 = 0.931417 loss)
I0527 11:05:55.881022 22103 sgd_solver.cpp:106] Iteration 322500, lr = 0.002
I0527 11:06:05.655642 22103 solver.cpp:237] Iteration 322875, loss = 1.28548
I0527 11:06:05.655678 22103 solver.cpp:253]     Train net output #0: loss = 1.28548 (* 1 = 1.28548 loss)
I0527 11:06:05.655696 22103 sgd_solver.cpp:106] Iteration 322875, lr = 0.002
I0527 11:06:15.435822 22103 solver.cpp:237] Iteration 323250, loss = 0.982079
I0527 11:06:15.435859 22103 solver.cpp:253]     Train net output #0: loss = 0.982079 (* 1 = 0.982079 loss)
I0527 11:06:15.435873 22103 sgd_solver.cpp:106] Iteration 323250, lr = 0.002
I0527 11:06:25.221586 22103 solver.cpp:237] Iteration 323625, loss = 1.12734
I0527 11:06:25.221623 22103 solver.cpp:253]     Train net output #0: loss = 1.12734 (* 1 = 1.12734 loss)
I0527 11:06:25.221647 22103 sgd_solver.cpp:106] Iteration 323625, lr = 0.002
I0527 11:06:55.901968 22103 solver.cpp:237] Iteration 324000, loss = 1.06779
I0527 11:06:55.902180 22103 solver.cpp:253]     Train net output #0: loss = 1.06779 (* 1 = 1.06779 loss)
I0527 11:06:55.902195 22103 sgd_solver.cpp:106] Iteration 324000, lr = 0.002
I0527 11:07:05.688451 22103 solver.cpp:237] Iteration 324375, loss = 1.05672
I0527 11:07:05.688483 22103 solver.cpp:253]     Train net output #0: loss = 1.05672 (* 1 = 1.05672 loss)
I0527 11:07:05.688498 22103 sgd_solver.cpp:106] Iteration 324375, lr = 0.002
I0527 11:07:15.474776 22103 solver.cpp:237] Iteration 324750, loss = 1.44329
I0527 11:07:15.474817 22103 solver.cpp:253]     Train net output #0: loss = 1.44329 (* 1 = 1.44329 loss)
I0527 11:07:15.474835 22103 sgd_solver.cpp:106] Iteration 324750, lr = 0.002
I0527 11:07:25.254040 22103 solver.cpp:237] Iteration 325125, loss = 0.926888
I0527 11:07:25.254076 22103 solver.cpp:253]     Train net output #0: loss = 0.926888 (* 1 = 0.926888 loss)
I0527 11:07:25.254092 22103 sgd_solver.cpp:106] Iteration 325125, lr = 0.002
I0527 11:07:35.041576 22103 solver.cpp:237] Iteration 325500, loss = 1.25529
I0527 11:07:35.041760 22103 solver.cpp:253]     Train net output #0: loss = 1.25529 (* 1 = 1.25529 loss)
I0527 11:07:35.041774 22103 sgd_solver.cpp:106] Iteration 325500, lr = 0.002
I0527 11:07:44.814846 22103 solver.cpp:237] Iteration 325875, loss = 1.18065
I0527 11:07:44.814883 22103 solver.cpp:253]     Train net output #0: loss = 1.18065 (* 1 = 1.18065 loss)
I0527 11:07:44.814898 22103 sgd_solver.cpp:106] Iteration 325875, lr = 0.002
I0527 11:07:54.573211 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_326250.caffemodel
I0527 11:07:54.630205 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_326250.solverstate
I0527 11:08:15.550688 22103 solver.cpp:237] Iteration 326250, loss = 1.05278
I0527 11:08:15.550895 22103 solver.cpp:253]     Train net output #0: loss = 1.05278 (* 1 = 1.05278 loss)
I0527 11:08:15.550911 22103 sgd_solver.cpp:106] Iteration 326250, lr = 0.002
I0527 11:08:25.333184 22103 solver.cpp:237] Iteration 326625, loss = 1.33454
I0527 11:08:25.333219 22103 solver.cpp:253]     Train net output #0: loss = 1.33454 (* 1 = 1.33454 loss)
I0527 11:08:25.333233 22103 sgd_solver.cpp:106] Iteration 326625, lr = 0.002
I0527 11:08:35.117748 22103 solver.cpp:237] Iteration 327000, loss = 0.838673
I0527 11:08:35.117789 22103 solver.cpp:253]     Train net output #0: loss = 0.838673 (* 1 = 0.838673 loss)
I0527 11:08:35.117806 22103 sgd_solver.cpp:106] Iteration 327000, lr = 0.002
I0527 11:08:44.895387 22103 solver.cpp:237] Iteration 327375, loss = 1.19983
I0527 11:08:44.895423 22103 solver.cpp:253]     Train net output #0: loss = 1.19983 (* 1 = 1.19983 loss)
I0527 11:08:44.895437 22103 sgd_solver.cpp:106] Iteration 327375, lr = 0.002
I0527 11:08:54.680146 22103 solver.cpp:237] Iteration 327750, loss = 0.812025
I0527 11:08:54.680336 22103 solver.cpp:253]     Train net output #0: loss = 0.812025 (* 1 = 0.812025 loss)
I0527 11:08:54.680351 22103 sgd_solver.cpp:106] Iteration 327750, lr = 0.002
I0527 11:09:04.458916 22103 solver.cpp:237] Iteration 328125, loss = 1.11919
I0527 11:09:04.458950 22103 solver.cpp:253]     Train net output #0: loss = 1.11919 (* 1 = 1.11919 loss)
I0527 11:09:04.458966 22103 sgd_solver.cpp:106] Iteration 328125, lr = 0.002
I0527 11:09:14.242974 22103 solver.cpp:237] Iteration 328500, loss = 0.926134
I0527 11:09:14.243010 22103 solver.cpp:253]     Train net output #0: loss = 0.926134 (* 1 = 0.926134 loss)
I0527 11:09:14.243026 22103 sgd_solver.cpp:106] Iteration 328500, lr = 0.002
I0527 11:09:44.922816 22103 solver.cpp:237] Iteration 328875, loss = 1.42738
I0527 11:09:44.923022 22103 solver.cpp:253]     Train net output #0: loss = 1.42738 (* 1 = 1.42738 loss)
I0527 11:09:44.923038 22103 sgd_solver.cpp:106] Iteration 328875, lr = 0.002
I0527 11:09:54.714934 22103 solver.cpp:237] Iteration 329250, loss = 1.06468
I0527 11:09:54.714968 22103 solver.cpp:253]     Train net output #0: loss = 1.06468 (* 1 = 1.06468 loss)
I0527 11:09:54.714982 22103 sgd_solver.cpp:106] Iteration 329250, lr = 0.002
I0527 11:10:04.506696 22103 solver.cpp:237] Iteration 329625, loss = 1.08794
I0527 11:10:04.506731 22103 solver.cpp:253]     Train net output #0: loss = 1.08794 (* 1 = 1.08794 loss)
I0527 11:10:04.506745 22103 sgd_solver.cpp:106] Iteration 329625, lr = 0.002
I0527 11:10:14.259687 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_330000.caffemodel
I0527 11:10:14.315403 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_330000.solverstate
I0527 11:10:14.341385 22103 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 11:11:02.921783 22103 solver.cpp:409]     Test net output #0: accuracy = 0.904846
I0527 11:11:02.921978 22103 solver.cpp:409]     Test net output #1: loss = 0.301617 (* 1 = 0.301617 loss)
I0527 11:11:02.930096 22103 solver.cpp:237] Iteration 330000, loss = 0.9942
I0527 11:11:02.930124 22103 solver.cpp:253]     Train net output #0: loss = 0.9942 (* 1 = 0.9942 loss)
I0527 11:11:02.930142 22103 sgd_solver.cpp:106] Iteration 330000, lr = 0.002
I0527 11:11:12.667031 22103 solver.cpp:237] Iteration 330375, loss = 1.25343
I0527 11:11:12.667067 22103 solver.cpp:253]     Train net output #0: loss = 1.25343 (* 1 = 1.25343 loss)
I0527 11:11:12.667079 22103 sgd_solver.cpp:106] Iteration 330375, lr = 0.002
I0527 11:11:22.408063 22103 solver.cpp:237] Iteration 330750, loss = 1.22867
I0527 11:11:22.408098 22103 solver.cpp:253]     Train net output #0: loss = 1.22867 (* 1 = 1.22867 loss)
I0527 11:11:22.408112 22103 sgd_solver.cpp:106] Iteration 330750, lr = 0.002
I0527 11:11:32.142024 22103 solver.cpp:237] Iteration 331125, loss = 1.23391
I0527 11:11:32.142060 22103 solver.cpp:253]     Train net output #0: loss = 1.23391 (* 1 = 1.23391 loss)
I0527 11:11:32.142078 22103 sgd_solver.cpp:106] Iteration 331125, lr = 0.002
I0527 11:12:02.774585 22103 solver.cpp:237] Iteration 331500, loss = 1.177
I0527 11:12:02.774785 22103 solver.cpp:253]     Train net output #0: loss = 1.177 (* 1 = 1.177 loss)
I0527 11:12:02.774799 22103 sgd_solver.cpp:106] Iteration 331500, lr = 0.002
I0527 11:12:12.509686 22103 solver.cpp:237] Iteration 331875, loss = 1.17803
I0527 11:12:12.509721 22103 solver.cpp:253]     Train net output #0: loss = 1.17803 (* 1 = 1.17803 loss)
I0527 11:12:12.509738 22103 sgd_solver.cpp:106] Iteration 331875, lr = 0.002
I0527 11:12:22.234127 22103 solver.cpp:237] Iteration 332250, loss = 1.06498
I0527 11:12:22.234174 22103 solver.cpp:253]     Train net output #0: loss = 1.06498 (* 1 = 1.06498 loss)
I0527 11:12:22.234190 22103 sgd_solver.cpp:106] Iteration 332250, lr = 0.002
I0527 11:12:31.966969 22103 solver.cpp:237] Iteration 332625, loss = 1.19974
I0527 11:12:31.967003 22103 solver.cpp:253]     Train net output #0: loss = 1.19974 (* 1 = 1.19974 loss)
I0527 11:12:31.967017 22103 sgd_solver.cpp:106] Iteration 332625, lr = 0.002
I0527 11:12:41.708035 22103 solver.cpp:237] Iteration 333000, loss = 1.47048
I0527 11:12:41.708225 22103 solver.cpp:253]     Train net output #0: loss = 1.47048 (* 1 = 1.47048 loss)
I0527 11:12:41.708240 22103 sgd_solver.cpp:106] Iteration 333000, lr = 0.002
I0527 11:12:51.447597 22103 solver.cpp:237] Iteration 333375, loss = 0.744011
I0527 11:12:51.447631 22103 solver.cpp:253]     Train net output #0: loss = 0.744011 (* 1 = 0.744011 loss)
I0527 11:12:51.447649 22103 sgd_solver.cpp:106] Iteration 333375, lr = 0.002
I0527 11:13:01.164180 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_333750.caffemodel
I0527 11:13:01.222940 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_333750.solverstate
I0527 11:13:22.166862 22103 solver.cpp:237] Iteration 333750, loss = 1.17418
I0527 11:13:22.167084 22103 solver.cpp:253]     Train net output #0: loss = 1.17418 (* 1 = 1.17418 loss)
I0527 11:13:22.167100 22103 sgd_solver.cpp:106] Iteration 333750, lr = 0.002
I0527 11:13:31.910815 22103 solver.cpp:237] Iteration 334125, loss = 0.772191
I0527 11:13:31.910856 22103 solver.cpp:253]     Train net output #0: loss = 0.772191 (* 1 = 0.772191 loss)
I0527 11:13:31.910876 22103 sgd_solver.cpp:106] Iteration 334125, lr = 0.002
I0527 11:13:41.647181 22103 solver.cpp:237] Iteration 334500, loss = 1.18206
I0527 11:13:41.647214 22103 solver.cpp:253]     Train net output #0: loss = 1.18206 (* 1 = 1.18206 loss)
I0527 11:13:41.647228 22103 sgd_solver.cpp:106] Iteration 334500, lr = 0.002
I0527 11:13:51.389842 22103 solver.cpp:237] Iteration 334875, loss = 1.15213
I0527 11:13:51.389876 22103 solver.cpp:253]     Train net output #0: loss = 1.15213 (* 1 = 1.15213 loss)
I0527 11:13:51.389889 22103 sgd_solver.cpp:106] Iteration 334875, lr = 0.002
I0527 11:14:01.133011 22103 solver.cpp:237] Iteration 335250, loss = 1.3422
I0527 11:14:01.133203 22103 solver.cpp:253]     Train net output #0: loss = 1.3422 (* 1 = 1.3422 loss)
I0527 11:14:01.133218 22103 sgd_solver.cpp:106] Iteration 335250, lr = 0.002
I0527 11:14:10.876760 22103 solver.cpp:237] Iteration 335625, loss = 0.890567
I0527 11:14:10.876796 22103 solver.cpp:253]     Train net output #0: loss = 0.890567 (* 1 = 0.890567 loss)
I0527 11:14:10.876809 22103 sgd_solver.cpp:106] Iteration 335625, lr = 0.002
I0527 11:14:20.609616 22103 solver.cpp:237] Iteration 336000, loss = 1.23773
I0527 11:14:20.609654 22103 solver.cpp:253]     Train net output #0: loss = 1.23773 (* 1 = 1.23773 loss)
I0527 11:14:20.609673 22103 sgd_solver.cpp:106] Iteration 336000, lr = 0.002
I0527 11:14:51.249763 22103 solver.cpp:237] Iteration 336375, loss = 1.06259
I0527 11:14:51.249958 22103 solver.cpp:253]     Train net output #0: loss = 1.06259 (* 1 = 1.06259 loss)
I0527 11:14:51.249974 22103 sgd_solver.cpp:106] Iteration 336375, lr = 0.002
I0527 11:15:00.984225 22103 solver.cpp:237] Iteration 336750, loss = 1.05631
I0527 11:15:00.984261 22103 solver.cpp:253]     Train net output #0: loss = 1.05631 (* 1 = 1.05631 loss)
I0527 11:15:00.984277 22103 sgd_solver.cpp:106] Iteration 336750, lr = 0.002
I0527 11:15:10.720819 22103 solver.cpp:237] Iteration 337125, loss = 0.83888
I0527 11:15:10.720861 22103 solver.cpp:253]     Train net output #0: loss = 0.83888 (* 1 = 0.83888 loss)
I0527 11:15:10.720882 22103 sgd_solver.cpp:106] Iteration 337125, lr = 0.002
I0527 11:15:20.427007 22103 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_337500.caffemodel
I0527 11:15:20.484148 22103 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0020_2016-05-20T15.49.02.258271_iter_337500.solverstate
I0527 11:15:20.512853 22103 solver.cpp:341] Iteration 337500, Testing net (#0)
aprun: Apid 11272834: Caught signal Terminated, sending to application
*** Aborted at 1464362162 (unix time) try "date -d @1464362162" if you are using GNU date ***
=>> PBS: job killed: walltime 7205 exceeded limit 7200
PC: @     0x2aaab928ec37 (unknown)
*** SIGTERM (@0x5654) received by PID 22103 (TID 0x2aaac746f900) from PID 22100; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab928ec37 (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11272834: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11272834: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11272834: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11272834: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
aprun: Apid 11272834: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02353] [c6-1c0s7n1] [Fri May 27 11:16:04 2016] PE RANK 0 exit signal Terminated
Application 11272834 exit codes: 143
Application 11272834 resources: utime ~6226s, stime ~971s, Rss ~5331980, inblocks ~15277456, outblocks ~696236
