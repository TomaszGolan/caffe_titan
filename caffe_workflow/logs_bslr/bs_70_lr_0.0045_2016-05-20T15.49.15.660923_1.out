2809292
I0524 04:25:16.164530 19864 caffe.cpp:184] Using GPUs 0
I0524 04:25:16.591943 19864 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2142
test_interval: 4285
base_lr: 0.0045
display: 214
max_iter: 214280
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2142
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923.prototxt"
I0524 04:25:16.593688 19864 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923.prototxt
I0524 04:25:16.607446 19864 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0524 04:25:16.607506 19864 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0524 04:25:16.607867 19864 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 04:25:16.608050 19864 layer_factory.hpp:77] Creating layer data_hdf5
I0524 04:25:16.608074 19864 net.cpp:106] Creating Layer data_hdf5
I0524 04:25:16.608089 19864 net.cpp:411] data_hdf5 -> data
I0524 04:25:16.608122 19864 net.cpp:411] data_hdf5 -> label
I0524 04:25:16.608155 19864 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0524 04:25:16.609694 19864 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0524 04:25:16.611995 19864 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0524 04:25:38.178163 19864 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0524 04:25:38.183305 19864 net.cpp:150] Setting up data_hdf5
I0524 04:25:38.183346 19864 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0524 04:25:38.183360 19864 net.cpp:157] Top shape: 70 (70)
I0524 04:25:38.183372 19864 net.cpp:165] Memory required for data: 1778280
I0524 04:25:38.183387 19864 layer_factory.hpp:77] Creating layer conv1
I0524 04:25:38.183420 19864 net.cpp:106] Creating Layer conv1
I0524 04:25:38.183431 19864 net.cpp:454] conv1 <- data
I0524 04:25:38.183452 19864 net.cpp:411] conv1 -> conv1
I0524 04:25:38.548014 19864 net.cpp:150] Setting up conv1
I0524 04:25:38.548063 19864 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 04:25:38.548072 19864 net.cpp:165] Memory required for data: 21131880
I0524 04:25:38.548101 19864 layer_factory.hpp:77] Creating layer relu1
I0524 04:25:38.548122 19864 net.cpp:106] Creating Layer relu1
I0524 04:25:38.548133 19864 net.cpp:454] relu1 <- conv1
I0524 04:25:38.548147 19864 net.cpp:397] relu1 -> conv1 (in-place)
I0524 04:25:38.548668 19864 net.cpp:150] Setting up relu1
I0524 04:25:38.548686 19864 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 04:25:38.548696 19864 net.cpp:165] Memory required for data: 40485480
I0524 04:25:38.548707 19864 layer_factory.hpp:77] Creating layer pool1
I0524 04:25:38.548723 19864 net.cpp:106] Creating Layer pool1
I0524 04:25:38.548733 19864 net.cpp:454] pool1 <- conv1
I0524 04:25:38.548746 19864 net.cpp:411] pool1 -> pool1
I0524 04:25:38.548827 19864 net.cpp:150] Setting up pool1
I0524 04:25:38.548841 19864 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0524 04:25:38.548851 19864 net.cpp:165] Memory required for data: 50162280
I0524 04:25:38.548861 19864 layer_factory.hpp:77] Creating layer conv2
I0524 04:25:38.548882 19864 net.cpp:106] Creating Layer conv2
I0524 04:25:38.548892 19864 net.cpp:454] conv2 <- pool1
I0524 04:25:38.548905 19864 net.cpp:411] conv2 -> conv2
I0524 04:25:38.551612 19864 net.cpp:150] Setting up conv2
I0524 04:25:38.551656 19864 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 04:25:38.551666 19864 net.cpp:165] Memory required for data: 64072680
I0524 04:25:38.551687 19864 layer_factory.hpp:77] Creating layer relu2
I0524 04:25:38.551702 19864 net.cpp:106] Creating Layer relu2
I0524 04:25:38.551712 19864 net.cpp:454] relu2 <- conv2
I0524 04:25:38.551725 19864 net.cpp:397] relu2 -> conv2 (in-place)
I0524 04:25:38.552057 19864 net.cpp:150] Setting up relu2
I0524 04:25:38.552070 19864 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 04:25:38.552080 19864 net.cpp:165] Memory required for data: 77983080
I0524 04:25:38.552090 19864 layer_factory.hpp:77] Creating layer pool2
I0524 04:25:38.552103 19864 net.cpp:106] Creating Layer pool2
I0524 04:25:38.552112 19864 net.cpp:454] pool2 <- conv2
I0524 04:25:38.552125 19864 net.cpp:411] pool2 -> pool2
I0524 04:25:38.552206 19864 net.cpp:150] Setting up pool2
I0524 04:25:38.552219 19864 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0524 04:25:38.552228 19864 net.cpp:165] Memory required for data: 84938280
I0524 04:25:38.552238 19864 layer_factory.hpp:77] Creating layer conv3
I0524 04:25:38.552255 19864 net.cpp:106] Creating Layer conv3
I0524 04:25:38.552265 19864 net.cpp:454] conv3 <- pool2
I0524 04:25:38.552279 19864 net.cpp:411] conv3 -> conv3
I0524 04:25:38.554196 19864 net.cpp:150] Setting up conv3
I0524 04:25:38.554219 19864 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 04:25:38.554231 19864 net.cpp:165] Memory required for data: 92527400
I0524 04:25:38.554250 19864 layer_factory.hpp:77] Creating layer relu3
I0524 04:25:38.554265 19864 net.cpp:106] Creating Layer relu3
I0524 04:25:38.554275 19864 net.cpp:454] relu3 <- conv3
I0524 04:25:38.554288 19864 net.cpp:397] relu3 -> conv3 (in-place)
I0524 04:25:38.554757 19864 net.cpp:150] Setting up relu3
I0524 04:25:38.554774 19864 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 04:25:38.554785 19864 net.cpp:165] Memory required for data: 100116520
I0524 04:25:38.554795 19864 layer_factory.hpp:77] Creating layer pool3
I0524 04:25:38.554808 19864 net.cpp:106] Creating Layer pool3
I0524 04:25:38.554817 19864 net.cpp:454] pool3 <- conv3
I0524 04:25:38.554831 19864 net.cpp:411] pool3 -> pool3
I0524 04:25:38.554898 19864 net.cpp:150] Setting up pool3
I0524 04:25:38.554911 19864 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0524 04:25:38.554921 19864 net.cpp:165] Memory required for data: 103911080
I0524 04:25:38.554931 19864 layer_factory.hpp:77] Creating layer conv4
I0524 04:25:38.554950 19864 net.cpp:106] Creating Layer conv4
I0524 04:25:38.554960 19864 net.cpp:454] conv4 <- pool3
I0524 04:25:38.554973 19864 net.cpp:411] conv4 -> conv4
I0524 04:25:38.557755 19864 net.cpp:150] Setting up conv4
I0524 04:25:38.557780 19864 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 04:25:38.557790 19864 net.cpp:165] Memory required for data: 106451240
I0524 04:25:38.557804 19864 layer_factory.hpp:77] Creating layer relu4
I0524 04:25:38.557819 19864 net.cpp:106] Creating Layer relu4
I0524 04:25:38.557829 19864 net.cpp:454] relu4 <- conv4
I0524 04:25:38.557842 19864 net.cpp:397] relu4 -> conv4 (in-place)
I0524 04:25:38.558316 19864 net.cpp:150] Setting up relu4
I0524 04:25:38.558332 19864 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 04:25:38.558343 19864 net.cpp:165] Memory required for data: 108991400
I0524 04:25:38.558353 19864 layer_factory.hpp:77] Creating layer pool4
I0524 04:25:38.558367 19864 net.cpp:106] Creating Layer pool4
I0524 04:25:38.558377 19864 net.cpp:454] pool4 <- conv4
I0524 04:25:38.558389 19864 net.cpp:411] pool4 -> pool4
I0524 04:25:38.558457 19864 net.cpp:150] Setting up pool4
I0524 04:25:38.558471 19864 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0524 04:25:38.558481 19864 net.cpp:165] Memory required for data: 110261480
I0524 04:25:38.558491 19864 layer_factory.hpp:77] Creating layer ip1
I0524 04:25:38.558509 19864 net.cpp:106] Creating Layer ip1
I0524 04:25:38.558519 19864 net.cpp:454] ip1 <- pool4
I0524 04:25:38.558532 19864 net.cpp:411] ip1 -> ip1
I0524 04:25:38.573907 19864 net.cpp:150] Setting up ip1
I0524 04:25:38.573931 19864 net.cpp:157] Top shape: 70 196 (13720)
I0524 04:25:38.573943 19864 net.cpp:165] Memory required for data: 110316360
I0524 04:25:38.573966 19864 layer_factory.hpp:77] Creating layer relu5
I0524 04:25:38.573981 19864 net.cpp:106] Creating Layer relu5
I0524 04:25:38.573990 19864 net.cpp:454] relu5 <- ip1
I0524 04:25:38.574003 19864 net.cpp:397] relu5 -> ip1 (in-place)
I0524 04:25:38.574344 19864 net.cpp:150] Setting up relu5
I0524 04:25:38.574358 19864 net.cpp:157] Top shape: 70 196 (13720)
I0524 04:25:38.574369 19864 net.cpp:165] Memory required for data: 110371240
I0524 04:25:38.574379 19864 layer_factory.hpp:77] Creating layer drop1
I0524 04:25:38.574401 19864 net.cpp:106] Creating Layer drop1
I0524 04:25:38.574411 19864 net.cpp:454] drop1 <- ip1
I0524 04:25:38.574424 19864 net.cpp:397] drop1 -> ip1 (in-place)
I0524 04:25:38.574486 19864 net.cpp:150] Setting up drop1
I0524 04:25:38.574499 19864 net.cpp:157] Top shape: 70 196 (13720)
I0524 04:25:38.574509 19864 net.cpp:165] Memory required for data: 110426120
I0524 04:25:38.574519 19864 layer_factory.hpp:77] Creating layer ip2
I0524 04:25:38.574538 19864 net.cpp:106] Creating Layer ip2
I0524 04:25:38.574548 19864 net.cpp:454] ip2 <- ip1
I0524 04:25:38.574561 19864 net.cpp:411] ip2 -> ip2
I0524 04:25:38.575022 19864 net.cpp:150] Setting up ip2
I0524 04:25:38.575036 19864 net.cpp:157] Top shape: 70 98 (6860)
I0524 04:25:38.575045 19864 net.cpp:165] Memory required for data: 110453560
I0524 04:25:38.575060 19864 layer_factory.hpp:77] Creating layer relu6
I0524 04:25:38.575073 19864 net.cpp:106] Creating Layer relu6
I0524 04:25:38.575083 19864 net.cpp:454] relu6 <- ip2
I0524 04:25:38.575093 19864 net.cpp:397] relu6 -> ip2 (in-place)
I0524 04:25:38.575613 19864 net.cpp:150] Setting up relu6
I0524 04:25:38.575628 19864 net.cpp:157] Top shape: 70 98 (6860)
I0524 04:25:38.575639 19864 net.cpp:165] Memory required for data: 110481000
I0524 04:25:38.575656 19864 layer_factory.hpp:77] Creating layer drop2
I0524 04:25:38.575670 19864 net.cpp:106] Creating Layer drop2
I0524 04:25:38.575678 19864 net.cpp:454] drop2 <- ip2
I0524 04:25:38.575691 19864 net.cpp:397] drop2 -> ip2 (in-place)
I0524 04:25:38.575736 19864 net.cpp:150] Setting up drop2
I0524 04:25:38.575748 19864 net.cpp:157] Top shape: 70 98 (6860)
I0524 04:25:38.575758 19864 net.cpp:165] Memory required for data: 110508440
I0524 04:25:38.575768 19864 layer_factory.hpp:77] Creating layer ip3
I0524 04:25:38.575783 19864 net.cpp:106] Creating Layer ip3
I0524 04:25:38.575793 19864 net.cpp:454] ip3 <- ip2
I0524 04:25:38.575805 19864 net.cpp:411] ip3 -> ip3
I0524 04:25:38.576015 19864 net.cpp:150] Setting up ip3
I0524 04:25:38.576028 19864 net.cpp:157] Top shape: 70 11 (770)
I0524 04:25:38.576038 19864 net.cpp:165] Memory required for data: 110511520
I0524 04:25:38.576053 19864 layer_factory.hpp:77] Creating layer drop3
I0524 04:25:38.576066 19864 net.cpp:106] Creating Layer drop3
I0524 04:25:38.576076 19864 net.cpp:454] drop3 <- ip3
I0524 04:25:38.576087 19864 net.cpp:397] drop3 -> ip3 (in-place)
I0524 04:25:38.576128 19864 net.cpp:150] Setting up drop3
I0524 04:25:38.576140 19864 net.cpp:157] Top shape: 70 11 (770)
I0524 04:25:38.576150 19864 net.cpp:165] Memory required for data: 110514600
I0524 04:25:38.576160 19864 layer_factory.hpp:77] Creating layer loss
I0524 04:25:38.576180 19864 net.cpp:106] Creating Layer loss
I0524 04:25:38.576190 19864 net.cpp:454] loss <- ip3
I0524 04:25:38.576200 19864 net.cpp:454] loss <- label
I0524 04:25:38.576212 19864 net.cpp:411] loss -> loss
I0524 04:25:38.576231 19864 layer_factory.hpp:77] Creating layer loss
I0524 04:25:38.576875 19864 net.cpp:150] Setting up loss
I0524 04:25:38.576895 19864 net.cpp:157] Top shape: (1)
I0524 04:25:38.576910 19864 net.cpp:160]     with loss weight 1
I0524 04:25:38.576951 19864 net.cpp:165] Memory required for data: 110514604
I0524 04:25:38.576961 19864 net.cpp:226] loss needs backward computation.
I0524 04:25:38.576973 19864 net.cpp:226] drop3 needs backward computation.
I0524 04:25:38.576983 19864 net.cpp:226] ip3 needs backward computation.
I0524 04:25:38.576992 19864 net.cpp:226] drop2 needs backward computation.
I0524 04:25:38.577002 19864 net.cpp:226] relu6 needs backward computation.
I0524 04:25:38.577011 19864 net.cpp:226] ip2 needs backward computation.
I0524 04:25:38.577020 19864 net.cpp:226] drop1 needs backward computation.
I0524 04:25:38.577031 19864 net.cpp:226] relu5 needs backward computation.
I0524 04:25:38.577040 19864 net.cpp:226] ip1 needs backward computation.
I0524 04:25:38.577050 19864 net.cpp:226] pool4 needs backward computation.
I0524 04:25:38.577060 19864 net.cpp:226] relu4 needs backward computation.
I0524 04:25:38.577070 19864 net.cpp:226] conv4 needs backward computation.
I0524 04:25:38.577080 19864 net.cpp:226] pool3 needs backward computation.
I0524 04:25:38.577090 19864 net.cpp:226] relu3 needs backward computation.
I0524 04:25:38.577108 19864 net.cpp:226] conv3 needs backward computation.
I0524 04:25:38.577119 19864 net.cpp:226] pool2 needs backward computation.
I0524 04:25:38.577129 19864 net.cpp:226] relu2 needs backward computation.
I0524 04:25:38.577141 19864 net.cpp:226] conv2 needs backward computation.
I0524 04:25:38.577150 19864 net.cpp:226] pool1 needs backward computation.
I0524 04:25:38.577162 19864 net.cpp:226] relu1 needs backward computation.
I0524 04:25:38.577172 19864 net.cpp:226] conv1 needs backward computation.
I0524 04:25:38.577209 19864 net.cpp:228] data_hdf5 does not need backward computation.
I0524 04:25:38.577220 19864 net.cpp:270] This network produces output loss
I0524 04:25:38.577244 19864 net.cpp:283] Network initialization done.
I0524 04:25:38.579000 19864 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923.prototxt
I0524 04:25:38.579071 19864 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0524 04:25:38.579428 19864 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 04:25:38.579615 19864 layer_factory.hpp:77] Creating layer data_hdf5
I0524 04:25:38.579630 19864 net.cpp:106] Creating Layer data_hdf5
I0524 04:25:38.579648 19864 net.cpp:411] data_hdf5 -> data
I0524 04:25:38.579665 19864 net.cpp:411] data_hdf5 -> label
I0524 04:25:38.579681 19864 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0524 04:25:38.581110 19864 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0524 04:25:59.900697 19864 net.cpp:150] Setting up data_hdf5
I0524 04:25:59.900857 19864 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0524 04:25:59.900871 19864 net.cpp:157] Top shape: 70 (70)
I0524 04:25:59.900883 19864 net.cpp:165] Memory required for data: 1778280
I0524 04:25:59.900897 19864 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0524 04:25:59.900925 19864 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0524 04:25:59.900935 19864 net.cpp:454] label_data_hdf5_1_split <- label
I0524 04:25:59.900950 19864 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0524 04:25:59.900972 19864 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0524 04:25:59.901044 19864 net.cpp:150] Setting up label_data_hdf5_1_split
I0524 04:25:59.901058 19864 net.cpp:157] Top shape: 70 (70)
I0524 04:25:59.901070 19864 net.cpp:157] Top shape: 70 (70)
I0524 04:25:59.901079 19864 net.cpp:165] Memory required for data: 1778840
I0524 04:25:59.901089 19864 layer_factory.hpp:77] Creating layer conv1
I0524 04:25:59.901113 19864 net.cpp:106] Creating Layer conv1
I0524 04:25:59.901123 19864 net.cpp:454] conv1 <- data
I0524 04:25:59.901134 19864 net.cpp:411] conv1 -> conv1
I0524 04:25:59.903048 19864 net.cpp:150] Setting up conv1
I0524 04:25:59.903074 19864 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 04:25:59.903084 19864 net.cpp:165] Memory required for data: 21132440
I0524 04:25:59.903105 19864 layer_factory.hpp:77] Creating layer relu1
I0524 04:25:59.903120 19864 net.cpp:106] Creating Layer relu1
I0524 04:25:59.903131 19864 net.cpp:454] relu1 <- conv1
I0524 04:25:59.903143 19864 net.cpp:397] relu1 -> conv1 (in-place)
I0524 04:25:59.903648 19864 net.cpp:150] Setting up relu1
I0524 04:25:59.903664 19864 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 04:25:59.903676 19864 net.cpp:165] Memory required for data: 40486040
I0524 04:25:59.903686 19864 layer_factory.hpp:77] Creating layer pool1
I0524 04:25:59.903702 19864 net.cpp:106] Creating Layer pool1
I0524 04:25:59.903712 19864 net.cpp:454] pool1 <- conv1
I0524 04:25:59.903724 19864 net.cpp:411] pool1 -> pool1
I0524 04:25:59.903798 19864 net.cpp:150] Setting up pool1
I0524 04:25:59.903812 19864 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0524 04:25:59.903822 19864 net.cpp:165] Memory required for data: 50162840
I0524 04:25:59.903832 19864 layer_factory.hpp:77] Creating layer conv2
I0524 04:25:59.903851 19864 net.cpp:106] Creating Layer conv2
I0524 04:25:59.903861 19864 net.cpp:454] conv2 <- pool1
I0524 04:25:59.903877 19864 net.cpp:411] conv2 -> conv2
I0524 04:25:59.905789 19864 net.cpp:150] Setting up conv2
I0524 04:25:59.905807 19864 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 04:25:59.905818 19864 net.cpp:165] Memory required for data: 64073240
I0524 04:25:59.905835 19864 layer_factory.hpp:77] Creating layer relu2
I0524 04:25:59.905849 19864 net.cpp:106] Creating Layer relu2
I0524 04:25:59.905859 19864 net.cpp:454] relu2 <- conv2
I0524 04:25:59.905871 19864 net.cpp:397] relu2 -> conv2 (in-place)
I0524 04:25:59.906204 19864 net.cpp:150] Setting up relu2
I0524 04:25:59.906219 19864 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 04:25:59.906229 19864 net.cpp:165] Memory required for data: 77983640
I0524 04:25:59.906239 19864 layer_factory.hpp:77] Creating layer pool2
I0524 04:25:59.906251 19864 net.cpp:106] Creating Layer pool2
I0524 04:25:59.906261 19864 net.cpp:454] pool2 <- conv2
I0524 04:25:59.906273 19864 net.cpp:411] pool2 -> pool2
I0524 04:25:59.906347 19864 net.cpp:150] Setting up pool2
I0524 04:25:59.906359 19864 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0524 04:25:59.906368 19864 net.cpp:165] Memory required for data: 84938840
I0524 04:25:59.906380 19864 layer_factory.hpp:77] Creating layer conv3
I0524 04:25:59.906397 19864 net.cpp:106] Creating Layer conv3
I0524 04:25:59.906409 19864 net.cpp:454] conv3 <- pool2
I0524 04:25:59.906422 19864 net.cpp:411] conv3 -> conv3
I0524 04:25:59.908401 19864 net.cpp:150] Setting up conv3
I0524 04:25:59.908424 19864 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 04:25:59.908437 19864 net.cpp:165] Memory required for data: 92527960
I0524 04:25:59.908469 19864 layer_factory.hpp:77] Creating layer relu3
I0524 04:25:59.908483 19864 net.cpp:106] Creating Layer relu3
I0524 04:25:59.908493 19864 net.cpp:454] relu3 <- conv3
I0524 04:25:59.908506 19864 net.cpp:397] relu3 -> conv3 (in-place)
I0524 04:25:59.908973 19864 net.cpp:150] Setting up relu3
I0524 04:25:59.908989 19864 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 04:25:59.908999 19864 net.cpp:165] Memory required for data: 100117080
I0524 04:25:59.909009 19864 layer_factory.hpp:77] Creating layer pool3
I0524 04:25:59.909023 19864 net.cpp:106] Creating Layer pool3
I0524 04:25:59.909032 19864 net.cpp:454] pool3 <- conv3
I0524 04:25:59.909045 19864 net.cpp:411] pool3 -> pool3
I0524 04:25:59.909117 19864 net.cpp:150] Setting up pool3
I0524 04:25:59.909131 19864 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0524 04:25:59.909139 19864 net.cpp:165] Memory required for data: 103911640
I0524 04:25:59.909153 19864 layer_factory.hpp:77] Creating layer conv4
I0524 04:25:59.909170 19864 net.cpp:106] Creating Layer conv4
I0524 04:25:59.909181 19864 net.cpp:454] conv4 <- pool3
I0524 04:25:59.909195 19864 net.cpp:411] conv4 -> conv4
I0524 04:25:59.911254 19864 net.cpp:150] Setting up conv4
I0524 04:25:59.911276 19864 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 04:25:59.911289 19864 net.cpp:165] Memory required for data: 106451800
I0524 04:25:59.911304 19864 layer_factory.hpp:77] Creating layer relu4
I0524 04:25:59.911317 19864 net.cpp:106] Creating Layer relu4
I0524 04:25:59.911327 19864 net.cpp:454] relu4 <- conv4
I0524 04:25:59.911340 19864 net.cpp:397] relu4 -> conv4 (in-place)
I0524 04:25:59.911818 19864 net.cpp:150] Setting up relu4
I0524 04:25:59.911834 19864 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 04:25:59.911844 19864 net.cpp:165] Memory required for data: 108991960
I0524 04:25:59.911854 19864 layer_factory.hpp:77] Creating layer pool4
I0524 04:25:59.911867 19864 net.cpp:106] Creating Layer pool4
I0524 04:25:59.911877 19864 net.cpp:454] pool4 <- conv4
I0524 04:25:59.911890 19864 net.cpp:411] pool4 -> pool4
I0524 04:25:59.911962 19864 net.cpp:150] Setting up pool4
I0524 04:25:59.911975 19864 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0524 04:25:59.911985 19864 net.cpp:165] Memory required for data: 110262040
I0524 04:25:59.911993 19864 layer_factory.hpp:77] Creating layer ip1
I0524 04:25:59.912009 19864 net.cpp:106] Creating Layer ip1
I0524 04:25:59.912019 19864 net.cpp:454] ip1 <- pool4
I0524 04:25:59.912032 19864 net.cpp:411] ip1 -> ip1
I0524 04:25:59.927530 19864 net.cpp:150] Setting up ip1
I0524 04:25:59.927558 19864 net.cpp:157] Top shape: 70 196 (13720)
I0524 04:25:59.927574 19864 net.cpp:165] Memory required for data: 110316920
I0524 04:25:59.927597 19864 layer_factory.hpp:77] Creating layer relu5
I0524 04:25:59.927613 19864 net.cpp:106] Creating Layer relu5
I0524 04:25:59.927623 19864 net.cpp:454] relu5 <- ip1
I0524 04:25:59.927636 19864 net.cpp:397] relu5 -> ip1 (in-place)
I0524 04:25:59.927989 19864 net.cpp:150] Setting up relu5
I0524 04:25:59.928002 19864 net.cpp:157] Top shape: 70 196 (13720)
I0524 04:25:59.928012 19864 net.cpp:165] Memory required for data: 110371800
I0524 04:25:59.928022 19864 layer_factory.hpp:77] Creating layer drop1
I0524 04:25:59.928040 19864 net.cpp:106] Creating Layer drop1
I0524 04:25:59.928051 19864 net.cpp:454] drop1 <- ip1
I0524 04:25:59.928064 19864 net.cpp:397] drop1 -> ip1 (in-place)
I0524 04:25:59.928112 19864 net.cpp:150] Setting up drop1
I0524 04:25:59.928124 19864 net.cpp:157] Top shape: 70 196 (13720)
I0524 04:25:59.928134 19864 net.cpp:165] Memory required for data: 110426680
I0524 04:25:59.928144 19864 layer_factory.hpp:77] Creating layer ip2
I0524 04:25:59.928158 19864 net.cpp:106] Creating Layer ip2
I0524 04:25:59.928169 19864 net.cpp:454] ip2 <- ip1
I0524 04:25:59.928181 19864 net.cpp:411] ip2 -> ip2
I0524 04:25:59.928663 19864 net.cpp:150] Setting up ip2
I0524 04:25:59.928676 19864 net.cpp:157] Top shape: 70 98 (6860)
I0524 04:25:59.928685 19864 net.cpp:165] Memory required for data: 110454120
I0524 04:25:59.928701 19864 layer_factory.hpp:77] Creating layer relu6
I0524 04:25:59.928727 19864 net.cpp:106] Creating Layer relu6
I0524 04:25:59.928737 19864 net.cpp:454] relu6 <- ip2
I0524 04:25:59.928750 19864 net.cpp:397] relu6 -> ip2 (in-place)
I0524 04:25:59.929286 19864 net.cpp:150] Setting up relu6
I0524 04:25:59.929301 19864 net.cpp:157] Top shape: 70 98 (6860)
I0524 04:25:59.929311 19864 net.cpp:165] Memory required for data: 110481560
I0524 04:25:59.929322 19864 layer_factory.hpp:77] Creating layer drop2
I0524 04:25:59.929334 19864 net.cpp:106] Creating Layer drop2
I0524 04:25:59.929344 19864 net.cpp:454] drop2 <- ip2
I0524 04:25:59.929358 19864 net.cpp:397] drop2 -> ip2 (in-place)
I0524 04:25:59.929402 19864 net.cpp:150] Setting up drop2
I0524 04:25:59.929414 19864 net.cpp:157] Top shape: 70 98 (6860)
I0524 04:25:59.929425 19864 net.cpp:165] Memory required for data: 110509000
I0524 04:25:59.929435 19864 layer_factory.hpp:77] Creating layer ip3
I0524 04:25:59.929448 19864 net.cpp:106] Creating Layer ip3
I0524 04:25:59.929458 19864 net.cpp:454] ip3 <- ip2
I0524 04:25:59.929471 19864 net.cpp:411] ip3 -> ip3
I0524 04:25:59.929694 19864 net.cpp:150] Setting up ip3
I0524 04:25:59.929708 19864 net.cpp:157] Top shape: 70 11 (770)
I0524 04:25:59.929718 19864 net.cpp:165] Memory required for data: 110512080
I0524 04:25:59.929733 19864 layer_factory.hpp:77] Creating layer drop3
I0524 04:25:59.929745 19864 net.cpp:106] Creating Layer drop3
I0524 04:25:59.929755 19864 net.cpp:454] drop3 <- ip3
I0524 04:25:59.929767 19864 net.cpp:397] drop3 -> ip3 (in-place)
I0524 04:25:59.929810 19864 net.cpp:150] Setting up drop3
I0524 04:25:59.929822 19864 net.cpp:157] Top shape: 70 11 (770)
I0524 04:25:59.929831 19864 net.cpp:165] Memory required for data: 110515160
I0524 04:25:59.929841 19864 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0524 04:25:59.929854 19864 net.cpp:106] Creating Layer ip3_drop3_0_split
I0524 04:25:59.929863 19864 net.cpp:454] ip3_drop3_0_split <- ip3
I0524 04:25:59.929877 19864 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0524 04:25:59.929891 19864 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0524 04:25:59.929965 19864 net.cpp:150] Setting up ip3_drop3_0_split
I0524 04:25:59.929978 19864 net.cpp:157] Top shape: 70 11 (770)
I0524 04:25:59.929991 19864 net.cpp:157] Top shape: 70 11 (770)
I0524 04:25:59.930001 19864 net.cpp:165] Memory required for data: 110521320
I0524 04:25:59.930011 19864 layer_factory.hpp:77] Creating layer accuracy
I0524 04:25:59.930032 19864 net.cpp:106] Creating Layer accuracy
I0524 04:25:59.930042 19864 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0524 04:25:59.930054 19864 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0524 04:25:59.930068 19864 net.cpp:411] accuracy -> accuracy
I0524 04:25:59.930090 19864 net.cpp:150] Setting up accuracy
I0524 04:25:59.930104 19864 net.cpp:157] Top shape: (1)
I0524 04:25:59.930114 19864 net.cpp:165] Memory required for data: 110521324
I0524 04:25:59.930122 19864 layer_factory.hpp:77] Creating layer loss
I0524 04:25:59.930136 19864 net.cpp:106] Creating Layer loss
I0524 04:25:59.930146 19864 net.cpp:454] loss <- ip3_drop3_0_split_1
I0524 04:25:59.930157 19864 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0524 04:25:59.930171 19864 net.cpp:411] loss -> loss
I0524 04:25:59.930188 19864 layer_factory.hpp:77] Creating layer loss
I0524 04:25:59.930675 19864 net.cpp:150] Setting up loss
I0524 04:25:59.930688 19864 net.cpp:157] Top shape: (1)
I0524 04:25:59.930698 19864 net.cpp:160]     with loss weight 1
I0524 04:25:59.930716 19864 net.cpp:165] Memory required for data: 110521328
I0524 04:25:59.930727 19864 net.cpp:226] loss needs backward computation.
I0524 04:25:59.930738 19864 net.cpp:228] accuracy does not need backward computation.
I0524 04:25:59.930749 19864 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0524 04:25:59.930759 19864 net.cpp:226] drop3 needs backward computation.
I0524 04:25:59.930769 19864 net.cpp:226] ip3 needs backward computation.
I0524 04:25:59.930778 19864 net.cpp:226] drop2 needs backward computation.
I0524 04:25:59.930788 19864 net.cpp:226] relu6 needs backward computation.
I0524 04:25:59.930805 19864 net.cpp:226] ip2 needs backward computation.
I0524 04:25:59.930815 19864 net.cpp:226] drop1 needs backward computation.
I0524 04:25:59.930824 19864 net.cpp:226] relu5 needs backward computation.
I0524 04:25:59.930835 19864 net.cpp:226] ip1 needs backward computation.
I0524 04:25:59.930845 19864 net.cpp:226] pool4 needs backward computation.
I0524 04:25:59.930855 19864 net.cpp:226] relu4 needs backward computation.
I0524 04:25:59.930863 19864 net.cpp:226] conv4 needs backward computation.
I0524 04:25:59.930874 19864 net.cpp:226] pool3 needs backward computation.
I0524 04:25:59.930886 19864 net.cpp:226] relu3 needs backward computation.
I0524 04:25:59.930896 19864 net.cpp:226] conv3 needs backward computation.
I0524 04:25:59.930904 19864 net.cpp:226] pool2 needs backward computation.
I0524 04:25:59.930914 19864 net.cpp:226] relu2 needs backward computation.
I0524 04:25:59.930924 19864 net.cpp:226] conv2 needs backward computation.
I0524 04:25:59.930934 19864 net.cpp:226] pool1 needs backward computation.
I0524 04:25:59.930944 19864 net.cpp:226] relu1 needs backward computation.
I0524 04:25:59.930954 19864 net.cpp:226] conv1 needs backward computation.
I0524 04:25:59.930965 19864 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0524 04:25:59.930976 19864 net.cpp:228] data_hdf5 does not need backward computation.
I0524 04:25:59.930986 19864 net.cpp:270] This network produces output accuracy
I0524 04:25:59.930997 19864 net.cpp:270] This network produces output loss
I0524 04:25:59.931025 19864 net.cpp:283] Network initialization done.
I0524 04:25:59.931159 19864 solver.cpp:60] Solver scaffolding done.
I0524 04:25:59.932303 19864 caffe.cpp:212] Starting Optimization
I0524 04:25:59.932322 19864 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0524 04:25:59.932335 19864 solver.cpp:289] Learning Rate Policy: fixed
I0524 04:25:59.933547 19864 solver.cpp:341] Iteration 0, Testing net (#0)
I0524 04:26:48.739735 19864 solver.cpp:409]     Test net output #0: accuracy = 0.0906495
I0524 04:26:48.739905 19864 solver.cpp:409]     Test net output #1: loss = 2.39788 (* 1 = 2.39788 loss)
I0524 04:26:48.767858 19864 solver.cpp:237] Iteration 0, loss = 2.39412
I0524 04:26:48.767894 19864 solver.cpp:253]     Train net output #0: loss = 2.39412 (* 1 = 2.39412 loss)
I0524 04:26:48.767912 19864 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0524 04:26:57.667934 19864 solver.cpp:237] Iteration 214, loss = 2.15367
I0524 04:26:57.667970 19864 solver.cpp:253]     Train net output #0: loss = 2.15367 (* 1 = 2.15367 loss)
I0524 04:26:57.667986 19864 sgd_solver.cpp:106] Iteration 214, lr = 0.0045
I0524 04:27:06.567492 19864 solver.cpp:237] Iteration 428, loss = 1.96855
I0524 04:27:06.567528 19864 solver.cpp:253]     Train net output #0: loss = 1.96855 (* 1 = 1.96855 loss)
I0524 04:27:06.567544 19864 sgd_solver.cpp:106] Iteration 428, lr = 0.0045
I0524 04:27:15.467717 19864 solver.cpp:237] Iteration 642, loss = 2.03209
I0524 04:27:15.467754 19864 solver.cpp:253]     Train net output #0: loss = 2.03209 (* 1 = 2.03209 loss)
I0524 04:27:15.467768 19864 sgd_solver.cpp:106] Iteration 642, lr = 0.0045
I0524 04:27:24.361956 19864 solver.cpp:237] Iteration 856, loss = 1.72126
I0524 04:27:24.362104 19864 solver.cpp:253]     Train net output #0: loss = 1.72126 (* 1 = 1.72126 loss)
I0524 04:27:24.362118 19864 sgd_solver.cpp:106] Iteration 856, lr = 0.0045
I0524 04:27:33.254161 19864 solver.cpp:237] Iteration 1070, loss = 1.70619
I0524 04:27:33.254206 19864 solver.cpp:253]     Train net output #0: loss = 1.70619 (* 1 = 1.70619 loss)
I0524 04:27:33.254225 19864 sgd_solver.cpp:106] Iteration 1070, lr = 0.0045
I0524 04:27:42.153002 19864 solver.cpp:237] Iteration 1284, loss = 1.75688
I0524 04:27:42.153038 19864 solver.cpp:253]     Train net output #0: loss = 1.75688 (* 1 = 1.75688 loss)
I0524 04:27:42.153054 19864 sgd_solver.cpp:106] Iteration 1284, lr = 0.0045
I0524 04:28:13.158044 19864 solver.cpp:237] Iteration 1498, loss = 1.7808
I0524 04:28:13.158205 19864 solver.cpp:253]     Train net output #0: loss = 1.7808 (* 1 = 1.7808 loss)
I0524 04:28:13.158218 19864 sgd_solver.cpp:106] Iteration 1498, lr = 0.0045
I0524 04:28:22.059844 19864 solver.cpp:237] Iteration 1712, loss = 1.4526
I0524 04:28:22.059888 19864 solver.cpp:253]     Train net output #0: loss = 1.4526 (* 1 = 1.4526 loss)
I0524 04:28:22.059906 19864 sgd_solver.cpp:106] Iteration 1712, lr = 0.0045
I0524 04:28:30.959393 19864 solver.cpp:237] Iteration 1926, loss = 1.62078
I0524 04:28:30.959427 19864 solver.cpp:253]     Train net output #0: loss = 1.62078 (* 1 = 1.62078 loss)
I0524 04:28:30.959444 19864 sgd_solver.cpp:106] Iteration 1926, lr = 0.0045
I0524 04:28:39.859112 19864 solver.cpp:237] Iteration 2140, loss = 1.65182
I0524 04:28:39.859148 19864 solver.cpp:253]     Train net output #0: loss = 1.65182 (* 1 = 1.65182 loss)
I0524 04:28:39.859165 19864 sgd_solver.cpp:106] Iteration 2140, lr = 0.0045
I0524 04:28:39.901403 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_2142.caffemodel
I0524 04:28:39.971987 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_2142.solverstate
I0524 04:28:48.830574 19864 solver.cpp:237] Iteration 2354, loss = 1.72179
I0524 04:28:48.830731 19864 solver.cpp:253]     Train net output #0: loss = 1.72179 (* 1 = 1.72179 loss)
I0524 04:28:48.830745 19864 sgd_solver.cpp:106] Iteration 2354, lr = 0.0045
I0524 04:28:57.722997 19864 solver.cpp:237] Iteration 2568, loss = 1.50055
I0524 04:28:57.723031 19864 solver.cpp:253]     Train net output #0: loss = 1.50055 (* 1 = 1.50055 loss)
I0524 04:28:57.723048 19864 sgd_solver.cpp:106] Iteration 2568, lr = 0.0045
I0524 04:29:06.614037 19864 solver.cpp:237] Iteration 2782, loss = 1.63512
I0524 04:29:06.614071 19864 solver.cpp:253]     Train net output #0: loss = 1.63512 (* 1 = 1.63512 loss)
I0524 04:29:06.614087 19864 sgd_solver.cpp:106] Iteration 2782, lr = 0.0045
I0524 04:29:37.650487 19864 solver.cpp:237] Iteration 2996, loss = 1.48503
I0524 04:29:37.650642 19864 solver.cpp:253]     Train net output #0: loss = 1.48503 (* 1 = 1.48503 loss)
I0524 04:29:37.650656 19864 sgd_solver.cpp:106] Iteration 2996, lr = 0.0045
I0524 04:29:46.554368 19864 solver.cpp:237] Iteration 3210, loss = 1.68147
I0524 04:29:46.554402 19864 solver.cpp:253]     Train net output #0: loss = 1.68147 (* 1 = 1.68147 loss)
I0524 04:29:46.554419 19864 sgd_solver.cpp:106] Iteration 3210, lr = 0.0045
I0524 04:29:55.454339 19864 solver.cpp:237] Iteration 3424, loss = 1.24807
I0524 04:29:55.454375 19864 solver.cpp:253]     Train net output #0: loss = 1.24807 (* 1 = 1.24807 loss)
I0524 04:29:55.454390 19864 sgd_solver.cpp:106] Iteration 3424, lr = 0.0045
I0524 04:30:04.351394 19864 solver.cpp:237] Iteration 3638, loss = 1.35449
I0524 04:30:04.351436 19864 solver.cpp:253]     Train net output #0: loss = 1.35449 (* 1 = 1.35449 loss)
I0524 04:30:04.351454 19864 sgd_solver.cpp:106] Iteration 3638, lr = 0.0045
I0524 04:30:13.251838 19864 solver.cpp:237] Iteration 3852, loss = 1.43357
I0524 04:30:13.251983 19864 solver.cpp:253]     Train net output #0: loss = 1.43357 (* 1 = 1.43357 loss)
I0524 04:30:13.251996 19864 sgd_solver.cpp:106] Iteration 3852, lr = 0.0045
I0524 04:30:22.158453 19864 solver.cpp:237] Iteration 4066, loss = 1.60271
I0524 04:30:22.158488 19864 solver.cpp:253]     Train net output #0: loss = 1.60271 (* 1 = 1.60271 loss)
I0524 04:30:22.158505 19864 sgd_solver.cpp:106] Iteration 4066, lr = 0.0045
I0524 04:30:31.055929 19864 solver.cpp:237] Iteration 4280, loss = 1.11575
I0524 04:30:31.055966 19864 solver.cpp:253]     Train net output #0: loss = 1.11575 (* 1 = 1.11575 loss)
I0524 04:30:31.055989 19864 sgd_solver.cpp:106] Iteration 4280, lr = 0.0045
I0524 04:30:31.181916 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_4284.caffemodel
I0524 04:30:31.248158 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_4284.solverstate
I0524 04:30:31.287820 19864 solver.cpp:341] Iteration 4285, Testing net (#0)
I0524 04:31:19.194548 19864 solver.cpp:409]     Test net output #0: accuracy = 0.798569
I0524 04:31:19.194706 19864 solver.cpp:409]     Test net output #1: loss = 0.729455 (* 1 = 0.729455 loss)
I0524 04:31:49.985745 19864 solver.cpp:237] Iteration 4494, loss = 1.51134
I0524 04:31:49.985898 19864 solver.cpp:253]     Train net output #0: loss = 1.51134 (* 1 = 1.51134 loss)
I0524 04:31:49.985913 19864 sgd_solver.cpp:106] Iteration 4494, lr = 0.0045
I0524 04:31:58.864167 19864 solver.cpp:237] Iteration 4708, loss = 1.24431
I0524 04:31:58.864202 19864 solver.cpp:253]     Train net output #0: loss = 1.24431 (* 1 = 1.24431 loss)
I0524 04:31:58.864217 19864 sgd_solver.cpp:106] Iteration 4708, lr = 0.0045
I0524 04:32:07.740023 19864 solver.cpp:237] Iteration 4922, loss = 1.26286
I0524 04:32:07.740069 19864 solver.cpp:253]     Train net output #0: loss = 1.26286 (* 1 = 1.26286 loss)
I0524 04:32:07.740085 19864 sgd_solver.cpp:106] Iteration 4922, lr = 0.0045
I0524 04:32:16.610143 19864 solver.cpp:237] Iteration 5136, loss = 1.36867
I0524 04:32:16.610178 19864 solver.cpp:253]     Train net output #0: loss = 1.36867 (* 1 = 1.36867 loss)
I0524 04:32:16.610194 19864 sgd_solver.cpp:106] Iteration 5136, lr = 0.0045
I0524 04:32:25.488047 19864 solver.cpp:237] Iteration 5350, loss = 1.5745
I0524 04:32:25.488183 19864 solver.cpp:253]     Train net output #0: loss = 1.5745 (* 1 = 1.5745 loss)
I0524 04:32:25.488196 19864 sgd_solver.cpp:106] Iteration 5350, lr = 0.0045
I0524 04:32:34.356642 19864 solver.cpp:237] Iteration 5564, loss = 1.29038
I0524 04:32:34.356681 19864 solver.cpp:253]     Train net output #0: loss = 1.29038 (* 1 = 1.29038 loss)
I0524 04:32:34.356701 19864 sgd_solver.cpp:106] Iteration 5564, lr = 0.0045
I0524 04:33:05.359076 19864 solver.cpp:237] Iteration 5778, loss = 1.48511
I0524 04:33:05.359241 19864 solver.cpp:253]     Train net output #0: loss = 1.48511 (* 1 = 1.48511 loss)
I0524 04:33:05.359256 19864 sgd_solver.cpp:106] Iteration 5778, lr = 0.0045
I0524 04:33:14.231752 19864 solver.cpp:237] Iteration 5992, loss = 1.09084
I0524 04:33:14.231787 19864 solver.cpp:253]     Train net output #0: loss = 1.09084 (* 1 = 1.09084 loss)
I0524 04:33:14.231801 19864 sgd_solver.cpp:106] Iteration 5992, lr = 0.0045
I0524 04:33:23.103013 19864 solver.cpp:237] Iteration 6206, loss = 1.44366
I0524 04:33:23.103061 19864 solver.cpp:253]     Train net output #0: loss = 1.44366 (* 1 = 1.44366 loss)
I0524 04:33:23.103075 19864 sgd_solver.cpp:106] Iteration 6206, lr = 0.0045
I0524 04:33:31.970026 19864 solver.cpp:237] Iteration 6420, loss = 1.26166
I0524 04:33:31.970062 19864 solver.cpp:253]     Train net output #0: loss = 1.26166 (* 1 = 1.26166 loss)
I0524 04:33:31.970077 19864 sgd_solver.cpp:106] Iteration 6420, lr = 0.0045
I0524 04:33:32.177264 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_6426.caffemodel
I0524 04:33:32.246459 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_6426.solverstate
I0524 04:33:40.915870 19864 solver.cpp:237] Iteration 6634, loss = 1.47973
I0524 04:33:40.916039 19864 solver.cpp:253]     Train net output #0: loss = 1.47973 (* 1 = 1.47973 loss)
I0524 04:33:40.916054 19864 sgd_solver.cpp:106] Iteration 6634, lr = 0.0045
I0524 04:33:49.793483 19864 solver.cpp:237] Iteration 6848, loss = 1.05143
I0524 04:33:49.793526 19864 solver.cpp:253]     Train net output #0: loss = 1.05143 (* 1 = 1.05143 loss)
I0524 04:33:49.793545 19864 sgd_solver.cpp:106] Iteration 6848, lr = 0.0045
I0524 04:33:58.666848 19864 solver.cpp:237] Iteration 7062, loss = 1.23768
I0524 04:33:58.666884 19864 solver.cpp:253]     Train net output #0: loss = 1.23768 (* 1 = 1.23768 loss)
I0524 04:33:58.666898 19864 sgd_solver.cpp:106] Iteration 7062, lr = 0.0045
I0524 04:34:29.718091 19864 solver.cpp:237] Iteration 7276, loss = 1.55779
I0524 04:34:29.718250 19864 solver.cpp:253]     Train net output #0: loss = 1.55779 (* 1 = 1.55779 loss)
I0524 04:34:29.718266 19864 sgd_solver.cpp:106] Iteration 7276, lr = 0.0045
I0524 04:34:38.591543 19864 solver.cpp:237] Iteration 7490, loss = 1.29646
I0524 04:34:38.591584 19864 solver.cpp:253]     Train net output #0: loss = 1.29646 (* 1 = 1.29646 loss)
I0524 04:34:38.591604 19864 sgd_solver.cpp:106] Iteration 7490, lr = 0.0045
I0524 04:34:47.464443 19864 solver.cpp:237] Iteration 7704, loss = 1.5264
I0524 04:34:47.464479 19864 solver.cpp:253]     Train net output #0: loss = 1.5264 (* 1 = 1.5264 loss)
I0524 04:34:47.464495 19864 sgd_solver.cpp:106] Iteration 7704, lr = 0.0045
I0524 04:34:56.338156 19864 solver.cpp:237] Iteration 7918, loss = 1.44054
I0524 04:34:56.338191 19864 solver.cpp:253]     Train net output #0: loss = 1.44054 (* 1 = 1.44054 loss)
I0524 04:34:56.338207 19864 sgd_solver.cpp:106] Iteration 7918, lr = 0.0045
I0524 04:35:05.212796 19864 solver.cpp:237] Iteration 8132, loss = 1.33201
I0524 04:35:05.212960 19864 solver.cpp:253]     Train net output #0: loss = 1.33201 (* 1 = 1.33201 loss)
I0524 04:35:05.212975 19864 sgd_solver.cpp:106] Iteration 8132, lr = 0.0045
I0524 04:35:14.085536 19864 solver.cpp:237] Iteration 8346, loss = 1.24145
I0524 04:35:14.085571 19864 solver.cpp:253]     Train net output #0: loss = 1.24145 (* 1 = 1.24145 loss)
I0524 04:35:14.085589 19864 sgd_solver.cpp:106] Iteration 8346, lr = 0.0045
I0524 04:35:22.966145 19864 solver.cpp:237] Iteration 8560, loss = 1.32569
I0524 04:35:22.966181 19864 solver.cpp:253]     Train net output #0: loss = 1.32569 (* 1 = 1.32569 loss)
I0524 04:35:22.966197 19864 sgd_solver.cpp:106] Iteration 8560, lr = 0.0045
I0524 04:35:23.256429 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_8568.caffemodel
I0524 04:35:23.325343 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_8568.solverstate
I0524 04:35:23.409266 19864 solver.cpp:341] Iteration 8570, Testing net (#0)
I0524 04:36:32.111606 19864 solver.cpp:409]     Test net output #0: accuracy = 0.839522
I0524 04:36:32.111781 19864 solver.cpp:409]     Test net output #1: loss = 0.52999 (* 1 = 0.52999 loss)
I0524 04:37:02.748843 19864 solver.cpp:237] Iteration 8774, loss = 1.23371
I0524 04:37:02.749007 19864 solver.cpp:253]     Train net output #0: loss = 1.23371 (* 1 = 1.23371 loss)
I0524 04:37:02.749022 19864 sgd_solver.cpp:106] Iteration 8774, lr = 0.0045
I0524 04:37:11.653946 19864 solver.cpp:237] Iteration 8988, loss = 1.18698
I0524 04:37:11.653987 19864 solver.cpp:253]     Train net output #0: loss = 1.18698 (* 1 = 1.18698 loss)
I0524 04:37:11.654006 19864 sgd_solver.cpp:106] Iteration 8988, lr = 0.0045
I0524 04:37:20.555560 19864 solver.cpp:237] Iteration 9202, loss = 1.20637
I0524 04:37:20.555595 19864 solver.cpp:253]     Train net output #0: loss = 1.20637 (* 1 = 1.20637 loss)
I0524 04:37:20.555609 19864 sgd_solver.cpp:106] Iteration 9202, lr = 0.0045
I0524 04:37:29.466202 19864 solver.cpp:237] Iteration 9416, loss = 1.21176
I0524 04:37:29.466236 19864 solver.cpp:253]     Train net output #0: loss = 1.21176 (* 1 = 1.21176 loss)
I0524 04:37:29.466249 19864 sgd_solver.cpp:106] Iteration 9416, lr = 0.0045
I0524 04:37:38.368409 19864 solver.cpp:237] Iteration 9630, loss = 1.16034
I0524 04:37:38.368551 19864 solver.cpp:253]     Train net output #0: loss = 1.16034 (* 1 = 1.16034 loss)
I0524 04:37:38.368564 19864 sgd_solver.cpp:106] Iteration 9630, lr = 0.0045
I0524 04:37:47.272236 19864 solver.cpp:237] Iteration 9844, loss = 1.28714
I0524 04:37:47.272271 19864 solver.cpp:253]     Train net output #0: loss = 1.28714 (* 1 = 1.28714 loss)
I0524 04:37:47.272284 19864 sgd_solver.cpp:106] Iteration 9844, lr = 0.0045
I0524 04:38:18.354015 19864 solver.cpp:237] Iteration 10058, loss = 1.39815
I0524 04:38:18.354182 19864 solver.cpp:253]     Train net output #0: loss = 1.39815 (* 1 = 1.39815 loss)
I0524 04:38:18.354197 19864 sgd_solver.cpp:106] Iteration 10058, lr = 0.0045
I0524 04:38:27.264221 19864 solver.cpp:237] Iteration 10272, loss = 1.54815
I0524 04:38:27.264267 19864 solver.cpp:253]     Train net output #0: loss = 1.54815 (* 1 = 1.54815 loss)
I0524 04:38:27.264282 19864 sgd_solver.cpp:106] Iteration 10272, lr = 0.0045
I0524 04:38:36.174432 19864 solver.cpp:237] Iteration 10486, loss = 1.40949
I0524 04:38:36.174468 19864 solver.cpp:253]     Train net output #0: loss = 1.40949 (* 1 = 1.40949 loss)
I0524 04:38:36.174484 19864 sgd_solver.cpp:106] Iteration 10486, lr = 0.0045
I0524 04:38:45.075748 19864 solver.cpp:237] Iteration 10700, loss = 1.39396
I0524 04:38:45.075784 19864 solver.cpp:253]     Train net output #0: loss = 1.39396 (* 1 = 1.39396 loss)
I0524 04:38:45.075798 19864 sgd_solver.cpp:106] Iteration 10700, lr = 0.0045
I0524 04:38:45.451766 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_10710.caffemodel
I0524 04:38:45.520145 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_10710.solverstate
I0524 04:38:54.057082 19864 solver.cpp:237] Iteration 10914, loss = 1.39621
I0524 04:38:54.057242 19864 solver.cpp:253]     Train net output #0: loss = 1.39621 (* 1 = 1.39621 loss)
I0524 04:38:54.057257 19864 sgd_solver.cpp:106] Iteration 10914, lr = 0.0045
I0524 04:39:02.963027 19864 solver.cpp:237] Iteration 11128, loss = 1.20448
I0524 04:39:02.963062 19864 solver.cpp:253]     Train net output #0: loss = 1.20448 (* 1 = 1.20448 loss)
I0524 04:39:02.963079 19864 sgd_solver.cpp:106] Iteration 11128, lr = 0.0045
I0524 04:39:11.870815 19864 solver.cpp:237] Iteration 11342, loss = 1.25714
I0524 04:39:11.870862 19864 solver.cpp:253]     Train net output #0: loss = 1.25714 (* 1 = 1.25714 loss)
I0524 04:39:11.870880 19864 sgd_solver.cpp:106] Iteration 11342, lr = 0.0045
I0524 04:39:42.906137 19864 solver.cpp:237] Iteration 11556, loss = 1.21842
I0524 04:39:42.906308 19864 solver.cpp:253]     Train net output #0: loss = 1.21842 (* 1 = 1.21842 loss)
I0524 04:39:42.906324 19864 sgd_solver.cpp:106] Iteration 11556, lr = 0.0045
I0524 04:39:51.811089 19864 solver.cpp:237] Iteration 11770, loss = 1.09437
I0524 04:39:51.811125 19864 solver.cpp:253]     Train net output #0: loss = 1.09437 (* 1 = 1.09437 loss)
I0524 04:39:51.811142 19864 sgd_solver.cpp:106] Iteration 11770, lr = 0.0045
I0524 04:40:00.715430 19864 solver.cpp:237] Iteration 11984, loss = 1.27713
I0524 04:40:00.715464 19864 solver.cpp:253]     Train net output #0: loss = 1.27713 (* 1 = 1.27713 loss)
I0524 04:40:00.715479 19864 sgd_solver.cpp:106] Iteration 11984, lr = 0.0045
I0524 04:40:09.621594 19864 solver.cpp:237] Iteration 12198, loss = 1.08387
I0524 04:40:09.621640 19864 solver.cpp:253]     Train net output #0: loss = 1.08387 (* 1 = 1.08387 loss)
I0524 04:40:09.621656 19864 sgd_solver.cpp:106] Iteration 12198, lr = 0.0045
I0524 04:40:18.527158 19864 solver.cpp:237] Iteration 12412, loss = 1.15695
I0524 04:40:18.527302 19864 solver.cpp:253]     Train net output #0: loss = 1.15695 (* 1 = 1.15695 loss)
I0524 04:40:18.527315 19864 sgd_solver.cpp:106] Iteration 12412, lr = 0.0045
I0524 04:40:27.432574 19864 solver.cpp:237] Iteration 12626, loss = 1.35255
I0524 04:40:27.432613 19864 solver.cpp:253]     Train net output #0: loss = 1.35255 (* 1 = 1.35255 loss)
I0524 04:40:27.432632 19864 sgd_solver.cpp:106] Iteration 12626, lr = 0.0045
I0524 04:40:36.341629 19864 solver.cpp:237] Iteration 12840, loss = 1.26757
I0524 04:40:36.341665 19864 solver.cpp:253]     Train net output #0: loss = 1.26757 (* 1 = 1.26757 loss)
I0524 04:40:36.341681 19864 sgd_solver.cpp:106] Iteration 12840, lr = 0.0045
I0524 04:40:36.798606 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_12852.caffemodel
I0524 04:40:36.865564 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_12852.solverstate
I0524 04:40:36.988867 19864 solver.cpp:341] Iteration 12855, Testing net (#0)
I0524 04:41:24.585638 19864 solver.cpp:409]     Test net output #0: accuracy = 0.856417
I0524 04:41:24.585796 19864 solver.cpp:409]     Test net output #1: loss = 0.494261 (* 1 = 0.494261 loss)
I0524 04:41:55.022876 19864 solver.cpp:237] Iteration 13054, loss = 1.2113
I0524 04:41:55.023036 19864 solver.cpp:253]     Train net output #0: loss = 1.2113 (* 1 = 1.2113 loss)
I0524 04:41:55.023051 19864 sgd_solver.cpp:106] Iteration 13054, lr = 0.0045
I0524 04:42:03.917191 19864 solver.cpp:237] Iteration 13268, loss = 1.37482
I0524 04:42:03.917225 19864 solver.cpp:253]     Train net output #0: loss = 1.37482 (* 1 = 1.37482 loss)
I0524 04:42:03.917243 19864 sgd_solver.cpp:106] Iteration 13268, lr = 0.0045
I0524 04:42:12.803316 19864 solver.cpp:237] Iteration 13482, loss = 0.982446
I0524 04:42:12.803364 19864 solver.cpp:253]     Train net output #0: loss = 0.982446 (* 1 = 0.982446 loss)
I0524 04:42:12.803380 19864 sgd_solver.cpp:106] Iteration 13482, lr = 0.0045
I0524 04:42:21.698724 19864 solver.cpp:237] Iteration 13696, loss = 1.49642
I0524 04:42:21.698760 19864 solver.cpp:253]     Train net output #0: loss = 1.49642 (* 1 = 1.49642 loss)
I0524 04:42:21.698776 19864 sgd_solver.cpp:106] Iteration 13696, lr = 0.0045
I0524 04:42:30.578176 19864 solver.cpp:237] Iteration 13910, loss = 1.43269
I0524 04:42:30.578317 19864 solver.cpp:253]     Train net output #0: loss = 1.43269 (* 1 = 1.43269 loss)
I0524 04:42:30.578330 19864 sgd_solver.cpp:106] Iteration 13910, lr = 0.0045
I0524 04:42:39.467731 19864 solver.cpp:237] Iteration 14124, loss = 1.3555
I0524 04:42:39.467773 19864 solver.cpp:253]     Train net output #0: loss = 1.3555 (* 1 = 1.3555 loss)
I0524 04:42:39.467787 19864 sgd_solver.cpp:106] Iteration 14124, lr = 0.0045
I0524 04:43:10.507246 19864 solver.cpp:237] Iteration 14338, loss = 1.32045
I0524 04:43:10.507423 19864 solver.cpp:253]     Train net output #0: loss = 1.32045 (* 1 = 1.32045 loss)
I0524 04:43:10.507441 19864 sgd_solver.cpp:106] Iteration 14338, lr = 0.0045
I0524 04:43:19.398748 19864 solver.cpp:237] Iteration 14552, loss = 1.07884
I0524 04:43:19.398783 19864 solver.cpp:253]     Train net output #0: loss = 1.07884 (* 1 = 1.07884 loss)
I0524 04:43:19.398800 19864 sgd_solver.cpp:106] Iteration 14552, lr = 0.0045
I0524 04:43:28.285528 19864 solver.cpp:237] Iteration 14766, loss = 1.17333
I0524 04:43:28.285567 19864 solver.cpp:253]     Train net output #0: loss = 1.17333 (* 1 = 1.17333 loss)
I0524 04:43:28.285586 19864 sgd_solver.cpp:106] Iteration 14766, lr = 0.0045
I0524 04:43:37.176044 19864 solver.cpp:237] Iteration 14980, loss = 1.19585
I0524 04:43:37.176079 19864 solver.cpp:253]     Train net output #0: loss = 1.19585 (* 1 = 1.19585 loss)
I0524 04:43:37.176097 19864 sgd_solver.cpp:106] Iteration 14980, lr = 0.0045
I0524 04:43:37.717557 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_14994.caffemodel
I0524 04:43:37.784137 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_14994.solverstate
I0524 04:43:46.131340 19864 solver.cpp:237] Iteration 15194, loss = 1.20146
I0524 04:43:46.131497 19864 solver.cpp:253]     Train net output #0: loss = 1.20146 (* 1 = 1.20146 loss)
I0524 04:43:46.131510 19864 sgd_solver.cpp:106] Iteration 15194, lr = 0.0045
I0524 04:43:55.019542 19864 solver.cpp:237] Iteration 15408, loss = 1.27518
I0524 04:43:55.019587 19864 solver.cpp:253]     Train net output #0: loss = 1.27518 (* 1 = 1.27518 loss)
I0524 04:43:55.019604 19864 sgd_solver.cpp:106] Iteration 15408, lr = 0.0045
I0524 04:44:03.904752 19864 solver.cpp:237] Iteration 15622, loss = 1.40214
I0524 04:44:03.904786 19864 solver.cpp:253]     Train net output #0: loss = 1.40214 (* 1 = 1.40214 loss)
I0524 04:44:03.904803 19864 sgd_solver.cpp:106] Iteration 15622, lr = 0.0045
I0524 04:44:34.960512 19864 solver.cpp:237] Iteration 15836, loss = 1.13672
I0524 04:44:34.960678 19864 solver.cpp:253]     Train net output #0: loss = 1.13672 (* 1 = 1.13672 loss)
I0524 04:44:34.960692 19864 sgd_solver.cpp:106] Iteration 15836, lr = 0.0045
I0524 04:44:43.845463 19864 solver.cpp:237] Iteration 16050, loss = 1.04197
I0524 04:44:43.845506 19864 solver.cpp:253]     Train net output #0: loss = 1.04197 (* 1 = 1.04197 loss)
I0524 04:44:43.845526 19864 sgd_solver.cpp:106] Iteration 16050, lr = 0.0045
I0524 04:44:52.731293 19864 solver.cpp:237] Iteration 16264, loss = 1.05868
I0524 04:44:52.731328 19864 solver.cpp:253]     Train net output #0: loss = 1.05868 (* 1 = 1.05868 loss)
I0524 04:44:52.731343 19864 sgd_solver.cpp:106] Iteration 16264, lr = 0.0045
I0524 04:45:01.617549 19864 solver.cpp:237] Iteration 16478, loss = 1.04122
I0524 04:45:01.617585 19864 solver.cpp:253]     Train net output #0: loss = 1.04122 (* 1 = 1.04122 loss)
I0524 04:45:01.617602 19864 sgd_solver.cpp:106] Iteration 16478, lr = 0.0045
I0524 04:45:10.513376 19864 solver.cpp:237] Iteration 16692, loss = 1.2218
I0524 04:45:10.513531 19864 solver.cpp:253]     Train net output #0: loss = 1.2218 (* 1 = 1.2218 loss)
I0524 04:45:10.513545 19864 sgd_solver.cpp:106] Iteration 16692, lr = 0.0045
I0524 04:45:19.400663 19864 solver.cpp:237] Iteration 16906, loss = 1.15602
I0524 04:45:19.400698 19864 solver.cpp:253]     Train net output #0: loss = 1.15602 (* 1 = 1.15602 loss)
I0524 04:45:19.400714 19864 sgd_solver.cpp:106] Iteration 16906, lr = 0.0045
I0524 04:45:28.295383 19864 solver.cpp:237] Iteration 17120, loss = 1.20702
I0524 04:45:28.295426 19864 solver.cpp:253]     Train net output #0: loss = 1.20702 (* 1 = 1.20702 loss)
I0524 04:45:28.295446 19864 sgd_solver.cpp:106] Iteration 17120, lr = 0.0045
I0524 04:45:28.919056 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_17136.caffemodel
I0524 04:45:28.986222 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_17136.solverstate
I0524 04:45:29.150832 19864 solver.cpp:341] Iteration 17140, Testing net (#0)
I0524 04:46:37.992596 19864 solver.cpp:409]     Test net output #0: accuracy = 0.863245
I0524 04:46:37.992763 19864 solver.cpp:409]     Test net output #1: loss = 0.430661 (* 1 = 0.430661 loss)
I0524 04:47:08.206017 19864 solver.cpp:237] Iteration 17334, loss = 1.26903
I0524 04:47:08.206181 19864 solver.cpp:253]     Train net output #0: loss = 1.26903 (* 1 = 1.26903 loss)
I0524 04:47:08.206197 19864 sgd_solver.cpp:106] Iteration 17334, lr = 0.0045
I0524 04:47:17.091024 19864 solver.cpp:237] Iteration 17548, loss = 1.26437
I0524 04:47:17.091058 19864 solver.cpp:253]     Train net output #0: loss = 1.26437 (* 1 = 1.26437 loss)
I0524 04:47:17.091076 19864 sgd_solver.cpp:106] Iteration 17548, lr = 0.0045
I0524 04:47:25.984992 19864 solver.cpp:237] Iteration 17762, loss = 1.38437
I0524 04:47:25.985028 19864 solver.cpp:253]     Train net output #0: loss = 1.38437 (* 1 = 1.38437 loss)
I0524 04:47:25.985044 19864 sgd_solver.cpp:106] Iteration 17762, lr = 0.0045
I0524 04:47:34.869580 19864 solver.cpp:237] Iteration 17976, loss = 1.23301
I0524 04:47:34.869623 19864 solver.cpp:253]     Train net output #0: loss = 1.23301 (* 1 = 1.23301 loss)
I0524 04:47:34.869642 19864 sgd_solver.cpp:106] Iteration 17976, lr = 0.0045
I0524 04:47:43.756537 19864 solver.cpp:237] Iteration 18190, loss = 1.30938
I0524 04:47:43.756681 19864 solver.cpp:253]     Train net output #0: loss = 1.30938 (* 1 = 1.30938 loss)
I0524 04:47:43.756695 19864 sgd_solver.cpp:106] Iteration 18190, lr = 0.0045
I0524 04:47:52.643133 19864 solver.cpp:237] Iteration 18404, loss = 1.11197
I0524 04:47:52.643168 19864 solver.cpp:253]     Train net output #0: loss = 1.11197 (* 1 = 1.11197 loss)
I0524 04:47:52.643185 19864 sgd_solver.cpp:106] Iteration 18404, lr = 0.0045
I0524 04:48:23.653383 19864 solver.cpp:237] Iteration 18618, loss = 1.07932
I0524 04:48:23.653553 19864 solver.cpp:253]     Train net output #0: loss = 1.07932 (* 1 = 1.07932 loss)
I0524 04:48:23.653568 19864 sgd_solver.cpp:106] Iteration 18618, lr = 0.0045
I0524 04:48:32.539855 19864 solver.cpp:237] Iteration 18832, loss = 1.08116
I0524 04:48:32.539890 19864 solver.cpp:253]     Train net output #0: loss = 1.08116 (* 1 = 1.08116 loss)
I0524 04:48:32.539906 19864 sgd_solver.cpp:106] Iteration 18832, lr = 0.0045
I0524 04:48:41.433995 19864 solver.cpp:237] Iteration 19046, loss = 1.20169
I0524 04:48:41.434029 19864 solver.cpp:253]     Train net output #0: loss = 1.20169 (* 1 = 1.20169 loss)
I0524 04:48:41.434046 19864 sgd_solver.cpp:106] Iteration 19046, lr = 0.0045
I0524 04:48:50.319741 19864 solver.cpp:237] Iteration 19260, loss = 1.06628
I0524 04:48:50.319788 19864 solver.cpp:253]     Train net output #0: loss = 1.06628 (* 1 = 1.06628 loss)
I0524 04:48:50.319807 19864 sgd_solver.cpp:106] Iteration 19260, lr = 0.0045
I0524 04:48:51.026406 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_19278.caffemodel
I0524 04:48:51.095026 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_19278.solverstate
I0524 04:48:59.278803 19864 solver.cpp:237] Iteration 19474, loss = 1.32384
I0524 04:48:59.278967 19864 solver.cpp:253]     Train net output #0: loss = 1.32384 (* 1 = 1.32384 loss)
I0524 04:48:59.278981 19864 sgd_solver.cpp:106] Iteration 19474, lr = 0.0045
I0524 04:49:08.171476 19864 solver.cpp:237] Iteration 19688, loss = 1.14747
I0524 04:49:08.171510 19864 solver.cpp:253]     Train net output #0: loss = 1.14747 (* 1 = 1.14747 loss)
I0524 04:49:08.171524 19864 sgd_solver.cpp:106] Iteration 19688, lr = 0.0045
I0524 04:49:17.055364 19864 solver.cpp:237] Iteration 19902, loss = 1.05292
I0524 04:49:17.055408 19864 solver.cpp:253]     Train net output #0: loss = 1.05292 (* 1 = 1.05292 loss)
I0524 04:49:17.055423 19864 sgd_solver.cpp:106] Iteration 19902, lr = 0.0045
I0524 04:49:48.105126 19864 solver.cpp:237] Iteration 20116, loss = 1.09636
I0524 04:49:48.105298 19864 solver.cpp:253]     Train net output #0: loss = 1.09636 (* 1 = 1.09636 loss)
I0524 04:49:48.105314 19864 sgd_solver.cpp:106] Iteration 20116, lr = 0.0045
I0524 04:49:56.995527 19864 solver.cpp:237] Iteration 20330, loss = 1.27289
I0524 04:49:56.995561 19864 solver.cpp:253]     Train net output #0: loss = 1.27289 (* 1 = 1.27289 loss)
I0524 04:49:56.995579 19864 sgd_solver.cpp:106] Iteration 20330, lr = 0.0045
I0524 04:50:05.880878 19864 solver.cpp:237] Iteration 20544, loss = 1.16701
I0524 04:50:05.880924 19864 solver.cpp:253]     Train net output #0: loss = 1.16701 (* 1 = 1.16701 loss)
I0524 04:50:05.880941 19864 sgd_solver.cpp:106] Iteration 20544, lr = 0.0045
I0524 04:50:14.771481 19864 solver.cpp:237] Iteration 20758, loss = 1.16348
I0524 04:50:14.771515 19864 solver.cpp:253]     Train net output #0: loss = 1.16348 (* 1 = 1.16348 loss)
I0524 04:50:14.771529 19864 sgd_solver.cpp:106] Iteration 20758, lr = 0.0045
I0524 04:50:23.658249 19864 solver.cpp:237] Iteration 20972, loss = 1.22548
I0524 04:50:23.658393 19864 solver.cpp:253]     Train net output #0: loss = 1.22548 (* 1 = 1.22548 loss)
I0524 04:50:23.658407 19864 sgd_solver.cpp:106] Iteration 20972, lr = 0.0045
I0524 04:50:32.552507 19864 solver.cpp:237] Iteration 21186, loss = 1.05553
I0524 04:50:32.552554 19864 solver.cpp:253]     Train net output #0: loss = 1.05553 (* 1 = 1.05553 loss)
I0524 04:50:32.552572 19864 sgd_solver.cpp:106] Iteration 21186, lr = 0.0045
I0524 04:50:41.444222 19864 solver.cpp:237] Iteration 21400, loss = 1.08533
I0524 04:50:41.444258 19864 solver.cpp:253]     Train net output #0: loss = 1.08533 (* 1 = 1.08533 loss)
I0524 04:50:41.444275 19864 sgd_solver.cpp:106] Iteration 21400, lr = 0.0045
I0524 04:50:42.232466 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_21420.caffemodel
I0524 04:50:42.300775 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_21420.solverstate
I0524 04:50:42.509775 19864 solver.cpp:341] Iteration 21425, Testing net (#0)
I0524 04:51:30.463449 19864 solver.cpp:409]     Test net output #0: accuracy = 0.869755
I0524 04:51:30.463611 19864 solver.cpp:409]     Test net output #1: loss = 0.448096 (* 1 = 0.448096 loss)
I0524 04:51:59.252045 19864 solver.cpp:237] Iteration 21614, loss = 1.13997
I0524 04:51:59.252096 19864 solver.cpp:253]     Train net output #0: loss = 1.13997 (* 1 = 1.13997 loss)
I0524 04:51:59.252112 19864 sgd_solver.cpp:106] Iteration 21614, lr = 0.0045
I0524 04:52:08.137055 19864 solver.cpp:237] Iteration 21828, loss = 1.22295
I0524 04:52:08.137220 19864 solver.cpp:253]     Train net output #0: loss = 1.22295 (* 1 = 1.22295 loss)
I0524 04:52:08.137234 19864 sgd_solver.cpp:106] Iteration 21828, lr = 0.0045
I0524 04:52:17.026023 19864 solver.cpp:237] Iteration 22042, loss = 1.27322
I0524 04:52:17.026058 19864 solver.cpp:253]     Train net output #0: loss = 1.27322 (* 1 = 1.27322 loss)
I0524 04:52:17.026077 19864 sgd_solver.cpp:106] Iteration 22042, lr = 0.0045
I0524 04:52:25.915566 19864 solver.cpp:237] Iteration 22256, loss = 1.26193
I0524 04:52:25.915602 19864 solver.cpp:253]     Train net output #0: loss = 1.26193 (* 1 = 1.26193 loss)
I0524 04:52:25.915616 19864 sgd_solver.cpp:106] Iteration 22256, lr = 0.0045
I0524 04:52:34.804215 19864 solver.cpp:237] Iteration 22470, loss = 1.0318
I0524 04:52:34.804260 19864 solver.cpp:253]     Train net output #0: loss = 1.0318 (* 1 = 1.0318 loss)
I0524 04:52:34.804276 19864 sgd_solver.cpp:106] Iteration 22470, lr = 0.0045
I0524 04:52:43.691243 19864 solver.cpp:237] Iteration 22684, loss = 0.955954
I0524 04:52:43.691402 19864 solver.cpp:253]     Train net output #0: loss = 0.955954 (* 1 = 0.955954 loss)
I0524 04:52:43.691418 19864 sgd_solver.cpp:106] Iteration 22684, lr = 0.0045
I0524 04:53:13.448561 19864 solver.cpp:237] Iteration 22898, loss = 1.18063
I0524 04:53:13.448611 19864 solver.cpp:253]     Train net output #0: loss = 1.18063 (* 1 = 1.18063 loss)
I0524 04:53:13.448629 19864 sgd_solver.cpp:106] Iteration 22898, lr = 0.0045
I0524 04:53:22.336450 19864 solver.cpp:237] Iteration 23112, loss = 1.36437
I0524 04:53:22.336609 19864 solver.cpp:253]     Train net output #0: loss = 1.36437 (* 1 = 1.36437 loss)
I0524 04:53:22.336623 19864 sgd_solver.cpp:106] Iteration 23112, lr = 0.0045
I0524 04:53:31.224220 19864 solver.cpp:237] Iteration 23326, loss = 1.23405
I0524 04:53:31.224256 19864 solver.cpp:253]     Train net output #0: loss = 1.23405 (* 1 = 1.23405 loss)
I0524 04:53:31.224269 19864 sgd_solver.cpp:106] Iteration 23326, lr = 0.0045
I0524 04:53:40.111744 19864 solver.cpp:237] Iteration 23540, loss = 1.13274
I0524 04:53:40.111780 19864 solver.cpp:253]     Train net output #0: loss = 1.13274 (* 1 = 1.13274 loss)
I0524 04:53:40.111796 19864 sgd_solver.cpp:106] Iteration 23540, lr = 0.0045
I0524 04:53:40.986227 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_23562.caffemodel
I0524 04:53:41.052956 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_23562.solverstate
I0524 04:53:49.065078 19864 solver.cpp:237] Iteration 23754, loss = 1.11335
I0524 04:53:49.065127 19864 solver.cpp:253]     Train net output #0: loss = 1.11335 (* 1 = 1.11335 loss)
I0524 04:53:49.065146 19864 sgd_solver.cpp:106] Iteration 23754, lr = 0.0045
I0524 04:53:57.955338 19864 solver.cpp:237] Iteration 23968, loss = 1.10192
I0524 04:53:57.955487 19864 solver.cpp:253]     Train net output #0: loss = 1.10192 (* 1 = 1.10192 loss)
I0524 04:53:57.955502 19864 sgd_solver.cpp:106] Iteration 23968, lr = 0.0045
I0524 04:54:06.845125 19864 solver.cpp:237] Iteration 24182, loss = 1.18946
I0524 04:54:06.845160 19864 solver.cpp:253]     Train net output #0: loss = 1.18946 (* 1 = 1.18946 loss)
I0524 04:54:06.845175 19864 sgd_solver.cpp:106] Iteration 24182, lr = 0.0045
I0524 04:54:36.629389 19864 solver.cpp:237] Iteration 24396, loss = 1.15864
I0524 04:54:36.629555 19864 solver.cpp:253]     Train net output #0: loss = 1.15864 (* 1 = 1.15864 loss)
I0524 04:54:36.629571 19864 sgd_solver.cpp:106] Iteration 24396, lr = 0.0045
I0524 04:54:45.521169 19864 solver.cpp:237] Iteration 24610, loss = 1.17934
I0524 04:54:45.521211 19864 solver.cpp:253]     Train net output #0: loss = 1.17934 (* 1 = 1.17934 loss)
I0524 04:54:45.521230 19864 sgd_solver.cpp:106] Iteration 24610, lr = 0.0045
I0524 04:54:54.405799 19864 solver.cpp:237] Iteration 24824, loss = 1.06449
I0524 04:54:54.405834 19864 solver.cpp:253]     Train net output #0: loss = 1.06449 (* 1 = 1.06449 loss)
I0524 04:54:54.405851 19864 sgd_solver.cpp:106] Iteration 24824, lr = 0.0045
I0524 04:55:03.300768 19864 solver.cpp:237] Iteration 25038, loss = 0.869763
I0524 04:55:03.300808 19864 solver.cpp:253]     Train net output #0: loss = 0.869763 (* 1 = 0.869763 loss)
I0524 04:55:03.300824 19864 sgd_solver.cpp:106] Iteration 25038, lr = 0.0045
I0524 04:55:12.187222 19864 solver.cpp:237] Iteration 25252, loss = 1.22904
I0524 04:55:12.187368 19864 solver.cpp:253]     Train net output #0: loss = 1.22904 (* 1 = 1.22904 loss)
I0524 04:55:12.187382 19864 sgd_solver.cpp:106] Iteration 25252, lr = 0.0045
I0524 04:55:21.081084 19864 solver.cpp:237] Iteration 25466, loss = 1.12628
I0524 04:55:21.081118 19864 solver.cpp:253]     Train net output #0: loss = 1.12628 (* 1 = 1.12628 loss)
I0524 04:55:21.081132 19864 sgd_solver.cpp:106] Iteration 25466, lr = 0.0045
I0524 04:55:29.974407 19864 solver.cpp:237] Iteration 25680, loss = 1.22785
I0524 04:55:29.974453 19864 solver.cpp:253]     Train net output #0: loss = 1.22785 (* 1 = 1.22785 loss)
I0524 04:55:29.974470 19864 sgd_solver.cpp:106] Iteration 25680, lr = 0.0045
I0524 04:55:30.930146 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_25704.caffemodel
I0524 04:55:30.996462 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_25704.solverstate
I0524 04:55:31.245690 19864 solver.cpp:341] Iteration 25710, Testing net (#0)
I0524 04:56:40.073997 19864 solver.cpp:409]     Test net output #0: accuracy = 0.863372
I0524 04:56:40.074175 19864 solver.cpp:409]     Test net output #1: loss = 0.419647 (* 1 = 0.419647 loss)
I0524 04:57:08.601187 19864 solver.cpp:237] Iteration 25894, loss = 1.19424
I0524 04:57:08.601235 19864 solver.cpp:253]     Train net output #0: loss = 1.19424 (* 1 = 1.19424 loss)
I0524 04:57:08.601253 19864 sgd_solver.cpp:106] Iteration 25894, lr = 0.0045
I0524 04:57:17.486006 19864 solver.cpp:237] Iteration 26108, loss = 1.53839
I0524 04:57:17.486156 19864 solver.cpp:253]     Train net output #0: loss = 1.53839 (* 1 = 1.53839 loss)
I0524 04:57:17.486171 19864 sgd_solver.cpp:106] Iteration 26108, lr = 0.0045
I0524 04:57:26.366204 19864 solver.cpp:237] Iteration 26322, loss = 1.31286
I0524 04:57:26.366238 19864 solver.cpp:253]     Train net output #0: loss = 1.31286 (* 1 = 1.31286 loss)
I0524 04:57:26.366252 19864 sgd_solver.cpp:106] Iteration 26322, lr = 0.0045
I0524 04:57:35.238698 19864 solver.cpp:237] Iteration 26536, loss = 1.07613
I0524 04:57:35.238739 19864 solver.cpp:253]     Train net output #0: loss = 1.07613 (* 1 = 1.07613 loss)
I0524 04:57:35.238755 19864 sgd_solver.cpp:106] Iteration 26536, lr = 0.0045
I0524 04:57:44.119307 19864 solver.cpp:237] Iteration 26750, loss = 1.37929
I0524 04:57:44.119341 19864 solver.cpp:253]     Train net output #0: loss = 1.37929 (* 1 = 1.37929 loss)
I0524 04:57:44.119359 19864 sgd_solver.cpp:106] Iteration 26750, lr = 0.0045
I0524 04:57:52.999533 19864 solver.cpp:237] Iteration 26964, loss = 1.31297
I0524 04:57:52.999701 19864 solver.cpp:253]     Train net output #0: loss = 1.31297 (* 1 = 1.31297 loss)
I0524 04:57:52.999714 19864 sgd_solver.cpp:106] Iteration 26964, lr = 0.0045
I0524 04:58:22.773300 19864 solver.cpp:237] Iteration 27178, loss = 1.04961
I0524 04:58:22.773350 19864 solver.cpp:253]     Train net output #0: loss = 1.04961 (* 1 = 1.04961 loss)
I0524 04:58:22.773365 19864 sgd_solver.cpp:106] Iteration 27178, lr = 0.0045
I0524 04:58:31.649722 19864 solver.cpp:237] Iteration 27392, loss = 0.911576
I0524 04:58:31.649878 19864 solver.cpp:253]     Train net output #0: loss = 0.911576 (* 1 = 0.911576 loss)
I0524 04:58:31.649891 19864 sgd_solver.cpp:106] Iteration 27392, lr = 0.0045
I0524 04:58:40.529685 19864 solver.cpp:237] Iteration 27606, loss = 1.14054
I0524 04:58:40.529721 19864 solver.cpp:253]     Train net output #0: loss = 1.14054 (* 1 = 1.14054 loss)
I0524 04:58:40.529737 19864 sgd_solver.cpp:106] Iteration 27606, lr = 0.0045
I0524 04:58:49.406811 19864 solver.cpp:237] Iteration 27820, loss = 1.24242
I0524 04:58:49.406852 19864 solver.cpp:253]     Train net output #0: loss = 1.24242 (* 1 = 1.24242 loss)
I0524 04:58:49.406872 19864 sgd_solver.cpp:106] Iteration 27820, lr = 0.0045
I0524 04:58:50.445389 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_27846.caffemodel
I0524 04:58:50.512075 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_27846.solverstate
I0524 04:58:58.344972 19864 solver.cpp:237] Iteration 28034, loss = 1.10882
I0524 04:58:58.345019 19864 solver.cpp:253]     Train net output #0: loss = 1.10882 (* 1 = 1.10882 loss)
I0524 04:58:58.345034 19864 sgd_solver.cpp:106] Iteration 28034, lr = 0.0045
I0524 04:59:07.221938 19864 solver.cpp:237] Iteration 28248, loss = 1.26584
I0524 04:59:07.222108 19864 solver.cpp:253]     Train net output #0: loss = 1.26584 (* 1 = 1.26584 loss)
I0524 04:59:07.222123 19864 sgd_solver.cpp:106] Iteration 28248, lr = 0.0045
I0524 04:59:16.094997 19864 solver.cpp:237] Iteration 28462, loss = 1.13063
I0524 04:59:16.095039 19864 solver.cpp:253]     Train net output #0: loss = 1.13063 (* 1 = 1.13063 loss)
I0524 04:59:16.095052 19864 sgd_solver.cpp:106] Iteration 28462, lr = 0.0045
I0524 04:59:45.873725 19864 solver.cpp:237] Iteration 28676, loss = 1.16333
I0524 04:59:45.873895 19864 solver.cpp:253]     Train net output #0: loss = 1.16333 (* 1 = 1.16333 loss)
I0524 04:59:45.873909 19864 sgd_solver.cpp:106] Iteration 28676, lr = 0.0045
I0524 04:59:54.760162 19864 solver.cpp:237] Iteration 28890, loss = 1.14415
I0524 04:59:54.760196 19864 solver.cpp:253]     Train net output #0: loss = 1.14415 (* 1 = 1.14415 loss)
I0524 04:59:54.760213 19864 sgd_solver.cpp:106] Iteration 28890, lr = 0.0045
I0524 05:00:03.638897 19864 solver.cpp:237] Iteration 29104, loss = 1.08385
I0524 05:00:03.638944 19864 solver.cpp:253]     Train net output #0: loss = 1.08385 (* 1 = 1.08385 loss)
I0524 05:00:03.638959 19864 sgd_solver.cpp:106] Iteration 29104, lr = 0.0045
I0524 05:00:12.522310 19864 solver.cpp:237] Iteration 29318, loss = 1.42657
I0524 05:00:12.522346 19864 solver.cpp:253]     Train net output #0: loss = 1.42657 (* 1 = 1.42657 loss)
I0524 05:00:12.522362 19864 sgd_solver.cpp:106] Iteration 29318, lr = 0.0045
I0524 05:00:21.395082 19864 solver.cpp:237] Iteration 29532, loss = 1.05876
I0524 05:00:21.395231 19864 solver.cpp:253]     Train net output #0: loss = 1.05876 (* 1 = 1.05876 loss)
I0524 05:00:21.395244 19864 sgd_solver.cpp:106] Iteration 29532, lr = 0.0045
I0524 05:00:30.271116 19864 solver.cpp:237] Iteration 29746, loss = 1.15641
I0524 05:00:30.271160 19864 solver.cpp:253]     Train net output #0: loss = 1.15641 (* 1 = 1.15641 loss)
I0524 05:00:30.271176 19864 sgd_solver.cpp:106] Iteration 29746, lr = 0.0045
I0524 05:00:39.151278 19864 solver.cpp:237] Iteration 29960, loss = 1.14901
I0524 05:00:39.151314 19864 solver.cpp:253]     Train net output #0: loss = 1.14901 (* 1 = 1.14901 loss)
I0524 05:00:39.151327 19864 sgd_solver.cpp:106] Iteration 29960, lr = 0.0045
I0524 05:00:40.273062 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_29988.caffemodel
I0524 05:00:40.339932 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_29988.solverstate
I0524 05:00:40.628444 19864 solver.cpp:341] Iteration 29995, Testing net (#0)
I0524 05:01:28.267221 19864 solver.cpp:409]     Test net output #0: accuracy = 0.876017
I0524 05:01:28.267386 19864 solver.cpp:409]     Test net output #1: loss = 0.407084 (* 1 = 0.407084 loss)
I0524 05:01:56.629657 19864 solver.cpp:237] Iteration 30174, loss = 1.05932
I0524 05:01:56.629703 19864 solver.cpp:253]     Train net output #0: loss = 1.05932 (* 1 = 1.05932 loss)
I0524 05:01:56.629716 19864 sgd_solver.cpp:106] Iteration 30174, lr = 0.0045
I0524 05:02:05.527065 19864 solver.cpp:237] Iteration 30388, loss = 0.987859
I0524 05:02:05.527223 19864 solver.cpp:253]     Train net output #0: loss = 0.987859 (* 1 = 0.987859 loss)
I0524 05:02:05.527237 19864 sgd_solver.cpp:106] Iteration 30388, lr = 0.0045
I0524 05:02:14.428624 19864 solver.cpp:237] Iteration 30602, loss = 1.12668
I0524 05:02:14.428668 19864 solver.cpp:253]     Train net output #0: loss = 1.12668 (* 1 = 1.12668 loss)
I0524 05:02:14.428689 19864 sgd_solver.cpp:106] Iteration 30602, lr = 0.0045
I0524 05:02:23.323503 19864 solver.cpp:237] Iteration 30816, loss = 1.19331
I0524 05:02:23.323537 19864 solver.cpp:253]     Train net output #0: loss = 1.19331 (* 1 = 1.19331 loss)
I0524 05:02:23.323554 19864 sgd_solver.cpp:106] Iteration 30816, lr = 0.0045
I0524 05:02:32.229984 19864 solver.cpp:237] Iteration 31030, loss = 1.45869
I0524 05:02:32.230033 19864 solver.cpp:253]     Train net output #0: loss = 1.45869 (* 1 = 1.45869 loss)
I0524 05:02:32.230046 19864 sgd_solver.cpp:106] Iteration 31030, lr = 0.0045
I0524 05:02:41.125221 19864 solver.cpp:237] Iteration 31244, loss = 1.08854
I0524 05:02:41.125382 19864 solver.cpp:253]     Train net output #0: loss = 1.08854 (* 1 = 1.08854 loss)
I0524 05:02:41.125396 19864 sgd_solver.cpp:106] Iteration 31244, lr = 0.0045
I0524 05:03:10.956718 19864 solver.cpp:237] Iteration 31458, loss = 1.12942
I0524 05:03:10.956769 19864 solver.cpp:253]     Train net output #0: loss = 1.12942 (* 1 = 1.12942 loss)
I0524 05:03:10.956786 19864 sgd_solver.cpp:106] Iteration 31458, lr = 0.0045
I0524 05:03:19.855232 19864 solver.cpp:237] Iteration 31672, loss = 1.00911
I0524 05:03:19.855401 19864 solver.cpp:253]     Train net output #0: loss = 1.00911 (* 1 = 1.00911 loss)
I0524 05:03:19.855415 19864 sgd_solver.cpp:106] Iteration 31672, lr = 0.0045
I0524 05:03:28.755810 19864 solver.cpp:237] Iteration 31886, loss = 1.20547
I0524 05:03:28.755848 19864 solver.cpp:253]     Train net output #0: loss = 1.20547 (* 1 = 1.20547 loss)
I0524 05:03:28.755867 19864 sgd_solver.cpp:106] Iteration 31886, lr = 0.0045
I0524 05:03:37.654780 19864 solver.cpp:237] Iteration 32100, loss = 1.14293
I0524 05:03:37.654816 19864 solver.cpp:253]     Train net output #0: loss = 1.14293 (* 1 = 1.14293 loss)
I0524 05:03:37.654832 19864 sgd_solver.cpp:106] Iteration 32100, lr = 0.0045
I0524 05:03:38.860684 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_32130.caffemodel
I0524 05:03:38.935724 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_32130.solverstate
I0524 05:03:46.626837 19864 solver.cpp:237] Iteration 32314, loss = 1.18616
I0524 05:03:46.626884 19864 solver.cpp:253]     Train net output #0: loss = 1.18616 (* 1 = 1.18616 loss)
I0524 05:03:46.626900 19864 sgd_solver.cpp:106] Iteration 32314, lr = 0.0045
I0524 05:03:55.520251 19864 solver.cpp:237] Iteration 32528, loss = 1.57155
I0524 05:03:55.520418 19864 solver.cpp:253]     Train net output #0: loss = 1.57155 (* 1 = 1.57155 loss)
I0524 05:03:55.520432 19864 sgd_solver.cpp:106] Iteration 32528, lr = 0.0045
I0524 05:04:04.420317 19864 solver.cpp:237] Iteration 32742, loss = 1.16813
I0524 05:04:04.420352 19864 solver.cpp:253]     Train net output #0: loss = 1.16813 (* 1 = 1.16813 loss)
I0524 05:04:04.420369 19864 sgd_solver.cpp:106] Iteration 32742, lr = 0.0045
I0524 05:04:34.272614 19864 solver.cpp:237] Iteration 32956, loss = 1.33448
I0524 05:04:34.272786 19864 solver.cpp:253]     Train net output #0: loss = 1.33448 (* 1 = 1.33448 loss)
I0524 05:04:34.272801 19864 sgd_solver.cpp:106] Iteration 32956, lr = 0.0045
I0524 05:04:43.174417 19864 solver.cpp:237] Iteration 33170, loss = 1.35021
I0524 05:04:43.174461 19864 solver.cpp:253]     Train net output #0: loss = 1.35021 (* 1 = 1.35021 loss)
I0524 05:04:43.174479 19864 sgd_solver.cpp:106] Iteration 33170, lr = 0.0045
I0524 05:04:52.072863 19864 solver.cpp:237] Iteration 33384, loss = 1.23113
I0524 05:04:52.072901 19864 solver.cpp:253]     Train net output #0: loss = 1.23113 (* 1 = 1.23113 loss)
I0524 05:04:52.072916 19864 sgd_solver.cpp:106] Iteration 33384, lr = 0.0045
I0524 05:05:00.971935 19864 solver.cpp:237] Iteration 33598, loss = 1.09815
I0524 05:05:00.971971 19864 solver.cpp:253]     Train net output #0: loss = 1.09815 (* 1 = 1.09815 loss)
I0524 05:05:00.971987 19864 sgd_solver.cpp:106] Iteration 33598, lr = 0.0045
I0524 05:05:09.878211 19864 solver.cpp:237] Iteration 33812, loss = 1.21952
I0524 05:05:09.878381 19864 solver.cpp:253]     Train net output #0: loss = 1.21952 (* 1 = 1.21952 loss)
I0524 05:05:09.878396 19864 sgd_solver.cpp:106] Iteration 33812, lr = 0.0045
I0524 05:05:18.782680 19864 solver.cpp:237] Iteration 34026, loss = 1.0974
I0524 05:05:18.782716 19864 solver.cpp:253]     Train net output #0: loss = 1.0974 (* 1 = 1.0974 loss)
I0524 05:05:18.782728 19864 sgd_solver.cpp:106] Iteration 34026, lr = 0.0045
I0524 05:05:27.686048 19864 solver.cpp:237] Iteration 34240, loss = 1.39889
I0524 05:05:27.686085 19864 solver.cpp:253]     Train net output #0: loss = 1.39889 (* 1 = 1.39889 loss)
I0524 05:05:27.686101 19864 sgd_solver.cpp:106] Iteration 34240, lr = 0.0045
I0524 05:05:28.978176 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_34272.caffemodel
I0524 05:05:29.044801 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_34272.solverstate
I0524 05:05:29.375831 19864 solver.cpp:341] Iteration 34280, Testing net (#0)
I0524 05:06:38.217116 19864 solver.cpp:409]     Test net output #0: accuracy = 0.883073
I0524 05:06:38.217288 19864 solver.cpp:409]     Test net output #1: loss = 0.378762 (* 1 = 0.378762 loss)
I0524 05:07:06.351604 19864 solver.cpp:237] Iteration 34454, loss = 1.24568
I0524 05:07:06.351660 19864 solver.cpp:253]     Train net output #0: loss = 1.24568 (* 1 = 1.24568 loss)
I0524 05:07:06.351673 19864 sgd_solver.cpp:106] Iteration 34454, lr = 0.0045
I0524 05:07:15.226936 19864 solver.cpp:237] Iteration 34668, loss = 1.2332
I0524 05:07:15.227102 19864 solver.cpp:253]     Train net output #0: loss = 1.2332 (* 1 = 1.2332 loss)
I0524 05:07:15.227116 19864 sgd_solver.cpp:106] Iteration 34668, lr = 0.0045
I0524 05:07:24.098311 19864 solver.cpp:237] Iteration 34882, loss = 1.19308
I0524 05:07:24.098346 19864 solver.cpp:253]     Train net output #0: loss = 1.19308 (* 1 = 1.19308 loss)
I0524 05:07:24.098363 19864 sgd_solver.cpp:106] Iteration 34882, lr = 0.0045
I0524 05:07:32.971854 19864 solver.cpp:237] Iteration 35096, loss = 1.24267
I0524 05:07:32.971894 19864 solver.cpp:253]     Train net output #0: loss = 1.24267 (* 1 = 1.24267 loss)
I0524 05:07:32.971915 19864 sgd_solver.cpp:106] Iteration 35096, lr = 0.0045
I0524 05:07:41.846992 19864 solver.cpp:237] Iteration 35310, loss = 1.21178
I0524 05:07:41.847028 19864 solver.cpp:253]     Train net output #0: loss = 1.21178 (* 1 = 1.21178 loss)
I0524 05:07:41.847044 19864 sgd_solver.cpp:106] Iteration 35310, lr = 0.0045
I0524 05:07:50.719283 19864 solver.cpp:237] Iteration 35524, loss = 1.17725
I0524 05:07:50.719436 19864 solver.cpp:253]     Train net output #0: loss = 1.17725 (* 1 = 1.17725 loss)
I0524 05:07:50.719450 19864 sgd_solver.cpp:106] Iteration 35524, lr = 0.0045
I0524 05:08:20.467345 19864 solver.cpp:237] Iteration 35738, loss = 1.40257
I0524 05:08:20.467396 19864 solver.cpp:253]     Train net output #0: loss = 1.40257 (* 1 = 1.40257 loss)
I0524 05:08:20.467412 19864 sgd_solver.cpp:106] Iteration 35738, lr = 0.0045
I0524 05:08:29.339124 19864 solver.cpp:237] Iteration 35952, loss = 1.13346
I0524 05:08:29.339303 19864 solver.cpp:253]     Train net output #0: loss = 1.13346 (* 1 = 1.13346 loss)
I0524 05:08:29.339318 19864 sgd_solver.cpp:106] Iteration 35952, lr = 0.0045
I0524 05:08:38.216353 19864 solver.cpp:237] Iteration 36166, loss = 1.18822
I0524 05:08:38.216388 19864 solver.cpp:253]     Train net output #0: loss = 1.18822 (* 1 = 1.18822 loss)
I0524 05:08:38.216405 19864 sgd_solver.cpp:106] Iteration 36166, lr = 0.0045
I0524 05:08:47.089635 19864 solver.cpp:237] Iteration 36380, loss = 1.25674
I0524 05:08:47.089678 19864 solver.cpp:253]     Train net output #0: loss = 1.25674 (* 1 = 1.25674 loss)
I0524 05:08:47.089696 19864 sgd_solver.cpp:106] Iteration 36380, lr = 0.0045
I0524 05:08:48.457866 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_36414.caffemodel
I0524 05:08:48.524251 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_36414.solverstate
I0524 05:08:56.026178 19864 solver.cpp:237] Iteration 36594, loss = 1.06309
I0524 05:08:56.026226 19864 solver.cpp:253]     Train net output #0: loss = 1.06309 (* 1 = 1.06309 loss)
I0524 05:08:56.026243 19864 sgd_solver.cpp:106] Iteration 36594, lr = 0.0045
I0524 05:09:04.900337 19864 solver.cpp:237] Iteration 36808, loss = 1.20983
I0524 05:09:04.900501 19864 solver.cpp:253]     Train net output #0: loss = 1.20983 (* 1 = 1.20983 loss)
I0524 05:09:04.900514 19864 sgd_solver.cpp:106] Iteration 36808, lr = 0.0045
I0524 05:09:13.776654 19864 solver.cpp:237] Iteration 37022, loss = 1.15762
I0524 05:09:13.776701 19864 solver.cpp:253]     Train net output #0: loss = 1.15762 (* 1 = 1.15762 loss)
I0524 05:09:13.776718 19864 sgd_solver.cpp:106] Iteration 37022, lr = 0.0045
I0524 05:09:43.562880 19864 solver.cpp:237] Iteration 37236, loss = 1.29912
I0524 05:09:43.563055 19864 solver.cpp:253]     Train net output #0: loss = 1.29912 (* 1 = 1.29912 loss)
I0524 05:09:43.563071 19864 sgd_solver.cpp:106] Iteration 37236, lr = 0.0045
I0524 05:09:52.437062 19864 solver.cpp:237] Iteration 37450, loss = 1.30494
I0524 05:09:52.437098 19864 solver.cpp:253]     Train net output #0: loss = 1.30494 (* 1 = 1.30494 loss)
I0524 05:09:52.437113 19864 sgd_solver.cpp:106] Iteration 37450, lr = 0.0045
I0524 05:10:01.314131 19864 solver.cpp:237] Iteration 37664, loss = 1.11916
I0524 05:10:01.314167 19864 solver.cpp:253]     Train net output #0: loss = 1.11916 (* 1 = 1.11916 loss)
I0524 05:10:01.314182 19864 sgd_solver.cpp:106] Iteration 37664, lr = 0.0045
I0524 05:10:10.192562 19864 solver.cpp:237] Iteration 37878, loss = 1.21801
I0524 05:10:10.192597 19864 solver.cpp:253]     Train net output #0: loss = 1.21801 (* 1 = 1.21801 loss)
I0524 05:10:10.192616 19864 sgd_solver.cpp:106] Iteration 37878, lr = 0.0045
I0524 05:10:19.062734 19864 solver.cpp:237] Iteration 38092, loss = 1.18317
I0524 05:10:19.062885 19864 solver.cpp:253]     Train net output #0: loss = 1.18317 (* 1 = 1.18317 loss)
I0524 05:10:19.062898 19864 sgd_solver.cpp:106] Iteration 38092, lr = 0.0045
I0524 05:10:27.936063 19864 solver.cpp:237] Iteration 38306, loss = 1.3013
I0524 05:10:27.936110 19864 solver.cpp:253]     Train net output #0: loss = 1.3013 (* 1 = 1.3013 loss)
I0524 05:10:27.936126 19864 sgd_solver.cpp:106] Iteration 38306, lr = 0.0045
I0524 05:10:36.810307 19864 solver.cpp:237] Iteration 38520, loss = 1.41415
I0524 05:10:36.810343 19864 solver.cpp:253]     Train net output #0: loss = 1.41415 (* 1 = 1.41415 loss)
I0524 05:10:36.810359 19864 sgd_solver.cpp:106] Iteration 38520, lr = 0.0045
I0524 05:10:38.261724 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_38556.caffemodel
I0524 05:10:38.328301 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_38556.solverstate
I0524 05:10:38.700084 19864 solver.cpp:341] Iteration 38565, Testing net (#0)
I0524 05:11:26.621513 19864 solver.cpp:409]     Test net output #0: accuracy = 0.884694
I0524 05:11:26.621685 19864 solver.cpp:409]     Test net output #1: loss = 0.37129 (* 1 = 0.37129 loss)
I0524 05:11:54.557104 19864 solver.cpp:237] Iteration 38734, loss = 1.16726
I0524 05:11:54.557154 19864 solver.cpp:253]     Train net output #0: loss = 1.16726 (* 1 = 1.16726 loss)
I0524 05:11:54.557168 19864 sgd_solver.cpp:106] Iteration 38734, lr = 0.0045
I0524 05:12:03.460278 19864 solver.cpp:237] Iteration 38948, loss = 1.29203
I0524 05:12:03.460435 19864 solver.cpp:253]     Train net output #0: loss = 1.29203 (* 1 = 1.29203 loss)
I0524 05:12:03.460448 19864 sgd_solver.cpp:106] Iteration 38948, lr = 0.0045
I0524 05:12:12.365406 19864 solver.cpp:237] Iteration 39162, loss = 1.1856
I0524 05:12:12.365443 19864 solver.cpp:253]     Train net output #0: loss = 1.1856 (* 1 = 1.1856 loss)
I0524 05:12:12.365463 19864 sgd_solver.cpp:106] Iteration 39162, lr = 0.0045
I0524 05:12:21.270864 19864 solver.cpp:237] Iteration 39376, loss = 1.11906
I0524 05:12:21.270900 19864 solver.cpp:253]     Train net output #0: loss = 1.11906 (* 1 = 1.11906 loss)
I0524 05:12:21.270913 19864 sgd_solver.cpp:106] Iteration 39376, lr = 0.0045
I0524 05:12:30.174424 19864 solver.cpp:237] Iteration 39590, loss = 1.0137
I0524 05:12:30.174459 19864 solver.cpp:253]     Train net output #0: loss = 1.0137 (* 1 = 1.0137 loss)
I0524 05:12:30.174475 19864 sgd_solver.cpp:106] Iteration 39590, lr = 0.0045
I0524 05:12:39.078421 19864 solver.cpp:237] Iteration 39804, loss = 1.15998
I0524 05:12:39.078599 19864 solver.cpp:253]     Train net output #0: loss = 1.15998 (* 1 = 1.15998 loss)
I0524 05:12:39.078613 19864 sgd_solver.cpp:106] Iteration 39804, lr = 0.0045
I0524 05:13:08.888144 19864 solver.cpp:237] Iteration 40018, loss = 1.13005
I0524 05:13:08.888195 19864 solver.cpp:253]     Train net output #0: loss = 1.13005 (* 1 = 1.13005 loss)
I0524 05:13:08.888208 19864 sgd_solver.cpp:106] Iteration 40018, lr = 0.0045
I0524 05:13:17.793764 19864 solver.cpp:237] Iteration 40232, loss = 1.25935
I0524 05:13:17.793925 19864 solver.cpp:253]     Train net output #0: loss = 1.25935 (* 1 = 1.25935 loss)
I0524 05:13:17.793937 19864 sgd_solver.cpp:106] Iteration 40232, lr = 0.0045
I0524 05:13:26.703690 19864 solver.cpp:237] Iteration 40446, loss = 1.18391
I0524 05:13:26.703727 19864 solver.cpp:253]     Train net output #0: loss = 1.18391 (* 1 = 1.18391 loss)
I0524 05:13:26.703749 19864 sgd_solver.cpp:106] Iteration 40446, lr = 0.0045
I0524 05:13:35.611961 19864 solver.cpp:237] Iteration 40660, loss = 1.1155
I0524 05:13:35.611997 19864 solver.cpp:253]     Train net output #0: loss = 1.1155 (* 1 = 1.1155 loss)
I0524 05:13:35.612013 19864 sgd_solver.cpp:106] Iteration 40660, lr = 0.0045
I0524 05:13:37.155496 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_40698.caffemodel
I0524 05:13:37.225076 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_40698.solverstate
I0524 05:13:44.593044 19864 solver.cpp:237] Iteration 40874, loss = 1.17873
I0524 05:13:44.593092 19864 solver.cpp:253]     Train net output #0: loss = 1.17873 (* 1 = 1.17873 loss)
I0524 05:13:44.593106 19864 sgd_solver.cpp:106] Iteration 40874, lr = 0.0045
I0524 05:13:53.503449 19864 solver.cpp:237] Iteration 41088, loss = 0.959123
I0524 05:13:53.503614 19864 solver.cpp:253]     Train net output #0: loss = 0.959123 (* 1 = 0.959123 loss)
I0524 05:13:53.503628 19864 sgd_solver.cpp:106] Iteration 41088, lr = 0.0045
I0524 05:14:02.411473 19864 solver.cpp:237] Iteration 41302, loss = 1.15442
I0524 05:14:02.411509 19864 solver.cpp:253]     Train net output #0: loss = 1.15442 (* 1 = 1.15442 loss)
I0524 05:14:02.411522 19864 sgd_solver.cpp:106] Iteration 41302, lr = 0.0045
I0524 05:14:32.260691 19864 solver.cpp:237] Iteration 41516, loss = 1.25985
I0524 05:14:32.260869 19864 solver.cpp:253]     Train net output #0: loss = 1.25985 (* 1 = 1.25985 loss)
I0524 05:14:32.260882 19864 sgd_solver.cpp:106] Iteration 41516, lr = 0.0045
I0524 05:14:41.169863 19864 solver.cpp:237] Iteration 41730, loss = 1.27985
I0524 05:14:41.169912 19864 solver.cpp:253]     Train net output #0: loss = 1.27985 (* 1 = 1.27985 loss)
I0524 05:14:41.169927 19864 sgd_solver.cpp:106] Iteration 41730, lr = 0.0045
I0524 05:14:50.066385 19864 solver.cpp:237] Iteration 41944, loss = 1.2028
I0524 05:14:50.066421 19864 solver.cpp:253]     Train net output #0: loss = 1.2028 (* 1 = 1.2028 loss)
I0524 05:14:50.066437 19864 sgd_solver.cpp:106] Iteration 41944, lr = 0.0045
I0524 05:14:58.972810 19864 solver.cpp:237] Iteration 42158, loss = 1.0343
I0524 05:14:58.972843 19864 solver.cpp:253]     Train net output #0: loss = 1.0343 (* 1 = 1.0343 loss)
I0524 05:14:58.972859 19864 sgd_solver.cpp:106] Iteration 42158, lr = 0.0045
I0524 05:15:07.876015 19864 solver.cpp:237] Iteration 42372, loss = 1.18253
I0524 05:15:07.876196 19864 solver.cpp:253]     Train net output #0: loss = 1.18253 (* 1 = 1.18253 loss)
I0524 05:15:07.876210 19864 sgd_solver.cpp:106] Iteration 42372, lr = 0.0045
I0524 05:15:16.784507 19864 solver.cpp:237] Iteration 42586, loss = 1.3383
I0524 05:15:16.784543 19864 solver.cpp:253]     Train net output #0: loss = 1.3383 (* 1 = 1.3383 loss)
I0524 05:15:16.784559 19864 sgd_solver.cpp:106] Iteration 42586, lr = 0.0045
I0524 05:15:25.685204 19864 solver.cpp:237] Iteration 42800, loss = 1.44293
I0524 05:15:25.685240 19864 solver.cpp:253]     Train net output #0: loss = 1.44293 (* 1 = 1.44293 loss)
I0524 05:15:25.685253 19864 sgd_solver.cpp:106] Iteration 42800, lr = 0.0045
I0524 05:15:27.306337 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_42840.caffemodel
I0524 05:15:27.374878 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_42840.solverstate
I0524 05:15:27.792613 19864 solver.cpp:341] Iteration 42850, Testing net (#0)
I0524 05:16:36.630023 19864 solver.cpp:409]     Test net output #0: accuracy = 0.888289
I0524 05:16:36.630208 19864 solver.cpp:409]     Test net output #1: loss = 0.350112 (* 1 = 0.350112 loss)
I0524 05:17:04.362630 19864 solver.cpp:237] Iteration 43014, loss = 1.09747
I0524 05:17:04.362681 19864 solver.cpp:253]     Train net output #0: loss = 1.09747 (* 1 = 1.09747 loss)
I0524 05:17:04.362696 19864 sgd_solver.cpp:106] Iteration 43014, lr = 0.0045
I0524 05:17:13.249927 19864 solver.cpp:237] Iteration 43228, loss = 1.264
I0524 05:17:13.250092 19864 solver.cpp:253]     Train net output #0: loss = 1.264 (* 1 = 1.264 loss)
I0524 05:17:13.250105 19864 sgd_solver.cpp:106] Iteration 43228, lr = 0.0045
I0524 05:17:22.140094 19864 solver.cpp:237] Iteration 43442, loss = 1.24124
I0524 05:17:22.140128 19864 solver.cpp:253]     Train net output #0: loss = 1.24124 (* 1 = 1.24124 loss)
I0524 05:17:22.140142 19864 sgd_solver.cpp:106] Iteration 43442, lr = 0.0045
I0524 05:17:31.022281 19864 solver.cpp:237] Iteration 43656, loss = 1.27393
I0524 05:17:31.022317 19864 solver.cpp:253]     Train net output #0: loss = 1.27393 (* 1 = 1.27393 loss)
I0524 05:17:31.022335 19864 sgd_solver.cpp:106] Iteration 43656, lr = 0.0045
I0524 05:17:39.909884 19864 solver.cpp:237] Iteration 43870, loss = 1.18606
I0524 05:17:39.909929 19864 solver.cpp:253]     Train net output #0: loss = 1.18606 (* 1 = 1.18606 loss)
I0524 05:17:39.909947 19864 sgd_solver.cpp:106] Iteration 43870, lr = 0.0045
I0524 05:17:48.798038 19864 solver.cpp:237] Iteration 44084, loss = 1.61618
I0524 05:17:48.798197 19864 solver.cpp:253]     Train net output #0: loss = 1.61618 (* 1 = 1.61618 loss)
I0524 05:17:48.798209 19864 sgd_solver.cpp:106] Iteration 44084, lr = 0.0045
I0524 05:18:18.582036 19864 solver.cpp:237] Iteration 44298, loss = 1.06919
I0524 05:18:18.582084 19864 solver.cpp:253]     Train net output #0: loss = 1.06919 (* 1 = 1.06919 loss)
I0524 05:18:18.582103 19864 sgd_solver.cpp:106] Iteration 44298, lr = 0.0045
I0524 05:18:27.463125 19864 solver.cpp:237] Iteration 44512, loss = 1.43313
I0524 05:18:27.463289 19864 solver.cpp:253]     Train net output #0: loss = 1.43313 (* 1 = 1.43313 loss)
I0524 05:18:27.463304 19864 sgd_solver.cpp:106] Iteration 44512, lr = 0.0045
I0524 05:18:36.361311 19864 solver.cpp:237] Iteration 44726, loss = 1.1145
I0524 05:18:36.361346 19864 solver.cpp:253]     Train net output #0: loss = 1.1145 (* 1 = 1.1145 loss)
I0524 05:18:36.361363 19864 sgd_solver.cpp:106] Iteration 44726, lr = 0.0045
I0524 05:18:45.246897 19864 solver.cpp:237] Iteration 44940, loss = 1.2595
I0524 05:18:45.246932 19864 solver.cpp:253]     Train net output #0: loss = 1.2595 (* 1 = 1.2595 loss)
I0524 05:18:45.246945 19864 sgd_solver.cpp:106] Iteration 44940, lr = 0.0045
I0524 05:18:46.953356 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_44982.caffemodel
I0524 05:18:47.020606 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_44982.solverstate
I0524 05:18:54.207540 19864 solver.cpp:237] Iteration 45154, loss = 1.24104
I0524 05:18:54.207587 19864 solver.cpp:253]     Train net output #0: loss = 1.24104 (* 1 = 1.24104 loss)
I0524 05:18:54.207599 19864 sgd_solver.cpp:106] Iteration 45154, lr = 0.0045
I0524 05:19:03.093739 19864 solver.cpp:237] Iteration 45368, loss = 1.04791
I0524 05:19:03.093909 19864 solver.cpp:253]     Train net output #0: loss = 1.04791 (* 1 = 1.04791 loss)
I0524 05:19:03.093922 19864 sgd_solver.cpp:106] Iteration 45368, lr = 0.0045
I0524 05:19:11.982180 19864 solver.cpp:237] Iteration 45582, loss = 1.12263
I0524 05:19:11.982226 19864 solver.cpp:253]     Train net output #0: loss = 1.12263 (* 1 = 1.12263 loss)
I0524 05:19:11.982244 19864 sgd_solver.cpp:106] Iteration 45582, lr = 0.0045
I0524 05:19:41.797173 19864 solver.cpp:237] Iteration 45796, loss = 0.84612
I0524 05:19:41.797353 19864 solver.cpp:253]     Train net output #0: loss = 0.84612 (* 1 = 0.84612 loss)
I0524 05:19:41.797368 19864 sgd_solver.cpp:106] Iteration 45796, lr = 0.0045
I0524 05:19:50.688066 19864 solver.cpp:237] Iteration 46010, loss = 1.05932
I0524 05:19:50.688099 19864 solver.cpp:253]     Train net output #0: loss = 1.05932 (* 1 = 1.05932 loss)
I0524 05:19:50.688114 19864 sgd_solver.cpp:106] Iteration 46010, lr = 0.0045
I0524 05:19:59.571655 19864 solver.cpp:237] Iteration 46224, loss = 1.03731
I0524 05:19:59.571688 19864 solver.cpp:253]     Train net output #0: loss = 1.03731 (* 1 = 1.03731 loss)
I0524 05:19:59.571703 19864 sgd_solver.cpp:106] Iteration 46224, lr = 0.0045
I0524 05:20:08.459324 19864 solver.cpp:237] Iteration 46438, loss = 1.19654
I0524 05:20:08.459370 19864 solver.cpp:253]     Train net output #0: loss = 1.19654 (* 1 = 1.19654 loss)
I0524 05:20:08.459389 19864 sgd_solver.cpp:106] Iteration 46438, lr = 0.0045
I0524 05:20:17.351248 19864 solver.cpp:237] Iteration 46652, loss = 0.984449
I0524 05:20:17.351416 19864 solver.cpp:253]     Train net output #0: loss = 0.984449 (* 1 = 0.984449 loss)
I0524 05:20:17.351430 19864 sgd_solver.cpp:106] Iteration 46652, lr = 0.0045
I0524 05:20:26.237110 19864 solver.cpp:237] Iteration 46866, loss = 1.07688
I0524 05:20:26.237144 19864 solver.cpp:253]     Train net output #0: loss = 1.07688 (* 1 = 1.07688 loss)
I0524 05:20:26.237161 19864 sgd_solver.cpp:106] Iteration 46866, lr = 0.0045
I0524 05:20:35.132781 19864 solver.cpp:237] Iteration 47080, loss = 1.08267
I0524 05:20:35.132817 19864 solver.cpp:253]     Train net output #0: loss = 1.08267 (* 1 = 1.08267 loss)
I0524 05:20:35.132840 19864 sgd_solver.cpp:106] Iteration 47080, lr = 0.0045
I0524 05:20:36.922945 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_47124.caffemodel
I0524 05:20:36.989629 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_47124.solverstate
I0524 05:20:37.446038 19864 solver.cpp:341] Iteration 47135, Testing net (#0)
I0524 05:21:25.079026 19864 solver.cpp:409]     Test net output #0: accuracy = 0.888789
I0524 05:21:25.079198 19864 solver.cpp:409]     Test net output #1: loss = 0.365233 (* 1 = 0.365233 loss)
I0524 05:21:52.603476 19864 solver.cpp:237] Iteration 47294, loss = 1.04077
I0524 05:21:52.603525 19864 solver.cpp:253]     Train net output #0: loss = 1.04077 (* 1 = 1.04077 loss)
I0524 05:21:52.603541 19864 sgd_solver.cpp:106] Iteration 47294, lr = 0.0045
I0524 05:22:01.494192 19864 solver.cpp:237] Iteration 47508, loss = 1.09183
I0524 05:22:01.494374 19864 solver.cpp:253]     Train net output #0: loss = 1.09183 (* 1 = 1.09183 loss)
I0524 05:22:01.494387 19864 sgd_solver.cpp:106] Iteration 47508, lr = 0.0045
I0524 05:22:10.382997 19864 solver.cpp:237] Iteration 47722, loss = 1.02574
I0524 05:22:10.383036 19864 solver.cpp:253]     Train net output #0: loss = 1.02574 (* 1 = 1.02574 loss)
I0524 05:22:10.383057 19864 sgd_solver.cpp:106] Iteration 47722, lr = 0.0045
I0524 05:22:19.274672 19864 solver.cpp:237] Iteration 47936, loss = 0.878936
I0524 05:22:19.274708 19864 solver.cpp:253]     Train net output #0: loss = 0.878936 (* 1 = 0.878936 loss)
I0524 05:22:19.274724 19864 sgd_solver.cpp:106] Iteration 47936, lr = 0.0045
I0524 05:22:28.163218 19864 solver.cpp:237] Iteration 48150, loss = 1.50691
I0524 05:22:28.163252 19864 solver.cpp:253]     Train net output #0: loss = 1.50691 (* 1 = 1.50691 loss)
I0524 05:22:28.163269 19864 sgd_solver.cpp:106] Iteration 48150, lr = 0.0045
I0524 05:22:37.059638 19864 solver.cpp:237] Iteration 48364, loss = 0.926922
I0524 05:22:37.059808 19864 solver.cpp:253]     Train net output #0: loss = 0.926922 (* 1 = 0.926922 loss)
I0524 05:22:37.059823 19864 sgd_solver.cpp:106] Iteration 48364, lr = 0.0045
I0524 05:23:06.837215 19864 solver.cpp:237] Iteration 48578, loss = 1.21121
I0524 05:23:06.837266 19864 solver.cpp:253]     Train net output #0: loss = 1.21121 (* 1 = 1.21121 loss)
I0524 05:23:06.837285 19864 sgd_solver.cpp:106] Iteration 48578, lr = 0.0045
I0524 05:23:15.726155 19864 solver.cpp:237] Iteration 48792, loss = 1.1438
I0524 05:23:15.726317 19864 solver.cpp:253]     Train net output #0: loss = 1.1438 (* 1 = 1.1438 loss)
I0524 05:23:15.726330 19864 sgd_solver.cpp:106] Iteration 48792, lr = 0.0045
I0524 05:23:24.617094 19864 solver.cpp:237] Iteration 49006, loss = 1.2066
I0524 05:23:24.617135 19864 solver.cpp:253]     Train net output #0: loss = 1.2066 (* 1 = 1.2066 loss)
I0524 05:23:24.617151 19864 sgd_solver.cpp:106] Iteration 49006, lr = 0.0045
I0524 05:23:33.501886 19864 solver.cpp:237] Iteration 49220, loss = 0.923275
I0524 05:23:33.501924 19864 solver.cpp:253]     Train net output #0: loss = 0.923275 (* 1 = 0.923275 loss)
I0524 05:23:33.501936 19864 sgd_solver.cpp:106] Iteration 49220, lr = 0.0045
I0524 05:23:35.370628 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_49266.caffemodel
I0524 05:23:35.436883 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_49266.solverstate
I0524 05:23:42.459069 19864 solver.cpp:237] Iteration 49434, loss = 1.23139
I0524 05:23:42.459117 19864 solver.cpp:253]     Train net output #0: loss = 1.23139 (* 1 = 1.23139 loss)
I0524 05:23:42.459131 19864 sgd_solver.cpp:106] Iteration 49434, lr = 0.0045
I0524 05:23:51.352641 19864 solver.cpp:237] Iteration 49648, loss = 1.31971
I0524 05:23:51.352813 19864 solver.cpp:253]     Train net output #0: loss = 1.31971 (* 1 = 1.31971 loss)
I0524 05:23:51.352828 19864 sgd_solver.cpp:106] Iteration 49648, lr = 0.0045
I0524 05:24:00.232975 19864 solver.cpp:237] Iteration 49862, loss = 1.26543
I0524 05:24:00.233009 19864 solver.cpp:253]     Train net output #0: loss = 1.26543 (* 1 = 1.26543 loss)
I0524 05:24:00.233027 19864 sgd_solver.cpp:106] Iteration 49862, lr = 0.0045
I0524 05:24:29.988278 19864 solver.cpp:237] Iteration 50076, loss = 1.10352
I0524 05:24:29.988458 19864 solver.cpp:253]     Train net output #0: loss = 1.10352 (* 1 = 1.10352 loss)
I0524 05:24:29.988472 19864 sgd_solver.cpp:106] Iteration 50076, lr = 0.0045
I0524 05:24:38.876566 19864 solver.cpp:237] Iteration 50290, loss = 0.955795
I0524 05:24:38.876610 19864 solver.cpp:253]     Train net output #0: loss = 0.955795 (* 1 = 0.955795 loss)
I0524 05:24:38.876628 19864 sgd_solver.cpp:106] Iteration 50290, lr = 0.0045
I0524 05:24:47.771525 19864 solver.cpp:237] Iteration 50504, loss = 1.2
I0524 05:24:47.771560 19864 solver.cpp:253]     Train net output #0: loss = 1.2 (* 1 = 1.2 loss)
I0524 05:24:47.771576 19864 sgd_solver.cpp:106] Iteration 50504, lr = 0.0045
I0524 05:24:56.660969 19864 solver.cpp:237] Iteration 50718, loss = 1.06446
I0524 05:24:56.661005 19864 solver.cpp:253]     Train net output #0: loss = 1.06446 (* 1 = 1.06446 loss)
I0524 05:24:56.661020 19864 sgd_solver.cpp:106] Iteration 50718, lr = 0.0045
I0524 05:25:05.556064 19864 solver.cpp:237] Iteration 50932, loss = 1.07086
I0524 05:25:05.556243 19864 solver.cpp:253]     Train net output #0: loss = 1.07086 (* 1 = 1.07086 loss)
I0524 05:25:05.556257 19864 sgd_solver.cpp:106] Iteration 50932, lr = 0.0045
I0524 05:25:14.444308 19864 solver.cpp:237] Iteration 51146, loss = 1.20745
I0524 05:25:14.444341 19864 solver.cpp:253]     Train net output #0: loss = 1.20745 (* 1 = 1.20745 loss)
I0524 05:25:14.444360 19864 sgd_solver.cpp:106] Iteration 51146, lr = 0.0045
I0524 05:25:23.328532 19864 solver.cpp:237] Iteration 51360, loss = 1.16723
I0524 05:25:23.328567 19864 solver.cpp:253]     Train net output #0: loss = 1.16723 (* 1 = 1.16723 loss)
I0524 05:25:23.328583 19864 sgd_solver.cpp:106] Iteration 51360, lr = 0.0045
I0524 05:25:25.279496 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_51408.caffemodel
I0524 05:25:25.345660 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_51408.solverstate
I0524 05:25:25.842264 19864 solver.cpp:341] Iteration 51420, Testing net (#0)
I0524 05:26:34.592221 19864 solver.cpp:409]     Test net output #0: accuracy = 0.887349
I0524 05:26:34.592409 19864 solver.cpp:409]     Test net output #1: loss = 0.398333 (* 1 = 0.398333 loss)
I0524 05:27:01.874006 19864 solver.cpp:237] Iteration 51574, loss = 1.07228
I0524 05:27:01.874056 19864 solver.cpp:253]     Train net output #0: loss = 1.07228 (* 1 = 1.07228 loss)
I0524 05:27:01.874073 19864 sgd_solver.cpp:106] Iteration 51574, lr = 0.0045
I0524 05:27:10.761340 19864 solver.cpp:237] Iteration 51788, loss = 1.08474
I0524 05:27:10.761515 19864 solver.cpp:253]     Train net output #0: loss = 1.08474 (* 1 = 1.08474 loss)
I0524 05:27:10.761529 19864 sgd_solver.cpp:106] Iteration 51788, lr = 0.0045
I0524 05:27:19.653731 19864 solver.cpp:237] Iteration 52002, loss = 1.00957
I0524 05:27:19.653766 19864 solver.cpp:253]     Train net output #0: loss = 1.00957 (* 1 = 1.00957 loss)
I0524 05:27:19.653784 19864 sgd_solver.cpp:106] Iteration 52002, lr = 0.0045
I0524 05:27:28.544598 19864 solver.cpp:237] Iteration 52216, loss = 1.18893
I0524 05:27:28.544634 19864 solver.cpp:253]     Train net output #0: loss = 1.18893 (* 1 = 1.18893 loss)
I0524 05:27:28.544651 19864 sgd_solver.cpp:106] Iteration 52216, lr = 0.0045
I0524 05:27:37.442896 19864 solver.cpp:237] Iteration 52430, loss = 1.14127
I0524 05:27:37.442935 19864 solver.cpp:253]     Train net output #0: loss = 1.14127 (* 1 = 1.14127 loss)
I0524 05:27:37.442955 19864 sgd_solver.cpp:106] Iteration 52430, lr = 0.0045
I0524 05:27:46.329421 19864 solver.cpp:237] Iteration 52644, loss = 1.14746
I0524 05:27:46.329586 19864 solver.cpp:253]     Train net output #0: loss = 1.14746 (* 1 = 1.14746 loss)
I0524 05:27:46.329601 19864 sgd_solver.cpp:106] Iteration 52644, lr = 0.0045
I0524 05:28:16.093670 19864 solver.cpp:237] Iteration 52858, loss = 0.874201
I0524 05:28:16.093724 19864 solver.cpp:253]     Train net output #0: loss = 0.874201 (* 1 = 0.874201 loss)
I0524 05:28:16.093739 19864 sgd_solver.cpp:106] Iteration 52858, lr = 0.0045
I0524 05:28:24.979594 19864 solver.cpp:237] Iteration 53072, loss = 1.40321
I0524 05:28:24.979784 19864 solver.cpp:253]     Train net output #0: loss = 1.40321 (* 1 = 1.40321 loss)
I0524 05:28:24.979799 19864 sgd_solver.cpp:106] Iteration 53072, lr = 0.0045
I0524 05:28:33.874584 19864 solver.cpp:237] Iteration 53286, loss = 1.09345
I0524 05:28:33.874619 19864 solver.cpp:253]     Train net output #0: loss = 1.09345 (* 1 = 1.09345 loss)
I0524 05:28:33.874634 19864 sgd_solver.cpp:106] Iteration 53286, lr = 0.0045
I0524 05:28:42.769989 19864 solver.cpp:237] Iteration 53500, loss = 1.10093
I0524 05:28:42.770025 19864 solver.cpp:253]     Train net output #0: loss = 1.10093 (* 1 = 1.10093 loss)
I0524 05:28:42.770040 19864 sgd_solver.cpp:106] Iteration 53500, lr = 0.0045
I0524 05:28:44.804659 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_53550.caffemodel
I0524 05:28:44.872740 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_53550.solverstate
I0524 05:28:51.724805 19864 solver.cpp:237] Iteration 53714, loss = 0.997972
I0524 05:28:51.724854 19864 solver.cpp:253]     Train net output #0: loss = 0.997972 (* 1 = 0.997972 loss)
I0524 05:28:51.724869 19864 sgd_solver.cpp:106] Iteration 53714, lr = 0.0045
I0524 05:29:00.603760 19864 solver.cpp:237] Iteration 53928, loss = 1.18514
I0524 05:29:00.603936 19864 solver.cpp:253]     Train net output #0: loss = 1.18514 (* 1 = 1.18514 loss)
I0524 05:29:00.603950 19864 sgd_solver.cpp:106] Iteration 53928, lr = 0.0045
I0524 05:29:09.486922 19864 solver.cpp:237] Iteration 54142, loss = 1.09716
I0524 05:29:09.486958 19864 solver.cpp:253]     Train net output #0: loss = 1.09716 (* 1 = 1.09716 loss)
I0524 05:29:09.486974 19864 sgd_solver.cpp:106] Iteration 54142, lr = 0.0045
I0524 05:29:39.305693 19864 solver.cpp:237] Iteration 54356, loss = 1.18863
I0524 05:29:39.305873 19864 solver.cpp:253]     Train net output #0: loss = 1.18863 (* 1 = 1.18863 loss)
I0524 05:29:39.305888 19864 sgd_solver.cpp:106] Iteration 54356, lr = 0.0045
I0524 05:29:48.193298 19864 solver.cpp:237] Iteration 54570, loss = 1.20361
I0524 05:29:48.193333 19864 solver.cpp:253]     Train net output #0: loss = 1.20361 (* 1 = 1.20361 loss)
I0524 05:29:48.193351 19864 sgd_solver.cpp:106] Iteration 54570, lr = 0.0045
I0524 05:29:57.080157 19864 solver.cpp:237] Iteration 54784, loss = 1.11172
I0524 05:29:57.080193 19864 solver.cpp:253]     Train net output #0: loss = 1.11172 (* 1 = 1.11172 loss)
I0524 05:29:57.080207 19864 sgd_solver.cpp:106] Iteration 54784, lr = 0.0045
I0524 05:30:05.974854 19864 solver.cpp:237] Iteration 54998, loss = 1.44507
I0524 05:30:05.974905 19864 solver.cpp:253]     Train net output #0: loss = 1.44507 (* 1 = 1.44507 loss)
I0524 05:30:05.974917 19864 sgd_solver.cpp:106] Iteration 54998, lr = 0.0045
I0524 05:30:14.861673 19864 solver.cpp:237] Iteration 55212, loss = 1.24102
I0524 05:30:14.861835 19864 solver.cpp:253]     Train net output #0: loss = 1.24102 (* 1 = 1.24102 loss)
I0524 05:30:14.861848 19864 sgd_solver.cpp:106] Iteration 55212, lr = 0.0045
I0524 05:30:23.749686 19864 solver.cpp:237] Iteration 55426, loss = 1.09129
I0524 05:30:23.749722 19864 solver.cpp:253]     Train net output #0: loss = 1.09129 (* 1 = 1.09129 loss)
I0524 05:30:23.749738 19864 sgd_solver.cpp:106] Iteration 55426, lr = 0.0045
I0524 05:30:32.643589 19864 solver.cpp:237] Iteration 55640, loss = 1.07341
I0524 05:30:32.643631 19864 solver.cpp:253]     Train net output #0: loss = 1.07341 (* 1 = 1.07341 loss)
I0524 05:30:32.643652 19864 sgd_solver.cpp:106] Iteration 55640, lr = 0.0045
I0524 05:30:34.765774 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_55692.caffemodel
I0524 05:30:34.831727 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_55692.solverstate
I0524 05:30:35.371088 19864 solver.cpp:341] Iteration 55705, Testing net (#0)
I0524 05:31:23.360648 19864 solver.cpp:409]     Test net output #0: accuracy = 0.892537
I0524 05:31:23.360838 19864 solver.cpp:409]     Test net output #1: loss = 0.348351 (* 1 = 0.348351 loss)
I0524 05:31:50.434684 19864 solver.cpp:237] Iteration 55854, loss = 0.891111
I0524 05:31:50.434734 19864 solver.cpp:253]     Train net output #0: loss = 0.891111 (* 1 = 0.891111 loss)
I0524 05:31:50.434748 19864 sgd_solver.cpp:106] Iteration 55854, lr = 0.0045
I0524 05:31:59.312770 19864 solver.cpp:237] Iteration 56068, loss = 1.32088
I0524 05:31:59.312947 19864 solver.cpp:253]     Train net output #0: loss = 1.32088 (* 1 = 1.32088 loss)
I0524 05:31:59.312960 19864 sgd_solver.cpp:106] Iteration 56068, lr = 0.0045
I0524 05:32:08.191290 19864 solver.cpp:237] Iteration 56282, loss = 1.05178
I0524 05:32:08.191339 19864 solver.cpp:253]     Train net output #0: loss = 1.05178 (* 1 = 1.05178 loss)
I0524 05:32:08.191354 19864 sgd_solver.cpp:106] Iteration 56282, lr = 0.0045
I0524 05:32:17.068459 19864 solver.cpp:237] Iteration 56496, loss = 1.19455
I0524 05:32:17.068495 19864 solver.cpp:253]     Train net output #0: loss = 1.19455 (* 1 = 1.19455 loss)
I0524 05:32:17.068511 19864 sgd_solver.cpp:106] Iteration 56496, lr = 0.0045
I0524 05:32:25.941444 19864 solver.cpp:237] Iteration 56710, loss = 1.31896
I0524 05:32:25.941479 19864 solver.cpp:253]     Train net output #0: loss = 1.31896 (* 1 = 1.31896 loss)
I0524 05:32:25.941493 19864 sgd_solver.cpp:106] Iteration 56710, lr = 0.0045
I0524 05:32:34.823565 19864 solver.cpp:237] Iteration 56924, loss = 1.2458
I0524 05:32:34.823753 19864 solver.cpp:253]     Train net output #0: loss = 1.2458 (* 1 = 1.2458 loss)
I0524 05:32:34.823768 19864 sgd_solver.cpp:106] Iteration 56924, lr = 0.0045
I0524 05:32:43.696387 19864 solver.cpp:237] Iteration 57138, loss = 1.26913
I0524 05:32:43.696420 19864 solver.cpp:253]     Train net output #0: loss = 1.26913 (* 1 = 1.26913 loss)
I0524 05:32:43.696435 19864 sgd_solver.cpp:106] Iteration 57138, lr = 0.0045
I0524 05:33:13.466317 19864 solver.cpp:237] Iteration 57352, loss = 1.26843
I0524 05:33:13.466500 19864 solver.cpp:253]     Train net output #0: loss = 1.26843 (* 1 = 1.26843 loss)
I0524 05:33:13.466516 19864 sgd_solver.cpp:106] Iteration 57352, lr = 0.0045
I0524 05:33:22.339615 19864 solver.cpp:237] Iteration 57566, loss = 1.30316
I0524 05:33:22.339663 19864 solver.cpp:253]     Train net output #0: loss = 1.30316 (* 1 = 1.30316 loss)
I0524 05:33:22.339680 19864 sgd_solver.cpp:106] Iteration 57566, lr = 0.0045
I0524 05:33:31.216929 19864 solver.cpp:237] Iteration 57780, loss = 1.17571
I0524 05:33:31.216965 19864 solver.cpp:253]     Train net output #0: loss = 1.17571 (* 1 = 1.17571 loss)
I0524 05:33:31.216982 19864 sgd_solver.cpp:106] Iteration 57780, lr = 0.0045
I0524 05:33:33.418407 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_57834.caffemodel
I0524 05:33:33.484777 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_57834.solverstate
I0524 05:33:40.161032 19864 solver.cpp:237] Iteration 57994, loss = 1.26219
I0524 05:33:40.161077 19864 solver.cpp:253]     Train net output #0: loss = 1.26219 (* 1 = 1.26219 loss)
I0524 05:33:40.161093 19864 sgd_solver.cpp:106] Iteration 57994, lr = 0.0045
I0524 05:33:49.033663 19864 solver.cpp:237] Iteration 58208, loss = 1.21428
I0524 05:33:49.033851 19864 solver.cpp:253]     Train net output #0: loss = 1.21428 (* 1 = 1.21428 loss)
I0524 05:33:49.033866 19864 sgd_solver.cpp:106] Iteration 58208, lr = 0.0045
I0524 05:33:57.904280 19864 solver.cpp:237] Iteration 58422, loss = 1.03587
I0524 05:33:57.904315 19864 solver.cpp:253]     Train net output #0: loss = 1.03587 (* 1 = 1.03587 loss)
I0524 05:33:57.904332 19864 sgd_solver.cpp:106] Iteration 58422, lr = 0.0045
I0524 05:34:27.661074 19864 solver.cpp:237] Iteration 58636, loss = 1.32569
I0524 05:34:27.661269 19864 solver.cpp:253]     Train net output #0: loss = 1.32569 (* 1 = 1.32569 loss)
I0524 05:34:27.661284 19864 sgd_solver.cpp:106] Iteration 58636, lr = 0.0045
I0524 05:34:36.536975 19864 solver.cpp:237] Iteration 58850, loss = 1.17186
I0524 05:34:36.537009 19864 solver.cpp:253]     Train net output #0: loss = 1.17186 (* 1 = 1.17186 loss)
I0524 05:34:36.537027 19864 sgd_solver.cpp:106] Iteration 58850, lr = 0.0045
I0524 05:34:45.412518 19864 solver.cpp:237] Iteration 59064, loss = 1.25345
I0524 05:34:45.412555 19864 solver.cpp:253]     Train net output #0: loss = 1.25345 (* 1 = 1.25345 loss)
I0524 05:34:45.412575 19864 sgd_solver.cpp:106] Iteration 59064, lr = 0.0045
I0524 05:34:54.287698 19864 solver.cpp:237] Iteration 59278, loss = 1.06022
I0524 05:34:54.287734 19864 solver.cpp:253]     Train net output #0: loss = 1.06022 (* 1 = 1.06022 loss)
I0524 05:34:54.287749 19864 sgd_solver.cpp:106] Iteration 59278, lr = 0.0045
I0524 05:35:03.160434 19864 solver.cpp:237] Iteration 59492, loss = 1.37097
I0524 05:35:03.160614 19864 solver.cpp:253]     Train net output #0: loss = 1.37097 (* 1 = 1.37097 loss)
I0524 05:35:03.160627 19864 sgd_solver.cpp:106] Iteration 59492, lr = 0.0045
I0524 05:35:12.035662 19864 solver.cpp:237] Iteration 59706, loss = 1.37634
I0524 05:35:12.035697 19864 solver.cpp:253]     Train net output #0: loss = 1.37634 (* 1 = 1.37634 loss)
I0524 05:35:12.035714 19864 sgd_solver.cpp:106] Iteration 59706, lr = 0.0045
I0524 05:35:20.911120 19864 solver.cpp:237] Iteration 59920, loss = 1.27282
I0524 05:35:20.911156 19864 solver.cpp:253]     Train net output #0: loss = 1.27282 (* 1 = 1.27282 loss)
I0524 05:35:20.911172 19864 sgd_solver.cpp:106] Iteration 59920, lr = 0.0045
I0524 05:35:23.197492 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_59976.caffemodel
I0524 05:35:23.264176 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_59976.solverstate
I0524 05:35:23.842690 19864 solver.cpp:341] Iteration 59990, Testing net (#0)
I0524 05:36:32.700253 19864 solver.cpp:409]     Test net output #0: accuracy = 0.89109
I0524 05:36:32.700435 19864 solver.cpp:409]     Test net output #1: loss = 0.342404 (* 1 = 0.342404 loss)
I0524 05:36:59.574463 19864 solver.cpp:237] Iteration 60134, loss = 1.28963
I0524 05:36:59.574513 19864 solver.cpp:253]     Train net output #0: loss = 1.28963 (* 1 = 1.28963 loss)
I0524 05:36:59.574529 19864 sgd_solver.cpp:106] Iteration 60134, lr = 0.0045
I0524 05:37:08.475375 19864 solver.cpp:237] Iteration 60348, loss = 0.998749
I0524 05:37:08.475559 19864 solver.cpp:253]     Train net output #0: loss = 0.998749 (* 1 = 0.998749 loss)
I0524 05:37:08.475574 19864 sgd_solver.cpp:106] Iteration 60348, lr = 0.0045
I0524 05:37:17.371861 19864 solver.cpp:237] Iteration 60562, loss = 1.41083
I0524 05:37:17.371896 19864 solver.cpp:253]     Train net output #0: loss = 1.41083 (* 1 = 1.41083 loss)
I0524 05:37:17.371913 19864 sgd_solver.cpp:106] Iteration 60562, lr = 0.0045
I0524 05:37:26.269891 19864 solver.cpp:237] Iteration 60776, loss = 1.28763
I0524 05:37:26.269925 19864 solver.cpp:253]     Train net output #0: loss = 1.28763 (* 1 = 1.28763 loss)
I0524 05:37:26.269942 19864 sgd_solver.cpp:106] Iteration 60776, lr = 0.0045
I0524 05:37:35.165184 19864 solver.cpp:237] Iteration 60990, loss = 1.03603
I0524 05:37:35.165228 19864 solver.cpp:253]     Train net output #0: loss = 1.03603 (* 1 = 1.03603 loss)
I0524 05:37:35.165243 19864 sgd_solver.cpp:106] Iteration 60990, lr = 0.0045
I0524 05:37:44.067948 19864 solver.cpp:237] Iteration 61204, loss = 1.05252
I0524 05:37:44.068111 19864 solver.cpp:253]     Train net output #0: loss = 1.05252 (* 1 = 1.05252 loss)
I0524 05:37:44.068125 19864 sgd_solver.cpp:106] Iteration 61204, lr = 0.0045
I0524 05:37:52.970101 19864 solver.cpp:237] Iteration 61418, loss = 1.13397
I0524 05:37:52.970136 19864 solver.cpp:253]     Train net output #0: loss = 1.13397 (* 1 = 1.13397 loss)
I0524 05:37:52.970150 19864 sgd_solver.cpp:106] Iteration 61418, lr = 0.0045
I0524 05:38:22.779906 19864 solver.cpp:237] Iteration 61632, loss = 1.11707
I0524 05:38:22.780108 19864 solver.cpp:253]     Train net output #0: loss = 1.11707 (* 1 = 1.11707 loss)
I0524 05:38:22.780123 19864 sgd_solver.cpp:106] Iteration 61632, lr = 0.0045
I0524 05:38:31.674120 19864 solver.cpp:237] Iteration 61846, loss = 1.01649
I0524 05:38:31.674156 19864 solver.cpp:253]     Train net output #0: loss = 1.01649 (* 1 = 1.01649 loss)
I0524 05:38:31.674172 19864 sgd_solver.cpp:106] Iteration 61846, lr = 0.0045
I0524 05:38:40.569787 19864 solver.cpp:237] Iteration 62060, loss = 1.15158
I0524 05:38:40.569823 19864 solver.cpp:253]     Train net output #0: loss = 1.15158 (* 1 = 1.15158 loss)
I0524 05:38:40.569839 19864 sgd_solver.cpp:106] Iteration 62060, lr = 0.0045
I0524 05:38:42.941714 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_62118.caffemodel
I0524 05:38:43.009992 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_62118.solverstate
I0524 05:38:49.537037 19864 solver.cpp:237] Iteration 62274, loss = 1.3086
I0524 05:38:49.537086 19864 solver.cpp:253]     Train net output #0: loss = 1.3086 (* 1 = 1.3086 loss)
I0524 05:38:49.537103 19864 sgd_solver.cpp:106] Iteration 62274, lr = 0.0045
I0524 05:38:58.435292 19864 solver.cpp:237] Iteration 62488, loss = 1.09128
I0524 05:38:58.435463 19864 solver.cpp:253]     Train net output #0: loss = 1.09128 (* 1 = 1.09128 loss)
I0524 05:38:58.435477 19864 sgd_solver.cpp:106] Iteration 62488, lr = 0.0045
I0524 05:39:07.331102 19864 solver.cpp:237] Iteration 62702, loss = 1.24311
I0524 05:39:07.331136 19864 solver.cpp:253]     Train net output #0: loss = 1.24311 (* 1 = 1.24311 loss)
I0524 05:39:07.331153 19864 sgd_solver.cpp:106] Iteration 62702, lr = 0.0045
I0524 05:39:37.136304 19864 solver.cpp:237] Iteration 62916, loss = 1.08001
I0524 05:39:37.136484 19864 solver.cpp:253]     Train net output #0: loss = 1.08001 (* 1 = 1.08001 loss)
I0524 05:39:37.136498 19864 sgd_solver.cpp:106] Iteration 62916, lr = 0.0045
I0524 05:39:46.035261 19864 solver.cpp:237] Iteration 63130, loss = 1.59388
I0524 05:39:46.035296 19864 solver.cpp:253]     Train net output #0: loss = 1.59388 (* 1 = 1.59388 loss)
I0524 05:39:46.035315 19864 sgd_solver.cpp:106] Iteration 63130, lr = 0.0045
I0524 05:39:54.937794 19864 solver.cpp:237] Iteration 63344, loss = 1.07625
I0524 05:39:54.937829 19864 solver.cpp:253]     Train net output #0: loss = 1.07625 (* 1 = 1.07625 loss)
I0524 05:39:54.937844 19864 sgd_solver.cpp:106] Iteration 63344, lr = 0.0045
I0524 05:40:03.834995 19864 solver.cpp:237] Iteration 63558, loss = 1.06262
I0524 05:40:03.835043 19864 solver.cpp:253]     Train net output #0: loss = 1.06262 (* 1 = 1.06262 loss)
I0524 05:40:03.835059 19864 sgd_solver.cpp:106] Iteration 63558, lr = 0.0045
I0524 05:40:12.737853 19864 solver.cpp:237] Iteration 63772, loss = 1.09181
I0524 05:40:12.738016 19864 solver.cpp:253]     Train net output #0: loss = 1.09181 (* 1 = 1.09181 loss)
I0524 05:40:12.738030 19864 sgd_solver.cpp:106] Iteration 63772, lr = 0.0045
I0524 05:40:21.637048 19864 solver.cpp:237] Iteration 63986, loss = 0.968393
I0524 05:40:21.637084 19864 solver.cpp:253]     Train net output #0: loss = 0.968393 (* 1 = 0.968393 loss)
I0524 05:40:21.637097 19864 sgd_solver.cpp:106] Iteration 63986, lr = 0.0045
I0524 05:40:30.540648 19864 solver.cpp:237] Iteration 64200, loss = 1.05756
I0524 05:40:30.540689 19864 solver.cpp:253]     Train net output #0: loss = 1.05756 (* 1 = 1.05756 loss)
I0524 05:40:30.540710 19864 sgd_solver.cpp:106] Iteration 64200, lr = 0.0045
I0524 05:40:32.995574 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_64260.caffemodel
I0524 05:40:33.063609 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_64260.solverstate
I0524 05:40:33.688817 19864 solver.cpp:341] Iteration 64275, Testing net (#0)
I0524 05:41:21.330099 19864 solver.cpp:409]     Test net output #0: accuracy = 0.889529
I0524 05:41:21.330292 19864 solver.cpp:409]     Test net output #1: loss = 0.359903 (* 1 = 0.359903 loss)
I0524 05:41:48.029378 19864 solver.cpp:237] Iteration 64414, loss = 1.21351
I0524 05:41:48.029428 19864 solver.cpp:253]     Train net output #0: loss = 1.21351 (* 1 = 1.21351 loss)
I0524 05:41:48.029445 19864 sgd_solver.cpp:106] Iteration 64414, lr = 0.0045
I0524 05:41:56.908251 19864 solver.cpp:237] Iteration 64628, loss = 1.08473
I0524 05:41:56.908435 19864 solver.cpp:253]     Train net output #0: loss = 1.08473 (* 1 = 1.08473 loss)
I0524 05:41:56.908449 19864 sgd_solver.cpp:106] Iteration 64628, lr = 0.0045
I0524 05:42:05.777032 19864 solver.cpp:237] Iteration 64842, loss = 1.1459
I0524 05:42:05.777067 19864 solver.cpp:253]     Train net output #0: loss = 1.1459 (* 1 = 1.1459 loss)
I0524 05:42:05.777086 19864 sgd_solver.cpp:106] Iteration 64842, lr = 0.0045
I0524 05:42:14.654650 19864 solver.cpp:237] Iteration 65056, loss = 1.13112
I0524 05:42:14.654692 19864 solver.cpp:253]     Train net output #0: loss = 1.13112 (* 1 = 1.13112 loss)
I0524 05:42:14.654709 19864 sgd_solver.cpp:106] Iteration 65056, lr = 0.0045
I0524 05:42:23.531867 19864 solver.cpp:237] Iteration 65270, loss = 1.08095
I0524 05:42:23.531903 19864 solver.cpp:253]     Train net output #0: loss = 1.08095 (* 1 = 1.08095 loss)
I0524 05:42:23.531920 19864 sgd_solver.cpp:106] Iteration 65270, lr = 0.0045
I0524 05:42:32.400813 19864 solver.cpp:237] Iteration 65484, loss = 1.445
I0524 05:42:32.400986 19864 solver.cpp:253]     Train net output #0: loss = 1.445 (* 1 = 1.445 loss)
I0524 05:42:32.401000 19864 sgd_solver.cpp:106] Iteration 65484, lr = 0.0045
I0524 05:42:41.269600 19864 solver.cpp:237] Iteration 65698, loss = 1.3345
I0524 05:42:41.269634 19864 solver.cpp:253]     Train net output #0: loss = 1.3345 (* 1 = 1.3345 loss)
I0524 05:42:41.269651 19864 sgd_solver.cpp:106] Iteration 65698, lr = 0.0045
I0524 05:43:11.034145 19864 solver.cpp:237] Iteration 65912, loss = 0.976662
I0524 05:43:11.034332 19864 solver.cpp:253]     Train net output #0: loss = 0.976662 (* 1 = 0.976662 loss)
I0524 05:43:11.034348 19864 sgd_solver.cpp:106] Iteration 65912, lr = 0.0045
I0524 05:43:19.907776 19864 solver.cpp:237] Iteration 66126, loss = 1.26578
I0524 05:43:19.907810 19864 solver.cpp:253]     Train net output #0: loss = 1.26578 (* 1 = 1.26578 loss)
I0524 05:43:19.907829 19864 sgd_solver.cpp:106] Iteration 66126, lr = 0.0045
I0524 05:43:28.772058 19864 solver.cpp:237] Iteration 66340, loss = 1.11334
I0524 05:43:28.772094 19864 solver.cpp:253]     Train net output #0: loss = 1.11334 (* 1 = 1.11334 loss)
I0524 05:43:28.772116 19864 sgd_solver.cpp:106] Iteration 66340, lr = 0.0045
I0524 05:43:31.302367 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_66402.caffemodel
I0524 05:43:31.369401 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_66402.solverstate
I0524 05:43:37.709367 19864 solver.cpp:237] Iteration 66554, loss = 1.07972
I0524 05:43:37.709414 19864 solver.cpp:253]     Train net output #0: loss = 1.07972 (* 1 = 1.07972 loss)
I0524 05:43:37.709426 19864 sgd_solver.cpp:106] Iteration 66554, lr = 0.0045
I0524 05:43:46.574924 19864 solver.cpp:237] Iteration 66768, loss = 1.0728
I0524 05:43:46.575114 19864 solver.cpp:253]     Train net output #0: loss = 1.0728 (* 1 = 1.0728 loss)
I0524 05:43:46.575127 19864 sgd_solver.cpp:106] Iteration 66768, lr = 0.0045
I0524 05:43:55.449103 19864 solver.cpp:237] Iteration 66982, loss = 1.16727
I0524 05:43:55.449137 19864 solver.cpp:253]     Train net output #0: loss = 1.16727 (* 1 = 1.16727 loss)
I0524 05:43:55.449154 19864 sgd_solver.cpp:106] Iteration 66982, lr = 0.0045
I0524 05:44:25.198973 19864 solver.cpp:237] Iteration 67196, loss = 1.36557
I0524 05:44:25.199163 19864 solver.cpp:253]     Train net output #0: loss = 1.36557 (* 1 = 1.36557 loss)
I0524 05:44:25.199177 19864 sgd_solver.cpp:106] Iteration 67196, lr = 0.0045
I0524 05:44:34.074501 19864 solver.cpp:237] Iteration 67410, loss = 1.23374
I0524 05:44:34.074535 19864 solver.cpp:253]     Train net output #0: loss = 1.23374 (* 1 = 1.23374 loss)
I0524 05:44:34.074553 19864 sgd_solver.cpp:106] Iteration 67410, lr = 0.0045
I0524 05:44:42.948554 19864 solver.cpp:237] Iteration 67624, loss = 0.930188
I0524 05:44:42.948601 19864 solver.cpp:253]     Train net output #0: loss = 0.930188 (* 1 = 0.930188 loss)
I0524 05:44:42.948618 19864 sgd_solver.cpp:106] Iteration 67624, lr = 0.0045
I0524 05:44:51.821188 19864 solver.cpp:237] Iteration 67838, loss = 1.38746
I0524 05:44:51.821224 19864 solver.cpp:253]     Train net output #0: loss = 1.38746 (* 1 = 1.38746 loss)
I0524 05:44:51.821243 19864 sgd_solver.cpp:106] Iteration 67838, lr = 0.0045
I0524 05:45:00.690987 19864 solver.cpp:237] Iteration 68052, loss = 1.08533
I0524 05:45:00.691154 19864 solver.cpp:253]     Train net output #0: loss = 1.08533 (* 1 = 1.08533 loss)
I0524 05:45:00.691167 19864 sgd_solver.cpp:106] Iteration 68052, lr = 0.0045
I0524 05:45:09.570149 19864 solver.cpp:237] Iteration 68266, loss = 1.14194
I0524 05:45:09.570188 19864 solver.cpp:253]     Train net output #0: loss = 1.14194 (* 1 = 1.14194 loss)
I0524 05:45:09.570207 19864 sgd_solver.cpp:106] Iteration 68266, lr = 0.0045
I0524 05:45:18.443063 19864 solver.cpp:237] Iteration 68480, loss = 1.15752
I0524 05:45:18.443097 19864 solver.cpp:253]     Train net output #0: loss = 1.15752 (* 1 = 1.15752 loss)
I0524 05:45:18.443111 19864 sgd_solver.cpp:106] Iteration 68480, lr = 0.0045
I0524 05:45:21.056105 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_68544.caffemodel
I0524 05:45:21.122922 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_68544.solverstate
I0524 05:45:21.785585 19864 solver.cpp:341] Iteration 68560, Testing net (#0)
I0524 05:46:30.525825 19864 solver.cpp:409]     Test net output #0: accuracy = 0.893751
I0524 05:46:30.526012 19864 solver.cpp:409]     Test net output #1: loss = 0.341883 (* 1 = 0.341883 loss)
I0524 05:46:56.987658 19864 solver.cpp:237] Iteration 68694, loss = 1.19603
I0524 05:46:56.987709 19864 solver.cpp:253]     Train net output #0: loss = 1.19603 (* 1 = 1.19603 loss)
I0524 05:46:56.987725 19864 sgd_solver.cpp:106] Iteration 68694, lr = 0.0045
I0524 05:47:05.893585 19864 solver.cpp:237] Iteration 68908, loss = 1.04414
I0524 05:47:05.893756 19864 solver.cpp:253]     Train net output #0: loss = 1.04414 (* 1 = 1.04414 loss)
I0524 05:47:05.893770 19864 sgd_solver.cpp:106] Iteration 68908, lr = 0.0045
I0524 05:47:14.802690 19864 solver.cpp:237] Iteration 69122, loss = 1.28574
I0524 05:47:14.802736 19864 solver.cpp:253]     Train net output #0: loss = 1.28574 (* 1 = 1.28574 loss)
I0524 05:47:14.802753 19864 sgd_solver.cpp:106] Iteration 69122, lr = 0.0045
I0524 05:47:23.711235 19864 solver.cpp:237] Iteration 69336, loss = 1.14996
I0524 05:47:23.711269 19864 solver.cpp:253]     Train net output #0: loss = 1.14996 (* 1 = 1.14996 loss)
I0524 05:47:23.711285 19864 sgd_solver.cpp:106] Iteration 69336, lr = 0.0045
I0524 05:47:32.615561 19864 solver.cpp:237] Iteration 69550, loss = 1.47399
I0524 05:47:32.615599 19864 solver.cpp:253]     Train net output #0: loss = 1.47399 (* 1 = 1.47399 loss)
I0524 05:47:32.615619 19864 sgd_solver.cpp:106] Iteration 69550, lr = 0.0045
I0524 05:47:41.516223 19864 solver.cpp:237] Iteration 69764, loss = 1.40529
I0524 05:47:41.516402 19864 solver.cpp:253]     Train net output #0: loss = 1.40529 (* 1 = 1.40529 loss)
I0524 05:47:41.516414 19864 sgd_solver.cpp:106] Iteration 69764, lr = 0.0045
I0524 05:47:50.422544 19864 solver.cpp:237] Iteration 69978, loss = 1.03148
I0524 05:47:50.422577 19864 solver.cpp:253]     Train net output #0: loss = 1.03148 (* 1 = 1.03148 loss)
I0524 05:47:50.422592 19864 sgd_solver.cpp:106] Iteration 69978, lr = 0.0045
I0524 05:48:20.191670 19864 solver.cpp:237] Iteration 70192, loss = 1.16924
I0524 05:48:20.191862 19864 solver.cpp:253]     Train net output #0: loss = 1.16924 (* 1 = 1.16924 loss)
I0524 05:48:20.191877 19864 sgd_solver.cpp:106] Iteration 70192, lr = 0.0045
I0524 05:48:29.091864 19864 solver.cpp:237] Iteration 70406, loss = 0.869147
I0524 05:48:29.091904 19864 solver.cpp:253]     Train net output #0: loss = 0.869147 (* 1 = 0.869147 loss)
I0524 05:48:29.091924 19864 sgd_solver.cpp:106] Iteration 70406, lr = 0.0045
I0524 05:48:38.006934 19864 solver.cpp:237] Iteration 70620, loss = 1.38443
I0524 05:48:38.006970 19864 solver.cpp:253]     Train net output #0: loss = 1.38443 (* 1 = 1.38443 loss)
I0524 05:48:38.006984 19864 sgd_solver.cpp:106] Iteration 70620, lr = 0.0045
I0524 05:48:40.712162 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_70686.caffemodel
I0524 05:48:40.779422 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_70686.solverstate
I0524 05:48:46.972460 19864 solver.cpp:237] Iteration 70834, loss = 0.845294
I0524 05:48:46.972512 19864 solver.cpp:253]     Train net output #0: loss = 0.845294 (* 1 = 0.845294 loss)
I0524 05:48:46.972529 19864 sgd_solver.cpp:106] Iteration 70834, lr = 0.0045
I0524 05:48:55.874430 19864 solver.cpp:237] Iteration 71048, loss = 1.09373
I0524 05:48:55.874619 19864 solver.cpp:253]     Train net output #0: loss = 1.09373 (* 1 = 1.09373 loss)
I0524 05:48:55.874634 19864 sgd_solver.cpp:106] Iteration 71048, lr = 0.0045
I0524 05:49:04.782395 19864 solver.cpp:237] Iteration 71262, loss = 1.20839
I0524 05:49:04.782430 19864 solver.cpp:253]     Train net output #0: loss = 1.20839 (* 1 = 1.20839 loss)
I0524 05:49:04.782447 19864 sgd_solver.cpp:106] Iteration 71262, lr = 0.0045
I0524 05:49:34.609606 19864 solver.cpp:237] Iteration 71476, loss = 0.988125
I0524 05:49:34.609797 19864 solver.cpp:253]     Train net output #0: loss = 0.988125 (* 1 = 0.988125 loss)
I0524 05:49:34.609810 19864 sgd_solver.cpp:106] Iteration 71476, lr = 0.0045
I0524 05:49:43.514039 19864 solver.cpp:237] Iteration 71690, loss = 1.02114
I0524 05:49:43.514080 19864 solver.cpp:253]     Train net output #0: loss = 1.02114 (* 1 = 1.02114 loss)
I0524 05:49:43.514099 19864 sgd_solver.cpp:106] Iteration 71690, lr = 0.0045
I0524 05:49:52.426331 19864 solver.cpp:237] Iteration 71904, loss = 1.21762
I0524 05:49:52.426365 19864 solver.cpp:253]     Train net output #0: loss = 1.21762 (* 1 = 1.21762 loss)
I0524 05:49:52.426383 19864 sgd_solver.cpp:106] Iteration 71904, lr = 0.0045
I0524 05:50:01.333567 19864 solver.cpp:237] Iteration 72118, loss = 1.12737
I0524 05:50:01.333603 19864 solver.cpp:253]     Train net output #0: loss = 1.12737 (* 1 = 1.12737 loss)
I0524 05:50:01.333616 19864 sgd_solver.cpp:106] Iteration 72118, lr = 0.0045
I0524 05:50:10.238659 19864 solver.cpp:237] Iteration 72332, loss = 1.08219
I0524 05:50:10.238839 19864 solver.cpp:253]     Train net output #0: loss = 1.08219 (* 1 = 1.08219 loss)
I0524 05:50:10.238853 19864 sgd_solver.cpp:106] Iteration 72332, lr = 0.0045
I0524 05:50:19.143200 19864 solver.cpp:237] Iteration 72546, loss = 0.98201
I0524 05:50:19.143235 19864 solver.cpp:253]     Train net output #0: loss = 0.98201 (* 1 = 0.98201 loss)
I0524 05:50:19.143252 19864 sgd_solver.cpp:106] Iteration 72546, lr = 0.0045
I0524 05:50:28.049710 19864 solver.cpp:237] Iteration 72760, loss = 1.13497
I0524 05:50:28.049752 19864 solver.cpp:253]     Train net output #0: loss = 1.13497 (* 1 = 1.13497 loss)
I0524 05:50:28.049765 19864 sgd_solver.cpp:106] Iteration 72760, lr = 0.0045
I0524 05:50:30.839539 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_72828.caffemodel
I0524 05:50:30.905151 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_72828.solverstate
I0524 05:50:31.609733 19864 solver.cpp:341] Iteration 72845, Testing net (#0)
I0524 05:51:19.555388 19864 solver.cpp:409]     Test net output #0: accuracy = 0.896532
I0524 05:51:19.555584 19864 solver.cpp:409]     Test net output #1: loss = 0.351348 (* 1 = 0.351348 loss)
I0524 05:51:45.791127 19864 solver.cpp:237] Iteration 72974, loss = 1.16911
I0524 05:51:45.791177 19864 solver.cpp:253]     Train net output #0: loss = 1.16911 (* 1 = 1.16911 loss)
I0524 05:51:45.791191 19864 sgd_solver.cpp:106] Iteration 72974, lr = 0.0045
I0524 05:51:54.680948 19864 solver.cpp:237] Iteration 73188, loss = 0.848802
I0524 05:51:54.681120 19864 solver.cpp:253]     Train net output #0: loss = 0.848802 (* 1 = 0.848802 loss)
I0524 05:51:54.681134 19864 sgd_solver.cpp:106] Iteration 73188, lr = 0.0045
I0524 05:52:03.566975 19864 solver.cpp:237] Iteration 73402, loss = 1.41345
I0524 05:52:03.567010 19864 solver.cpp:253]     Train net output #0: loss = 1.41345 (* 1 = 1.41345 loss)
I0524 05:52:03.567028 19864 sgd_solver.cpp:106] Iteration 73402, lr = 0.0045
I0524 05:52:12.452549 19864 solver.cpp:237] Iteration 73616, loss = 1.10799
I0524 05:52:12.452589 19864 solver.cpp:253]     Train net output #0: loss = 1.10799 (* 1 = 1.10799 loss)
I0524 05:52:12.452610 19864 sgd_solver.cpp:106] Iteration 73616, lr = 0.0045
I0524 05:52:21.332422 19864 solver.cpp:237] Iteration 73830, loss = 1.26565
I0524 05:52:21.332458 19864 solver.cpp:253]     Train net output #0: loss = 1.26565 (* 1 = 1.26565 loss)
I0524 05:52:21.332473 19864 sgd_solver.cpp:106] Iteration 73830, lr = 0.0045
I0524 05:52:30.214640 19864 solver.cpp:237] Iteration 74044, loss = 1.4337
I0524 05:52:30.214807 19864 solver.cpp:253]     Train net output #0: loss = 1.4337 (* 1 = 1.4337 loss)
I0524 05:52:30.214819 19864 sgd_solver.cpp:106] Iteration 74044, lr = 0.0045
I0524 05:52:39.104465 19864 solver.cpp:237] Iteration 74258, loss = 1.31292
I0524 05:52:39.104512 19864 solver.cpp:253]     Train net output #0: loss = 1.31292 (* 1 = 1.31292 loss)
I0524 05:52:39.104529 19864 sgd_solver.cpp:106] Iteration 74258, lr = 0.0045
I0524 05:53:08.866106 19864 solver.cpp:237] Iteration 74472, loss = 1.25281
I0524 05:53:08.866297 19864 solver.cpp:253]     Train net output #0: loss = 1.25281 (* 1 = 1.25281 loss)
I0524 05:53:08.866310 19864 sgd_solver.cpp:106] Iteration 74472, lr = 0.0045
I0524 05:53:17.752120 19864 solver.cpp:237] Iteration 74686, loss = 1.19229
I0524 05:53:17.752154 19864 solver.cpp:253]     Train net output #0: loss = 1.19229 (* 1 = 1.19229 loss)
I0524 05:53:17.752172 19864 sgd_solver.cpp:106] Iteration 74686, lr = 0.0045
I0524 05:53:26.639942 19864 solver.cpp:237] Iteration 74900, loss = 1.05652
I0524 05:53:26.639989 19864 solver.cpp:253]     Train net output #0: loss = 1.05652 (* 1 = 1.05652 loss)
I0524 05:53:26.640007 19864 sgd_solver.cpp:106] Iteration 74900, lr = 0.0045
I0524 05:53:29.510511 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_74970.caffemodel
I0524 05:53:29.579274 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_74970.solverstate
I0524 05:53:35.601305 19864 solver.cpp:237] Iteration 75114, loss = 1.02272
I0524 05:53:35.601354 19864 solver.cpp:253]     Train net output #0: loss = 1.02272 (* 1 = 1.02272 loss)
I0524 05:53:35.601371 19864 sgd_solver.cpp:106] Iteration 75114, lr = 0.0045
I0524 05:53:44.490984 19864 solver.cpp:237] Iteration 75328, loss = 0.993753
I0524 05:53:44.491169 19864 solver.cpp:253]     Train net output #0: loss = 0.993753 (* 1 = 0.993753 loss)
I0524 05:53:44.491184 19864 sgd_solver.cpp:106] Iteration 75328, lr = 0.0045
I0524 05:53:53.378434 19864 solver.cpp:237] Iteration 75542, loss = 1.01906
I0524 05:53:53.378479 19864 solver.cpp:253]     Train net output #0: loss = 1.01906 (* 1 = 1.01906 loss)
I0524 05:53:53.378501 19864 sgd_solver.cpp:106] Iteration 75542, lr = 0.0045
I0524 05:54:23.139482 19864 solver.cpp:237] Iteration 75756, loss = 1.06603
I0524 05:54:23.139680 19864 solver.cpp:253]     Train net output #0: loss = 1.06603 (* 1 = 1.06603 loss)
I0524 05:54:23.139695 19864 sgd_solver.cpp:106] Iteration 75756, lr = 0.0045
I0524 05:54:32.031649 19864 solver.cpp:237] Iteration 75970, loss = 1.25733
I0524 05:54:32.031684 19864 solver.cpp:253]     Train net output #0: loss = 1.25733 (* 1 = 1.25733 loss)
I0524 05:54:32.031702 19864 sgd_solver.cpp:106] Iteration 75970, lr = 0.0045
I0524 05:54:40.919101 19864 solver.cpp:237] Iteration 76184, loss = 1.11457
I0524 05:54:40.919142 19864 solver.cpp:253]     Train net output #0: loss = 1.11457 (* 1 = 1.11457 loss)
I0524 05:54:40.919162 19864 sgd_solver.cpp:106] Iteration 76184, lr = 0.0045
I0524 05:54:49.811236 19864 solver.cpp:237] Iteration 76398, loss = 1.22484
I0524 05:54:49.811272 19864 solver.cpp:253]     Train net output #0: loss = 1.22484 (* 1 = 1.22484 loss)
I0524 05:54:49.811288 19864 sgd_solver.cpp:106] Iteration 76398, lr = 0.0045
I0524 05:54:58.700006 19864 solver.cpp:237] Iteration 76612, loss = 1.05956
I0524 05:54:58.700175 19864 solver.cpp:253]     Train net output #0: loss = 1.05956 (* 1 = 1.05956 loss)
I0524 05:54:58.700188 19864 sgd_solver.cpp:106] Iteration 76612, lr = 0.0045
I0524 05:55:07.589292 19864 solver.cpp:237] Iteration 76826, loss = 1.19369
I0524 05:55:07.589337 19864 solver.cpp:253]     Train net output #0: loss = 1.19369 (* 1 = 1.19369 loss)
I0524 05:55:07.589352 19864 sgd_solver.cpp:106] Iteration 76826, lr = 0.0045
I0524 05:55:16.479146 19864 solver.cpp:237] Iteration 77040, loss = 1.09904
I0524 05:55:16.479181 19864 solver.cpp:253]     Train net output #0: loss = 1.09904 (* 1 = 1.09904 loss)
I0524 05:55:16.479197 19864 sgd_solver.cpp:106] Iteration 77040, lr = 0.0045
I0524 05:55:19.431236 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_77112.caffemodel
I0524 05:55:19.499968 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_77112.solverstate
I0524 05:55:20.253234 19864 solver.cpp:341] Iteration 77130, Testing net (#0)
I0524 05:56:29.057328 19864 solver.cpp:409]     Test net output #0: accuracy = 0.896598
I0524 05:56:29.057518 19864 solver.cpp:409]     Test net output #1: loss = 0.324451 (* 1 = 0.324451 loss)
I0524 05:56:55.096118 19864 solver.cpp:237] Iteration 77254, loss = 1.26528
I0524 05:56:55.096168 19864 solver.cpp:253]     Train net output #0: loss = 1.26528 (* 1 = 1.26528 loss)
I0524 05:56:55.096184 19864 sgd_solver.cpp:106] Iteration 77254, lr = 0.0045
I0524 05:57:03.983566 19864 solver.cpp:237] Iteration 77468, loss = 1.03369
I0524 05:57:03.983738 19864 solver.cpp:253]     Train net output #0: loss = 1.03369 (* 1 = 1.03369 loss)
I0524 05:57:03.983752 19864 sgd_solver.cpp:106] Iteration 77468, lr = 0.0045
I0524 05:57:12.874651 19864 solver.cpp:237] Iteration 77682, loss = 1.27399
I0524 05:57:12.874696 19864 solver.cpp:253]     Train net output #0: loss = 1.27399 (* 1 = 1.27399 loss)
I0524 05:57:12.874713 19864 sgd_solver.cpp:106] Iteration 77682, lr = 0.0045
I0524 05:57:21.762636 19864 solver.cpp:237] Iteration 77896, loss = 1.06844
I0524 05:57:21.762672 19864 solver.cpp:253]     Train net output #0: loss = 1.06844 (* 1 = 1.06844 loss)
I0524 05:57:21.762688 19864 sgd_solver.cpp:106] Iteration 77896, lr = 0.0045
I0524 05:57:30.647408 19864 solver.cpp:237] Iteration 78110, loss = 1.2484
I0524 05:57:30.647442 19864 solver.cpp:253]     Train net output #0: loss = 1.2484 (* 1 = 1.2484 loss)
I0524 05:57:30.647459 19864 sgd_solver.cpp:106] Iteration 78110, lr = 0.0045
I0524 05:57:39.542260 19864 solver.cpp:237] Iteration 78324, loss = 1.15201
I0524 05:57:39.542445 19864 solver.cpp:253]     Train net output #0: loss = 1.15201 (* 1 = 1.15201 loss)
I0524 05:57:39.542460 19864 sgd_solver.cpp:106] Iteration 78324, lr = 0.0045
I0524 05:57:48.437124 19864 solver.cpp:237] Iteration 78538, loss = 1.26579
I0524 05:57:48.437158 19864 solver.cpp:253]     Train net output #0: loss = 1.26579 (* 1 = 1.26579 loss)
I0524 05:57:48.437175 19864 sgd_solver.cpp:106] Iteration 78538, lr = 0.0045
I0524 05:58:18.188971 19864 solver.cpp:237] Iteration 78752, loss = 1.02622
I0524 05:58:18.189167 19864 solver.cpp:253]     Train net output #0: loss = 1.02622 (* 1 = 1.02622 loss)
I0524 05:58:18.189183 19864 sgd_solver.cpp:106] Iteration 78752, lr = 0.0045
I0524 05:58:27.078377 19864 solver.cpp:237] Iteration 78966, loss = 1.05366
I0524 05:58:27.078423 19864 solver.cpp:253]     Train net output #0: loss = 1.05366 (* 1 = 1.05366 loss)
I0524 05:58:27.078438 19864 sgd_solver.cpp:106] Iteration 78966, lr = 0.0045
I0524 05:58:35.970862 19864 solver.cpp:237] Iteration 79180, loss = 1.05471
I0524 05:58:35.970898 19864 solver.cpp:253]     Train net output #0: loss = 1.05471 (* 1 = 1.05471 loss)
I0524 05:58:35.970913 19864 sgd_solver.cpp:106] Iteration 79180, lr = 0.0045
I0524 05:58:39.008640 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_79254.caffemodel
I0524 05:58:39.075340 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_79254.solverstate
I0524 05:58:44.927239 19864 solver.cpp:237] Iteration 79394, loss = 1.06939
I0524 05:58:44.927286 19864 solver.cpp:253]     Train net output #0: loss = 1.06939 (* 1 = 1.06939 loss)
I0524 05:58:44.927302 19864 sgd_solver.cpp:106] Iteration 79394, lr = 0.0045
I0524 05:58:53.815577 19864 solver.cpp:237] Iteration 79608, loss = 1.07167
I0524 05:58:53.815767 19864 solver.cpp:253]     Train net output #0: loss = 1.07167 (* 1 = 1.07167 loss)
I0524 05:58:53.815780 19864 sgd_solver.cpp:106] Iteration 79608, lr = 0.0045
I0524 05:59:02.698329 19864 solver.cpp:237] Iteration 79822, loss = 1.12493
I0524 05:59:02.698364 19864 solver.cpp:253]     Train net output #0: loss = 1.12493 (* 1 = 1.12493 loss)
I0524 05:59:02.698380 19864 sgd_solver.cpp:106] Iteration 79822, lr = 0.0045
I0524 05:59:32.493604 19864 solver.cpp:237] Iteration 80036, loss = 1.11413
I0524 05:59:32.493806 19864 solver.cpp:253]     Train net output #0: loss = 1.11413 (* 1 = 1.11413 loss)
I0524 05:59:32.493820 19864 sgd_solver.cpp:106] Iteration 80036, lr = 0.0045
I0524 05:59:41.373014 19864 solver.cpp:237] Iteration 80250, loss = 1.14316
I0524 05:59:41.373056 19864 solver.cpp:253]     Train net output #0: loss = 1.14316 (* 1 = 1.14316 loss)
I0524 05:59:41.373075 19864 sgd_solver.cpp:106] Iteration 80250, lr = 0.0045
I0524 05:59:50.262056 19864 solver.cpp:237] Iteration 80464, loss = 1.23909
I0524 05:59:50.262091 19864 solver.cpp:253]     Train net output #0: loss = 1.23909 (* 1 = 1.23909 loss)
I0524 05:59:50.262104 19864 sgd_solver.cpp:106] Iteration 80464, lr = 0.0045
I0524 05:59:59.148887 19864 solver.cpp:237] Iteration 80678, loss = 1.01223
I0524 05:59:59.148922 19864 solver.cpp:253]     Train net output #0: loss = 1.01223 (* 1 = 1.01223 loss)
I0524 05:59:59.148938 19864 sgd_solver.cpp:106] Iteration 80678, lr = 0.0045
I0524 06:00:08.042599 19864 solver.cpp:237] Iteration 80892, loss = 1.20019
I0524 06:00:08.042794 19864 solver.cpp:253]     Train net output #0: loss = 1.20019 (* 1 = 1.20019 loss)
I0524 06:00:08.042809 19864 sgd_solver.cpp:106] Iteration 80892, lr = 0.0045
I0524 06:00:16.931200 19864 solver.cpp:237] Iteration 81106, loss = 1.07556
I0524 06:00:16.931236 19864 solver.cpp:253]     Train net output #0: loss = 1.07556 (* 1 = 1.07556 loss)
I0524 06:00:16.931249 19864 sgd_solver.cpp:106] Iteration 81106, lr = 0.0045
I0524 06:00:25.819751 19864 solver.cpp:237] Iteration 81320, loss = 0.972614
I0524 06:00:25.819787 19864 solver.cpp:253]     Train net output #0: loss = 0.972614 (* 1 = 0.972614 loss)
I0524 06:00:25.819803 19864 sgd_solver.cpp:106] Iteration 81320, lr = 0.0045
I0524 06:00:28.936250 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_81396.caffemodel
I0524 06:00:29.002650 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_81396.solverstate
I0524 06:00:29.790488 19864 solver.cpp:341] Iteration 81415, Testing net (#0)
I0524 06:01:17.378594 19864 solver.cpp:409]     Test net output #0: accuracy = 0.896765
I0524 06:01:17.378785 19864 solver.cpp:409]     Test net output #1: loss = 0.330066 (* 1 = 0.330066 loss)
I0524 06:01:43.270081 19864 solver.cpp:237] Iteration 81534, loss = 1.26472
I0524 06:01:43.270129 19864 solver.cpp:253]     Train net output #0: loss = 1.26472 (* 1 = 1.26472 loss)
I0524 06:01:43.270148 19864 sgd_solver.cpp:106] Iteration 81534, lr = 0.0045
I0524 06:01:52.162230 19864 solver.cpp:237] Iteration 81748, loss = 1.07148
I0524 06:01:52.162406 19864 solver.cpp:253]     Train net output #0: loss = 1.07148 (* 1 = 1.07148 loss)
I0524 06:01:52.162420 19864 sgd_solver.cpp:106] Iteration 81748, lr = 0.0045
I0524 06:02:01.054889 19864 solver.cpp:237] Iteration 81962, loss = 1.33083
I0524 06:02:01.054924 19864 solver.cpp:253]     Train net output #0: loss = 1.33083 (* 1 = 1.33083 loss)
I0524 06:02:01.054941 19864 sgd_solver.cpp:106] Iteration 81962, lr = 0.0045
I0524 06:02:09.938670 19864 solver.cpp:237] Iteration 82176, loss = 1.18126
I0524 06:02:09.938712 19864 solver.cpp:253]     Train net output #0: loss = 1.18126 (* 1 = 1.18126 loss)
I0524 06:02:09.938730 19864 sgd_solver.cpp:106] Iteration 82176, lr = 0.0045
I0524 06:02:18.836206 19864 solver.cpp:237] Iteration 82390, loss = 1.24662
I0524 06:02:18.836241 19864 solver.cpp:253]     Train net output #0: loss = 1.24662 (* 1 = 1.24662 loss)
I0524 06:02:18.836254 19864 sgd_solver.cpp:106] Iteration 82390, lr = 0.0045
I0524 06:02:27.726444 19864 solver.cpp:237] Iteration 82604, loss = 1.05061
I0524 06:02:27.726613 19864 solver.cpp:253]     Train net output #0: loss = 1.05061 (* 1 = 1.05061 loss)
I0524 06:02:27.726627 19864 sgd_solver.cpp:106] Iteration 82604, lr = 0.0045
I0524 06:02:36.613129 19864 solver.cpp:237] Iteration 82818, loss = 1.14419
I0524 06:02:36.613168 19864 solver.cpp:253]     Train net output #0: loss = 1.14419 (* 1 = 1.14419 loss)
I0524 06:02:36.613186 19864 sgd_solver.cpp:106] Iteration 82818, lr = 0.0045
I0524 06:03:06.356310 19864 solver.cpp:237] Iteration 83032, loss = 1.18674
I0524 06:03:06.356505 19864 solver.cpp:253]     Train net output #0: loss = 1.18674 (* 1 = 1.18674 loss)
I0524 06:03:06.356519 19864 sgd_solver.cpp:106] Iteration 83032, lr = 0.0045
I0524 06:03:15.244114 19864 solver.cpp:237] Iteration 83246, loss = 1.09123
I0524 06:03:15.244148 19864 solver.cpp:253]     Train net output #0: loss = 1.09123 (* 1 = 1.09123 loss)
I0524 06:03:15.244163 19864 sgd_solver.cpp:106] Iteration 83246, lr = 0.0045
I0524 06:03:24.133287 19864 solver.cpp:237] Iteration 83460, loss = 0.998576
I0524 06:03:24.133332 19864 solver.cpp:253]     Train net output #0: loss = 0.998576 (* 1 = 0.998576 loss)
I0524 06:03:24.133348 19864 sgd_solver.cpp:106] Iteration 83460, lr = 0.0045
I0524 06:03:27.332893 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_83538.caffemodel
I0524 06:03:27.399884 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_83538.solverstate
I0524 06:03:33.086447 19864 solver.cpp:237] Iteration 83674, loss = 1.14864
I0524 06:03:33.086493 19864 solver.cpp:253]     Train net output #0: loss = 1.14864 (* 1 = 1.14864 loss)
I0524 06:03:33.086511 19864 sgd_solver.cpp:106] Iteration 83674, lr = 0.0045
I0524 06:03:41.973409 19864 solver.cpp:237] Iteration 83888, loss = 0.975914
I0524 06:03:41.973597 19864 solver.cpp:253]     Train net output #0: loss = 0.975914 (* 1 = 0.975914 loss)
I0524 06:03:41.973611 19864 sgd_solver.cpp:106] Iteration 83888, lr = 0.0045
I0524 06:03:50.856482 19864 solver.cpp:237] Iteration 84102, loss = 1.06886
I0524 06:03:50.856531 19864 solver.cpp:253]     Train net output #0: loss = 1.06886 (* 1 = 1.06886 loss)
I0524 06:03:50.856544 19864 sgd_solver.cpp:106] Iteration 84102, lr = 0.0045
I0524 06:04:20.685940 19864 solver.cpp:237] Iteration 84316, loss = 1.15773
I0524 06:04:20.686139 19864 solver.cpp:253]     Train net output #0: loss = 1.15773 (* 1 = 1.15773 loss)
I0524 06:04:20.686154 19864 sgd_solver.cpp:106] Iteration 84316, lr = 0.0045
I0524 06:04:29.576923 19864 solver.cpp:237] Iteration 84530, loss = 0.951669
I0524 06:04:29.576961 19864 solver.cpp:253]     Train net output #0: loss = 0.951669 (* 1 = 0.951669 loss)
I0524 06:04:29.576977 19864 sgd_solver.cpp:106] Iteration 84530, lr = 0.0045
I0524 06:04:38.469976 19864 solver.cpp:237] Iteration 84744, loss = 1.13133
I0524 06:04:38.470018 19864 solver.cpp:253]     Train net output #0: loss = 1.13133 (* 1 = 1.13133 loss)
I0524 06:04:38.470038 19864 sgd_solver.cpp:106] Iteration 84744, lr = 0.0045
I0524 06:04:47.364038 19864 solver.cpp:237] Iteration 84958, loss = 1.11002
I0524 06:04:47.364074 19864 solver.cpp:253]     Train net output #0: loss = 1.11002 (* 1 = 1.11002 loss)
I0524 06:04:47.364089 19864 sgd_solver.cpp:106] Iteration 84958, lr = 0.0045
I0524 06:04:56.252379 19864 solver.cpp:237] Iteration 85172, loss = 0.98092
I0524 06:04:56.252553 19864 solver.cpp:253]     Train net output #0: loss = 0.98092 (* 1 = 0.98092 loss)
I0524 06:04:56.252569 19864 sgd_solver.cpp:106] Iteration 85172, lr = 0.0045
I0524 06:05:05.145066 19864 solver.cpp:237] Iteration 85386, loss = 1.10548
I0524 06:05:05.145114 19864 solver.cpp:253]     Train net output #0: loss = 1.10548 (* 1 = 1.10548 loss)
I0524 06:05:05.145131 19864 sgd_solver.cpp:106] Iteration 85386, lr = 0.0045
I0524 06:05:14.027115 19864 solver.cpp:237] Iteration 85600, loss = 1.08449
I0524 06:05:14.027150 19864 solver.cpp:253]     Train net output #0: loss = 1.08449 (* 1 = 1.08449 loss)
I0524 06:05:14.027168 19864 sgd_solver.cpp:106] Iteration 85600, lr = 0.0045
I0524 06:05:17.311030 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_85680.caffemodel
I0524 06:05:17.383266 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_85680.solverstate
I0524 06:05:18.215292 19864 solver.cpp:341] Iteration 85700, Testing net (#0)
I0524 06:06:26.981490 19864 solver.cpp:409]     Test net output #0: accuracy = 0.893477
I0524 06:06:26.981683 19864 solver.cpp:409]     Test net output #1: loss = 0.331672 (* 1 = 0.331672 loss)
I0524 06:06:52.594218 19864 solver.cpp:237] Iteration 85814, loss = 1.11124
I0524 06:06:52.594269 19864 solver.cpp:253]     Train net output #0: loss = 1.11124 (* 1 = 1.11124 loss)
I0524 06:06:52.594282 19864 sgd_solver.cpp:106] Iteration 85814, lr = 0.0045
I0524 06:07:01.468924 19864 solver.cpp:237] Iteration 86028, loss = 1.12897
I0524 06:07:01.469110 19864 solver.cpp:253]     Train net output #0: loss = 1.12897 (* 1 = 1.12897 loss)
I0524 06:07:01.469123 19864 sgd_solver.cpp:106] Iteration 86028, lr = 0.0045
I0524 06:07:10.346552 19864 solver.cpp:237] Iteration 86242, loss = 1.21326
I0524 06:07:10.346593 19864 solver.cpp:253]     Train net output #0: loss = 1.21326 (* 1 = 1.21326 loss)
I0524 06:07:10.346613 19864 sgd_solver.cpp:106] Iteration 86242, lr = 0.0045
I0524 06:07:19.226107 19864 solver.cpp:237] Iteration 86456, loss = 1.16469
I0524 06:07:19.226143 19864 solver.cpp:253]     Train net output #0: loss = 1.16469 (* 1 = 1.16469 loss)
I0524 06:07:19.226161 19864 sgd_solver.cpp:106] Iteration 86456, lr = 0.0045
I0524 06:07:28.109273 19864 solver.cpp:237] Iteration 86670, loss = 1.11468
I0524 06:07:28.109309 19864 solver.cpp:253]     Train net output #0: loss = 1.11468 (* 1 = 1.11468 loss)
I0524 06:07:28.109326 19864 sgd_solver.cpp:106] Iteration 86670, lr = 0.0045
I0524 06:07:36.983965 19864 solver.cpp:237] Iteration 86884, loss = 1.05398
I0524 06:07:36.984156 19864 solver.cpp:253]     Train net output #0: loss = 1.05398 (* 1 = 1.05398 loss)
I0524 06:07:36.984170 19864 sgd_solver.cpp:106] Iteration 86884, lr = 0.0045
I0524 06:07:45.867733 19864 solver.cpp:237] Iteration 87098, loss = 1.19867
I0524 06:07:45.867768 19864 solver.cpp:253]     Train net output #0: loss = 1.19867 (* 1 = 1.19867 loss)
I0524 06:07:45.867784 19864 sgd_solver.cpp:106] Iteration 87098, lr = 0.0045
I0524 06:08:15.598853 19864 solver.cpp:237] Iteration 87312, loss = 1.17663
I0524 06:08:15.599051 19864 solver.cpp:253]     Train net output #0: loss = 1.17663 (* 1 = 1.17663 loss)
I0524 06:08:15.599066 19864 sgd_solver.cpp:106] Iteration 87312, lr = 0.0045
I0524 06:08:24.476186 19864 solver.cpp:237] Iteration 87526, loss = 1.13514
I0524 06:08:24.476227 19864 solver.cpp:253]     Train net output #0: loss = 1.13514 (* 1 = 1.13514 loss)
I0524 06:08:24.476240 19864 sgd_solver.cpp:106] Iteration 87526, lr = 0.0045
I0524 06:08:33.354351 19864 solver.cpp:237] Iteration 87740, loss = 1.06427
I0524 06:08:33.354387 19864 solver.cpp:253]     Train net output #0: loss = 1.06427 (* 1 = 1.06427 loss)
I0524 06:08:33.354404 19864 sgd_solver.cpp:106] Iteration 87740, lr = 0.0045
I0524 06:08:36.718344 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_87822.caffemodel
I0524 06:08:36.784803 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_87822.solverstate
I0524 06:08:42.300212 19864 solver.cpp:237] Iteration 87954, loss = 1.08742
I0524 06:08:42.300259 19864 solver.cpp:253]     Train net output #0: loss = 1.08742 (* 1 = 1.08742 loss)
I0524 06:08:42.300272 19864 sgd_solver.cpp:106] Iteration 87954, lr = 0.0045
I0524 06:08:51.180163 19864 solver.cpp:237] Iteration 88168, loss = 1.3082
I0524 06:08:51.180361 19864 solver.cpp:253]     Train net output #0: loss = 1.3082 (* 1 = 1.3082 loss)
I0524 06:08:51.180376 19864 sgd_solver.cpp:106] Iteration 88168, lr = 0.0045
I0524 06:09:00.060348 19864 solver.cpp:237] Iteration 88382, loss = 0.96195
I0524 06:09:00.060382 19864 solver.cpp:253]     Train net output #0: loss = 0.96195 (* 1 = 0.96195 loss)
I0524 06:09:00.060398 19864 sgd_solver.cpp:106] Iteration 88382, lr = 0.0045
I0524 06:09:29.785827 19864 solver.cpp:237] Iteration 88596, loss = 1.1362
I0524 06:09:29.786023 19864 solver.cpp:253]     Train net output #0: loss = 1.1362 (* 1 = 1.1362 loss)
I0524 06:09:29.786039 19864 sgd_solver.cpp:106] Iteration 88596, lr = 0.0045
I0524 06:09:38.664551 19864 solver.cpp:237] Iteration 88810, loss = 1.16875
I0524 06:09:38.664599 19864 solver.cpp:253]     Train net output #0: loss = 1.16875 (* 1 = 1.16875 loss)
I0524 06:09:38.664616 19864 sgd_solver.cpp:106] Iteration 88810, lr = 0.0045
I0524 06:09:47.544929 19864 solver.cpp:237] Iteration 89024, loss = 1.13429
I0524 06:09:47.544965 19864 solver.cpp:253]     Train net output #0: loss = 1.13429 (* 1 = 1.13429 loss)
I0524 06:09:47.544981 19864 sgd_solver.cpp:106] Iteration 89024, lr = 0.0045
I0524 06:09:56.416421 19864 solver.cpp:237] Iteration 89238, loss = 1.33156
I0524 06:09:56.416456 19864 solver.cpp:253]     Train net output #0: loss = 1.33156 (* 1 = 1.33156 loss)
I0524 06:09:56.416473 19864 sgd_solver.cpp:106] Iteration 89238, lr = 0.0045
I0524 06:10:05.285665 19864 solver.cpp:237] Iteration 89452, loss = 1.02762
I0524 06:10:05.285864 19864 solver.cpp:253]     Train net output #0: loss = 1.02762 (* 1 = 1.02762 loss)
I0524 06:10:05.285878 19864 sgd_solver.cpp:106] Iteration 89452, lr = 0.0045
I0524 06:10:14.163507 19864 solver.cpp:237] Iteration 89666, loss = 1.46459
I0524 06:10:14.163542 19864 solver.cpp:253]     Train net output #0: loss = 1.46459 (* 1 = 1.46459 loss)
I0524 06:10:14.163560 19864 sgd_solver.cpp:106] Iteration 89666, lr = 0.0045
I0524 06:10:23.038241 19864 solver.cpp:237] Iteration 89880, loss = 1.04958
I0524 06:10:23.038277 19864 solver.cpp:253]     Train net output #0: loss = 1.04958 (* 1 = 1.04958 loss)
I0524 06:10:23.038290 19864 sgd_solver.cpp:106] Iteration 89880, lr = 0.0045
I0524 06:10:26.483675 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_89964.caffemodel
I0524 06:10:26.549906 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_89964.solverstate
I0524 06:10:27.418344 19864 solver.cpp:341] Iteration 89985, Testing net (#0)
I0524 06:11:15.345723 19864 solver.cpp:409]     Test net output #0: accuracy = 0.897266
I0524 06:11:15.345919 19864 solver.cpp:409]     Test net output #1: loss = 0.331292 (* 1 = 0.331292 loss)
I0524 06:11:40.759217 19864 solver.cpp:237] Iteration 90094, loss = 1.05087
I0524 06:11:40.759268 19864 solver.cpp:253]     Train net output #0: loss = 1.05087 (* 1 = 1.05087 loss)
I0524 06:11:40.759284 19864 sgd_solver.cpp:106] Iteration 90094, lr = 0.0045
I0524 06:11:49.658994 19864 solver.cpp:237] Iteration 90308, loss = 1.06393
I0524 06:11:49.659184 19864 solver.cpp:253]     Train net output #0: loss = 1.06393 (* 1 = 1.06393 loss)
I0524 06:11:49.659198 19864 sgd_solver.cpp:106] Iteration 90308, lr = 0.0045
I0524 06:11:58.559897 19864 solver.cpp:237] Iteration 90522, loss = 1.12599
I0524 06:11:58.559931 19864 solver.cpp:253]     Train net output #0: loss = 1.12599 (* 1 = 1.12599 loss)
I0524 06:11:58.559948 19864 sgd_solver.cpp:106] Iteration 90522, lr = 0.0045
I0524 06:12:07.458482 19864 solver.cpp:237] Iteration 90736, loss = 1.24233
I0524 06:12:07.458523 19864 solver.cpp:253]     Train net output #0: loss = 1.24233 (* 1 = 1.24233 loss)
I0524 06:12:07.458542 19864 sgd_solver.cpp:106] Iteration 90736, lr = 0.0045
I0524 06:12:16.357396 19864 solver.cpp:237] Iteration 90950, loss = 1.14759
I0524 06:12:16.357432 19864 solver.cpp:253]     Train net output #0: loss = 1.14759 (* 1 = 1.14759 loss)
I0524 06:12:16.357448 19864 sgd_solver.cpp:106] Iteration 90950, lr = 0.0045
I0524 06:12:25.256453 19864 solver.cpp:237] Iteration 91164, loss = 1.08807
I0524 06:12:25.256628 19864 solver.cpp:253]     Train net output #0: loss = 1.08807 (* 1 = 1.08807 loss)
I0524 06:12:25.256641 19864 sgd_solver.cpp:106] Iteration 91164, lr = 0.0045
I0524 06:12:34.159257 19864 solver.cpp:237] Iteration 91378, loss = 1.14741
I0524 06:12:34.159297 19864 solver.cpp:253]     Train net output #0: loss = 1.14741 (* 1 = 1.14741 loss)
I0524 06:12:34.159319 19864 sgd_solver.cpp:106] Iteration 91378, lr = 0.0045
I0524 06:13:03.925226 19864 solver.cpp:237] Iteration 91592, loss = 1.08701
I0524 06:13:03.925423 19864 solver.cpp:253]     Train net output #0: loss = 1.08701 (* 1 = 1.08701 loss)
I0524 06:13:03.925438 19864 sgd_solver.cpp:106] Iteration 91592, lr = 0.0045
I0524 06:13:12.822332 19864 solver.cpp:237] Iteration 91806, loss = 1.23841
I0524 06:13:12.822366 19864 solver.cpp:253]     Train net output #0: loss = 1.23841 (* 1 = 1.23841 loss)
I0524 06:13:12.822384 19864 sgd_solver.cpp:106] Iteration 91806, lr = 0.0045
I0524 06:13:21.728462 19864 solver.cpp:237] Iteration 92020, loss = 1.18573
I0524 06:13:21.728498 19864 solver.cpp:253]     Train net output #0: loss = 1.18573 (* 1 = 1.18573 loss)
I0524 06:13:21.728514 19864 sgd_solver.cpp:106] Iteration 92020, lr = 0.0045
I0524 06:13:25.265202 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_92106.caffemodel
I0524 06:13:25.331112 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_92106.solverstate
I0524 06:13:30.693680 19864 solver.cpp:237] Iteration 92234, loss = 1.25377
I0524 06:13:30.693722 19864 solver.cpp:253]     Train net output #0: loss = 1.25377 (* 1 = 1.25377 loss)
I0524 06:13:30.693742 19864 sgd_solver.cpp:106] Iteration 92234, lr = 0.0045
I0524 06:13:39.594269 19864 solver.cpp:237] Iteration 92448, loss = 1.489
I0524 06:13:39.594468 19864 solver.cpp:253]     Train net output #0: loss = 1.489 (* 1 = 1.489 loss)
I0524 06:13:39.594482 19864 sgd_solver.cpp:106] Iteration 92448, lr = 0.0045
I0524 06:13:48.496683 19864 solver.cpp:237] Iteration 92662, loss = 1.06646
I0524 06:13:48.496729 19864 solver.cpp:253]     Train net output #0: loss = 1.06646 (* 1 = 1.06646 loss)
I0524 06:13:48.496747 19864 sgd_solver.cpp:106] Iteration 92662, lr = 0.0045
I0524 06:14:18.252653 19864 solver.cpp:237] Iteration 92876, loss = 0.853293
I0524 06:14:18.252853 19864 solver.cpp:253]     Train net output #0: loss = 0.853293 (* 1 = 0.853293 loss)
I0524 06:14:18.252868 19864 sgd_solver.cpp:106] Iteration 92876, lr = 0.0045
I0524 06:14:27.149202 19864 solver.cpp:237] Iteration 93090, loss = 1.13697
I0524 06:14:27.149238 19864 solver.cpp:253]     Train net output #0: loss = 1.13697 (* 1 = 1.13697 loss)
I0524 06:14:27.149252 19864 sgd_solver.cpp:106] Iteration 93090, lr = 0.0045
I0524 06:14:36.052131 19864 solver.cpp:237] Iteration 93304, loss = 1.08894
I0524 06:14:36.052167 19864 solver.cpp:253]     Train net output #0: loss = 1.08894 (* 1 = 1.08894 loss)
I0524 06:14:36.052182 19864 sgd_solver.cpp:106] Iteration 93304, lr = 0.0045
I0524 06:14:44.953742 19864 solver.cpp:237] Iteration 93518, loss = 1.10886
I0524 06:14:44.953789 19864 solver.cpp:253]     Train net output #0: loss = 1.10886 (* 1 = 1.10886 loss)
I0524 06:14:44.953805 19864 sgd_solver.cpp:106] Iteration 93518, lr = 0.0045
I0524 06:14:53.857427 19864 solver.cpp:237] Iteration 93732, loss = 0.961158
I0524 06:14:53.857606 19864 solver.cpp:253]     Train net output #0: loss = 0.961158 (* 1 = 0.961158 loss)
I0524 06:14:53.857621 19864 sgd_solver.cpp:106] Iteration 93732, lr = 0.0045
I0524 06:15:02.761214 19864 solver.cpp:237] Iteration 93946, loss = 1.15728
I0524 06:15:02.761257 19864 solver.cpp:253]     Train net output #0: loss = 1.15728 (* 1 = 1.15728 loss)
I0524 06:15:02.761274 19864 sgd_solver.cpp:106] Iteration 93946, lr = 0.0045
I0524 06:15:11.657286 19864 solver.cpp:237] Iteration 94160, loss = 1.15793
I0524 06:15:11.657321 19864 solver.cpp:253]     Train net output #0: loss = 1.15793 (* 1 = 1.15793 loss)
I0524 06:15:11.657335 19864 sgd_solver.cpp:106] Iteration 94160, lr = 0.0045
I0524 06:15:15.278187 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_94248.caffemodel
I0524 06:15:15.344292 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_94248.solverstate
I0524 06:15:16.257369 19864 solver.cpp:341] Iteration 94270, Testing net (#0)
I0524 06:16:25.088035 19864 solver.cpp:409]     Test net output #0: accuracy = 0.897393
I0524 06:16:25.088238 19864 solver.cpp:409]     Test net output #1: loss = 0.352561 (* 1 = 0.352561 loss)
I0524 06:16:50.298741 19864 solver.cpp:237] Iteration 94374, loss = 1.1453
I0524 06:16:50.298791 19864 solver.cpp:253]     Train net output #0: loss = 1.1453 (* 1 = 1.1453 loss)
I0524 06:16:50.298807 19864 sgd_solver.cpp:106] Iteration 94374, lr = 0.0045
I0524 06:16:59.169430 19864 solver.cpp:237] Iteration 94588, loss = 1.29887
I0524 06:16:59.169613 19864 solver.cpp:253]     Train net output #0: loss = 1.29887 (* 1 = 1.29887 loss)
I0524 06:16:59.169627 19864 sgd_solver.cpp:106] Iteration 94588, lr = 0.0045
I0524 06:17:08.045738 19864 solver.cpp:237] Iteration 94802, loss = 1.40531
I0524 06:17:08.045780 19864 solver.cpp:253]     Train net output #0: loss = 1.40531 (* 1 = 1.40531 loss)
I0524 06:17:08.045799 19864 sgd_solver.cpp:106] Iteration 94802, lr = 0.0045
I0524 06:17:16.920361 19864 solver.cpp:237] Iteration 95016, loss = 1.20568
I0524 06:17:16.920395 19864 solver.cpp:253]     Train net output #0: loss = 1.20568 (* 1 = 1.20568 loss)
I0524 06:17:16.920408 19864 sgd_solver.cpp:106] Iteration 95016, lr = 0.0045
I0524 06:17:25.792404 19864 solver.cpp:237] Iteration 95230, loss = 0.948831
I0524 06:17:25.792440 19864 solver.cpp:253]     Train net output #0: loss = 0.948831 (* 1 = 0.948831 loss)
I0524 06:17:25.792454 19864 sgd_solver.cpp:106] Iteration 95230, lr = 0.0045
I0524 06:17:34.663789 19864 solver.cpp:237] Iteration 95444, loss = 1.14586
I0524 06:17:34.663974 19864 solver.cpp:253]     Train net output #0: loss = 1.14586 (* 1 = 1.14586 loss)
I0524 06:17:34.663987 19864 sgd_solver.cpp:106] Iteration 95444, lr = 0.0045
I0524 06:17:43.527987 19864 solver.cpp:237] Iteration 95658, loss = 1.06386
I0524 06:17:43.528020 19864 solver.cpp:253]     Train net output #0: loss = 1.06386 (* 1 = 1.06386 loss)
I0524 06:17:43.528035 19864 sgd_solver.cpp:106] Iteration 95658, lr = 0.0045
I0524 06:18:13.308125 19864 solver.cpp:237] Iteration 95872, loss = 0.901491
I0524 06:18:13.308323 19864 solver.cpp:253]     Train net output #0: loss = 0.901491 (* 1 = 0.901491 loss)
I0524 06:18:13.308339 19864 sgd_solver.cpp:106] Iteration 95872, lr = 0.0045
I0524 06:18:22.181015 19864 solver.cpp:237] Iteration 96086, loss = 1.12885
I0524 06:18:22.181056 19864 solver.cpp:253]     Train net output #0: loss = 1.12885 (* 1 = 1.12885 loss)
I0524 06:18:22.181077 19864 sgd_solver.cpp:106] Iteration 96086, lr = 0.0045
I0524 06:18:31.054199 19864 solver.cpp:237] Iteration 96300, loss = 0.881697
I0524 06:18:31.054237 19864 solver.cpp:253]     Train net output #0: loss = 0.881697 (* 1 = 0.881697 loss)
I0524 06:18:31.054252 19864 sgd_solver.cpp:106] Iteration 96300, lr = 0.0045
I0524 06:18:34.742489 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_96390.caffemodel
I0524 06:18:34.810763 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_96390.solverstate
I0524 06:18:39.994599 19864 solver.cpp:237] Iteration 96514, loss = 1.15811
I0524 06:18:39.994648 19864 solver.cpp:253]     Train net output #0: loss = 1.15811 (* 1 = 1.15811 loss)
I0524 06:18:39.994664 19864 sgd_solver.cpp:106] Iteration 96514, lr = 0.0045
I0524 06:18:48.872125 19864 solver.cpp:237] Iteration 96728, loss = 1.14606
I0524 06:18:48.872326 19864 solver.cpp:253]     Train net output #0: loss = 1.14606 (* 1 = 1.14606 loss)
I0524 06:18:48.872341 19864 sgd_solver.cpp:106] Iteration 96728, lr = 0.0045
I0524 06:18:57.750819 19864 solver.cpp:237] Iteration 96942, loss = 1.16412
I0524 06:18:57.750854 19864 solver.cpp:253]     Train net output #0: loss = 1.16412 (* 1 = 1.16412 loss)
I0524 06:18:57.750869 19864 sgd_solver.cpp:106] Iteration 96942, lr = 0.0045
I0524 06:19:27.525558 19864 solver.cpp:237] Iteration 97156, loss = 1.26439
I0524 06:19:27.525759 19864 solver.cpp:253]     Train net output #0: loss = 1.26439 (* 1 = 1.26439 loss)
I0524 06:19:27.525774 19864 sgd_solver.cpp:106] Iteration 97156, lr = 0.0045
I0524 06:19:36.404335 19864 solver.cpp:237] Iteration 97370, loss = 1.06377
I0524 06:19:36.404368 19864 solver.cpp:253]     Train net output #0: loss = 1.06377 (* 1 = 1.06377 loss)
I0524 06:19:36.404386 19864 sgd_solver.cpp:106] Iteration 97370, lr = 0.0045
I0524 06:19:45.275856 19864 solver.cpp:237] Iteration 97584, loss = 1.14827
I0524 06:19:45.275890 19864 solver.cpp:253]     Train net output #0: loss = 1.14827 (* 1 = 1.14827 loss)
I0524 06:19:45.275909 19864 sgd_solver.cpp:106] Iteration 97584, lr = 0.0045
I0524 06:19:54.152155 19864 solver.cpp:237] Iteration 97798, loss = 1.42657
I0524 06:19:54.152190 19864 solver.cpp:253]     Train net output #0: loss = 1.42657 (* 1 = 1.42657 loss)
I0524 06:19:54.152207 19864 sgd_solver.cpp:106] Iteration 97798, lr = 0.0045
I0524 06:20:03.027606 19864 solver.cpp:237] Iteration 98012, loss = 1.39179
I0524 06:20:03.027806 19864 solver.cpp:253]     Train net output #0: loss = 1.39179 (* 1 = 1.39179 loss)
I0524 06:20:03.027820 19864 sgd_solver.cpp:106] Iteration 98012, lr = 0.0045
I0524 06:20:11.902942 19864 solver.cpp:237] Iteration 98226, loss = 1.30844
I0524 06:20:11.902976 19864 solver.cpp:253]     Train net output #0: loss = 1.30844 (* 1 = 1.30844 loss)
I0524 06:20:11.902994 19864 sgd_solver.cpp:106] Iteration 98226, lr = 0.0045
I0524 06:20:20.781005 19864 solver.cpp:237] Iteration 98440, loss = 1.06566
I0524 06:20:20.781040 19864 solver.cpp:253]     Train net output #0: loss = 1.06566 (* 1 = 1.06566 loss)
I0524 06:20:20.781055 19864 sgd_solver.cpp:106] Iteration 98440, lr = 0.0045
I0524 06:20:24.557819 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_98532.caffemodel
I0524 06:20:24.624722 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_98532.solverstate
I0524 06:20:25.576342 19864 solver.cpp:341] Iteration 98555, Testing net (#0)
I0524 06:21:13.171291 19864 solver.cpp:409]     Test net output #0: accuracy = 0.899366
I0524 06:21:13.171491 19864 solver.cpp:409]     Test net output #1: loss = 0.328366 (* 1 = 0.328366 loss)
I0524 06:21:38.195556 19864 solver.cpp:237] Iteration 98654, loss = 0.94275
I0524 06:21:38.195607 19864 solver.cpp:253]     Train net output #0: loss = 0.94275 (* 1 = 0.94275 loss)
I0524 06:21:38.195621 19864 sgd_solver.cpp:106] Iteration 98654, lr = 0.0045
I0524 06:21:47.104706 19864 solver.cpp:237] Iteration 98868, loss = 1.28936
I0524 06:21:47.104898 19864 solver.cpp:253]     Train net output #0: loss = 1.28936 (* 1 = 1.28936 loss)
I0524 06:21:47.104912 19864 sgd_solver.cpp:106] Iteration 98868, lr = 0.0045
I0524 06:21:56.010021 19864 solver.cpp:237] Iteration 99082, loss = 1.4064
I0524 06:21:56.010056 19864 solver.cpp:253]     Train net output #0: loss = 1.4064 (* 1 = 1.4064 loss)
I0524 06:21:56.010074 19864 sgd_solver.cpp:106] Iteration 99082, lr = 0.0045
I0524 06:22:04.911417 19864 solver.cpp:237] Iteration 99296, loss = 1.07761
I0524 06:22:04.911453 19864 solver.cpp:253]     Train net output #0: loss = 1.07761 (* 1 = 1.07761 loss)
I0524 06:22:04.911466 19864 sgd_solver.cpp:106] Iteration 99296, lr = 0.0045
I0524 06:22:13.818107 19864 solver.cpp:237] Iteration 99510, loss = 1.12905
I0524 06:22:13.818146 19864 solver.cpp:253]     Train net output #0: loss = 1.12905 (* 1 = 1.12905 loss)
I0524 06:22:13.818166 19864 sgd_solver.cpp:106] Iteration 99510, lr = 0.0045
I0524 06:22:22.725225 19864 solver.cpp:237] Iteration 99724, loss = 1.2332
I0524 06:22:22.725405 19864 solver.cpp:253]     Train net output #0: loss = 1.2332 (* 1 = 1.2332 loss)
I0524 06:22:22.725419 19864 sgd_solver.cpp:106] Iteration 99724, lr = 0.0045
I0524 06:22:31.632335 19864 solver.cpp:237] Iteration 99938, loss = 1.05369
I0524 06:22:31.632369 19864 solver.cpp:253]     Train net output #0: loss = 1.05369 (* 1 = 1.05369 loss)
I0524 06:22:31.632386 19864 sgd_solver.cpp:106] Iteration 99938, lr = 0.0045
I0524 06:23:01.444942 19864 solver.cpp:237] Iteration 100152, loss = 1.21561
I0524 06:23:01.445169 19864 solver.cpp:253]     Train net output #0: loss = 1.21561 (* 1 = 1.21561 loss)
I0524 06:23:01.445183 19864 sgd_solver.cpp:106] Iteration 100152, lr = 0.0045
I0524 06:23:10.347607 19864 solver.cpp:237] Iteration 100366, loss = 1.28395
I0524 06:23:10.347651 19864 solver.cpp:253]     Train net output #0: loss = 1.28395 (* 1 = 1.28395 loss)
I0524 06:23:10.347666 19864 sgd_solver.cpp:106] Iteration 100366, lr = 0.0045
I0524 06:23:19.253053 19864 solver.cpp:237] Iteration 100580, loss = 1.18741
I0524 06:23:19.253088 19864 solver.cpp:253]     Train net output #0: loss = 1.18741 (* 1 = 1.18741 loss)
I0524 06:23:19.253101 19864 sgd_solver.cpp:106] Iteration 100580, lr = 0.0045
I0524 06:23:23.123626 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_100674.caffemodel
I0524 06:23:23.190554 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_100674.solverstate
I0524 06:23:28.220943 19864 solver.cpp:237] Iteration 100794, loss = 1.37082
I0524 06:23:28.220989 19864 solver.cpp:253]     Train net output #0: loss = 1.37082 (* 1 = 1.37082 loss)
I0524 06:23:28.221004 19864 sgd_solver.cpp:106] Iteration 100794, lr = 0.0045
I0524 06:23:37.121356 19864 solver.cpp:237] Iteration 101008, loss = 1.18288
I0524 06:23:37.121542 19864 solver.cpp:253]     Train net output #0: loss = 1.18288 (* 1 = 1.18288 loss)
I0524 06:23:37.121556 19864 sgd_solver.cpp:106] Iteration 101008, lr = 0.0045
I0524 06:23:46.029144 19864 solver.cpp:237] Iteration 101222, loss = 0.893077
I0524 06:23:46.029178 19864 solver.cpp:253]     Train net output #0: loss = 0.893077 (* 1 = 0.893077 loss)
I0524 06:23:46.029196 19864 sgd_solver.cpp:106] Iteration 101222, lr = 0.0045
I0524 06:24:15.829463 19864 solver.cpp:237] Iteration 101436, loss = 1.05219
I0524 06:24:15.829669 19864 solver.cpp:253]     Train net output #0: loss = 1.05219 (* 1 = 1.05219 loss)
I0524 06:24:15.829684 19864 sgd_solver.cpp:106] Iteration 101436, lr = 0.0045
I0524 06:24:24.737141 19864 solver.cpp:237] Iteration 101650, loss = 1.21382
I0524 06:24:24.737176 19864 solver.cpp:253]     Train net output #0: loss = 1.21382 (* 1 = 1.21382 loss)
I0524 06:24:24.737195 19864 sgd_solver.cpp:106] Iteration 101650, lr = 0.0045
I0524 06:24:33.643033 19864 solver.cpp:237] Iteration 101864, loss = 1.17335
I0524 06:24:33.643069 19864 solver.cpp:253]     Train net output #0: loss = 1.17335 (* 1 = 1.17335 loss)
I0524 06:24:33.643085 19864 sgd_solver.cpp:106] Iteration 101864, lr = 0.0045
I0524 06:24:42.545585 19864 solver.cpp:237] Iteration 102078, loss = 1.25443
I0524 06:24:42.545624 19864 solver.cpp:253]     Train net output #0: loss = 1.25443 (* 1 = 1.25443 loss)
I0524 06:24:42.545644 19864 sgd_solver.cpp:106] Iteration 102078, lr = 0.0045
I0524 06:24:51.447765 19864 solver.cpp:237] Iteration 102292, loss = 1.14319
I0524 06:24:51.447942 19864 solver.cpp:253]     Train net output #0: loss = 1.14319 (* 1 = 1.14319 loss)
I0524 06:24:51.447957 19864 sgd_solver.cpp:106] Iteration 102292, lr = 0.0045
I0524 06:25:00.356142 19864 solver.cpp:237] Iteration 102506, loss = 1.10115
I0524 06:25:00.356178 19864 solver.cpp:253]     Train net output #0: loss = 1.10115 (* 1 = 1.10115 loss)
I0524 06:25:00.356194 19864 sgd_solver.cpp:106] Iteration 102506, lr = 0.0045
I0524 06:25:09.259928 19864 solver.cpp:237] Iteration 102720, loss = 1.1631
I0524 06:25:09.259974 19864 solver.cpp:253]     Train net output #0: loss = 1.1631 (* 1 = 1.1631 loss)
I0524 06:25:09.259990 19864 sgd_solver.cpp:106] Iteration 102720, lr = 0.0045
I0524 06:25:13.209605 19864 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_102816.caffemodel
I0524 06:25:13.276229 19864 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0045_2016-05-20T15.49.15.660923_iter_102816.solverstate
I0524 06:25:14.270723 19864 solver.cpp:341] Iteration 102840, Testing net (#0)
aprun: Apid 11260167: Caught signal Terminated, sending to application
*** Aborted at 1464085551 (unix time) try "date -d @1464085551" if you are using GNU date ***
aprun: Apid 11260167: Caught signal Terminated, sending to application
aprun: Apid 11260167: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7244 exceeded limit 7200
PC: @     0x2aaab9276640 (unknown)
*** SIGTERM (@0x4d95) received by PID 19864 (TID 0x2aaac746f900) from PID 19861; stack trace: ***
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab9276640 (unknown)
    @     0x2aaab930eb7d (unknown)
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab928a408 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11260167: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11260167: Caught signal Terminated, sending to application
aprun: Apid 11260167: Caught signal Terminated, sending to application
aprun: Apid 11260167: Caught signal Terminated, sending to application
aprun: Apid 11260167: Caught signal Terminated, sending to application
aprun: Apid 11260167: Caught signal Terminated, sending to application
aprun: Apid 11260167: Caught signal Terminated, sending to application
