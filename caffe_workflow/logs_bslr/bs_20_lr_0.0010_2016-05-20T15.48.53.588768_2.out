2811874
I0526 13:06:23.285024 15070 caffe.cpp:184] Using GPUs 0
I0526 13:06:23.724284 15070 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.001
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768.prototxt"
I0526 13:06:23.726016 15070 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768.prototxt
I0526 13:06:23.737282 15070 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 13:06:23.737339 15070 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 13:06:23.737685 15070 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 13:06:23.737864 15070 layer_factory.hpp:77] Creating layer data_hdf5
I0526 13:06:23.737889 15070 net.cpp:106] Creating Layer data_hdf5
I0526 13:06:23.737902 15070 net.cpp:411] data_hdf5 -> data
I0526 13:06:23.737937 15070 net.cpp:411] data_hdf5 -> label
I0526 13:06:23.737969 15070 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 13:06:23.748072 15070 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 13:06:23.763068 15070 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 13:06:45.352092 15070 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 13:06:45.357244 15070 net.cpp:150] Setting up data_hdf5
I0526 13:06:45.357285 15070 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 13:06:45.357300 15070 net.cpp:157] Top shape: 20 (20)
I0526 13:06:45.357312 15070 net.cpp:165] Memory required for data: 508080
I0526 13:06:45.357326 15070 layer_factory.hpp:77] Creating layer conv1
I0526 13:06:45.357359 15070 net.cpp:106] Creating Layer conv1
I0526 13:06:45.357370 15070 net.cpp:454] conv1 <- data
I0526 13:06:45.357391 15070 net.cpp:411] conv1 -> conv1
I0526 13:06:48.818717 15070 net.cpp:150] Setting up conv1
I0526 13:06:48.818764 15070 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:06:48.818775 15070 net.cpp:165] Memory required for data: 6037680
I0526 13:06:48.818804 15070 layer_factory.hpp:77] Creating layer relu1
I0526 13:06:48.818826 15070 net.cpp:106] Creating Layer relu1
I0526 13:06:48.818836 15070 net.cpp:454] relu1 <- conv1
I0526 13:06:48.818851 15070 net.cpp:397] relu1 -> conv1 (in-place)
I0526 13:06:48.819375 15070 net.cpp:150] Setting up relu1
I0526 13:06:48.819391 15070 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:06:48.819401 15070 net.cpp:165] Memory required for data: 11567280
I0526 13:06:48.819411 15070 layer_factory.hpp:77] Creating layer pool1
I0526 13:06:48.819429 15070 net.cpp:106] Creating Layer pool1
I0526 13:06:48.819439 15070 net.cpp:454] pool1 <- conv1
I0526 13:06:48.819453 15070 net.cpp:411] pool1 -> pool1
I0526 13:06:48.819533 15070 net.cpp:150] Setting up pool1
I0526 13:06:48.819547 15070 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 13:06:48.819557 15070 net.cpp:165] Memory required for data: 14332080
I0526 13:06:48.819568 15070 layer_factory.hpp:77] Creating layer conv2
I0526 13:06:48.819591 15070 net.cpp:106] Creating Layer conv2
I0526 13:06:48.819602 15070 net.cpp:454] conv2 <- pool1
I0526 13:06:48.819614 15070 net.cpp:411] conv2 -> conv2
I0526 13:06:48.822322 15070 net.cpp:150] Setting up conv2
I0526 13:06:48.822350 15070 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:06:48.822363 15070 net.cpp:165] Memory required for data: 18306480
I0526 13:06:48.822382 15070 layer_factory.hpp:77] Creating layer relu2
I0526 13:06:48.822397 15070 net.cpp:106] Creating Layer relu2
I0526 13:06:48.822407 15070 net.cpp:454] relu2 <- conv2
I0526 13:06:48.822420 15070 net.cpp:397] relu2 -> conv2 (in-place)
I0526 13:06:48.822762 15070 net.cpp:150] Setting up relu2
I0526 13:06:48.822777 15070 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:06:48.822787 15070 net.cpp:165] Memory required for data: 22280880
I0526 13:06:48.822798 15070 layer_factory.hpp:77] Creating layer pool2
I0526 13:06:48.822809 15070 net.cpp:106] Creating Layer pool2
I0526 13:06:48.822819 15070 net.cpp:454] pool2 <- conv2
I0526 13:06:48.822832 15070 net.cpp:411] pool2 -> pool2
I0526 13:06:48.822913 15070 net.cpp:150] Setting up pool2
I0526 13:06:48.822927 15070 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 13:06:48.822937 15070 net.cpp:165] Memory required for data: 24268080
I0526 13:06:48.822945 15070 layer_factory.hpp:77] Creating layer conv3
I0526 13:06:48.822964 15070 net.cpp:106] Creating Layer conv3
I0526 13:06:48.822974 15070 net.cpp:454] conv3 <- pool2
I0526 13:06:48.822988 15070 net.cpp:411] conv3 -> conv3
I0526 13:06:48.824929 15070 net.cpp:150] Setting up conv3
I0526 13:06:48.824949 15070 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:06:48.824959 15070 net.cpp:165] Memory required for data: 26436400
I0526 13:06:48.824978 15070 layer_factory.hpp:77] Creating layer relu3
I0526 13:06:48.824995 15070 net.cpp:106] Creating Layer relu3
I0526 13:06:48.825004 15070 net.cpp:454] relu3 <- conv3
I0526 13:06:48.825018 15070 net.cpp:397] relu3 -> conv3 (in-place)
I0526 13:06:48.825489 15070 net.cpp:150] Setting up relu3
I0526 13:06:48.825505 15070 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:06:48.825515 15070 net.cpp:165] Memory required for data: 28604720
I0526 13:06:48.825526 15070 layer_factory.hpp:77] Creating layer pool3
I0526 13:06:48.825539 15070 net.cpp:106] Creating Layer pool3
I0526 13:06:48.825549 15070 net.cpp:454] pool3 <- conv3
I0526 13:06:48.825562 15070 net.cpp:411] pool3 -> pool3
I0526 13:06:48.825630 15070 net.cpp:150] Setting up pool3
I0526 13:06:48.825644 15070 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 13:06:48.825654 15070 net.cpp:165] Memory required for data: 29688880
I0526 13:06:48.825664 15070 layer_factory.hpp:77] Creating layer conv4
I0526 13:06:48.825680 15070 net.cpp:106] Creating Layer conv4
I0526 13:06:48.825690 15070 net.cpp:454] conv4 <- pool3
I0526 13:06:48.825705 15070 net.cpp:411] conv4 -> conv4
I0526 13:06:48.828425 15070 net.cpp:150] Setting up conv4
I0526 13:06:48.828454 15070 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:06:48.828464 15070 net.cpp:165] Memory required for data: 30414640
I0526 13:06:48.828481 15070 layer_factory.hpp:77] Creating layer relu4
I0526 13:06:48.828495 15070 net.cpp:106] Creating Layer relu4
I0526 13:06:48.828506 15070 net.cpp:454] relu4 <- conv4
I0526 13:06:48.828521 15070 net.cpp:397] relu4 -> conv4 (in-place)
I0526 13:06:48.828984 15070 net.cpp:150] Setting up relu4
I0526 13:06:48.829000 15070 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:06:48.829011 15070 net.cpp:165] Memory required for data: 31140400
I0526 13:06:48.829021 15070 layer_factory.hpp:77] Creating layer pool4
I0526 13:06:48.829035 15070 net.cpp:106] Creating Layer pool4
I0526 13:06:48.829044 15070 net.cpp:454] pool4 <- conv4
I0526 13:06:48.829058 15070 net.cpp:411] pool4 -> pool4
I0526 13:06:48.829126 15070 net.cpp:150] Setting up pool4
I0526 13:06:48.829139 15070 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 13:06:48.829150 15070 net.cpp:165] Memory required for data: 31503280
I0526 13:06:48.829160 15070 layer_factory.hpp:77] Creating layer ip1
I0526 13:06:48.829182 15070 net.cpp:106] Creating Layer ip1
I0526 13:06:48.829193 15070 net.cpp:454] ip1 <- pool4
I0526 13:06:48.829206 15070 net.cpp:411] ip1 -> ip1
I0526 13:06:48.844631 15070 net.cpp:150] Setting up ip1
I0526 13:06:48.844656 15070 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:06:48.844668 15070 net.cpp:165] Memory required for data: 31518960
I0526 13:06:48.844692 15070 layer_factory.hpp:77] Creating layer relu5
I0526 13:06:48.844707 15070 net.cpp:106] Creating Layer relu5
I0526 13:06:48.844717 15070 net.cpp:454] relu5 <- ip1
I0526 13:06:48.844732 15070 net.cpp:397] relu5 -> ip1 (in-place)
I0526 13:06:48.845072 15070 net.cpp:150] Setting up relu5
I0526 13:06:48.845087 15070 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:06:48.845098 15070 net.cpp:165] Memory required for data: 31534640
I0526 13:06:48.845108 15070 layer_factory.hpp:77] Creating layer drop1
I0526 13:06:48.845130 15070 net.cpp:106] Creating Layer drop1
I0526 13:06:48.845140 15070 net.cpp:454] drop1 <- ip1
I0526 13:06:48.845152 15070 net.cpp:397] drop1 -> ip1 (in-place)
I0526 13:06:48.845212 15070 net.cpp:150] Setting up drop1
I0526 13:06:48.845226 15070 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:06:48.845235 15070 net.cpp:165] Memory required for data: 31550320
I0526 13:06:48.845245 15070 layer_factory.hpp:77] Creating layer ip2
I0526 13:06:48.845263 15070 net.cpp:106] Creating Layer ip2
I0526 13:06:48.845273 15070 net.cpp:454] ip2 <- ip1
I0526 13:06:48.845288 15070 net.cpp:411] ip2 -> ip2
I0526 13:06:48.845749 15070 net.cpp:150] Setting up ip2
I0526 13:06:48.845762 15070 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:06:48.845772 15070 net.cpp:165] Memory required for data: 31558160
I0526 13:06:48.845788 15070 layer_factory.hpp:77] Creating layer relu6
I0526 13:06:48.845800 15070 net.cpp:106] Creating Layer relu6
I0526 13:06:48.845809 15070 net.cpp:454] relu6 <- ip2
I0526 13:06:48.845821 15070 net.cpp:397] relu6 -> ip2 (in-place)
I0526 13:06:48.846338 15070 net.cpp:150] Setting up relu6
I0526 13:06:48.846354 15070 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:06:48.846364 15070 net.cpp:165] Memory required for data: 31566000
I0526 13:06:48.846374 15070 layer_factory.hpp:77] Creating layer drop2
I0526 13:06:48.846387 15070 net.cpp:106] Creating Layer drop2
I0526 13:06:48.846397 15070 net.cpp:454] drop2 <- ip2
I0526 13:06:48.846410 15070 net.cpp:397] drop2 -> ip2 (in-place)
I0526 13:06:48.846452 15070 net.cpp:150] Setting up drop2
I0526 13:06:48.846465 15070 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:06:48.846477 15070 net.cpp:165] Memory required for data: 31573840
I0526 13:06:48.846487 15070 layer_factory.hpp:77] Creating layer ip3
I0526 13:06:48.846500 15070 net.cpp:106] Creating Layer ip3
I0526 13:06:48.846509 15070 net.cpp:454] ip3 <- ip2
I0526 13:06:48.846523 15070 net.cpp:411] ip3 -> ip3
I0526 13:06:48.846742 15070 net.cpp:150] Setting up ip3
I0526 13:06:48.846755 15070 net.cpp:157] Top shape: 20 11 (220)
I0526 13:06:48.846765 15070 net.cpp:165] Memory required for data: 31574720
I0526 13:06:48.846781 15070 layer_factory.hpp:77] Creating layer drop3
I0526 13:06:48.846792 15070 net.cpp:106] Creating Layer drop3
I0526 13:06:48.846802 15070 net.cpp:454] drop3 <- ip3
I0526 13:06:48.846815 15070 net.cpp:397] drop3 -> ip3 (in-place)
I0526 13:06:48.846855 15070 net.cpp:150] Setting up drop3
I0526 13:06:48.846868 15070 net.cpp:157] Top shape: 20 11 (220)
I0526 13:06:48.846878 15070 net.cpp:165] Memory required for data: 31575600
I0526 13:06:48.846887 15070 layer_factory.hpp:77] Creating layer loss
I0526 13:06:48.846906 15070 net.cpp:106] Creating Layer loss
I0526 13:06:48.846916 15070 net.cpp:454] loss <- ip3
I0526 13:06:48.846927 15070 net.cpp:454] loss <- label
I0526 13:06:48.846940 15070 net.cpp:411] loss -> loss
I0526 13:06:48.846957 15070 layer_factory.hpp:77] Creating layer loss
I0526 13:06:48.847596 15070 net.cpp:150] Setting up loss
I0526 13:06:48.847617 15070 net.cpp:157] Top shape: (1)
I0526 13:06:48.847631 15070 net.cpp:160]     with loss weight 1
I0526 13:06:48.847673 15070 net.cpp:165] Memory required for data: 31575604
I0526 13:06:48.847683 15070 net.cpp:226] loss needs backward computation.
I0526 13:06:48.847694 15070 net.cpp:226] drop3 needs backward computation.
I0526 13:06:48.847704 15070 net.cpp:226] ip3 needs backward computation.
I0526 13:06:48.847715 15070 net.cpp:226] drop2 needs backward computation.
I0526 13:06:48.847725 15070 net.cpp:226] relu6 needs backward computation.
I0526 13:06:48.847735 15070 net.cpp:226] ip2 needs backward computation.
I0526 13:06:48.847745 15070 net.cpp:226] drop1 needs backward computation.
I0526 13:06:48.847755 15070 net.cpp:226] relu5 needs backward computation.
I0526 13:06:48.847765 15070 net.cpp:226] ip1 needs backward computation.
I0526 13:06:48.847775 15070 net.cpp:226] pool4 needs backward computation.
I0526 13:06:48.847785 15070 net.cpp:226] relu4 needs backward computation.
I0526 13:06:48.847795 15070 net.cpp:226] conv4 needs backward computation.
I0526 13:06:48.847805 15070 net.cpp:226] pool3 needs backward computation.
I0526 13:06:48.847816 15070 net.cpp:226] relu3 needs backward computation.
I0526 13:06:48.847826 15070 net.cpp:226] conv3 needs backward computation.
I0526 13:06:48.847846 15070 net.cpp:226] pool2 needs backward computation.
I0526 13:06:48.847856 15070 net.cpp:226] relu2 needs backward computation.
I0526 13:06:48.847867 15070 net.cpp:226] conv2 needs backward computation.
I0526 13:06:48.847878 15070 net.cpp:226] pool1 needs backward computation.
I0526 13:06:48.847888 15070 net.cpp:226] relu1 needs backward computation.
I0526 13:06:48.847898 15070 net.cpp:226] conv1 needs backward computation.
I0526 13:06:48.847909 15070 net.cpp:228] data_hdf5 does not need backward computation.
I0526 13:06:48.847920 15070 net.cpp:270] This network produces output loss
I0526 13:06:48.847944 15070 net.cpp:283] Network initialization done.
I0526 13:06:48.849537 15070 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768.prototxt
I0526 13:06:48.849608 15070 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 13:06:48.849966 15070 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 13:06:48.850152 15070 layer_factory.hpp:77] Creating layer data_hdf5
I0526 13:06:48.850167 15070 net.cpp:106] Creating Layer data_hdf5
I0526 13:06:48.850179 15070 net.cpp:411] data_hdf5 -> data
I0526 13:06:48.850196 15070 net.cpp:411] data_hdf5 -> label
I0526 13:06:48.850213 15070 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 13:06:48.861027 15070 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 13:07:10.275212 15070 net.cpp:150] Setting up data_hdf5
I0526 13:07:10.275374 15070 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 13:07:10.275388 15070 net.cpp:157] Top shape: 20 (20)
I0526 13:07:10.275400 15070 net.cpp:165] Memory required for data: 508080
I0526 13:07:10.275415 15070 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 13:07:10.275444 15070 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 13:07:10.275454 15070 net.cpp:454] label_data_hdf5_1_split <- label
I0526 13:07:10.275470 15070 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 13:07:10.275490 15070 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 13:07:10.275564 15070 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 13:07:10.275578 15070 net.cpp:157] Top shape: 20 (20)
I0526 13:07:10.275590 15070 net.cpp:157] Top shape: 20 (20)
I0526 13:07:10.275600 15070 net.cpp:165] Memory required for data: 508240
I0526 13:07:10.275610 15070 layer_factory.hpp:77] Creating layer conv1
I0526 13:07:10.275629 15070 net.cpp:106] Creating Layer conv1
I0526 13:07:10.275640 15070 net.cpp:454] conv1 <- data
I0526 13:07:10.275655 15070 net.cpp:411] conv1 -> conv1
I0526 13:07:10.277607 15070 net.cpp:150] Setting up conv1
I0526 13:07:10.277631 15070 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:07:10.277643 15070 net.cpp:165] Memory required for data: 6037840
I0526 13:07:10.277664 15070 layer_factory.hpp:77] Creating layer relu1
I0526 13:07:10.277679 15070 net.cpp:106] Creating Layer relu1
I0526 13:07:10.277689 15070 net.cpp:454] relu1 <- conv1
I0526 13:07:10.277701 15070 net.cpp:397] relu1 -> conv1 (in-place)
I0526 13:07:10.278198 15070 net.cpp:150] Setting up relu1
I0526 13:07:10.278213 15070 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 13:07:10.278223 15070 net.cpp:165] Memory required for data: 11567440
I0526 13:07:10.278234 15070 layer_factory.hpp:77] Creating layer pool1
I0526 13:07:10.278249 15070 net.cpp:106] Creating Layer pool1
I0526 13:07:10.278259 15070 net.cpp:454] pool1 <- conv1
I0526 13:07:10.278273 15070 net.cpp:411] pool1 -> pool1
I0526 13:07:10.278347 15070 net.cpp:150] Setting up pool1
I0526 13:07:10.278360 15070 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 13:07:10.278370 15070 net.cpp:165] Memory required for data: 14332240
I0526 13:07:10.278381 15070 layer_factory.hpp:77] Creating layer conv2
I0526 13:07:10.278399 15070 net.cpp:106] Creating Layer conv2
I0526 13:07:10.278409 15070 net.cpp:454] conv2 <- pool1
I0526 13:07:10.278424 15070 net.cpp:411] conv2 -> conv2
I0526 13:07:10.280350 15070 net.cpp:150] Setting up conv2
I0526 13:07:10.280374 15070 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:07:10.280383 15070 net.cpp:165] Memory required for data: 18306640
I0526 13:07:10.280402 15070 layer_factory.hpp:77] Creating layer relu2
I0526 13:07:10.280416 15070 net.cpp:106] Creating Layer relu2
I0526 13:07:10.280426 15070 net.cpp:454] relu2 <- conv2
I0526 13:07:10.280438 15070 net.cpp:397] relu2 -> conv2 (in-place)
I0526 13:07:10.280771 15070 net.cpp:150] Setting up relu2
I0526 13:07:10.280786 15070 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 13:07:10.280797 15070 net.cpp:165] Memory required for data: 22281040
I0526 13:07:10.280807 15070 layer_factory.hpp:77] Creating layer pool2
I0526 13:07:10.280820 15070 net.cpp:106] Creating Layer pool2
I0526 13:07:10.280830 15070 net.cpp:454] pool2 <- conv2
I0526 13:07:10.280843 15070 net.cpp:411] pool2 -> pool2
I0526 13:07:10.280915 15070 net.cpp:150] Setting up pool2
I0526 13:07:10.280928 15070 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 13:07:10.280938 15070 net.cpp:165] Memory required for data: 24268240
I0526 13:07:10.280946 15070 layer_factory.hpp:77] Creating layer conv3
I0526 13:07:10.280966 15070 net.cpp:106] Creating Layer conv3
I0526 13:07:10.280977 15070 net.cpp:454] conv3 <- pool2
I0526 13:07:10.280989 15070 net.cpp:411] conv3 -> conv3
I0526 13:07:10.282965 15070 net.cpp:150] Setting up conv3
I0526 13:07:10.282989 15070 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:07:10.283000 15070 net.cpp:165] Memory required for data: 26436560
I0526 13:07:10.283020 15070 layer_factory.hpp:77] Creating layer relu3
I0526 13:07:10.283046 15070 net.cpp:106] Creating Layer relu3
I0526 13:07:10.283056 15070 net.cpp:454] relu3 <- conv3
I0526 13:07:10.283071 15070 net.cpp:397] relu3 -> conv3 (in-place)
I0526 13:07:10.283546 15070 net.cpp:150] Setting up relu3
I0526 13:07:10.283562 15070 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 13:07:10.283572 15070 net.cpp:165] Memory required for data: 28604880
I0526 13:07:10.283582 15070 layer_factory.hpp:77] Creating layer pool3
I0526 13:07:10.283596 15070 net.cpp:106] Creating Layer pool3
I0526 13:07:10.283606 15070 net.cpp:454] pool3 <- conv3
I0526 13:07:10.283618 15070 net.cpp:411] pool3 -> pool3
I0526 13:07:10.283690 15070 net.cpp:150] Setting up pool3
I0526 13:07:10.283704 15070 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 13:07:10.283713 15070 net.cpp:165] Memory required for data: 29689040
I0526 13:07:10.283723 15070 layer_factory.hpp:77] Creating layer conv4
I0526 13:07:10.283740 15070 net.cpp:106] Creating Layer conv4
I0526 13:07:10.283751 15070 net.cpp:454] conv4 <- pool3
I0526 13:07:10.283766 15070 net.cpp:411] conv4 -> conv4
I0526 13:07:10.285820 15070 net.cpp:150] Setting up conv4
I0526 13:07:10.285841 15070 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:07:10.285853 15070 net.cpp:165] Memory required for data: 30414800
I0526 13:07:10.285869 15070 layer_factory.hpp:77] Creating layer relu4
I0526 13:07:10.285882 15070 net.cpp:106] Creating Layer relu4
I0526 13:07:10.285893 15070 net.cpp:454] relu4 <- conv4
I0526 13:07:10.285907 15070 net.cpp:397] relu4 -> conv4 (in-place)
I0526 13:07:10.286376 15070 net.cpp:150] Setting up relu4
I0526 13:07:10.286392 15070 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 13:07:10.286402 15070 net.cpp:165] Memory required for data: 31140560
I0526 13:07:10.286412 15070 layer_factory.hpp:77] Creating layer pool4
I0526 13:07:10.286427 15070 net.cpp:106] Creating Layer pool4
I0526 13:07:10.286437 15070 net.cpp:454] pool4 <- conv4
I0526 13:07:10.286449 15070 net.cpp:411] pool4 -> pool4
I0526 13:07:10.286521 15070 net.cpp:150] Setting up pool4
I0526 13:07:10.286535 15070 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 13:07:10.286545 15070 net.cpp:165] Memory required for data: 31503440
I0526 13:07:10.286553 15070 layer_factory.hpp:77] Creating layer ip1
I0526 13:07:10.286569 15070 net.cpp:106] Creating Layer ip1
I0526 13:07:10.286579 15070 net.cpp:454] ip1 <- pool4
I0526 13:07:10.286594 15070 net.cpp:411] ip1 -> ip1
I0526 13:07:10.302116 15070 net.cpp:150] Setting up ip1
I0526 13:07:10.302145 15070 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:07:10.302161 15070 net.cpp:165] Memory required for data: 31519120
I0526 13:07:10.302189 15070 layer_factory.hpp:77] Creating layer relu5
I0526 13:07:10.302204 15070 net.cpp:106] Creating Layer relu5
I0526 13:07:10.302215 15070 net.cpp:454] relu5 <- ip1
I0526 13:07:10.302229 15070 net.cpp:397] relu5 -> ip1 (in-place)
I0526 13:07:10.302577 15070 net.cpp:150] Setting up relu5
I0526 13:07:10.302592 15070 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:07:10.302602 15070 net.cpp:165] Memory required for data: 31534800
I0526 13:07:10.302611 15070 layer_factory.hpp:77] Creating layer drop1
I0526 13:07:10.302631 15070 net.cpp:106] Creating Layer drop1
I0526 13:07:10.302641 15070 net.cpp:454] drop1 <- ip1
I0526 13:07:10.302654 15070 net.cpp:397] drop1 -> ip1 (in-place)
I0526 13:07:10.302700 15070 net.cpp:150] Setting up drop1
I0526 13:07:10.302719 15070 net.cpp:157] Top shape: 20 196 (3920)
I0526 13:07:10.302731 15070 net.cpp:165] Memory required for data: 31550480
I0526 13:07:10.302741 15070 layer_factory.hpp:77] Creating layer ip2
I0526 13:07:10.302754 15070 net.cpp:106] Creating Layer ip2
I0526 13:07:10.302764 15070 net.cpp:454] ip2 <- ip1
I0526 13:07:10.302778 15070 net.cpp:411] ip2 -> ip2
I0526 13:07:10.303261 15070 net.cpp:150] Setting up ip2
I0526 13:07:10.303274 15070 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:07:10.303284 15070 net.cpp:165] Memory required for data: 31558320
I0526 13:07:10.303300 15070 layer_factory.hpp:77] Creating layer relu6
I0526 13:07:10.303325 15070 net.cpp:106] Creating Layer relu6
I0526 13:07:10.303336 15070 net.cpp:454] relu6 <- ip2
I0526 13:07:10.303349 15070 net.cpp:397] relu6 -> ip2 (in-place)
I0526 13:07:10.303887 15070 net.cpp:150] Setting up relu6
I0526 13:07:10.303910 15070 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:07:10.303920 15070 net.cpp:165] Memory required for data: 31566160
I0526 13:07:10.303930 15070 layer_factory.hpp:77] Creating layer drop2
I0526 13:07:10.303943 15070 net.cpp:106] Creating Layer drop2
I0526 13:07:10.303953 15070 net.cpp:454] drop2 <- ip2
I0526 13:07:10.303966 15070 net.cpp:397] drop2 -> ip2 (in-place)
I0526 13:07:10.304010 15070 net.cpp:150] Setting up drop2
I0526 13:07:10.304023 15070 net.cpp:157] Top shape: 20 98 (1960)
I0526 13:07:10.304034 15070 net.cpp:165] Memory required for data: 31574000
I0526 13:07:10.304044 15070 layer_factory.hpp:77] Creating layer ip3
I0526 13:07:10.304057 15070 net.cpp:106] Creating Layer ip3
I0526 13:07:10.304067 15070 net.cpp:454] ip3 <- ip2
I0526 13:07:10.304081 15070 net.cpp:411] ip3 -> ip3
I0526 13:07:10.304306 15070 net.cpp:150] Setting up ip3
I0526 13:07:10.304321 15070 net.cpp:157] Top shape: 20 11 (220)
I0526 13:07:10.304329 15070 net.cpp:165] Memory required for data: 31574880
I0526 13:07:10.304345 15070 layer_factory.hpp:77] Creating layer drop3
I0526 13:07:10.304358 15070 net.cpp:106] Creating Layer drop3
I0526 13:07:10.304368 15070 net.cpp:454] drop3 <- ip3
I0526 13:07:10.304380 15070 net.cpp:397] drop3 -> ip3 (in-place)
I0526 13:07:10.304421 15070 net.cpp:150] Setting up drop3
I0526 13:07:10.304435 15070 net.cpp:157] Top shape: 20 11 (220)
I0526 13:07:10.304445 15070 net.cpp:165] Memory required for data: 31575760
I0526 13:07:10.304453 15070 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 13:07:10.304467 15070 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 13:07:10.304476 15070 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 13:07:10.304491 15070 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 13:07:10.304505 15070 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 13:07:10.304579 15070 net.cpp:150] Setting up ip3_drop3_0_split
I0526 13:07:10.304592 15070 net.cpp:157] Top shape: 20 11 (220)
I0526 13:07:10.304605 15070 net.cpp:157] Top shape: 20 11 (220)
I0526 13:07:10.304615 15070 net.cpp:165] Memory required for data: 31577520
I0526 13:07:10.304625 15070 layer_factory.hpp:77] Creating layer accuracy
I0526 13:07:10.304646 15070 net.cpp:106] Creating Layer accuracy
I0526 13:07:10.304656 15070 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 13:07:10.304667 15070 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 13:07:10.304682 15070 net.cpp:411] accuracy -> accuracy
I0526 13:07:10.304705 15070 net.cpp:150] Setting up accuracy
I0526 13:07:10.304718 15070 net.cpp:157] Top shape: (1)
I0526 13:07:10.304728 15070 net.cpp:165] Memory required for data: 31577524
I0526 13:07:10.304738 15070 layer_factory.hpp:77] Creating layer loss
I0526 13:07:10.304750 15070 net.cpp:106] Creating Layer loss
I0526 13:07:10.304762 15070 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 13:07:10.304774 15070 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 13:07:10.304785 15070 net.cpp:411] loss -> loss
I0526 13:07:10.304803 15070 layer_factory.hpp:77] Creating layer loss
I0526 13:07:10.305285 15070 net.cpp:150] Setting up loss
I0526 13:07:10.305299 15070 net.cpp:157] Top shape: (1)
I0526 13:07:10.305310 15070 net.cpp:160]     with loss weight 1
I0526 13:07:10.305327 15070 net.cpp:165] Memory required for data: 31577528
I0526 13:07:10.305337 15070 net.cpp:226] loss needs backward computation.
I0526 13:07:10.305348 15070 net.cpp:228] accuracy does not need backward computation.
I0526 13:07:10.305361 15070 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 13:07:10.305371 15070 net.cpp:226] drop3 needs backward computation.
I0526 13:07:10.305382 15070 net.cpp:226] ip3 needs backward computation.
I0526 13:07:10.305392 15070 net.cpp:226] drop2 needs backward computation.
I0526 13:07:10.305402 15070 net.cpp:226] relu6 needs backward computation.
I0526 13:07:10.305419 15070 net.cpp:226] ip2 needs backward computation.
I0526 13:07:10.305430 15070 net.cpp:226] drop1 needs backward computation.
I0526 13:07:10.305439 15070 net.cpp:226] relu5 needs backward computation.
I0526 13:07:10.305449 15070 net.cpp:226] ip1 needs backward computation.
I0526 13:07:10.305459 15070 net.cpp:226] pool4 needs backward computation.
I0526 13:07:10.305470 15070 net.cpp:226] relu4 needs backward computation.
I0526 13:07:10.305480 15070 net.cpp:226] conv4 needs backward computation.
I0526 13:07:10.305490 15070 net.cpp:226] pool3 needs backward computation.
I0526 13:07:10.305501 15070 net.cpp:226] relu3 needs backward computation.
I0526 13:07:10.305511 15070 net.cpp:226] conv3 needs backward computation.
I0526 13:07:10.305521 15070 net.cpp:226] pool2 needs backward computation.
I0526 13:07:10.305532 15070 net.cpp:226] relu2 needs backward computation.
I0526 13:07:10.305542 15070 net.cpp:226] conv2 needs backward computation.
I0526 13:07:10.305552 15070 net.cpp:226] pool1 needs backward computation.
I0526 13:07:10.305562 15070 net.cpp:226] relu1 needs backward computation.
I0526 13:07:10.305572 15070 net.cpp:226] conv1 needs backward computation.
I0526 13:07:10.305584 15070 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 13:07:10.305596 15070 net.cpp:228] data_hdf5 does not need backward computation.
I0526 13:07:10.305606 15070 net.cpp:270] This network produces output accuracy
I0526 13:07:10.305618 15070 net.cpp:270] This network produces output loss
I0526 13:07:10.305644 15070 net.cpp:283] Network initialization done.
I0526 13:07:10.305776 15070 solver.cpp:60] Solver scaffolding done.
I0526 13:07:10.306928 15070 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_285000.solverstate
I0526 13:07:10.536631 15070 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 13:07:10.542132 15070 caffe.cpp:212] Starting Optimization
I0526 13:07:10.542173 15070 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 13:07:10.542183 15070 solver.cpp:289] Learning Rate Policy: fixed
I0526 13:07:10.543594 15070 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 13:08:03.466603 15070 solver.cpp:409]     Test net output #0: accuracy = 0.896397
I0526 13:08:03.466763 15070 solver.cpp:409]     Test net output #1: loss = 0.327552 (* 1 = 0.327552 loss)
I0526 13:08:03.485873 15070 solver.cpp:237] Iteration 285000, loss = 0.885188
I0526 13:08:03.485909 15070 solver.cpp:253]     Train net output #0: loss = 0.885188 (* 1 = 0.885188 loss)
I0526 13:08:03.485929 15070 sgd_solver.cpp:106] Iteration 285000, lr = 0.001
I0526 13:08:15.633615 15070 solver.cpp:237] Iteration 285750, loss = 0.966656
I0526 13:08:15.633662 15070 solver.cpp:253]     Train net output #0: loss = 0.966656 (* 1 = 0.966656 loss)
I0526 13:08:15.633676 15070 sgd_solver.cpp:106] Iteration 285750, lr = 0.001
I0526 13:08:27.839974 15070 solver.cpp:237] Iteration 286500, loss = 1.03298
I0526 13:08:27.840010 15070 solver.cpp:253]     Train net output #0: loss = 1.03298 (* 1 = 1.03298 loss)
I0526 13:08:27.840025 15070 sgd_solver.cpp:106] Iteration 286500, lr = 0.001
I0526 13:08:39.976205 15070 solver.cpp:237] Iteration 287250, loss = 1.24904
I0526 13:08:39.976362 15070 solver.cpp:253]     Train net output #0: loss = 1.24904 (* 1 = 1.24904 loss)
I0526 13:08:39.976378 15070 sgd_solver.cpp:106] Iteration 287250, lr = 0.001
I0526 13:08:52.109181 15070 solver.cpp:237] Iteration 288000, loss = 0.867336
I0526 13:08:52.109218 15070 solver.cpp:253]     Train net output #0: loss = 0.867336 (* 1 = 0.867336 loss)
I0526 13:08:52.109231 15070 sgd_solver.cpp:106] Iteration 288000, lr = 0.001
I0526 13:09:04.257272 15070 solver.cpp:237] Iteration 288750, loss = 1.21024
I0526 13:09:04.257318 15070 solver.cpp:253]     Train net output #0: loss = 1.21024 (* 1 = 1.21024 loss)
I0526 13:09:04.257334 15070 sgd_solver.cpp:106] Iteration 288750, lr = 0.001
I0526 13:09:16.400935 15070 solver.cpp:237] Iteration 289500, loss = 1.24005
I0526 13:09:16.401073 15070 solver.cpp:253]     Train net output #0: loss = 1.24005 (* 1 = 1.24005 loss)
I0526 13:09:16.401087 15070 sgd_solver.cpp:106] Iteration 289500, lr = 0.001
I0526 13:09:50.743371 15070 solver.cpp:237] Iteration 290250, loss = 0.934782
I0526 13:09:50.743532 15070 solver.cpp:253]     Train net output #0: loss = 0.934782 (* 1 = 0.934782 loss)
I0526 13:09:50.743549 15070 sgd_solver.cpp:106] Iteration 290250, lr = 0.001
I0526 13:10:02.913969 15070 solver.cpp:237] Iteration 291000, loss = 1.43275
I0526 13:10:02.914011 15070 solver.cpp:253]     Train net output #0: loss = 1.43275 (* 1 = 1.43275 loss)
I0526 13:10:02.914027 15070 sgd_solver.cpp:106] Iteration 291000, lr = 0.001
I0526 13:10:15.102571 15070 solver.cpp:237] Iteration 291750, loss = 1.69687
I0526 13:10:15.102607 15070 solver.cpp:253]     Train net output #0: loss = 1.69687 (* 1 = 1.69687 loss)
I0526 13:10:15.102623 15070 sgd_solver.cpp:106] Iteration 291750, lr = 0.001
I0526 13:10:27.227027 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_292500.caffemodel
I0526 13:10:27.277240 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_292500.solverstate
I0526 13:10:27.308374 15070 solver.cpp:237] Iteration 292500, loss = 0.922991
I0526 13:10:27.308419 15070 solver.cpp:253]     Train net output #0: loss = 0.922991 (* 1 = 0.922991 loss)
I0526 13:10:27.308434 15070 sgd_solver.cpp:106] Iteration 292500, lr = 0.001
I0526 13:10:39.501735 15070 solver.cpp:237] Iteration 293250, loss = 1.19027
I0526 13:10:39.501772 15070 solver.cpp:253]     Train net output #0: loss = 1.19027 (* 1 = 1.19027 loss)
I0526 13:10:39.501785 15070 sgd_solver.cpp:106] Iteration 293250, lr = 0.001
I0526 13:10:51.642946 15070 solver.cpp:237] Iteration 294000, loss = 0.954745
I0526 13:10:51.642997 15070 solver.cpp:253]     Train net output #0: loss = 0.954745 (* 1 = 0.954745 loss)
I0526 13:10:51.643010 15070 sgd_solver.cpp:106] Iteration 294000, lr = 0.001
I0526 13:11:03.817909 15070 solver.cpp:237] Iteration 294750, loss = 1.37241
I0526 13:11:03.818051 15070 solver.cpp:253]     Train net output #0: loss = 1.37241 (* 1 = 1.37241 loss)
I0526 13:11:03.818065 15070 sgd_solver.cpp:106] Iteration 294750, lr = 0.001
I0526 13:11:38.073961 15070 solver.cpp:237] Iteration 295500, loss = 1.11103
I0526 13:11:38.074132 15070 solver.cpp:253]     Train net output #0: loss = 1.11103 (* 1 = 1.11103 loss)
I0526 13:11:38.074147 15070 sgd_solver.cpp:106] Iteration 295500, lr = 0.001
I0526 13:11:50.153035 15070 solver.cpp:237] Iteration 296250, loss = 0.742243
I0526 13:11:50.153071 15070 solver.cpp:253]     Train net output #0: loss = 0.742243 (* 1 = 0.742243 loss)
I0526 13:11:50.153087 15070 sgd_solver.cpp:106] Iteration 296250, lr = 0.001
I0526 13:12:02.233620 15070 solver.cpp:237] Iteration 297000, loss = 1.02943
I0526 13:12:02.233664 15070 solver.cpp:253]     Train net output #0: loss = 1.02943 (* 1 = 1.02943 loss)
I0526 13:12:02.233676 15070 sgd_solver.cpp:106] Iteration 297000, lr = 0.001
I0526 13:12:14.315354 15070 solver.cpp:237] Iteration 297750, loss = 1.52022
I0526 13:12:14.315488 15070 solver.cpp:253]     Train net output #0: loss = 1.52022 (* 1 = 1.52022 loss)
I0526 13:12:14.315503 15070 sgd_solver.cpp:106] Iteration 297750, lr = 0.001
I0526 13:12:26.467696 15070 solver.cpp:237] Iteration 298500, loss = 1.09002
I0526 13:12:26.467744 15070 solver.cpp:253]     Train net output #0: loss = 1.09002 (* 1 = 1.09002 loss)
I0526 13:12:26.467759 15070 sgd_solver.cpp:106] Iteration 298500, lr = 0.001
I0526 13:12:38.655817 15070 solver.cpp:237] Iteration 299250, loss = 0.946728
I0526 13:12:38.655854 15070 solver.cpp:253]     Train net output #0: loss = 0.946728 (* 1 = 0.946728 loss)
I0526 13:12:38.655870 15070 sgd_solver.cpp:106] Iteration 299250, lr = 0.001
I0526 13:12:50.784162 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_300000.caffemodel
I0526 13:12:50.833930 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_300000.solverstate
I0526 13:12:50.863924 15070 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 13:13:42.864270 15070 solver.cpp:409]     Test net output #0: accuracy = 0.898238
I0526 13:13:42.864425 15070 solver.cpp:409]     Test net output #1: loss = 0.326801 (* 1 = 0.326801 loss)
I0526 13:14:05.043545 15070 solver.cpp:237] Iteration 300000, loss = 1.25158
I0526 13:14:05.043598 15070 solver.cpp:253]     Train net output #0: loss = 1.25158 (* 1 = 1.25158 loss)
I0526 13:14:05.043613 15070 sgd_solver.cpp:106] Iteration 300000, lr = 0.001
I0526 13:14:17.230973 15070 solver.cpp:237] Iteration 300750, loss = 0.89062
I0526 13:14:17.231137 15070 solver.cpp:253]     Train net output #0: loss = 0.89062 (* 1 = 0.89062 loss)
I0526 13:14:17.231153 15070 sgd_solver.cpp:106] Iteration 300750, lr = 0.001
I0526 13:14:29.391664 15070 solver.cpp:237] Iteration 301500, loss = 1.05722
I0526 13:14:29.391710 15070 solver.cpp:253]     Train net output #0: loss = 1.05722 (* 1 = 1.05722 loss)
I0526 13:14:29.391726 15070 sgd_solver.cpp:106] Iteration 301500, lr = 0.001
I0526 13:14:41.543848 15070 solver.cpp:237] Iteration 302250, loss = 1.19425
I0526 13:14:41.543884 15070 solver.cpp:253]     Train net output #0: loss = 1.19425 (* 1 = 1.19425 loss)
I0526 13:14:41.543896 15070 sgd_solver.cpp:106] Iteration 302250, lr = 0.001
I0526 13:14:53.650748 15070 solver.cpp:237] Iteration 303000, loss = 1.08786
I0526 13:14:53.650902 15070 solver.cpp:253]     Train net output #0: loss = 1.08786 (* 1 = 1.08786 loss)
I0526 13:14:53.650918 15070 sgd_solver.cpp:106] Iteration 303000, lr = 0.001
I0526 13:15:05.789496 15070 solver.cpp:237] Iteration 303750, loss = 1.05108
I0526 13:15:05.789533 15070 solver.cpp:253]     Train net output #0: loss = 1.05108 (* 1 = 1.05108 loss)
I0526 13:15:05.789546 15070 sgd_solver.cpp:106] Iteration 303750, lr = 0.001
I0526 13:15:17.880918 15070 solver.cpp:237] Iteration 304500, loss = 1.23231
I0526 13:15:17.880962 15070 solver.cpp:253]     Train net output #0: loss = 1.23231 (* 1 = 1.23231 loss)
I0526 13:15:17.880978 15070 sgd_solver.cpp:106] Iteration 304500, lr = 0.001
I0526 13:15:52.130460 15070 solver.cpp:237] Iteration 305250, loss = 1.28805
I0526 13:15:52.130633 15070 solver.cpp:253]     Train net output #0: loss = 1.28806 (* 1 = 1.28806 loss)
I0526 13:15:52.130648 15070 sgd_solver.cpp:106] Iteration 305250, lr = 0.001
I0526 13:16:04.211577 15070 solver.cpp:237] Iteration 306000, loss = 1.47183
I0526 13:16:04.211613 15070 solver.cpp:253]     Train net output #0: loss = 1.47183 (* 1 = 1.47183 loss)
I0526 13:16:04.211629 15070 sgd_solver.cpp:106] Iteration 306000, lr = 0.001
I0526 13:16:16.348772 15070 solver.cpp:237] Iteration 306750, loss = 1.18947
I0526 13:16:16.348819 15070 solver.cpp:253]     Train net output #0: loss = 1.18948 (* 1 = 1.18948 loss)
I0526 13:16:16.348834 15070 sgd_solver.cpp:106] Iteration 306750, lr = 0.001
I0526 13:16:28.483507 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_307500.caffemodel
I0526 13:16:28.535585 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_307500.solverstate
I0526 13:16:28.568272 15070 solver.cpp:237] Iteration 307500, loss = 1.22775
I0526 13:16:28.568322 15070 solver.cpp:253]     Train net output #0: loss = 1.22775 (* 1 = 1.22775 loss)
I0526 13:16:28.568336 15070 sgd_solver.cpp:106] Iteration 307500, lr = 0.001
I0526 13:16:40.753464 15070 solver.cpp:237] Iteration 308250, loss = 1.02062
I0526 13:16:40.753506 15070 solver.cpp:253]     Train net output #0: loss = 1.02062 (* 1 = 1.02062 loss)
I0526 13:16:40.753522 15070 sgd_solver.cpp:106] Iteration 308250, lr = 0.001
I0526 13:16:52.953004 15070 solver.cpp:237] Iteration 309000, loss = 1.06004
I0526 13:16:52.953040 15070 solver.cpp:253]     Train net output #0: loss = 1.06004 (* 1 = 1.06004 loss)
I0526 13:16:52.953053 15070 sgd_solver.cpp:106] Iteration 309000, lr = 0.001
I0526 13:17:05.137037 15070 solver.cpp:237] Iteration 309750, loss = 1.12715
I0526 13:17:05.137194 15070 solver.cpp:253]     Train net output #0: loss = 1.12715 (* 1 = 1.12715 loss)
I0526 13:17:05.137210 15070 sgd_solver.cpp:106] Iteration 309750, lr = 0.001
I0526 13:17:39.514039 15070 solver.cpp:237] Iteration 310500, loss = 0.698891
I0526 13:17:39.514204 15070 solver.cpp:253]     Train net output #0: loss = 0.698891 (* 1 = 0.698891 loss)
I0526 13:17:39.514219 15070 sgd_solver.cpp:106] Iteration 310500, lr = 0.001
I0526 13:17:51.674342 15070 solver.cpp:237] Iteration 311250, loss = 1.0926
I0526 13:17:51.674389 15070 solver.cpp:253]     Train net output #0: loss = 1.0926 (* 1 = 1.0926 loss)
I0526 13:17:51.674403 15070 sgd_solver.cpp:106] Iteration 311250, lr = 0.001
I0526 13:18:03.838618 15070 solver.cpp:237] Iteration 312000, loss = 1.26785
I0526 13:18:03.838654 15070 solver.cpp:253]     Train net output #0: loss = 1.26785 (* 1 = 1.26785 loss)
I0526 13:18:03.838667 15070 sgd_solver.cpp:106] Iteration 312000, lr = 0.001
I0526 13:18:16.000584 15070 solver.cpp:237] Iteration 312750, loss = 1.49381
I0526 13:18:16.000735 15070 solver.cpp:253]     Train net output #0: loss = 1.49381 (* 1 = 1.49381 loss)
I0526 13:18:16.000749 15070 sgd_solver.cpp:106] Iteration 312750, lr = 0.001
I0526 13:18:28.165346 15070 solver.cpp:237] Iteration 313500, loss = 1.30327
I0526 13:18:28.165381 15070 solver.cpp:253]     Train net output #0: loss = 1.30327 (* 1 = 1.30327 loss)
I0526 13:18:28.165398 15070 sgd_solver.cpp:106] Iteration 313500, lr = 0.001
I0526 13:18:40.301270 15070 solver.cpp:237] Iteration 314250, loss = 1.14118
I0526 13:18:40.301316 15070 solver.cpp:253]     Train net output #0: loss = 1.14118 (* 1 = 1.14118 loss)
I0526 13:18:40.301331 15070 sgd_solver.cpp:106] Iteration 314250, lr = 0.001
I0526 13:18:52.466387 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_315000.caffemodel
I0526 13:18:52.518153 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_315000.solverstate
I0526 13:18:52.545727 15070 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 13:20:05.369148 15070 solver.cpp:409]     Test net output #0: accuracy = 0.897704
I0526 13:20:05.369308 15070 solver.cpp:409]     Test net output #1: loss = 0.331672 (* 1 = 0.331672 loss)
I0526 13:20:27.577811 15070 solver.cpp:237] Iteration 315000, loss = 0.870127
I0526 13:20:27.577862 15070 solver.cpp:253]     Train net output #0: loss = 0.870127 (* 1 = 0.870127 loss)
I0526 13:20:27.577878 15070 sgd_solver.cpp:106] Iteration 315000, lr = 0.001
I0526 13:20:39.770551 15070 solver.cpp:237] Iteration 315750, loss = 1.39282
I0526 13:20:39.770704 15070 solver.cpp:253]     Train net output #0: loss = 1.39282 (* 1 = 1.39282 loss)
I0526 13:20:39.770723 15070 sgd_solver.cpp:106] Iteration 315750, lr = 0.001
I0526 13:20:51.951870 15070 solver.cpp:237] Iteration 316500, loss = 0.749723
I0526 13:20:51.951918 15070 solver.cpp:253]     Train net output #0: loss = 0.749724 (* 1 = 0.749724 loss)
I0526 13:20:51.951935 15070 sgd_solver.cpp:106] Iteration 316500, lr = 0.001
I0526 13:21:04.181136 15070 solver.cpp:237] Iteration 317250, loss = 1.10961
I0526 13:21:04.181174 15070 solver.cpp:253]     Train net output #0: loss = 1.10961 (* 1 = 1.10961 loss)
I0526 13:21:04.181186 15070 sgd_solver.cpp:106] Iteration 317250, lr = 0.001
I0526 13:21:16.386260 15070 solver.cpp:237] Iteration 318000, loss = 1.04475
I0526 13:21:16.386415 15070 solver.cpp:253]     Train net output #0: loss = 1.04475 (* 1 = 1.04475 loss)
I0526 13:21:16.386430 15070 sgd_solver.cpp:106] Iteration 318000, lr = 0.001
I0526 13:21:28.598578 15070 solver.cpp:237] Iteration 318750, loss = 0.874072
I0526 13:21:28.598615 15070 solver.cpp:253]     Train net output #0: loss = 0.874072 (* 1 = 0.874072 loss)
I0526 13:21:28.598633 15070 sgd_solver.cpp:106] Iteration 318750, lr = 0.001
I0526 13:21:40.818918 15070 solver.cpp:237] Iteration 319500, loss = 1.07607
I0526 13:21:40.818963 15070 solver.cpp:253]     Train net output #0: loss = 1.07607 (* 1 = 1.07607 loss)
I0526 13:21:40.818979 15070 sgd_solver.cpp:106] Iteration 319500, lr = 0.001
I0526 13:22:15.228052 15070 solver.cpp:237] Iteration 320250, loss = 1.4953
I0526 13:22:15.228215 15070 solver.cpp:253]     Train net output #0: loss = 1.4953 (* 1 = 1.4953 loss)
I0526 13:22:15.228229 15070 sgd_solver.cpp:106] Iteration 320250, lr = 0.001
I0526 13:22:27.434600 15070 solver.cpp:237] Iteration 321000, loss = 1.36293
I0526 13:22:27.434645 15070 solver.cpp:253]     Train net output #0: loss = 1.36293 (* 1 = 1.36293 loss)
I0526 13:22:27.434659 15070 sgd_solver.cpp:106] Iteration 321000, lr = 0.001
I0526 13:22:39.663189 15070 solver.cpp:237] Iteration 321750, loss = 0.908266
I0526 13:22:39.663225 15070 solver.cpp:253]     Train net output #0: loss = 0.908266 (* 1 = 0.908266 loss)
I0526 13:22:39.663239 15070 sgd_solver.cpp:106] Iteration 321750, lr = 0.001
I0526 13:22:51.871496 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_322500.caffemodel
I0526 13:22:51.923120 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_322500.solverstate
I0526 13:22:51.955683 15070 solver.cpp:237] Iteration 322500, loss = 0.685897
I0526 13:22:51.955734 15070 solver.cpp:253]     Train net output #0: loss = 0.685897 (* 1 = 0.685897 loss)
I0526 13:22:51.955749 15070 sgd_solver.cpp:106] Iteration 322500, lr = 0.001
I0526 13:23:04.178334 15070 solver.cpp:237] Iteration 323250, loss = 1.45022
I0526 13:23:04.178370 15070 solver.cpp:253]     Train net output #0: loss = 1.45022 (* 1 = 1.45022 loss)
I0526 13:23:04.178386 15070 sgd_solver.cpp:106] Iteration 323250, lr = 0.001
I0526 13:23:16.383319 15070 solver.cpp:237] Iteration 324000, loss = 0.876987
I0526 13:23:16.383366 15070 solver.cpp:253]     Train net output #0: loss = 0.876987 (* 1 = 0.876987 loss)
I0526 13:23:16.383380 15070 sgd_solver.cpp:106] Iteration 324000, lr = 0.001
I0526 13:23:28.590600 15070 solver.cpp:237] Iteration 324750, loss = 1.17494
I0526 13:23:28.590772 15070 solver.cpp:253]     Train net output #0: loss = 1.17494 (* 1 = 1.17494 loss)
I0526 13:23:28.590788 15070 sgd_solver.cpp:106] Iteration 324750, lr = 0.001
I0526 13:24:03.017235 15070 solver.cpp:237] Iteration 325500, loss = 1.45114
I0526 13:24:03.017417 15070 solver.cpp:253]     Train net output #0: loss = 1.45114 (* 1 = 1.45114 loss)
I0526 13:24:03.017431 15070 sgd_solver.cpp:106] Iteration 325500, lr = 0.001
I0526 13:24:15.236285 15070 solver.cpp:237] Iteration 326250, loss = 1.24396
I0526 13:24:15.236321 15070 solver.cpp:253]     Train net output #0: loss = 1.24396 (* 1 = 1.24396 loss)
I0526 13:24:15.236340 15070 sgd_solver.cpp:106] Iteration 326250, lr = 0.001
I0526 13:24:27.415727 15070 solver.cpp:237] Iteration 327000, loss = 1.51421
I0526 13:24:27.415773 15070 solver.cpp:253]     Train net output #0: loss = 1.51421 (* 1 = 1.51421 loss)
I0526 13:24:27.415791 15070 sgd_solver.cpp:106] Iteration 327000, lr = 0.001
I0526 13:24:39.595973 15070 solver.cpp:237] Iteration 327750, loss = 1.21761
I0526 13:24:39.596114 15070 solver.cpp:253]     Train net output #0: loss = 1.21761 (* 1 = 1.21761 loss)
I0526 13:24:39.596129 15070 sgd_solver.cpp:106] Iteration 327750, lr = 0.001
I0526 13:24:51.777359 15070 solver.cpp:237] Iteration 328500, loss = 1.31407
I0526 13:24:51.777401 15070 solver.cpp:253]     Train net output #0: loss = 1.31407 (* 1 = 1.31407 loss)
I0526 13:24:51.777418 15070 sgd_solver.cpp:106] Iteration 328500, lr = 0.001
I0526 13:25:04.047333 15070 solver.cpp:237] Iteration 329250, loss = 1.21548
I0526 13:25:04.047369 15070 solver.cpp:253]     Train net output #0: loss = 1.21548 (* 1 = 1.21548 loss)
I0526 13:25:04.047382 15070 sgd_solver.cpp:106] Iteration 329250, lr = 0.001
I0526 13:25:16.274159 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_330000.caffemodel
I0526 13:25:16.323257 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_330000.solverstate
I0526 13:25:16.348584 15070 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 13:26:08.009999 15070 solver.cpp:409]     Test net output #0: accuracy = 0.896011
I0526 13:26:08.010154 15070 solver.cpp:409]     Test net output #1: loss = 0.330691 (* 1 = 0.330691 loss)
I0526 13:26:30.253610 15070 solver.cpp:237] Iteration 330000, loss = 0.780748
I0526 13:26:30.253662 15070 solver.cpp:253]     Train net output #0: loss = 0.780748 (* 1 = 0.780748 loss)
I0526 13:26:30.253676 15070 sgd_solver.cpp:106] Iteration 330000, lr = 0.001
I0526 13:26:42.439404 15070 solver.cpp:237] Iteration 330750, loss = 0.741762
I0526 13:26:42.439564 15070 solver.cpp:253]     Train net output #0: loss = 0.741762 (* 1 = 0.741762 loss)
I0526 13:26:42.439579 15070 sgd_solver.cpp:106] Iteration 330750, lr = 0.001
I0526 13:26:54.589957 15070 solver.cpp:237] Iteration 331500, loss = 1.51075
I0526 13:26:54.589993 15070 solver.cpp:253]     Train net output #0: loss = 1.51075 (* 1 = 1.51075 loss)
I0526 13:26:54.590009 15070 sgd_solver.cpp:106] Iteration 331500, lr = 0.001
I0526 13:27:06.706275 15070 solver.cpp:237] Iteration 332250, loss = 0.683188
I0526 13:27:06.706322 15070 solver.cpp:253]     Train net output #0: loss = 0.683189 (* 1 = 0.683189 loss)
I0526 13:27:06.706337 15070 sgd_solver.cpp:106] Iteration 332250, lr = 0.001
I0526 13:27:18.823324 15070 solver.cpp:237] Iteration 333000, loss = 1.10593
I0526 13:27:18.823462 15070 solver.cpp:253]     Train net output #0: loss = 1.10593 (* 1 = 1.10593 loss)
I0526 13:27:18.823477 15070 sgd_solver.cpp:106] Iteration 333000, lr = 0.001
I0526 13:27:30.944578 15070 solver.cpp:237] Iteration 333750, loss = 0.582667
I0526 13:27:30.944627 15070 solver.cpp:253]     Train net output #0: loss = 0.582668 (* 1 = 0.582668 loss)
I0526 13:27:30.944641 15070 sgd_solver.cpp:106] Iteration 333750, lr = 0.001
I0526 13:27:43.061481 15070 solver.cpp:237] Iteration 334500, loss = 1.4365
I0526 13:27:43.061517 15070 solver.cpp:253]     Train net output #0: loss = 1.4365 (* 1 = 1.4365 loss)
I0526 13:27:43.061533 15070 sgd_solver.cpp:106] Iteration 334500, lr = 0.001
I0526 13:28:17.408849 15070 solver.cpp:237] Iteration 335250, loss = 1.48059
I0526 13:28:17.409020 15070 solver.cpp:253]     Train net output #0: loss = 1.48059 (* 1 = 1.48059 loss)
I0526 13:28:17.409034 15070 sgd_solver.cpp:106] Iteration 335250, lr = 0.001
I0526 13:28:29.572134 15070 solver.cpp:237] Iteration 336000, loss = 0.698473
I0526 13:28:29.572171 15070 solver.cpp:253]     Train net output #0: loss = 0.698474 (* 1 = 0.698474 loss)
I0526 13:28:29.572185 15070 sgd_solver.cpp:106] Iteration 336000, lr = 0.001
I0526 13:28:41.711472 15070 solver.cpp:237] Iteration 336750, loss = 1.40182
I0526 13:28:41.711519 15070 solver.cpp:253]     Train net output #0: loss = 1.40182 (* 1 = 1.40182 loss)
I0526 13:28:41.711534 15070 sgd_solver.cpp:106] Iteration 336750, lr = 0.001
I0526 13:28:53.828647 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_337500.caffemodel
I0526 13:28:53.878262 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_337500.solverstate
I0526 13:28:53.908781 15070 solver.cpp:237] Iteration 337500, loss = 1.78963
I0526 13:28:53.908824 15070 solver.cpp:253]     Train net output #0: loss = 1.78963 (* 1 = 1.78963 loss)
I0526 13:28:53.908838 15070 sgd_solver.cpp:106] Iteration 337500, lr = 0.001
I0526 13:29:06.012441 15070 solver.cpp:237] Iteration 338250, loss = 0.960364
I0526 13:29:06.012488 15070 solver.cpp:253]     Train net output #0: loss = 0.960365 (* 1 = 0.960365 loss)
I0526 13:29:06.012502 15070 sgd_solver.cpp:106] Iteration 338250, lr = 0.001
I0526 13:29:18.140573 15070 solver.cpp:237] Iteration 339000, loss = 0.796391
I0526 13:29:18.140609 15070 solver.cpp:253]     Train net output #0: loss = 0.796392 (* 1 = 0.796392 loss)
I0526 13:29:18.140624 15070 sgd_solver.cpp:106] Iteration 339000, lr = 0.001
I0526 13:29:30.269287 15070 solver.cpp:237] Iteration 339750, loss = 1.24736
I0526 13:29:30.269454 15070 solver.cpp:253]     Train net output #0: loss = 1.24736 (* 1 = 1.24736 loss)
I0526 13:29:30.269469 15070 sgd_solver.cpp:106] Iteration 339750, lr = 0.001
I0526 13:30:04.552080 15070 solver.cpp:237] Iteration 340500, loss = 0.784119
I0526 13:30:04.552243 15070 solver.cpp:253]     Train net output #0: loss = 0.78412 (* 1 = 0.78412 loss)
I0526 13:30:04.552259 15070 sgd_solver.cpp:106] Iteration 340500, lr = 0.001
I0526 13:30:16.662386 15070 solver.cpp:237] Iteration 341250, loss = 1.56227
I0526 13:30:16.662436 15070 solver.cpp:253]     Train net output #0: loss = 1.56227 (* 1 = 1.56227 loss)
I0526 13:30:16.662451 15070 sgd_solver.cpp:106] Iteration 341250, lr = 0.001
I0526 13:30:28.795711 15070 solver.cpp:237] Iteration 342000, loss = 1.51884
I0526 13:30:28.795747 15070 solver.cpp:253]     Train net output #0: loss = 1.51884 (* 1 = 1.51884 loss)
I0526 13:30:28.795763 15070 sgd_solver.cpp:106] Iteration 342000, lr = 0.001
I0526 13:30:40.952538 15070 solver.cpp:237] Iteration 342750, loss = 1.17645
I0526 13:30:40.952680 15070 solver.cpp:253]     Train net output #0: loss = 1.17646 (* 1 = 1.17646 loss)
I0526 13:30:40.952695 15070 sgd_solver.cpp:106] Iteration 342750, lr = 0.001
I0526 13:30:53.145849 15070 solver.cpp:237] Iteration 343500, loss = 0.980398
I0526 13:30:53.145897 15070 solver.cpp:253]     Train net output #0: loss = 0.9804 (* 1 = 0.9804 loss)
I0526 13:30:53.145911 15070 sgd_solver.cpp:106] Iteration 343500, lr = 0.001
I0526 13:31:05.338506 15070 solver.cpp:237] Iteration 344250, loss = 0.850557
I0526 13:31:05.338543 15070 solver.cpp:253]     Train net output #0: loss = 0.850558 (* 1 = 0.850558 loss)
I0526 13:31:05.338559 15070 sgd_solver.cpp:106] Iteration 344250, lr = 0.001
I0526 13:31:17.489022 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_345000.caffemodel
I0526 13:31:17.538391 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_345000.solverstate
I0526 13:31:17.563777 15070 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 13:32:30.337666 15070 solver.cpp:409]     Test net output #0: accuracy = 0.898422
I0526 13:32:30.337827 15070 solver.cpp:409]     Test net output #1: loss = 0.316845 (* 1 = 0.316845 loss)
I0526 13:32:52.591197 15070 solver.cpp:237] Iteration 345000, loss = 1.37285
I0526 13:32:52.591248 15070 solver.cpp:253]     Train net output #0: loss = 1.37285 (* 1 = 1.37285 loss)
I0526 13:32:52.591265 15070 sgd_solver.cpp:106] Iteration 345000, lr = 0.001
I0526 13:33:04.700439 15070 solver.cpp:237] Iteration 345750, loss = 0.840976
I0526 13:33:04.700610 15070 solver.cpp:253]     Train net output #0: loss = 0.840977 (* 1 = 0.840977 loss)
I0526 13:33:04.700626 15070 sgd_solver.cpp:106] Iteration 345750, lr = 0.001
I0526 13:33:16.808607 15070 solver.cpp:237] Iteration 346500, loss = 0.799519
I0526 13:33:16.808652 15070 solver.cpp:253]     Train net output #0: loss = 0.799521 (* 1 = 0.799521 loss)
I0526 13:33:16.808665 15070 sgd_solver.cpp:106] Iteration 346500, lr = 0.001
I0526 13:33:28.984333 15070 solver.cpp:237] Iteration 347250, loss = 0.806425
I0526 13:33:28.984369 15070 solver.cpp:253]     Train net output #0: loss = 0.806427 (* 1 = 0.806427 loss)
I0526 13:33:28.984383 15070 sgd_solver.cpp:106] Iteration 347250, lr = 0.001
I0526 13:33:41.151990 15070 solver.cpp:237] Iteration 348000, loss = 1.03433
I0526 13:33:41.152140 15070 solver.cpp:253]     Train net output #0: loss = 1.03433 (* 1 = 1.03433 loss)
I0526 13:33:41.152154 15070 sgd_solver.cpp:106] Iteration 348000, lr = 0.001
I0526 13:33:53.319319 15070 solver.cpp:237] Iteration 348750, loss = 1.08164
I0526 13:33:53.319353 15070 solver.cpp:253]     Train net output #0: loss = 1.08164 (* 1 = 1.08164 loss)
I0526 13:33:53.319370 15070 sgd_solver.cpp:106] Iteration 348750, lr = 0.001
I0526 13:34:05.485296 15070 solver.cpp:237] Iteration 349500, loss = 1.3463
I0526 13:34:05.485343 15070 solver.cpp:253]     Train net output #0: loss = 1.3463 (* 1 = 1.3463 loss)
I0526 13:34:05.485358 15070 sgd_solver.cpp:106] Iteration 349500, lr = 0.001
I0526 13:35:02.943738 15070 solver.cpp:237] Iteration 350250, loss = 1.46907
I0526 13:35:02.943904 15070 solver.cpp:253]     Train net output #0: loss = 1.46907 (* 1 = 1.46907 loss)
I0526 13:35:02.943918 15070 sgd_solver.cpp:106] Iteration 350250, lr = 0.001
I0526 13:35:15.104238 15070 solver.cpp:237] Iteration 351000, loss = 1.05868
I0526 13:35:15.104274 15070 solver.cpp:253]     Train net output #0: loss = 1.05868 (* 1 = 1.05868 loss)
I0526 13:35:15.104290 15070 sgd_solver.cpp:106] Iteration 351000, lr = 0.001
I0526 13:35:27.251839 15070 solver.cpp:237] Iteration 351750, loss = 1.0121
I0526 13:35:27.251880 15070 solver.cpp:253]     Train net output #0: loss = 1.01211 (* 1 = 1.01211 loss)
I0526 13:35:27.251898 15070 sgd_solver.cpp:106] Iteration 351750, lr = 0.001
I0526 13:35:39.372916 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_352500.caffemodel
I0526 13:35:39.424865 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_352500.solverstate
I0526 13:35:39.457779 15070 solver.cpp:237] Iteration 352500, loss = 1.27656
I0526 13:35:39.457830 15070 solver.cpp:253]     Train net output #0: loss = 1.27656 (* 1 = 1.27656 loss)
I0526 13:35:39.457844 15070 sgd_solver.cpp:106] Iteration 352500, lr = 0.001
I0526 13:35:51.591764 15070 solver.cpp:237] Iteration 353250, loss = 1.23186
I0526 13:35:51.591809 15070 solver.cpp:253]     Train net output #0: loss = 1.23186 (* 1 = 1.23186 loss)
I0526 13:35:51.591822 15070 sgd_solver.cpp:106] Iteration 353250, lr = 0.001
I0526 13:36:03.708953 15070 solver.cpp:237] Iteration 354000, loss = 1.78128
I0526 13:36:03.708989 15070 solver.cpp:253]     Train net output #0: loss = 1.78128 (* 1 = 1.78128 loss)
I0526 13:36:03.709003 15070 sgd_solver.cpp:106] Iteration 354000, lr = 0.001
I0526 13:36:15.867640 15070 solver.cpp:237] Iteration 354750, loss = 0.972126
I0526 13:36:15.867825 15070 solver.cpp:253]     Train net output #0: loss = 0.972127 (* 1 = 0.972127 loss)
I0526 13:36:15.867841 15070 sgd_solver.cpp:106] Iteration 354750, lr = 0.001
I0526 13:36:50.260277 15070 solver.cpp:237] Iteration 355500, loss = 0.926486
I0526 13:36:50.260452 15070 solver.cpp:253]     Train net output #0: loss = 0.926487 (* 1 = 0.926487 loss)
I0526 13:36:50.260467 15070 sgd_solver.cpp:106] Iteration 355500, lr = 0.001
I0526 13:37:02.382468 15070 solver.cpp:237] Iteration 356250, loss = 1.037
I0526 13:37:02.382514 15070 solver.cpp:253]     Train net output #0: loss = 1.037 (* 1 = 1.037 loss)
I0526 13:37:02.382529 15070 sgd_solver.cpp:106] Iteration 356250, lr = 0.001
I0526 13:37:14.510888 15070 solver.cpp:237] Iteration 357000, loss = 1.0954
I0526 13:37:14.510924 15070 solver.cpp:253]     Train net output #0: loss = 1.0954 (* 1 = 1.0954 loss)
I0526 13:37:14.510937 15070 sgd_solver.cpp:106] Iteration 357000, lr = 0.001
I0526 13:37:26.671581 15070 solver.cpp:237] Iteration 357750, loss = 1.43827
I0526 13:37:26.671739 15070 solver.cpp:253]     Train net output #0: loss = 1.43827 (* 1 = 1.43827 loss)
I0526 13:37:26.671753 15070 sgd_solver.cpp:106] Iteration 357750, lr = 0.001
I0526 13:37:38.803248 15070 solver.cpp:237] Iteration 358500, loss = 1.38273
I0526 13:37:38.803284 15070 solver.cpp:253]     Train net output #0: loss = 1.38273 (* 1 = 1.38273 loss)
I0526 13:37:38.803300 15070 sgd_solver.cpp:106] Iteration 358500, lr = 0.001
I0526 13:37:50.927997 15070 solver.cpp:237] Iteration 359250, loss = 1.33593
I0526 13:37:50.928043 15070 solver.cpp:253]     Train net output #0: loss = 1.33593 (* 1 = 1.33593 loss)
I0526 13:37:50.928058 15070 sgd_solver.cpp:106] Iteration 359250, lr = 0.001
I0526 13:38:03.036046 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_360000.caffemodel
I0526 13:38:03.087947 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_360000.solverstate
I0526 13:38:03.115628 15070 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 13:38:55.177804 15070 solver.cpp:409]     Test net output #0: accuracy = 0.897791
I0526 13:38:55.177968 15070 solver.cpp:409]     Test net output #1: loss = 0.329808 (* 1 = 0.329808 loss)
I0526 13:39:16.071705 15070 solver.cpp:237] Iteration 360000, loss = 0.896391
I0526 13:39:16.071758 15070 solver.cpp:253]     Train net output #0: loss = 0.896392 (* 1 = 0.896392 loss)
I0526 13:39:16.071774 15070 sgd_solver.cpp:106] Iteration 360000, lr = 0.001
I0526 13:39:28.240478 15070 solver.cpp:237] Iteration 360750, loss = 0.752722
I0526 13:39:28.240648 15070 solver.cpp:253]     Train net output #0: loss = 0.752723 (* 1 = 0.752723 loss)
I0526 13:39:28.240663 15070 sgd_solver.cpp:106] Iteration 360750, lr = 0.001
I0526 13:39:40.377023 15070 solver.cpp:237] Iteration 361500, loss = 1.02654
I0526 13:39:40.377059 15070 solver.cpp:253]     Train net output #0: loss = 1.02654 (* 1 = 1.02654 loss)
I0526 13:39:40.377077 15070 sgd_solver.cpp:106] Iteration 361500, lr = 0.001
I0526 13:39:52.497745 15070 solver.cpp:237] Iteration 362250, loss = 0.932142
I0526 13:39:52.497787 15070 solver.cpp:253]     Train net output #0: loss = 0.932142 (* 1 = 0.932142 loss)
I0526 13:39:52.497807 15070 sgd_solver.cpp:106] Iteration 362250, lr = 0.001
I0526 13:40:04.661048 15070 solver.cpp:237] Iteration 363000, loss = 1.15787
I0526 13:40:04.661216 15070 solver.cpp:253]     Train net output #0: loss = 1.15787 (* 1 = 1.15787 loss)
I0526 13:40:04.661231 15070 sgd_solver.cpp:106] Iteration 363000, lr = 0.001
I0526 13:40:16.828941 15070 solver.cpp:237] Iteration 363750, loss = 0.910445
I0526 13:40:16.828985 15070 solver.cpp:253]     Train net output #0: loss = 0.910446 (* 1 = 0.910446 loss)
I0526 13:40:16.828999 15070 sgd_solver.cpp:106] Iteration 363750, lr = 0.001
I0526 13:40:29.018391 15070 solver.cpp:237] Iteration 364500, loss = 1.20602
I0526 13:40:29.018429 15070 solver.cpp:253]     Train net output #0: loss = 1.20602 (* 1 = 1.20602 loss)
I0526 13:40:29.018442 15070 sgd_solver.cpp:106] Iteration 364500, lr = 0.001
I0526 13:41:02.088362 15070 solver.cpp:237] Iteration 365250, loss = 1.22374
I0526 13:41:02.088532 15070 solver.cpp:253]     Train net output #0: loss = 1.22374 (* 1 = 1.22374 loss)
I0526 13:41:02.088547 15070 sgd_solver.cpp:106] Iteration 365250, lr = 0.001
I0526 13:41:14.241389 15070 solver.cpp:237] Iteration 366000, loss = 0.975996
I0526 13:41:14.241435 15070 solver.cpp:253]     Train net output #0: loss = 0.975996 (* 1 = 0.975996 loss)
I0526 13:41:14.241451 15070 sgd_solver.cpp:106] Iteration 366000, lr = 0.001
I0526 13:41:26.423709 15070 solver.cpp:237] Iteration 366750, loss = 1.97699
I0526 13:41:26.423745 15070 solver.cpp:253]     Train net output #0: loss = 1.97699 (* 1 = 1.97699 loss)
I0526 13:41:26.423763 15070 sgd_solver.cpp:106] Iteration 366750, lr = 0.001
I0526 13:41:38.566299 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_367500.caffemodel
I0526 13:41:38.616336 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_367500.solverstate
I0526 13:41:38.647099 15070 solver.cpp:237] Iteration 367500, loss = 1.21587
I0526 13:41:38.647145 15070 solver.cpp:253]     Train net output #0: loss = 1.21587 (* 1 = 1.21587 loss)
I0526 13:41:38.647161 15070 sgd_solver.cpp:106] Iteration 367500, lr = 0.001
I0526 13:41:50.811403 15070 solver.cpp:237] Iteration 368250, loss = 1.10508
I0526 13:41:50.811439 15070 solver.cpp:253]     Train net output #0: loss = 1.10509 (* 1 = 1.10509 loss)
I0526 13:41:50.811455 15070 sgd_solver.cpp:106] Iteration 368250, lr = 0.001
I0526 13:42:02.950992 15070 solver.cpp:237] Iteration 369000, loss = 1.02897
I0526 13:42:02.951038 15070 solver.cpp:253]     Train net output #0: loss = 1.02897 (* 1 = 1.02897 loss)
I0526 13:42:02.951053 15070 sgd_solver.cpp:106] Iteration 369000, lr = 0.001
I0526 13:42:15.079226 15070 solver.cpp:237] Iteration 369750, loss = 1.45412
I0526 13:42:15.079375 15070 solver.cpp:253]     Train net output #0: loss = 1.45412 (* 1 = 1.45412 loss)
I0526 13:42:15.079390 15070 sgd_solver.cpp:106] Iteration 369750, lr = 0.001
I0526 13:42:48.109845 15070 solver.cpp:237] Iteration 370500, loss = 1.02999
I0526 13:42:48.110009 15070 solver.cpp:253]     Train net output #0: loss = 1.02999 (* 1 = 1.02999 loss)
I0526 13:42:48.110023 15070 sgd_solver.cpp:106] Iteration 370500, lr = 0.001
I0526 13:43:00.274344 15070 solver.cpp:237] Iteration 371250, loss = 0.794899
I0526 13:43:00.274381 15070 solver.cpp:253]     Train net output #0: loss = 0.7949 (* 1 = 0.7949 loss)
I0526 13:43:00.274399 15070 sgd_solver.cpp:106] Iteration 371250, lr = 0.001
I0526 13:43:12.448254 15070 solver.cpp:237] Iteration 372000, loss = 1.12102
I0526 13:43:12.448302 15070 solver.cpp:253]     Train net output #0: loss = 1.12102 (* 1 = 1.12102 loss)
I0526 13:43:12.448318 15070 sgd_solver.cpp:106] Iteration 372000, lr = 0.001
I0526 13:43:24.566375 15070 solver.cpp:237] Iteration 372750, loss = 1.17
I0526 13:43:24.566542 15070 solver.cpp:253]     Train net output #0: loss = 1.17 (* 1 = 1.17 loss)
I0526 13:43:24.566557 15070 sgd_solver.cpp:106] Iteration 372750, lr = 0.001
I0526 13:43:36.667240 15070 solver.cpp:237] Iteration 373500, loss = 1.15459
I0526 13:43:36.667289 15070 solver.cpp:253]     Train net output #0: loss = 1.15459 (* 1 = 1.15459 loss)
I0526 13:43:36.667302 15070 sgd_solver.cpp:106] Iteration 373500, lr = 0.001
I0526 13:43:48.808666 15070 solver.cpp:237] Iteration 374250, loss = 1.08717
I0526 13:43:48.808702 15070 solver.cpp:253]     Train net output #0: loss = 1.08717 (* 1 = 1.08717 loss)
I0526 13:43:48.808715 15070 sgd_solver.cpp:106] Iteration 374250, lr = 0.001
I0526 13:44:00.947067 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_375000.caffemodel
I0526 13:44:00.997064 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_375000.solverstate
I0526 13:44:01.022893 15070 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 13:45:13.834105 15070 solver.cpp:409]     Test net output #0: accuracy = 0.899619
I0526 13:45:13.834275 15070 solver.cpp:409]     Test net output #1: loss = 0.316038 (* 1 = 0.316038 loss)
I0526 13:45:34.723788 15070 solver.cpp:237] Iteration 375000, loss = 0.89761
I0526 13:45:34.723840 15070 solver.cpp:253]     Train net output #0: loss = 0.897611 (* 1 = 0.897611 loss)
I0526 13:45:34.723856 15070 sgd_solver.cpp:106] Iteration 375000, lr = 0.001
I0526 13:45:46.869119 15070 solver.cpp:237] Iteration 375750, loss = 0.950638
I0526 13:45:46.869290 15070 solver.cpp:253]     Train net output #0: loss = 0.950639 (* 1 = 0.950639 loss)
I0526 13:45:46.869307 15070 sgd_solver.cpp:106] Iteration 375750, lr = 0.001
I0526 13:45:58.984547 15070 solver.cpp:237] Iteration 376500, loss = 1.19157
I0526 13:45:58.984582 15070 solver.cpp:253]     Train net output #0: loss = 1.19157 (* 1 = 1.19157 loss)
I0526 13:45:58.984601 15070 sgd_solver.cpp:106] Iteration 376500, lr = 0.001
I0526 13:46:11.125964 15070 solver.cpp:237] Iteration 377250, loss = 1.07514
I0526 13:46:11.126014 15070 solver.cpp:253]     Train net output #0: loss = 1.07514 (* 1 = 1.07514 loss)
I0526 13:46:11.126029 15070 sgd_solver.cpp:106] Iteration 377250, lr = 0.001
I0526 13:46:23.279953 15070 solver.cpp:237] Iteration 378000, loss = 1.32341
I0526 13:46:23.280100 15070 solver.cpp:253]     Train net output #0: loss = 1.32341 (* 1 = 1.32341 loss)
I0526 13:46:23.280115 15070 sgd_solver.cpp:106] Iteration 378000, lr = 0.001
I0526 13:46:35.421691 15070 solver.cpp:237] Iteration 378750, loss = 1.59923
I0526 13:46:35.421737 15070 solver.cpp:253]     Train net output #0: loss = 1.59923 (* 1 = 1.59923 loss)
I0526 13:46:35.421753 15070 sgd_solver.cpp:106] Iteration 378750, lr = 0.001
I0526 13:46:47.538941 15070 solver.cpp:237] Iteration 379500, loss = 1.22874
I0526 13:46:47.538976 15070 solver.cpp:253]     Train net output #0: loss = 1.22874 (* 1 = 1.22874 loss)
I0526 13:46:47.538995 15070 sgd_solver.cpp:106] Iteration 379500, lr = 0.001
I0526 13:47:20.568799 15070 solver.cpp:237] Iteration 380250, loss = 1.38261
I0526 13:47:20.568964 15070 solver.cpp:253]     Train net output #0: loss = 1.38261 (* 1 = 1.38261 loss)
I0526 13:47:20.568979 15070 sgd_solver.cpp:106] Iteration 380250, lr = 0.001
I0526 13:47:32.725739 15070 solver.cpp:237] Iteration 381000, loss = 0.870847
I0526 13:47:32.725782 15070 solver.cpp:253]     Train net output #0: loss = 0.870848 (* 1 = 0.870848 loss)
I0526 13:47:32.725796 15070 sgd_solver.cpp:106] Iteration 381000, lr = 0.001
I0526 13:47:44.863948 15070 solver.cpp:237] Iteration 381750, loss = 1.36342
I0526 13:47:44.863984 15070 solver.cpp:253]     Train net output #0: loss = 1.36342 (* 1 = 1.36342 loss)
I0526 13:47:44.863997 15070 sgd_solver.cpp:106] Iteration 381750, lr = 0.001
I0526 13:47:56.982830 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_382500.caffemodel
I0526 13:47:57.032733 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_382500.solverstate
I0526 13:47:57.063487 15070 solver.cpp:237] Iteration 382500, loss = 0.855589
I0526 13:47:57.063531 15070 solver.cpp:253]     Train net output #0: loss = 0.85559 (* 1 = 0.85559 loss)
I0526 13:47:57.063546 15070 sgd_solver.cpp:106] Iteration 382500, lr = 0.001
I0526 13:48:09.202345 15070 solver.cpp:237] Iteration 383250, loss = 0.819955
I0526 13:48:09.202383 15070 solver.cpp:253]     Train net output #0: loss = 0.819956 (* 1 = 0.819956 loss)
I0526 13:48:09.202399 15070 sgd_solver.cpp:106] Iteration 383250, lr = 0.001
I0526 13:48:21.337433 15070 solver.cpp:237] Iteration 384000, loss = 0.781688
I0526 13:48:21.337481 15070 solver.cpp:253]     Train net output #0: loss = 0.781688 (* 1 = 0.781688 loss)
I0526 13:48:21.337496 15070 sgd_solver.cpp:106] Iteration 384000, lr = 0.001
I0526 13:48:33.469266 15070 solver.cpp:237] Iteration 384750, loss = 0.748585
I0526 13:48:33.469430 15070 solver.cpp:253]     Train net output #0: loss = 0.748586 (* 1 = 0.748586 loss)
I0526 13:48:33.469444 15070 sgd_solver.cpp:106] Iteration 384750, lr = 0.001
I0526 13:49:06.485960 15070 solver.cpp:237] Iteration 385500, loss = 0.68878
I0526 13:49:06.486132 15070 solver.cpp:253]     Train net output #0: loss = 0.688781 (* 1 = 0.688781 loss)
I0526 13:49:06.486147 15070 sgd_solver.cpp:106] Iteration 385500, lr = 0.001
I0526 13:49:18.614601 15070 solver.cpp:237] Iteration 386250, loss = 1.2113
I0526 13:49:18.614636 15070 solver.cpp:253]     Train net output #0: loss = 1.2113 (* 1 = 1.2113 loss)
I0526 13:49:18.614652 15070 sgd_solver.cpp:106] Iteration 386250, lr = 0.001
I0526 13:49:30.732949 15070 solver.cpp:237] Iteration 387000, loss = 1.24597
I0526 13:49:30.732993 15070 solver.cpp:253]     Train net output #0: loss = 1.24597 (* 1 = 1.24597 loss)
I0526 13:49:30.733009 15070 sgd_solver.cpp:106] Iteration 387000, lr = 0.001
I0526 13:49:42.844892 15070 solver.cpp:237] Iteration 387750, loss = 1.39677
I0526 13:49:42.845041 15070 solver.cpp:253]     Train net output #0: loss = 1.39677 (* 1 = 1.39677 loss)
I0526 13:49:42.845054 15070 sgd_solver.cpp:106] Iteration 387750, lr = 0.001
I0526 13:49:54.967411 15070 solver.cpp:237] Iteration 388500, loss = 1.12819
I0526 13:49:54.967454 15070 solver.cpp:253]     Train net output #0: loss = 1.12819 (* 1 = 1.12819 loss)
I0526 13:49:54.967468 15070 sgd_solver.cpp:106] Iteration 388500, lr = 0.001
I0526 13:50:07.101294 15070 solver.cpp:237] Iteration 389250, loss = 0.814953
I0526 13:50:07.101330 15070 solver.cpp:253]     Train net output #0: loss = 0.814954 (* 1 = 0.814954 loss)
I0526 13:50:07.101344 15070 sgd_solver.cpp:106] Iteration 389250, lr = 0.001
I0526 13:50:19.235359 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_390000.caffemodel
I0526 13:50:19.285955 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_390000.solverstate
I0526 13:50:19.311458 15070 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 13:51:10.960307 15070 solver.cpp:409]     Test net output #0: accuracy = 0.895178
I0526 13:51:10.960474 15070 solver.cpp:409]     Test net output #1: loss = 0.330241 (* 1 = 0.330241 loss)
I0526 13:51:31.864142 15070 solver.cpp:237] Iteration 390000, loss = 1.00213
I0526 13:51:31.864194 15070 solver.cpp:253]     Train net output #0: loss = 1.00213 (* 1 = 1.00213 loss)
I0526 13:51:31.864212 15070 sgd_solver.cpp:106] Iteration 390000, lr = 0.001
I0526 13:51:44.078409 15070 solver.cpp:237] Iteration 390750, loss = 1.114
I0526 13:51:44.078565 15070 solver.cpp:253]     Train net output #0: loss = 1.114 (* 1 = 1.114 loss)
I0526 13:51:44.078579 15070 sgd_solver.cpp:106] Iteration 390750, lr = 0.001
I0526 13:51:56.262068 15070 solver.cpp:237] Iteration 391500, loss = 1.076
I0526 13:51:56.262115 15070 solver.cpp:253]     Train net output #0: loss = 1.076 (* 1 = 1.076 loss)
I0526 13:51:56.262130 15070 sgd_solver.cpp:106] Iteration 391500, lr = 0.001
I0526 13:52:08.444629 15070 solver.cpp:237] Iteration 392250, loss = 1.48331
I0526 13:52:08.444666 15070 solver.cpp:253]     Train net output #0: loss = 1.48332 (* 1 = 1.48332 loss)
I0526 13:52:08.444684 15070 sgd_solver.cpp:106] Iteration 392250, lr = 0.001
I0526 13:52:20.609625 15070 solver.cpp:237] Iteration 393000, loss = 1.42951
I0526 13:52:20.609787 15070 solver.cpp:253]     Train net output #0: loss = 1.42951 (* 1 = 1.42951 loss)
I0526 13:52:20.609803 15070 sgd_solver.cpp:106] Iteration 393000, lr = 0.001
I0526 13:52:32.823801 15070 solver.cpp:237] Iteration 393750, loss = 0.892019
I0526 13:52:32.823843 15070 solver.cpp:253]     Train net output #0: loss = 0.89202 (* 1 = 0.89202 loss)
I0526 13:52:32.823859 15070 sgd_solver.cpp:106] Iteration 393750, lr = 0.001
I0526 13:52:45.048380 15070 solver.cpp:237] Iteration 394500, loss = 1.35208
I0526 13:52:45.048415 15070 solver.cpp:253]     Train net output #0: loss = 1.35208 (* 1 = 1.35208 loss)
I0526 13:52:45.048434 15070 sgd_solver.cpp:106] Iteration 394500, lr = 0.001
I0526 13:53:18.152112 15070 solver.cpp:237] Iteration 395250, loss = 1.33162
I0526 13:53:18.152289 15070 solver.cpp:253]     Train net output #0: loss = 1.33162 (* 1 = 1.33162 loss)
I0526 13:53:18.152303 15070 sgd_solver.cpp:106] Iteration 395250, lr = 0.001
I0526 13:53:30.346667 15070 solver.cpp:237] Iteration 396000, loss = 1.10519
I0526 13:53:30.346703 15070 solver.cpp:253]     Train net output #0: loss = 1.10519 (* 1 = 1.10519 loss)
I0526 13:53:30.346722 15070 sgd_solver.cpp:106] Iteration 396000, lr = 0.001
I0526 13:53:42.521111 15070 solver.cpp:237] Iteration 396750, loss = 0.973911
I0526 13:53:42.521162 15070 solver.cpp:253]     Train net output #0: loss = 0.973911 (* 1 = 0.973911 loss)
I0526 13:53:42.521176 15070 sgd_solver.cpp:106] Iteration 396750, lr = 0.001
I0526 13:53:54.725392 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_397500.caffemodel
I0526 13:53:54.777200 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_397500.solverstate
I0526 13:53:54.810406 15070 solver.cpp:237] Iteration 397500, loss = 1.61768
I0526 13:53:54.810456 15070 solver.cpp:253]     Train net output #0: loss = 1.61768 (* 1 = 1.61768 loss)
I0526 13:53:54.810473 15070 sgd_solver.cpp:106] Iteration 397500, lr = 0.001
I0526 13:54:07.008560 15070 solver.cpp:237] Iteration 398250, loss = 1.31457
I0526 13:54:07.008607 15070 solver.cpp:253]     Train net output #0: loss = 1.31457 (* 1 = 1.31457 loss)
I0526 13:54:07.008622 15070 sgd_solver.cpp:106] Iteration 398250, lr = 0.001
I0526 13:54:19.105609 15070 solver.cpp:237] Iteration 399000, loss = 1.01696
I0526 13:54:19.105644 15070 solver.cpp:253]     Train net output #0: loss = 1.01696 (* 1 = 1.01696 loss)
I0526 13:54:19.105661 15070 sgd_solver.cpp:106] Iteration 399000, lr = 0.001
I0526 13:54:31.245311 15070 solver.cpp:237] Iteration 399750, loss = 1.06837
I0526 13:54:31.245488 15070 solver.cpp:253]     Train net output #0: loss = 1.06837 (* 1 = 1.06837 loss)
I0526 13:54:31.245503 15070 sgd_solver.cpp:106] Iteration 399750, lr = 0.001
I0526 13:55:04.337508 15070 solver.cpp:237] Iteration 400500, loss = 1.04112
I0526 13:55:04.337684 15070 solver.cpp:253]     Train net output #0: loss = 1.04112 (* 1 = 1.04112 loss)
I0526 13:55:04.337699 15070 sgd_solver.cpp:106] Iteration 400500, lr = 0.001
I0526 13:55:16.509903 15070 solver.cpp:237] Iteration 401250, loss = 1.06526
I0526 13:55:16.509948 15070 solver.cpp:253]     Train net output #0: loss = 1.06526 (* 1 = 1.06526 loss)
I0526 13:55:16.509961 15070 sgd_solver.cpp:106] Iteration 401250, lr = 0.001
I0526 13:55:28.744212 15070 solver.cpp:237] Iteration 402000, loss = 1.12813
I0526 13:55:28.744249 15070 solver.cpp:253]     Train net output #0: loss = 1.12814 (* 1 = 1.12814 loss)
I0526 13:55:28.744266 15070 sgd_solver.cpp:106] Iteration 402000, lr = 0.001
I0526 13:55:40.965477 15070 solver.cpp:237] Iteration 402750, loss = 0.884847
I0526 13:55:40.965638 15070 solver.cpp:253]     Train net output #0: loss = 0.884847 (* 1 = 0.884847 loss)
I0526 13:55:40.965652 15070 sgd_solver.cpp:106] Iteration 402750, lr = 0.001
I0526 13:55:53.166116 15070 solver.cpp:237] Iteration 403500, loss = 1.22824
I0526 13:55:53.166162 15070 solver.cpp:253]     Train net output #0: loss = 1.22824 (* 1 = 1.22824 loss)
I0526 13:55:53.166177 15070 sgd_solver.cpp:106] Iteration 403500, lr = 0.001
I0526 13:56:05.352955 15070 solver.cpp:237] Iteration 404250, loss = 0.89081
I0526 13:56:05.352993 15070 solver.cpp:253]     Train net output #0: loss = 0.890811 (* 1 = 0.890811 loss)
I0526 13:56:05.353006 15070 sgd_solver.cpp:106] Iteration 404250, lr = 0.001
I0526 13:56:17.535727 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_405000.caffemodel
I0526 13:56:17.584789 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_405000.solverstate
I0526 13:56:17.610519 15070 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 13:57:30.443800 15070 solver.cpp:409]     Test net output #0: accuracy = 0.898866
I0526 13:57:30.443972 15070 solver.cpp:409]     Test net output #1: loss = 0.325419 (* 1 = 0.325419 loss)
I0526 13:57:51.324561 15070 solver.cpp:237] Iteration 405000, loss = 1.18756
I0526 13:57:51.324614 15070 solver.cpp:253]     Train net output #0: loss = 1.18756 (* 1 = 1.18756 loss)
I0526 13:57:51.324628 15070 sgd_solver.cpp:106] Iteration 405000, lr = 0.001
I0526 13:58:03.437649 15070 solver.cpp:237] Iteration 405750, loss = 0.810309
I0526 13:58:03.437808 15070 solver.cpp:253]     Train net output #0: loss = 0.810309 (* 1 = 0.810309 loss)
I0526 13:58:03.437824 15070 sgd_solver.cpp:106] Iteration 405750, lr = 0.001
I0526 13:58:15.555166 15070 solver.cpp:237] Iteration 406500, loss = 1.59985
I0526 13:58:15.555212 15070 solver.cpp:253]     Train net output #0: loss = 1.59985 (* 1 = 1.59985 loss)
I0526 13:58:15.555227 15070 sgd_solver.cpp:106] Iteration 406500, lr = 0.001
I0526 13:58:27.710489 15070 solver.cpp:237] Iteration 407250, loss = 1.00334
I0526 13:58:27.710525 15070 solver.cpp:253]     Train net output #0: loss = 1.00334 (* 1 = 1.00334 loss)
I0526 13:58:27.710541 15070 sgd_solver.cpp:106] Iteration 407250, lr = 0.001
I0526 13:58:39.833139 15070 solver.cpp:237] Iteration 408000, loss = 1.2143
I0526 13:58:39.833300 15070 solver.cpp:253]     Train net output #0: loss = 1.2143 (* 1 = 1.2143 loss)
I0526 13:58:39.833314 15070 sgd_solver.cpp:106] Iteration 408000, lr = 0.001
I0526 13:58:51.973387 15070 solver.cpp:237] Iteration 408750, loss = 1.16601
I0526 13:58:51.973423 15070 solver.cpp:253]     Train net output #0: loss = 1.16601 (* 1 = 1.16601 loss)
I0526 13:58:51.973438 15070 sgd_solver.cpp:106] Iteration 408750, lr = 0.001
I0526 13:59:04.121140 15070 solver.cpp:237] Iteration 409500, loss = 0.779537
I0526 13:59:04.121188 15070 solver.cpp:253]     Train net output #0: loss = 0.779537 (* 1 = 0.779537 loss)
I0526 13:59:04.121202 15070 sgd_solver.cpp:106] Iteration 409500, lr = 0.001
I0526 13:59:37.107954 15070 solver.cpp:237] Iteration 410250, loss = 1.17625
I0526 13:59:37.108129 15070 solver.cpp:253]     Train net output #0: loss = 1.17625 (* 1 = 1.17625 loss)
I0526 13:59:37.108145 15070 sgd_solver.cpp:106] Iteration 410250, lr = 0.001
I0526 13:59:49.254262 15070 solver.cpp:237] Iteration 411000, loss = 0.870099
I0526 13:59:49.254298 15070 solver.cpp:253]     Train net output #0: loss = 0.870099 (* 1 = 0.870099 loss)
I0526 13:59:49.254317 15070 sgd_solver.cpp:106] Iteration 411000, lr = 0.001
I0526 14:00:01.362831 15070 solver.cpp:237] Iteration 411750, loss = 1.14292
I0526 14:00:01.362880 15070 solver.cpp:253]     Train net output #0: loss = 1.14292 (* 1 = 1.14292 loss)
I0526 14:00:01.362895 15070 sgd_solver.cpp:106] Iteration 411750, lr = 0.001
I0526 14:00:13.523638 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_412500.caffemodel
I0526 14:00:13.579408 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_412500.solverstate
I0526 14:00:13.610183 15070 solver.cpp:237] Iteration 412500, loss = 1.25907
I0526 14:00:13.610229 15070 solver.cpp:253]     Train net output #0: loss = 1.25906 (* 1 = 1.25906 loss)
I0526 14:00:13.610244 15070 sgd_solver.cpp:106] Iteration 412500, lr = 0.001
I0526 14:00:25.752756 15070 solver.cpp:237] Iteration 413250, loss = 1.10912
I0526 14:00:25.752802 15070 solver.cpp:253]     Train net output #0: loss = 1.10912 (* 1 = 1.10912 loss)
I0526 14:00:25.752818 15070 sgd_solver.cpp:106] Iteration 413250, lr = 0.001
I0526 14:00:37.861408 15070 solver.cpp:237] Iteration 414000, loss = 1.12938
I0526 14:00:37.861443 15070 solver.cpp:253]     Train net output #0: loss = 1.12938 (* 1 = 1.12938 loss)
I0526 14:00:37.861460 15070 sgd_solver.cpp:106] Iteration 414000, lr = 0.001
I0526 14:00:49.966737 15070 solver.cpp:237] Iteration 414750, loss = 0.962616
I0526 14:00:49.966912 15070 solver.cpp:253]     Train net output #0: loss = 0.962615 (* 1 = 0.962615 loss)
I0526 14:00:49.966928 15070 sgd_solver.cpp:106] Iteration 414750, lr = 0.001
I0526 14:01:22.978798 15070 solver.cpp:237] Iteration 415500, loss = 1.25297
I0526 14:01:22.978976 15070 solver.cpp:253]     Train net output #0: loss = 1.25297 (* 1 = 1.25297 loss)
I0526 14:01:22.978991 15070 sgd_solver.cpp:106] Iteration 415500, lr = 0.001
I0526 14:01:35.118283 15070 solver.cpp:237] Iteration 416250, loss = 1.48932
I0526 14:01:35.118333 15070 solver.cpp:253]     Train net output #0: loss = 1.48932 (* 1 = 1.48932 loss)
I0526 14:01:35.118348 15070 sgd_solver.cpp:106] Iteration 416250, lr = 0.001
I0526 14:01:47.237843 15070 solver.cpp:237] Iteration 417000, loss = 1.00821
I0526 14:01:47.237880 15070 solver.cpp:253]     Train net output #0: loss = 1.00821 (* 1 = 1.00821 loss)
I0526 14:01:47.237898 15070 sgd_solver.cpp:106] Iteration 417000, lr = 0.001
I0526 14:01:59.378614 15070 solver.cpp:237] Iteration 417750, loss = 0.979914
I0526 14:01:59.378796 15070 solver.cpp:253]     Train net output #0: loss = 0.979913 (* 1 = 0.979913 loss)
I0526 14:01:59.378811 15070 sgd_solver.cpp:106] Iteration 417750, lr = 0.001
I0526 14:02:11.541345 15070 solver.cpp:237] Iteration 418500, loss = 1.20908
I0526 14:02:11.541383 15070 solver.cpp:253]     Train net output #0: loss = 1.20908 (* 1 = 1.20908 loss)
I0526 14:02:11.541399 15070 sgd_solver.cpp:106] Iteration 418500, lr = 0.001
I0526 14:02:23.707303 15070 solver.cpp:237] Iteration 419250, loss = 1.01447
I0526 14:02:23.707351 15070 solver.cpp:253]     Train net output #0: loss = 1.01447 (* 1 = 1.01447 loss)
I0526 14:02:23.707365 15070 sgd_solver.cpp:106] Iteration 419250, lr = 0.001
I0526 14:02:35.835682 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_420000.caffemodel
I0526 14:02:35.884922 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_420000.solverstate
I0526 14:02:35.910248 15070 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 14:03:27.959383 15070 solver.cpp:409]     Test net output #0: accuracy = 0.898364
I0526 14:03:27.959553 15070 solver.cpp:409]     Test net output #1: loss = 0.310623 (* 1 = 0.310623 loss)
I0526 14:03:48.844295 15070 solver.cpp:237] Iteration 420000, loss = 1.03657
I0526 14:03:48.844347 15070 solver.cpp:253]     Train net output #0: loss = 1.03657 (* 1 = 1.03657 loss)
I0526 14:03:48.844362 15070 sgd_solver.cpp:106] Iteration 420000, lr = 0.001
I0526 14:04:01.012794 15070 solver.cpp:237] Iteration 420750, loss = 1.25024
I0526 14:04:01.012964 15070 solver.cpp:253]     Train net output #0: loss = 1.25024 (* 1 = 1.25024 loss)
I0526 14:04:01.012979 15070 sgd_solver.cpp:106] Iteration 420750, lr = 0.001
I0526 14:04:13.238561 15070 solver.cpp:237] Iteration 421500, loss = 1.11904
I0526 14:04:13.238603 15070 solver.cpp:253]     Train net output #0: loss = 1.11904 (* 1 = 1.11904 loss)
I0526 14:04:13.238616 15070 sgd_solver.cpp:106] Iteration 421500, lr = 0.001
I0526 14:04:25.491870 15070 solver.cpp:237] Iteration 422250, loss = 0.977409
I0526 14:04:25.491907 15070 solver.cpp:253]     Train net output #0: loss = 0.977409 (* 1 = 0.977409 loss)
I0526 14:04:25.491924 15070 sgd_solver.cpp:106] Iteration 422250, lr = 0.001
I0526 14:04:37.591902 15070 solver.cpp:237] Iteration 423000, loss = 0.930442
I0526 14:04:37.592083 15070 solver.cpp:253]     Train net output #0: loss = 0.930441 (* 1 = 0.930441 loss)
I0526 14:04:37.592098 15070 sgd_solver.cpp:106] Iteration 423000, lr = 0.001
I0526 14:04:49.657111 15070 solver.cpp:237] Iteration 423750, loss = 0.943639
I0526 14:04:49.657148 15070 solver.cpp:253]     Train net output #0: loss = 0.943639 (* 1 = 0.943639 loss)
I0526 14:04:49.657163 15070 sgd_solver.cpp:106] Iteration 423750, lr = 0.001
I0526 14:05:01.719884 15070 solver.cpp:237] Iteration 424500, loss = 1.00384
I0526 14:05:01.719933 15070 solver.cpp:253]     Train net output #0: loss = 1.00384 (* 1 = 1.00384 loss)
I0526 14:05:01.719947 15070 sgd_solver.cpp:106] Iteration 424500, lr = 0.001
I0526 14:05:34.807051 15070 solver.cpp:237] Iteration 425250, loss = 1.05766
I0526 14:05:34.807227 15070 solver.cpp:253]     Train net output #0: loss = 1.05766 (* 1 = 1.05766 loss)
I0526 14:05:34.807245 15070 sgd_solver.cpp:106] Iteration 425250, lr = 0.001
I0526 14:05:46.982678 15070 solver.cpp:237] Iteration 426000, loss = 1.17999
I0526 14:05:46.982738 15070 solver.cpp:253]     Train net output #0: loss = 1.17999 (* 1 = 1.17999 loss)
I0526 14:05:46.982753 15070 sgd_solver.cpp:106] Iteration 426000, lr = 0.001
I0526 14:05:59.131019 15070 solver.cpp:237] Iteration 426750, loss = 1.29431
I0526 14:05:59.131049 15070 solver.cpp:253]     Train net output #0: loss = 1.29431 (* 1 = 1.29431 loss)
I0526 14:05:59.131062 15070 sgd_solver.cpp:106] Iteration 426750, lr = 0.001
I0526 14:06:11.265601 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_427500.caffemodel
I0526 14:06:11.318119 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_427500.solverstate
I0526 14:06:11.350913 15070 solver.cpp:237] Iteration 427500, loss = 1.51254
I0526 14:06:11.350958 15070 solver.cpp:253]     Train net output #0: loss = 1.51254 (* 1 = 1.51254 loss)
I0526 14:06:11.350975 15070 sgd_solver.cpp:106] Iteration 427500, lr = 0.001
I0526 14:06:23.503429 15070 solver.cpp:237] Iteration 428250, loss = 1.02008
I0526 14:06:23.503465 15070 solver.cpp:253]     Train net output #0: loss = 1.02008 (* 1 = 1.02008 loss)
I0526 14:06:23.503480 15070 sgd_solver.cpp:106] Iteration 428250, lr = 0.001
I0526 14:06:35.652071 15070 solver.cpp:237] Iteration 429000, loss = 1.33747
I0526 14:06:35.652117 15070 solver.cpp:253]     Train net output #0: loss = 1.33747 (* 1 = 1.33747 loss)
I0526 14:06:35.652132 15070 sgd_solver.cpp:106] Iteration 429000, lr = 0.001
I0526 14:06:47.773403 15070 solver.cpp:237] Iteration 429750, loss = 1.08455
I0526 14:06:47.773564 15070 solver.cpp:253]     Train net output #0: loss = 1.08455 (* 1 = 1.08455 loss)
I0526 14:06:47.773578 15070 sgd_solver.cpp:106] Iteration 429750, lr = 0.001
I0526 14:07:20.752951 15070 solver.cpp:237] Iteration 430500, loss = 1.2326
I0526 14:07:20.753160 15070 solver.cpp:253]     Train net output #0: loss = 1.2326 (* 1 = 1.2326 loss)
I0526 14:07:20.753175 15070 sgd_solver.cpp:106] Iteration 430500, lr = 0.001
I0526 14:07:32.922091 15070 solver.cpp:237] Iteration 431250, loss = 1.10085
I0526 14:07:32.922135 15070 solver.cpp:253]     Train net output #0: loss = 1.10085 (* 1 = 1.10085 loss)
I0526 14:07:32.922152 15070 sgd_solver.cpp:106] Iteration 431250, lr = 0.001
I0526 14:07:45.079388 15070 solver.cpp:237] Iteration 432000, loss = 1.32578
I0526 14:07:45.079424 15070 solver.cpp:253]     Train net output #0: loss = 1.32578 (* 1 = 1.32578 loss)
I0526 14:07:45.079440 15070 sgd_solver.cpp:106] Iteration 432000, lr = 0.001
I0526 14:07:57.219838 15070 solver.cpp:237] Iteration 432750, loss = 1.19988
I0526 14:07:57.220026 15070 solver.cpp:253]     Train net output #0: loss = 1.19987 (* 1 = 1.19987 loss)
I0526 14:07:57.220042 15070 sgd_solver.cpp:106] Iteration 432750, lr = 0.001
I0526 14:08:09.402638 15070 solver.cpp:237] Iteration 433500, loss = 1.17423
I0526 14:08:09.402674 15070 solver.cpp:253]     Train net output #0: loss = 1.17423 (* 1 = 1.17423 loss)
I0526 14:08:09.402688 15070 sgd_solver.cpp:106] Iteration 433500, lr = 0.001
I0526 14:08:21.518697 15070 solver.cpp:237] Iteration 434250, loss = 1.2096
I0526 14:08:21.518748 15070 solver.cpp:253]     Train net output #0: loss = 1.2096 (* 1 = 1.2096 loss)
I0526 14:08:21.518764 15070 sgd_solver.cpp:106] Iteration 434250, lr = 0.001
I0526 14:08:33.608136 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_435000.caffemodel
I0526 14:08:33.660440 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_435000.solverstate
I0526 14:08:33.688355 15070 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 14:09:46.463973 15070 solver.cpp:409]     Test net output #0: accuracy = 0.89837
I0526 14:09:46.464146 15070 solver.cpp:409]     Test net output #1: loss = 0.321228 (* 1 = 0.321228 loss)
I0526 14:10:07.353040 15070 solver.cpp:237] Iteration 435000, loss = 1.31806
I0526 14:10:07.353093 15070 solver.cpp:253]     Train net output #0: loss = 1.31806 (* 1 = 1.31806 loss)
I0526 14:10:07.353108 15070 sgd_solver.cpp:106] Iteration 435000, lr = 0.001
I0526 14:10:19.501385 15070 solver.cpp:237] Iteration 435750, loss = 1.15481
I0526 14:10:19.501552 15070 solver.cpp:253]     Train net output #0: loss = 1.15481 (* 1 = 1.15481 loss)
I0526 14:10:19.501567 15070 sgd_solver.cpp:106] Iteration 435750, lr = 0.001
I0526 14:10:31.650559 15070 solver.cpp:237] Iteration 436500, loss = 1.19278
I0526 14:10:31.650595 15070 solver.cpp:253]     Train net output #0: loss = 1.19278 (* 1 = 1.19278 loss)
I0526 14:10:31.650611 15070 sgd_solver.cpp:106] Iteration 436500, lr = 0.001
I0526 14:10:43.800179 15070 solver.cpp:237] Iteration 437250, loss = 1.25761
I0526 14:10:43.800220 15070 solver.cpp:253]     Train net output #0: loss = 1.25761 (* 1 = 1.25761 loss)
I0526 14:10:43.800236 15070 sgd_solver.cpp:106] Iteration 437250, lr = 0.001
I0526 14:10:55.908236 15070 solver.cpp:237] Iteration 438000, loss = 0.835217
I0526 14:10:55.908390 15070 solver.cpp:253]     Train net output #0: loss = 0.835216 (* 1 = 0.835216 loss)
I0526 14:10:55.908403 15070 sgd_solver.cpp:106] Iteration 438000, lr = 0.001
I0526 14:11:08.019826 15070 solver.cpp:237] Iteration 438750, loss = 1.11896
I0526 14:11:08.019870 15070 solver.cpp:253]     Train net output #0: loss = 1.11895 (* 1 = 1.11895 loss)
I0526 14:11:08.019889 15070 sgd_solver.cpp:106] Iteration 438750, lr = 0.001
I0526 14:11:20.112412 15070 solver.cpp:237] Iteration 439500, loss = 1.29329
I0526 14:11:20.112448 15070 solver.cpp:253]     Train net output #0: loss = 1.29329 (* 1 = 1.29329 loss)
I0526 14:11:20.112464 15070 sgd_solver.cpp:106] Iteration 439500, lr = 0.001
I0526 14:11:53.077210 15070 solver.cpp:237] Iteration 440250, loss = 1.00582
I0526 14:11:53.077421 15070 solver.cpp:253]     Train net output #0: loss = 1.00582 (* 1 = 1.00582 loss)
I0526 14:11:53.077437 15070 sgd_solver.cpp:106] Iteration 440250, lr = 0.001
I0526 14:12:05.250005 15070 solver.cpp:237] Iteration 441000, loss = 1.05856
I0526 14:12:05.250048 15070 solver.cpp:253]     Train net output #0: loss = 1.05856 (* 1 = 1.05856 loss)
I0526 14:12:05.250061 15070 sgd_solver.cpp:106] Iteration 441000, lr = 0.001
I0526 14:12:17.378234 15070 solver.cpp:237] Iteration 441750, loss = 1.53441
I0526 14:12:17.378269 15070 solver.cpp:253]     Train net output #0: loss = 1.53441 (* 1 = 1.53441 loss)
I0526 14:12:17.378286 15070 sgd_solver.cpp:106] Iteration 441750, lr = 0.001
I0526 14:12:29.461272 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_442500.caffemodel
I0526 14:12:29.511374 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_442500.solverstate
I0526 14:12:29.541988 15070 solver.cpp:237] Iteration 442500, loss = 1.01773
I0526 14:12:29.542032 15070 solver.cpp:253]     Train net output #0: loss = 1.01773 (* 1 = 1.01773 loss)
I0526 14:12:29.542052 15070 sgd_solver.cpp:106] Iteration 442500, lr = 0.001
I0526 14:12:41.723592 15070 solver.cpp:237] Iteration 443250, loss = 1.00308
I0526 14:12:41.723628 15070 solver.cpp:253]     Train net output #0: loss = 1.00308 (* 1 = 1.00308 loss)
I0526 14:12:41.723641 15070 sgd_solver.cpp:106] Iteration 443250, lr = 0.001
I0526 14:12:53.900081 15070 solver.cpp:237] Iteration 444000, loss = 1.08009
I0526 14:12:53.900128 15070 solver.cpp:253]     Train net output #0: loss = 1.08009 (* 1 = 1.08009 loss)
I0526 14:12:53.900142 15070 sgd_solver.cpp:106] Iteration 444000, lr = 0.001
I0526 14:13:06.108448 15070 solver.cpp:237] Iteration 444750, loss = 1.37218
I0526 14:13:06.108608 15070 solver.cpp:253]     Train net output #0: loss = 1.37218 (* 1 = 1.37218 loss)
I0526 14:13:06.108621 15070 sgd_solver.cpp:106] Iteration 444750, lr = 0.001
I0526 14:13:39.118645 15070 solver.cpp:237] Iteration 445500, loss = 1.32457
I0526 14:13:39.118824 15070 solver.cpp:253]     Train net output #0: loss = 1.32457 (* 1 = 1.32457 loss)
I0526 14:13:39.118839 15070 sgd_solver.cpp:106] Iteration 445500, lr = 0.001
I0526 14:13:51.285930 15070 solver.cpp:237] Iteration 446250, loss = 0.84106
I0526 14:13:51.285966 15070 solver.cpp:253]     Train net output #0: loss = 0.84106 (* 1 = 0.84106 loss)
I0526 14:13:51.285984 15070 sgd_solver.cpp:106] Iteration 446250, lr = 0.001
I0526 14:14:03.477500 15070 solver.cpp:237] Iteration 447000, loss = 1.42369
I0526 14:14:03.477550 15070 solver.cpp:253]     Train net output #0: loss = 1.42369 (* 1 = 1.42369 loss)
I0526 14:14:03.477566 15070 sgd_solver.cpp:106] Iteration 447000, lr = 0.001
I0526 14:14:15.683099 15070 solver.cpp:237] Iteration 447750, loss = 0.751414
I0526 14:14:15.683259 15070 solver.cpp:253]     Train net output #0: loss = 0.751414 (* 1 = 0.751414 loss)
I0526 14:14:15.683272 15070 sgd_solver.cpp:106] Iteration 447750, lr = 0.001
I0526 14:14:27.884001 15070 solver.cpp:237] Iteration 448500, loss = 1.25314
I0526 14:14:27.884045 15070 solver.cpp:253]     Train net output #0: loss = 1.25314 (* 1 = 1.25314 loss)
I0526 14:14:27.884059 15070 sgd_solver.cpp:106] Iteration 448500, lr = 0.001
I0526 14:14:40.022686 15070 solver.cpp:237] Iteration 449250, loss = 1.03181
I0526 14:14:40.022727 15070 solver.cpp:253]     Train net output #0: loss = 1.0318 (* 1 = 1.0318 loss)
I0526 14:14:40.022742 15070 sgd_solver.cpp:106] Iteration 449250, lr = 0.001
I0526 14:14:52.144376 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_450000.caffemodel
I0526 14:14:52.194011 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_450000.solverstate
I0526 14:14:52.219805 15070 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 14:15:43.779093 15070 solver.cpp:409]     Test net output #0: accuracy = 0.901283
I0526 14:15:43.779269 15070 solver.cpp:409]     Test net output #1: loss = 0.313063 (* 1 = 0.313063 loss)
I0526 14:16:04.650570 15070 solver.cpp:237] Iteration 450000, loss = 1.1877
I0526 14:16:04.650624 15070 solver.cpp:253]     Train net output #0: loss = 1.1877 (* 1 = 1.1877 loss)
I0526 14:16:04.650640 15070 sgd_solver.cpp:106] Iteration 450000, lr = 0.001
I0526 14:16:16.842082 15070 solver.cpp:237] Iteration 450750, loss = 1.0934
I0526 14:16:16.842254 15070 solver.cpp:253]     Train net output #0: loss = 1.0934 (* 1 = 1.0934 loss)
I0526 14:16:16.842268 15070 sgd_solver.cpp:106] Iteration 450750, lr = 0.001
I0526 14:16:29.084314 15070 solver.cpp:237] Iteration 451500, loss = 0.655532
I0526 14:16:29.084352 15070 solver.cpp:253]     Train net output #0: loss = 0.655532 (* 1 = 0.655532 loss)
I0526 14:16:29.084368 15070 sgd_solver.cpp:106] Iteration 451500, lr = 0.001
I0526 14:16:41.298765 15070 solver.cpp:237] Iteration 452250, loss = 1.39302
I0526 14:16:41.298810 15070 solver.cpp:253]     Train net output #0: loss = 1.39302 (* 1 = 1.39302 loss)
I0526 14:16:41.298825 15070 sgd_solver.cpp:106] Iteration 452250, lr = 0.001
I0526 14:16:53.469614 15070 solver.cpp:237] Iteration 453000, loss = 0.933063
I0526 14:16:53.469769 15070 solver.cpp:253]     Train net output #0: loss = 0.933063 (* 1 = 0.933063 loss)
I0526 14:16:53.469784 15070 sgd_solver.cpp:106] Iteration 453000, lr = 0.001
I0526 14:17:05.663362 15070 solver.cpp:237] Iteration 453750, loss = 1.23455
I0526 14:17:05.663408 15070 solver.cpp:253]     Train net output #0: loss = 1.23455 (* 1 = 1.23455 loss)
I0526 14:17:05.663422 15070 sgd_solver.cpp:106] Iteration 453750, lr = 0.001
I0526 14:17:17.854979 15070 solver.cpp:237] Iteration 454500, loss = 1.30268
I0526 14:17:17.855015 15070 solver.cpp:253]     Train net output #0: loss = 1.30268 (* 1 = 1.30268 loss)
I0526 14:17:17.855031 15070 sgd_solver.cpp:106] Iteration 454500, lr = 0.001
I0526 14:17:50.970093 15070 solver.cpp:237] Iteration 455250, loss = 1.17336
I0526 14:17:50.970271 15070 solver.cpp:253]     Train net output #0: loss = 1.17336 (* 1 = 1.17336 loss)
I0526 14:17:50.970286 15070 sgd_solver.cpp:106] Iteration 455250, lr = 0.001
I0526 14:18:03.171607 15070 solver.cpp:237] Iteration 456000, loss = 0.808928
I0526 14:18:03.171644 15070 solver.cpp:253]     Train net output #0: loss = 0.808928 (* 1 = 0.808928 loss)
I0526 14:18:03.171660 15070 sgd_solver.cpp:106] Iteration 456000, lr = 0.001
I0526 14:18:15.364075 15070 solver.cpp:237] Iteration 456750, loss = 0.932774
I0526 14:18:15.364121 15070 solver.cpp:253]     Train net output #0: loss = 0.932773 (* 1 = 0.932773 loss)
I0526 14:18:15.364136 15070 sgd_solver.cpp:106] Iteration 456750, lr = 0.001
I0526 14:18:27.523815 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_457500.caffemodel
I0526 14:18:27.573071 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_457500.solverstate
I0526 14:18:27.604120 15070 solver.cpp:237] Iteration 457500, loss = 1.58191
I0526 14:18:27.604163 15070 solver.cpp:253]     Train net output #0: loss = 1.58191 (* 1 = 1.58191 loss)
I0526 14:18:27.604178 15070 sgd_solver.cpp:106] Iteration 457500, lr = 0.001
I0526 14:18:39.850478 15070 solver.cpp:237] Iteration 458250, loss = 1.03692
I0526 14:18:39.850528 15070 solver.cpp:253]     Train net output #0: loss = 1.03692 (* 1 = 1.03692 loss)
I0526 14:18:39.850541 15070 sgd_solver.cpp:106] Iteration 458250, lr = 0.001
I0526 14:18:52.063935 15070 solver.cpp:237] Iteration 459000, loss = 1.13305
I0526 14:18:52.063971 15070 solver.cpp:253]     Train net output #0: loss = 1.13305 (* 1 = 1.13305 loss)
I0526 14:18:52.063987 15070 sgd_solver.cpp:106] Iteration 459000, lr = 0.001
I0526 14:19:04.273753 15070 solver.cpp:237] Iteration 459750, loss = 1.11492
I0526 14:19:04.273944 15070 solver.cpp:253]     Train net output #0: loss = 1.11492 (* 1 = 1.11492 loss)
I0526 14:19:04.273960 15070 sgd_solver.cpp:106] Iteration 459750, lr = 0.001
I0526 14:19:37.320420 15070 solver.cpp:237] Iteration 460500, loss = 0.548021
I0526 14:19:37.320602 15070 solver.cpp:253]     Train net output #0: loss = 0.54802 (* 1 = 0.54802 loss)
I0526 14:19:37.320618 15070 sgd_solver.cpp:106] Iteration 460500, lr = 0.001
I0526 14:19:49.533409 15070 solver.cpp:237] Iteration 461250, loss = 1.43103
I0526 14:19:49.533445 15070 solver.cpp:253]     Train net output #0: loss = 1.43103 (* 1 = 1.43103 loss)
I0526 14:19:49.533458 15070 sgd_solver.cpp:106] Iteration 461250, lr = 0.001
I0526 14:20:01.741603 15070 solver.cpp:237] Iteration 462000, loss = 1.03402
I0526 14:20:01.741652 15070 solver.cpp:253]     Train net output #0: loss = 1.03402 (* 1 = 1.03402 loss)
I0526 14:20:01.741664 15070 sgd_solver.cpp:106] Iteration 462000, lr = 0.001
I0526 14:20:13.934926 15070 solver.cpp:237] Iteration 462750, loss = 0.950504
I0526 14:20:13.935087 15070 solver.cpp:253]     Train net output #0: loss = 0.950504 (* 1 = 0.950504 loss)
I0526 14:20:13.935101 15070 sgd_solver.cpp:106] Iteration 462750, lr = 0.001
I0526 14:20:26.093706 15070 solver.cpp:237] Iteration 463500, loss = 0.98798
I0526 14:20:26.093756 15070 solver.cpp:253]     Train net output #0: loss = 0.98798 (* 1 = 0.98798 loss)
I0526 14:20:26.093771 15070 sgd_solver.cpp:106] Iteration 463500, lr = 0.001
I0526 14:20:38.254472 15070 solver.cpp:237] Iteration 464250, loss = 0.888106
I0526 14:20:38.254508 15070 solver.cpp:253]     Train net output #0: loss = 0.888106 (* 1 = 0.888106 loss)
I0526 14:20:38.254524 15070 sgd_solver.cpp:106] Iteration 464250, lr = 0.001
I0526 14:20:50.394529 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_465000.caffemodel
I0526 14:20:50.443730 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_465000.solverstate
I0526 14:20:50.469193 15070 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 14:22:03.267928 15070 solver.cpp:409]     Test net output #0: accuracy = 0.898722
I0526 14:22:03.268105 15070 solver.cpp:409]     Test net output #1: loss = 0.314486 (* 1 = 0.314486 loss)
I0526 14:22:24.148064 15070 solver.cpp:237] Iteration 465000, loss = 1.14369
I0526 14:22:24.148118 15070 solver.cpp:253]     Train net output #0: loss = 1.14369 (* 1 = 1.14369 loss)
I0526 14:22:24.148133 15070 sgd_solver.cpp:106] Iteration 465000, lr = 0.001
I0526 14:22:36.305654 15070 solver.cpp:237] Iteration 465750, loss = 0.856955
I0526 14:22:36.305819 15070 solver.cpp:253]     Train net output #0: loss = 0.856955 (* 1 = 0.856955 loss)
I0526 14:22:36.305832 15070 sgd_solver.cpp:106] Iteration 465750, lr = 0.001
I0526 14:22:48.474212 15070 solver.cpp:237] Iteration 466500, loss = 1.04164
I0526 14:22:48.474256 15070 solver.cpp:253]     Train net output #0: loss = 1.04164 (* 1 = 1.04164 loss)
I0526 14:22:48.474272 15070 sgd_solver.cpp:106] Iteration 466500, lr = 0.001
I0526 14:23:00.673506 15070 solver.cpp:237] Iteration 467250, loss = 1.0926
I0526 14:23:00.673542 15070 solver.cpp:253]     Train net output #0: loss = 1.0926 (* 1 = 1.0926 loss)
I0526 14:23:00.673555 15070 sgd_solver.cpp:106] Iteration 467250, lr = 0.001
I0526 14:23:12.907011 15070 solver.cpp:237] Iteration 468000, loss = 0.946613
I0526 14:23:12.907186 15070 solver.cpp:253]     Train net output #0: loss = 0.946612 (* 1 = 0.946612 loss)
I0526 14:23:12.907202 15070 sgd_solver.cpp:106] Iteration 468000, lr = 0.001
I0526 14:23:25.122901 15070 solver.cpp:237] Iteration 468750, loss = 1.66331
I0526 14:23:25.122937 15070 solver.cpp:253]     Train net output #0: loss = 1.6633 (* 1 = 1.6633 loss)
I0526 14:23:25.122953 15070 sgd_solver.cpp:106] Iteration 468750, lr = 0.001
I0526 14:23:37.274480 15070 solver.cpp:237] Iteration 469500, loss = 2.00797
I0526 14:23:37.274524 15070 solver.cpp:253]     Train net output #0: loss = 2.00797 (* 1 = 2.00797 loss)
I0526 14:23:37.274543 15070 sgd_solver.cpp:106] Iteration 469500, lr = 0.001
I0526 14:24:10.289080 15070 solver.cpp:237] Iteration 470250, loss = 1.58015
I0526 14:24:10.289269 15070 solver.cpp:253]     Train net output #0: loss = 1.58015 (* 1 = 1.58015 loss)
I0526 14:24:10.289285 15070 sgd_solver.cpp:106] Iteration 470250, lr = 0.001
I0526 14:24:22.428475 15070 solver.cpp:237] Iteration 471000, loss = 1.51431
I0526 14:24:22.428510 15070 solver.cpp:253]     Train net output #0: loss = 1.51431 (* 1 = 1.51431 loss)
I0526 14:24:22.428529 15070 sgd_solver.cpp:106] Iteration 471000, lr = 0.001
I0526 14:24:34.619451 15070 solver.cpp:237] Iteration 471750, loss = 1.26941
I0526 14:24:34.619498 15070 solver.cpp:253]     Train net output #0: loss = 1.26941 (* 1 = 1.26941 loss)
I0526 14:24:34.619513 15070 sgd_solver.cpp:106] Iteration 471750, lr = 0.001
I0526 14:24:46.829900 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_472500.caffemodel
I0526 14:24:46.887112 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_472500.solverstate
I0526 14:24:46.927886 15070 solver.cpp:237] Iteration 472500, loss = 0.912903
I0526 14:24:46.927934 15070 solver.cpp:253]     Train net output #0: loss = 0.912903 (* 1 = 0.912903 loss)
I0526 14:24:46.927949 15070 sgd_solver.cpp:106] Iteration 472500, lr = 0.001
I0526 14:24:59.157644 15070 solver.cpp:237] Iteration 473250, loss = 1.222
I0526 14:24:59.157691 15070 solver.cpp:253]     Train net output #0: loss = 1.222 (* 1 = 1.222 loss)
I0526 14:24:59.157704 15070 sgd_solver.cpp:106] Iteration 473250, lr = 0.001
I0526 14:25:11.363795 15070 solver.cpp:237] Iteration 474000, loss = 0.930106
I0526 14:25:11.363831 15070 solver.cpp:253]     Train net output #0: loss = 0.930106 (* 1 = 0.930106 loss)
I0526 14:25:11.363847 15070 sgd_solver.cpp:106] Iteration 474000, lr = 0.001
I0526 14:25:23.525215 15070 solver.cpp:237] Iteration 474750, loss = 1.10527
I0526 14:25:23.525389 15070 solver.cpp:253]     Train net output #0: loss = 1.10527 (* 1 = 1.10527 loss)
I0526 14:25:23.525403 15070 sgd_solver.cpp:106] Iteration 474750, lr = 0.001
I0526 14:25:56.681545 15070 solver.cpp:237] Iteration 475500, loss = 0.796261
I0526 14:25:56.681726 15070 solver.cpp:253]     Train net output #0: loss = 0.796261 (* 1 = 0.796261 loss)
I0526 14:25:56.681742 15070 sgd_solver.cpp:106] Iteration 475500, lr = 0.001
I0526 14:26:08.877930 15070 solver.cpp:237] Iteration 476250, loss = 1.13205
I0526 14:26:08.877977 15070 solver.cpp:253]     Train net output #0: loss = 1.13205 (* 1 = 1.13205 loss)
I0526 14:26:08.877992 15070 sgd_solver.cpp:106] Iteration 476250, lr = 0.001
I0526 14:26:21.002224 15070 solver.cpp:237] Iteration 477000, loss = 1.52308
I0526 14:26:21.002259 15070 solver.cpp:253]     Train net output #0: loss = 1.52308 (* 1 = 1.52308 loss)
I0526 14:26:21.002276 15070 sgd_solver.cpp:106] Iteration 477000, lr = 0.001
I0526 14:26:33.161680 15070 solver.cpp:237] Iteration 477750, loss = 1.23389
I0526 14:26:33.161872 15070 solver.cpp:253]     Train net output #0: loss = 1.23389 (* 1 = 1.23389 loss)
I0526 14:26:33.161887 15070 sgd_solver.cpp:106] Iteration 477750, lr = 0.001
I0526 14:26:45.317241 15070 solver.cpp:237] Iteration 478500, loss = 0.787962
I0526 14:26:45.317277 15070 solver.cpp:253]     Train net output #0: loss = 0.787962 (* 1 = 0.787962 loss)
I0526 14:26:45.317293 15070 sgd_solver.cpp:106] Iteration 478500, lr = 0.001
I0526 14:26:57.463683 15070 solver.cpp:237] Iteration 479250, loss = 1.1271
I0526 14:26:57.463734 15070 solver.cpp:253]     Train net output #0: loss = 1.1271 (* 1 = 1.1271 loss)
I0526 14:26:57.463748 15070 sgd_solver.cpp:106] Iteration 479250, lr = 0.001
I0526 14:27:09.630512 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_480000.caffemodel
I0526 14:27:09.707521 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_480000.solverstate
I0526 14:27:09.741255 15070 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 14:28:01.707016 15070 solver.cpp:409]     Test net output #0: accuracy = 0.902206
I0526 14:28:01.707197 15070 solver.cpp:409]     Test net output #1: loss = 0.306047 (* 1 = 0.306047 loss)
I0526 14:28:22.602612 15070 solver.cpp:237] Iteration 480000, loss = 0.70022
I0526 14:28:22.602664 15070 solver.cpp:253]     Train net output #0: loss = 0.70022 (* 1 = 0.70022 loss)
I0526 14:28:22.602679 15070 sgd_solver.cpp:106] Iteration 480000, lr = 0.001
I0526 14:28:34.725240 15070 solver.cpp:237] Iteration 480750, loss = 1.3463
I0526 14:28:34.725409 15070 solver.cpp:253]     Train net output #0: loss = 1.3463 (* 1 = 1.3463 loss)
I0526 14:28:34.725425 15070 sgd_solver.cpp:106] Iteration 480750, lr = 0.001
I0526 14:28:46.833101 15070 solver.cpp:237] Iteration 481500, loss = 1.68034
I0526 14:28:46.833150 15070 solver.cpp:253]     Train net output #0: loss = 1.68034 (* 1 = 1.68034 loss)
I0526 14:28:46.833164 15070 sgd_solver.cpp:106] Iteration 481500, lr = 0.001
I0526 14:28:58.992259 15070 solver.cpp:237] Iteration 482250, loss = 0.859241
I0526 14:28:58.992296 15070 solver.cpp:253]     Train net output #0: loss = 0.859241 (* 1 = 0.859241 loss)
I0526 14:28:58.992312 15070 sgd_solver.cpp:106] Iteration 482250, lr = 0.001
I0526 14:29:11.145236 15070 solver.cpp:237] Iteration 483000, loss = 1.48154
I0526 14:29:11.145407 15070 solver.cpp:253]     Train net output #0: loss = 1.48154 (* 1 = 1.48154 loss)
I0526 14:29:11.145421 15070 sgd_solver.cpp:106] Iteration 483000, lr = 0.001
I0526 14:29:23.246747 15070 solver.cpp:237] Iteration 483750, loss = 1.24952
I0526 14:29:23.246781 15070 solver.cpp:253]     Train net output #0: loss = 1.24952 (* 1 = 1.24952 loss)
I0526 14:29:23.246795 15070 sgd_solver.cpp:106] Iteration 483750, lr = 0.001
I0526 14:29:35.356619 15070 solver.cpp:237] Iteration 484500, loss = 1.0341
I0526 14:29:35.356660 15070 solver.cpp:253]     Train net output #0: loss = 1.0341 (* 1 = 1.0341 loss)
I0526 14:29:35.356675 15070 sgd_solver.cpp:106] Iteration 484500, lr = 0.001
I0526 14:30:08.319985 15070 solver.cpp:237] Iteration 485250, loss = 1.04565
I0526 14:30:08.320164 15070 solver.cpp:253]     Train net output #0: loss = 1.04565 (* 1 = 1.04565 loss)
I0526 14:30:08.320178 15070 sgd_solver.cpp:106] Iteration 485250, lr = 0.001
I0526 14:30:20.437022 15070 solver.cpp:237] Iteration 486000, loss = 1.08807
I0526 14:30:20.437070 15070 solver.cpp:253]     Train net output #0: loss = 1.08807 (* 1 = 1.08807 loss)
I0526 14:30:20.437085 15070 sgd_solver.cpp:106] Iteration 486000, lr = 0.001
I0526 14:30:32.566627 15070 solver.cpp:237] Iteration 486750, loss = 1.26592
I0526 14:30:32.566663 15070 solver.cpp:253]     Train net output #0: loss = 1.26592 (* 1 = 1.26592 loss)
I0526 14:30:32.566679 15070 sgd_solver.cpp:106] Iteration 486750, lr = 0.001
I0526 14:30:44.682868 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_487500.caffemodel
I0526 14:30:44.745930 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_487500.solverstate
I0526 14:30:44.783556 15070 solver.cpp:237] Iteration 487500, loss = 1.29038
I0526 14:30:44.783602 15070 solver.cpp:253]     Train net output #0: loss = 1.29038 (* 1 = 1.29038 loss)
I0526 14:30:44.783620 15070 sgd_solver.cpp:106] Iteration 487500, lr = 0.001
I0526 14:30:56.904167 15070 solver.cpp:237] Iteration 488250, loss = 0.812976
I0526 14:30:56.904204 15070 solver.cpp:253]     Train net output #0: loss = 0.812976 (* 1 = 0.812976 loss)
I0526 14:30:56.904220 15070 sgd_solver.cpp:106] Iteration 488250, lr = 0.001
I0526 14:31:09.082115 15070 solver.cpp:237] Iteration 489000, loss = 0.976596
I0526 14:31:09.082162 15070 solver.cpp:253]     Train net output #0: loss = 0.976596 (* 1 = 0.976596 loss)
I0526 14:31:09.082180 15070 sgd_solver.cpp:106] Iteration 489000, lr = 0.001
I0526 14:31:21.255020 15070 solver.cpp:237] Iteration 489750, loss = 1.29097
I0526 14:31:21.255213 15070 solver.cpp:253]     Train net output #0: loss = 1.29098 (* 1 = 1.29098 loss)
I0526 14:31:21.255228 15070 sgd_solver.cpp:106] Iteration 489750, lr = 0.001
I0526 14:31:54.287653 15070 solver.cpp:237] Iteration 490500, loss = 1.08497
I0526 14:31:54.287838 15070 solver.cpp:253]     Train net output #0: loss = 1.08497 (* 1 = 1.08497 loss)
I0526 14:31:54.287853 15070 sgd_solver.cpp:106] Iteration 490500, lr = 0.001
I0526 14:32:06.466933 15070 solver.cpp:237] Iteration 491250, loss = 1.63786
I0526 14:32:06.466980 15070 solver.cpp:253]     Train net output #0: loss = 1.63786 (* 1 = 1.63786 loss)
I0526 14:32:06.466995 15070 sgd_solver.cpp:106] Iteration 491250, lr = 0.001
I0526 14:32:18.641327 15070 solver.cpp:237] Iteration 492000, loss = 1.1021
I0526 14:32:18.641363 15070 solver.cpp:253]     Train net output #0: loss = 1.1021 (* 1 = 1.1021 loss)
I0526 14:32:18.641381 15070 sgd_solver.cpp:106] Iteration 492000, lr = 0.001
I0526 14:32:30.766360 15070 solver.cpp:237] Iteration 492750, loss = 0.977479
I0526 14:32:30.766540 15070 solver.cpp:253]     Train net output #0: loss = 0.977479 (* 1 = 0.977479 loss)
I0526 14:32:30.766554 15070 sgd_solver.cpp:106] Iteration 492750, lr = 0.001
I0526 14:32:42.886929 15070 solver.cpp:237] Iteration 493500, loss = 1.04603
I0526 14:32:42.886965 15070 solver.cpp:253]     Train net output #0: loss = 1.04603 (* 1 = 1.04603 loss)
I0526 14:32:42.886981 15070 sgd_solver.cpp:106] Iteration 493500, lr = 0.001
I0526 14:32:55.012267 15070 solver.cpp:237] Iteration 494250, loss = 1.16616
I0526 14:32:55.012317 15070 solver.cpp:253]     Train net output #0: loss = 1.16616 (* 1 = 1.16616 loss)
I0526 14:32:55.012331 15070 sgd_solver.cpp:106] Iteration 494250, lr = 0.001
I0526 14:33:07.116968 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_495000.caffemodel
I0526 14:33:07.175037 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_495000.solverstate
I0526 14:33:07.207131 15070 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 14:34:19.999014 15070 solver.cpp:409]     Test net output #0: accuracy = 0.9021
I0526 14:34:19.999196 15070 solver.cpp:409]     Test net output #1: loss = 0.304301 (* 1 = 0.304301 loss)
I0526 14:34:40.873848 15070 solver.cpp:237] Iteration 495000, loss = 1.08965
I0526 14:34:40.873898 15070 solver.cpp:253]     Train net output #0: loss = 1.08965 (* 1 = 1.08965 loss)
I0526 14:34:40.873916 15070 sgd_solver.cpp:106] Iteration 495000, lr = 0.001
I0526 14:34:53.083503 15070 solver.cpp:237] Iteration 495750, loss = 1.00658
I0526 14:34:53.083681 15070 solver.cpp:253]     Train net output #0: loss = 1.00658 (* 1 = 1.00658 loss)
I0526 14:34:53.083695 15070 sgd_solver.cpp:106] Iteration 495750, lr = 0.001
I0526 14:35:05.289629 15070 solver.cpp:237] Iteration 496500, loss = 1.08678
I0526 14:35:05.289665 15070 solver.cpp:253]     Train net output #0: loss = 1.08678 (* 1 = 1.08678 loss)
I0526 14:35:05.289680 15070 sgd_solver.cpp:106] Iteration 496500, lr = 0.001
I0526 14:35:17.508615 15070 solver.cpp:237] Iteration 497250, loss = 0.988662
I0526 14:35:17.508664 15070 solver.cpp:253]     Train net output #0: loss = 0.988662 (* 1 = 0.988662 loss)
I0526 14:35:17.508677 15070 sgd_solver.cpp:106] Iteration 497250, lr = 0.001
I0526 14:35:29.707599 15070 solver.cpp:237] Iteration 498000, loss = 1.24714
I0526 14:35:29.707774 15070 solver.cpp:253]     Train net output #0: loss = 1.24714 (* 1 = 1.24714 loss)
I0526 14:35:29.707790 15070 sgd_solver.cpp:106] Iteration 498000, lr = 0.001
I0526 14:35:41.888104 15070 solver.cpp:237] Iteration 498750, loss = 1.25192
I0526 14:35:41.888149 15070 solver.cpp:253]     Train net output #0: loss = 1.25192 (* 1 = 1.25192 loss)
I0526 14:35:41.888166 15070 sgd_solver.cpp:106] Iteration 498750, lr = 0.001
I0526 14:35:54.062496 15070 solver.cpp:237] Iteration 499500, loss = 0.825699
I0526 14:35:54.062532 15070 solver.cpp:253]     Train net output #0: loss = 0.8257 (* 1 = 0.8257 loss)
I0526 14:35:54.062546 15070 sgd_solver.cpp:106] Iteration 499500, lr = 0.001
I0526 14:36:27.147130 15070 solver.cpp:237] Iteration 500250, loss = 0.910719
I0526 14:36:27.147318 15070 solver.cpp:253]     Train net output #0: loss = 0.91072 (* 1 = 0.91072 loss)
I0526 14:36:27.147333 15070 sgd_solver.cpp:106] Iteration 500250, lr = 0.001
I0526 14:36:39.354192 15070 solver.cpp:237] Iteration 501000, loss = 1.10676
I0526 14:36:39.354238 15070 solver.cpp:253]     Train net output #0: loss = 1.10676 (* 1 = 1.10676 loss)
I0526 14:36:39.354250 15070 sgd_solver.cpp:106] Iteration 501000, lr = 0.001
I0526 14:36:51.542402 15070 solver.cpp:237] Iteration 501750, loss = 0.897894
I0526 14:36:51.542438 15070 solver.cpp:253]     Train net output #0: loss = 0.897894 (* 1 = 0.897894 loss)
I0526 14:36:51.542450 15070 sgd_solver.cpp:106] Iteration 501750, lr = 0.001
I0526 14:37:03.726227 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_502500.caffemodel
I0526 14:37:03.784296 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_502500.solverstate
I0526 14:37:03.827610 15070 solver.cpp:237] Iteration 502500, loss = 1.80669
I0526 14:37:03.827657 15070 solver.cpp:253]     Train net output #0: loss = 1.80669 (* 1 = 1.80669 loss)
I0526 14:37:03.827674 15070 sgd_solver.cpp:106] Iteration 502500, lr = 0.001
I0526 14:37:16.091152 15070 solver.cpp:237] Iteration 503250, loss = 0.917554
I0526 14:37:16.091188 15070 solver.cpp:253]     Train net output #0: loss = 0.917555 (* 1 = 0.917555 loss)
I0526 14:37:16.091205 15070 sgd_solver.cpp:106] Iteration 503250, lr = 0.001
I0526 14:37:28.318151 15070 solver.cpp:237] Iteration 504000, loss = 1.75857
I0526 14:37:28.318198 15070 solver.cpp:253]     Train net output #0: loss = 1.75857 (* 1 = 1.75857 loss)
I0526 14:37:28.318214 15070 sgd_solver.cpp:106] Iteration 504000, lr = 0.001
I0526 14:37:40.536238 15070 solver.cpp:237] Iteration 504750, loss = 0.974942
I0526 14:37:40.536407 15070 solver.cpp:253]     Train net output #0: loss = 0.974943 (* 1 = 0.974943 loss)
I0526 14:37:40.536422 15070 sgd_solver.cpp:106] Iteration 504750, lr = 0.001
I0526 14:38:13.629647 15070 solver.cpp:237] Iteration 505500, loss = 0.818297
I0526 14:38:13.629830 15070 solver.cpp:253]     Train net output #0: loss = 0.818298 (* 1 = 0.818298 loss)
I0526 14:38:13.629845 15070 sgd_solver.cpp:106] Iteration 505500, lr = 0.001
I0526 14:38:25.852695 15070 solver.cpp:237] Iteration 506250, loss = 0.924959
I0526 14:38:25.852731 15070 solver.cpp:253]     Train net output #0: loss = 0.92496 (* 1 = 0.92496 loss)
I0526 14:38:25.852746 15070 sgd_solver.cpp:106] Iteration 506250, lr = 0.001
I0526 14:38:38.077455 15070 solver.cpp:237] Iteration 507000, loss = 0.983434
I0526 14:38:38.077502 15070 solver.cpp:253]     Train net output #0: loss = 0.983435 (* 1 = 0.983435 loss)
I0526 14:38:38.077515 15070 sgd_solver.cpp:106] Iteration 507000, lr = 0.001
I0526 14:38:50.246549 15070 solver.cpp:237] Iteration 507750, loss = 1.00608
I0526 14:38:50.246733 15070 solver.cpp:253]     Train net output #0: loss = 1.00608 (* 1 = 1.00608 loss)
I0526 14:38:50.246747 15070 sgd_solver.cpp:106] Iteration 507750, lr = 0.001
I0526 14:39:02.445942 15070 solver.cpp:237] Iteration 508500, loss = 1.15434
I0526 14:39:02.445988 15070 solver.cpp:253]     Train net output #0: loss = 1.15434 (* 1 = 1.15434 loss)
I0526 14:39:02.446005 15070 sgd_solver.cpp:106] Iteration 508500, lr = 0.001
I0526 14:39:14.634402 15070 solver.cpp:237] Iteration 509250, loss = 1.37978
I0526 14:39:14.634438 15070 solver.cpp:253]     Train net output #0: loss = 1.37978 (* 1 = 1.37978 loss)
I0526 14:39:14.634450 15070 sgd_solver.cpp:106] Iteration 509250, lr = 0.001
I0526 14:39:26.782311 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_510000.caffemodel
I0526 14:39:26.843457 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_510000.solverstate
I0526 14:39:26.884573 15070 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 14:40:18.537282 15070 solver.cpp:409]     Test net output #0: accuracy = 0.899971
I0526 14:40:18.537467 15070 solver.cpp:409]     Test net output #1: loss = 0.32589 (* 1 = 0.32589 loss)
I0526 14:40:39.469806 15070 solver.cpp:237] Iteration 510000, loss = 1.34882
I0526 14:40:39.469858 15070 solver.cpp:253]     Train net output #0: loss = 1.34882 (* 1 = 1.34882 loss)
I0526 14:40:39.469874 15070 sgd_solver.cpp:106] Iteration 510000, lr = 0.001
I0526 14:40:51.688297 15070 solver.cpp:237] Iteration 510750, loss = 0.884117
I0526 14:40:51.688475 15070 solver.cpp:253]     Train net output #0: loss = 0.884118 (* 1 = 0.884118 loss)
I0526 14:40:51.688489 15070 sgd_solver.cpp:106] Iteration 510750, lr = 0.001
I0526 14:41:03.903987 15070 solver.cpp:237] Iteration 511500, loss = 1.23762
I0526 14:41:03.904023 15070 solver.cpp:253]     Train net output #0: loss = 1.23762 (* 1 = 1.23762 loss)
I0526 14:41:03.904039 15070 sgd_solver.cpp:106] Iteration 511500, lr = 0.001
I0526 14:41:16.108002 15070 solver.cpp:237] Iteration 512250, loss = 1.37894
I0526 14:41:16.108047 15070 solver.cpp:253]     Train net output #0: loss = 1.37894 (* 1 = 1.37894 loss)
I0526 14:41:16.108062 15070 sgd_solver.cpp:106] Iteration 512250, lr = 0.001
I0526 14:41:28.296702 15070 solver.cpp:237] Iteration 513000, loss = 1.19171
I0526 14:41:28.296866 15070 solver.cpp:253]     Train net output #0: loss = 1.19171 (* 1 = 1.19171 loss)
I0526 14:41:28.296880 15070 sgd_solver.cpp:106] Iteration 513000, lr = 0.001
I0526 14:41:40.404325 15070 solver.cpp:237] Iteration 513750, loss = 1.22377
I0526 14:41:40.404372 15070 solver.cpp:253]     Train net output #0: loss = 1.22377 (* 1 = 1.22377 loss)
I0526 14:41:40.404388 15070 sgd_solver.cpp:106] Iteration 513750, lr = 0.001
I0526 14:41:52.511461 15070 solver.cpp:237] Iteration 514500, loss = 1.66777
I0526 14:41:52.511495 15070 solver.cpp:253]     Train net output #0: loss = 1.66777 (* 1 = 1.66777 loss)
I0526 14:41:52.511512 15070 sgd_solver.cpp:106] Iteration 514500, lr = 0.001
I0526 14:42:25.477861 15070 solver.cpp:237] Iteration 515250, loss = 1.30591
I0526 14:42:25.478047 15070 solver.cpp:253]     Train net output #0: loss = 1.30591 (* 1 = 1.30591 loss)
I0526 14:42:25.478063 15070 sgd_solver.cpp:106] Iteration 515250, lr = 0.001
I0526 14:42:37.604743 15070 solver.cpp:237] Iteration 516000, loss = 0.800996
I0526 14:42:37.604779 15070 solver.cpp:253]     Train net output #0: loss = 0.800997 (* 1 = 0.800997 loss)
I0526 14:42:37.604795 15070 sgd_solver.cpp:106] Iteration 516000, lr = 0.001
I0526 14:42:49.777948 15070 solver.cpp:237] Iteration 516750, loss = 1.56297
I0526 14:42:49.777997 15070 solver.cpp:253]     Train net output #0: loss = 1.56297 (* 1 = 1.56297 loss)
I0526 14:42:49.778010 15070 sgd_solver.cpp:106] Iteration 516750, lr = 0.001
I0526 14:43:01.935605 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_517500.caffemodel
I0526 14:43:01.998414 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_517500.solverstate
I0526 14:43:02.035143 15070 solver.cpp:237] Iteration 517500, loss = 1.04919
I0526 14:43:02.035188 15070 solver.cpp:253]     Train net output #0: loss = 1.04919 (* 1 = 1.04919 loss)
I0526 14:43:02.035207 15070 sgd_solver.cpp:106] Iteration 517500, lr = 0.001
I0526 14:43:14.230499 15070 solver.cpp:237] Iteration 518250, loss = 1.29206
I0526 14:43:14.230545 15070 solver.cpp:253]     Train net output #0: loss = 1.29206 (* 1 = 1.29206 loss)
I0526 14:43:14.230561 15070 sgd_solver.cpp:106] Iteration 518250, lr = 0.001
I0526 14:43:26.403234 15070 solver.cpp:237] Iteration 519000, loss = 0.742522
I0526 14:43:26.403270 15070 solver.cpp:253]     Train net output #0: loss = 0.742522 (* 1 = 0.742522 loss)
I0526 14:43:26.403283 15070 sgd_solver.cpp:106] Iteration 519000, lr = 0.001
I0526 14:43:38.589339 15070 solver.cpp:237] Iteration 519750, loss = 1.42819
I0526 14:43:38.589534 15070 solver.cpp:253]     Train net output #0: loss = 1.42819 (* 1 = 1.42819 loss)
I0526 14:43:38.589550 15070 sgd_solver.cpp:106] Iteration 519750, lr = 0.001
I0526 14:44:11.667016 15070 solver.cpp:237] Iteration 520500, loss = 0.841214
I0526 14:44:11.667217 15070 solver.cpp:253]     Train net output #0: loss = 0.841214 (* 1 = 0.841214 loss)
I0526 14:44:11.667232 15070 sgd_solver.cpp:106] Iteration 520500, lr = 0.001
I0526 14:44:23.853377 15070 solver.cpp:237] Iteration 521250, loss = 0.695676
I0526 14:44:23.853415 15070 solver.cpp:253]     Train net output #0: loss = 0.695676 (* 1 = 0.695676 loss)
I0526 14:44:23.853430 15070 sgd_solver.cpp:106] Iteration 521250, lr = 0.001
I0526 14:44:36.023010 15070 solver.cpp:237] Iteration 522000, loss = 0.958927
I0526 14:44:36.023057 15070 solver.cpp:253]     Train net output #0: loss = 0.958927 (* 1 = 0.958927 loss)
I0526 14:44:36.023072 15070 sgd_solver.cpp:106] Iteration 522000, lr = 0.001
I0526 14:44:48.187700 15070 solver.cpp:237] Iteration 522750, loss = 1.04973
I0526 14:44:48.187868 15070 solver.cpp:253]     Train net output #0: loss = 1.04973 (* 1 = 1.04973 loss)
I0526 14:44:48.187882 15070 sgd_solver.cpp:106] Iteration 522750, lr = 0.001
I0526 14:45:00.351338 15070 solver.cpp:237] Iteration 523500, loss = 1.4865
I0526 14:45:00.351384 15070 solver.cpp:253]     Train net output #0: loss = 1.4865 (* 1 = 1.4865 loss)
I0526 14:45:00.351402 15070 sgd_solver.cpp:106] Iteration 523500, lr = 0.001
I0526 14:45:12.525815 15070 solver.cpp:237] Iteration 524250, loss = 1.28693
I0526 14:45:12.525851 15070 solver.cpp:253]     Train net output #0: loss = 1.28693 (* 1 = 1.28693 loss)
I0526 14:45:12.525867 15070 sgd_solver.cpp:106] Iteration 524250, lr = 0.001
I0526 14:45:24.676126 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_525000.caffemodel
I0526 14:45:24.734791 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_525000.solverstate
I0526 14:45:24.771872 15070 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 14:46:37.673008 15070 solver.cpp:409]     Test net output #0: accuracy = 0.903465
I0526 14:46:37.673207 15070 solver.cpp:409]     Test net output #1: loss = 0.296591 (* 1 = 0.296591 loss)
I0526 14:46:58.556591 15070 solver.cpp:237] Iteration 525000, loss = 0.925996
I0526 14:46:58.556643 15070 solver.cpp:253]     Train net output #0: loss = 0.925996 (* 1 = 0.925996 loss)
I0526 14:46:58.556659 15070 sgd_solver.cpp:106] Iteration 525000, lr = 0.001
I0526 14:47:10.604979 15070 solver.cpp:237] Iteration 525750, loss = 1.30435
I0526 14:47:10.605150 15070 solver.cpp:253]     Train net output #0: loss = 1.30435 (* 1 = 1.30435 loss)
I0526 14:47:10.605165 15070 sgd_solver.cpp:106] Iteration 525750, lr = 0.001
I0526 14:47:22.669301 15070 solver.cpp:237] Iteration 526500, loss = 1.00755
I0526 14:47:22.669342 15070 solver.cpp:253]     Train net output #0: loss = 1.00755 (* 1 = 1.00755 loss)
I0526 14:47:22.669361 15070 sgd_solver.cpp:106] Iteration 526500, lr = 0.001
I0526 14:47:34.741802 15070 solver.cpp:237] Iteration 527250, loss = 1.58212
I0526 14:47:34.741838 15070 solver.cpp:253]     Train net output #0: loss = 1.58212 (* 1 = 1.58212 loss)
I0526 14:47:34.741852 15070 sgd_solver.cpp:106] Iteration 527250, lr = 0.001
I0526 14:47:46.810564 15070 solver.cpp:237] Iteration 528000, loss = 1.41778
I0526 14:47:46.810751 15070 solver.cpp:253]     Train net output #0: loss = 1.41778 (* 1 = 1.41778 loss)
I0526 14:47:46.810765 15070 sgd_solver.cpp:106] Iteration 528000, lr = 0.001
I0526 14:47:58.872995 15070 solver.cpp:237] Iteration 528750, loss = 1.32721
I0526 14:47:58.873030 15070 solver.cpp:253]     Train net output #0: loss = 1.32721 (* 1 = 1.32721 loss)
I0526 14:47:58.873044 15070 sgd_solver.cpp:106] Iteration 528750, lr = 0.001
I0526 14:48:10.942567 15070 solver.cpp:237] Iteration 529500, loss = 1.23363
I0526 14:48:10.942601 15070 solver.cpp:253]     Train net output #0: loss = 1.23363 (* 1 = 1.23363 loss)
I0526 14:48:10.942620 15070 sgd_solver.cpp:106] Iteration 529500, lr = 0.001
I0526 14:48:43.987104 15070 solver.cpp:237] Iteration 530250, loss = 0.750922
I0526 14:48:43.987296 15070 solver.cpp:253]     Train net output #0: loss = 0.750921 (* 1 = 0.750921 loss)
I0526 14:48:43.987313 15070 sgd_solver.cpp:106] Iteration 530250, lr = 0.001
I0526 14:48:56.110534 15070 solver.cpp:237] Iteration 531000, loss = 1.08518
I0526 14:48:56.110570 15070 solver.cpp:253]     Train net output #0: loss = 1.08518 (* 1 = 1.08518 loss)
I0526 14:48:56.110586 15070 sgd_solver.cpp:106] Iteration 531000, lr = 0.001
I0526 14:49:08.270380 15070 solver.cpp:237] Iteration 531750, loss = 1.35484
I0526 14:49:08.270429 15070 solver.cpp:253]     Train net output #0: loss = 1.35484 (* 1 = 1.35484 loss)
I0526 14:49:08.270444 15070 sgd_solver.cpp:106] Iteration 531750, lr = 0.001
I0526 14:49:20.395289 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_532500.caffemodel
I0526 14:49:20.453018 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_532500.solverstate
I0526 14:49:20.493531 15070 solver.cpp:237] Iteration 532500, loss = 1.14004
I0526 14:49:20.493577 15070 solver.cpp:253]     Train net output #0: loss = 1.14004 (* 1 = 1.14004 loss)
I0526 14:49:20.493594 15070 sgd_solver.cpp:106] Iteration 532500, lr = 0.001
I0526 14:49:32.638124 15070 solver.cpp:237] Iteration 533250, loss = 0.831405
I0526 14:49:32.638171 15070 solver.cpp:253]     Train net output #0: loss = 0.831405 (* 1 = 0.831405 loss)
I0526 14:49:32.638185 15070 sgd_solver.cpp:106] Iteration 533250, lr = 0.001
I0526 14:49:44.776732 15070 solver.cpp:237] Iteration 534000, loss = 1.18766
I0526 14:49:44.776767 15070 solver.cpp:253]     Train net output #0: loss = 1.18766 (* 1 = 1.18766 loss)
I0526 14:49:44.776780 15070 sgd_solver.cpp:106] Iteration 534000, lr = 0.001
I0526 14:49:56.916254 15070 solver.cpp:237] Iteration 534750, loss = 0.945209
I0526 14:49:56.916440 15070 solver.cpp:253]     Train net output #0: loss = 0.945209 (* 1 = 0.945209 loss)
I0526 14:49:56.916455 15070 sgd_solver.cpp:106] Iteration 534750, lr = 0.001
I0526 14:50:29.938242 15070 solver.cpp:237] Iteration 535500, loss = 1.01558
I0526 14:50:29.938431 15070 solver.cpp:253]     Train net output #0: loss = 1.01558 (* 1 = 1.01558 loss)
I0526 14:50:29.938446 15070 sgd_solver.cpp:106] Iteration 535500, lr = 0.001
I0526 14:50:42.088856 15070 solver.cpp:237] Iteration 536250, loss = 1.33538
I0526 14:50:42.088901 15070 solver.cpp:253]     Train net output #0: loss = 1.33538 (* 1 = 1.33538 loss)
I0526 14:50:42.088915 15070 sgd_solver.cpp:106] Iteration 536250, lr = 0.001
I0526 14:50:54.253918 15070 solver.cpp:237] Iteration 537000, loss = 1.29795
I0526 14:50:54.253953 15070 solver.cpp:253]     Train net output #0: loss = 1.29795 (* 1 = 1.29795 loss)
I0526 14:50:54.253968 15070 sgd_solver.cpp:106] Iteration 537000, lr = 0.001
I0526 14:51:06.487414 15070 solver.cpp:237] Iteration 537750, loss = 1.10198
I0526 14:51:06.487586 15070 solver.cpp:253]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0526 14:51:06.487601 15070 sgd_solver.cpp:106] Iteration 537750, lr = 0.001
I0526 14:51:18.587211 15070 solver.cpp:237] Iteration 538500, loss = 1.15887
I0526 14:51:18.587246 15070 solver.cpp:253]     Train net output #0: loss = 1.15887 (* 1 = 1.15887 loss)
I0526 14:51:18.587261 15070 sgd_solver.cpp:106] Iteration 538500, lr = 0.001
I0526 14:51:30.678786 15070 solver.cpp:237] Iteration 539250, loss = 0.962878
I0526 14:51:30.678822 15070 solver.cpp:253]     Train net output #0: loss = 0.962878 (* 1 = 0.962878 loss)
I0526 14:51:30.678836 15070 sgd_solver.cpp:106] Iteration 539250, lr = 0.001
I0526 14:51:42.758980 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_540000.caffemodel
I0526 14:51:42.817073 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_540000.solverstate
I0526 14:51:42.850985 15070 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 14:52:34.844385 15070 solver.cpp:409]     Test net output #0: accuracy = 0.904393
I0526 14:52:34.844573 15070 solver.cpp:409]     Test net output #1: loss = 0.316701 (* 1 = 0.316701 loss)
I0526 14:52:55.723387 15070 solver.cpp:237] Iteration 540000, loss = 0.848059
I0526 14:52:55.723439 15070 solver.cpp:253]     Train net output #0: loss = 0.848059 (* 1 = 0.848059 loss)
I0526 14:52:55.723455 15070 sgd_solver.cpp:106] Iteration 540000, lr = 0.001
I0526 14:53:07.980298 15070 solver.cpp:237] Iteration 540750, loss = 1.00539
I0526 14:53:07.980471 15070 solver.cpp:253]     Train net output #0: loss = 1.00539 (* 1 = 1.00539 loss)
I0526 14:53:07.980485 15070 sgd_solver.cpp:106] Iteration 540750, lr = 0.001
I0526 14:53:20.237058 15070 solver.cpp:237] Iteration 541500, loss = 0.766525
I0526 14:53:20.237105 15070 solver.cpp:253]     Train net output #0: loss = 0.766526 (* 1 = 0.766526 loss)
I0526 14:53:20.237120 15070 sgd_solver.cpp:106] Iteration 541500, lr = 0.001
I0526 14:53:32.502338 15070 solver.cpp:237] Iteration 542250, loss = 1.77508
I0526 14:53:32.502374 15070 solver.cpp:253]     Train net output #0: loss = 1.77508 (* 1 = 1.77508 loss)
I0526 14:53:32.502388 15070 sgd_solver.cpp:106] Iteration 542250, lr = 0.001
I0526 14:53:44.751538 15070 solver.cpp:237] Iteration 543000, loss = 0.79116
I0526 14:53:44.751718 15070 solver.cpp:253]     Train net output #0: loss = 0.79116 (* 1 = 0.79116 loss)
I0526 14:53:44.751732 15070 sgd_solver.cpp:106] Iteration 543000, lr = 0.001
I0526 14:53:56.988011 15070 solver.cpp:237] Iteration 543750, loss = 0.803631
I0526 14:53:56.988049 15070 solver.cpp:253]     Train net output #0: loss = 0.803632 (* 1 = 0.803632 loss)
I0526 14:53:56.988065 15070 sgd_solver.cpp:106] Iteration 543750, lr = 0.001
I0526 14:54:09.198439 15070 solver.cpp:237] Iteration 544500, loss = 1.41537
I0526 14:54:09.198489 15070 solver.cpp:253]     Train net output #0: loss = 1.41537 (* 1 = 1.41537 loss)
I0526 14:54:09.198504 15070 sgd_solver.cpp:106] Iteration 544500, lr = 0.001
I0526 14:54:42.349694 15070 solver.cpp:237] Iteration 545250, loss = 1.53186
I0526 14:54:42.349884 15070 solver.cpp:253]     Train net output #0: loss = 1.53187 (* 1 = 1.53187 loss)
I0526 14:54:42.349898 15070 sgd_solver.cpp:106] Iteration 545250, lr = 0.001
I0526 14:54:54.536450 15070 solver.cpp:237] Iteration 546000, loss = 0.969516
I0526 14:54:54.536499 15070 solver.cpp:253]     Train net output #0: loss = 0.969516 (* 1 = 0.969516 loss)
I0526 14:54:54.536514 15070 sgd_solver.cpp:106] Iteration 546000, lr = 0.001
I0526 14:55:06.715045 15070 solver.cpp:237] Iteration 546750, loss = 0.853454
I0526 14:55:06.715081 15070 solver.cpp:253]     Train net output #0: loss = 0.853455 (* 1 = 0.853455 loss)
I0526 14:55:06.715097 15070 sgd_solver.cpp:106] Iteration 546750, lr = 0.001
I0526 14:55:18.906273 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_547500.caffemodel
I0526 14:55:18.964174 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_547500.solverstate
I0526 14:55:19.009181 15070 solver.cpp:237] Iteration 547500, loss = 1.39063
I0526 14:55:19.009228 15070 solver.cpp:253]     Train net output #0: loss = 1.39063 (* 1 = 1.39063 loss)
I0526 14:55:19.009244 15070 sgd_solver.cpp:106] Iteration 547500, lr = 0.001
I0526 14:55:31.188171 15070 solver.cpp:237] Iteration 548250, loss = 1.09199
I0526 14:55:31.188207 15070 solver.cpp:253]     Train net output #0: loss = 1.092 (* 1 = 1.092 loss)
I0526 14:55:31.188223 15070 sgd_solver.cpp:106] Iteration 548250, lr = 0.001
I0526 14:55:43.383518 15070 solver.cpp:237] Iteration 549000, loss = 0.684078
I0526 14:55:43.383568 15070 solver.cpp:253]     Train net output #0: loss = 0.684079 (* 1 = 0.684079 loss)
I0526 14:55:43.383582 15070 sgd_solver.cpp:106] Iteration 549000, lr = 0.001
I0526 14:55:55.598852 15070 solver.cpp:237] Iteration 549750, loss = 1.20943
I0526 14:55:55.599023 15070 solver.cpp:253]     Train net output #0: loss = 1.20943 (* 1 = 1.20943 loss)
I0526 14:55:55.599037 15070 sgd_solver.cpp:106] Iteration 549750, lr = 0.001
I0526 14:56:28.680019 15070 solver.cpp:237] Iteration 550500, loss = 1.54528
I0526 14:56:28.680208 15070 solver.cpp:253]     Train net output #0: loss = 1.54529 (* 1 = 1.54529 loss)
I0526 14:56:28.680225 15070 sgd_solver.cpp:106] Iteration 550500, lr = 0.001
I0526 14:56:40.826576 15070 solver.cpp:237] Iteration 551250, loss = 0.954703
I0526 14:56:40.826627 15070 solver.cpp:253]     Train net output #0: loss = 0.954704 (* 1 = 0.954704 loss)
I0526 14:56:40.826640 15070 sgd_solver.cpp:106] Iteration 551250, lr = 0.001
I0526 14:56:53.019350 15070 solver.cpp:237] Iteration 552000, loss = 1.53104
I0526 14:56:53.019385 15070 solver.cpp:253]     Train net output #0: loss = 1.53104 (* 1 = 1.53104 loss)
I0526 14:56:53.019399 15070 sgd_solver.cpp:106] Iteration 552000, lr = 0.001
I0526 14:57:05.234372 15070 solver.cpp:237] Iteration 552750, loss = 1.3153
I0526 14:57:05.234561 15070 solver.cpp:253]     Train net output #0: loss = 1.3153 (* 1 = 1.3153 loss)
I0526 14:57:05.234576 15070 sgd_solver.cpp:106] Iteration 552750, lr = 0.001
I0526 14:57:17.449357 15070 solver.cpp:237] Iteration 553500, loss = 0.978996
I0526 14:57:17.449394 15070 solver.cpp:253]     Train net output #0: loss = 0.978997 (* 1 = 0.978997 loss)
I0526 14:57:17.449409 15070 sgd_solver.cpp:106] Iteration 553500, lr = 0.001
I0526 14:57:29.557940 15070 solver.cpp:237] Iteration 554250, loss = 0.829615
I0526 14:57:29.557991 15070 solver.cpp:253]     Train net output #0: loss = 0.829615 (* 1 = 0.829615 loss)
I0526 14:57:29.558006 15070 sgd_solver.cpp:106] Iteration 554250, lr = 0.001
I0526 14:57:41.593857 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_555000.caffemodel
I0526 14:57:41.665921 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_555000.solverstate
I0526 14:57:41.704704 15070 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 14:58:54.703563 15070 solver.cpp:409]     Test net output #0: accuracy = 0.903932
I0526 14:58:54.703765 15070 solver.cpp:409]     Test net output #1: loss = 0.307684 (* 1 = 0.307684 loss)
I0526 14:59:15.562325 15070 solver.cpp:237] Iteration 555000, loss = 1.27155
I0526 14:59:15.562376 15070 solver.cpp:253]     Train net output #0: loss = 1.27156 (* 1 = 1.27156 loss)
I0526 14:59:15.562391 15070 sgd_solver.cpp:106] Iteration 555000, lr = 0.001
I0526 14:59:27.665601 15070 solver.cpp:237] Iteration 555750, loss = 0.912315
I0526 14:59:27.665807 15070 solver.cpp:253]     Train net output #0: loss = 0.912315 (* 1 = 0.912315 loss)
I0526 14:59:27.665822 15070 sgd_solver.cpp:106] Iteration 555750, lr = 0.001
I0526 14:59:39.808909 15070 solver.cpp:237] Iteration 556500, loss = 1.32747
I0526 14:59:39.808945 15070 solver.cpp:253]     Train net output #0: loss = 1.32747 (* 1 = 1.32747 loss)
I0526 14:59:39.808959 15070 sgd_solver.cpp:106] Iteration 556500, lr = 0.001
I0526 14:59:51.975445 15070 solver.cpp:237] Iteration 557250, loss = 1.4529
I0526 14:59:51.975488 15070 solver.cpp:253]     Train net output #0: loss = 1.4529 (* 1 = 1.4529 loss)
I0526 14:59:51.975505 15070 sgd_solver.cpp:106] Iteration 557250, lr = 0.001
I0526 15:00:04.114825 15070 solver.cpp:237] Iteration 558000, loss = 1.18077
I0526 15:00:04.115011 15070 solver.cpp:253]     Train net output #0: loss = 1.18077 (* 1 = 1.18077 loss)
I0526 15:00:04.115027 15070 sgd_solver.cpp:106] Iteration 558000, lr = 0.001
I0526 15:00:16.262200 15070 solver.cpp:237] Iteration 558750, loss = 1.18096
I0526 15:00:16.262243 15070 solver.cpp:253]     Train net output #0: loss = 1.18096 (* 1 = 1.18096 loss)
I0526 15:00:16.262259 15070 sgd_solver.cpp:106] Iteration 558750, lr = 0.001
I0526 15:00:28.317214 15070 solver.cpp:237] Iteration 559500, loss = 1.20134
I0526 15:00:28.317250 15070 solver.cpp:253]     Train net output #0: loss = 1.20134 (* 1 = 1.20134 loss)
I0526 15:00:28.317265 15070 sgd_solver.cpp:106] Iteration 559500, lr = 0.001
I0526 15:01:01.328120 15070 solver.cpp:237] Iteration 560250, loss = 0.989743
I0526 15:01:01.328315 15070 solver.cpp:253]     Train net output #0: loss = 0.989744 (* 1 = 0.989744 loss)
I0526 15:01:01.328331 15070 sgd_solver.cpp:106] Iteration 560250, lr = 0.001
I0526 15:01:13.453673 15070 solver.cpp:237] Iteration 561000, loss = 0.704455
I0526 15:01:13.453721 15070 solver.cpp:253]     Train net output #0: loss = 0.704456 (* 1 = 0.704456 loss)
I0526 15:01:13.453734 15070 sgd_solver.cpp:106] Iteration 561000, lr = 0.001
I0526 15:01:25.584712 15070 solver.cpp:237] Iteration 561750, loss = 1.21408
I0526 15:01:25.584748 15070 solver.cpp:253]     Train net output #0: loss = 1.21408 (* 1 = 1.21408 loss)
I0526 15:01:25.584761 15070 sgd_solver.cpp:106] Iteration 561750, lr = 0.001
I0526 15:01:37.678165 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_562500.caffemodel
I0526 15:01:37.736754 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_562500.solverstate
I0526 15:01:37.777302 15070 solver.cpp:237] Iteration 562500, loss = 1.55
I0526 15:01:37.777349 15070 solver.cpp:253]     Train net output #0: loss = 1.55 (* 1 = 1.55 loss)
I0526 15:01:37.777364 15070 sgd_solver.cpp:106] Iteration 562500, lr = 0.001
I0526 15:01:49.888767 15070 solver.cpp:237] Iteration 563250, loss = 0.666136
I0526 15:01:49.888803 15070 solver.cpp:253]     Train net output #0: loss = 0.666136 (* 1 = 0.666136 loss)
I0526 15:01:49.888818 15070 sgd_solver.cpp:106] Iteration 563250, lr = 0.001
I0526 15:02:01.982758 15070 solver.cpp:237] Iteration 564000, loss = 0.766568
I0526 15:02:01.982806 15070 solver.cpp:253]     Train net output #0: loss = 0.766569 (* 1 = 0.766569 loss)
I0526 15:02:01.982820 15070 sgd_solver.cpp:106] Iteration 564000, lr = 0.001
I0526 15:02:14.080431 15070 solver.cpp:237] Iteration 564750, loss = 1.40693
I0526 15:02:14.080608 15070 solver.cpp:253]     Train net output #0: loss = 1.40693 (* 1 = 1.40693 loss)
I0526 15:02:14.080622 15070 sgd_solver.cpp:106] Iteration 564750, lr = 0.001
I0526 15:02:47.081960 15070 solver.cpp:237] Iteration 565500, loss = 1.17001
I0526 15:02:47.082161 15070 solver.cpp:253]     Train net output #0: loss = 1.17001 (* 1 = 1.17001 loss)
I0526 15:02:47.082176 15070 sgd_solver.cpp:106] Iteration 565500, lr = 0.001
I0526 15:02:59.217039 15070 solver.cpp:237] Iteration 566250, loss = 1.17625
I0526 15:02:59.217075 15070 solver.cpp:253]     Train net output #0: loss = 1.17625 (* 1 = 1.17625 loss)
I0526 15:02:59.217090 15070 sgd_solver.cpp:106] Iteration 566250, lr = 0.001
I0526 15:03:11.330463 15070 solver.cpp:237] Iteration 567000, loss = 1.12975
I0526 15:03:11.330509 15070 solver.cpp:253]     Train net output #0: loss = 1.12975 (* 1 = 1.12975 loss)
I0526 15:03:11.330524 15070 sgd_solver.cpp:106] Iteration 567000, lr = 0.001
I0526 15:03:23.447556 15070 solver.cpp:237] Iteration 567750, loss = 0.873471
I0526 15:03:23.447731 15070 solver.cpp:253]     Train net output #0: loss = 0.873471 (* 1 = 0.873471 loss)
I0526 15:03:23.447744 15070 sgd_solver.cpp:106] Iteration 567750, lr = 0.001
I0526 15:03:35.553874 15070 solver.cpp:237] Iteration 568500, loss = 1.03703
I0526 15:03:35.553910 15070 solver.cpp:253]     Train net output #0: loss = 1.03703 (* 1 = 1.03703 loss)
I0526 15:03:35.553923 15070 sgd_solver.cpp:106] Iteration 568500, lr = 0.001
I0526 15:03:47.702220 15070 solver.cpp:237] Iteration 569250, loss = 1.10331
I0526 15:03:47.702261 15070 solver.cpp:253]     Train net output #0: loss = 1.10331 (* 1 = 1.10331 loss)
I0526 15:03:47.702276 15070 sgd_solver.cpp:106] Iteration 569250, lr = 0.001
I0526 15:03:59.832278 15070 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_570000.caffemodel
I0526 15:03:59.891224 15070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0010_2016-05-20T15.48.53.588768_iter_570000.solverstate
I0526 15:03:59.925957 15070 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 15:04:51.623317 15070 solver.cpp:409]     Test net output #0: accuracy = 0.903592
I0526 15:04:51.623499 15070 solver.cpp:409]     Test net output #1: loss = 0.301864 (* 1 = 0.301864 loss)
I0526 15:05:12.467684 15070 solver.cpp:237] Iteration 570000, loss = 0.960802
I0526 15:05:12.467736 15070 solver.cpp:253]     Train net output #0: loss = 0.960802 (* 1 = 0.960802 loss)
I0526 15:05:12.467751 15070 sgd_solver.cpp:106] Iteration 570000, lr = 0.001
I0526 15:05:24.676298 15070 solver.cpp:237] Iteration 570750, loss = 1.43212
I0526 15:05:24.676486 15070 solver.cpp:253]     Train net output #0: loss = 1.43212 (* 1 = 1.43212 loss)
I0526 15:05:24.676501 15070 sgd_solver.cpp:106] Iteration 570750, lr = 0.001
I0526 15:05:36.910480 15070 solver.cpp:237] Iteration 571500, loss = 0.884152
I0526 15:05:36.910516 15070 solver.cpp:253]     Train net output #0: loss = 0.884152 (* 1 = 0.884152 loss)
I0526 15:05:36.910531 15070 sgd_solver.cpp:106] Iteration 571500, lr = 0.001
I0526 15:05:49.126821 15070 solver.cpp:237] Iteration 572250, loss = 1.0864
I0526 15:05:49.126864 15070 solver.cpp:253]     Train net output #0: loss = 1.0864 (* 1 = 1.0864 loss)
I0526 15:05:49.126878 15070 sgd_solver.cpp:106] Iteration 572250, lr = 0.001
I0526 15:06:01.377274 15070 solver.cpp:237] Iteration 573000, loss = 1.00521
I0526 15:06:01.377444 15070 solver.cpp:253]     Train net output #0: loss = 1.00521 (* 1 = 1.00521 loss)
I0526 15:06:01.377457 15070 sgd_solver.cpp:106] Iteration 573000, lr = 0.001
I0526 15:06:13.586118 15070 solver.cpp:237] Iteration 573750, loss = 0.728443
I0526 15:06:13.586169 15070 solver.cpp:253]     Train net output #0: loss = 0.728443 (* 1 = 0.728443 loss)
I0526 15:06:13.586184 15070 sgd_solver.cpp:106] Iteration 573750, lr = 0.001
I0526 15:06:25.775311 15070 solver.cpp:237] Iteration 574500, loss = 0.993545
I0526 15:06:25.775348 15070 solver.cpp:253]     Train net output #0: loss = 0.993545 (* 1 = 0.993545 loss)
I0526 15:06:25.775362 15070 sgd_solver.cpp:106] Iteration 574500, lr = 0.001
=>> PBS: job killed: walltime 7229 exceeded limit 7200
aprun: Apid 11268847: Caught signal Terminated, sending to application
*** Aborted at 1464289600 (unix time) try "date -d @1464289600" if you are using GNU date ***
PC: @     0x2aaac5e9bb44 (unknown)
*** SIGTERM (@0x3adb) received by PID 15070 (TID 0x2aaac746f900) from PID 15067; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaac5e9bb44 (unknown)
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11268847: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
aprun: Apid 11268847: Caught signal Terminated, sending to application
