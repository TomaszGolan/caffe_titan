2817205
I0530 13:42:51.379348 25855 caffe.cpp:184] Using GPUs 0
I0530 13:42:51.806924 25855 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 5000
base_lr: 0.0025
display: 5000
max_iter: 150000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0001
stepsize: 5000
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_inv_2016-05-30T07.39.00.897234.prototxt"
I0530 13:42:51.808909 25855 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_inv_2016-05-30T07.39.00.897234.prototxt
I0530 13:42:51.812767 25855 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0530 13:42:51.812850 25855 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0530 13:42:51.813596 25855 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0530 13:42:51.813953 25855 layer_factory.hpp:77] Creating layer data
I0530 13:42:51.813977 25855 net.cpp:106] Creating Layer data
I0530 13:42:51.813992 25855 net.cpp:411] data -> hits-x
I0530 13:42:51.814024 25855 net.cpp:411] data -> hits-u
I0530 13:42:51.814046 25855 net.cpp:411] data -> hits-v
I0530 13:42:51.814062 25855 net.cpp:411] data -> segments
I0530 13:42:51.814088 25855 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist
I0530 13:42:51.815716 25855 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0530 13:42:51.818784 25855 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0530 13:43:55.751397 25855 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0530 13:43:55.757127 25855 net.cpp:150] Setting up data
I0530 13:43:55.757167 25855 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 13:43:55.757182 25855 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 13:43:55.757197 25855 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 13:43:55.757208 25855 net.cpp:157] Top shape: 100 (100)
I0530 13:43:55.757218 25855 net.cpp:165] Memory required for data: 7620400
I0530 13:43:55.757232 25855 layer_factory.hpp:77] Creating layer conv_x1
I0530 13:43:55.757264 25855 net.cpp:106] Creating Layer conv_x1
I0530 13:43:55.757275 25855 net.cpp:454] conv_x1 <- hits-x
I0530 13:43:55.757298 25855 net.cpp:411] conv_x1 -> conv_x1
I0530 13:43:56.115386 25855 net.cpp:150] Setting up conv_x1
I0530 13:43:56.115432 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:43:56.115442 25855 net.cpp:165] Memory required for data: 35268400
I0530 13:43:56.115473 25855 layer_factory.hpp:77] Creating layer relu_x1
I0530 13:43:56.115494 25855 net.cpp:106] Creating Layer relu_x1
I0530 13:43:56.115505 25855 net.cpp:454] relu_x1 <- conv_x1
I0530 13:43:56.115520 25855 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0530 13:43:56.116039 25855 net.cpp:150] Setting up relu_x1
I0530 13:43:56.116055 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:43:56.116066 25855 net.cpp:165] Memory required for data: 62916400
I0530 13:43:56.116077 25855 layer_factory.hpp:77] Creating layer pool_x1
I0530 13:43:56.116094 25855 net.cpp:106] Creating Layer pool_x1
I0530 13:43:56.116104 25855 net.cpp:454] pool_x1 <- conv_x1
I0530 13:43:56.116118 25855 net.cpp:411] pool_x1 -> pool_x1
I0530 13:43:56.116200 25855 net.cpp:150] Setting up pool_x1
I0530 13:43:56.116214 25855 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 13:43:56.116224 25855 net.cpp:165] Memory required for data: 76740400
I0530 13:43:56.116235 25855 layer_factory.hpp:77] Creating layer conv_x2
I0530 13:43:56.116256 25855 net.cpp:106] Creating Layer conv_x2
I0530 13:43:56.116268 25855 net.cpp:454] conv_x2 <- pool_x1
I0530 13:43:56.116282 25855 net.cpp:411] conv_x2 -> conv_x2
I0530 13:43:56.118952 25855 net.cpp:150] Setting up conv_x2
I0530 13:43:56.118978 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:43:56.118991 25855 net.cpp:165] Memory required for data: 96612400
I0530 13:43:56.119011 25855 layer_factory.hpp:77] Creating layer relu_x2
I0530 13:43:56.119026 25855 net.cpp:106] Creating Layer relu_x2
I0530 13:43:56.119036 25855 net.cpp:454] relu_x2 <- conv_x2
I0530 13:43:56.119050 25855 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0530 13:43:56.119390 25855 net.cpp:150] Setting up relu_x2
I0530 13:43:56.119403 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:43:56.119413 25855 net.cpp:165] Memory required for data: 116484400
I0530 13:43:56.119423 25855 layer_factory.hpp:77] Creating layer pool_x2
I0530 13:43:56.119436 25855 net.cpp:106] Creating Layer pool_x2
I0530 13:43:56.119446 25855 net.cpp:454] pool_x2 <- conv_x2
I0530 13:43:56.119459 25855 net.cpp:411] pool_x2 -> pool_x2
I0530 13:43:56.119529 25855 net.cpp:150] Setting up pool_x2
I0530 13:43:56.119544 25855 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 13:43:56.119552 25855 net.cpp:165] Memory required for data: 126420400
I0530 13:43:56.119562 25855 layer_factory.hpp:77] Creating layer conv_x3
I0530 13:43:56.119580 25855 net.cpp:106] Creating Layer conv_x3
I0530 13:43:56.119590 25855 net.cpp:454] conv_x3 <- pool_x2
I0530 13:43:56.119603 25855 net.cpp:411] conv_x3 -> conv_x3
I0530 13:43:56.121513 25855 net.cpp:150] Setting up conv_x3
I0530 13:43:56.121537 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:43:56.121548 25855 net.cpp:165] Memory required for data: 137262000
I0530 13:43:56.121567 25855 layer_factory.hpp:77] Creating layer relu_x3
I0530 13:43:56.121583 25855 net.cpp:106] Creating Layer relu_x3
I0530 13:43:56.121593 25855 net.cpp:454] relu_x3 <- conv_x3
I0530 13:43:56.121606 25855 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0530 13:43:56.122073 25855 net.cpp:150] Setting up relu_x3
I0530 13:43:56.122089 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:43:56.122112 25855 net.cpp:165] Memory required for data: 148103600
I0530 13:43:56.122123 25855 layer_factory.hpp:77] Creating layer pool_x3
I0530 13:43:56.122136 25855 net.cpp:106] Creating Layer pool_x3
I0530 13:43:56.122146 25855 net.cpp:454] pool_x3 <- conv_x3
I0530 13:43:56.122159 25855 net.cpp:411] pool_x3 -> pool_x3
I0530 13:43:56.122228 25855 net.cpp:150] Setting up pool_x3
I0530 13:43:56.122242 25855 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 13:43:56.122252 25855 net.cpp:165] Memory required for data: 153524400
I0530 13:43:56.122262 25855 layer_factory.hpp:77] Creating layer conv_x4
I0530 13:43:56.122279 25855 net.cpp:106] Creating Layer conv_x4
I0530 13:43:56.122289 25855 net.cpp:454] conv_x4 <- pool_x3
I0530 13:43:56.122303 25855 net.cpp:411] conv_x4 -> conv_x4
I0530 13:43:56.125253 25855 net.cpp:150] Setting up conv_x4
I0530 13:43:56.125277 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:43:56.125288 25855 net.cpp:165] Memory required for data: 157153200
I0530 13:43:56.125303 25855 layer_factory.hpp:77] Creating layer relu_x4
I0530 13:43:56.125318 25855 net.cpp:106] Creating Layer relu_x4
I0530 13:43:56.125329 25855 net.cpp:454] relu_x4 <- conv_x4
I0530 13:43:56.125341 25855 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0530 13:43:56.125808 25855 net.cpp:150] Setting up relu_x4
I0530 13:43:56.125824 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:43:56.125834 25855 net.cpp:165] Memory required for data: 160782000
I0530 13:43:56.125845 25855 layer_factory.hpp:77] Creating layer pool_x4
I0530 13:43:56.125859 25855 net.cpp:106] Creating Layer pool_x4
I0530 13:43:56.125869 25855 net.cpp:454] pool_x4 <- conv_x4
I0530 13:43:56.125881 25855 net.cpp:411] pool_x4 -> pool_x4
I0530 13:43:56.125952 25855 net.cpp:150] Setting up pool_x4
I0530 13:43:56.125964 25855 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 13:43:56.125974 25855 net.cpp:165] Memory required for data: 162596400
I0530 13:43:56.125984 25855 layer_factory.hpp:77] Creating layer dl_x1
I0530 13:43:56.126005 25855 net.cpp:106] Creating Layer dl_x1
I0530 13:43:56.126015 25855 net.cpp:454] dl_x1 <- pool_x4
I0530 13:43:56.126030 25855 net.cpp:411] dl_x1 -> dl_x1
I0530 13:43:56.141459 25855 net.cpp:150] Setting up dl_x1
I0530 13:43:56.141489 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.141499 25855 net.cpp:165] Memory required for data: 162674800
I0530 13:43:56.141521 25855 layer_factory.hpp:77] Creating layer relu_x5
I0530 13:43:56.141536 25855 net.cpp:106] Creating Layer relu_x5
I0530 13:43:56.141547 25855 net.cpp:454] relu_x5 <- dl_x1
I0530 13:43:56.141561 25855 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0530 13:43:56.141903 25855 net.cpp:150] Setting up relu_x5
I0530 13:43:56.141917 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.141927 25855 net.cpp:165] Memory required for data: 162753200
I0530 13:43:56.141937 25855 layer_factory.hpp:77] Creating layer drop_x1
I0530 13:43:56.141958 25855 net.cpp:106] Creating Layer drop_x1
I0530 13:43:56.141968 25855 net.cpp:454] drop_x1 <- dl_x1
I0530 13:43:56.141981 25855 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0530 13:43:56.142027 25855 net.cpp:150] Setting up drop_x1
I0530 13:43:56.142040 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.142050 25855 net.cpp:165] Memory required for data: 162831600
I0530 13:43:56.142060 25855 layer_factory.hpp:77] Creating layer conv_u1
I0530 13:43:56.142082 25855 net.cpp:106] Creating Layer conv_u1
I0530 13:43:56.142092 25855 net.cpp:454] conv_u1 <- hits-u
I0530 13:43:56.142107 25855 net.cpp:411] conv_u1 -> conv_u1
I0530 13:43:56.143936 25855 net.cpp:150] Setting up conv_u1
I0530 13:43:56.143959 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:43:56.143971 25855 net.cpp:165] Memory required for data: 190479600
I0530 13:43:56.143986 25855 layer_factory.hpp:77] Creating layer relu_u1
I0530 13:43:56.144001 25855 net.cpp:106] Creating Layer relu_u1
I0530 13:43:56.144011 25855 net.cpp:454] relu_u1 <- conv_u1
I0530 13:43:56.144022 25855 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0530 13:43:56.144506 25855 net.cpp:150] Setting up relu_u1
I0530 13:43:56.144525 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:43:56.144534 25855 net.cpp:165] Memory required for data: 218127600
I0530 13:43:56.144546 25855 layer_factory.hpp:77] Creating layer pool_u1
I0530 13:43:56.144558 25855 net.cpp:106] Creating Layer pool_u1
I0530 13:43:56.144568 25855 net.cpp:454] pool_u1 <- conv_u1
I0530 13:43:56.144582 25855 net.cpp:411] pool_u1 -> pool_u1
I0530 13:43:56.144654 25855 net.cpp:150] Setting up pool_u1
I0530 13:43:56.144666 25855 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 13:43:56.144676 25855 net.cpp:165] Memory required for data: 231951600
I0530 13:43:56.144686 25855 layer_factory.hpp:77] Creating layer conv_u2
I0530 13:43:56.144702 25855 net.cpp:106] Creating Layer conv_u2
I0530 13:43:56.144713 25855 net.cpp:454] conv_u2 <- pool_u1
I0530 13:43:56.144727 25855 net.cpp:411] conv_u2 -> conv_u2
I0530 13:43:56.146546 25855 net.cpp:150] Setting up conv_u2
I0530 13:43:56.146569 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:43:56.146581 25855 net.cpp:165] Memory required for data: 251823600
I0530 13:43:56.146596 25855 layer_factory.hpp:77] Creating layer relu_u2
I0530 13:43:56.146610 25855 net.cpp:106] Creating Layer relu_u2
I0530 13:43:56.146620 25855 net.cpp:454] relu_u2 <- conv_u2
I0530 13:43:56.146631 25855 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0530 13:43:56.146952 25855 net.cpp:150] Setting up relu_u2
I0530 13:43:56.146966 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:43:56.146976 25855 net.cpp:165] Memory required for data: 271695600
I0530 13:43:56.146986 25855 layer_factory.hpp:77] Creating layer pool_u2
I0530 13:43:56.146999 25855 net.cpp:106] Creating Layer pool_u2
I0530 13:43:56.147009 25855 net.cpp:454] pool_u2 <- conv_u2
I0530 13:43:56.147022 25855 net.cpp:411] pool_u2 -> pool_u2
I0530 13:43:56.147095 25855 net.cpp:150] Setting up pool_u2
I0530 13:43:56.147109 25855 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 13:43:56.147126 25855 net.cpp:165] Memory required for data: 281631600
I0530 13:43:56.147136 25855 layer_factory.hpp:77] Creating layer conv_u3
I0530 13:43:56.147151 25855 net.cpp:106] Creating Layer conv_u3
I0530 13:43:56.147162 25855 net.cpp:454] conv_u3 <- pool_u2
I0530 13:43:56.147176 25855 net.cpp:411] conv_u3 -> conv_u3
I0530 13:43:56.149085 25855 net.cpp:150] Setting up conv_u3
I0530 13:43:56.149102 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:43:56.149114 25855 net.cpp:165] Memory required for data: 292473200
I0530 13:43:56.149129 25855 layer_factory.hpp:77] Creating layer relu_u3
I0530 13:43:56.149142 25855 net.cpp:106] Creating Layer relu_u3
I0530 13:43:56.149152 25855 net.cpp:454] relu_u3 <- conv_u3
I0530 13:43:56.149165 25855 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0530 13:43:56.149497 25855 net.cpp:150] Setting up relu_u3
I0530 13:43:56.149509 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:43:56.149520 25855 net.cpp:165] Memory required for data: 303314800
I0530 13:43:56.149530 25855 layer_factory.hpp:77] Creating layer pool_u3
I0530 13:43:56.149544 25855 net.cpp:106] Creating Layer pool_u3
I0530 13:43:56.149552 25855 net.cpp:454] pool_u3 <- conv_u3
I0530 13:43:56.149565 25855 net.cpp:411] pool_u3 -> pool_u3
I0530 13:43:56.149633 25855 net.cpp:150] Setting up pool_u3
I0530 13:43:56.149646 25855 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 13:43:56.149657 25855 net.cpp:165] Memory required for data: 308735600
I0530 13:43:56.149667 25855 layer_factory.hpp:77] Creating layer conv_u4
I0530 13:43:56.149683 25855 net.cpp:106] Creating Layer conv_u4
I0530 13:43:56.149694 25855 net.cpp:454] conv_u4 <- pool_u3
I0530 13:43:56.149708 25855 net.cpp:411] conv_u4 -> conv_u4
I0530 13:43:56.151911 25855 net.cpp:150] Setting up conv_u4
I0530 13:43:56.151933 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:43:56.151947 25855 net.cpp:165] Memory required for data: 312364400
I0530 13:43:56.151969 25855 layer_factory.hpp:77] Creating layer relu_u4
I0530 13:43:56.151983 25855 net.cpp:106] Creating Layer relu_u4
I0530 13:43:56.152004 25855 net.cpp:454] relu_u4 <- conv_u4
I0530 13:43:56.152019 25855 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0530 13:43:56.152492 25855 net.cpp:150] Setting up relu_u4
I0530 13:43:56.152508 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:43:56.152518 25855 net.cpp:165] Memory required for data: 315993200
I0530 13:43:56.152529 25855 layer_factory.hpp:77] Creating layer pool_u4
I0530 13:43:56.152541 25855 net.cpp:106] Creating Layer pool_u4
I0530 13:43:56.152551 25855 net.cpp:454] pool_u4 <- conv_u4
I0530 13:43:56.152565 25855 net.cpp:411] pool_u4 -> pool_u4
I0530 13:43:56.152634 25855 net.cpp:150] Setting up pool_u4
I0530 13:43:56.152648 25855 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 13:43:56.152659 25855 net.cpp:165] Memory required for data: 317807600
I0530 13:43:56.152669 25855 layer_factory.hpp:77] Creating layer dl_u1
I0530 13:43:56.152683 25855 net.cpp:106] Creating Layer dl_u1
I0530 13:43:56.152693 25855 net.cpp:454] dl_u1 <- pool_u4
I0530 13:43:56.152707 25855 net.cpp:411] dl_u1 -> dl_u1
I0530 13:43:56.168123 25855 net.cpp:150] Setting up dl_u1
I0530 13:43:56.168149 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.168162 25855 net.cpp:165] Memory required for data: 317886000
I0530 13:43:56.168179 25855 layer_factory.hpp:77] Creating layer relu_u5
I0530 13:43:56.168193 25855 net.cpp:106] Creating Layer relu_u5
I0530 13:43:56.168203 25855 net.cpp:454] relu_u5 <- dl_u1
I0530 13:43:56.168217 25855 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0530 13:43:56.168560 25855 net.cpp:150] Setting up relu_u5
I0530 13:43:56.168573 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.168583 25855 net.cpp:165] Memory required for data: 317964400
I0530 13:43:56.168593 25855 layer_factory.hpp:77] Creating layer drop_u1
I0530 13:43:56.168606 25855 net.cpp:106] Creating Layer drop_u1
I0530 13:43:56.168615 25855 net.cpp:454] drop_u1 <- dl_u1
I0530 13:43:56.168628 25855 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0530 13:43:56.168671 25855 net.cpp:150] Setting up drop_u1
I0530 13:43:56.168684 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.168694 25855 net.cpp:165] Memory required for data: 318042800
I0530 13:43:56.168705 25855 layer_factory.hpp:77] Creating layer conv_v1
I0530 13:43:56.168722 25855 net.cpp:106] Creating Layer conv_v1
I0530 13:43:56.168732 25855 net.cpp:454] conv_v1 <- hits-v
I0530 13:43:56.168746 25855 net.cpp:411] conv_v1 -> conv_v1
I0530 13:43:56.170596 25855 net.cpp:150] Setting up conv_v1
I0530 13:43:56.170619 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:43:56.170631 25855 net.cpp:165] Memory required for data: 345690800
I0530 13:43:56.170646 25855 layer_factory.hpp:77] Creating layer relu_v1
I0530 13:43:56.170670 25855 net.cpp:106] Creating Layer relu_v1
I0530 13:43:56.170680 25855 net.cpp:454] relu_v1 <- conv_v1
I0530 13:43:56.170692 25855 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0530 13:43:56.171169 25855 net.cpp:150] Setting up relu_v1
I0530 13:43:56.171187 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:43:56.171197 25855 net.cpp:165] Memory required for data: 373338800
I0530 13:43:56.171207 25855 layer_factory.hpp:77] Creating layer pool_v1
I0530 13:43:56.171221 25855 net.cpp:106] Creating Layer pool_v1
I0530 13:43:56.171231 25855 net.cpp:454] pool_v1 <- conv_v1
I0530 13:43:56.171246 25855 net.cpp:411] pool_v1 -> pool_v1
I0530 13:43:56.171317 25855 net.cpp:150] Setting up pool_v1
I0530 13:43:56.171331 25855 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 13:43:56.171341 25855 net.cpp:165] Memory required for data: 387162800
I0530 13:43:56.171350 25855 layer_factory.hpp:77] Creating layer conv_v2
I0530 13:43:56.171366 25855 net.cpp:106] Creating Layer conv_v2
I0530 13:43:56.171377 25855 net.cpp:454] conv_v2 <- pool_v1
I0530 13:43:56.171391 25855 net.cpp:411] conv_v2 -> conv_v2
I0530 13:43:56.173084 25855 net.cpp:150] Setting up conv_v2
I0530 13:43:56.173100 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:43:56.173111 25855 net.cpp:165] Memory required for data: 407034800
I0530 13:43:56.173141 25855 layer_factory.hpp:77] Creating layer relu_v2
I0530 13:43:56.173153 25855 net.cpp:106] Creating Layer relu_v2
I0530 13:43:56.173164 25855 net.cpp:454] relu_v2 <- conv_v2
I0530 13:43:56.173177 25855 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0530 13:43:56.173652 25855 net.cpp:150] Setting up relu_v2
I0530 13:43:56.173669 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:43:56.173679 25855 net.cpp:165] Memory required for data: 426906800
I0530 13:43:56.173689 25855 layer_factory.hpp:77] Creating layer pool_v2
I0530 13:43:56.173702 25855 net.cpp:106] Creating Layer pool_v2
I0530 13:43:56.173712 25855 net.cpp:454] pool_v2 <- conv_v2
I0530 13:43:56.173725 25855 net.cpp:411] pool_v2 -> pool_v2
I0530 13:43:56.173797 25855 net.cpp:150] Setting up pool_v2
I0530 13:43:56.173810 25855 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 13:43:56.173820 25855 net.cpp:165] Memory required for data: 436842800
I0530 13:43:56.173830 25855 layer_factory.hpp:77] Creating layer conv_v3
I0530 13:43:56.173847 25855 net.cpp:106] Creating Layer conv_v3
I0530 13:43:56.173857 25855 net.cpp:454] conv_v3 <- pool_v2
I0530 13:43:56.173871 25855 net.cpp:411] conv_v3 -> conv_v3
I0530 13:43:56.175809 25855 net.cpp:150] Setting up conv_v3
I0530 13:43:56.175832 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:43:56.175848 25855 net.cpp:165] Memory required for data: 447684400
I0530 13:43:56.175864 25855 layer_factory.hpp:77] Creating layer relu_v3
I0530 13:43:56.175878 25855 net.cpp:106] Creating Layer relu_v3
I0530 13:43:56.175889 25855 net.cpp:454] relu_v3 <- conv_v3
I0530 13:43:56.175900 25855 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0530 13:43:56.176219 25855 net.cpp:150] Setting up relu_v3
I0530 13:43:56.176234 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:43:56.176244 25855 net.cpp:165] Memory required for data: 458526000
I0530 13:43:56.176254 25855 layer_factory.hpp:77] Creating layer pool_v3
I0530 13:43:56.176266 25855 net.cpp:106] Creating Layer pool_v3
I0530 13:43:56.176276 25855 net.cpp:454] pool_v3 <- conv_v3
I0530 13:43:56.176290 25855 net.cpp:411] pool_v3 -> pool_v3
I0530 13:43:56.176358 25855 net.cpp:150] Setting up pool_v3
I0530 13:43:56.176372 25855 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 13:43:56.176383 25855 net.cpp:165] Memory required for data: 463946800
I0530 13:43:56.176393 25855 layer_factory.hpp:77] Creating layer conv_v4
I0530 13:43:56.176410 25855 net.cpp:106] Creating Layer conv_v4
I0530 13:43:56.176421 25855 net.cpp:454] conv_v4 <- pool_v3
I0530 13:43:56.176436 25855 net.cpp:411] conv_v4 -> conv_v4
I0530 13:43:56.178513 25855 net.cpp:150] Setting up conv_v4
I0530 13:43:56.178535 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:43:56.178547 25855 net.cpp:165] Memory required for data: 467575600
I0530 13:43:56.178562 25855 layer_factory.hpp:77] Creating layer relu_v4
I0530 13:43:56.178575 25855 net.cpp:106] Creating Layer relu_v4
I0530 13:43:56.178586 25855 net.cpp:454] relu_v4 <- conv_v4
I0530 13:43:56.178598 25855 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0530 13:43:56.179072 25855 net.cpp:150] Setting up relu_v4
I0530 13:43:56.179088 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:43:56.179100 25855 net.cpp:165] Memory required for data: 471204400
I0530 13:43:56.179110 25855 layer_factory.hpp:77] Creating layer pool_v4
I0530 13:43:56.179129 25855 net.cpp:106] Creating Layer pool_v4
I0530 13:43:56.179139 25855 net.cpp:454] pool_v4 <- conv_v4
I0530 13:43:56.179153 25855 net.cpp:411] pool_v4 -> pool_v4
I0530 13:43:56.179227 25855 net.cpp:150] Setting up pool_v4
I0530 13:43:56.179240 25855 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 13:43:56.179250 25855 net.cpp:165] Memory required for data: 473018800
I0530 13:43:56.179261 25855 layer_factory.hpp:77] Creating layer dl_v1
I0530 13:43:56.179275 25855 net.cpp:106] Creating Layer dl_v1
I0530 13:43:56.179286 25855 net.cpp:454] dl_v1 <- pool_v4
I0530 13:43:56.179299 25855 net.cpp:411] dl_v1 -> dl_v1
I0530 13:43:56.194838 25855 net.cpp:150] Setting up dl_v1
I0530 13:43:56.194877 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.194895 25855 net.cpp:165] Memory required for data: 473097200
I0530 13:43:56.194913 25855 layer_factory.hpp:77] Creating layer relu_v5
I0530 13:43:56.194928 25855 net.cpp:106] Creating Layer relu_v5
I0530 13:43:56.194938 25855 net.cpp:454] relu_v5 <- dl_v1
I0530 13:43:56.194952 25855 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0530 13:43:56.195309 25855 net.cpp:150] Setting up relu_v5
I0530 13:43:56.195323 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.195334 25855 net.cpp:165] Memory required for data: 473175600
I0530 13:43:56.195344 25855 layer_factory.hpp:77] Creating layer drop_v1
I0530 13:43:56.195358 25855 net.cpp:106] Creating Layer drop_v1
I0530 13:43:56.195368 25855 net.cpp:454] drop_v1 <- dl_v1
I0530 13:43:56.195379 25855 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0530 13:43:56.195425 25855 net.cpp:150] Setting up drop_v1
I0530 13:43:56.195437 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:43:56.195448 25855 net.cpp:165] Memory required for data: 473254000
I0530 13:43:56.195458 25855 layer_factory.hpp:77] Creating layer concat_xuv
I0530 13:43:56.195478 25855 net.cpp:106] Creating Layer concat_xuv
I0530 13:43:56.195489 25855 net.cpp:454] concat_xuv <- dl_x1
I0530 13:43:56.195502 25855 net.cpp:454] concat_xuv <- dl_u1
I0530 13:43:56.195513 25855 net.cpp:454] concat_xuv <- dl_v1
I0530 13:43:56.195526 25855 net.cpp:411] concat_xuv -> concat_xuv
I0530 13:43:56.195579 25855 net.cpp:150] Setting up concat_xuv
I0530 13:43:56.195591 25855 net.cpp:157] Top shape: 100 588 (58800)
I0530 13:43:56.195601 25855 net.cpp:165] Memory required for data: 473489200
I0530 13:43:56.195612 25855 layer_factory.hpp:77] Creating layer dl_xuv
I0530 13:43:56.195626 25855 net.cpp:106] Creating Layer dl_xuv
I0530 13:43:56.195637 25855 net.cpp:454] dl_xuv <- concat_xuv
I0530 13:43:56.195650 25855 net.cpp:411] dl_xuv -> dl_xuv
I0530 13:43:56.196686 25855 net.cpp:150] Setting up dl_xuv
I0530 13:43:56.196705 25855 net.cpp:157] Top shape: 100 98 (9800)
I0530 13:43:56.196715 25855 net.cpp:165] Memory required for data: 473528400
I0530 13:43:56.196730 25855 layer_factory.hpp:77] Creating layer relu_xuv
I0530 13:43:56.196743 25855 net.cpp:106] Creating Layer relu_xuv
I0530 13:43:56.196753 25855 net.cpp:454] relu_xuv <- dl_xuv
I0530 13:43:56.196765 25855 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0530 13:43:56.197310 25855 net.cpp:150] Setting up relu_xuv
I0530 13:43:56.197326 25855 net.cpp:157] Top shape: 100 98 (9800)
I0530 13:43:56.197337 25855 net.cpp:165] Memory required for data: 473567600
I0530 13:43:56.197348 25855 layer_factory.hpp:77] Creating layer drop_xuv
I0530 13:43:56.197361 25855 net.cpp:106] Creating Layer drop_xuv
I0530 13:43:56.197371 25855 net.cpp:454] drop_xuv <- dl_xuv
I0530 13:43:56.197384 25855 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0530 13:43:56.197430 25855 net.cpp:150] Setting up drop_xuv
I0530 13:43:56.197443 25855 net.cpp:157] Top shape: 100 98 (9800)
I0530 13:43:56.197453 25855 net.cpp:165] Memory required for data: 473606800
I0530 13:43:56.197463 25855 layer_factory.hpp:77] Creating layer output
I0530 13:43:56.197477 25855 net.cpp:106] Creating Layer output
I0530 13:43:56.197486 25855 net.cpp:454] output <- dl_xuv
I0530 13:43:56.197500 25855 net.cpp:411] output -> output
I0530 13:43:56.197728 25855 net.cpp:150] Setting up output
I0530 13:43:56.197742 25855 net.cpp:157] Top shape: 100 11 (1100)
I0530 13:43:56.197752 25855 net.cpp:165] Memory required for data: 473611200
I0530 13:43:56.197782 25855 layer_factory.hpp:77] Creating layer drop_output
I0530 13:43:56.197794 25855 net.cpp:106] Creating Layer drop_output
I0530 13:43:56.197804 25855 net.cpp:454] drop_output <- output
I0530 13:43:56.197818 25855 net.cpp:397] drop_output -> output (in-place)
I0530 13:43:56.197860 25855 net.cpp:150] Setting up drop_output
I0530 13:43:56.197873 25855 net.cpp:157] Top shape: 100 11 (1100)
I0530 13:43:56.197883 25855 net.cpp:165] Memory required for data: 473615600
I0530 13:43:56.197893 25855 layer_factory.hpp:77] Creating layer loss
I0530 13:43:56.197922 25855 net.cpp:106] Creating Layer loss
I0530 13:43:56.197932 25855 net.cpp:454] loss <- output
I0530 13:43:56.197944 25855 net.cpp:454] loss <- segments
I0530 13:43:56.197957 25855 net.cpp:411] loss -> loss
I0530 13:43:56.197974 25855 layer_factory.hpp:77] Creating layer loss
I0530 13:43:56.198477 25855 net.cpp:150] Setting up loss
I0530 13:43:56.198489 25855 net.cpp:157] Top shape: (1)
I0530 13:43:56.198499 25855 net.cpp:160]     with loss weight 1
I0530 13:43:56.198544 25855 net.cpp:165] Memory required for data: 473615604
I0530 13:43:56.198554 25855 net.cpp:226] loss needs backward computation.
I0530 13:43:56.198566 25855 net.cpp:226] drop_output needs backward computation.
I0530 13:43:56.198576 25855 net.cpp:226] output needs backward computation.
I0530 13:43:56.198587 25855 net.cpp:226] drop_xuv needs backward computation.
I0530 13:43:56.198597 25855 net.cpp:226] relu_xuv needs backward computation.
I0530 13:43:56.198607 25855 net.cpp:226] dl_xuv needs backward computation.
I0530 13:43:56.198617 25855 net.cpp:226] concat_xuv needs backward computation.
I0530 13:43:56.198629 25855 net.cpp:226] drop_v1 needs backward computation.
I0530 13:43:56.198638 25855 net.cpp:226] relu_v5 needs backward computation.
I0530 13:43:56.198648 25855 net.cpp:226] dl_v1 needs backward computation.
I0530 13:43:56.198658 25855 net.cpp:226] pool_v4 needs backward computation.
I0530 13:43:56.198669 25855 net.cpp:226] relu_v4 needs backward computation.
I0530 13:43:56.198679 25855 net.cpp:226] conv_v4 needs backward computation.
I0530 13:43:56.198690 25855 net.cpp:226] pool_v3 needs backward computation.
I0530 13:43:56.198699 25855 net.cpp:226] relu_v3 needs backward computation.
I0530 13:43:56.198709 25855 net.cpp:226] conv_v3 needs backward computation.
I0530 13:43:56.198721 25855 net.cpp:226] pool_v2 needs backward computation.
I0530 13:43:56.198731 25855 net.cpp:226] relu_v2 needs backward computation.
I0530 13:43:56.198741 25855 net.cpp:226] conv_v2 needs backward computation.
I0530 13:43:56.198751 25855 net.cpp:226] pool_v1 needs backward computation.
I0530 13:43:56.198762 25855 net.cpp:226] relu_v1 needs backward computation.
I0530 13:43:56.198772 25855 net.cpp:226] conv_v1 needs backward computation.
I0530 13:43:56.198783 25855 net.cpp:226] drop_u1 needs backward computation.
I0530 13:43:56.198793 25855 net.cpp:226] relu_u5 needs backward computation.
I0530 13:43:56.198803 25855 net.cpp:226] dl_u1 needs backward computation.
I0530 13:43:56.198814 25855 net.cpp:226] pool_u4 needs backward computation.
I0530 13:43:56.198824 25855 net.cpp:226] relu_u4 needs backward computation.
I0530 13:43:56.198835 25855 net.cpp:226] conv_u4 needs backward computation.
I0530 13:43:56.198845 25855 net.cpp:226] pool_u3 needs backward computation.
I0530 13:43:56.198856 25855 net.cpp:226] relu_u3 needs backward computation.
I0530 13:43:56.198866 25855 net.cpp:226] conv_u3 needs backward computation.
I0530 13:43:56.198878 25855 net.cpp:226] pool_u2 needs backward computation.
I0530 13:43:56.198889 25855 net.cpp:226] relu_u2 needs backward computation.
I0530 13:43:56.198899 25855 net.cpp:226] conv_u2 needs backward computation.
I0530 13:43:56.198910 25855 net.cpp:226] pool_u1 needs backward computation.
I0530 13:43:56.198921 25855 net.cpp:226] relu_u1 needs backward computation.
I0530 13:43:56.198931 25855 net.cpp:226] conv_u1 needs backward computation.
I0530 13:43:56.198941 25855 net.cpp:226] drop_x1 needs backward computation.
I0530 13:43:56.198951 25855 net.cpp:226] relu_x5 needs backward computation.
I0530 13:43:56.198961 25855 net.cpp:226] dl_x1 needs backward computation.
I0530 13:43:56.198972 25855 net.cpp:226] pool_x4 needs backward computation.
I0530 13:43:56.198983 25855 net.cpp:226] relu_x4 needs backward computation.
I0530 13:43:56.198993 25855 net.cpp:226] conv_x4 needs backward computation.
I0530 13:43:56.199004 25855 net.cpp:226] pool_x3 needs backward computation.
I0530 13:43:56.199015 25855 net.cpp:226] relu_x3 needs backward computation.
I0530 13:43:56.199026 25855 net.cpp:226] conv_x3 needs backward computation.
I0530 13:43:56.199043 25855 net.cpp:226] pool_x2 needs backward computation.
I0530 13:43:56.199055 25855 net.cpp:226] relu_x2 needs backward computation.
I0530 13:43:56.199065 25855 net.cpp:226] conv_x2 needs backward computation.
I0530 13:43:56.199077 25855 net.cpp:226] pool_x1 needs backward computation.
I0530 13:43:56.199089 25855 net.cpp:226] relu_x1 needs backward computation.
I0530 13:43:56.199098 25855 net.cpp:226] conv_x1 needs backward computation.
I0530 13:43:56.199111 25855 net.cpp:228] data does not need backward computation.
I0530 13:43:56.199127 25855 net.cpp:270] This network produces output loss
I0530 13:43:56.199172 25855 net.cpp:283] Network initialization done.
I0530 13:43:56.202184 25855 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_inv_2016-05-30T07.39.00.897234.prototxt
I0530 13:43:56.202316 25855 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0530 13:43:56.203088 25855 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "output"
  bottom: "segments"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0530 13:43:56.203472 25855 layer_factory.hpp:77] Creating layer data
I0530 13:43:56.203488 25855 net.cpp:106] Creating Layer data
I0530 13:43:56.203500 25855 net.cpp:411] data -> hits-x
I0530 13:43:56.203516 25855 net.cpp:411] data -> hits-u
I0530 13:43:56.203532 25855 net.cpp:411] data -> hits-v
I0530 13:43:56.203549 25855 net.cpp:411] data -> segments
I0530 13:43:56.203563 25855 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist
I0530 13:43:56.204983 25855 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0530 13:45:00.659041 25855 net.cpp:150] Setting up data
I0530 13:45:00.659209 25855 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 13:45:00.659224 25855 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 13:45:00.659240 25855 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 13:45:00.659252 25855 net.cpp:157] Top shape: 100 (100)
I0530 13:45:00.659262 25855 net.cpp:165] Memory required for data: 7620400
I0530 13:45:00.659276 25855 layer_factory.hpp:77] Creating layer segments_data_3_split
I0530 13:45:00.659302 25855 net.cpp:106] Creating Layer segments_data_3_split
I0530 13:45:00.659313 25855 net.cpp:454] segments_data_3_split <- segments
I0530 13:45:00.659328 25855 net.cpp:411] segments_data_3_split -> segments_data_3_split_0
I0530 13:45:00.659348 25855 net.cpp:411] segments_data_3_split -> segments_data_3_split_1
I0530 13:45:00.659426 25855 net.cpp:150] Setting up segments_data_3_split
I0530 13:45:00.659440 25855 net.cpp:157] Top shape: 100 (100)
I0530 13:45:00.659452 25855 net.cpp:157] Top shape: 100 (100)
I0530 13:45:00.659463 25855 net.cpp:165] Memory required for data: 7621200
I0530 13:45:00.659473 25855 layer_factory.hpp:77] Creating layer conv_x1
I0530 13:45:00.659497 25855 net.cpp:106] Creating Layer conv_x1
I0530 13:45:00.659507 25855 net.cpp:454] conv_x1 <- hits-x
I0530 13:45:00.659523 25855 net.cpp:411] conv_x1 -> conv_x1
I0530 13:45:00.661730 25855 net.cpp:150] Setting up conv_x1
I0530 13:45:00.661753 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:45:00.661767 25855 net.cpp:165] Memory required for data: 35269200
I0530 13:45:00.661787 25855 layer_factory.hpp:77] Creating layer relu_x1
I0530 13:45:00.661803 25855 net.cpp:106] Creating Layer relu_x1
I0530 13:45:00.661813 25855 net.cpp:454] relu_x1 <- conv_x1
I0530 13:45:00.661825 25855 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0530 13:45:00.662338 25855 net.cpp:150] Setting up relu_x1
I0530 13:45:00.662353 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:45:00.662364 25855 net.cpp:165] Memory required for data: 62917200
I0530 13:45:00.662374 25855 layer_factory.hpp:77] Creating layer pool_x1
I0530 13:45:00.662391 25855 net.cpp:106] Creating Layer pool_x1
I0530 13:45:00.662401 25855 net.cpp:454] pool_x1 <- conv_x1
I0530 13:45:00.662415 25855 net.cpp:411] pool_x1 -> pool_x1
I0530 13:45:00.662495 25855 net.cpp:150] Setting up pool_x1
I0530 13:45:00.662508 25855 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 13:45:00.662518 25855 net.cpp:165] Memory required for data: 76741200
I0530 13:45:00.662528 25855 layer_factory.hpp:77] Creating layer conv_x2
I0530 13:45:00.662547 25855 net.cpp:106] Creating Layer conv_x2
I0530 13:45:00.662559 25855 net.cpp:454] conv_x2 <- pool_x1
I0530 13:45:00.662572 25855 net.cpp:411] conv_x2 -> conv_x2
I0530 13:45:00.664458 25855 net.cpp:150] Setting up conv_x2
I0530 13:45:00.664482 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:45:00.664494 25855 net.cpp:165] Memory required for data: 96613200
I0530 13:45:00.664512 25855 layer_factory.hpp:77] Creating layer relu_x2
I0530 13:45:00.664526 25855 net.cpp:106] Creating Layer relu_x2
I0530 13:45:00.664537 25855 net.cpp:454] relu_x2 <- conv_x2
I0530 13:45:00.664551 25855 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0530 13:45:00.665056 25855 net.cpp:150] Setting up relu_x2
I0530 13:45:00.665071 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:45:00.665082 25855 net.cpp:165] Memory required for data: 116485200
I0530 13:45:00.665092 25855 layer_factory.hpp:77] Creating layer pool_x2
I0530 13:45:00.665107 25855 net.cpp:106] Creating Layer pool_x2
I0530 13:45:00.665117 25855 net.cpp:454] pool_x2 <- conv_x2
I0530 13:45:00.665129 25855 net.cpp:411] pool_x2 -> pool_x2
I0530 13:45:00.665208 25855 net.cpp:150] Setting up pool_x2
I0530 13:45:00.665221 25855 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 13:45:00.665231 25855 net.cpp:165] Memory required for data: 126421200
I0530 13:45:00.665240 25855 layer_factory.hpp:77] Creating layer conv_x3
I0530 13:45:00.665261 25855 net.cpp:106] Creating Layer conv_x3
I0530 13:45:00.665271 25855 net.cpp:454] conv_x3 <- pool_x2
I0530 13:45:00.665285 25855 net.cpp:411] conv_x3 -> conv_x3
I0530 13:45:00.667557 25855 net.cpp:150] Setting up conv_x3
I0530 13:45:00.667580 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:45:00.667593 25855 net.cpp:165] Memory required for data: 137262800
I0530 13:45:00.667611 25855 layer_factory.hpp:77] Creating layer relu_x3
I0530 13:45:00.667625 25855 net.cpp:106] Creating Layer relu_x3
I0530 13:45:00.667635 25855 net.cpp:454] relu_x3 <- conv_x3
I0530 13:45:00.667649 25855 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0530 13:45:00.667991 25855 net.cpp:150] Setting up relu_x3
I0530 13:45:00.668005 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:45:00.668015 25855 net.cpp:165] Memory required for data: 148104400
I0530 13:45:00.668025 25855 layer_factory.hpp:77] Creating layer pool_x3
I0530 13:45:00.668038 25855 net.cpp:106] Creating Layer pool_x3
I0530 13:45:00.668047 25855 net.cpp:454] pool_x3 <- conv_x3
I0530 13:45:00.668061 25855 net.cpp:411] pool_x3 -> pool_x3
I0530 13:45:00.668138 25855 net.cpp:150] Setting up pool_x3
I0530 13:45:00.668153 25855 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 13:45:00.668161 25855 net.cpp:165] Memory required for data: 153525200
I0530 13:45:00.668171 25855 layer_factory.hpp:77] Creating layer conv_x4
I0530 13:45:00.668187 25855 net.cpp:106] Creating Layer conv_x4
I0530 13:45:00.668198 25855 net.cpp:454] conv_x4 <- pool_x3
I0530 13:45:00.668212 25855 net.cpp:411] conv_x4 -> conv_x4
I0530 13:45:00.670368 25855 net.cpp:150] Setting up conv_x4
I0530 13:45:00.670390 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:45:00.670403 25855 net.cpp:165] Memory required for data: 157154000
I0530 13:45:00.670418 25855 layer_factory.hpp:77] Creating layer relu_x4
I0530 13:45:00.670433 25855 net.cpp:106] Creating Layer relu_x4
I0530 13:45:00.670442 25855 net.cpp:454] relu_x4 <- conv_x4
I0530 13:45:00.670456 25855 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0530 13:45:00.670944 25855 net.cpp:150] Setting up relu_x4
I0530 13:45:00.670960 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:45:00.670970 25855 net.cpp:165] Memory required for data: 160782800
I0530 13:45:00.670980 25855 layer_factory.hpp:77] Creating layer pool_x4
I0530 13:45:00.670994 25855 net.cpp:106] Creating Layer pool_x4
I0530 13:45:00.671005 25855 net.cpp:454] pool_x4 <- conv_x4
I0530 13:45:00.671017 25855 net.cpp:411] pool_x4 -> pool_x4
I0530 13:45:00.671095 25855 net.cpp:150] Setting up pool_x4
I0530 13:45:00.671108 25855 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 13:45:00.671125 25855 net.cpp:165] Memory required for data: 162597200
I0530 13:45:00.671135 25855 layer_factory.hpp:77] Creating layer dl_x1
I0530 13:45:00.671152 25855 net.cpp:106] Creating Layer dl_x1
I0530 13:45:00.671162 25855 net.cpp:454] dl_x1 <- pool_x4
I0530 13:45:00.671176 25855 net.cpp:411] dl_x1 -> dl_x1
I0530 13:45:00.687367 25855 net.cpp:150] Setting up dl_x1
I0530 13:45:00.687396 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.687407 25855 net.cpp:165] Memory required for data: 162675600
I0530 13:45:00.687429 25855 layer_factory.hpp:77] Creating layer relu_x5
I0530 13:45:00.687444 25855 net.cpp:106] Creating Layer relu_x5
I0530 13:45:00.687454 25855 net.cpp:454] relu_x5 <- dl_x1
I0530 13:45:00.687469 25855 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0530 13:45:00.687829 25855 net.cpp:150] Setting up relu_x5
I0530 13:45:00.687842 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.687852 25855 net.cpp:165] Memory required for data: 162754000
I0530 13:45:00.687862 25855 layer_factory.hpp:77] Creating layer drop_x1
I0530 13:45:00.687881 25855 net.cpp:106] Creating Layer drop_x1
I0530 13:45:00.687891 25855 net.cpp:454] drop_x1 <- dl_x1
I0530 13:45:00.687904 25855 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0530 13:45:00.687952 25855 net.cpp:150] Setting up drop_x1
I0530 13:45:00.687965 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.687976 25855 net.cpp:165] Memory required for data: 162832400
I0530 13:45:00.687986 25855 layer_factory.hpp:77] Creating layer conv_u1
I0530 13:45:00.688004 25855 net.cpp:106] Creating Layer conv_u1
I0530 13:45:00.688029 25855 net.cpp:454] conv_u1 <- hits-u
I0530 13:45:00.688045 25855 net.cpp:411] conv_u1 -> conv_u1
I0530 13:45:00.690023 25855 net.cpp:150] Setting up conv_u1
I0530 13:45:00.690045 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:45:00.690058 25855 net.cpp:165] Memory required for data: 190480400
I0530 13:45:00.690073 25855 layer_factory.hpp:77] Creating layer relu_u1
I0530 13:45:00.690088 25855 net.cpp:106] Creating Layer relu_u1
I0530 13:45:00.690098 25855 net.cpp:454] relu_u1 <- conv_u1
I0530 13:45:00.690111 25855 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0530 13:45:00.690443 25855 net.cpp:150] Setting up relu_u1
I0530 13:45:00.690456 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:45:00.690466 25855 net.cpp:165] Memory required for data: 218128400
I0530 13:45:00.690476 25855 layer_factory.hpp:77] Creating layer pool_u1
I0530 13:45:00.690490 25855 net.cpp:106] Creating Layer pool_u1
I0530 13:45:00.690500 25855 net.cpp:454] pool_u1 <- conv_u1
I0530 13:45:00.690513 25855 net.cpp:411] pool_u1 -> pool_u1
I0530 13:45:00.690598 25855 net.cpp:150] Setting up pool_u1
I0530 13:45:00.690611 25855 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 13:45:00.690621 25855 net.cpp:165] Memory required for data: 231952400
I0530 13:45:00.690629 25855 layer_factory.hpp:77] Creating layer conv_u2
I0530 13:45:00.690647 25855 net.cpp:106] Creating Layer conv_u2
I0530 13:45:00.690659 25855 net.cpp:454] conv_u2 <- pool_u1
I0530 13:45:00.690672 25855 net.cpp:411] conv_u2 -> conv_u2
I0530 13:45:00.692670 25855 net.cpp:150] Setting up conv_u2
I0530 13:45:00.692693 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:45:00.692703 25855 net.cpp:165] Memory required for data: 251824400
I0530 13:45:00.692720 25855 layer_factory.hpp:77] Creating layer relu_u2
I0530 13:45:00.692734 25855 net.cpp:106] Creating Layer relu_u2
I0530 13:45:00.692744 25855 net.cpp:454] relu_u2 <- conv_u2
I0530 13:45:00.692759 25855 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0530 13:45:00.693256 25855 net.cpp:150] Setting up relu_u2
I0530 13:45:00.693274 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:45:00.693284 25855 net.cpp:165] Memory required for data: 271696400
I0530 13:45:00.693294 25855 layer_factory.hpp:77] Creating layer pool_u2
I0530 13:45:00.693307 25855 net.cpp:106] Creating Layer pool_u2
I0530 13:45:00.693317 25855 net.cpp:454] pool_u2 <- conv_u2
I0530 13:45:00.693331 25855 net.cpp:411] pool_u2 -> pool_u2
I0530 13:45:00.693409 25855 net.cpp:150] Setting up pool_u2
I0530 13:45:00.693423 25855 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 13:45:00.693433 25855 net.cpp:165] Memory required for data: 281632400
I0530 13:45:00.693444 25855 layer_factory.hpp:77] Creating layer conv_u3
I0530 13:45:00.693461 25855 net.cpp:106] Creating Layer conv_u3
I0530 13:45:00.693472 25855 net.cpp:454] conv_u3 <- pool_u2
I0530 13:45:00.693486 25855 net.cpp:411] conv_u3 -> conv_u3
I0530 13:45:00.695531 25855 net.cpp:150] Setting up conv_u3
I0530 13:45:00.695554 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:45:00.695566 25855 net.cpp:165] Memory required for data: 292474000
I0530 13:45:00.695582 25855 layer_factory.hpp:77] Creating layer relu_u3
I0530 13:45:00.695595 25855 net.cpp:106] Creating Layer relu_u3
I0530 13:45:00.695606 25855 net.cpp:454] relu_u3 <- conv_u3
I0530 13:45:00.695619 25855 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0530 13:45:00.695947 25855 net.cpp:150] Setting up relu_u3
I0530 13:45:00.695961 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:45:00.695971 25855 net.cpp:165] Memory required for data: 303315600
I0530 13:45:00.695981 25855 layer_factory.hpp:77] Creating layer pool_u3
I0530 13:45:00.695996 25855 net.cpp:106] Creating Layer pool_u3
I0530 13:45:00.696005 25855 net.cpp:454] pool_u3 <- conv_u3
I0530 13:45:00.696018 25855 net.cpp:411] pool_u3 -> pool_u3
I0530 13:45:00.696096 25855 net.cpp:150] Setting up pool_u3
I0530 13:45:00.696110 25855 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 13:45:00.696120 25855 net.cpp:165] Memory required for data: 308736400
I0530 13:45:00.696141 25855 layer_factory.hpp:77] Creating layer conv_u4
I0530 13:45:00.696159 25855 net.cpp:106] Creating Layer conv_u4
I0530 13:45:00.696171 25855 net.cpp:454] conv_u4 <- pool_u3
I0530 13:45:00.696184 25855 net.cpp:411] conv_u4 -> conv_u4
I0530 13:45:00.698374 25855 net.cpp:150] Setting up conv_u4
I0530 13:45:00.698395 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:45:00.698408 25855 net.cpp:165] Memory required for data: 312365200
I0530 13:45:00.698431 25855 layer_factory.hpp:77] Creating layer relu_u4
I0530 13:45:00.698444 25855 net.cpp:106] Creating Layer relu_u4
I0530 13:45:00.698454 25855 net.cpp:454] relu_u4 <- conv_u4
I0530 13:45:00.698467 25855 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0530 13:45:00.698797 25855 net.cpp:150] Setting up relu_u4
I0530 13:45:00.698812 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:45:00.698822 25855 net.cpp:165] Memory required for data: 315994000
I0530 13:45:00.698832 25855 layer_factory.hpp:77] Creating layer pool_u4
I0530 13:45:00.698845 25855 net.cpp:106] Creating Layer pool_u4
I0530 13:45:00.698854 25855 net.cpp:454] pool_u4 <- conv_u4
I0530 13:45:00.698868 25855 net.cpp:411] pool_u4 -> pool_u4
I0530 13:45:00.698946 25855 net.cpp:150] Setting up pool_u4
I0530 13:45:00.698961 25855 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 13:45:00.698971 25855 net.cpp:165] Memory required for data: 317808400
I0530 13:45:00.698979 25855 layer_factory.hpp:77] Creating layer dl_u1
I0530 13:45:00.698995 25855 net.cpp:106] Creating Layer dl_u1
I0530 13:45:00.699005 25855 net.cpp:454] dl_u1 <- pool_u4
I0530 13:45:00.699021 25855 net.cpp:411] dl_u1 -> dl_u1
I0530 13:45:00.715487 25855 net.cpp:150] Setting up dl_u1
I0530 13:45:00.715517 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.715533 25855 net.cpp:165] Memory required for data: 317886800
I0530 13:45:00.715554 25855 layer_factory.hpp:77] Creating layer relu_u5
I0530 13:45:00.715569 25855 net.cpp:106] Creating Layer relu_u5
I0530 13:45:00.715580 25855 net.cpp:454] relu_u5 <- dl_u1
I0530 13:45:00.715595 25855 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0530 13:45:00.716186 25855 net.cpp:150] Setting up relu_u5
I0530 13:45:00.716207 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.716217 25855 net.cpp:165] Memory required for data: 317965200
I0530 13:45:00.716226 25855 layer_factory.hpp:77] Creating layer drop_u1
I0530 13:45:00.716240 25855 net.cpp:106] Creating Layer drop_u1
I0530 13:45:00.716251 25855 net.cpp:454] drop_u1 <- dl_u1
I0530 13:45:00.716264 25855 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0530 13:45:00.716313 25855 net.cpp:150] Setting up drop_u1
I0530 13:45:00.716325 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.716336 25855 net.cpp:165] Memory required for data: 318043600
I0530 13:45:00.716346 25855 layer_factory.hpp:77] Creating layer conv_v1
I0530 13:45:00.716373 25855 net.cpp:106] Creating Layer conv_v1
I0530 13:45:00.716383 25855 net.cpp:454] conv_v1 <- hits-v
I0530 13:45:00.716398 25855 net.cpp:411] conv_v1 -> conv_v1
I0530 13:45:00.718343 25855 net.cpp:150] Setting up conv_v1
I0530 13:45:00.718365 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:45:00.718377 25855 net.cpp:165] Memory required for data: 345691600
I0530 13:45:00.718394 25855 layer_factory.hpp:77] Creating layer relu_v1
I0530 13:45:00.718406 25855 net.cpp:106] Creating Layer relu_v1
I0530 13:45:00.718416 25855 net.cpp:454] relu_v1 <- conv_v1
I0530 13:45:00.718430 25855 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0530 13:45:00.718763 25855 net.cpp:150] Setting up relu_v1
I0530 13:45:00.718777 25855 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 13:45:00.718787 25855 net.cpp:165] Memory required for data: 373339600
I0530 13:45:00.718797 25855 layer_factory.hpp:77] Creating layer pool_v1
I0530 13:45:00.718811 25855 net.cpp:106] Creating Layer pool_v1
I0530 13:45:00.718822 25855 net.cpp:454] pool_v1 <- conv_v1
I0530 13:45:00.718835 25855 net.cpp:411] pool_v1 -> pool_v1
I0530 13:45:00.718916 25855 net.cpp:150] Setting up pool_v1
I0530 13:45:00.718942 25855 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 13:45:00.718953 25855 net.cpp:165] Memory required for data: 387163600
I0530 13:45:00.718963 25855 layer_factory.hpp:77] Creating layer conv_v2
I0530 13:45:00.718981 25855 net.cpp:106] Creating Layer conv_v2
I0530 13:45:00.718991 25855 net.cpp:454] conv_v2 <- pool_v1
I0530 13:45:00.719005 25855 net.cpp:411] conv_v2 -> conv_v2
I0530 13:45:00.721042 25855 net.cpp:150] Setting up conv_v2
I0530 13:45:00.721061 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:45:00.721071 25855 net.cpp:165] Memory required for data: 407035600
I0530 13:45:00.721087 25855 layer_factory.hpp:77] Creating layer relu_v2
I0530 13:45:00.721101 25855 net.cpp:106] Creating Layer relu_v2
I0530 13:45:00.721112 25855 net.cpp:454] relu_v2 <- conv_v2
I0530 13:45:00.721124 25855 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0530 13:45:00.721621 25855 net.cpp:150] Setting up relu_v2
I0530 13:45:00.721637 25855 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 13:45:00.721647 25855 net.cpp:165] Memory required for data: 426907600
I0530 13:45:00.721657 25855 layer_factory.hpp:77] Creating layer pool_v2
I0530 13:45:00.721670 25855 net.cpp:106] Creating Layer pool_v2
I0530 13:45:00.721680 25855 net.cpp:454] pool_v2 <- conv_v2
I0530 13:45:00.721694 25855 net.cpp:411] pool_v2 -> pool_v2
I0530 13:45:00.721774 25855 net.cpp:150] Setting up pool_v2
I0530 13:45:00.721787 25855 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 13:45:00.721797 25855 net.cpp:165] Memory required for data: 436843600
I0530 13:45:00.721807 25855 layer_factory.hpp:77] Creating layer conv_v3
I0530 13:45:00.721825 25855 net.cpp:106] Creating Layer conv_v3
I0530 13:45:00.721837 25855 net.cpp:454] conv_v3 <- pool_v2
I0530 13:45:00.721850 25855 net.cpp:411] conv_v3 -> conv_v3
I0530 13:45:00.723929 25855 net.cpp:150] Setting up conv_v3
I0530 13:45:00.723951 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:45:00.723964 25855 net.cpp:165] Memory required for data: 447685200
I0530 13:45:00.723979 25855 layer_factory.hpp:77] Creating layer relu_v3
I0530 13:45:00.723994 25855 net.cpp:106] Creating Layer relu_v3
I0530 13:45:00.724004 25855 net.cpp:454] relu_v3 <- conv_v3
I0530 13:45:00.724016 25855 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0530 13:45:00.724514 25855 net.cpp:150] Setting up relu_v3
I0530 13:45:00.724531 25855 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 13:45:00.724541 25855 net.cpp:165] Memory required for data: 458526800
I0530 13:45:00.724551 25855 layer_factory.hpp:77] Creating layer pool_v3
I0530 13:45:00.724565 25855 net.cpp:106] Creating Layer pool_v3
I0530 13:45:00.724575 25855 net.cpp:454] pool_v3 <- conv_v3
I0530 13:45:00.724589 25855 net.cpp:411] pool_v3 -> pool_v3
I0530 13:45:00.724668 25855 net.cpp:150] Setting up pool_v3
I0530 13:45:00.724683 25855 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 13:45:00.724692 25855 net.cpp:165] Memory required for data: 463947600
I0530 13:45:00.724702 25855 layer_factory.hpp:77] Creating layer conv_v4
I0530 13:45:00.724720 25855 net.cpp:106] Creating Layer conv_v4
I0530 13:45:00.724730 25855 net.cpp:454] conv_v4 <- pool_v3
I0530 13:45:00.724745 25855 net.cpp:411] conv_v4 -> conv_v4
I0530 13:45:00.726939 25855 net.cpp:150] Setting up conv_v4
I0530 13:45:00.726961 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:45:00.726974 25855 net.cpp:165] Memory required for data: 467576400
I0530 13:45:00.726989 25855 layer_factory.hpp:77] Creating layer relu_v4
I0530 13:45:00.727002 25855 net.cpp:106] Creating Layer relu_v4
I0530 13:45:00.727012 25855 net.cpp:454] relu_v4 <- conv_v4
I0530 13:45:00.727025 25855 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0530 13:45:00.727366 25855 net.cpp:150] Setting up relu_v4
I0530 13:45:00.727380 25855 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 13:45:00.727391 25855 net.cpp:165] Memory required for data: 471205200
I0530 13:45:00.727401 25855 layer_factory.hpp:77] Creating layer pool_v4
I0530 13:45:00.727414 25855 net.cpp:106] Creating Layer pool_v4
I0530 13:45:00.727435 25855 net.cpp:454] pool_v4 <- conv_v4
I0530 13:45:00.727448 25855 net.cpp:411] pool_v4 -> pool_v4
I0530 13:45:00.727529 25855 net.cpp:150] Setting up pool_v4
I0530 13:45:00.727541 25855 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 13:45:00.727552 25855 net.cpp:165] Memory required for data: 473019600
I0530 13:45:00.727562 25855 layer_factory.hpp:77] Creating layer dl_v1
I0530 13:45:00.727577 25855 net.cpp:106] Creating Layer dl_v1
I0530 13:45:00.727589 25855 net.cpp:454] dl_v1 <- pool_v4
I0530 13:45:00.727603 25855 net.cpp:411] dl_v1 -> dl_v1
I0530 13:45:00.744072 25855 net.cpp:150] Setting up dl_v1
I0530 13:45:00.744102 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.744113 25855 net.cpp:165] Memory required for data: 473098000
I0530 13:45:00.744130 25855 layer_factory.hpp:77] Creating layer relu_v5
I0530 13:45:00.744145 25855 net.cpp:106] Creating Layer relu_v5
I0530 13:45:00.744155 25855 net.cpp:454] relu_v5 <- dl_v1
I0530 13:45:00.744169 25855 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0530 13:45:00.744768 25855 net.cpp:150] Setting up relu_v5
I0530 13:45:00.744791 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.744803 25855 net.cpp:165] Memory required for data: 473176400
I0530 13:45:00.744813 25855 layer_factory.hpp:77] Creating layer drop_v1
I0530 13:45:00.744828 25855 net.cpp:106] Creating Layer drop_v1
I0530 13:45:00.744838 25855 net.cpp:454] drop_v1 <- dl_v1
I0530 13:45:00.744851 25855 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0530 13:45:00.744901 25855 net.cpp:150] Setting up drop_v1
I0530 13:45:00.744915 25855 net.cpp:157] Top shape: 100 196 (19600)
I0530 13:45:00.744925 25855 net.cpp:165] Memory required for data: 473254800
I0530 13:45:00.744935 25855 layer_factory.hpp:77] Creating layer concat_xuv
I0530 13:45:00.744948 25855 net.cpp:106] Creating Layer concat_xuv
I0530 13:45:00.744958 25855 net.cpp:454] concat_xuv <- dl_x1
I0530 13:45:00.744971 25855 net.cpp:454] concat_xuv <- dl_u1
I0530 13:45:00.744982 25855 net.cpp:454] concat_xuv <- dl_v1
I0530 13:45:00.744995 25855 net.cpp:411] concat_xuv -> concat_xuv
I0530 13:45:00.745043 25855 net.cpp:150] Setting up concat_xuv
I0530 13:45:00.745057 25855 net.cpp:157] Top shape: 100 588 (58800)
I0530 13:45:00.745067 25855 net.cpp:165] Memory required for data: 473490000
I0530 13:45:00.745076 25855 layer_factory.hpp:77] Creating layer dl_xuv
I0530 13:45:00.745090 25855 net.cpp:106] Creating Layer dl_xuv
I0530 13:45:00.745101 25855 net.cpp:454] dl_xuv <- concat_xuv
I0530 13:45:00.745115 25855 net.cpp:411] dl_xuv -> dl_xuv
I0530 13:45:00.746161 25855 net.cpp:150] Setting up dl_xuv
I0530 13:45:00.746181 25855 net.cpp:157] Top shape: 100 98 (9800)
I0530 13:45:00.746193 25855 net.cpp:165] Memory required for data: 473529200
I0530 13:45:00.746211 25855 layer_factory.hpp:77] Creating layer relu_xuv
I0530 13:45:00.746224 25855 net.cpp:106] Creating Layer relu_xuv
I0530 13:45:00.746234 25855 net.cpp:454] relu_xuv <- dl_xuv
I0530 13:45:00.746246 25855 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0530 13:45:00.746578 25855 net.cpp:150] Setting up relu_xuv
I0530 13:45:00.746592 25855 net.cpp:157] Top shape: 100 98 (9800)
I0530 13:45:00.746603 25855 net.cpp:165] Memory required for data: 473568400
I0530 13:45:00.746613 25855 layer_factory.hpp:77] Creating layer drop_xuv
I0530 13:45:00.746625 25855 net.cpp:106] Creating Layer drop_xuv
I0530 13:45:00.746635 25855 net.cpp:454] drop_xuv <- dl_xuv
I0530 13:45:00.746649 25855 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0530 13:45:00.746695 25855 net.cpp:150] Setting up drop_xuv
I0530 13:45:00.746707 25855 net.cpp:157] Top shape: 100 98 (9800)
I0530 13:45:00.746717 25855 net.cpp:165] Memory required for data: 473607600
I0530 13:45:00.746727 25855 layer_factory.hpp:77] Creating layer output
I0530 13:45:00.746742 25855 net.cpp:106] Creating Layer output
I0530 13:45:00.746752 25855 net.cpp:454] output <- dl_xuv
I0530 13:45:00.746764 25855 net.cpp:411] output -> output
I0530 13:45:00.747012 25855 net.cpp:150] Setting up output
I0530 13:45:00.747025 25855 net.cpp:157] Top shape: 100 11 (1100)
I0530 13:45:00.747048 25855 net.cpp:165] Memory required for data: 473612000
I0530 13:45:00.747081 25855 layer_factory.hpp:77] Creating layer drop_output
I0530 13:45:00.747095 25855 net.cpp:106] Creating Layer drop_output
I0530 13:45:00.747107 25855 net.cpp:454] drop_output <- output
I0530 13:45:00.747128 25855 net.cpp:397] drop_output -> output (in-place)
I0530 13:45:00.747175 25855 net.cpp:150] Setting up drop_output
I0530 13:45:00.747187 25855 net.cpp:157] Top shape: 100 11 (1100)
I0530 13:45:00.747198 25855 net.cpp:165] Memory required for data: 473616400
I0530 13:45:00.747208 25855 layer_factory.hpp:77] Creating layer output_drop_output_0_split
I0530 13:45:00.747222 25855 net.cpp:106] Creating Layer output_drop_output_0_split
I0530 13:45:00.747232 25855 net.cpp:454] output_drop_output_0_split <- output
I0530 13:45:00.747246 25855 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_0
I0530 13:45:00.747259 25855 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_1
I0530 13:45:00.747334 25855 net.cpp:150] Setting up output_drop_output_0_split
I0530 13:45:00.747349 25855 net.cpp:157] Top shape: 100 11 (1100)
I0530 13:45:00.747360 25855 net.cpp:157] Top shape: 100 11 (1100)
I0530 13:45:00.747370 25855 net.cpp:165] Memory required for data: 473625200
I0530 13:45:00.747380 25855 layer_factory.hpp:77] Creating layer accuracy
I0530 13:45:00.747400 25855 net.cpp:106] Creating Layer accuracy
I0530 13:45:00.747411 25855 net.cpp:454] accuracy <- output_drop_output_0_split_0
I0530 13:45:00.747422 25855 net.cpp:454] accuracy <- segments_data_3_split_0
I0530 13:45:00.747437 25855 net.cpp:411] accuracy -> accuracy
I0530 13:45:00.747460 25855 net.cpp:150] Setting up accuracy
I0530 13:45:00.747473 25855 net.cpp:157] Top shape: (1)
I0530 13:45:00.747483 25855 net.cpp:165] Memory required for data: 473625204
I0530 13:45:00.747493 25855 layer_factory.hpp:77] Creating layer loss
I0530 13:45:00.747505 25855 net.cpp:106] Creating Layer loss
I0530 13:45:00.747516 25855 net.cpp:454] loss <- output_drop_output_0_split_1
I0530 13:45:00.747527 25855 net.cpp:454] loss <- segments_data_3_split_1
I0530 13:45:00.747541 25855 net.cpp:411] loss -> loss
I0530 13:45:00.747560 25855 layer_factory.hpp:77] Creating layer loss
I0530 13:45:00.748278 25855 net.cpp:150] Setting up loss
I0530 13:45:00.748299 25855 net.cpp:157] Top shape: (1)
I0530 13:45:00.748312 25855 net.cpp:160]     with loss weight 1
I0530 13:45:00.748332 25855 net.cpp:165] Memory required for data: 473625208
I0530 13:45:00.748342 25855 net.cpp:226] loss needs backward computation.
I0530 13:45:00.748353 25855 net.cpp:228] accuracy does not need backward computation.
I0530 13:45:00.748364 25855 net.cpp:226] output_drop_output_0_split needs backward computation.
I0530 13:45:00.748375 25855 net.cpp:226] drop_output needs backward computation.
I0530 13:45:00.748385 25855 net.cpp:226] output needs backward computation.
I0530 13:45:00.748399 25855 net.cpp:226] drop_xuv needs backward computation.
I0530 13:45:00.748409 25855 net.cpp:226] relu_xuv needs backward computation.
I0530 13:45:00.748419 25855 net.cpp:226] dl_xuv needs backward computation.
I0530 13:45:00.748430 25855 net.cpp:226] concat_xuv needs backward computation.
I0530 13:45:00.748441 25855 net.cpp:226] drop_v1 needs backward computation.
I0530 13:45:00.748451 25855 net.cpp:226] relu_v5 needs backward computation.
I0530 13:45:00.748461 25855 net.cpp:226] dl_v1 needs backward computation.
I0530 13:45:00.748472 25855 net.cpp:226] pool_v4 needs backward computation.
I0530 13:45:00.748482 25855 net.cpp:226] relu_v4 needs backward computation.
I0530 13:45:00.748493 25855 net.cpp:226] conv_v4 needs backward computation.
I0530 13:45:00.748504 25855 net.cpp:226] pool_v3 needs backward computation.
I0530 13:45:00.748515 25855 net.cpp:226] relu_v3 needs backward computation.
I0530 13:45:00.748524 25855 net.cpp:226] conv_v3 needs backward computation.
I0530 13:45:00.748535 25855 net.cpp:226] pool_v2 needs backward computation.
I0530 13:45:00.748545 25855 net.cpp:226] relu_v2 needs backward computation.
I0530 13:45:00.748565 25855 net.cpp:226] conv_v2 needs backward computation.
I0530 13:45:00.748576 25855 net.cpp:226] pool_v1 needs backward computation.
I0530 13:45:00.748589 25855 net.cpp:226] relu_v1 needs backward computation.
I0530 13:45:00.748599 25855 net.cpp:226] conv_v1 needs backward computation.
I0530 13:45:00.748610 25855 net.cpp:226] drop_u1 needs backward computation.
I0530 13:45:00.748620 25855 net.cpp:226] relu_u5 needs backward computation.
I0530 13:45:00.748628 25855 net.cpp:226] dl_u1 needs backward computation.
I0530 13:45:00.748639 25855 net.cpp:226] pool_u4 needs backward computation.
I0530 13:45:00.748651 25855 net.cpp:226] relu_u4 needs backward computation.
I0530 13:45:00.748662 25855 net.cpp:226] conv_u4 needs backward computation.
I0530 13:45:00.748673 25855 net.cpp:226] pool_u3 needs backward computation.
I0530 13:45:00.748684 25855 net.cpp:226] relu_u3 needs backward computation.
I0530 13:45:00.748695 25855 net.cpp:226] conv_u3 needs backward computation.
I0530 13:45:00.748706 25855 net.cpp:226] pool_u2 needs backward computation.
I0530 13:45:00.748718 25855 net.cpp:226] relu_u2 needs backward computation.
I0530 13:45:00.748728 25855 net.cpp:226] conv_u2 needs backward computation.
I0530 13:45:00.748739 25855 net.cpp:226] pool_u1 needs backward computation.
I0530 13:45:00.748750 25855 net.cpp:226] relu_u1 needs backward computation.
I0530 13:45:00.748760 25855 net.cpp:226] conv_u1 needs backward computation.
I0530 13:45:00.748772 25855 net.cpp:226] drop_x1 needs backward computation.
I0530 13:45:00.748782 25855 net.cpp:226] relu_x5 needs backward computation.
I0530 13:45:00.748793 25855 net.cpp:226] dl_x1 needs backward computation.
I0530 13:45:00.748805 25855 net.cpp:226] pool_x4 needs backward computation.
I0530 13:45:00.748816 25855 net.cpp:226] relu_x4 needs backward computation.
I0530 13:45:00.748826 25855 net.cpp:226] conv_x4 needs backward computation.
I0530 13:45:00.748837 25855 net.cpp:226] pool_x3 needs backward computation.
I0530 13:45:00.748848 25855 net.cpp:226] relu_x3 needs backward computation.
I0530 13:45:00.748858 25855 net.cpp:226] conv_x3 needs backward computation.
I0530 13:45:00.748869 25855 net.cpp:226] pool_x2 needs backward computation.
I0530 13:45:00.748883 25855 net.cpp:226] relu_x2 needs backward computation.
I0530 13:45:00.748894 25855 net.cpp:226] conv_x2 needs backward computation.
I0530 13:45:00.748905 25855 net.cpp:226] pool_x1 needs backward computation.
I0530 13:45:00.748916 25855 net.cpp:226] relu_x1 needs backward computation.
I0530 13:45:00.748926 25855 net.cpp:226] conv_x1 needs backward computation.
I0530 13:45:00.748939 25855 net.cpp:228] segments_data_3_split does not need backward computation.
I0530 13:45:00.748951 25855 net.cpp:228] data does not need backward computation.
I0530 13:45:00.748961 25855 net.cpp:270] This network produces output accuracy
I0530 13:45:00.748972 25855 net.cpp:270] This network produces output loss
I0530 13:45:00.749032 25855 net.cpp:283] Network initialization done.
I0530 13:45:00.749317 25855 solver.cpp:60] Solver scaffolding done.
I0530 13:45:00.752490 25855 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_75000.solverstate
I0530 13:45:00.910946 25855 sgd_solver.cpp:318] SGDSolver: restoring history
I0530 13:45:00.931159 25855 caffe.cpp:212] Starting Optimization
I0530 13:45:00.931203 25855 solver.cpp:288] Solving epsilon_127x50_xuv
I0530 13:45:00.931215 25855 solver.cpp:289] Learning Rate Policy: inv
I0530 13:45:00.933706 25855 solver.cpp:341] Iteration 75000, Testing net (#0)
I0530 13:47:18.597033 25855 solver.cpp:409]     Test net output #0: accuracy = 0.887854
I0530 13:47:18.597220 25855 solver.cpp:409]     Test net output #1: loss = 0.371031 (* 1 = 0.371031 loss)
I0530 13:47:18.668714 25855 solver.cpp:237] Iteration 75000, loss = 1.15657
I0530 13:47:18.668751 25855 solver.cpp:253]     Train net output #0: loss = 1.15657 (* 1 = 1.15657 loss)
I0530 13:47:18.668787 25855 sgd_solver.cpp:106] Iteration 75000, lr = 0.000502199
I0530 14:05:58.124455 25855 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_80000.caffemodel
I0530 14:05:58.401119 25855 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_80000.solverstate
I0530 14:05:58.483090 25855 solver.cpp:341] Iteration 80000, Testing net (#0)
I0530 14:08:13.286386 25855 solver.cpp:409]     Test net output #0: accuracy = 0.889076
I0530 14:08:13.286557 25855 solver.cpp:409]     Test net output #1: loss = 0.363441 (* 1 = 0.363441 loss)
I0530 14:09:20.657544 25855 solver.cpp:237] Iteration 80000, loss = 1.03586
I0530 14:09:20.657728 25855 solver.cpp:253]     Train net output #0: loss = 1.03586 (* 1 = 1.03586 loss)
I0530 14:09:20.657745 25855 sgd_solver.cpp:106] Iteration 80000, lr = 0.000481125
I0530 14:28:00.774806 25855 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_85000.caffemodel
I0530 14:28:01.035867 25855 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_85000.solverstate
I0530 14:28:01.116068 25855 solver.cpp:341] Iteration 85000, Testing net (#0)
I0530 14:31:19.419190 25855 solver.cpp:409]     Test net output #0: accuracy = 0.890276
I0530 14:31:19.419369 25855 solver.cpp:409]     Test net output #1: loss = 0.361108 (* 1 = 0.361108 loss)
I0530 14:32:26.666945 25855 solver.cpp:237] Iteration 85000, loss = 1.14914
I0530 14:32:26.667132 25855 solver.cpp:253]     Train net output #0: loss = 1.14914 (* 1 = 1.14914 loss)
I0530 14:32:26.667150 25855 sgd_solver.cpp:106] Iteration 85000, lr = 0.000462006
I0530 14:51:06.521327 25855 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_90000.caffemodel
I0530 14:51:06.780539 25855 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_90000.solverstate
I0530 14:51:06.860618 25855 solver.cpp:341] Iteration 90000, Testing net (#0)
I0530 14:53:20.526178 25855 solver.cpp:409]     Test net output #0: accuracy = 0.890389
I0530 14:53:20.526360 25855 solver.cpp:409]     Test net output #1: loss = 0.35635 (* 1 = 0.35635 loss)
I0530 14:54:23.830271 25855 solver.cpp:237] Iteration 90000, loss = 1.40386
I0530 14:54:23.830451 25855 solver.cpp:253]     Train net output #0: loss = 1.40386 (* 1 = 1.40386 loss)
I0530 14:54:23.830467 25855 sgd_solver.cpp:106] Iteration 90000, lr = 0.00044457
I0530 15:12:47.818536 25855 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_95000.caffemodel
I0530 15:12:48.085114 25855 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_95000.solverstate
I0530 15:12:48.170137 25855 solver.cpp:341] Iteration 95000, Testing net (#0)
I0530 15:16:06.217509 25855 solver.cpp:409]     Test net output #0: accuracy = 0.892089
I0530 15:16:06.217681 25855 solver.cpp:409]     Test net output #1: loss = 0.358085 (* 1 = 0.358085 loss)
I0530 15:17:09.500216 25855 solver.cpp:237] Iteration 95000, loss = 0.978316
I0530 15:17:09.500397 25855 solver.cpp:253]     Train net output #0: loss = 0.978316 (* 1 = 0.978316 loss)
I0530 15:17:09.500416 25855 sgd_solver.cpp:106] Iteration 95000, lr = 0.000428596
I0530 15:35:33.624888 25855 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_100000.caffemodel
I0530 15:35:33.885985 25855 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_100000.solverstate
I0530 15:35:33.970829 25855 solver.cpp:341] Iteration 100000, Testing net (#0)
I0530 15:37:48.730690 25855 solver.cpp:409]     Test net output #0: accuracy = 0.892229
I0530 15:37:48.730861 25855 solver.cpp:409]     Test net output #1: loss = 0.366799 (* 1 = 0.366799 loss)
I0530 15:38:52.097944 25855 solver.cpp:237] Iteration 100000, loss = 1.13576
I0530 15:38:52.098125 25855 solver.cpp:253]     Train net output #0: loss = 1.13576 (* 1 = 1.13576 loss)
I0530 15:38:52.098142 25855 sgd_solver.cpp:106] Iteration 100000, lr = 0.0004139
aprun: Apid 11286825: Caught signal Terminated, sending to application
*** Aborted at 1464637364 (unix time) try "date -d @1464637364" if you are using GNU date ***
aprun: Apid 11286825: Caught signal Terminated, sending to application
aprun: Apid 11286825: Caught signal Terminated, sending to application
aprun: Apid 11286825: Caught signal Terminated, sending to application
PC: @     0x2aaab144c9f0 H5VM_memcpyvv
aprun: Apid 11286825: Caught signal Terminated, sending to application
*** SIGTERM (@0x64fc) received by PID 25855 (TID 0x2aaac746f900) from PID 25852; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11286825: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7202 exceeded limit 7200
    @     0x2aaab144c9f0 H5VM_memcpyvv
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab12905af H5D__compact_readvv
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab12a3143 H5D__select_io
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab12a38cd H5D__select_read
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab128be3d H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x43020c main
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11286825: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11286825: Caught signal Terminated, sending to application
