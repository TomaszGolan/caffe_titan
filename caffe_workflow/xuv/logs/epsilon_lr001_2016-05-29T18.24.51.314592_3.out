2816512
I0529 22:27:35.334305 23976 caffe.cpp:184] Using GPUs 0
I0529 22:27:35.763219 23976 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 5000
base_lr: 0.001
display: 5000
max_iter: 150000
lr_policy: "fixed"
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_lr001_2016-05-29T18.24.51.314592.prototxt"
type: "AdaGrad"
I0529 22:27:35.766288 23976 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_lr001_2016-05-29T18.24.51.314592.prototxt
I0529 22:27:35.791085 23976 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0529 22:27:35.791172 23976 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0529 22:27:35.791905 23976 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0529 22:27:35.792266 23976 layer_factory.hpp:77] Creating layer data
I0529 22:27:35.792291 23976 net.cpp:106] Creating Layer data
I0529 22:27:35.792305 23976 net.cpp:411] data -> hits-x
I0529 22:27:35.792340 23976 net.cpp:411] data -> hits-u
I0529 22:27:35.792361 23976 net.cpp:411] data -> hits-v
I0529 22:27:35.792376 23976 net.cpp:411] data -> segments
I0529 22:27:35.792400 23976 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist
I0529 22:27:35.803896 23976 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0529 22:27:35.854017 23976 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0529 22:28:40.164604 23976 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0529 22:28:40.170253 23976 net.cpp:150] Setting up data
I0529 22:28:40.170295 23976 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 22:28:40.170310 23976 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 22:28:40.170323 23976 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 22:28:40.170336 23976 net.cpp:157] Top shape: 100 (100)
I0529 22:28:40.170346 23976 net.cpp:165] Memory required for data: 7620400
I0529 22:28:40.170358 23976 layer_factory.hpp:77] Creating layer conv_x1
I0529 22:28:40.170393 23976 net.cpp:106] Creating Layer conv_x1
I0529 22:28:40.170404 23976 net.cpp:454] conv_x1 <- hits-x
I0529 22:28:40.170426 23976 net.cpp:411] conv_x1 -> conv_x1
I0529 22:28:43.011993 23976 net.cpp:150] Setting up conv_x1
I0529 22:28:43.012039 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:28:43.012050 23976 net.cpp:165] Memory required for data: 35268400
I0529 22:28:43.012081 23976 layer_factory.hpp:77] Creating layer relu_x1
I0529 22:28:43.012104 23976 net.cpp:106] Creating Layer relu_x1
I0529 22:28:43.012115 23976 net.cpp:454] relu_x1 <- conv_x1
I0529 22:28:43.012128 23976 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0529 22:28:43.012646 23976 net.cpp:150] Setting up relu_x1
I0529 22:28:43.012663 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:28:43.012675 23976 net.cpp:165] Memory required for data: 62916400
I0529 22:28:43.012684 23976 layer_factory.hpp:77] Creating layer pool_x1
I0529 22:28:43.012701 23976 net.cpp:106] Creating Layer pool_x1
I0529 22:28:43.012712 23976 net.cpp:454] pool_x1 <- conv_x1
I0529 22:28:43.012725 23976 net.cpp:411] pool_x1 -> pool_x1
I0529 22:28:43.012806 23976 net.cpp:150] Setting up pool_x1
I0529 22:28:43.012820 23976 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 22:28:43.012831 23976 net.cpp:165] Memory required for data: 76740400
I0529 22:28:43.012841 23976 layer_factory.hpp:77] Creating layer conv_x2
I0529 22:28:43.012864 23976 net.cpp:106] Creating Layer conv_x2
I0529 22:28:43.012876 23976 net.cpp:454] conv_x2 <- pool_x1
I0529 22:28:43.012888 23976 net.cpp:411] conv_x2 -> conv_x2
I0529 22:28:43.015564 23976 net.cpp:150] Setting up conv_x2
I0529 22:28:43.015593 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:28:43.015605 23976 net.cpp:165] Memory required for data: 96612400
I0529 22:28:43.015625 23976 layer_factory.hpp:77] Creating layer relu_x2
I0529 22:28:43.015640 23976 net.cpp:106] Creating Layer relu_x2
I0529 22:28:43.015650 23976 net.cpp:454] relu_x2 <- conv_x2
I0529 22:28:43.015664 23976 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0529 22:28:43.015995 23976 net.cpp:150] Setting up relu_x2
I0529 22:28:43.016010 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:28:43.016019 23976 net.cpp:165] Memory required for data: 116484400
I0529 22:28:43.016029 23976 layer_factory.hpp:77] Creating layer pool_x2
I0529 22:28:43.016041 23976 net.cpp:106] Creating Layer pool_x2
I0529 22:28:43.016052 23976 net.cpp:454] pool_x2 <- conv_x2
I0529 22:28:43.016065 23976 net.cpp:411] pool_x2 -> pool_x2
I0529 22:28:43.016135 23976 net.cpp:150] Setting up pool_x2
I0529 22:28:43.016149 23976 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 22:28:43.016158 23976 net.cpp:165] Memory required for data: 126420400
I0529 22:28:43.016168 23976 layer_factory.hpp:77] Creating layer conv_x3
I0529 22:28:43.016185 23976 net.cpp:106] Creating Layer conv_x3
I0529 22:28:43.016196 23976 net.cpp:454] conv_x3 <- pool_x2
I0529 22:28:43.016211 23976 net.cpp:411] conv_x3 -> conv_x3
I0529 22:28:43.018132 23976 net.cpp:150] Setting up conv_x3
I0529 22:28:43.018157 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:28:43.018168 23976 net.cpp:165] Memory required for data: 137262000
I0529 22:28:43.018187 23976 layer_factory.hpp:77] Creating layer relu_x3
I0529 22:28:43.018203 23976 net.cpp:106] Creating Layer relu_x3
I0529 22:28:43.018213 23976 net.cpp:454] relu_x3 <- conv_x3
I0529 22:28:43.018235 23976 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0529 22:28:43.018707 23976 net.cpp:150] Setting up relu_x3
I0529 22:28:43.018724 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:28:43.018746 23976 net.cpp:165] Memory required for data: 148103600
I0529 22:28:43.018757 23976 layer_factory.hpp:77] Creating layer pool_x3
I0529 22:28:43.018770 23976 net.cpp:106] Creating Layer pool_x3
I0529 22:28:43.018780 23976 net.cpp:454] pool_x3 <- conv_x3
I0529 22:28:43.018795 23976 net.cpp:411] pool_x3 -> pool_x3
I0529 22:28:43.018863 23976 net.cpp:150] Setting up pool_x3
I0529 22:28:43.018877 23976 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 22:28:43.018887 23976 net.cpp:165] Memory required for data: 153524400
I0529 22:28:43.018896 23976 layer_factory.hpp:77] Creating layer conv_x4
I0529 22:28:43.018914 23976 net.cpp:106] Creating Layer conv_x4
I0529 22:28:43.018924 23976 net.cpp:454] conv_x4 <- pool_x3
I0529 22:28:43.018937 23976 net.cpp:411] conv_x4 -> conv_x4
I0529 22:28:43.021884 23976 net.cpp:150] Setting up conv_x4
I0529 22:28:43.021913 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:28:43.021924 23976 net.cpp:165] Memory required for data: 157153200
I0529 22:28:43.021939 23976 layer_factory.hpp:77] Creating layer relu_x4
I0529 22:28:43.021953 23976 net.cpp:106] Creating Layer relu_x4
I0529 22:28:43.021965 23976 net.cpp:454] relu_x4 <- conv_x4
I0529 22:28:43.021977 23976 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0529 22:28:43.022455 23976 net.cpp:150] Setting up relu_x4
I0529 22:28:43.022472 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:28:43.022482 23976 net.cpp:165] Memory required for data: 160782000
I0529 22:28:43.022493 23976 layer_factory.hpp:77] Creating layer pool_x4
I0529 22:28:43.022506 23976 net.cpp:106] Creating Layer pool_x4
I0529 22:28:43.022517 23976 net.cpp:454] pool_x4 <- conv_x4
I0529 22:28:43.022531 23976 net.cpp:411] pool_x4 -> pool_x4
I0529 22:28:43.022600 23976 net.cpp:150] Setting up pool_x4
I0529 22:28:43.022614 23976 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 22:28:43.022624 23976 net.cpp:165] Memory required for data: 162596400
I0529 22:28:43.022634 23976 layer_factory.hpp:77] Creating layer dl_x1
I0529 22:28:43.022655 23976 net.cpp:106] Creating Layer dl_x1
I0529 22:28:43.022665 23976 net.cpp:454] dl_x1 <- pool_x4
I0529 22:28:43.022678 23976 net.cpp:411] dl_x1 -> dl_x1
I0529 22:28:43.038084 23976 net.cpp:150] Setting up dl_x1
I0529 22:28:43.038111 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.038122 23976 net.cpp:165] Memory required for data: 162674800
I0529 22:28:43.038144 23976 layer_factory.hpp:77] Creating layer relu_x5
I0529 22:28:43.038159 23976 net.cpp:106] Creating Layer relu_x5
I0529 22:28:43.038169 23976 net.cpp:454] relu_x5 <- dl_x1
I0529 22:28:43.038183 23976 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0529 22:28:43.038532 23976 net.cpp:150] Setting up relu_x5
I0529 22:28:43.038545 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.038555 23976 net.cpp:165] Memory required for data: 162753200
I0529 22:28:43.038566 23976 layer_factory.hpp:77] Creating layer drop_x1
I0529 22:28:43.038589 23976 net.cpp:106] Creating Layer drop_x1
I0529 22:28:43.038599 23976 net.cpp:454] drop_x1 <- dl_x1
I0529 22:28:43.038612 23976 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0529 22:28:43.038657 23976 net.cpp:150] Setting up drop_x1
I0529 22:28:43.038671 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.038682 23976 net.cpp:165] Memory required for data: 162831600
I0529 22:28:43.038692 23976 layer_factory.hpp:77] Creating layer conv_u1
I0529 22:28:43.038715 23976 net.cpp:106] Creating Layer conv_u1
I0529 22:28:43.038727 23976 net.cpp:454] conv_u1 <- hits-u
I0529 22:28:43.038739 23976 net.cpp:411] conv_u1 -> conv_u1
I0529 22:28:43.040568 23976 net.cpp:150] Setting up conv_u1
I0529 22:28:43.040591 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:28:43.040603 23976 net.cpp:165] Memory required for data: 190479600
I0529 22:28:43.040619 23976 layer_factory.hpp:77] Creating layer relu_u1
I0529 22:28:43.040632 23976 net.cpp:106] Creating Layer relu_u1
I0529 22:28:43.040642 23976 net.cpp:454] relu_u1 <- conv_u1
I0529 22:28:43.040655 23976 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0529 22:28:43.041142 23976 net.cpp:150] Setting up relu_u1
I0529 22:28:43.041162 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:28:43.041172 23976 net.cpp:165] Memory required for data: 218127600
I0529 22:28:43.041182 23976 layer_factory.hpp:77] Creating layer pool_u1
I0529 22:28:43.041196 23976 net.cpp:106] Creating Layer pool_u1
I0529 22:28:43.041205 23976 net.cpp:454] pool_u1 <- conv_u1
I0529 22:28:43.041219 23976 net.cpp:411] pool_u1 -> pool_u1
I0529 22:28:43.041290 23976 net.cpp:150] Setting up pool_u1
I0529 22:28:43.041303 23976 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 22:28:43.041313 23976 net.cpp:165] Memory required for data: 231951600
I0529 22:28:43.041323 23976 layer_factory.hpp:77] Creating layer conv_u2
I0529 22:28:43.041342 23976 net.cpp:106] Creating Layer conv_u2
I0529 22:28:43.041352 23976 net.cpp:454] conv_u2 <- pool_u1
I0529 22:28:43.041366 23976 net.cpp:411] conv_u2 -> conv_u2
I0529 22:28:43.043191 23976 net.cpp:150] Setting up conv_u2
I0529 22:28:43.043213 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:28:43.043226 23976 net.cpp:165] Memory required for data: 251823600
I0529 22:28:43.043241 23976 layer_factory.hpp:77] Creating layer relu_u2
I0529 22:28:43.043256 23976 net.cpp:106] Creating Layer relu_u2
I0529 22:28:43.043265 23976 net.cpp:454] relu_u2 <- conv_u2
I0529 22:28:43.043278 23976 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0529 22:28:43.043597 23976 net.cpp:150] Setting up relu_u2
I0529 22:28:43.043612 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:28:43.043622 23976 net.cpp:165] Memory required for data: 271695600
I0529 22:28:43.043632 23976 layer_factory.hpp:77] Creating layer pool_u2
I0529 22:28:43.043645 23976 net.cpp:106] Creating Layer pool_u2
I0529 22:28:43.043655 23976 net.cpp:454] pool_u2 <- conv_u2
I0529 22:28:43.043668 23976 net.cpp:411] pool_u2 -> pool_u2
I0529 22:28:43.043740 23976 net.cpp:150] Setting up pool_u2
I0529 22:28:43.043754 23976 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 22:28:43.043764 23976 net.cpp:165] Memory required for data: 281631600
I0529 22:28:43.043774 23976 layer_factory.hpp:77] Creating layer conv_u3
I0529 22:28:43.043792 23976 net.cpp:106] Creating Layer conv_u3
I0529 22:28:43.043802 23976 net.cpp:454] conv_u3 <- pool_u2
I0529 22:28:43.043815 23976 net.cpp:411] conv_u3 -> conv_u3
I0529 22:28:43.045720 23976 net.cpp:150] Setting up conv_u3
I0529 22:28:43.045742 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:28:43.045755 23976 net.cpp:165] Memory required for data: 292473200
I0529 22:28:43.045769 23976 layer_factory.hpp:77] Creating layer relu_u3
I0529 22:28:43.045783 23976 net.cpp:106] Creating Layer relu_u3
I0529 22:28:43.045794 23976 net.cpp:454] relu_u3 <- conv_u3
I0529 22:28:43.045805 23976 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0529 22:28:43.046136 23976 net.cpp:150] Setting up relu_u3
I0529 22:28:43.046150 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:28:43.046160 23976 net.cpp:165] Memory required for data: 303314800
I0529 22:28:43.046169 23976 layer_factory.hpp:77] Creating layer pool_u3
I0529 22:28:43.046182 23976 net.cpp:106] Creating Layer pool_u3
I0529 22:28:43.046192 23976 net.cpp:454] pool_u3 <- conv_u3
I0529 22:28:43.046205 23976 net.cpp:411] pool_u3 -> pool_u3
I0529 22:28:43.046281 23976 net.cpp:150] Setting up pool_u3
I0529 22:28:43.046294 23976 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 22:28:43.046304 23976 net.cpp:165] Memory required for data: 308735600
I0529 22:28:43.046314 23976 layer_factory.hpp:77] Creating layer conv_u4
I0529 22:28:43.046331 23976 net.cpp:106] Creating Layer conv_u4
I0529 22:28:43.046342 23976 net.cpp:454] conv_u4 <- pool_u3
I0529 22:28:43.046356 23976 net.cpp:411] conv_u4 -> conv_u4
I0529 22:28:43.048553 23976 net.cpp:150] Setting up conv_u4
I0529 22:28:43.048576 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:28:43.048588 23976 net.cpp:165] Memory required for data: 312364400
I0529 22:28:43.048610 23976 layer_factory.hpp:77] Creating layer relu_u4
I0529 22:28:43.048624 23976 net.cpp:106] Creating Layer relu_u4
I0529 22:28:43.048643 23976 net.cpp:454] relu_u4 <- conv_u4
I0529 22:28:43.048655 23976 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0529 22:28:43.049126 23976 net.cpp:150] Setting up relu_u4
I0529 22:28:43.049144 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:28:43.049154 23976 net.cpp:165] Memory required for data: 315993200
I0529 22:28:43.049165 23976 layer_factory.hpp:77] Creating layer pool_u4
I0529 22:28:43.049176 23976 net.cpp:106] Creating Layer pool_u4
I0529 22:28:43.049186 23976 net.cpp:454] pool_u4 <- conv_u4
I0529 22:28:43.049201 23976 net.cpp:411] pool_u4 -> pool_u4
I0529 22:28:43.049269 23976 net.cpp:150] Setting up pool_u4
I0529 22:28:43.049283 23976 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 22:28:43.049293 23976 net.cpp:165] Memory required for data: 317807600
I0529 22:28:43.049304 23976 layer_factory.hpp:77] Creating layer dl_u1
I0529 22:28:43.049319 23976 net.cpp:106] Creating Layer dl_u1
I0529 22:28:43.049329 23976 net.cpp:454] dl_u1 <- pool_u4
I0529 22:28:43.049342 23976 net.cpp:411] dl_u1 -> dl_u1
I0529 22:28:43.064844 23976 net.cpp:150] Setting up dl_u1
I0529 22:28:43.064872 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.064883 23976 net.cpp:165] Memory required for data: 317886000
I0529 22:28:43.064899 23976 layer_factory.hpp:77] Creating layer relu_u5
I0529 22:28:43.064914 23976 net.cpp:106] Creating Layer relu_u5
I0529 22:28:43.064925 23976 net.cpp:454] relu_u5 <- dl_u1
I0529 22:28:43.064939 23976 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0529 22:28:43.065282 23976 net.cpp:150] Setting up relu_u5
I0529 22:28:43.065296 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.065306 23976 net.cpp:165] Memory required for data: 317964400
I0529 22:28:43.065316 23976 layer_factory.hpp:77] Creating layer drop_u1
I0529 22:28:43.065330 23976 net.cpp:106] Creating Layer drop_u1
I0529 22:28:43.065340 23976 net.cpp:454] drop_u1 <- dl_u1
I0529 22:28:43.065351 23976 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0529 22:28:43.065394 23976 net.cpp:150] Setting up drop_u1
I0529 22:28:43.065407 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.065418 23976 net.cpp:165] Memory required for data: 318042800
I0529 22:28:43.065428 23976 layer_factory.hpp:77] Creating layer conv_v1
I0529 22:28:43.065444 23976 net.cpp:106] Creating Layer conv_v1
I0529 22:28:43.065454 23976 net.cpp:454] conv_v1 <- hits-v
I0529 22:28:43.065469 23976 net.cpp:411] conv_v1 -> conv_v1
I0529 22:28:43.067332 23976 net.cpp:150] Setting up conv_v1
I0529 22:28:43.067349 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:28:43.067364 23976 net.cpp:165] Memory required for data: 345690800
I0529 22:28:43.067381 23976 layer_factory.hpp:77] Creating layer relu_v1
I0529 22:28:43.067404 23976 net.cpp:106] Creating Layer relu_v1
I0529 22:28:43.067414 23976 net.cpp:454] relu_v1 <- conv_v1
I0529 22:28:43.067427 23976 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0529 22:28:43.067895 23976 net.cpp:150] Setting up relu_v1
I0529 22:28:43.067914 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:28:43.067924 23976 net.cpp:165] Memory required for data: 373338800
I0529 22:28:43.067934 23976 layer_factory.hpp:77] Creating layer pool_v1
I0529 22:28:43.067947 23976 net.cpp:106] Creating Layer pool_v1
I0529 22:28:43.067957 23976 net.cpp:454] pool_v1 <- conv_v1
I0529 22:28:43.067970 23976 net.cpp:411] pool_v1 -> pool_v1
I0529 22:28:43.068043 23976 net.cpp:150] Setting up pool_v1
I0529 22:28:43.068058 23976 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 22:28:43.068068 23976 net.cpp:165] Memory required for data: 387162800
I0529 22:28:43.068075 23976 layer_factory.hpp:77] Creating layer conv_v2
I0529 22:28:43.068091 23976 net.cpp:106] Creating Layer conv_v2
I0529 22:28:43.068102 23976 net.cpp:454] conv_v2 <- pool_v1
I0529 22:28:43.068116 23976 net.cpp:411] conv_v2 -> conv_v2
I0529 22:28:43.069802 23976 net.cpp:150] Setting up conv_v2
I0529 22:28:43.069824 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:28:43.069836 23976 net.cpp:165] Memory required for data: 407034800
I0529 22:28:43.069865 23976 layer_factory.hpp:77] Creating layer relu_v2
I0529 22:28:43.069880 23976 net.cpp:106] Creating Layer relu_v2
I0529 22:28:43.069890 23976 net.cpp:454] relu_v2 <- conv_v2
I0529 22:28:43.069902 23976 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0529 22:28:43.070387 23976 net.cpp:150] Setting up relu_v2
I0529 22:28:43.070404 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:28:43.070413 23976 net.cpp:165] Memory required for data: 426906800
I0529 22:28:43.070425 23976 layer_factory.hpp:77] Creating layer pool_v2
I0529 22:28:43.070438 23976 net.cpp:106] Creating Layer pool_v2
I0529 22:28:43.070448 23976 net.cpp:454] pool_v2 <- conv_v2
I0529 22:28:43.070462 23976 net.cpp:411] pool_v2 -> pool_v2
I0529 22:28:43.070533 23976 net.cpp:150] Setting up pool_v2
I0529 22:28:43.070546 23976 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 22:28:43.070556 23976 net.cpp:165] Memory required for data: 436842800
I0529 22:28:43.070564 23976 layer_factory.hpp:77] Creating layer conv_v3
I0529 22:28:43.070581 23976 net.cpp:106] Creating Layer conv_v3
I0529 22:28:43.070591 23976 net.cpp:454] conv_v3 <- pool_v2
I0529 22:28:43.070606 23976 net.cpp:411] conv_v3 -> conv_v3
I0529 22:28:43.072538 23976 net.cpp:150] Setting up conv_v3
I0529 22:28:43.072561 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:28:43.072573 23976 net.cpp:165] Memory required for data: 447684400
I0529 22:28:43.072588 23976 layer_factory.hpp:77] Creating layer relu_v3
I0529 22:28:43.072602 23976 net.cpp:106] Creating Layer relu_v3
I0529 22:28:43.072612 23976 net.cpp:454] relu_v3 <- conv_v3
I0529 22:28:43.072624 23976 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0529 22:28:43.072944 23976 net.cpp:150] Setting up relu_v3
I0529 22:28:43.072958 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:28:43.072968 23976 net.cpp:165] Memory required for data: 458526000
I0529 22:28:43.072978 23976 layer_factory.hpp:77] Creating layer pool_v3
I0529 22:28:43.072991 23976 net.cpp:106] Creating Layer pool_v3
I0529 22:28:43.073001 23976 net.cpp:454] pool_v3 <- conv_v3
I0529 22:28:43.073014 23976 net.cpp:411] pool_v3 -> pool_v3
I0529 22:28:43.073082 23976 net.cpp:150] Setting up pool_v3
I0529 22:28:43.073096 23976 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 22:28:43.073107 23976 net.cpp:165] Memory required for data: 463946800
I0529 22:28:43.073117 23976 layer_factory.hpp:77] Creating layer conv_v4
I0529 22:28:43.073133 23976 net.cpp:106] Creating Layer conv_v4
I0529 22:28:43.073143 23976 net.cpp:454] conv_v4 <- pool_v3
I0529 22:28:43.073158 23976 net.cpp:411] conv_v4 -> conv_v4
I0529 22:28:43.075239 23976 net.cpp:150] Setting up conv_v4
I0529 22:28:43.075260 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:28:43.075274 23976 net.cpp:165] Memory required for data: 467575600
I0529 22:28:43.075289 23976 layer_factory.hpp:77] Creating layer relu_v4
I0529 22:28:43.075301 23976 net.cpp:106] Creating Layer relu_v4
I0529 22:28:43.075312 23976 net.cpp:454] relu_v4 <- conv_v4
I0529 22:28:43.075325 23976 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0529 22:28:43.075800 23976 net.cpp:150] Setting up relu_v4
I0529 22:28:43.075816 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:28:43.075826 23976 net.cpp:165] Memory required for data: 471204400
I0529 22:28:43.075836 23976 layer_factory.hpp:77] Creating layer pool_v4
I0529 22:28:43.075850 23976 net.cpp:106] Creating Layer pool_v4
I0529 22:28:43.075860 23976 net.cpp:454] pool_v4 <- conv_v4
I0529 22:28:43.075873 23976 net.cpp:411] pool_v4 -> pool_v4
I0529 22:28:43.075947 23976 net.cpp:150] Setting up pool_v4
I0529 22:28:43.075959 23976 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 22:28:43.075969 23976 net.cpp:165] Memory required for data: 473018800
I0529 22:28:43.075978 23976 layer_factory.hpp:77] Creating layer dl_v1
I0529 22:28:43.075992 23976 net.cpp:106] Creating Layer dl_v1
I0529 22:28:43.076002 23976 net.cpp:454] dl_v1 <- pool_v4
I0529 22:28:43.076017 23976 net.cpp:411] dl_v1 -> dl_v1
I0529 22:28:43.091454 23976 net.cpp:150] Setting up dl_v1
I0529 22:28:43.091490 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.091507 23976 net.cpp:165] Memory required for data: 473097200
I0529 22:28:43.091524 23976 layer_factory.hpp:77] Creating layer relu_v5
I0529 22:28:43.091539 23976 net.cpp:106] Creating Layer relu_v5
I0529 22:28:43.091550 23976 net.cpp:454] relu_v5 <- dl_v1
I0529 22:28:43.091563 23976 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0529 22:28:43.091915 23976 net.cpp:150] Setting up relu_v5
I0529 22:28:43.091929 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.091940 23976 net.cpp:165] Memory required for data: 473175600
I0529 22:28:43.091950 23976 layer_factory.hpp:77] Creating layer drop_v1
I0529 22:28:43.091963 23976 net.cpp:106] Creating Layer drop_v1
I0529 22:28:43.091974 23976 net.cpp:454] drop_v1 <- dl_v1
I0529 22:28:43.091985 23976 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0529 22:28:43.092030 23976 net.cpp:150] Setting up drop_v1
I0529 22:28:43.092042 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:28:43.092053 23976 net.cpp:165] Memory required for data: 473254000
I0529 22:28:43.092063 23976 layer_factory.hpp:77] Creating layer concat_xuv
I0529 22:28:43.092084 23976 net.cpp:106] Creating Layer concat_xuv
I0529 22:28:43.092094 23976 net.cpp:454] concat_xuv <- dl_x1
I0529 22:28:43.092103 23976 net.cpp:454] concat_xuv <- dl_u1
I0529 22:28:43.092115 23976 net.cpp:454] concat_xuv <- dl_v1
I0529 22:28:43.092130 23976 net.cpp:411] concat_xuv -> concat_xuv
I0529 22:28:43.092182 23976 net.cpp:150] Setting up concat_xuv
I0529 22:28:43.092195 23976 net.cpp:157] Top shape: 100 588 (58800)
I0529 22:28:43.092206 23976 net.cpp:165] Memory required for data: 473489200
I0529 22:28:43.092216 23976 layer_factory.hpp:77] Creating layer dl_xuv
I0529 22:28:43.092227 23976 net.cpp:106] Creating Layer dl_xuv
I0529 22:28:43.092238 23976 net.cpp:454] dl_xuv <- concat_xuv
I0529 22:28:43.092252 23976 net.cpp:411] dl_xuv -> dl_xuv
I0529 22:28:43.093287 23976 net.cpp:150] Setting up dl_xuv
I0529 22:28:43.093307 23976 net.cpp:157] Top shape: 100 98 (9800)
I0529 22:28:43.093319 23976 net.cpp:165] Memory required for data: 473528400
I0529 22:28:43.093334 23976 layer_factory.hpp:77] Creating layer relu_xuv
I0529 22:28:43.093348 23976 net.cpp:106] Creating Layer relu_xuv
I0529 22:28:43.093358 23976 net.cpp:454] relu_xuv <- dl_xuv
I0529 22:28:43.093370 23976 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0529 22:28:43.093911 23976 net.cpp:150] Setting up relu_xuv
I0529 22:28:43.093929 23976 net.cpp:157] Top shape: 100 98 (9800)
I0529 22:28:43.093938 23976 net.cpp:165] Memory required for data: 473567600
I0529 22:28:43.093950 23976 layer_factory.hpp:77] Creating layer drop_xuv
I0529 22:28:43.093962 23976 net.cpp:106] Creating Layer drop_xuv
I0529 22:28:43.093972 23976 net.cpp:454] drop_xuv <- dl_xuv
I0529 22:28:43.093984 23976 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0529 22:28:43.094032 23976 net.cpp:150] Setting up drop_xuv
I0529 22:28:43.094044 23976 net.cpp:157] Top shape: 100 98 (9800)
I0529 22:28:43.094054 23976 net.cpp:165] Memory required for data: 473606800
I0529 22:28:43.094064 23976 layer_factory.hpp:77] Creating layer output
I0529 22:28:43.094077 23976 net.cpp:106] Creating Layer output
I0529 22:28:43.094087 23976 net.cpp:454] output <- dl_xuv
I0529 22:28:43.094100 23976 net.cpp:411] output -> output
I0529 22:28:43.094339 23976 net.cpp:150] Setting up output
I0529 22:28:43.094353 23976 net.cpp:157] Top shape: 100 11 (1100)
I0529 22:28:43.094363 23976 net.cpp:165] Memory required for data: 473611200
I0529 22:28:43.094393 23976 layer_factory.hpp:77] Creating layer drop_output
I0529 22:28:43.094406 23976 net.cpp:106] Creating Layer drop_output
I0529 22:28:43.094415 23976 net.cpp:454] drop_output <- output
I0529 22:28:43.094429 23976 net.cpp:397] drop_output -> output (in-place)
I0529 22:28:43.094472 23976 net.cpp:150] Setting up drop_output
I0529 22:28:43.094485 23976 net.cpp:157] Top shape: 100 11 (1100)
I0529 22:28:43.094496 23976 net.cpp:165] Memory required for data: 473615600
I0529 22:28:43.094506 23976 layer_factory.hpp:77] Creating layer loss
I0529 22:28:43.094534 23976 net.cpp:106] Creating Layer loss
I0529 22:28:43.094544 23976 net.cpp:454] loss <- output
I0529 22:28:43.094555 23976 net.cpp:454] loss <- segments
I0529 22:28:43.094568 23976 net.cpp:411] loss -> loss
I0529 22:28:43.094586 23976 layer_factory.hpp:77] Creating layer loss
I0529 22:28:43.095088 23976 net.cpp:150] Setting up loss
I0529 22:28:43.095100 23976 net.cpp:157] Top shape: (1)
I0529 22:28:43.095110 23976 net.cpp:160]     with loss weight 1
I0529 22:28:43.095155 23976 net.cpp:165] Memory required for data: 473615604
I0529 22:28:43.095165 23976 net.cpp:226] loss needs backward computation.
I0529 22:28:43.095175 23976 net.cpp:226] drop_output needs backward computation.
I0529 22:28:43.095186 23976 net.cpp:226] output needs backward computation.
I0529 22:28:43.095196 23976 net.cpp:226] drop_xuv needs backward computation.
I0529 22:28:43.095207 23976 net.cpp:226] relu_xuv needs backward computation.
I0529 22:28:43.095216 23976 net.cpp:226] dl_xuv needs backward computation.
I0529 22:28:43.095227 23976 net.cpp:226] concat_xuv needs backward computation.
I0529 22:28:43.095238 23976 net.cpp:226] drop_v1 needs backward computation.
I0529 22:28:43.095248 23976 net.cpp:226] relu_v5 needs backward computation.
I0529 22:28:43.095257 23976 net.cpp:226] dl_v1 needs backward computation.
I0529 22:28:43.095268 23976 net.cpp:226] pool_v4 needs backward computation.
I0529 22:28:43.095278 23976 net.cpp:226] relu_v4 needs backward computation.
I0529 22:28:43.095288 23976 net.cpp:226] conv_v4 needs backward computation.
I0529 22:28:43.095299 23976 net.cpp:226] pool_v3 needs backward computation.
I0529 22:28:43.095310 23976 net.cpp:226] relu_v3 needs backward computation.
I0529 22:28:43.095320 23976 net.cpp:226] conv_v3 needs backward computation.
I0529 22:28:43.095331 23976 net.cpp:226] pool_v2 needs backward computation.
I0529 22:28:43.095341 23976 net.cpp:226] relu_v2 needs backward computation.
I0529 22:28:43.095351 23976 net.cpp:226] conv_v2 needs backward computation.
I0529 22:28:43.095362 23976 net.cpp:226] pool_v1 needs backward computation.
I0529 22:28:43.095372 23976 net.cpp:226] relu_v1 needs backward computation.
I0529 22:28:43.095382 23976 net.cpp:226] conv_v1 needs backward computation.
I0529 22:28:43.095393 23976 net.cpp:226] drop_u1 needs backward computation.
I0529 22:28:43.095403 23976 net.cpp:226] relu_u5 needs backward computation.
I0529 22:28:43.095413 23976 net.cpp:226] dl_u1 needs backward computation.
I0529 22:28:43.095424 23976 net.cpp:226] pool_u4 needs backward computation.
I0529 22:28:43.095435 23976 net.cpp:226] relu_u4 needs backward computation.
I0529 22:28:43.095446 23976 net.cpp:226] conv_u4 needs backward computation.
I0529 22:28:43.095458 23976 net.cpp:226] pool_u3 needs backward computation.
I0529 22:28:43.095468 23976 net.cpp:226] relu_u3 needs backward computation.
I0529 22:28:43.095477 23976 net.cpp:226] conv_u3 needs backward computation.
I0529 22:28:43.095489 23976 net.cpp:226] pool_u2 needs backward computation.
I0529 22:28:43.095499 23976 net.cpp:226] relu_u2 needs backward computation.
I0529 22:28:43.095510 23976 net.cpp:226] conv_u2 needs backward computation.
I0529 22:28:43.095520 23976 net.cpp:226] pool_u1 needs backward computation.
I0529 22:28:43.095531 23976 net.cpp:226] relu_u1 needs backward computation.
I0529 22:28:43.095542 23976 net.cpp:226] conv_u1 needs backward computation.
I0529 22:28:43.095553 23976 net.cpp:226] drop_x1 needs backward computation.
I0529 22:28:43.095564 23976 net.cpp:226] relu_x5 needs backward computation.
I0529 22:28:43.095574 23976 net.cpp:226] dl_x1 needs backward computation.
I0529 22:28:43.095585 23976 net.cpp:226] pool_x4 needs backward computation.
I0529 22:28:43.095595 23976 net.cpp:226] relu_x4 needs backward computation.
I0529 22:28:43.095605 23976 net.cpp:226] conv_x4 needs backward computation.
I0529 22:28:43.095616 23976 net.cpp:226] pool_x3 needs backward computation.
I0529 22:28:43.095628 23976 net.cpp:226] relu_x3 needs backward computation.
I0529 22:28:43.095638 23976 net.cpp:226] conv_x3 needs backward computation.
I0529 22:28:43.095655 23976 net.cpp:226] pool_x2 needs backward computation.
I0529 22:28:43.095667 23976 net.cpp:226] relu_x2 needs backward computation.
I0529 22:28:43.095679 23976 net.cpp:226] conv_x2 needs backward computation.
I0529 22:28:43.095690 23976 net.cpp:226] pool_x1 needs backward computation.
I0529 22:28:43.095700 23976 net.cpp:226] relu_x1 needs backward computation.
I0529 22:28:43.095710 23976 net.cpp:226] conv_x1 needs backward computation.
I0529 22:28:43.095723 23976 net.cpp:228] data does not need backward computation.
I0529 22:28:43.095733 23976 net.cpp:270] This network produces output loss
I0529 22:28:43.095778 23976 net.cpp:283] Network initialization done.
I0529 22:28:43.098625 23976 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_lr001_2016-05-29T18.24.51.314592.prototxt
I0529 22:28:43.098757 23976 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0529 22:28:43.099548 23976 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "output"
  bottom: "segments"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0529 22:28:43.099926 23976 layer_factory.hpp:77] Creating layer data
I0529 22:28:43.099942 23976 net.cpp:106] Creating Layer data
I0529 22:28:43.099956 23976 net.cpp:411] data -> hits-x
I0529 22:28:43.099972 23976 net.cpp:411] data -> hits-u
I0529 22:28:43.099988 23976 net.cpp:411] data -> hits-v
I0529 22:28:43.100003 23976 net.cpp:411] data -> segments
I0529 22:28:43.100018 23976 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist
I0529 22:28:43.112315 23976 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0529 22:29:47.294831 23976 net.cpp:150] Setting up data
I0529 22:29:47.294991 23976 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 22:29:47.295006 23976 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 22:29:47.295020 23976 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 22:29:47.295032 23976 net.cpp:157] Top shape: 100 (100)
I0529 22:29:47.295042 23976 net.cpp:165] Memory required for data: 7620400
I0529 22:29:47.295055 23976 layer_factory.hpp:77] Creating layer segments_data_3_split
I0529 22:29:47.295083 23976 net.cpp:106] Creating Layer segments_data_3_split
I0529 22:29:47.295094 23976 net.cpp:454] segments_data_3_split <- segments
I0529 22:29:47.295109 23976 net.cpp:411] segments_data_3_split -> segments_data_3_split_0
I0529 22:29:47.295131 23976 net.cpp:411] segments_data_3_split -> segments_data_3_split_1
I0529 22:29:47.295207 23976 net.cpp:150] Setting up segments_data_3_split
I0529 22:29:47.295220 23976 net.cpp:157] Top shape: 100 (100)
I0529 22:29:47.295233 23976 net.cpp:157] Top shape: 100 (100)
I0529 22:29:47.295245 23976 net.cpp:165] Memory required for data: 7621200
I0529 22:29:47.295255 23976 layer_factory.hpp:77] Creating layer conv_x1
I0529 22:29:47.295279 23976 net.cpp:106] Creating Layer conv_x1
I0529 22:29:47.295289 23976 net.cpp:454] conv_x1 <- hits-x
I0529 22:29:47.295303 23976 net.cpp:411] conv_x1 -> conv_x1
I0529 22:29:47.297485 23976 net.cpp:150] Setting up conv_x1
I0529 22:29:47.297510 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:29:47.297521 23976 net.cpp:165] Memory required for data: 35269200
I0529 22:29:47.297543 23976 layer_factory.hpp:77] Creating layer relu_x1
I0529 22:29:47.297557 23976 net.cpp:106] Creating Layer relu_x1
I0529 22:29:47.297567 23976 net.cpp:454] relu_x1 <- conv_x1
I0529 22:29:47.297580 23976 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0529 22:29:47.298089 23976 net.cpp:150] Setting up relu_x1
I0529 22:29:47.298105 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:29:47.298115 23976 net.cpp:165] Memory required for data: 62917200
I0529 22:29:47.298125 23976 layer_factory.hpp:77] Creating layer pool_x1
I0529 22:29:47.298142 23976 net.cpp:106] Creating Layer pool_x1
I0529 22:29:47.298152 23976 net.cpp:454] pool_x1 <- conv_x1
I0529 22:29:47.298166 23976 net.cpp:411] pool_x1 -> pool_x1
I0529 22:29:47.298257 23976 net.cpp:150] Setting up pool_x1
I0529 22:29:47.298270 23976 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 22:29:47.298280 23976 net.cpp:165] Memory required for data: 76741200
I0529 22:29:47.298291 23976 layer_factory.hpp:77] Creating layer conv_x2
I0529 22:29:47.298308 23976 net.cpp:106] Creating Layer conv_x2
I0529 22:29:47.298319 23976 net.cpp:454] conv_x2 <- pool_x1
I0529 22:29:47.298333 23976 net.cpp:411] conv_x2 -> conv_x2
I0529 22:29:47.300204 23976 net.cpp:150] Setting up conv_x2
I0529 22:29:47.300222 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:29:47.300232 23976 net.cpp:165] Memory required for data: 96613200
I0529 22:29:47.300251 23976 layer_factory.hpp:77] Creating layer relu_x2
I0529 22:29:47.300266 23976 net.cpp:106] Creating Layer relu_x2
I0529 22:29:47.300276 23976 net.cpp:454] relu_x2 <- conv_x2
I0529 22:29:47.300288 23976 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0529 22:29:47.300793 23976 net.cpp:150] Setting up relu_x2
I0529 22:29:47.300809 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:29:47.300820 23976 net.cpp:165] Memory required for data: 116485200
I0529 22:29:47.300830 23976 layer_factory.hpp:77] Creating layer pool_x2
I0529 22:29:47.300844 23976 net.cpp:106] Creating Layer pool_x2
I0529 22:29:47.300854 23976 net.cpp:454] pool_x2 <- conv_x2
I0529 22:29:47.300868 23976 net.cpp:411] pool_x2 -> pool_x2
I0529 22:29:47.300945 23976 net.cpp:150] Setting up pool_x2
I0529 22:29:47.300959 23976 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 22:29:47.300969 23976 net.cpp:165] Memory required for data: 126421200
I0529 22:29:47.300979 23976 layer_factory.hpp:77] Creating layer conv_x3
I0529 22:29:47.300999 23976 net.cpp:106] Creating Layer conv_x3
I0529 22:29:47.301010 23976 net.cpp:454] conv_x3 <- pool_x2
I0529 22:29:47.301025 23976 net.cpp:411] conv_x3 -> conv_x3
I0529 22:29:47.303269 23976 net.cpp:150] Setting up conv_x3
I0529 22:29:47.303292 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:29:47.303305 23976 net.cpp:165] Memory required for data: 137262800
I0529 22:29:47.303324 23976 layer_factory.hpp:77] Creating layer relu_x3
I0529 22:29:47.303338 23976 net.cpp:106] Creating Layer relu_x3
I0529 22:29:47.303349 23976 net.cpp:454] relu_x3 <- conv_x3
I0529 22:29:47.303360 23976 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0529 22:29:47.303704 23976 net.cpp:150] Setting up relu_x3
I0529 22:29:47.303719 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:29:47.303728 23976 net.cpp:165] Memory required for data: 148104400
I0529 22:29:47.303737 23976 layer_factory.hpp:77] Creating layer pool_x3
I0529 22:29:47.303751 23976 net.cpp:106] Creating Layer pool_x3
I0529 22:29:47.303761 23976 net.cpp:454] pool_x3 <- conv_x3
I0529 22:29:47.303774 23976 net.cpp:411] pool_x3 -> pool_x3
I0529 22:29:47.303853 23976 net.cpp:150] Setting up pool_x3
I0529 22:29:47.303866 23976 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 22:29:47.303875 23976 net.cpp:165] Memory required for data: 153525200
I0529 22:29:47.303885 23976 layer_factory.hpp:77] Creating layer conv_x4
I0529 22:29:47.303902 23976 net.cpp:106] Creating Layer conv_x4
I0529 22:29:47.303913 23976 net.cpp:454] conv_x4 <- pool_x3
I0529 22:29:47.303927 23976 net.cpp:411] conv_x4 -> conv_x4
I0529 22:29:47.306080 23976 net.cpp:150] Setting up conv_x4
I0529 22:29:47.306103 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:29:47.306115 23976 net.cpp:165] Memory required for data: 157154000
I0529 22:29:47.306131 23976 layer_factory.hpp:77] Creating layer relu_x4
I0529 22:29:47.306144 23976 net.cpp:106] Creating Layer relu_x4
I0529 22:29:47.306154 23976 net.cpp:454] relu_x4 <- conv_x4
I0529 22:29:47.306167 23976 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0529 22:29:47.306666 23976 net.cpp:150] Setting up relu_x4
I0529 22:29:47.306682 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:29:47.306692 23976 net.cpp:165] Memory required for data: 160782800
I0529 22:29:47.306704 23976 layer_factory.hpp:77] Creating layer pool_x4
I0529 22:29:47.306717 23976 net.cpp:106] Creating Layer pool_x4
I0529 22:29:47.306727 23976 net.cpp:454] pool_x4 <- conv_x4
I0529 22:29:47.306740 23976 net.cpp:411] pool_x4 -> pool_x4
I0529 22:29:47.306819 23976 net.cpp:150] Setting up pool_x4
I0529 22:29:47.306833 23976 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 22:29:47.306843 23976 net.cpp:165] Memory required for data: 162597200
I0529 22:29:47.306854 23976 layer_factory.hpp:77] Creating layer dl_x1
I0529 22:29:47.306869 23976 net.cpp:106] Creating Layer dl_x1
I0529 22:29:47.306879 23976 net.cpp:454] dl_x1 <- pool_x4
I0529 22:29:47.306892 23976 net.cpp:411] dl_x1 -> dl_x1
I0529 22:29:47.322875 23976 net.cpp:150] Setting up dl_x1
I0529 22:29:47.322903 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.322916 23976 net.cpp:165] Memory required for data: 162675600
I0529 22:29:47.322938 23976 layer_factory.hpp:77] Creating layer relu_x5
I0529 22:29:47.322954 23976 net.cpp:106] Creating Layer relu_x5
I0529 22:29:47.322964 23976 net.cpp:454] relu_x5 <- dl_x1
I0529 22:29:47.322983 23976 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0529 22:29:47.323339 23976 net.cpp:150] Setting up relu_x5
I0529 22:29:47.323354 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.323364 23976 net.cpp:165] Memory required for data: 162754000
I0529 22:29:47.323374 23976 layer_factory.hpp:77] Creating layer drop_x1
I0529 22:29:47.323392 23976 net.cpp:106] Creating Layer drop_x1
I0529 22:29:47.323403 23976 net.cpp:454] drop_x1 <- dl_x1
I0529 22:29:47.323416 23976 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0529 22:29:47.323465 23976 net.cpp:150] Setting up drop_x1
I0529 22:29:47.323479 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.323489 23976 net.cpp:165] Memory required for data: 162832400
I0529 22:29:47.323499 23976 layer_factory.hpp:77] Creating layer conv_u1
I0529 22:29:47.323518 23976 net.cpp:106] Creating Layer conv_u1
I0529 22:29:47.323542 23976 net.cpp:454] conv_u1 <- hits-u
I0529 22:29:47.323559 23976 net.cpp:411] conv_u1 -> conv_u1
I0529 22:29:47.325564 23976 net.cpp:150] Setting up conv_u1
I0529 22:29:47.325587 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:29:47.325599 23976 net.cpp:165] Memory required for data: 190480400
I0529 22:29:47.325615 23976 layer_factory.hpp:77] Creating layer relu_u1
I0529 22:29:47.325629 23976 net.cpp:106] Creating Layer relu_u1
I0529 22:29:47.325639 23976 net.cpp:454] relu_u1 <- conv_u1
I0529 22:29:47.325652 23976 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0529 22:29:47.325986 23976 net.cpp:150] Setting up relu_u1
I0529 22:29:47.326000 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:29:47.326010 23976 net.cpp:165] Memory required for data: 218128400
I0529 22:29:47.326020 23976 layer_factory.hpp:77] Creating layer pool_u1
I0529 22:29:47.326035 23976 net.cpp:106] Creating Layer pool_u1
I0529 22:29:47.326045 23976 net.cpp:454] pool_u1 <- conv_u1
I0529 22:29:47.326058 23976 net.cpp:411] pool_u1 -> pool_u1
I0529 22:29:47.326143 23976 net.cpp:150] Setting up pool_u1
I0529 22:29:47.326156 23976 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 22:29:47.326166 23976 net.cpp:165] Memory required for data: 231952400
I0529 22:29:47.326174 23976 layer_factory.hpp:77] Creating layer conv_u2
I0529 22:29:47.326192 23976 net.cpp:106] Creating Layer conv_u2
I0529 22:29:47.326202 23976 net.cpp:454] conv_u2 <- pool_u1
I0529 22:29:47.326217 23976 net.cpp:411] conv_u2 -> conv_u2
I0529 22:29:47.328202 23976 net.cpp:150] Setting up conv_u2
I0529 22:29:47.328218 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:29:47.328229 23976 net.cpp:165] Memory required for data: 251824400
I0529 22:29:47.328245 23976 layer_factory.hpp:77] Creating layer relu_u2
I0529 22:29:47.328259 23976 net.cpp:106] Creating Layer relu_u2
I0529 22:29:47.328269 23976 net.cpp:454] relu_u2 <- conv_u2
I0529 22:29:47.328282 23976 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0529 22:29:47.328788 23976 net.cpp:150] Setting up relu_u2
I0529 22:29:47.328804 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:29:47.328814 23976 net.cpp:165] Memory required for data: 271696400
I0529 22:29:47.328824 23976 layer_factory.hpp:77] Creating layer pool_u2
I0529 22:29:47.328837 23976 net.cpp:106] Creating Layer pool_u2
I0529 22:29:47.328847 23976 net.cpp:454] pool_u2 <- conv_u2
I0529 22:29:47.328861 23976 net.cpp:411] pool_u2 -> pool_u2
I0529 22:29:47.328939 23976 net.cpp:150] Setting up pool_u2
I0529 22:29:47.328953 23976 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 22:29:47.328964 23976 net.cpp:165] Memory required for data: 281632400
I0529 22:29:47.328974 23976 layer_factory.hpp:77] Creating layer conv_u3
I0529 22:29:47.328994 23976 net.cpp:106] Creating Layer conv_u3
I0529 22:29:47.329004 23976 net.cpp:454] conv_u3 <- pool_u2
I0529 22:29:47.329018 23976 net.cpp:411] conv_u3 -> conv_u3
I0529 22:29:47.331099 23976 net.cpp:150] Setting up conv_u3
I0529 22:29:47.331120 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:29:47.331133 23976 net.cpp:165] Memory required for data: 292474000
I0529 22:29:47.331149 23976 layer_factory.hpp:77] Creating layer relu_u3
I0529 22:29:47.331163 23976 net.cpp:106] Creating Layer relu_u3
I0529 22:29:47.331173 23976 net.cpp:454] relu_u3 <- conv_u3
I0529 22:29:47.331187 23976 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0529 22:29:47.331513 23976 net.cpp:150] Setting up relu_u3
I0529 22:29:47.331527 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:29:47.331538 23976 net.cpp:165] Memory required for data: 303315600
I0529 22:29:47.331548 23976 layer_factory.hpp:77] Creating layer pool_u3
I0529 22:29:47.331562 23976 net.cpp:106] Creating Layer pool_u3
I0529 22:29:47.331571 23976 net.cpp:454] pool_u3 <- conv_u3
I0529 22:29:47.331584 23976 net.cpp:411] pool_u3 -> pool_u3
I0529 22:29:47.331661 23976 net.cpp:150] Setting up pool_u3
I0529 22:29:47.331676 23976 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 22:29:47.331684 23976 net.cpp:165] Memory required for data: 308736400
I0529 22:29:47.331707 23976 layer_factory.hpp:77] Creating layer conv_u4
I0529 22:29:47.331725 23976 net.cpp:106] Creating Layer conv_u4
I0529 22:29:47.331737 23976 net.cpp:454] conv_u4 <- pool_u3
I0529 22:29:47.331751 23976 net.cpp:411] conv_u4 -> conv_u4
I0529 22:29:47.333951 23976 net.cpp:150] Setting up conv_u4
I0529 22:29:47.333974 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:29:47.333986 23976 net.cpp:165] Memory required for data: 312365200
I0529 22:29:47.334008 23976 layer_factory.hpp:77] Creating layer relu_u4
I0529 22:29:47.334022 23976 net.cpp:106] Creating Layer relu_u4
I0529 22:29:47.334033 23976 net.cpp:454] relu_u4 <- conv_u4
I0529 22:29:47.334045 23976 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0529 22:29:47.334386 23976 net.cpp:150] Setting up relu_u4
I0529 22:29:47.334400 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:29:47.334411 23976 net.cpp:165] Memory required for data: 315994000
I0529 22:29:47.334421 23976 layer_factory.hpp:77] Creating layer pool_u4
I0529 22:29:47.334434 23976 net.cpp:106] Creating Layer pool_u4
I0529 22:29:47.334444 23976 net.cpp:454] pool_u4 <- conv_u4
I0529 22:29:47.334456 23976 net.cpp:411] pool_u4 -> pool_u4
I0529 22:29:47.334533 23976 net.cpp:150] Setting up pool_u4
I0529 22:29:47.334547 23976 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 22:29:47.334558 23976 net.cpp:165] Memory required for data: 317808400
I0529 22:29:47.334566 23976 layer_factory.hpp:77] Creating layer dl_u1
I0529 22:29:47.334581 23976 net.cpp:106] Creating Layer dl_u1
I0529 22:29:47.334594 23976 net.cpp:454] dl_u1 <- pool_u4
I0529 22:29:47.334607 23976 net.cpp:411] dl_u1 -> dl_u1
I0529 22:29:47.350976 23976 net.cpp:150] Setting up dl_u1
I0529 22:29:47.351002 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.351016 23976 net.cpp:165] Memory required for data: 317886800
I0529 22:29:47.351032 23976 layer_factory.hpp:77] Creating layer relu_u5
I0529 22:29:47.351047 23976 net.cpp:106] Creating Layer relu_u5
I0529 22:29:47.351058 23976 net.cpp:454] relu_u5 <- dl_u1
I0529 22:29:47.351070 23976 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0529 22:29:47.351665 23976 net.cpp:150] Setting up relu_u5
I0529 22:29:47.351686 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.351699 23976 net.cpp:165] Memory required for data: 317965200
I0529 22:29:47.351709 23976 layer_factory.hpp:77] Creating layer drop_u1
I0529 22:29:47.351723 23976 net.cpp:106] Creating Layer drop_u1
I0529 22:29:47.351737 23976 net.cpp:454] drop_u1 <- dl_u1
I0529 22:29:47.351750 23976 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0529 22:29:47.351799 23976 net.cpp:150] Setting up drop_u1
I0529 22:29:47.351812 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.351822 23976 net.cpp:165] Memory required for data: 318043600
I0529 22:29:47.351832 23976 layer_factory.hpp:77] Creating layer conv_v1
I0529 22:29:47.351861 23976 net.cpp:106] Creating Layer conv_v1
I0529 22:29:47.351871 23976 net.cpp:454] conv_v1 <- hits-v
I0529 22:29:47.351886 23976 net.cpp:411] conv_v1 -> conv_v1
I0529 22:29:47.353837 23976 net.cpp:150] Setting up conv_v1
I0529 22:29:47.353860 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:29:47.353871 23976 net.cpp:165] Memory required for data: 345691600
I0529 22:29:47.353888 23976 layer_factory.hpp:77] Creating layer relu_v1
I0529 22:29:47.353901 23976 net.cpp:106] Creating Layer relu_v1
I0529 22:29:47.353911 23976 net.cpp:454] relu_v1 <- conv_v1
I0529 22:29:47.353924 23976 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0529 22:29:47.354264 23976 net.cpp:150] Setting up relu_v1
I0529 22:29:47.354277 23976 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 22:29:47.354288 23976 net.cpp:165] Memory required for data: 373339600
I0529 22:29:47.354298 23976 layer_factory.hpp:77] Creating layer pool_v1
I0529 22:29:47.354311 23976 net.cpp:106] Creating Layer pool_v1
I0529 22:29:47.354321 23976 net.cpp:454] pool_v1 <- conv_v1
I0529 22:29:47.354336 23976 net.cpp:411] pool_v1 -> pool_v1
I0529 22:29:47.354416 23976 net.cpp:150] Setting up pool_v1
I0529 22:29:47.354444 23976 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 22:29:47.354454 23976 net.cpp:165] Memory required for data: 387163600
I0529 22:29:47.354463 23976 layer_factory.hpp:77] Creating layer conv_v2
I0529 22:29:47.354481 23976 net.cpp:106] Creating Layer conv_v2
I0529 22:29:47.354491 23976 net.cpp:454] conv_v2 <- pool_v1
I0529 22:29:47.354506 23976 net.cpp:411] conv_v2 -> conv_v2
I0529 22:29:47.356554 23976 net.cpp:150] Setting up conv_v2
I0529 22:29:47.356576 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:29:47.356587 23976 net.cpp:165] Memory required for data: 407035600
I0529 22:29:47.356603 23976 layer_factory.hpp:77] Creating layer relu_v2
I0529 22:29:47.356616 23976 net.cpp:106] Creating Layer relu_v2
I0529 22:29:47.356627 23976 net.cpp:454] relu_v2 <- conv_v2
I0529 22:29:47.356640 23976 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0529 22:29:47.357143 23976 net.cpp:150] Setting up relu_v2
I0529 22:29:47.357161 23976 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 22:29:47.357170 23976 net.cpp:165] Memory required for data: 426907600
I0529 22:29:47.357180 23976 layer_factory.hpp:77] Creating layer pool_v2
I0529 22:29:47.357193 23976 net.cpp:106] Creating Layer pool_v2
I0529 22:29:47.357203 23976 net.cpp:454] pool_v2 <- conv_v2
I0529 22:29:47.357216 23976 net.cpp:411] pool_v2 -> pool_v2
I0529 22:29:47.357297 23976 net.cpp:150] Setting up pool_v2
I0529 22:29:47.357311 23976 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 22:29:47.357321 23976 net.cpp:165] Memory required for data: 436843600
I0529 22:29:47.357331 23976 layer_factory.hpp:77] Creating layer conv_v3
I0529 22:29:47.357349 23976 net.cpp:106] Creating Layer conv_v3
I0529 22:29:47.357360 23976 net.cpp:454] conv_v3 <- pool_v2
I0529 22:29:47.357374 23976 net.cpp:411] conv_v3 -> conv_v3
I0529 22:29:47.359462 23976 net.cpp:150] Setting up conv_v3
I0529 22:29:47.359483 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:29:47.359495 23976 net.cpp:165] Memory required for data: 447685200
I0529 22:29:47.359510 23976 layer_factory.hpp:77] Creating layer relu_v3
I0529 22:29:47.359524 23976 net.cpp:106] Creating Layer relu_v3
I0529 22:29:47.359535 23976 net.cpp:454] relu_v3 <- conv_v3
I0529 22:29:47.359549 23976 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0529 22:29:47.360054 23976 net.cpp:150] Setting up relu_v3
I0529 22:29:47.360070 23976 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 22:29:47.360080 23976 net.cpp:165] Memory required for data: 458526800
I0529 22:29:47.360090 23976 layer_factory.hpp:77] Creating layer pool_v3
I0529 22:29:47.360105 23976 net.cpp:106] Creating Layer pool_v3
I0529 22:29:47.360116 23976 net.cpp:454] pool_v3 <- conv_v3
I0529 22:29:47.360128 23976 net.cpp:411] pool_v3 -> pool_v3
I0529 22:29:47.360208 23976 net.cpp:150] Setting up pool_v3
I0529 22:29:47.360221 23976 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 22:29:47.360231 23976 net.cpp:165] Memory required for data: 463947600
I0529 22:29:47.360242 23976 layer_factory.hpp:77] Creating layer conv_v4
I0529 22:29:47.360258 23976 net.cpp:106] Creating Layer conv_v4
I0529 22:29:47.360270 23976 net.cpp:454] conv_v4 <- pool_v3
I0529 22:29:47.360283 23976 net.cpp:411] conv_v4 -> conv_v4
I0529 22:29:47.362481 23976 net.cpp:150] Setting up conv_v4
I0529 22:29:47.362504 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:29:47.362516 23976 net.cpp:165] Memory required for data: 467576400
I0529 22:29:47.362532 23976 layer_factory.hpp:77] Creating layer relu_v4
I0529 22:29:47.362546 23976 net.cpp:106] Creating Layer relu_v4
I0529 22:29:47.362556 23976 net.cpp:454] relu_v4 <- conv_v4
I0529 22:29:47.362570 23976 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0529 22:29:47.362901 23976 net.cpp:150] Setting up relu_v4
I0529 22:29:47.362915 23976 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 22:29:47.362926 23976 net.cpp:165] Memory required for data: 471205200
I0529 22:29:47.362936 23976 layer_factory.hpp:77] Creating layer pool_v4
I0529 22:29:47.362948 23976 net.cpp:106] Creating Layer pool_v4
I0529 22:29:47.362970 23976 net.cpp:454] pool_v4 <- conv_v4
I0529 22:29:47.362984 23976 net.cpp:411] pool_v4 -> pool_v4
I0529 22:29:47.363062 23976 net.cpp:150] Setting up pool_v4
I0529 22:29:47.363076 23976 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 22:29:47.363087 23976 net.cpp:165] Memory required for data: 473019600
I0529 22:29:47.363097 23976 layer_factory.hpp:77] Creating layer dl_v1
I0529 22:29:47.363112 23976 net.cpp:106] Creating Layer dl_v1
I0529 22:29:47.363122 23976 net.cpp:454] dl_v1 <- pool_v4
I0529 22:29:47.363137 23976 net.cpp:411] dl_v1 -> dl_v1
I0529 22:29:47.379487 23976 net.cpp:150] Setting up dl_v1
I0529 22:29:47.379518 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.379528 23976 net.cpp:165] Memory required for data: 473098000
I0529 22:29:47.379544 23976 layer_factory.hpp:77] Creating layer relu_v5
I0529 22:29:47.379559 23976 net.cpp:106] Creating Layer relu_v5
I0529 22:29:47.379570 23976 net.cpp:454] relu_v5 <- dl_v1
I0529 22:29:47.379583 23976 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0529 22:29:47.380236 23976 net.cpp:150] Setting up relu_v5
I0529 22:29:47.380259 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.380271 23976 net.cpp:165] Memory required for data: 473176400
I0529 22:29:47.380281 23976 layer_factory.hpp:77] Creating layer drop_v1
I0529 22:29:47.380295 23976 net.cpp:106] Creating Layer drop_v1
I0529 22:29:47.380306 23976 net.cpp:454] drop_v1 <- dl_v1
I0529 22:29:47.380319 23976 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0529 22:29:47.380369 23976 net.cpp:150] Setting up drop_v1
I0529 22:29:47.380383 23976 net.cpp:157] Top shape: 100 196 (19600)
I0529 22:29:47.380393 23976 net.cpp:165] Memory required for data: 473254800
I0529 22:29:47.380403 23976 layer_factory.hpp:77] Creating layer concat_xuv
I0529 22:29:47.380419 23976 net.cpp:106] Creating Layer concat_xuv
I0529 22:29:47.380429 23976 net.cpp:454] concat_xuv <- dl_x1
I0529 22:29:47.380440 23976 net.cpp:454] concat_xuv <- dl_u1
I0529 22:29:47.380452 23976 net.cpp:454] concat_xuv <- dl_v1
I0529 22:29:47.380465 23976 net.cpp:411] concat_xuv -> concat_xuv
I0529 22:29:47.380516 23976 net.cpp:150] Setting up concat_xuv
I0529 22:29:47.380528 23976 net.cpp:157] Top shape: 100 588 (58800)
I0529 22:29:47.380538 23976 net.cpp:165] Memory required for data: 473490000
I0529 22:29:47.380548 23976 layer_factory.hpp:77] Creating layer dl_xuv
I0529 22:29:47.380563 23976 net.cpp:106] Creating Layer dl_xuv
I0529 22:29:47.380573 23976 net.cpp:454] dl_xuv <- concat_xuv
I0529 22:29:47.380586 23976 net.cpp:411] dl_xuv -> dl_xuv
I0529 22:29:47.381630 23976 net.cpp:150] Setting up dl_xuv
I0529 22:29:47.381649 23976 net.cpp:157] Top shape: 100 98 (9800)
I0529 22:29:47.381662 23976 net.cpp:165] Memory required for data: 473529200
I0529 22:29:47.381677 23976 layer_factory.hpp:77] Creating layer relu_xuv
I0529 22:29:47.381690 23976 net.cpp:106] Creating Layer relu_xuv
I0529 22:29:47.381700 23976 net.cpp:454] relu_xuv <- dl_xuv
I0529 22:29:47.381713 23976 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0529 22:29:47.382041 23976 net.cpp:150] Setting up relu_xuv
I0529 22:29:47.382056 23976 net.cpp:157] Top shape: 100 98 (9800)
I0529 22:29:47.382066 23976 net.cpp:165] Memory required for data: 473568400
I0529 22:29:47.382076 23976 layer_factory.hpp:77] Creating layer drop_xuv
I0529 22:29:47.382089 23976 net.cpp:106] Creating Layer drop_xuv
I0529 22:29:47.382099 23976 net.cpp:454] drop_xuv <- dl_xuv
I0529 22:29:47.382112 23976 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0529 22:29:47.382159 23976 net.cpp:150] Setting up drop_xuv
I0529 22:29:47.382172 23976 net.cpp:157] Top shape: 100 98 (9800)
I0529 22:29:47.382182 23976 net.cpp:165] Memory required for data: 473607600
I0529 22:29:47.382191 23976 layer_factory.hpp:77] Creating layer output
I0529 22:29:47.382205 23976 net.cpp:106] Creating Layer output
I0529 22:29:47.382215 23976 net.cpp:454] output <- dl_xuv
I0529 22:29:47.382236 23976 net.cpp:411] output -> output
I0529 22:29:47.382480 23976 net.cpp:150] Setting up output
I0529 22:29:47.382494 23976 net.cpp:157] Top shape: 100 11 (1100)
I0529 22:29:47.382516 23976 net.cpp:165] Memory required for data: 473612000
I0529 22:29:47.382550 23976 layer_factory.hpp:77] Creating layer drop_output
I0529 22:29:47.382563 23976 net.cpp:106] Creating Layer drop_output
I0529 22:29:47.382575 23976 net.cpp:454] drop_output <- output
I0529 22:29:47.382587 23976 net.cpp:397] drop_output -> output (in-place)
I0529 22:29:47.382633 23976 net.cpp:150] Setting up drop_output
I0529 22:29:47.382647 23976 net.cpp:157] Top shape: 100 11 (1100)
I0529 22:29:47.382657 23976 net.cpp:165] Memory required for data: 473616400
I0529 22:29:47.382665 23976 layer_factory.hpp:77] Creating layer output_drop_output_0_split
I0529 22:29:47.382679 23976 net.cpp:106] Creating Layer output_drop_output_0_split
I0529 22:29:47.382690 23976 net.cpp:454] output_drop_output_0_split <- output
I0529 22:29:47.382704 23976 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_0
I0529 22:29:47.382719 23976 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_1
I0529 22:29:47.382794 23976 net.cpp:150] Setting up output_drop_output_0_split
I0529 22:29:47.382807 23976 net.cpp:157] Top shape: 100 11 (1100)
I0529 22:29:47.382819 23976 net.cpp:157] Top shape: 100 11 (1100)
I0529 22:29:47.382828 23976 net.cpp:165] Memory required for data: 473625200
I0529 22:29:47.382838 23976 layer_factory.hpp:77] Creating layer accuracy
I0529 22:29:47.382859 23976 net.cpp:106] Creating Layer accuracy
I0529 22:29:47.382869 23976 net.cpp:454] accuracy <- output_drop_output_0_split_0
I0529 22:29:47.382881 23976 net.cpp:454] accuracy <- segments_data_3_split_0
I0529 22:29:47.382894 23976 net.cpp:411] accuracy -> accuracy
I0529 22:29:47.382918 23976 net.cpp:150] Setting up accuracy
I0529 22:29:47.382930 23976 net.cpp:157] Top shape: (1)
I0529 22:29:47.382939 23976 net.cpp:165] Memory required for data: 473625204
I0529 22:29:47.382949 23976 layer_factory.hpp:77] Creating layer loss
I0529 22:29:47.382964 23976 net.cpp:106] Creating Layer loss
I0529 22:29:47.382973 23976 net.cpp:454] loss <- output_drop_output_0_split_1
I0529 22:29:47.382984 23976 net.cpp:454] loss <- segments_data_3_split_1
I0529 22:29:47.382998 23976 net.cpp:411] loss -> loss
I0529 22:29:47.383018 23976 layer_factory.hpp:77] Creating layer loss
I0529 22:29:47.383735 23976 net.cpp:150] Setting up loss
I0529 22:29:47.383756 23976 net.cpp:157] Top shape: (1)
I0529 22:29:47.383766 23976 net.cpp:160]     with loss weight 1
I0529 22:29:47.383785 23976 net.cpp:165] Memory required for data: 473625208
I0529 22:29:47.383795 23976 net.cpp:226] loss needs backward computation.
I0529 22:29:47.383807 23976 net.cpp:228] accuracy does not need backward computation.
I0529 22:29:47.383818 23976 net.cpp:226] output_drop_output_0_split needs backward computation.
I0529 22:29:47.383828 23976 net.cpp:226] drop_output needs backward computation.
I0529 22:29:47.383838 23976 net.cpp:226] output needs backward computation.
I0529 22:29:47.383849 23976 net.cpp:226] drop_xuv needs backward computation.
I0529 22:29:47.383859 23976 net.cpp:226] relu_xuv needs backward computation.
I0529 22:29:47.383869 23976 net.cpp:226] dl_xuv needs backward computation.
I0529 22:29:47.383880 23976 net.cpp:226] concat_xuv needs backward computation.
I0529 22:29:47.383893 23976 net.cpp:226] drop_v1 needs backward computation.
I0529 22:29:47.383903 23976 net.cpp:226] relu_v5 needs backward computation.
I0529 22:29:47.383913 23976 net.cpp:226] dl_v1 needs backward computation.
I0529 22:29:47.383924 23976 net.cpp:226] pool_v4 needs backward computation.
I0529 22:29:47.383934 23976 net.cpp:226] relu_v4 needs backward computation.
I0529 22:29:47.383944 23976 net.cpp:226] conv_v4 needs backward computation.
I0529 22:29:47.383955 23976 net.cpp:226] pool_v3 needs backward computation.
I0529 22:29:47.383965 23976 net.cpp:226] relu_v3 needs backward computation.
I0529 22:29:47.383975 23976 net.cpp:226] conv_v3 needs backward computation.
I0529 22:29:47.383985 23976 net.cpp:226] pool_v2 needs backward computation.
I0529 22:29:47.383996 23976 net.cpp:226] relu_v2 needs backward computation.
I0529 22:29:47.384016 23976 net.cpp:226] conv_v2 needs backward computation.
I0529 22:29:47.384027 23976 net.cpp:226] pool_v1 needs backward computation.
I0529 22:29:47.384037 23976 net.cpp:226] relu_v1 needs backward computation.
I0529 22:29:47.384047 23976 net.cpp:226] conv_v1 needs backward computation.
I0529 22:29:47.384059 23976 net.cpp:226] drop_u1 needs backward computation.
I0529 22:29:47.384069 23976 net.cpp:226] relu_u5 needs backward computation.
I0529 22:29:47.384079 23976 net.cpp:226] dl_u1 needs backward computation.
I0529 22:29:47.384090 23976 net.cpp:226] pool_u4 needs backward computation.
I0529 22:29:47.384102 23976 net.cpp:226] relu_u4 needs backward computation.
I0529 22:29:47.384110 23976 net.cpp:226] conv_u4 needs backward computation.
I0529 22:29:47.384121 23976 net.cpp:226] pool_u3 needs backward computation.
I0529 22:29:47.384132 23976 net.cpp:226] relu_u3 needs backward computation.
I0529 22:29:47.384143 23976 net.cpp:226] conv_u3 needs backward computation.
I0529 22:29:47.384153 23976 net.cpp:226] pool_u2 needs backward computation.
I0529 22:29:47.384165 23976 net.cpp:226] relu_u2 needs backward computation.
I0529 22:29:47.384174 23976 net.cpp:226] conv_u2 needs backward computation.
I0529 22:29:47.384186 23976 net.cpp:226] pool_u1 needs backward computation.
I0529 22:29:47.384196 23976 net.cpp:226] relu_u1 needs backward computation.
I0529 22:29:47.384207 23976 net.cpp:226] conv_u1 needs backward computation.
I0529 22:29:47.384218 23976 net.cpp:226] drop_x1 needs backward computation.
I0529 22:29:47.384229 23976 net.cpp:226] relu_x5 needs backward computation.
I0529 22:29:47.384240 23976 net.cpp:226] dl_x1 needs backward computation.
I0529 22:29:47.384251 23976 net.cpp:226] pool_x4 needs backward computation.
I0529 22:29:47.384263 23976 net.cpp:226] relu_x4 needs backward computation.
I0529 22:29:47.384273 23976 net.cpp:226] conv_x4 needs backward computation.
I0529 22:29:47.384284 23976 net.cpp:226] pool_x3 needs backward computation.
I0529 22:29:47.384294 23976 net.cpp:226] relu_x3 needs backward computation.
I0529 22:29:47.384305 23976 net.cpp:226] conv_x3 needs backward computation.
I0529 22:29:47.384315 23976 net.cpp:226] pool_x2 needs backward computation.
I0529 22:29:47.384326 23976 net.cpp:226] relu_x2 needs backward computation.
I0529 22:29:47.384337 23976 net.cpp:226] conv_x2 needs backward computation.
I0529 22:29:47.384348 23976 net.cpp:226] pool_x1 needs backward computation.
I0529 22:29:47.384361 23976 net.cpp:226] relu_x1 needs backward computation.
I0529 22:29:47.384371 23976 net.cpp:226] conv_x1 needs backward computation.
I0529 22:29:47.384383 23976 net.cpp:228] segments_data_3_split does not need backward computation.
I0529 22:29:47.384397 23976 net.cpp:228] data does not need backward computation.
I0529 22:29:47.384407 23976 net.cpp:270] This network produces output accuracy
I0529 22:29:47.384418 23976 net.cpp:270] This network produces output loss
I0529 22:29:47.384476 23976 net.cpp:283] Network initialization done.
I0529 22:29:47.384763 23976 solver.cpp:60] Solver scaffolding done.
I0529 22:29:47.387900 23976 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_50000.solverstate
I0529 22:29:47.547946 23976 sgd_solver.cpp:318] SGDSolver: restoring history
I0529 22:29:47.567966 23976 caffe.cpp:212] Starting Optimization
I0529 22:29:47.568011 23976 solver.cpp:288] Solving epsilon_127x50_xuv
I0529 22:29:47.568022 23976 solver.cpp:289] Learning Rate Policy: fixed
I0529 22:29:47.570500 23976 solver.cpp:341] Iteration 50000, Testing net (#0)
I0529 22:32:05.253321 23976 solver.cpp:409]     Test net output #0: accuracy = 0.846399
I0529 22:32:05.253499 23976 solver.cpp:409]     Test net output #1: loss = 0.551339 (* 1 = 0.551339 loss)
I0529 22:32:05.324617 23976 solver.cpp:237] Iteration 50000, loss = 1.13561
I0529 22:32:05.324653 23976 solver.cpp:253]     Train net output #0: loss = 1.13561 (* 1 = 1.13561 loss)
I0529 22:32:05.324676 23976 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0529 22:50:45.998083 23976 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_55000.caffemodel
I0529 22:50:46.254328 23976 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_55000.solverstate
I0529 22:50:46.334395 23976 solver.cpp:341] Iteration 55000, Testing net (#0)
I0529 22:53:01.010435 23976 solver.cpp:409]     Test net output #0: accuracy = 0.850052
I0529 22:53:01.010623 23976 solver.cpp:409]     Test net output #1: loss = 0.547594 (* 1 = 0.547594 loss)
I0529 22:54:08.450924 23976 solver.cpp:237] Iteration 55000, loss = 1.4407
I0529 22:54:08.451108 23976 solver.cpp:253]     Train net output #0: loss = 1.4407 (* 1 = 1.4407 loss)
I0529 22:54:08.451123 23976 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0529 23:12:49.643735 23976 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_60000.caffemodel
I0529 23:12:49.915132 23976 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_60000.solverstate
I0529 23:12:49.996556 23976 solver.cpp:341] Iteration 60000, Testing net (#0)
I0529 23:16:07.959699 23976 solver.cpp:409]     Test net output #0: accuracy = 0.850099
I0529 23:16:07.959867 23976 solver.cpp:409]     Test net output #1: loss = 0.530726 (* 1 = 0.530726 loss)
I0529 23:17:15.409251 23976 solver.cpp:237] Iteration 60000, loss = 1.45086
I0529 23:17:15.409435 23976 solver.cpp:253]     Train net output #0: loss = 1.45086 (* 1 = 1.45086 loss)
I0529 23:17:15.409451 23976 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0529 23:35:56.571144 23976 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_65000.caffemodel
I0529 23:35:56.832631 23976 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_65000.solverstate
I0529 23:35:56.914146 23976 solver.cpp:341] Iteration 65000, Testing net (#0)
I0529 23:38:10.507535 23976 solver.cpp:409]     Test net output #0: accuracy = 0.852293
I0529 23:38:10.507719 23976 solver.cpp:409]     Test net output #1: loss = 0.528172 (* 1 = 0.528172 loss)
I0529 23:39:13.699425 23976 solver.cpp:237] Iteration 65000, loss = 1.43737
I0529 23:39:13.699607 23976 solver.cpp:253]     Train net output #0: loss = 1.43737 (* 1 = 1.43737 loss)
I0529 23:39:13.699623 23976 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I0529 23:57:38.044430 23976 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_70000.caffemodel
I0529 23:57:38.305349 23976 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_70000.solverstate
I0529 23:57:38.384030 23976 solver.cpp:341] Iteration 70000, Testing net (#0)
I0530 00:00:56.501723 23976 solver.cpp:409]     Test net output #0: accuracy = 0.854439
I0530 00:00:56.501894 23976 solver.cpp:409]     Test net output #1: loss = 0.525675 (* 1 = 0.525675 loss)
I0530 00:01:59.824973 23976 solver.cpp:237] Iteration 70000, loss = 1.31165
I0530 00:01:59.825152 23976 solver.cpp:253]     Train net output #0: loss = 1.31165 (* 1 = 1.31165 loss)
I0530 00:01:59.825170 23976 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I0530 00:20:24.029081 23976 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_75000.caffemodel
I0530 00:20:24.289952 23976 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_lr001_2016-05-29T18.24.51.314592_iter_75000.solverstate
I0530 00:20:24.369143 23976 solver.cpp:341] Iteration 75000, Testing net (#0)
I0530 00:22:38.975152 23976 solver.cpp:409]     Test net output #0: accuracy = 0.855559
I0530 00:22:38.975323 23976 solver.cpp:409]     Test net output #1: loss = 0.508165 (* 1 = 0.508165 loss)
I0530 00:23:42.193085 23976 solver.cpp:237] Iteration 75000, loss = 1.32956
I0530 00:23:42.193270 23976 solver.cpp:253]     Train net output #0: loss = 1.32956 (* 1 = 1.32956 loss)
I0530 00:23:42.193285 23976 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
aprun: Apid 11283484: Caught signal Terminated, sending to application
*** Aborted at 1464582485 (unix time) try "date -d @1464582485" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11283484: Caught signal Terminated, sending to application
*** SIGTERM (@0x5da5) received by PID 23976 (TID 0x2aaac746f900) from PID 23973; stack trace: ***
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
=>> PBS: job killed: walltime 7242 exceeded limit 7200
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11283484: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
aprun: Apid 11283484: Caught signal Terminated, sending to application
