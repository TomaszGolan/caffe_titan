2816770
I0530 09:38:09.562111 25279 caffe.cpp:184] Using GPUs 0
I0530 09:38:09.991271 25279 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 5000
base_lr: 0.0025
display: 5000
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_noada_2016-05-30T07.36.54.892099.prototxt"
I0530 09:38:09.993477 25279 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_noada_2016-05-30T07.36.54.892099.prototxt
I0530 09:38:10.014596 25279 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0530 09:38:10.014683 25279 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0530 09:38:10.015440 25279 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0530 09:38:10.015794 25279 layer_factory.hpp:77] Creating layer data
I0530 09:38:10.015817 25279 net.cpp:106] Creating Layer data
I0530 09:38:10.015831 25279 net.cpp:411] data -> hits-x
I0530 09:38:10.015866 25279 net.cpp:411] data -> hits-u
I0530 09:38:10.015888 25279 net.cpp:411] data -> hits-v
I0530 09:38:10.015903 25279 net.cpp:411] data -> segments
I0530 09:38:10.015931 25279 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist
I0530 09:38:10.017379 25279 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0530 09:38:10.048105 25279 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0530 09:39:14.109937 25279 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0530 09:39:14.115706 25279 net.cpp:150] Setting up data
I0530 09:39:14.115746 25279 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 09:39:14.115761 25279 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 09:39:14.115777 25279 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 09:39:14.115788 25279 net.cpp:157] Top shape: 100 (100)
I0530 09:39:14.115798 25279 net.cpp:165] Memory required for data: 7620400
I0530 09:39:14.115813 25279 layer_factory.hpp:77] Creating layer conv_x1
I0530 09:39:14.115845 25279 net.cpp:106] Creating Layer conv_x1
I0530 09:39:14.115856 25279 net.cpp:454] conv_x1 <- hits-x
I0530 09:39:14.115880 25279 net.cpp:411] conv_x1 -> conv_x1
I0530 09:39:15.551749 25279 net.cpp:150] Setting up conv_x1
I0530 09:39:15.551791 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:39:15.551802 25279 net.cpp:165] Memory required for data: 35268400
I0530 09:39:15.551834 25279 layer_factory.hpp:77] Creating layer relu_x1
I0530 09:39:15.551856 25279 net.cpp:106] Creating Layer relu_x1
I0530 09:39:15.551867 25279 net.cpp:454] relu_x1 <- conv_x1
I0530 09:39:15.551882 25279 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0530 09:39:15.552398 25279 net.cpp:150] Setting up relu_x1
I0530 09:39:15.552414 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:39:15.552425 25279 net.cpp:165] Memory required for data: 62916400
I0530 09:39:15.552435 25279 layer_factory.hpp:77] Creating layer pool_x1
I0530 09:39:15.552453 25279 net.cpp:106] Creating Layer pool_x1
I0530 09:39:15.552464 25279 net.cpp:454] pool_x1 <- conv_x1
I0530 09:39:15.552477 25279 net.cpp:411] pool_x1 -> pool_x1
I0530 09:39:15.552558 25279 net.cpp:150] Setting up pool_x1
I0530 09:39:15.552572 25279 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 09:39:15.552582 25279 net.cpp:165] Memory required for data: 76740400
I0530 09:39:15.552592 25279 layer_factory.hpp:77] Creating layer conv_x2
I0530 09:39:15.552613 25279 net.cpp:106] Creating Layer conv_x2
I0530 09:39:15.552624 25279 net.cpp:454] conv_x2 <- pool_x1
I0530 09:39:15.552637 25279 net.cpp:411] conv_x2 -> conv_x2
I0530 09:39:15.555333 25279 net.cpp:150] Setting up conv_x2
I0530 09:39:15.555361 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:39:15.555374 25279 net.cpp:165] Memory required for data: 96612400
I0530 09:39:15.555397 25279 layer_factory.hpp:77] Creating layer relu_x2
I0530 09:39:15.555411 25279 net.cpp:106] Creating Layer relu_x2
I0530 09:39:15.555423 25279 net.cpp:454] relu_x2 <- conv_x2
I0530 09:39:15.555436 25279 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0530 09:39:15.555765 25279 net.cpp:150] Setting up relu_x2
I0530 09:39:15.555780 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:39:15.555790 25279 net.cpp:165] Memory required for data: 116484400
I0530 09:39:15.555801 25279 layer_factory.hpp:77] Creating layer pool_x2
I0530 09:39:15.555814 25279 net.cpp:106] Creating Layer pool_x2
I0530 09:39:15.555824 25279 net.cpp:454] pool_x2 <- conv_x2
I0530 09:39:15.555837 25279 net.cpp:411] pool_x2 -> pool_x2
I0530 09:39:15.555907 25279 net.cpp:150] Setting up pool_x2
I0530 09:39:15.555920 25279 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 09:39:15.555929 25279 net.cpp:165] Memory required for data: 126420400
I0530 09:39:15.555938 25279 layer_factory.hpp:77] Creating layer conv_x3
I0530 09:39:15.555958 25279 net.cpp:106] Creating Layer conv_x3
I0530 09:39:15.555968 25279 net.cpp:454] conv_x3 <- pool_x2
I0530 09:39:15.555981 25279 net.cpp:411] conv_x3 -> conv_x3
I0530 09:39:15.557889 25279 net.cpp:150] Setting up conv_x3
I0530 09:39:15.557914 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:39:15.557925 25279 net.cpp:165] Memory required for data: 137262000
I0530 09:39:15.557943 25279 layer_factory.hpp:77] Creating layer relu_x3
I0530 09:39:15.557960 25279 net.cpp:106] Creating Layer relu_x3
I0530 09:39:15.557971 25279 net.cpp:454] relu_x3 <- conv_x3
I0530 09:39:15.557983 25279 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0530 09:39:15.558452 25279 net.cpp:150] Setting up relu_x3
I0530 09:39:15.558468 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:39:15.558490 25279 net.cpp:165] Memory required for data: 148103600
I0530 09:39:15.558501 25279 layer_factory.hpp:77] Creating layer pool_x3
I0530 09:39:15.558516 25279 net.cpp:106] Creating Layer pool_x3
I0530 09:39:15.558526 25279 net.cpp:454] pool_x3 <- conv_x3
I0530 09:39:15.558538 25279 net.cpp:411] pool_x3 -> pool_x3
I0530 09:39:15.558607 25279 net.cpp:150] Setting up pool_x3
I0530 09:39:15.558620 25279 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 09:39:15.558631 25279 net.cpp:165] Memory required for data: 153524400
I0530 09:39:15.558641 25279 layer_factory.hpp:77] Creating layer conv_x4
I0530 09:39:15.558658 25279 net.cpp:106] Creating Layer conv_x4
I0530 09:39:15.558668 25279 net.cpp:454] conv_x4 <- pool_x3
I0530 09:39:15.558682 25279 net.cpp:411] conv_x4 -> conv_x4
I0530 09:39:15.561638 25279 net.cpp:150] Setting up conv_x4
I0530 09:39:15.561666 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:39:15.561677 25279 net.cpp:165] Memory required for data: 157153200
I0530 09:39:15.561693 25279 layer_factory.hpp:77] Creating layer relu_x4
I0530 09:39:15.561708 25279 net.cpp:106] Creating Layer relu_x4
I0530 09:39:15.561718 25279 net.cpp:454] relu_x4 <- conv_x4
I0530 09:39:15.561733 25279 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0530 09:39:15.562196 25279 net.cpp:150] Setting up relu_x4
I0530 09:39:15.562211 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:39:15.562222 25279 net.cpp:165] Memory required for data: 160782000
I0530 09:39:15.562232 25279 layer_factory.hpp:77] Creating layer pool_x4
I0530 09:39:15.562245 25279 net.cpp:106] Creating Layer pool_x4
I0530 09:39:15.562255 25279 net.cpp:454] pool_x4 <- conv_x4
I0530 09:39:15.562268 25279 net.cpp:411] pool_x4 -> pool_x4
I0530 09:39:15.562337 25279 net.cpp:150] Setting up pool_x4
I0530 09:39:15.562350 25279 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 09:39:15.562361 25279 net.cpp:165] Memory required for data: 162596400
I0530 09:39:15.562371 25279 layer_factory.hpp:77] Creating layer dl_x1
I0530 09:39:15.562391 25279 net.cpp:106] Creating Layer dl_x1
I0530 09:39:15.562402 25279 net.cpp:454] dl_x1 <- pool_x4
I0530 09:39:15.562415 25279 net.cpp:411] dl_x1 -> dl_x1
I0530 09:39:15.577960 25279 net.cpp:150] Setting up dl_x1
I0530 09:39:15.577991 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.578001 25279 net.cpp:165] Memory required for data: 162674800
I0530 09:39:15.578023 25279 layer_factory.hpp:77] Creating layer relu_x5
I0530 09:39:15.578039 25279 net.cpp:106] Creating Layer relu_x5
I0530 09:39:15.578049 25279 net.cpp:454] relu_x5 <- dl_x1
I0530 09:39:15.578063 25279 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0530 09:39:15.578408 25279 net.cpp:150] Setting up relu_x5
I0530 09:39:15.578421 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.578431 25279 net.cpp:165] Memory required for data: 162753200
I0530 09:39:15.578443 25279 layer_factory.hpp:77] Creating layer drop_x1
I0530 09:39:15.578464 25279 net.cpp:106] Creating Layer drop_x1
I0530 09:39:15.578474 25279 net.cpp:454] drop_x1 <- dl_x1
I0530 09:39:15.578487 25279 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0530 09:39:15.578532 25279 net.cpp:150] Setting up drop_x1
I0530 09:39:15.578547 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.578557 25279 net.cpp:165] Memory required for data: 162831600
I0530 09:39:15.578567 25279 layer_factory.hpp:77] Creating layer conv_u1
I0530 09:39:15.578590 25279 net.cpp:106] Creating Layer conv_u1
I0530 09:39:15.578600 25279 net.cpp:454] conv_u1 <- hits-u
I0530 09:39:15.578614 25279 net.cpp:411] conv_u1 -> conv_u1
I0530 09:39:15.580452 25279 net.cpp:150] Setting up conv_u1
I0530 09:39:15.580476 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:39:15.580488 25279 net.cpp:165] Memory required for data: 190479600
I0530 09:39:15.580503 25279 layer_factory.hpp:77] Creating layer relu_u1
I0530 09:39:15.580516 25279 net.cpp:106] Creating Layer relu_u1
I0530 09:39:15.580526 25279 net.cpp:454] relu_u1 <- conv_u1
I0530 09:39:15.580539 25279 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0530 09:39:15.581027 25279 net.cpp:150] Setting up relu_u1
I0530 09:39:15.581044 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:39:15.581055 25279 net.cpp:165] Memory required for data: 218127600
I0530 09:39:15.581065 25279 layer_factory.hpp:77] Creating layer pool_u1
I0530 09:39:15.581079 25279 net.cpp:106] Creating Layer pool_u1
I0530 09:39:15.581089 25279 net.cpp:454] pool_u1 <- conv_u1
I0530 09:39:15.581102 25279 net.cpp:411] pool_u1 -> pool_u1
I0530 09:39:15.581173 25279 net.cpp:150] Setting up pool_u1
I0530 09:39:15.581187 25279 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 09:39:15.581197 25279 net.cpp:165] Memory required for data: 231951600
I0530 09:39:15.581207 25279 layer_factory.hpp:77] Creating layer conv_u2
I0530 09:39:15.581223 25279 net.cpp:106] Creating Layer conv_u2
I0530 09:39:15.581234 25279 net.cpp:454] conv_u2 <- pool_u1
I0530 09:39:15.581249 25279 net.cpp:411] conv_u2 -> conv_u2
I0530 09:39:15.583068 25279 net.cpp:150] Setting up conv_u2
I0530 09:39:15.583091 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:39:15.583103 25279 net.cpp:165] Memory required for data: 251823600
I0530 09:39:15.583129 25279 layer_factory.hpp:77] Creating layer relu_u2
I0530 09:39:15.583143 25279 net.cpp:106] Creating Layer relu_u2
I0530 09:39:15.583153 25279 net.cpp:454] relu_u2 <- conv_u2
I0530 09:39:15.583166 25279 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0530 09:39:15.583487 25279 net.cpp:150] Setting up relu_u2
I0530 09:39:15.583501 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:39:15.583513 25279 net.cpp:165] Memory required for data: 271695600
I0530 09:39:15.583523 25279 layer_factory.hpp:77] Creating layer pool_u2
I0530 09:39:15.583535 25279 net.cpp:106] Creating Layer pool_u2
I0530 09:39:15.583545 25279 net.cpp:454] pool_u2 <- conv_u2
I0530 09:39:15.583559 25279 net.cpp:411] pool_u2 -> pool_u2
I0530 09:39:15.583631 25279 net.cpp:150] Setting up pool_u2
I0530 09:39:15.583645 25279 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 09:39:15.583657 25279 net.cpp:165] Memory required for data: 281631600
I0530 09:39:15.583667 25279 layer_factory.hpp:77] Creating layer conv_u3
I0530 09:39:15.583684 25279 net.cpp:106] Creating Layer conv_u3
I0530 09:39:15.583694 25279 net.cpp:454] conv_u3 <- pool_u2
I0530 09:39:15.583708 25279 net.cpp:411] conv_u3 -> conv_u3
I0530 09:39:15.585620 25279 net.cpp:150] Setting up conv_u3
I0530 09:39:15.585642 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:39:15.585655 25279 net.cpp:165] Memory required for data: 292473200
I0530 09:39:15.585671 25279 layer_factory.hpp:77] Creating layer relu_u3
I0530 09:39:15.585685 25279 net.cpp:106] Creating Layer relu_u3
I0530 09:39:15.585695 25279 net.cpp:454] relu_u3 <- conv_u3
I0530 09:39:15.585707 25279 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0530 09:39:15.586038 25279 net.cpp:150] Setting up relu_u3
I0530 09:39:15.586052 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:39:15.586063 25279 net.cpp:165] Memory required for data: 303314800
I0530 09:39:15.586073 25279 layer_factory.hpp:77] Creating layer pool_u3
I0530 09:39:15.586086 25279 net.cpp:106] Creating Layer pool_u3
I0530 09:39:15.586097 25279 net.cpp:454] pool_u3 <- conv_u3
I0530 09:39:15.586109 25279 net.cpp:411] pool_u3 -> pool_u3
I0530 09:39:15.586177 25279 net.cpp:150] Setting up pool_u3
I0530 09:39:15.586191 25279 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 09:39:15.586201 25279 net.cpp:165] Memory required for data: 308735600
I0530 09:39:15.586211 25279 layer_factory.hpp:77] Creating layer conv_u4
I0530 09:39:15.586228 25279 net.cpp:106] Creating Layer conv_u4
I0530 09:39:15.586239 25279 net.cpp:454] conv_u4 <- pool_u3
I0530 09:39:15.586253 25279 net.cpp:411] conv_u4 -> conv_u4
I0530 09:39:15.588459 25279 net.cpp:150] Setting up conv_u4
I0530 09:39:15.588482 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:39:15.588495 25279 net.cpp:165] Memory required for data: 312364400
I0530 09:39:15.588516 25279 layer_factory.hpp:77] Creating layer relu_u4
I0530 09:39:15.588529 25279 net.cpp:106] Creating Layer relu_u4
I0530 09:39:15.588549 25279 net.cpp:454] relu_u4 <- conv_u4
I0530 09:39:15.588563 25279 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0530 09:39:15.589037 25279 net.cpp:150] Setting up relu_u4
I0530 09:39:15.589053 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:39:15.589064 25279 net.cpp:165] Memory required for data: 315993200
I0530 09:39:15.589074 25279 layer_factory.hpp:77] Creating layer pool_u4
I0530 09:39:15.589087 25279 net.cpp:106] Creating Layer pool_u4
I0530 09:39:15.589097 25279 net.cpp:454] pool_u4 <- conv_u4
I0530 09:39:15.589112 25279 net.cpp:411] pool_u4 -> pool_u4
I0530 09:39:15.589181 25279 net.cpp:150] Setting up pool_u4
I0530 09:39:15.589195 25279 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 09:39:15.589206 25279 net.cpp:165] Memory required for data: 317807600
I0530 09:39:15.589215 25279 layer_factory.hpp:77] Creating layer dl_u1
I0530 09:39:15.589231 25279 net.cpp:106] Creating Layer dl_u1
I0530 09:39:15.589241 25279 net.cpp:454] dl_u1 <- pool_u4
I0530 09:39:15.589254 25279 net.cpp:411] dl_u1 -> dl_u1
I0530 09:39:15.604743 25279 net.cpp:150] Setting up dl_u1
I0530 09:39:15.604773 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.604784 25279 net.cpp:165] Memory required for data: 317886000
I0530 09:39:15.604801 25279 layer_factory.hpp:77] Creating layer relu_u5
I0530 09:39:15.604816 25279 net.cpp:106] Creating Layer relu_u5
I0530 09:39:15.604826 25279 net.cpp:454] relu_u5 <- dl_u1
I0530 09:39:15.604840 25279 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0530 09:39:15.605187 25279 net.cpp:150] Setting up relu_u5
I0530 09:39:15.605201 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.605211 25279 net.cpp:165] Memory required for data: 317964400
I0530 09:39:15.605222 25279 layer_factory.hpp:77] Creating layer drop_u1
I0530 09:39:15.605235 25279 net.cpp:106] Creating Layer drop_u1
I0530 09:39:15.605245 25279 net.cpp:454] drop_u1 <- dl_u1
I0530 09:39:15.605258 25279 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0530 09:39:15.605303 25279 net.cpp:150] Setting up drop_u1
I0530 09:39:15.605315 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.605325 25279 net.cpp:165] Memory required for data: 318042800
I0530 09:39:15.605335 25279 layer_factory.hpp:77] Creating layer conv_v1
I0530 09:39:15.605353 25279 net.cpp:106] Creating Layer conv_v1
I0530 09:39:15.605363 25279 net.cpp:454] conv_v1 <- hits-v
I0530 09:39:15.605377 25279 net.cpp:411] conv_v1 -> conv_v1
I0530 09:39:15.607246 25279 net.cpp:150] Setting up conv_v1
I0530 09:39:15.607270 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:39:15.607282 25279 net.cpp:165] Memory required for data: 345690800
I0530 09:39:15.607297 25279 layer_factory.hpp:77] Creating layer relu_v1
I0530 09:39:15.607321 25279 net.cpp:106] Creating Layer relu_v1
I0530 09:39:15.607331 25279 net.cpp:454] relu_v1 <- conv_v1
I0530 09:39:15.607344 25279 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0530 09:39:15.607817 25279 net.cpp:150] Setting up relu_v1
I0530 09:39:15.607834 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:39:15.607846 25279 net.cpp:165] Memory required for data: 373338800
I0530 09:39:15.607856 25279 layer_factory.hpp:77] Creating layer pool_v1
I0530 09:39:15.607870 25279 net.cpp:106] Creating Layer pool_v1
I0530 09:39:15.607880 25279 net.cpp:454] pool_v1 <- conv_v1
I0530 09:39:15.607894 25279 net.cpp:411] pool_v1 -> pool_v1
I0530 09:39:15.607966 25279 net.cpp:150] Setting up pool_v1
I0530 09:39:15.607980 25279 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 09:39:15.607990 25279 net.cpp:165] Memory required for data: 387162800
I0530 09:39:15.608000 25279 layer_factory.hpp:77] Creating layer conv_v2
I0530 09:39:15.608017 25279 net.cpp:106] Creating Layer conv_v2
I0530 09:39:15.608027 25279 net.cpp:454] conv_v2 <- pool_v1
I0530 09:39:15.608042 25279 net.cpp:411] conv_v2 -> conv_v2
I0530 09:39:15.609733 25279 net.cpp:150] Setting up conv_v2
I0530 09:39:15.609755 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:39:15.609768 25279 net.cpp:165] Memory required for data: 407034800
I0530 09:39:15.609797 25279 layer_factory.hpp:77] Creating layer relu_v2
I0530 09:39:15.609809 25279 net.cpp:106] Creating Layer relu_v2
I0530 09:39:15.609820 25279 net.cpp:454] relu_v2 <- conv_v2
I0530 09:39:15.609833 25279 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0530 09:39:15.610308 25279 net.cpp:150] Setting up relu_v2
I0530 09:39:15.610324 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:39:15.610335 25279 net.cpp:165] Memory required for data: 426906800
I0530 09:39:15.610345 25279 layer_factory.hpp:77] Creating layer pool_v2
I0530 09:39:15.610359 25279 net.cpp:106] Creating Layer pool_v2
I0530 09:39:15.610369 25279 net.cpp:454] pool_v2 <- conv_v2
I0530 09:39:15.610383 25279 net.cpp:411] pool_v2 -> pool_v2
I0530 09:39:15.610452 25279 net.cpp:150] Setting up pool_v2
I0530 09:39:15.610466 25279 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 09:39:15.610476 25279 net.cpp:165] Memory required for data: 436842800
I0530 09:39:15.610486 25279 layer_factory.hpp:77] Creating layer conv_v3
I0530 09:39:15.610502 25279 net.cpp:106] Creating Layer conv_v3
I0530 09:39:15.610513 25279 net.cpp:454] conv_v3 <- pool_v2
I0530 09:39:15.610527 25279 net.cpp:411] conv_v3 -> conv_v3
I0530 09:39:15.612463 25279 net.cpp:150] Setting up conv_v3
I0530 09:39:15.612486 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:39:15.612499 25279 net.cpp:165] Memory required for data: 447684400
I0530 09:39:15.612514 25279 layer_factory.hpp:77] Creating layer relu_v3
I0530 09:39:15.612527 25279 net.cpp:106] Creating Layer relu_v3
I0530 09:39:15.612537 25279 net.cpp:454] relu_v3 <- conv_v3
I0530 09:39:15.612550 25279 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0530 09:39:15.612870 25279 net.cpp:150] Setting up relu_v3
I0530 09:39:15.612884 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:39:15.612895 25279 net.cpp:165] Memory required for data: 458526000
I0530 09:39:15.612905 25279 layer_factory.hpp:77] Creating layer pool_v3
I0530 09:39:15.612917 25279 net.cpp:106] Creating Layer pool_v3
I0530 09:39:15.612927 25279 net.cpp:454] pool_v3 <- conv_v3
I0530 09:39:15.612941 25279 net.cpp:411] pool_v3 -> pool_v3
I0530 09:39:15.613014 25279 net.cpp:150] Setting up pool_v3
I0530 09:39:15.613031 25279 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 09:39:15.613042 25279 net.cpp:165] Memory required for data: 463946800
I0530 09:39:15.613050 25279 layer_factory.hpp:77] Creating layer conv_v4
I0530 09:39:15.613067 25279 net.cpp:106] Creating Layer conv_v4
I0530 09:39:15.613077 25279 net.cpp:454] conv_v4 <- pool_v3
I0530 09:39:15.613092 25279 net.cpp:411] conv_v4 -> conv_v4
I0530 09:39:15.615187 25279 net.cpp:150] Setting up conv_v4
I0530 09:39:15.615211 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:39:15.615222 25279 net.cpp:165] Memory required for data: 467575600
I0530 09:39:15.615238 25279 layer_factory.hpp:77] Creating layer relu_v4
I0530 09:39:15.615252 25279 net.cpp:106] Creating Layer relu_v4
I0530 09:39:15.615262 25279 net.cpp:454] relu_v4 <- conv_v4
I0530 09:39:15.615274 25279 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0530 09:39:15.615751 25279 net.cpp:150] Setting up relu_v4
I0530 09:39:15.615767 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:39:15.615777 25279 net.cpp:165] Memory required for data: 471204400
I0530 09:39:15.615787 25279 layer_factory.hpp:77] Creating layer pool_v4
I0530 09:39:15.615802 25279 net.cpp:106] Creating Layer pool_v4
I0530 09:39:15.615811 25279 net.cpp:454] pool_v4 <- conv_v4
I0530 09:39:15.615824 25279 net.cpp:411] pool_v4 -> pool_v4
I0530 09:39:15.615898 25279 net.cpp:150] Setting up pool_v4
I0530 09:39:15.615911 25279 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 09:39:15.615921 25279 net.cpp:165] Memory required for data: 473018800
I0530 09:39:15.615931 25279 layer_factory.hpp:77] Creating layer dl_v1
I0530 09:39:15.615947 25279 net.cpp:106] Creating Layer dl_v1
I0530 09:39:15.615957 25279 net.cpp:454] dl_v1 <- pool_v4
I0530 09:39:15.615972 25279 net.cpp:411] dl_v1 -> dl_v1
I0530 09:39:15.631595 25279 net.cpp:150] Setting up dl_v1
I0530 09:39:15.631636 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.631652 25279 net.cpp:165] Memory required for data: 473097200
I0530 09:39:15.631674 25279 layer_factory.hpp:77] Creating layer relu_v5
I0530 09:39:15.631688 25279 net.cpp:106] Creating Layer relu_v5
I0530 09:39:15.631700 25279 net.cpp:454] relu_v5 <- dl_v1
I0530 09:39:15.631712 25279 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0530 09:39:15.632066 25279 net.cpp:150] Setting up relu_v5
I0530 09:39:15.632079 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.632091 25279 net.cpp:165] Memory required for data: 473175600
I0530 09:39:15.632102 25279 layer_factory.hpp:77] Creating layer drop_v1
I0530 09:39:15.632114 25279 net.cpp:106] Creating Layer drop_v1
I0530 09:39:15.632124 25279 net.cpp:454] drop_v1 <- dl_v1
I0530 09:39:15.632136 25279 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0530 09:39:15.632181 25279 net.cpp:150] Setting up drop_v1
I0530 09:39:15.632194 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:39:15.632205 25279 net.cpp:165] Memory required for data: 473254000
I0530 09:39:15.632215 25279 layer_factory.hpp:77] Creating layer concat_xuv
I0530 09:39:15.632236 25279 net.cpp:106] Creating Layer concat_xuv
I0530 09:39:15.632246 25279 net.cpp:454] concat_xuv <- dl_x1
I0530 09:39:15.632258 25279 net.cpp:454] concat_xuv <- dl_u1
I0530 09:39:15.632269 25279 net.cpp:454] concat_xuv <- dl_v1
I0530 09:39:15.632283 25279 net.cpp:411] concat_xuv -> concat_xuv
I0530 09:39:15.632335 25279 net.cpp:150] Setting up concat_xuv
I0530 09:39:15.632349 25279 net.cpp:157] Top shape: 100 588 (58800)
I0530 09:39:15.632360 25279 net.cpp:165] Memory required for data: 473489200
I0530 09:39:15.632370 25279 layer_factory.hpp:77] Creating layer dl_xuv
I0530 09:39:15.632385 25279 net.cpp:106] Creating Layer dl_xuv
I0530 09:39:15.632395 25279 net.cpp:454] dl_xuv <- concat_xuv
I0530 09:39:15.632408 25279 net.cpp:411] dl_xuv -> dl_xuv
I0530 09:39:15.633445 25279 net.cpp:150] Setting up dl_xuv
I0530 09:39:15.633465 25279 net.cpp:157] Top shape: 100 98 (9800)
I0530 09:39:15.633477 25279 net.cpp:165] Memory required for data: 473528400
I0530 09:39:15.633492 25279 layer_factory.hpp:77] Creating layer relu_xuv
I0530 09:39:15.633505 25279 net.cpp:106] Creating Layer relu_xuv
I0530 09:39:15.633515 25279 net.cpp:454] relu_xuv <- dl_xuv
I0530 09:39:15.633527 25279 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0530 09:39:15.634071 25279 net.cpp:150] Setting up relu_xuv
I0530 09:39:15.634088 25279 net.cpp:157] Top shape: 100 98 (9800)
I0530 09:39:15.634099 25279 net.cpp:165] Memory required for data: 473567600
I0530 09:39:15.634109 25279 layer_factory.hpp:77] Creating layer drop_xuv
I0530 09:39:15.634122 25279 net.cpp:106] Creating Layer drop_xuv
I0530 09:39:15.634132 25279 net.cpp:454] drop_xuv <- dl_xuv
I0530 09:39:15.634145 25279 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0530 09:39:15.634191 25279 net.cpp:150] Setting up drop_xuv
I0530 09:39:15.634203 25279 net.cpp:157] Top shape: 100 98 (9800)
I0530 09:39:15.634213 25279 net.cpp:165] Memory required for data: 473606800
I0530 09:39:15.634223 25279 layer_factory.hpp:77] Creating layer output
I0530 09:39:15.634238 25279 net.cpp:106] Creating Layer output
I0530 09:39:15.634246 25279 net.cpp:454] output <- dl_xuv
I0530 09:39:15.634259 25279 net.cpp:411] output -> output
I0530 09:39:15.634487 25279 net.cpp:150] Setting up output
I0530 09:39:15.634501 25279 net.cpp:157] Top shape: 100 11 (1100)
I0530 09:39:15.634511 25279 net.cpp:165] Memory required for data: 473611200
I0530 09:39:15.634541 25279 layer_factory.hpp:77] Creating layer drop_output
I0530 09:39:15.634553 25279 net.cpp:106] Creating Layer drop_output
I0530 09:39:15.634563 25279 net.cpp:454] drop_output <- output
I0530 09:39:15.634577 25279 net.cpp:397] drop_output -> output (in-place)
I0530 09:39:15.634619 25279 net.cpp:150] Setting up drop_output
I0530 09:39:15.634634 25279 net.cpp:157] Top shape: 100 11 (1100)
I0530 09:39:15.634644 25279 net.cpp:165] Memory required for data: 473615600
I0530 09:39:15.634654 25279 layer_factory.hpp:77] Creating layer loss
I0530 09:39:15.634681 25279 net.cpp:106] Creating Layer loss
I0530 09:39:15.634692 25279 net.cpp:454] loss <- output
I0530 09:39:15.634704 25279 net.cpp:454] loss <- segments
I0530 09:39:15.634717 25279 net.cpp:411] loss -> loss
I0530 09:39:15.634734 25279 layer_factory.hpp:77] Creating layer loss
I0530 09:39:15.635247 25279 net.cpp:150] Setting up loss
I0530 09:39:15.635262 25279 net.cpp:157] Top shape: (1)
I0530 09:39:15.635272 25279 net.cpp:160]     with loss weight 1
I0530 09:39:15.635316 25279 net.cpp:165] Memory required for data: 473615604
I0530 09:39:15.635326 25279 net.cpp:226] loss needs backward computation.
I0530 09:39:15.635337 25279 net.cpp:226] drop_output needs backward computation.
I0530 09:39:15.635347 25279 net.cpp:226] output needs backward computation.
I0530 09:39:15.635359 25279 net.cpp:226] drop_xuv needs backward computation.
I0530 09:39:15.635368 25279 net.cpp:226] relu_xuv needs backward computation.
I0530 09:39:15.635378 25279 net.cpp:226] dl_xuv needs backward computation.
I0530 09:39:15.635390 25279 net.cpp:226] concat_xuv needs backward computation.
I0530 09:39:15.635401 25279 net.cpp:226] drop_v1 needs backward computation.
I0530 09:39:15.635411 25279 net.cpp:226] relu_v5 needs backward computation.
I0530 09:39:15.635421 25279 net.cpp:226] dl_v1 needs backward computation.
I0530 09:39:15.635431 25279 net.cpp:226] pool_v4 needs backward computation.
I0530 09:39:15.635442 25279 net.cpp:226] relu_v4 needs backward computation.
I0530 09:39:15.635452 25279 net.cpp:226] conv_v4 needs backward computation.
I0530 09:39:15.635460 25279 net.cpp:226] pool_v3 needs backward computation.
I0530 09:39:15.635471 25279 net.cpp:226] relu_v3 needs backward computation.
I0530 09:39:15.635481 25279 net.cpp:226] conv_v3 needs backward computation.
I0530 09:39:15.635493 25279 net.cpp:226] pool_v2 needs backward computation.
I0530 09:39:15.635502 25279 net.cpp:226] relu_v2 needs backward computation.
I0530 09:39:15.635512 25279 net.cpp:226] conv_v2 needs backward computation.
I0530 09:39:15.635524 25279 net.cpp:226] pool_v1 needs backward computation.
I0530 09:39:15.635534 25279 net.cpp:226] relu_v1 needs backward computation.
I0530 09:39:15.635543 25279 net.cpp:226] conv_v1 needs backward computation.
I0530 09:39:15.635555 25279 net.cpp:226] drop_u1 needs backward computation.
I0530 09:39:15.635565 25279 net.cpp:226] relu_u5 needs backward computation.
I0530 09:39:15.635576 25279 net.cpp:226] dl_u1 needs backward computation.
I0530 09:39:15.635587 25279 net.cpp:226] pool_u4 needs backward computation.
I0530 09:39:15.635598 25279 net.cpp:226] relu_u4 needs backward computation.
I0530 09:39:15.635609 25279 net.cpp:226] conv_u4 needs backward computation.
I0530 09:39:15.635620 25279 net.cpp:226] pool_u3 needs backward computation.
I0530 09:39:15.635632 25279 net.cpp:226] relu_u3 needs backward computation.
I0530 09:39:15.635643 25279 net.cpp:226] conv_u3 needs backward computation.
I0530 09:39:15.635653 25279 net.cpp:226] pool_u2 needs backward computation.
I0530 09:39:15.635664 25279 net.cpp:226] relu_u2 needs backward computation.
I0530 09:39:15.635674 25279 net.cpp:226] conv_u2 needs backward computation.
I0530 09:39:15.635685 25279 net.cpp:226] pool_u1 needs backward computation.
I0530 09:39:15.635696 25279 net.cpp:226] relu_u1 needs backward computation.
I0530 09:39:15.635707 25279 net.cpp:226] conv_u1 needs backward computation.
I0530 09:39:15.635720 25279 net.cpp:226] drop_x1 needs backward computation.
I0530 09:39:15.635730 25279 net.cpp:226] relu_x5 needs backward computation.
I0530 09:39:15.635741 25279 net.cpp:226] dl_x1 needs backward computation.
I0530 09:39:15.635752 25279 net.cpp:226] pool_x4 needs backward computation.
I0530 09:39:15.635762 25279 net.cpp:226] relu_x4 needs backward computation.
I0530 09:39:15.635773 25279 net.cpp:226] conv_x4 needs backward computation.
I0530 09:39:15.635783 25279 net.cpp:226] pool_x3 needs backward computation.
I0530 09:39:15.635795 25279 net.cpp:226] relu_x3 needs backward computation.
I0530 09:39:15.635805 25279 net.cpp:226] conv_x3 needs backward computation.
I0530 09:39:15.635824 25279 net.cpp:226] pool_x2 needs backward computation.
I0530 09:39:15.635835 25279 net.cpp:226] relu_x2 needs backward computation.
I0530 09:39:15.635845 25279 net.cpp:226] conv_x2 needs backward computation.
I0530 09:39:15.635856 25279 net.cpp:226] pool_x1 needs backward computation.
I0530 09:39:15.635867 25279 net.cpp:226] relu_x1 needs backward computation.
I0530 09:39:15.635879 25279 net.cpp:226] conv_x1 needs backward computation.
I0530 09:39:15.635891 25279 net.cpp:228] data does not need backward computation.
I0530 09:39:15.635901 25279 net.cpp:270] This network produces output loss
I0530 09:39:15.635947 25279 net.cpp:283] Network initialization done.
I0530 09:39:15.638887 25279 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_noada_2016-05-30T07.36.54.892099.prototxt
I0530 09:39:15.639019 25279 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0530 09:39:15.639809 25279 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "output"
  bottom: "segments"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0530 09:39:15.640183 25279 layer_factory.hpp:77] Creating layer data
I0530 09:39:15.640200 25279 net.cpp:106] Creating Layer data
I0530 09:39:15.640213 25279 net.cpp:411] data -> hits-x
I0530 09:39:15.640229 25279 net.cpp:411] data -> hits-u
I0530 09:39:15.640245 25279 net.cpp:411] data -> hits-v
I0530 09:39:15.640262 25279 net.cpp:411] data -> segments
I0530 09:39:15.640277 25279 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist
I0530 09:39:15.658417 25279 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0530 09:40:20.276537 25279 net.cpp:150] Setting up data
I0530 09:40:20.276703 25279 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 09:40:20.276718 25279 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 09:40:20.276731 25279 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 09:40:20.276746 25279 net.cpp:157] Top shape: 100 (100)
I0530 09:40:20.276756 25279 net.cpp:165] Memory required for data: 7620400
I0530 09:40:20.276769 25279 layer_factory.hpp:77] Creating layer segments_data_3_split
I0530 09:40:20.276798 25279 net.cpp:106] Creating Layer segments_data_3_split
I0530 09:40:20.276808 25279 net.cpp:454] segments_data_3_split <- segments
I0530 09:40:20.276823 25279 net.cpp:411] segments_data_3_split -> segments_data_3_split_0
I0530 09:40:20.276845 25279 net.cpp:411] segments_data_3_split -> segments_data_3_split_1
I0530 09:40:20.276921 25279 net.cpp:150] Setting up segments_data_3_split
I0530 09:40:20.276935 25279 net.cpp:157] Top shape: 100 (100)
I0530 09:40:20.276947 25279 net.cpp:157] Top shape: 100 (100)
I0530 09:40:20.276957 25279 net.cpp:165] Memory required for data: 7621200
I0530 09:40:20.276968 25279 layer_factory.hpp:77] Creating layer conv_x1
I0530 09:40:20.276990 25279 net.cpp:106] Creating Layer conv_x1
I0530 09:40:20.277000 25279 net.cpp:454] conv_x1 <- hits-x
I0530 09:40:20.277015 25279 net.cpp:411] conv_x1 -> conv_x1
I0530 09:40:20.279222 25279 net.cpp:150] Setting up conv_x1
I0530 09:40:20.279245 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:40:20.279258 25279 net.cpp:165] Memory required for data: 35269200
I0530 09:40:20.279278 25279 layer_factory.hpp:77] Creating layer relu_x1
I0530 09:40:20.279294 25279 net.cpp:106] Creating Layer relu_x1
I0530 09:40:20.279304 25279 net.cpp:454] relu_x1 <- conv_x1
I0530 09:40:20.279316 25279 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0530 09:40:20.279829 25279 net.cpp:150] Setting up relu_x1
I0530 09:40:20.279844 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:40:20.279855 25279 net.cpp:165] Memory required for data: 62917200
I0530 09:40:20.279865 25279 layer_factory.hpp:77] Creating layer pool_x1
I0530 09:40:20.279881 25279 net.cpp:106] Creating Layer pool_x1
I0530 09:40:20.279891 25279 net.cpp:454] pool_x1 <- conv_x1
I0530 09:40:20.279906 25279 net.cpp:411] pool_x1 -> pool_x1
I0530 09:40:20.279988 25279 net.cpp:150] Setting up pool_x1
I0530 09:40:20.280000 25279 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 09:40:20.280009 25279 net.cpp:165] Memory required for data: 76741200
I0530 09:40:20.280020 25279 layer_factory.hpp:77] Creating layer conv_x2
I0530 09:40:20.280040 25279 net.cpp:106] Creating Layer conv_x2
I0530 09:40:20.280050 25279 net.cpp:454] conv_x2 <- pool_x1
I0530 09:40:20.280063 25279 net.cpp:411] conv_x2 -> conv_x2
I0530 09:40:20.281945 25279 net.cpp:150] Setting up conv_x2
I0530 09:40:20.281970 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:40:20.281981 25279 net.cpp:165] Memory required for data: 96613200
I0530 09:40:20.281998 25279 layer_factory.hpp:77] Creating layer relu_x2
I0530 09:40:20.282013 25279 net.cpp:106] Creating Layer relu_x2
I0530 09:40:20.282023 25279 net.cpp:454] relu_x2 <- conv_x2
I0530 09:40:20.282037 25279 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0530 09:40:20.282544 25279 net.cpp:150] Setting up relu_x2
I0530 09:40:20.282560 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:40:20.282572 25279 net.cpp:165] Memory required for data: 116485200
I0530 09:40:20.282582 25279 layer_factory.hpp:77] Creating layer pool_x2
I0530 09:40:20.282595 25279 net.cpp:106] Creating Layer pool_x2
I0530 09:40:20.282605 25279 net.cpp:454] pool_x2 <- conv_x2
I0530 09:40:20.282618 25279 net.cpp:411] pool_x2 -> pool_x2
I0530 09:40:20.282698 25279 net.cpp:150] Setting up pool_x2
I0530 09:40:20.282711 25279 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 09:40:20.282721 25279 net.cpp:165] Memory required for data: 126421200
I0530 09:40:20.282732 25279 layer_factory.hpp:77] Creating layer conv_x3
I0530 09:40:20.282753 25279 net.cpp:106] Creating Layer conv_x3
I0530 09:40:20.282764 25279 net.cpp:454] conv_x3 <- pool_x2
I0530 09:40:20.282778 25279 net.cpp:411] conv_x3 -> conv_x3
I0530 09:40:20.285037 25279 net.cpp:150] Setting up conv_x3
I0530 09:40:20.285054 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:40:20.285064 25279 net.cpp:165] Memory required for data: 137262800
I0530 09:40:20.285084 25279 layer_factory.hpp:77] Creating layer relu_x3
I0530 09:40:20.285097 25279 net.cpp:106] Creating Layer relu_x3
I0530 09:40:20.285107 25279 net.cpp:454] relu_x3 <- conv_x3
I0530 09:40:20.285120 25279 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0530 09:40:20.285466 25279 net.cpp:150] Setting up relu_x3
I0530 09:40:20.285480 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:40:20.285491 25279 net.cpp:165] Memory required for data: 148104400
I0530 09:40:20.285501 25279 layer_factory.hpp:77] Creating layer pool_x3
I0530 09:40:20.285514 25279 net.cpp:106] Creating Layer pool_x3
I0530 09:40:20.285524 25279 net.cpp:454] pool_x3 <- conv_x3
I0530 09:40:20.285537 25279 net.cpp:411] pool_x3 -> pool_x3
I0530 09:40:20.285615 25279 net.cpp:150] Setting up pool_x3
I0530 09:40:20.285629 25279 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 09:40:20.285639 25279 net.cpp:165] Memory required for data: 153525200
I0530 09:40:20.285646 25279 layer_factory.hpp:77] Creating layer conv_x4
I0530 09:40:20.285665 25279 net.cpp:106] Creating Layer conv_x4
I0530 09:40:20.285676 25279 net.cpp:454] conv_x4 <- pool_x3
I0530 09:40:20.285688 25279 net.cpp:411] conv_x4 -> conv_x4
I0530 09:40:20.287865 25279 net.cpp:150] Setting up conv_x4
I0530 09:40:20.287889 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:40:20.287901 25279 net.cpp:165] Memory required for data: 157154000
I0530 09:40:20.287916 25279 layer_factory.hpp:77] Creating layer relu_x4
I0530 09:40:20.287930 25279 net.cpp:106] Creating Layer relu_x4
I0530 09:40:20.287940 25279 net.cpp:454] relu_x4 <- conv_x4
I0530 09:40:20.287955 25279 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0530 09:40:20.288445 25279 net.cpp:150] Setting up relu_x4
I0530 09:40:20.288461 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:40:20.288471 25279 net.cpp:165] Memory required for data: 160782800
I0530 09:40:20.288481 25279 layer_factory.hpp:77] Creating layer pool_x4
I0530 09:40:20.288496 25279 net.cpp:106] Creating Layer pool_x4
I0530 09:40:20.288506 25279 net.cpp:454] pool_x4 <- conv_x4
I0530 09:40:20.288521 25279 net.cpp:411] pool_x4 -> pool_x4
I0530 09:40:20.288599 25279 net.cpp:150] Setting up pool_x4
I0530 09:40:20.288612 25279 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 09:40:20.288622 25279 net.cpp:165] Memory required for data: 162597200
I0530 09:40:20.288630 25279 layer_factory.hpp:77] Creating layer dl_x1
I0530 09:40:20.288646 25279 net.cpp:106] Creating Layer dl_x1
I0530 09:40:20.288656 25279 net.cpp:454] dl_x1 <- pool_x4
I0530 09:40:20.288671 25279 net.cpp:411] dl_x1 -> dl_x1
I0530 09:40:20.305091 25279 net.cpp:150] Setting up dl_x1
I0530 09:40:20.305120 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.305137 25279 net.cpp:165] Memory required for data: 162675600
I0530 09:40:20.305166 25279 layer_factory.hpp:77] Creating layer relu_x5
I0530 09:40:20.305181 25279 net.cpp:106] Creating Layer relu_x5
I0530 09:40:20.305191 25279 net.cpp:454] relu_x5 <- dl_x1
I0530 09:40:20.305204 25279 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0530 09:40:20.305565 25279 net.cpp:150] Setting up relu_x5
I0530 09:40:20.305579 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.305589 25279 net.cpp:165] Memory required for data: 162754000
I0530 09:40:20.305600 25279 layer_factory.hpp:77] Creating layer drop_x1
I0530 09:40:20.305619 25279 net.cpp:106] Creating Layer drop_x1
I0530 09:40:20.305629 25279 net.cpp:454] drop_x1 <- dl_x1
I0530 09:40:20.305642 25279 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0530 09:40:20.305691 25279 net.cpp:150] Setting up drop_x1
I0530 09:40:20.305704 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.305716 25279 net.cpp:165] Memory required for data: 162832400
I0530 09:40:20.305726 25279 layer_factory.hpp:77] Creating layer conv_u1
I0530 09:40:20.305744 25279 net.cpp:106] Creating Layer conv_u1
I0530 09:40:20.305768 25279 net.cpp:454] conv_u1 <- hits-u
I0530 09:40:20.305783 25279 net.cpp:411] conv_u1 -> conv_u1
I0530 09:40:20.307813 25279 net.cpp:150] Setting up conv_u1
I0530 09:40:20.307837 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:40:20.307849 25279 net.cpp:165] Memory required for data: 190480400
I0530 09:40:20.307865 25279 layer_factory.hpp:77] Creating layer relu_u1
I0530 09:40:20.307879 25279 net.cpp:106] Creating Layer relu_u1
I0530 09:40:20.307889 25279 net.cpp:454] relu_u1 <- conv_u1
I0530 09:40:20.307903 25279 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0530 09:40:20.308236 25279 net.cpp:150] Setting up relu_u1
I0530 09:40:20.308250 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:40:20.308261 25279 net.cpp:165] Memory required for data: 218128400
I0530 09:40:20.308271 25279 layer_factory.hpp:77] Creating layer pool_u1
I0530 09:40:20.308285 25279 net.cpp:106] Creating Layer pool_u1
I0530 09:40:20.308295 25279 net.cpp:454] pool_u1 <- conv_u1
I0530 09:40:20.308308 25279 net.cpp:411] pool_u1 -> pool_u1
I0530 09:40:20.308393 25279 net.cpp:150] Setting up pool_u1
I0530 09:40:20.308406 25279 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 09:40:20.308416 25279 net.cpp:165] Memory required for data: 231952400
I0530 09:40:20.308428 25279 layer_factory.hpp:77] Creating layer conv_u2
I0530 09:40:20.308445 25279 net.cpp:106] Creating Layer conv_u2
I0530 09:40:20.308455 25279 net.cpp:454] conv_u2 <- pool_u1
I0530 09:40:20.308470 25279 net.cpp:411] conv_u2 -> conv_u2
I0530 09:40:20.310411 25279 net.cpp:150] Setting up conv_u2
I0530 09:40:20.310433 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:40:20.310446 25279 net.cpp:165] Memory required for data: 251824400
I0530 09:40:20.310461 25279 layer_factory.hpp:77] Creating layer relu_u2
I0530 09:40:20.310475 25279 net.cpp:106] Creating Layer relu_u2
I0530 09:40:20.310485 25279 net.cpp:454] relu_u2 <- conv_u2
I0530 09:40:20.310499 25279 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0530 09:40:20.310992 25279 net.cpp:150] Setting up relu_u2
I0530 09:40:20.311007 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:40:20.311018 25279 net.cpp:165] Memory required for data: 271696400
I0530 09:40:20.311028 25279 layer_factory.hpp:77] Creating layer pool_u2
I0530 09:40:20.311041 25279 net.cpp:106] Creating Layer pool_u2
I0530 09:40:20.311053 25279 net.cpp:454] pool_u2 <- conv_u2
I0530 09:40:20.311065 25279 net.cpp:411] pool_u2 -> pool_u2
I0530 09:40:20.311152 25279 net.cpp:150] Setting up pool_u2
I0530 09:40:20.311167 25279 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 09:40:20.311177 25279 net.cpp:165] Memory required for data: 281632400
I0530 09:40:20.311187 25279 layer_factory.hpp:77] Creating layer conv_u3
I0530 09:40:20.311205 25279 net.cpp:106] Creating Layer conv_u3
I0530 09:40:20.311215 25279 net.cpp:454] conv_u3 <- pool_u2
I0530 09:40:20.311230 25279 net.cpp:411] conv_u3 -> conv_u3
I0530 09:40:20.313263 25279 net.cpp:150] Setting up conv_u3
I0530 09:40:20.313282 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:40:20.313292 25279 net.cpp:165] Memory required for data: 292474000
I0530 09:40:20.313308 25279 layer_factory.hpp:77] Creating layer relu_u3
I0530 09:40:20.313321 25279 net.cpp:106] Creating Layer relu_u3
I0530 09:40:20.313331 25279 net.cpp:454] relu_u3 <- conv_u3
I0530 09:40:20.313344 25279 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0530 09:40:20.313673 25279 net.cpp:150] Setting up relu_u3
I0530 09:40:20.313688 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:40:20.313699 25279 net.cpp:165] Memory required for data: 303315600
I0530 09:40:20.313709 25279 layer_factory.hpp:77] Creating layer pool_u3
I0530 09:40:20.313721 25279 net.cpp:106] Creating Layer pool_u3
I0530 09:40:20.313731 25279 net.cpp:454] pool_u3 <- conv_u3
I0530 09:40:20.313745 25279 net.cpp:411] pool_u3 -> pool_u3
I0530 09:40:20.313822 25279 net.cpp:150] Setting up pool_u3
I0530 09:40:20.313837 25279 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 09:40:20.313845 25279 net.cpp:165] Memory required for data: 308736400
I0530 09:40:20.313868 25279 layer_factory.hpp:77] Creating layer conv_u4
I0530 09:40:20.313885 25279 net.cpp:106] Creating Layer conv_u4
I0530 09:40:20.313896 25279 net.cpp:454] conv_u4 <- pool_u3
I0530 09:40:20.313910 25279 net.cpp:411] conv_u4 -> conv_u4
I0530 09:40:20.316098 25279 net.cpp:150] Setting up conv_u4
I0530 09:40:20.316121 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:40:20.316133 25279 net.cpp:165] Memory required for data: 312365200
I0530 09:40:20.316156 25279 layer_factory.hpp:77] Creating layer relu_u4
I0530 09:40:20.316170 25279 net.cpp:106] Creating Layer relu_u4
I0530 09:40:20.316180 25279 net.cpp:454] relu_u4 <- conv_u4
I0530 09:40:20.316193 25279 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0530 09:40:20.316526 25279 net.cpp:150] Setting up relu_u4
I0530 09:40:20.316540 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:40:20.316550 25279 net.cpp:165] Memory required for data: 315994000
I0530 09:40:20.316560 25279 layer_factory.hpp:77] Creating layer pool_u4
I0530 09:40:20.316573 25279 net.cpp:106] Creating Layer pool_u4
I0530 09:40:20.316583 25279 net.cpp:454] pool_u4 <- conv_u4
I0530 09:40:20.316597 25279 net.cpp:411] pool_u4 -> pool_u4
I0530 09:40:20.316675 25279 net.cpp:150] Setting up pool_u4
I0530 09:40:20.316689 25279 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 09:40:20.316699 25279 net.cpp:165] Memory required for data: 317808400
I0530 09:40:20.316709 25279 layer_factory.hpp:77] Creating layer dl_u1
I0530 09:40:20.316725 25279 net.cpp:106] Creating Layer dl_u1
I0530 09:40:20.316735 25279 net.cpp:454] dl_u1 <- pool_u4
I0530 09:40:20.316751 25279 net.cpp:411] dl_u1 -> dl_u1
I0530 09:40:20.332914 25279 net.cpp:150] Setting up dl_u1
I0530 09:40:20.332944 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.332955 25279 net.cpp:165] Memory required for data: 317886800
I0530 09:40:20.332973 25279 layer_factory.hpp:77] Creating layer relu_u5
I0530 09:40:20.332988 25279 net.cpp:106] Creating Layer relu_u5
I0530 09:40:20.332998 25279 net.cpp:454] relu_u5 <- dl_u1
I0530 09:40:20.333014 25279 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0530 09:40:20.333605 25279 net.cpp:150] Setting up relu_u5
I0530 09:40:20.333626 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.333642 25279 net.cpp:165] Memory required for data: 317965200
I0530 09:40:20.333650 25279 layer_factory.hpp:77] Creating layer drop_u1
I0530 09:40:20.333664 25279 net.cpp:106] Creating Layer drop_u1
I0530 09:40:20.333675 25279 net.cpp:454] drop_u1 <- dl_u1
I0530 09:40:20.333688 25279 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0530 09:40:20.333737 25279 net.cpp:150] Setting up drop_u1
I0530 09:40:20.333750 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.333760 25279 net.cpp:165] Memory required for data: 318043600
I0530 09:40:20.333770 25279 layer_factory.hpp:77] Creating layer conv_v1
I0530 09:40:20.333798 25279 net.cpp:106] Creating Layer conv_v1
I0530 09:40:20.333808 25279 net.cpp:454] conv_v1 <- hits-v
I0530 09:40:20.333823 25279 net.cpp:411] conv_v1 -> conv_v1
I0530 09:40:20.335783 25279 net.cpp:150] Setting up conv_v1
I0530 09:40:20.335806 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:40:20.335819 25279 net.cpp:165] Memory required for data: 345691600
I0530 09:40:20.335834 25279 layer_factory.hpp:77] Creating layer relu_v1
I0530 09:40:20.335849 25279 net.cpp:106] Creating Layer relu_v1
I0530 09:40:20.335858 25279 net.cpp:454] relu_v1 <- conv_v1
I0530 09:40:20.335871 25279 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0530 09:40:20.336210 25279 net.cpp:150] Setting up relu_v1
I0530 09:40:20.336223 25279 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 09:40:20.336233 25279 net.cpp:165] Memory required for data: 373339600
I0530 09:40:20.336244 25279 layer_factory.hpp:77] Creating layer pool_v1
I0530 09:40:20.336257 25279 net.cpp:106] Creating Layer pool_v1
I0530 09:40:20.336267 25279 net.cpp:454] pool_v1 <- conv_v1
I0530 09:40:20.336282 25279 net.cpp:411] pool_v1 -> pool_v1
I0530 09:40:20.336362 25279 net.cpp:150] Setting up pool_v1
I0530 09:40:20.336390 25279 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 09:40:20.336400 25279 net.cpp:165] Memory required for data: 387163600
I0530 09:40:20.336410 25279 layer_factory.hpp:77] Creating layer conv_v2
I0530 09:40:20.336428 25279 net.cpp:106] Creating Layer conv_v2
I0530 09:40:20.336439 25279 net.cpp:454] conv_v2 <- pool_v1
I0530 09:40:20.336453 25279 net.cpp:411] conv_v2 -> conv_v2
I0530 09:40:20.338491 25279 net.cpp:150] Setting up conv_v2
I0530 09:40:20.338515 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:40:20.338526 25279 net.cpp:165] Memory required for data: 407035600
I0530 09:40:20.338541 25279 layer_factory.hpp:77] Creating layer relu_v2
I0530 09:40:20.338556 25279 net.cpp:106] Creating Layer relu_v2
I0530 09:40:20.338565 25279 net.cpp:454] relu_v2 <- conv_v2
I0530 09:40:20.338579 25279 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0530 09:40:20.339079 25279 net.cpp:150] Setting up relu_v2
I0530 09:40:20.339095 25279 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 09:40:20.339107 25279 net.cpp:165] Memory required for data: 426907600
I0530 09:40:20.339128 25279 layer_factory.hpp:77] Creating layer pool_v2
I0530 09:40:20.339140 25279 net.cpp:106] Creating Layer pool_v2
I0530 09:40:20.339150 25279 net.cpp:454] pool_v2 <- conv_v2
I0530 09:40:20.339164 25279 net.cpp:411] pool_v2 -> pool_v2
I0530 09:40:20.339246 25279 net.cpp:150] Setting up pool_v2
I0530 09:40:20.339259 25279 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 09:40:20.339270 25279 net.cpp:165] Memory required for data: 436843600
I0530 09:40:20.339280 25279 layer_factory.hpp:77] Creating layer conv_v3
I0530 09:40:20.339298 25279 net.cpp:106] Creating Layer conv_v3
I0530 09:40:20.339308 25279 net.cpp:454] conv_v3 <- pool_v2
I0530 09:40:20.339323 25279 net.cpp:411] conv_v3 -> conv_v3
I0530 09:40:20.341397 25279 net.cpp:150] Setting up conv_v3
I0530 09:40:20.341414 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:40:20.341425 25279 net.cpp:165] Memory required for data: 447685200
I0530 09:40:20.341440 25279 layer_factory.hpp:77] Creating layer relu_v3
I0530 09:40:20.341454 25279 net.cpp:106] Creating Layer relu_v3
I0530 09:40:20.341464 25279 net.cpp:454] relu_v3 <- conv_v3
I0530 09:40:20.341477 25279 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0530 09:40:20.341980 25279 net.cpp:150] Setting up relu_v3
I0530 09:40:20.341997 25279 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 09:40:20.342007 25279 net.cpp:165] Memory required for data: 458526800
I0530 09:40:20.342017 25279 layer_factory.hpp:77] Creating layer pool_v3
I0530 09:40:20.342031 25279 net.cpp:106] Creating Layer pool_v3
I0530 09:40:20.342041 25279 net.cpp:454] pool_v3 <- conv_v3
I0530 09:40:20.342054 25279 net.cpp:411] pool_v3 -> pool_v3
I0530 09:40:20.342133 25279 net.cpp:150] Setting up pool_v3
I0530 09:40:20.342147 25279 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 09:40:20.342156 25279 net.cpp:165] Memory required for data: 463947600
I0530 09:40:20.342166 25279 layer_factory.hpp:77] Creating layer conv_v4
I0530 09:40:20.342185 25279 net.cpp:106] Creating Layer conv_v4
I0530 09:40:20.342195 25279 net.cpp:454] conv_v4 <- pool_v3
I0530 09:40:20.342209 25279 net.cpp:411] conv_v4 -> conv_v4
I0530 09:40:20.344408 25279 net.cpp:150] Setting up conv_v4
I0530 09:40:20.344431 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:40:20.344444 25279 net.cpp:165] Memory required for data: 467576400
I0530 09:40:20.344460 25279 layer_factory.hpp:77] Creating layer relu_v4
I0530 09:40:20.344472 25279 net.cpp:106] Creating Layer relu_v4
I0530 09:40:20.344483 25279 net.cpp:454] relu_v4 <- conv_v4
I0530 09:40:20.344496 25279 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0530 09:40:20.344830 25279 net.cpp:150] Setting up relu_v4
I0530 09:40:20.344844 25279 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 09:40:20.344854 25279 net.cpp:165] Memory required for data: 471205200
I0530 09:40:20.344864 25279 layer_factory.hpp:77] Creating layer pool_v4
I0530 09:40:20.344877 25279 net.cpp:106] Creating Layer pool_v4
I0530 09:40:20.344898 25279 net.cpp:454] pool_v4 <- conv_v4
I0530 09:40:20.344913 25279 net.cpp:411] pool_v4 -> pool_v4
I0530 09:40:20.344991 25279 net.cpp:150] Setting up pool_v4
I0530 09:40:20.345005 25279 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 09:40:20.345016 25279 net.cpp:165] Memory required for data: 473019600
I0530 09:40:20.345026 25279 layer_factory.hpp:77] Creating layer dl_v1
I0530 09:40:20.345041 25279 net.cpp:106] Creating Layer dl_v1
I0530 09:40:20.345052 25279 net.cpp:454] dl_v1 <- pool_v4
I0530 09:40:20.345065 25279 net.cpp:411] dl_v1 -> dl_v1
I0530 09:40:20.361465 25279 net.cpp:150] Setting up dl_v1
I0530 09:40:20.361495 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.361505 25279 net.cpp:165] Memory required for data: 473098000
I0530 09:40:20.361522 25279 layer_factory.hpp:77] Creating layer relu_v5
I0530 09:40:20.361537 25279 net.cpp:106] Creating Layer relu_v5
I0530 09:40:20.361548 25279 net.cpp:454] relu_v5 <- dl_v1
I0530 09:40:20.361562 25279 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0530 09:40:20.362152 25279 net.cpp:150] Setting up relu_v5
I0530 09:40:20.362174 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.362188 25279 net.cpp:165] Memory required for data: 473176400
I0530 09:40:20.362198 25279 layer_factory.hpp:77] Creating layer drop_v1
I0530 09:40:20.362212 25279 net.cpp:106] Creating Layer drop_v1
I0530 09:40:20.362223 25279 net.cpp:454] drop_v1 <- dl_v1
I0530 09:40:20.362236 25279 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0530 09:40:20.362287 25279 net.cpp:150] Setting up drop_v1
I0530 09:40:20.362299 25279 net.cpp:157] Top shape: 100 196 (19600)
I0530 09:40:20.362309 25279 net.cpp:165] Memory required for data: 473254800
I0530 09:40:20.362319 25279 layer_factory.hpp:77] Creating layer concat_xuv
I0530 09:40:20.362334 25279 net.cpp:106] Creating Layer concat_xuv
I0530 09:40:20.362345 25279 net.cpp:454] concat_xuv <- dl_x1
I0530 09:40:20.362357 25279 net.cpp:454] concat_xuv <- dl_u1
I0530 09:40:20.362370 25279 net.cpp:454] concat_xuv <- dl_v1
I0530 09:40:20.362382 25279 net.cpp:411] concat_xuv -> concat_xuv
I0530 09:40:20.362432 25279 net.cpp:150] Setting up concat_xuv
I0530 09:40:20.362445 25279 net.cpp:157] Top shape: 100 588 (58800)
I0530 09:40:20.362455 25279 net.cpp:165] Memory required for data: 473490000
I0530 09:40:20.362467 25279 layer_factory.hpp:77] Creating layer dl_xuv
I0530 09:40:20.362480 25279 net.cpp:106] Creating Layer dl_xuv
I0530 09:40:20.362490 25279 net.cpp:454] dl_xuv <- concat_xuv
I0530 09:40:20.362504 25279 net.cpp:411] dl_xuv -> dl_xuv
I0530 09:40:20.363559 25279 net.cpp:150] Setting up dl_xuv
I0530 09:40:20.363576 25279 net.cpp:157] Top shape: 100 98 (9800)
I0530 09:40:20.363590 25279 net.cpp:165] Memory required for data: 473529200
I0530 09:40:20.363606 25279 layer_factory.hpp:77] Creating layer relu_xuv
I0530 09:40:20.363620 25279 net.cpp:106] Creating Layer relu_xuv
I0530 09:40:20.363629 25279 net.cpp:454] relu_xuv <- dl_xuv
I0530 09:40:20.363642 25279 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0530 09:40:20.363973 25279 net.cpp:150] Setting up relu_xuv
I0530 09:40:20.363987 25279 net.cpp:157] Top shape: 100 98 (9800)
I0530 09:40:20.363998 25279 net.cpp:165] Memory required for data: 473568400
I0530 09:40:20.364008 25279 layer_factory.hpp:77] Creating layer drop_xuv
I0530 09:40:20.364022 25279 net.cpp:106] Creating Layer drop_xuv
I0530 09:40:20.364032 25279 net.cpp:454] drop_xuv <- dl_xuv
I0530 09:40:20.364044 25279 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0530 09:40:20.364091 25279 net.cpp:150] Setting up drop_xuv
I0530 09:40:20.364104 25279 net.cpp:157] Top shape: 100 98 (9800)
I0530 09:40:20.364114 25279 net.cpp:165] Memory required for data: 473607600
I0530 09:40:20.364125 25279 layer_factory.hpp:77] Creating layer output
I0530 09:40:20.364137 25279 net.cpp:106] Creating Layer output
I0530 09:40:20.364147 25279 net.cpp:454] output <- dl_xuv
I0530 09:40:20.364161 25279 net.cpp:411] output -> output
I0530 09:40:20.364406 25279 net.cpp:150] Setting up output
I0530 09:40:20.364420 25279 net.cpp:157] Top shape: 100 11 (1100)
I0530 09:40:20.364442 25279 net.cpp:165] Memory required for data: 473612000
I0530 09:40:20.364475 25279 layer_factory.hpp:77] Creating layer drop_output
I0530 09:40:20.364488 25279 net.cpp:106] Creating Layer drop_output
I0530 09:40:20.364500 25279 net.cpp:454] drop_output <- output
I0530 09:40:20.364512 25279 net.cpp:397] drop_output -> output (in-place)
I0530 09:40:20.364558 25279 net.cpp:150] Setting up drop_output
I0530 09:40:20.364570 25279 net.cpp:157] Top shape: 100 11 (1100)
I0530 09:40:20.364580 25279 net.cpp:165] Memory required for data: 473616400
I0530 09:40:20.364590 25279 layer_factory.hpp:77] Creating layer output_drop_output_0_split
I0530 09:40:20.364604 25279 net.cpp:106] Creating Layer output_drop_output_0_split
I0530 09:40:20.364614 25279 net.cpp:454] output_drop_output_0_split <- output
I0530 09:40:20.364634 25279 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_0
I0530 09:40:20.364648 25279 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_1
I0530 09:40:20.364724 25279 net.cpp:150] Setting up output_drop_output_0_split
I0530 09:40:20.364739 25279 net.cpp:157] Top shape: 100 11 (1100)
I0530 09:40:20.364750 25279 net.cpp:157] Top shape: 100 11 (1100)
I0530 09:40:20.364760 25279 net.cpp:165] Memory required for data: 473625200
I0530 09:40:20.364770 25279 layer_factory.hpp:77] Creating layer accuracy
I0530 09:40:20.364792 25279 net.cpp:106] Creating Layer accuracy
I0530 09:40:20.364804 25279 net.cpp:454] accuracy <- output_drop_output_0_split_0
I0530 09:40:20.364815 25279 net.cpp:454] accuracy <- segments_data_3_split_0
I0530 09:40:20.364830 25279 net.cpp:411] accuracy -> accuracy
I0530 09:40:20.364853 25279 net.cpp:150] Setting up accuracy
I0530 09:40:20.364866 25279 net.cpp:157] Top shape: (1)
I0530 09:40:20.364874 25279 net.cpp:165] Memory required for data: 473625204
I0530 09:40:20.364886 25279 layer_factory.hpp:77] Creating layer loss
I0530 09:40:20.364899 25279 net.cpp:106] Creating Layer loss
I0530 09:40:20.364909 25279 net.cpp:454] loss <- output_drop_output_0_split_1
I0530 09:40:20.364922 25279 net.cpp:454] loss <- segments_data_3_split_1
I0530 09:40:20.364934 25279 net.cpp:411] loss -> loss
I0530 09:40:20.364953 25279 layer_factory.hpp:77] Creating layer loss
I0530 09:40:20.365665 25279 net.cpp:150] Setting up loss
I0530 09:40:20.365686 25279 net.cpp:157] Top shape: (1)
I0530 09:40:20.365700 25279 net.cpp:160]     with loss weight 1
I0530 09:40:20.365720 25279 net.cpp:165] Memory required for data: 473625208
I0530 09:40:20.365730 25279 net.cpp:226] loss needs backward computation.
I0530 09:40:20.365741 25279 net.cpp:228] accuracy does not need backward computation.
I0530 09:40:20.365752 25279 net.cpp:226] output_drop_output_0_split needs backward computation.
I0530 09:40:20.365763 25279 net.cpp:226] drop_output needs backward computation.
I0530 09:40:20.365774 25279 net.cpp:226] output needs backward computation.
I0530 09:40:20.365783 25279 net.cpp:226] drop_xuv needs backward computation.
I0530 09:40:20.365793 25279 net.cpp:226] relu_xuv needs backward computation.
I0530 09:40:20.365803 25279 net.cpp:226] dl_xuv needs backward computation.
I0530 09:40:20.365814 25279 net.cpp:226] concat_xuv needs backward computation.
I0530 09:40:20.365825 25279 net.cpp:226] drop_v1 needs backward computation.
I0530 09:40:20.365835 25279 net.cpp:226] relu_v5 needs backward computation.
I0530 09:40:20.365845 25279 net.cpp:226] dl_v1 needs backward computation.
I0530 09:40:20.365855 25279 net.cpp:226] pool_v4 needs backward computation.
I0530 09:40:20.365866 25279 net.cpp:226] relu_v4 needs backward computation.
I0530 09:40:20.365876 25279 net.cpp:226] conv_v4 needs backward computation.
I0530 09:40:20.365887 25279 net.cpp:226] pool_v3 needs backward computation.
I0530 09:40:20.365898 25279 net.cpp:226] relu_v3 needs backward computation.
I0530 09:40:20.365908 25279 net.cpp:226] conv_v3 needs backward computation.
I0530 09:40:20.365917 25279 net.cpp:226] pool_v2 needs backward computation.
I0530 09:40:20.365928 25279 net.cpp:226] relu_v2 needs backward computation.
I0530 09:40:20.365948 25279 net.cpp:226] conv_v2 needs backward computation.
I0530 09:40:20.365960 25279 net.cpp:226] pool_v1 needs backward computation.
I0530 09:40:20.365972 25279 net.cpp:226] relu_v1 needs backward computation.
I0530 09:40:20.365981 25279 net.cpp:226] conv_v1 needs backward computation.
I0530 09:40:20.365993 25279 net.cpp:226] drop_u1 needs backward computation.
I0530 09:40:20.366003 25279 net.cpp:226] relu_u5 needs backward computation.
I0530 09:40:20.366014 25279 net.cpp:226] dl_u1 needs backward computation.
I0530 09:40:20.366022 25279 net.cpp:226] pool_u4 needs backward computation.
I0530 09:40:20.366034 25279 net.cpp:226] relu_u4 needs backward computation.
I0530 09:40:20.366044 25279 net.cpp:226] conv_u4 needs backward computation.
I0530 09:40:20.366055 25279 net.cpp:226] pool_u3 needs backward computation.
I0530 09:40:20.366066 25279 net.cpp:226] relu_u3 needs backward computation.
I0530 09:40:20.366076 25279 net.cpp:226] conv_u3 needs backward computation.
I0530 09:40:20.366087 25279 net.cpp:226] pool_u2 needs backward computation.
I0530 09:40:20.366098 25279 net.cpp:226] relu_u2 needs backward computation.
I0530 09:40:20.366108 25279 net.cpp:226] conv_u2 needs backward computation.
I0530 09:40:20.366118 25279 net.cpp:226] pool_u1 needs backward computation.
I0530 09:40:20.366129 25279 net.cpp:226] relu_u1 needs backward computation.
I0530 09:40:20.366140 25279 net.cpp:226] conv_u1 needs backward computation.
I0530 09:40:20.366152 25279 net.cpp:226] drop_x1 needs backward computation.
I0530 09:40:20.366163 25279 net.cpp:226] relu_x5 needs backward computation.
I0530 09:40:20.366173 25279 net.cpp:226] dl_x1 needs backward computation.
I0530 09:40:20.366183 25279 net.cpp:226] pool_x4 needs backward computation.
I0530 09:40:20.366194 25279 net.cpp:226] relu_x4 needs backward computation.
I0530 09:40:20.366204 25279 net.cpp:226] conv_x4 needs backward computation.
I0530 09:40:20.366215 25279 net.cpp:226] pool_x3 needs backward computation.
I0530 09:40:20.366226 25279 net.cpp:226] relu_x3 needs backward computation.
I0530 09:40:20.366236 25279 net.cpp:226] conv_x3 needs backward computation.
I0530 09:40:20.366247 25279 net.cpp:226] pool_x2 needs backward computation.
I0530 09:40:20.366258 25279 net.cpp:226] relu_x2 needs backward computation.
I0530 09:40:20.366269 25279 net.cpp:226] conv_x2 needs backward computation.
I0530 09:40:20.366281 25279 net.cpp:226] pool_x1 needs backward computation.
I0530 09:40:20.366292 25279 net.cpp:226] relu_x1 needs backward computation.
I0530 09:40:20.366302 25279 net.cpp:226] conv_x1 needs backward computation.
I0530 09:40:20.366314 25279 net.cpp:228] segments_data_3_split does not need backward computation.
I0530 09:40:20.366328 25279 net.cpp:228] data does not need backward computation.
I0530 09:40:20.366338 25279 net.cpp:270] This network produces output accuracy
I0530 09:40:20.366348 25279 net.cpp:270] This network produces output loss
I0530 09:40:20.366405 25279 net.cpp:283] Network initialization done.
I0530 09:40:20.366693 25279 solver.cpp:60] Solver scaffolding done.
I0530 09:40:20.369850 25279 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_25000.solverstate
I0530 09:40:20.526439 25279 sgd_solver.cpp:318] SGDSolver: restoring history
I0530 09:40:20.546468 25279 caffe.cpp:212] Starting Optimization
I0530 09:40:20.546514 25279 solver.cpp:288] Solving epsilon_127x50_xuv
I0530 09:40:20.546525 25279 solver.cpp:289] Learning Rate Policy: fixed
I0530 09:40:20.549020 25279 solver.cpp:341] Iteration 25000, Testing net (#0)
I0530 09:42:38.415171 25279 solver.cpp:409]     Test net output #0: accuracy = 0.873214
I0530 09:42:38.415352 25279 solver.cpp:409]     Test net output #1: loss = 0.406681 (* 1 = 0.406681 loss)
I0530 09:42:38.486348 25279 solver.cpp:237] Iteration 25000, loss = 1.12805
I0530 09:42:38.486384 25279 solver.cpp:253]     Train net output #0: loss = 1.12805 (* 1 = 1.12805 loss)
I0530 09:42:38.486403 25279 sgd_solver.cpp:106] Iteration 25000, lr = 0.0025
I0530 10:01:18.463593 25279 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_30000.caffemodel
I0530 10:01:18.737982 25279 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_30000.solverstate
I0530 10:01:18.819970 25279 solver.cpp:341] Iteration 30000, Testing net (#0)
I0530 10:03:33.521657 25279 solver.cpp:409]     Test net output #0: accuracy = 0.878707
I0530 10:03:33.521831 25279 solver.cpp:409]     Test net output #1: loss = 0.402868 (* 1 = 0.402868 loss)
I0530 10:04:40.878608 25279 solver.cpp:237] Iteration 30000, loss = 1.03394
I0530 10:04:40.878795 25279 solver.cpp:253]     Train net output #0: loss = 1.03394 (* 1 = 1.03394 loss)
I0530 10:04:40.878810 25279 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0530 10:23:21.571321 25279 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_35000.caffemodel
I0530 10:23:21.836998 25279 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_35000.solverstate
I0530 10:23:21.920821 25279 solver.cpp:341] Iteration 35000, Testing net (#0)
I0530 10:26:40.161873 25279 solver.cpp:409]     Test net output #0: accuracy = 0.884941
I0530 10:26:40.162056 25279 solver.cpp:409]     Test net output #1: loss = 0.376889 (* 1 = 0.376889 loss)
I0530 10:27:47.459092 25279 solver.cpp:237] Iteration 35000, loss = 1.25839
I0530 10:27:47.459280 25279 solver.cpp:253]     Train net output #0: loss = 1.25839 (* 1 = 1.25839 loss)
I0530 10:27:47.459295 25279 sgd_solver.cpp:106] Iteration 35000, lr = 0.0025
I0530 10:46:27.851057 25279 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_40000.caffemodel
I0530 10:46:28.117063 25279 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_40000.solverstate
I0530 10:46:28.200980 25279 solver.cpp:341] Iteration 40000, Testing net (#0)
I0530 10:48:41.891067 25279 solver.cpp:409]     Test net output #0: accuracy = 0.888269
I0530 10:48:41.891252 25279 solver.cpp:409]     Test net output #1: loss = 0.376396 (* 1 = 0.376396 loss)
I0530 10:49:45.101447 25279 solver.cpp:237] Iteration 40000, loss = 1.29574
I0530 10:49:45.101625 25279 solver.cpp:253]     Train net output #0: loss = 1.29574 (* 1 = 1.29574 loss)
I0530 10:49:45.101642 25279 sgd_solver.cpp:106] Iteration 40000, lr = 0.0025
I0530 11:08:43.802892 25279 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_45000.caffemodel
I0530 11:08:44.067765 25279 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_45000.solverstate
I0530 11:08:44.151324 25279 solver.cpp:341] Iteration 45000, Testing net (#0)
I0530 11:12:02.433929 25279 solver.cpp:409]     Test net output #0: accuracy = 0.892856
I0530 11:12:02.434109 25279 solver.cpp:409]     Test net output #1: loss = 0.340625 (* 1 = 0.340625 loss)
I0530 11:13:05.811197 25279 solver.cpp:237] Iteration 45000, loss = 0.967166
I0530 11:13:05.811381 25279 solver.cpp:253]     Train net output #0: loss = 0.967166 (* 1 = 0.967166 loss)
I0530 11:13:05.811398 25279 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0530 11:31:30.079355 25279 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_50000.caffemodel
I0530 11:31:30.337762 25279 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_noada_2016-05-30T07.36.54.892099_iter_50000.solverstate
I0530 11:31:30.421380 25279 solver.cpp:341] Iteration 50000, Testing net (#0)
I0530 11:33:45.079102 25279 solver.cpp:409]     Test net output #0: accuracy = 0.897775
I0530 11:33:45.079293 25279 solver.cpp:409]     Test net output #1: loss = 0.332134 (* 1 = 0.332134 loss)
I0530 11:34:48.356248 25279 solver.cpp:237] Iteration 50000, loss = 1.30638
I0530 11:34:48.356429 25279 solver.cpp:253]     Train net output #0: loss = 1.30638 (* 1 = 1.30638 loss)
I0530 11:34:48.356447 25279 sgd_solver.cpp:106] Iteration 50000, lr = 0.0025
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
*** Aborted at 1464622687 (unix time) try "date -d @1464622687" if you are using GNU date ***
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9bb28 (unknown)
*** SIGTERM (@0x62bc) received by PID 25279 (TID 0x2aaac746f900) from PID 25276; stack trace: ***
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaac5e9bb28 (unknown)
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11285443: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7208 exceeded limit 7200
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11285443: Caught signal Terminated, sending to application
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11285443: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
