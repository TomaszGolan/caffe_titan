2815843
I0529 15:16:27.611733 16806 caffe.cpp:184] Using GPUs 0
I0529 15:16:28.039741 16806 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 15000
base_lr: 0.0025
display: 1500
max_iter: 150000
lr_policy: "fixed"
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_xuv_2016-05-29T11.13.49.302090"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_xuv_2016-05-29T11.13.49.302090.prototxt"
type: "AdaGrad"
I0529 15:16:28.041769 16806 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_xuv_2016-05-29T11.13.49.302090.prototxt
I0529 15:16:28.059000 16806 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0529 15:16:28.059085 16806 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0529 15:16:28.059826 16806 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0529 15:16:28.060184 16806 layer_factory.hpp:77] Creating layer data
I0529 15:16:28.060206 16806 net.cpp:106] Creating Layer data
I0529 15:16:28.060221 16806 net.cpp:411] data -> hits-x
I0529 15:16:28.060256 16806 net.cpp:411] data -> hits-u
I0529 15:16:28.060277 16806 net.cpp:411] data -> hits-v
I0529 15:16:28.060292 16806 net.cpp:411] data -> segments
I0529 15:16:28.060315 16806 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist
I0529 15:16:28.072115 16806 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0529 15:16:28.112597 16806 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0529 15:17:32.424162 16806 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0529 15:17:32.429905 16806 net.cpp:150] Setting up data
I0529 15:17:32.429949 16806 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 15:17:32.429965 16806 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 15:17:32.429977 16806 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 15:17:32.429989 16806 net.cpp:157] Top shape: 100 (100)
I0529 15:17:32.429999 16806 net.cpp:165] Memory required for data: 7620400
I0529 15:17:32.430012 16806 layer_factory.hpp:77] Creating layer conv_x1
I0529 15:17:32.430047 16806 net.cpp:106] Creating Layer conv_x1
I0529 15:17:32.430058 16806 net.cpp:454] conv_x1 <- hits-x
I0529 15:17:32.430080 16806 net.cpp:411] conv_x1 -> conv_x1
I0529 15:17:35.475293 16806 net.cpp:150] Setting up conv_x1
I0529 15:17:35.475338 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:17:35.475350 16806 net.cpp:165] Memory required for data: 35268400
I0529 15:17:35.475381 16806 layer_factory.hpp:77] Creating layer relu_x1
I0529 15:17:35.475404 16806 net.cpp:106] Creating Layer relu_x1
I0529 15:17:35.475414 16806 net.cpp:454] relu_x1 <- conv_x1
I0529 15:17:35.475428 16806 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0529 15:17:35.475949 16806 net.cpp:150] Setting up relu_x1
I0529 15:17:35.475965 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:17:35.475976 16806 net.cpp:165] Memory required for data: 62916400
I0529 15:17:35.475986 16806 layer_factory.hpp:77] Creating layer pool_x1
I0529 15:17:35.476004 16806 net.cpp:106] Creating Layer pool_x1
I0529 15:17:35.476014 16806 net.cpp:454] pool_x1 <- conv_x1
I0529 15:17:35.476028 16806 net.cpp:411] pool_x1 -> pool_x1
I0529 15:17:35.476109 16806 net.cpp:150] Setting up pool_x1
I0529 15:17:35.476124 16806 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 15:17:35.476133 16806 net.cpp:165] Memory required for data: 76740400
I0529 15:17:35.476145 16806 layer_factory.hpp:77] Creating layer conv_x2
I0529 15:17:35.476166 16806 net.cpp:106] Creating Layer conv_x2
I0529 15:17:35.476177 16806 net.cpp:454] conv_x2 <- pool_x1
I0529 15:17:35.476191 16806 net.cpp:411] conv_x2 -> conv_x2
I0529 15:17:35.478875 16806 net.cpp:150] Setting up conv_x2
I0529 15:17:35.478904 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:17:35.478916 16806 net.cpp:165] Memory required for data: 96612400
I0529 15:17:35.478936 16806 layer_factory.hpp:77] Creating layer relu_x2
I0529 15:17:35.478951 16806 net.cpp:106] Creating Layer relu_x2
I0529 15:17:35.478961 16806 net.cpp:454] relu_x2 <- conv_x2
I0529 15:17:35.478976 16806 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0529 15:17:35.479317 16806 net.cpp:150] Setting up relu_x2
I0529 15:17:35.479332 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:17:35.479343 16806 net.cpp:165] Memory required for data: 116484400
I0529 15:17:35.479353 16806 layer_factory.hpp:77] Creating layer pool_x2
I0529 15:17:35.479367 16806 net.cpp:106] Creating Layer pool_x2
I0529 15:17:35.479377 16806 net.cpp:454] pool_x2 <- conv_x2
I0529 15:17:35.479390 16806 net.cpp:411] pool_x2 -> pool_x2
I0529 15:17:35.479460 16806 net.cpp:150] Setting up pool_x2
I0529 15:17:35.479472 16806 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 15:17:35.479482 16806 net.cpp:165] Memory required for data: 126420400
I0529 15:17:35.479491 16806 layer_factory.hpp:77] Creating layer conv_x3
I0529 15:17:35.479509 16806 net.cpp:106] Creating Layer conv_x3
I0529 15:17:35.479521 16806 net.cpp:454] conv_x3 <- pool_x2
I0529 15:17:35.479534 16806 net.cpp:411] conv_x3 -> conv_x3
I0529 15:17:35.481452 16806 net.cpp:150] Setting up conv_x3
I0529 15:17:35.481478 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:17:35.481490 16806 net.cpp:165] Memory required for data: 137262000
I0529 15:17:35.481508 16806 layer_factory.hpp:77] Creating layer relu_x3
I0529 15:17:35.481525 16806 net.cpp:106] Creating Layer relu_x3
I0529 15:17:35.481535 16806 net.cpp:454] relu_x3 <- conv_x3
I0529 15:17:35.481549 16806 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0529 15:17:35.482018 16806 net.cpp:150] Setting up relu_x3
I0529 15:17:35.482034 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:17:35.482056 16806 net.cpp:165] Memory required for data: 148103600
I0529 15:17:35.482067 16806 layer_factory.hpp:77] Creating layer pool_x3
I0529 15:17:35.482081 16806 net.cpp:106] Creating Layer pool_x3
I0529 15:17:35.482091 16806 net.cpp:454] pool_x3 <- conv_x3
I0529 15:17:35.482105 16806 net.cpp:411] pool_x3 -> pool_x3
I0529 15:17:35.482174 16806 net.cpp:150] Setting up pool_x3
I0529 15:17:35.482187 16806 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 15:17:35.482200 16806 net.cpp:165] Memory required for data: 153524400
I0529 15:17:35.482210 16806 layer_factory.hpp:77] Creating layer conv_x4
I0529 15:17:35.482228 16806 net.cpp:106] Creating Layer conv_x4
I0529 15:17:35.482239 16806 net.cpp:454] conv_x4 <- pool_x3
I0529 15:17:35.482252 16806 net.cpp:411] conv_x4 -> conv_x4
I0529 15:17:35.485239 16806 net.cpp:150] Setting up conv_x4
I0529 15:17:35.485262 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:17:35.485272 16806 net.cpp:165] Memory required for data: 157153200
I0529 15:17:35.485288 16806 layer_factory.hpp:77] Creating layer relu_x4
I0529 15:17:35.485303 16806 net.cpp:106] Creating Layer relu_x4
I0529 15:17:35.485314 16806 net.cpp:454] relu_x4 <- conv_x4
I0529 15:17:35.485327 16806 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0529 15:17:35.485793 16806 net.cpp:150] Setting up relu_x4
I0529 15:17:35.485810 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:17:35.485821 16806 net.cpp:165] Memory required for data: 160782000
I0529 15:17:35.485831 16806 layer_factory.hpp:77] Creating layer pool_x4
I0529 15:17:35.485844 16806 net.cpp:106] Creating Layer pool_x4
I0529 15:17:35.485854 16806 net.cpp:454] pool_x4 <- conv_x4
I0529 15:17:35.485868 16806 net.cpp:411] pool_x4 -> pool_x4
I0529 15:17:35.485939 16806 net.cpp:150] Setting up pool_x4
I0529 15:17:35.485951 16806 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 15:17:35.485962 16806 net.cpp:165] Memory required for data: 162596400
I0529 15:17:35.485972 16806 layer_factory.hpp:77] Creating layer dl_x1
I0529 15:17:35.485992 16806 net.cpp:106] Creating Layer dl_x1
I0529 15:17:35.486003 16806 net.cpp:454] dl_x1 <- pool_x4
I0529 15:17:35.486016 16806 net.cpp:411] dl_x1 -> dl_x1
I0529 15:17:35.501469 16806 net.cpp:150] Setting up dl_x1
I0529 15:17:35.501497 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.501510 16806 net.cpp:165] Memory required for data: 162674800
I0529 15:17:35.501533 16806 layer_factory.hpp:77] Creating layer relu_x5
I0529 15:17:35.501549 16806 net.cpp:106] Creating Layer relu_x5
I0529 15:17:35.501559 16806 net.cpp:454] relu_x5 <- dl_x1
I0529 15:17:35.501572 16806 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0529 15:17:35.501914 16806 net.cpp:150] Setting up relu_x5
I0529 15:17:35.501929 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.501938 16806 net.cpp:165] Memory required for data: 162753200
I0529 15:17:35.501948 16806 layer_factory.hpp:77] Creating layer drop_x1
I0529 15:17:35.501970 16806 net.cpp:106] Creating Layer drop_x1
I0529 15:17:35.501981 16806 net.cpp:454] drop_x1 <- dl_x1
I0529 15:17:35.501993 16806 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0529 15:17:35.502038 16806 net.cpp:150] Setting up drop_x1
I0529 15:17:35.502051 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.502061 16806 net.cpp:165] Memory required for data: 162831600
I0529 15:17:35.502071 16806 layer_factory.hpp:77] Creating layer conv_u1
I0529 15:17:35.502094 16806 net.cpp:106] Creating Layer conv_u1
I0529 15:17:35.502104 16806 net.cpp:454] conv_u1 <- hits-u
I0529 15:17:35.502117 16806 net.cpp:411] conv_u1 -> conv_u1
I0529 15:17:35.503953 16806 net.cpp:150] Setting up conv_u1
I0529 15:17:35.503976 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:17:35.503989 16806 net.cpp:165] Memory required for data: 190479600
I0529 15:17:35.504004 16806 layer_factory.hpp:77] Creating layer relu_u1
I0529 15:17:35.504019 16806 net.cpp:106] Creating Layer relu_u1
I0529 15:17:35.504029 16806 net.cpp:454] relu_u1 <- conv_u1
I0529 15:17:35.504041 16806 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0529 15:17:35.504523 16806 net.cpp:150] Setting up relu_u1
I0529 15:17:35.504541 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:17:35.504551 16806 net.cpp:165] Memory required for data: 218127600
I0529 15:17:35.504562 16806 layer_factory.hpp:77] Creating layer pool_u1
I0529 15:17:35.504575 16806 net.cpp:106] Creating Layer pool_u1
I0529 15:17:35.504586 16806 net.cpp:454] pool_u1 <- conv_u1
I0529 15:17:35.504600 16806 net.cpp:411] pool_u1 -> pool_u1
I0529 15:17:35.504670 16806 net.cpp:150] Setting up pool_u1
I0529 15:17:35.504684 16806 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 15:17:35.504694 16806 net.cpp:165] Memory required for data: 231951600
I0529 15:17:35.504704 16806 layer_factory.hpp:77] Creating layer conv_u2
I0529 15:17:35.504722 16806 net.cpp:106] Creating Layer conv_u2
I0529 15:17:35.504734 16806 net.cpp:454] conv_u2 <- pool_u1
I0529 15:17:35.504747 16806 net.cpp:411] conv_u2 -> conv_u2
I0529 15:17:35.506563 16806 net.cpp:150] Setting up conv_u2
I0529 15:17:35.506587 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:17:35.506598 16806 net.cpp:165] Memory required for data: 251823600
I0529 15:17:35.506613 16806 layer_factory.hpp:77] Creating layer relu_u2
I0529 15:17:35.506626 16806 net.cpp:106] Creating Layer relu_u2
I0529 15:17:35.506636 16806 net.cpp:454] relu_u2 <- conv_u2
I0529 15:17:35.506649 16806 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0529 15:17:35.506969 16806 net.cpp:150] Setting up relu_u2
I0529 15:17:35.506984 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:17:35.506994 16806 net.cpp:165] Memory required for data: 271695600
I0529 15:17:35.507004 16806 layer_factory.hpp:77] Creating layer pool_u2
I0529 15:17:35.507017 16806 net.cpp:106] Creating Layer pool_u2
I0529 15:17:35.507027 16806 net.cpp:454] pool_u2 <- conv_u2
I0529 15:17:35.507040 16806 net.cpp:411] pool_u2 -> pool_u2
I0529 15:17:35.507113 16806 net.cpp:150] Setting up pool_u2
I0529 15:17:35.507138 16806 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 15:17:35.507148 16806 net.cpp:165] Memory required for data: 281631600
I0529 15:17:35.507159 16806 layer_factory.hpp:77] Creating layer conv_u3
I0529 15:17:35.507176 16806 net.cpp:106] Creating Layer conv_u3
I0529 15:17:35.507189 16806 net.cpp:454] conv_u3 <- pool_u2
I0529 15:17:35.507201 16806 net.cpp:411] conv_u3 -> conv_u3
I0529 15:17:35.509109 16806 net.cpp:150] Setting up conv_u3
I0529 15:17:35.509126 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:17:35.509137 16806 net.cpp:165] Memory required for data: 292473200
I0529 15:17:35.509152 16806 layer_factory.hpp:77] Creating layer relu_u3
I0529 15:17:35.509166 16806 net.cpp:106] Creating Layer relu_u3
I0529 15:17:35.509176 16806 net.cpp:454] relu_u3 <- conv_u3
I0529 15:17:35.509188 16806 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0529 15:17:35.509521 16806 net.cpp:150] Setting up relu_u3
I0529 15:17:35.509533 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:17:35.509544 16806 net.cpp:165] Memory required for data: 303314800
I0529 15:17:35.509554 16806 layer_factory.hpp:77] Creating layer pool_u3
I0529 15:17:35.509567 16806 net.cpp:106] Creating Layer pool_u3
I0529 15:17:35.509577 16806 net.cpp:454] pool_u3 <- conv_u3
I0529 15:17:35.509589 16806 net.cpp:411] pool_u3 -> pool_u3
I0529 15:17:35.509659 16806 net.cpp:150] Setting up pool_u3
I0529 15:17:35.509671 16806 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 15:17:35.509681 16806 net.cpp:165] Memory required for data: 308735600
I0529 15:17:35.509691 16806 layer_factory.hpp:77] Creating layer conv_u4
I0529 15:17:35.509711 16806 net.cpp:106] Creating Layer conv_u4
I0529 15:17:35.509721 16806 net.cpp:454] conv_u4 <- pool_u3
I0529 15:17:35.509737 16806 net.cpp:411] conv_u4 -> conv_u4
I0529 15:17:35.511935 16806 net.cpp:150] Setting up conv_u4
I0529 15:17:35.511958 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:17:35.511970 16806 net.cpp:165] Memory required for data: 312364400
I0529 15:17:35.511992 16806 layer_factory.hpp:77] Creating layer relu_u4
I0529 15:17:35.512006 16806 net.cpp:106] Creating Layer relu_u4
I0529 15:17:35.512025 16806 net.cpp:454] relu_u4 <- conv_u4
I0529 15:17:35.512038 16806 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0529 15:17:35.512511 16806 net.cpp:150] Setting up relu_u4
I0529 15:17:35.512527 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:17:35.512538 16806 net.cpp:165] Memory required for data: 315993200
I0529 15:17:35.512548 16806 layer_factory.hpp:77] Creating layer pool_u4
I0529 15:17:35.512560 16806 net.cpp:106] Creating Layer pool_u4
I0529 15:17:35.512570 16806 net.cpp:454] pool_u4 <- conv_u4
I0529 15:17:35.512583 16806 net.cpp:411] pool_u4 -> pool_u4
I0529 15:17:35.512652 16806 net.cpp:150] Setting up pool_u4
I0529 15:17:35.512666 16806 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 15:17:35.512676 16806 net.cpp:165] Memory required for data: 317807600
I0529 15:17:35.512687 16806 layer_factory.hpp:77] Creating layer dl_u1
I0529 15:17:35.512701 16806 net.cpp:106] Creating Layer dl_u1
I0529 15:17:35.512712 16806 net.cpp:454] dl_u1 <- pool_u4
I0529 15:17:35.512727 16806 net.cpp:411] dl_u1 -> dl_u1
I0529 15:17:35.528236 16806 net.cpp:150] Setting up dl_u1
I0529 15:17:35.528264 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.528275 16806 net.cpp:165] Memory required for data: 317886000
I0529 15:17:35.528291 16806 layer_factory.hpp:77] Creating layer relu_u5
I0529 15:17:35.528306 16806 net.cpp:106] Creating Layer relu_u5
I0529 15:17:35.528316 16806 net.cpp:454] relu_u5 <- dl_u1
I0529 15:17:35.528331 16806 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0529 15:17:35.528676 16806 net.cpp:150] Setting up relu_u5
I0529 15:17:35.528689 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.528699 16806 net.cpp:165] Memory required for data: 317964400
I0529 15:17:35.528709 16806 layer_factory.hpp:77] Creating layer drop_u1
I0529 15:17:35.528723 16806 net.cpp:106] Creating Layer drop_u1
I0529 15:17:35.528733 16806 net.cpp:454] drop_u1 <- dl_u1
I0529 15:17:35.528745 16806 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0529 15:17:35.528789 16806 net.cpp:150] Setting up drop_u1
I0529 15:17:35.528801 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.528811 16806 net.cpp:165] Memory required for data: 318042800
I0529 15:17:35.528822 16806 layer_factory.hpp:77] Creating layer conv_v1
I0529 15:17:35.528838 16806 net.cpp:106] Creating Layer conv_v1
I0529 15:17:35.528849 16806 net.cpp:454] conv_v1 <- hits-v
I0529 15:17:35.528863 16806 net.cpp:411] conv_v1 -> conv_v1
I0529 15:17:35.530716 16806 net.cpp:150] Setting up conv_v1
I0529 15:17:35.530738 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:17:35.530750 16806 net.cpp:165] Memory required for data: 345690800
I0529 15:17:35.530766 16806 layer_factory.hpp:77] Creating layer relu_v1
I0529 15:17:35.530788 16806 net.cpp:106] Creating Layer relu_v1
I0529 15:17:35.530798 16806 net.cpp:454] relu_v1 <- conv_v1
I0529 15:17:35.530812 16806 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0529 15:17:35.531288 16806 net.cpp:150] Setting up relu_v1
I0529 15:17:35.531306 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:17:35.531316 16806 net.cpp:165] Memory required for data: 373338800
I0529 15:17:35.531327 16806 layer_factory.hpp:77] Creating layer pool_v1
I0529 15:17:35.531340 16806 net.cpp:106] Creating Layer pool_v1
I0529 15:17:35.531350 16806 net.cpp:454] pool_v1 <- conv_v1
I0529 15:17:35.531363 16806 net.cpp:411] pool_v1 -> pool_v1
I0529 15:17:35.531436 16806 net.cpp:150] Setting up pool_v1
I0529 15:17:35.531450 16806 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 15:17:35.531460 16806 net.cpp:165] Memory required for data: 387162800
I0529 15:17:35.531467 16806 layer_factory.hpp:77] Creating layer conv_v2
I0529 15:17:35.531484 16806 net.cpp:106] Creating Layer conv_v2
I0529 15:17:35.531494 16806 net.cpp:454] conv_v2 <- pool_v1
I0529 15:17:35.531508 16806 net.cpp:411] conv_v2 -> conv_v2
I0529 15:17:35.533200 16806 net.cpp:150] Setting up conv_v2
I0529 15:17:35.533216 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:17:35.533227 16806 net.cpp:165] Memory required for data: 407034800
I0529 15:17:35.533257 16806 layer_factory.hpp:77] Creating layer relu_v2
I0529 15:17:35.533270 16806 net.cpp:106] Creating Layer relu_v2
I0529 15:17:35.533280 16806 net.cpp:454] relu_v2 <- conv_v2
I0529 15:17:35.533293 16806 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0529 15:17:35.533771 16806 net.cpp:150] Setting up relu_v2
I0529 15:17:35.533788 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:17:35.533798 16806 net.cpp:165] Memory required for data: 426906800
I0529 15:17:35.533809 16806 layer_factory.hpp:77] Creating layer pool_v2
I0529 15:17:35.533823 16806 net.cpp:106] Creating Layer pool_v2
I0529 15:17:35.533833 16806 net.cpp:454] pool_v2 <- conv_v2
I0529 15:17:35.533845 16806 net.cpp:411] pool_v2 -> pool_v2
I0529 15:17:35.533916 16806 net.cpp:150] Setting up pool_v2
I0529 15:17:35.533931 16806 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 15:17:35.533939 16806 net.cpp:165] Memory required for data: 436842800
I0529 15:17:35.533948 16806 layer_factory.hpp:77] Creating layer conv_v3
I0529 15:17:35.533967 16806 net.cpp:106] Creating Layer conv_v3
I0529 15:17:35.533977 16806 net.cpp:454] conv_v3 <- pool_v2
I0529 15:17:35.533990 16806 net.cpp:411] conv_v3 -> conv_v3
I0529 15:17:35.535926 16806 net.cpp:150] Setting up conv_v3
I0529 15:17:35.535948 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:17:35.535961 16806 net.cpp:165] Memory required for data: 447684400
I0529 15:17:35.535976 16806 layer_factory.hpp:77] Creating layer relu_v3
I0529 15:17:35.535990 16806 net.cpp:106] Creating Layer relu_v3
I0529 15:17:35.536000 16806 net.cpp:454] relu_v3 <- conv_v3
I0529 15:17:35.536013 16806 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0529 15:17:35.536334 16806 net.cpp:150] Setting up relu_v3
I0529 15:17:35.536347 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:17:35.536357 16806 net.cpp:165] Memory required for data: 458526000
I0529 15:17:35.536367 16806 layer_factory.hpp:77] Creating layer pool_v3
I0529 15:17:35.536381 16806 net.cpp:106] Creating Layer pool_v3
I0529 15:17:35.536391 16806 net.cpp:454] pool_v3 <- conv_v3
I0529 15:17:35.536402 16806 net.cpp:411] pool_v3 -> pool_v3
I0529 15:17:35.536471 16806 net.cpp:150] Setting up pool_v3
I0529 15:17:35.536485 16806 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 15:17:35.536495 16806 net.cpp:165] Memory required for data: 463946800
I0529 15:17:35.536506 16806 layer_factory.hpp:77] Creating layer conv_v4
I0529 15:17:35.536522 16806 net.cpp:106] Creating Layer conv_v4
I0529 15:17:35.536533 16806 net.cpp:454] conv_v4 <- pool_v3
I0529 15:17:35.536548 16806 net.cpp:411] conv_v4 -> conv_v4
I0529 15:17:35.538614 16806 net.cpp:150] Setting up conv_v4
I0529 15:17:35.538636 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:17:35.538648 16806 net.cpp:165] Memory required for data: 467575600
I0529 15:17:35.538664 16806 layer_factory.hpp:77] Creating layer relu_v4
I0529 15:17:35.538677 16806 net.cpp:106] Creating Layer relu_v4
I0529 15:17:35.538688 16806 net.cpp:454] relu_v4 <- conv_v4
I0529 15:17:35.538700 16806 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0529 15:17:35.539186 16806 net.cpp:150] Setting up relu_v4
I0529 15:17:35.539203 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:17:35.539213 16806 net.cpp:165] Memory required for data: 471204400
I0529 15:17:35.539223 16806 layer_factory.hpp:77] Creating layer pool_v4
I0529 15:17:35.539237 16806 net.cpp:106] Creating Layer pool_v4
I0529 15:17:35.539247 16806 net.cpp:454] pool_v4 <- conv_v4
I0529 15:17:35.539260 16806 net.cpp:411] pool_v4 -> pool_v4
I0529 15:17:35.539333 16806 net.cpp:150] Setting up pool_v4
I0529 15:17:35.539347 16806 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 15:17:35.539357 16806 net.cpp:165] Memory required for data: 473018800
I0529 15:17:35.539367 16806 layer_factory.hpp:77] Creating layer dl_v1
I0529 15:17:35.539382 16806 net.cpp:106] Creating Layer dl_v1
I0529 15:17:35.539393 16806 net.cpp:454] dl_v1 <- pool_v4
I0529 15:17:35.539408 16806 net.cpp:411] dl_v1 -> dl_v1
I0529 15:17:35.554873 16806 net.cpp:150] Setting up dl_v1
I0529 15:17:35.554913 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.554925 16806 net.cpp:165] Memory required for data: 473097200
I0529 15:17:35.554942 16806 layer_factory.hpp:77] Creating layer relu_v5
I0529 15:17:35.554956 16806 net.cpp:106] Creating Layer relu_v5
I0529 15:17:35.554967 16806 net.cpp:454] relu_v5 <- dl_v1
I0529 15:17:35.554980 16806 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0529 15:17:35.555342 16806 net.cpp:150] Setting up relu_v5
I0529 15:17:35.555356 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.555367 16806 net.cpp:165] Memory required for data: 473175600
I0529 15:17:35.555377 16806 layer_factory.hpp:77] Creating layer drop_v1
I0529 15:17:35.555390 16806 net.cpp:106] Creating Layer drop_v1
I0529 15:17:35.555400 16806 net.cpp:454] drop_v1 <- dl_v1
I0529 15:17:35.555413 16806 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0529 15:17:35.555457 16806 net.cpp:150] Setting up drop_v1
I0529 15:17:35.555470 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:17:35.555481 16806 net.cpp:165] Memory required for data: 473254000
I0529 15:17:35.555490 16806 layer_factory.hpp:77] Creating layer concat_xuv
I0529 15:17:35.555511 16806 net.cpp:106] Creating Layer concat_xuv
I0529 15:17:35.555521 16806 net.cpp:454] concat_xuv <- dl_x1
I0529 15:17:35.555533 16806 net.cpp:454] concat_xuv <- dl_u1
I0529 15:17:35.555546 16806 net.cpp:454] concat_xuv <- dl_v1
I0529 15:17:35.555558 16806 net.cpp:411] concat_xuv -> concat_xuv
I0529 15:17:35.555610 16806 net.cpp:150] Setting up concat_xuv
I0529 15:17:35.555624 16806 net.cpp:157] Top shape: 100 588 (58800)
I0529 15:17:35.555634 16806 net.cpp:165] Memory required for data: 473489200
I0529 15:17:35.555646 16806 layer_factory.hpp:77] Creating layer dl_xuv
I0529 15:17:35.555660 16806 net.cpp:106] Creating Layer dl_xuv
I0529 15:17:35.555670 16806 net.cpp:454] dl_xuv <- concat_xuv
I0529 15:17:35.555685 16806 net.cpp:411] dl_xuv -> dl_xuv
I0529 15:17:35.556716 16806 net.cpp:150] Setting up dl_xuv
I0529 15:17:35.556736 16806 net.cpp:157] Top shape: 100 98 (9800)
I0529 15:17:35.556746 16806 net.cpp:165] Memory required for data: 473528400
I0529 15:17:35.556761 16806 layer_factory.hpp:77] Creating layer relu_xuv
I0529 15:17:35.556776 16806 net.cpp:106] Creating Layer relu_xuv
I0529 15:17:35.556784 16806 net.cpp:454] relu_xuv <- dl_xuv
I0529 15:17:35.556797 16806 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0529 15:17:35.557370 16806 net.cpp:150] Setting up relu_xuv
I0529 15:17:35.557387 16806 net.cpp:157] Top shape: 100 98 (9800)
I0529 15:17:35.557399 16806 net.cpp:165] Memory required for data: 473567600
I0529 15:17:35.557407 16806 layer_factory.hpp:77] Creating layer drop_xuv
I0529 15:17:35.557421 16806 net.cpp:106] Creating Layer drop_xuv
I0529 15:17:35.557431 16806 net.cpp:454] drop_xuv <- dl_xuv
I0529 15:17:35.557445 16806 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0529 15:17:35.557489 16806 net.cpp:150] Setting up drop_xuv
I0529 15:17:35.557503 16806 net.cpp:157] Top shape: 100 98 (9800)
I0529 15:17:35.557513 16806 net.cpp:165] Memory required for data: 473606800
I0529 15:17:35.557523 16806 layer_factory.hpp:77] Creating layer output
I0529 15:17:35.557538 16806 net.cpp:106] Creating Layer output
I0529 15:17:35.557546 16806 net.cpp:454] output <- dl_xuv
I0529 15:17:35.557560 16806 net.cpp:411] output -> output
I0529 15:17:35.557790 16806 net.cpp:150] Setting up output
I0529 15:17:35.557803 16806 net.cpp:157] Top shape: 100 11 (1100)
I0529 15:17:35.557812 16806 net.cpp:165] Memory required for data: 473611200
I0529 15:17:35.557843 16806 layer_factory.hpp:77] Creating layer drop_output
I0529 15:17:35.557857 16806 net.cpp:106] Creating Layer drop_output
I0529 15:17:35.557865 16806 net.cpp:454] drop_output <- output
I0529 15:17:35.557878 16806 net.cpp:397] drop_output -> output (in-place)
I0529 15:17:35.557922 16806 net.cpp:150] Setting up drop_output
I0529 15:17:35.557935 16806 net.cpp:157] Top shape: 100 11 (1100)
I0529 15:17:35.557945 16806 net.cpp:165] Memory required for data: 473615600
I0529 15:17:35.557955 16806 layer_factory.hpp:77] Creating layer loss
I0529 15:17:35.557983 16806 net.cpp:106] Creating Layer loss
I0529 15:17:35.557994 16806 net.cpp:454] loss <- output
I0529 15:17:35.558006 16806 net.cpp:454] loss <- segments
I0529 15:17:35.558018 16806 net.cpp:411] loss -> loss
I0529 15:17:35.558037 16806 layer_factory.hpp:77] Creating layer loss
I0529 15:17:35.558536 16806 net.cpp:150] Setting up loss
I0529 15:17:35.558549 16806 net.cpp:157] Top shape: (1)
I0529 15:17:35.558558 16806 net.cpp:160]     with loss weight 1
I0529 15:17:35.558605 16806 net.cpp:165] Memory required for data: 473615604
I0529 15:17:35.558615 16806 net.cpp:226] loss needs backward computation.
I0529 15:17:35.558626 16806 net.cpp:226] drop_output needs backward computation.
I0529 15:17:35.558636 16806 net.cpp:226] output needs backward computation.
I0529 15:17:35.558647 16806 net.cpp:226] drop_xuv needs backward computation.
I0529 15:17:35.558657 16806 net.cpp:226] relu_xuv needs backward computation.
I0529 15:17:35.558667 16806 net.cpp:226] dl_xuv needs backward computation.
I0529 15:17:35.558678 16806 net.cpp:226] concat_xuv needs backward computation.
I0529 15:17:35.558689 16806 net.cpp:226] drop_v1 needs backward computation.
I0529 15:17:35.558698 16806 net.cpp:226] relu_v5 needs backward computation.
I0529 15:17:35.558708 16806 net.cpp:226] dl_v1 needs backward computation.
I0529 15:17:35.558719 16806 net.cpp:226] pool_v4 needs backward computation.
I0529 15:17:35.558732 16806 net.cpp:226] relu_v4 needs backward computation.
I0529 15:17:35.558742 16806 net.cpp:226] conv_v4 needs backward computation.
I0529 15:17:35.558753 16806 net.cpp:226] pool_v3 needs backward computation.
I0529 15:17:35.558763 16806 net.cpp:226] relu_v3 needs backward computation.
I0529 15:17:35.558773 16806 net.cpp:226] conv_v3 needs backward computation.
I0529 15:17:35.558784 16806 net.cpp:226] pool_v2 needs backward computation.
I0529 15:17:35.558795 16806 net.cpp:226] relu_v2 needs backward computation.
I0529 15:17:35.558805 16806 net.cpp:226] conv_v2 needs backward computation.
I0529 15:17:35.558815 16806 net.cpp:226] pool_v1 needs backward computation.
I0529 15:17:35.558826 16806 net.cpp:226] relu_v1 needs backward computation.
I0529 15:17:35.558836 16806 net.cpp:226] conv_v1 needs backward computation.
I0529 15:17:35.558847 16806 net.cpp:226] drop_u1 needs backward computation.
I0529 15:17:35.558858 16806 net.cpp:226] relu_u5 needs backward computation.
I0529 15:17:35.558866 16806 net.cpp:226] dl_u1 needs backward computation.
I0529 15:17:35.558878 16806 net.cpp:226] pool_u4 needs backward computation.
I0529 15:17:35.558888 16806 net.cpp:226] relu_u4 needs backward computation.
I0529 15:17:35.558899 16806 net.cpp:226] conv_u4 needs backward computation.
I0529 15:17:35.558910 16806 net.cpp:226] pool_u3 needs backward computation.
I0529 15:17:35.558920 16806 net.cpp:226] relu_u3 needs backward computation.
I0529 15:17:35.558931 16806 net.cpp:226] conv_u3 needs backward computation.
I0529 15:17:35.558941 16806 net.cpp:226] pool_u2 needs backward computation.
I0529 15:17:35.558953 16806 net.cpp:226] relu_u2 needs backward computation.
I0529 15:17:35.558964 16806 net.cpp:226] conv_u2 needs backward computation.
I0529 15:17:35.558974 16806 net.cpp:226] pool_u1 needs backward computation.
I0529 15:17:35.558985 16806 net.cpp:226] relu_u1 needs backward computation.
I0529 15:17:35.558993 16806 net.cpp:226] conv_u1 needs backward computation.
I0529 15:17:35.559005 16806 net.cpp:226] drop_x1 needs backward computation.
I0529 15:17:35.559015 16806 net.cpp:226] relu_x5 needs backward computation.
I0529 15:17:35.559026 16806 net.cpp:226] dl_x1 needs backward computation.
I0529 15:17:35.559036 16806 net.cpp:226] pool_x4 needs backward computation.
I0529 15:17:35.559047 16806 net.cpp:226] relu_x4 needs backward computation.
I0529 15:17:35.559057 16806 net.cpp:226] conv_x4 needs backward computation.
I0529 15:17:35.559068 16806 net.cpp:226] pool_x3 needs backward computation.
I0529 15:17:35.559079 16806 net.cpp:226] relu_x3 needs backward computation.
I0529 15:17:35.559090 16806 net.cpp:226] conv_x3 needs backward computation.
I0529 15:17:35.559108 16806 net.cpp:226] pool_x2 needs backward computation.
I0529 15:17:35.559128 16806 net.cpp:226] relu_x2 needs backward computation.
I0529 15:17:35.559139 16806 net.cpp:226] conv_x2 needs backward computation.
I0529 15:17:35.559150 16806 net.cpp:226] pool_x1 needs backward computation.
I0529 15:17:35.559161 16806 net.cpp:226] relu_x1 needs backward computation.
I0529 15:17:35.559171 16806 net.cpp:226] conv_x1 needs backward computation.
I0529 15:17:35.559185 16806 net.cpp:228] data does not need backward computation.
I0529 15:17:35.559195 16806 net.cpp:270] This network produces output loss
I0529 15:17:35.559239 16806 net.cpp:283] Network initialization done.
I0529 15:17:35.562252 16806 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_xuv_2016-05-29T11.13.49.302090.prototxt
I0529 15:17:35.562386 16806 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0529 15:17:35.563159 16806 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "output"
  bottom: "segments"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0529 15:17:35.563531 16806 layer_factory.hpp:77] Creating layer data
I0529 15:17:35.563547 16806 net.cpp:106] Creating Layer data
I0529 15:17:35.563560 16806 net.cpp:411] data -> hits-x
I0529 15:17:35.563576 16806 net.cpp:411] data -> hits-u
I0529 15:17:35.563592 16806 net.cpp:411] data -> hits-v
I0529 15:17:35.563608 16806 net.cpp:411] data -> segments
I0529 15:17:35.563623 16806 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist
I0529 15:17:35.574748 16806 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0529 15:18:39.962792 16806 net.cpp:150] Setting up data
I0529 15:18:39.962954 16806 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 15:18:39.962968 16806 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 15:18:39.962982 16806 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0529 15:18:39.962996 16806 net.cpp:157] Top shape: 100 (100)
I0529 15:18:39.963006 16806 net.cpp:165] Memory required for data: 7620400
I0529 15:18:39.963019 16806 layer_factory.hpp:77] Creating layer segments_data_3_split
I0529 15:18:39.963047 16806 net.cpp:106] Creating Layer segments_data_3_split
I0529 15:18:39.963057 16806 net.cpp:454] segments_data_3_split <- segments
I0529 15:18:39.963073 16806 net.cpp:411] segments_data_3_split -> segments_data_3_split_0
I0529 15:18:39.963095 16806 net.cpp:411] segments_data_3_split -> segments_data_3_split_1
I0529 15:18:39.963181 16806 net.cpp:150] Setting up segments_data_3_split
I0529 15:18:39.963196 16806 net.cpp:157] Top shape: 100 (100)
I0529 15:18:39.963207 16806 net.cpp:157] Top shape: 100 (100)
I0529 15:18:39.963217 16806 net.cpp:165] Memory required for data: 7621200
I0529 15:18:39.963227 16806 layer_factory.hpp:77] Creating layer conv_x1
I0529 15:18:39.963249 16806 net.cpp:106] Creating Layer conv_x1
I0529 15:18:39.963259 16806 net.cpp:454] conv_x1 <- hits-x
I0529 15:18:39.963275 16806 net.cpp:411] conv_x1 -> conv_x1
I0529 15:18:39.965482 16806 net.cpp:150] Setting up conv_x1
I0529 15:18:39.965502 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:18:39.965512 16806 net.cpp:165] Memory required for data: 35269200
I0529 15:18:39.965533 16806 layer_factory.hpp:77] Creating layer relu_x1
I0529 15:18:39.965548 16806 net.cpp:106] Creating Layer relu_x1
I0529 15:18:39.965558 16806 net.cpp:454] relu_x1 <- conv_x1
I0529 15:18:39.965570 16806 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0529 15:18:39.966080 16806 net.cpp:150] Setting up relu_x1
I0529 15:18:39.966096 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:18:39.966106 16806 net.cpp:165] Memory required for data: 62917200
I0529 15:18:39.966115 16806 layer_factory.hpp:77] Creating layer pool_x1
I0529 15:18:39.966132 16806 net.cpp:106] Creating Layer pool_x1
I0529 15:18:39.966142 16806 net.cpp:454] pool_x1 <- conv_x1
I0529 15:18:39.966156 16806 net.cpp:411] pool_x1 -> pool_x1
I0529 15:18:39.966236 16806 net.cpp:150] Setting up pool_x1
I0529 15:18:39.966249 16806 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 15:18:39.966259 16806 net.cpp:165] Memory required for data: 76741200
I0529 15:18:39.966272 16806 layer_factory.hpp:77] Creating layer conv_x2
I0529 15:18:39.966290 16806 net.cpp:106] Creating Layer conv_x2
I0529 15:18:39.966301 16806 net.cpp:454] conv_x2 <- pool_x1
I0529 15:18:39.966315 16806 net.cpp:411] conv_x2 -> conv_x2
I0529 15:18:39.968206 16806 net.cpp:150] Setting up conv_x2
I0529 15:18:39.968230 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:18:39.968240 16806 net.cpp:165] Memory required for data: 96613200
I0529 15:18:39.968258 16806 layer_factory.hpp:77] Creating layer relu_x2
I0529 15:18:39.968272 16806 net.cpp:106] Creating Layer relu_x2
I0529 15:18:39.968282 16806 net.cpp:454] relu_x2 <- conv_x2
I0529 15:18:39.968296 16806 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0529 15:18:39.968804 16806 net.cpp:150] Setting up relu_x2
I0529 15:18:39.968821 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:18:39.968830 16806 net.cpp:165] Memory required for data: 116485200
I0529 15:18:39.968839 16806 layer_factory.hpp:77] Creating layer pool_x2
I0529 15:18:39.968853 16806 net.cpp:106] Creating Layer pool_x2
I0529 15:18:39.968863 16806 net.cpp:454] pool_x2 <- conv_x2
I0529 15:18:39.968878 16806 net.cpp:411] pool_x2 -> pool_x2
I0529 15:18:39.968956 16806 net.cpp:150] Setting up pool_x2
I0529 15:18:39.968971 16806 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 15:18:39.968979 16806 net.cpp:165] Memory required for data: 126421200
I0529 15:18:39.968989 16806 layer_factory.hpp:77] Creating layer conv_x3
I0529 15:18:39.969007 16806 net.cpp:106] Creating Layer conv_x3
I0529 15:18:39.969018 16806 net.cpp:454] conv_x3 <- pool_x2
I0529 15:18:39.969033 16806 net.cpp:411] conv_x3 -> conv_x3
I0529 15:18:39.971284 16806 net.cpp:150] Setting up conv_x3
I0529 15:18:39.971308 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:18:39.971318 16806 net.cpp:165] Memory required for data: 137262800
I0529 15:18:39.971338 16806 layer_factory.hpp:77] Creating layer relu_x3
I0529 15:18:39.971351 16806 net.cpp:106] Creating Layer relu_x3
I0529 15:18:39.971361 16806 net.cpp:454] relu_x3 <- conv_x3
I0529 15:18:39.971374 16806 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0529 15:18:39.971719 16806 net.cpp:150] Setting up relu_x3
I0529 15:18:39.971735 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:18:39.971745 16806 net.cpp:165] Memory required for data: 148104400
I0529 15:18:39.971753 16806 layer_factory.hpp:77] Creating layer pool_x3
I0529 15:18:39.971767 16806 net.cpp:106] Creating Layer pool_x3
I0529 15:18:39.971777 16806 net.cpp:454] pool_x3 <- conv_x3
I0529 15:18:39.971791 16806 net.cpp:411] pool_x3 -> pool_x3
I0529 15:18:39.971868 16806 net.cpp:150] Setting up pool_x3
I0529 15:18:39.971881 16806 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 15:18:39.971891 16806 net.cpp:165] Memory required for data: 153525200
I0529 15:18:39.971901 16806 layer_factory.hpp:77] Creating layer conv_x4
I0529 15:18:39.971920 16806 net.cpp:106] Creating Layer conv_x4
I0529 15:18:39.971930 16806 net.cpp:454] conv_x4 <- pool_x3
I0529 15:18:39.971945 16806 net.cpp:411] conv_x4 -> conv_x4
I0529 15:18:39.974100 16806 net.cpp:150] Setting up conv_x4
I0529 15:18:39.974123 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:18:39.974134 16806 net.cpp:165] Memory required for data: 157154000
I0529 15:18:39.974149 16806 layer_factory.hpp:77] Creating layer relu_x4
I0529 15:18:39.974164 16806 net.cpp:106] Creating Layer relu_x4
I0529 15:18:39.974174 16806 net.cpp:454] relu_x4 <- conv_x4
I0529 15:18:39.974187 16806 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0529 15:18:39.974678 16806 net.cpp:150] Setting up relu_x4
I0529 15:18:39.974694 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:18:39.974704 16806 net.cpp:165] Memory required for data: 160782800
I0529 15:18:39.974714 16806 layer_factory.hpp:77] Creating layer pool_x4
I0529 15:18:39.974726 16806 net.cpp:106] Creating Layer pool_x4
I0529 15:18:39.974737 16806 net.cpp:454] pool_x4 <- conv_x4
I0529 15:18:39.974750 16806 net.cpp:411] pool_x4 -> pool_x4
I0529 15:18:39.974828 16806 net.cpp:150] Setting up pool_x4
I0529 15:18:39.974841 16806 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 15:18:39.974851 16806 net.cpp:165] Memory required for data: 162597200
I0529 15:18:39.974861 16806 layer_factory.hpp:77] Creating layer dl_x1
I0529 15:18:39.974877 16806 net.cpp:106] Creating Layer dl_x1
I0529 15:18:39.974887 16806 net.cpp:454] dl_x1 <- pool_x4
I0529 15:18:39.974902 16806 net.cpp:411] dl_x1 -> dl_x1
I0529 15:18:39.991238 16806 net.cpp:150] Setting up dl_x1
I0529 15:18:39.991266 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:39.991281 16806 net.cpp:165] Memory required for data: 162675600
I0529 15:18:39.991307 16806 layer_factory.hpp:77] Creating layer relu_x5
I0529 15:18:39.991322 16806 net.cpp:106] Creating Layer relu_x5
I0529 15:18:39.991333 16806 net.cpp:454] relu_x5 <- dl_x1
I0529 15:18:39.991348 16806 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0529 15:18:39.991708 16806 net.cpp:150] Setting up relu_x5
I0529 15:18:39.991722 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:39.991732 16806 net.cpp:165] Memory required for data: 162754000
I0529 15:18:39.991741 16806 layer_factory.hpp:77] Creating layer drop_x1
I0529 15:18:39.991761 16806 net.cpp:106] Creating Layer drop_x1
I0529 15:18:39.991771 16806 net.cpp:454] drop_x1 <- dl_x1
I0529 15:18:39.991785 16806 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0529 15:18:39.991832 16806 net.cpp:150] Setting up drop_x1
I0529 15:18:39.991845 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:39.991855 16806 net.cpp:165] Memory required for data: 162832400
I0529 15:18:39.991864 16806 layer_factory.hpp:77] Creating layer conv_u1
I0529 15:18:39.991884 16806 net.cpp:106] Creating Layer conv_u1
I0529 15:18:39.991906 16806 net.cpp:454] conv_u1 <- hits-u
I0529 15:18:39.991921 16806 net.cpp:411] conv_u1 -> conv_u1
I0529 15:18:39.993886 16806 net.cpp:150] Setting up conv_u1
I0529 15:18:39.993909 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:18:39.993919 16806 net.cpp:165] Memory required for data: 190480400
I0529 15:18:39.993935 16806 layer_factory.hpp:77] Creating layer relu_u1
I0529 15:18:39.993948 16806 net.cpp:106] Creating Layer relu_u1
I0529 15:18:39.993958 16806 net.cpp:454] relu_u1 <- conv_u1
I0529 15:18:39.993973 16806 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0529 15:18:39.994302 16806 net.cpp:150] Setting up relu_u1
I0529 15:18:39.994316 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:18:39.994326 16806 net.cpp:165] Memory required for data: 218128400
I0529 15:18:39.994335 16806 layer_factory.hpp:77] Creating layer pool_u1
I0529 15:18:39.994349 16806 net.cpp:106] Creating Layer pool_u1
I0529 15:18:39.994359 16806 net.cpp:454] pool_u1 <- conv_u1
I0529 15:18:39.994374 16806 net.cpp:411] pool_u1 -> pool_u1
I0529 15:18:39.994457 16806 net.cpp:150] Setting up pool_u1
I0529 15:18:39.994470 16806 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 15:18:39.994480 16806 net.cpp:165] Memory required for data: 231952400
I0529 15:18:39.994488 16806 layer_factory.hpp:77] Creating layer conv_u2
I0529 15:18:39.994506 16806 net.cpp:106] Creating Layer conv_u2
I0529 15:18:39.994516 16806 net.cpp:454] conv_u2 <- pool_u1
I0529 15:18:39.994531 16806 net.cpp:411] conv_u2 -> conv_u2
I0529 15:18:39.996487 16806 net.cpp:150] Setting up conv_u2
I0529 15:18:39.996510 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:18:39.996520 16806 net.cpp:165] Memory required for data: 251824400
I0529 15:18:39.996536 16806 layer_factory.hpp:77] Creating layer relu_u2
I0529 15:18:39.996549 16806 net.cpp:106] Creating Layer relu_u2
I0529 15:18:39.996561 16806 net.cpp:454] relu_u2 <- conv_u2
I0529 15:18:39.996573 16806 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0529 15:18:39.997068 16806 net.cpp:150] Setting up relu_u2
I0529 15:18:39.997086 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:18:39.997095 16806 net.cpp:165] Memory required for data: 271696400
I0529 15:18:39.997104 16806 layer_factory.hpp:77] Creating layer pool_u2
I0529 15:18:39.997118 16806 net.cpp:106] Creating Layer pool_u2
I0529 15:18:39.997129 16806 net.cpp:454] pool_u2 <- conv_u2
I0529 15:18:39.997143 16806 net.cpp:411] pool_u2 -> pool_u2
I0529 15:18:39.997221 16806 net.cpp:150] Setting up pool_u2
I0529 15:18:39.997236 16806 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 15:18:39.997246 16806 net.cpp:165] Memory required for data: 281632400
I0529 15:18:39.997257 16806 layer_factory.hpp:77] Creating layer conv_u3
I0529 15:18:39.997275 16806 net.cpp:106] Creating Layer conv_u3
I0529 15:18:39.997287 16806 net.cpp:454] conv_u3 <- pool_u2
I0529 15:18:39.997301 16806 net.cpp:411] conv_u3 -> conv_u3
I0529 15:18:39.999322 16806 net.cpp:150] Setting up conv_u3
I0529 15:18:39.999344 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:18:39.999356 16806 net.cpp:165] Memory required for data: 292474000
I0529 15:18:39.999372 16806 layer_factory.hpp:77] Creating layer relu_u3
I0529 15:18:39.999384 16806 net.cpp:106] Creating Layer relu_u3
I0529 15:18:39.999394 16806 net.cpp:454] relu_u3 <- conv_u3
I0529 15:18:39.999408 16806 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0529 15:18:39.999734 16806 net.cpp:150] Setting up relu_u3
I0529 15:18:39.999748 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:18:39.999759 16806 net.cpp:165] Memory required for data: 303315600
I0529 15:18:39.999768 16806 layer_factory.hpp:77] Creating layer pool_u3
I0529 15:18:39.999781 16806 net.cpp:106] Creating Layer pool_u3
I0529 15:18:39.999790 16806 net.cpp:454] pool_u3 <- conv_u3
I0529 15:18:39.999804 16806 net.cpp:411] pool_u3 -> pool_u3
I0529 15:18:39.999881 16806 net.cpp:150] Setting up pool_u3
I0529 15:18:39.999894 16806 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 15:18:39.999903 16806 net.cpp:165] Memory required for data: 308736400
I0529 15:18:39.999925 16806 layer_factory.hpp:77] Creating layer conv_u4
I0529 15:18:39.999943 16806 net.cpp:106] Creating Layer conv_u4
I0529 15:18:39.999954 16806 net.cpp:454] conv_u4 <- pool_u3
I0529 15:18:39.999969 16806 net.cpp:411] conv_u4 -> conv_u4
I0529 15:18:40.002137 16806 net.cpp:150] Setting up conv_u4
I0529 15:18:40.002159 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:18:40.002171 16806 net.cpp:165] Memory required for data: 312365200
I0529 15:18:40.002192 16806 layer_factory.hpp:77] Creating layer relu_u4
I0529 15:18:40.002207 16806 net.cpp:106] Creating Layer relu_u4
I0529 15:18:40.002218 16806 net.cpp:454] relu_u4 <- conv_u4
I0529 15:18:40.002230 16806 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0529 15:18:40.002562 16806 net.cpp:150] Setting up relu_u4
I0529 15:18:40.002575 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:18:40.002585 16806 net.cpp:165] Memory required for data: 315994000
I0529 15:18:40.002594 16806 layer_factory.hpp:77] Creating layer pool_u4
I0529 15:18:40.002607 16806 net.cpp:106] Creating Layer pool_u4
I0529 15:18:40.002617 16806 net.cpp:454] pool_u4 <- conv_u4
I0529 15:18:40.002630 16806 net.cpp:411] pool_u4 -> pool_u4
I0529 15:18:40.002708 16806 net.cpp:150] Setting up pool_u4
I0529 15:18:40.002722 16806 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 15:18:40.002732 16806 net.cpp:165] Memory required for data: 317808400
I0529 15:18:40.002742 16806 layer_factory.hpp:77] Creating layer dl_u1
I0529 15:18:40.002756 16806 net.cpp:106] Creating Layer dl_u1
I0529 15:18:40.002766 16806 net.cpp:454] dl_u1 <- pool_u4
I0529 15:18:40.002780 16806 net.cpp:411] dl_u1 -> dl_u1
I0529 15:18:40.019256 16806 net.cpp:150] Setting up dl_u1
I0529 15:18:40.019285 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:40.019300 16806 net.cpp:165] Memory required for data: 317886800
I0529 15:18:40.019317 16806 layer_factory.hpp:77] Creating layer relu_u5
I0529 15:18:40.019332 16806 net.cpp:106] Creating Layer relu_u5
I0529 15:18:40.019342 16806 net.cpp:454] relu_u5 <- dl_u1
I0529 15:18:40.019357 16806 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0529 15:18:40.019944 16806 net.cpp:150] Setting up relu_u5
I0529 15:18:40.019960 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:40.019970 16806 net.cpp:165] Memory required for data: 317965200
I0529 15:18:40.019980 16806 layer_factory.hpp:77] Creating layer drop_u1
I0529 15:18:40.019995 16806 net.cpp:106] Creating Layer drop_u1
I0529 15:18:40.020005 16806 net.cpp:454] drop_u1 <- dl_u1
I0529 15:18:40.020018 16806 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0529 15:18:40.020066 16806 net.cpp:150] Setting up drop_u1
I0529 15:18:40.020079 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:40.020089 16806 net.cpp:165] Memory required for data: 318043600
I0529 15:18:40.020098 16806 layer_factory.hpp:77] Creating layer conv_v1
I0529 15:18:40.020126 16806 net.cpp:106] Creating Layer conv_v1
I0529 15:18:40.020136 16806 net.cpp:454] conv_v1 <- hits-v
I0529 15:18:40.020150 16806 net.cpp:411] conv_v1 -> conv_v1
I0529 15:18:40.022078 16806 net.cpp:150] Setting up conv_v1
I0529 15:18:40.022101 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:18:40.022111 16806 net.cpp:165] Memory required for data: 345691600
I0529 15:18:40.022127 16806 layer_factory.hpp:77] Creating layer relu_v1
I0529 15:18:40.022140 16806 net.cpp:106] Creating Layer relu_v1
I0529 15:18:40.022151 16806 net.cpp:454] relu_v1 <- conv_v1
I0529 15:18:40.022163 16806 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0529 15:18:40.022496 16806 net.cpp:150] Setting up relu_v1
I0529 15:18:40.022511 16806 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0529 15:18:40.022521 16806 net.cpp:165] Memory required for data: 373339600
I0529 15:18:40.022528 16806 layer_factory.hpp:77] Creating layer pool_v1
I0529 15:18:40.022542 16806 net.cpp:106] Creating Layer pool_v1
I0529 15:18:40.022552 16806 net.cpp:454] pool_v1 <- conv_v1
I0529 15:18:40.022567 16806 net.cpp:411] pool_v1 -> pool_v1
I0529 15:18:40.022646 16806 net.cpp:150] Setting up pool_v1
I0529 15:18:40.022675 16806 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0529 15:18:40.022685 16806 net.cpp:165] Memory required for data: 387163600
I0529 15:18:40.022693 16806 layer_factory.hpp:77] Creating layer conv_v2
I0529 15:18:40.022711 16806 net.cpp:106] Creating Layer conv_v2
I0529 15:18:40.022721 16806 net.cpp:454] conv_v2 <- pool_v1
I0529 15:18:40.022734 16806 net.cpp:411] conv_v2 -> conv_v2
I0529 15:18:40.024742 16806 net.cpp:150] Setting up conv_v2
I0529 15:18:40.024765 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:18:40.024776 16806 net.cpp:165] Memory required for data: 407035600
I0529 15:18:40.024791 16806 layer_factory.hpp:77] Creating layer relu_v2
I0529 15:18:40.024804 16806 net.cpp:106] Creating Layer relu_v2
I0529 15:18:40.024816 16806 net.cpp:454] relu_v2 <- conv_v2
I0529 15:18:40.024828 16806 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0529 15:18:40.025328 16806 net.cpp:150] Setting up relu_v2
I0529 15:18:40.025346 16806 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0529 15:18:40.025357 16806 net.cpp:165] Memory required for data: 426907600
I0529 15:18:40.025365 16806 layer_factory.hpp:77] Creating layer pool_v2
I0529 15:18:40.025379 16806 net.cpp:106] Creating Layer pool_v2
I0529 15:18:40.025389 16806 net.cpp:454] pool_v2 <- conv_v2
I0529 15:18:40.025403 16806 net.cpp:411] pool_v2 -> pool_v2
I0529 15:18:40.025483 16806 net.cpp:150] Setting up pool_v2
I0529 15:18:40.025497 16806 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0529 15:18:40.025507 16806 net.cpp:165] Memory required for data: 436843600
I0529 15:18:40.025519 16806 layer_factory.hpp:77] Creating layer conv_v3
I0529 15:18:40.025538 16806 net.cpp:106] Creating Layer conv_v3
I0529 15:18:40.025549 16806 net.cpp:454] conv_v3 <- pool_v2
I0529 15:18:40.025564 16806 net.cpp:411] conv_v3 -> conv_v3
I0529 15:18:40.027642 16806 net.cpp:150] Setting up conv_v3
I0529 15:18:40.027664 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:18:40.027674 16806 net.cpp:165] Memory required for data: 447685200
I0529 15:18:40.027689 16806 layer_factory.hpp:77] Creating layer relu_v3
I0529 15:18:40.027704 16806 net.cpp:106] Creating Layer relu_v3
I0529 15:18:40.027714 16806 net.cpp:454] relu_v3 <- conv_v3
I0529 15:18:40.027726 16806 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0529 15:18:40.028220 16806 net.cpp:150] Setting up relu_v3
I0529 15:18:40.028237 16806 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0529 15:18:40.028247 16806 net.cpp:165] Memory required for data: 458526800
I0529 15:18:40.028256 16806 layer_factory.hpp:77] Creating layer pool_v3
I0529 15:18:40.028270 16806 net.cpp:106] Creating Layer pool_v3
I0529 15:18:40.028280 16806 net.cpp:454] pool_v3 <- conv_v3
I0529 15:18:40.028295 16806 net.cpp:411] pool_v3 -> pool_v3
I0529 15:18:40.028373 16806 net.cpp:150] Setting up pool_v3
I0529 15:18:40.028386 16806 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0529 15:18:40.028396 16806 net.cpp:165] Memory required for data: 463947600
I0529 15:18:40.028408 16806 layer_factory.hpp:77] Creating layer conv_v4
I0529 15:18:40.028425 16806 net.cpp:106] Creating Layer conv_v4
I0529 15:18:40.028436 16806 net.cpp:454] conv_v4 <- pool_v3
I0529 15:18:40.028450 16806 net.cpp:411] conv_v4 -> conv_v4
I0529 15:18:40.030618 16806 net.cpp:150] Setting up conv_v4
I0529 15:18:40.030642 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:18:40.030652 16806 net.cpp:165] Memory required for data: 467576400
I0529 15:18:40.030668 16806 layer_factory.hpp:77] Creating layer relu_v4
I0529 15:18:40.030681 16806 net.cpp:106] Creating Layer relu_v4
I0529 15:18:40.030691 16806 net.cpp:454] relu_v4 <- conv_v4
I0529 15:18:40.030704 16806 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0529 15:18:40.031033 16806 net.cpp:150] Setting up relu_v4
I0529 15:18:40.031047 16806 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0529 15:18:40.031057 16806 net.cpp:165] Memory required for data: 471205200
I0529 15:18:40.031066 16806 layer_factory.hpp:77] Creating layer pool_v4
I0529 15:18:40.031080 16806 net.cpp:106] Creating Layer pool_v4
I0529 15:18:40.031100 16806 net.cpp:454] pool_v4 <- conv_v4
I0529 15:18:40.031114 16806 net.cpp:411] pool_v4 -> pool_v4
I0529 15:18:40.031199 16806 net.cpp:150] Setting up pool_v4
I0529 15:18:40.031213 16806 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0529 15:18:40.031224 16806 net.cpp:165] Memory required for data: 473019600
I0529 15:18:40.031230 16806 layer_factory.hpp:77] Creating layer dl_v1
I0529 15:18:40.031246 16806 net.cpp:106] Creating Layer dl_v1
I0529 15:18:40.031257 16806 net.cpp:454] dl_v1 <- pool_v4
I0529 15:18:40.031271 16806 net.cpp:411] dl_v1 -> dl_v1
I0529 15:18:40.047654 16806 net.cpp:150] Setting up dl_v1
I0529 15:18:40.047683 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:40.047696 16806 net.cpp:165] Memory required for data: 473098000
I0529 15:18:40.047713 16806 layer_factory.hpp:77] Creating layer relu_v5
I0529 15:18:40.047729 16806 net.cpp:106] Creating Layer relu_v5
I0529 15:18:40.047739 16806 net.cpp:454] relu_v5 <- dl_v1
I0529 15:18:40.047754 16806 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0529 15:18:40.048336 16806 net.cpp:150] Setting up relu_v5
I0529 15:18:40.048353 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:40.048362 16806 net.cpp:165] Memory required for data: 473176400
I0529 15:18:40.048372 16806 layer_factory.hpp:77] Creating layer drop_v1
I0529 15:18:40.048387 16806 net.cpp:106] Creating Layer drop_v1
I0529 15:18:40.048396 16806 net.cpp:454] drop_v1 <- dl_v1
I0529 15:18:40.048410 16806 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0529 15:18:40.048460 16806 net.cpp:150] Setting up drop_v1
I0529 15:18:40.048472 16806 net.cpp:157] Top shape: 100 196 (19600)
I0529 15:18:40.048481 16806 net.cpp:165] Memory required for data: 473254800
I0529 15:18:40.048492 16806 layer_factory.hpp:77] Creating layer concat_xuv
I0529 15:18:40.048507 16806 net.cpp:106] Creating Layer concat_xuv
I0529 15:18:40.048517 16806 net.cpp:454] concat_xuv <- dl_x1
I0529 15:18:40.048528 16806 net.cpp:454] concat_xuv <- dl_u1
I0529 15:18:40.048540 16806 net.cpp:454] concat_xuv <- dl_v1
I0529 15:18:40.048553 16806 net.cpp:411] concat_xuv -> concat_xuv
I0529 15:18:40.048604 16806 net.cpp:150] Setting up concat_xuv
I0529 15:18:40.048617 16806 net.cpp:157] Top shape: 100 588 (58800)
I0529 15:18:40.048627 16806 net.cpp:165] Memory required for data: 473490000
I0529 15:18:40.048637 16806 layer_factory.hpp:77] Creating layer dl_xuv
I0529 15:18:40.048651 16806 net.cpp:106] Creating Layer dl_xuv
I0529 15:18:40.048661 16806 net.cpp:454] dl_xuv <- concat_xuv
I0529 15:18:40.048678 16806 net.cpp:411] dl_xuv -> dl_xuv
I0529 15:18:40.049721 16806 net.cpp:150] Setting up dl_xuv
I0529 15:18:40.049741 16806 net.cpp:157] Top shape: 100 98 (9800)
I0529 15:18:40.049752 16806 net.cpp:165] Memory required for data: 473529200
I0529 15:18:40.049767 16806 layer_factory.hpp:77] Creating layer relu_xuv
I0529 15:18:40.049780 16806 net.cpp:106] Creating Layer relu_xuv
I0529 15:18:40.049790 16806 net.cpp:454] relu_xuv <- dl_xuv
I0529 15:18:40.049803 16806 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0529 15:18:40.050135 16806 net.cpp:150] Setting up relu_xuv
I0529 15:18:40.050149 16806 net.cpp:157] Top shape: 100 98 (9800)
I0529 15:18:40.050159 16806 net.cpp:165] Memory required for data: 473568400
I0529 15:18:40.050168 16806 layer_factory.hpp:77] Creating layer drop_xuv
I0529 15:18:40.050181 16806 net.cpp:106] Creating Layer drop_xuv
I0529 15:18:40.050191 16806 net.cpp:454] drop_xuv <- dl_xuv
I0529 15:18:40.050204 16806 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0529 15:18:40.050251 16806 net.cpp:150] Setting up drop_xuv
I0529 15:18:40.050263 16806 net.cpp:157] Top shape: 100 98 (9800)
I0529 15:18:40.050273 16806 net.cpp:165] Memory required for data: 473607600
I0529 15:18:40.050283 16806 layer_factory.hpp:77] Creating layer output
I0529 15:18:40.050297 16806 net.cpp:106] Creating Layer output
I0529 15:18:40.050307 16806 net.cpp:454] output <- dl_xuv
I0529 15:18:40.050321 16806 net.cpp:411] output -> output
I0529 15:18:40.050565 16806 net.cpp:150] Setting up output
I0529 15:18:40.050578 16806 net.cpp:157] Top shape: 100 11 (1100)
I0529 15:18:40.050601 16806 net.cpp:165] Memory required for data: 473612000
I0529 15:18:40.050634 16806 layer_factory.hpp:77] Creating layer drop_output
I0529 15:18:40.050648 16806 net.cpp:106] Creating Layer drop_output
I0529 15:18:40.050658 16806 net.cpp:454] drop_output <- output
I0529 15:18:40.050671 16806 net.cpp:397] drop_output -> output (in-place)
I0529 15:18:40.050719 16806 net.cpp:150] Setting up drop_output
I0529 15:18:40.050730 16806 net.cpp:157] Top shape: 100 11 (1100)
I0529 15:18:40.050740 16806 net.cpp:165] Memory required for data: 473616400
I0529 15:18:40.050750 16806 layer_factory.hpp:77] Creating layer output_drop_output_0_split
I0529 15:18:40.050763 16806 net.cpp:106] Creating Layer output_drop_output_0_split
I0529 15:18:40.050773 16806 net.cpp:454] output_drop_output_0_split <- output
I0529 15:18:40.050787 16806 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_0
I0529 15:18:40.050802 16806 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_1
I0529 15:18:40.050878 16806 net.cpp:150] Setting up output_drop_output_0_split
I0529 15:18:40.050891 16806 net.cpp:157] Top shape: 100 11 (1100)
I0529 15:18:40.050904 16806 net.cpp:157] Top shape: 100 11 (1100)
I0529 15:18:40.050912 16806 net.cpp:165] Memory required for data: 473625200
I0529 15:18:40.050922 16806 layer_factory.hpp:77] Creating layer accuracy
I0529 15:18:40.050945 16806 net.cpp:106] Creating Layer accuracy
I0529 15:18:40.050954 16806 net.cpp:454] accuracy <- output_drop_output_0_split_0
I0529 15:18:40.050966 16806 net.cpp:454] accuracy <- segments_data_3_split_0
I0529 15:18:40.050979 16806 net.cpp:411] accuracy -> accuracy
I0529 15:18:40.051004 16806 net.cpp:150] Setting up accuracy
I0529 15:18:40.051017 16806 net.cpp:157] Top shape: (1)
I0529 15:18:40.051026 16806 net.cpp:165] Memory required for data: 473625204
I0529 15:18:40.051038 16806 layer_factory.hpp:77] Creating layer loss
I0529 15:18:40.051051 16806 net.cpp:106] Creating Layer loss
I0529 15:18:40.051061 16806 net.cpp:454] loss <- output_drop_output_0_split_1
I0529 15:18:40.051072 16806 net.cpp:454] loss <- segments_data_3_split_1
I0529 15:18:40.051086 16806 net.cpp:411] loss -> loss
I0529 15:18:40.051105 16806 layer_factory.hpp:77] Creating layer loss
I0529 15:18:40.051813 16806 net.cpp:150] Setting up loss
I0529 15:18:40.051834 16806 net.cpp:157] Top shape: (1)
I0529 15:18:40.051846 16806 net.cpp:160]     with loss weight 1
I0529 15:18:40.051867 16806 net.cpp:165] Memory required for data: 473625208
I0529 15:18:40.051877 16806 net.cpp:226] loss needs backward computation.
I0529 15:18:40.051888 16806 net.cpp:228] accuracy does not need backward computation.
I0529 15:18:40.051900 16806 net.cpp:226] output_drop_output_0_split needs backward computation.
I0529 15:18:40.051910 16806 net.cpp:226] drop_output needs backward computation.
I0529 15:18:40.051920 16806 net.cpp:226] output needs backward computation.
I0529 15:18:40.051931 16806 net.cpp:226] drop_xuv needs backward computation.
I0529 15:18:40.051944 16806 net.cpp:226] relu_xuv needs backward computation.
I0529 15:18:40.051954 16806 net.cpp:226] dl_xuv needs backward computation.
I0529 15:18:40.051965 16806 net.cpp:226] concat_xuv needs backward computation.
I0529 15:18:40.051978 16806 net.cpp:226] drop_v1 needs backward computation.
I0529 15:18:40.051990 16806 net.cpp:226] relu_v5 needs backward computation.
I0529 15:18:40.052000 16806 net.cpp:226] dl_v1 needs backward computation.
I0529 15:18:40.052011 16806 net.cpp:226] pool_v4 needs backward computation.
I0529 15:18:40.052021 16806 net.cpp:226] relu_v4 needs backward computation.
I0529 15:18:40.052031 16806 net.cpp:226] conv_v4 needs backward computation.
I0529 15:18:40.052042 16806 net.cpp:226] pool_v3 needs backward computation.
I0529 15:18:40.052053 16806 net.cpp:226] relu_v3 needs backward computation.
I0529 15:18:40.052063 16806 net.cpp:226] conv_v3 needs backward computation.
I0529 15:18:40.052074 16806 net.cpp:226] pool_v2 needs backward computation.
I0529 15:18:40.052085 16806 net.cpp:226] relu_v2 needs backward computation.
I0529 15:18:40.052104 16806 net.cpp:226] conv_v2 needs backward computation.
I0529 15:18:40.052115 16806 net.cpp:226] pool_v1 needs backward computation.
I0529 15:18:40.052127 16806 net.cpp:226] relu_v1 needs backward computation.
I0529 15:18:40.052137 16806 net.cpp:226] conv_v1 needs backward computation.
I0529 15:18:40.052148 16806 net.cpp:226] drop_u1 needs backward computation.
I0529 15:18:40.052158 16806 net.cpp:226] relu_u5 needs backward computation.
I0529 15:18:40.052168 16806 net.cpp:226] dl_u1 needs backward computation.
I0529 15:18:40.052180 16806 net.cpp:226] pool_u4 needs backward computation.
I0529 15:18:40.052191 16806 net.cpp:226] relu_u4 needs backward computation.
I0529 15:18:40.052201 16806 net.cpp:226] conv_u4 needs backward computation.
I0529 15:18:40.052212 16806 net.cpp:226] pool_u3 needs backward computation.
I0529 15:18:40.052223 16806 net.cpp:226] relu_u3 needs backward computation.
I0529 15:18:40.052234 16806 net.cpp:226] conv_u3 needs backward computation.
I0529 15:18:40.052247 16806 net.cpp:226] pool_u2 needs backward computation.
I0529 15:18:40.052258 16806 net.cpp:226] relu_u2 needs backward computation.
I0529 15:18:40.052268 16806 net.cpp:226] conv_u2 needs backward computation.
I0529 15:18:40.052278 16806 net.cpp:226] pool_u1 needs backward computation.
I0529 15:18:40.052289 16806 net.cpp:226] relu_u1 needs backward computation.
I0529 15:18:40.052299 16806 net.cpp:226] conv_u1 needs backward computation.
I0529 15:18:40.052311 16806 net.cpp:226] drop_x1 needs backward computation.
I0529 15:18:40.052321 16806 net.cpp:226] relu_x5 needs backward computation.
I0529 15:18:40.052331 16806 net.cpp:226] dl_x1 needs backward computation.
I0529 15:18:40.052342 16806 net.cpp:226] pool_x4 needs backward computation.
I0529 15:18:40.052353 16806 net.cpp:226] relu_x4 needs backward computation.
I0529 15:18:40.052363 16806 net.cpp:226] conv_x4 needs backward computation.
I0529 15:18:40.052374 16806 net.cpp:226] pool_x3 needs backward computation.
I0529 15:18:40.052386 16806 net.cpp:226] relu_x3 needs backward computation.
I0529 15:18:40.052397 16806 net.cpp:226] conv_x3 needs backward computation.
I0529 15:18:40.052407 16806 net.cpp:226] pool_x2 needs backward computation.
I0529 15:18:40.052418 16806 net.cpp:226] relu_x2 needs backward computation.
I0529 15:18:40.052429 16806 net.cpp:226] conv_x2 needs backward computation.
I0529 15:18:40.052441 16806 net.cpp:226] pool_x1 needs backward computation.
I0529 15:18:40.052453 16806 net.cpp:226] relu_x1 needs backward computation.
I0529 15:18:40.052462 16806 net.cpp:226] conv_x1 needs backward computation.
I0529 15:18:40.052474 16806 net.cpp:228] segments_data_3_split does not need backward computation.
I0529 15:18:40.052487 16806 net.cpp:228] data does not need backward computation.
I0529 15:18:40.052496 16806 net.cpp:270] This network produces output accuracy
I0529 15:18:40.052507 16806 net.cpp:270] This network produces output loss
I0529 15:18:40.052567 16806 net.cpp:283] Network initialization done.
I0529 15:18:40.052851 16806 solver.cpp:60] Solver scaffolding done.
I0529 15:18:40.055999 16806 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_xuv_2016-05-29T11.13.49.302090_iter_30000.solverstate
I0529 15:18:40.286319 16806 sgd_solver.cpp:318] SGDSolver: restoring history
I0529 15:18:40.306299 16806 caffe.cpp:212] Starting Optimization
I0529 15:18:40.306344 16806 solver.cpp:288] Solving epsilon_127x50_xuv
I0529 15:18:40.306354 16806 solver.cpp:289] Learning Rate Policy: fixed
I0529 15:18:40.308828 16806 solver.cpp:341] Iteration 30000, Testing net (#0)
I0529 15:20:58.063835 16806 solver.cpp:409]     Test net output #0: accuracy = 0.875746
I0529 15:20:58.064035 16806 solver.cpp:409]     Test net output #1: loss = 0.429397 (* 1 = 0.429397 loss)
I0529 15:20:58.135412 16806 solver.cpp:237] Iteration 30000, loss = 1.33842
I0529 15:20:58.135449 16806 solver.cpp:253]     Train net output #0: loss = 1.33842 (* 1 = 1.33842 loss)
I0529 15:20:58.135468 16806 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0529 15:26:20.878921 16806 solver.cpp:237] Iteration 31500, loss = 1.13003
I0529 15:26:20.879103 16806 solver.cpp:253]     Train net output #0: loss = 1.13003 (* 1 = 1.13003 loss)
I0529 15:26:20.879125 16806 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0529 15:32:50.946419 16806 solver.cpp:237] Iteration 33000, loss = 1.09732
I0529 15:32:50.946597 16806 solver.cpp:253]     Train net output #0: loss = 1.09732 (* 1 = 1.09732 loss)
I0529 15:32:50.946612 16806 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0529 15:38:13.761940 16806 solver.cpp:237] Iteration 34500, loss = 1.27185
I0529 15:38:13.762115 16806 solver.cpp:253]     Train net output #0: loss = 1.27185 (* 1 = 1.27185 loss)
I0529 15:38:13.762130 16806 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0529 15:44:44.015657 16806 solver.cpp:237] Iteration 36000, loss = 1.367
I0529 15:44:44.015841 16806 solver.cpp:253]     Train net output #0: loss = 1.367 (* 1 = 1.367 loss)
I0529 15:44:44.015854 16806 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0529 15:50:07.060503 16806 solver.cpp:237] Iteration 37500, loss = 1.13166
I0529 15:50:07.060678 16806 solver.cpp:253]     Train net output #0: loss = 1.13166 (* 1 = 1.13166 loss)
I0529 15:50:07.060693 16806 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0529 15:56:37.194334 16806 solver.cpp:237] Iteration 39000, loss = 1.20495
I0529 15:56:37.194520 16806 solver.cpp:253]     Train net output #0: loss = 1.20495 (* 1 = 1.20495 loss)
I0529 15:56:37.194535 16806 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0529 16:02:00.133041 16806 solver.cpp:237] Iteration 40500, loss = 1.16349
I0529 16:02:00.133220 16806 solver.cpp:253]     Train net output #0: loss = 1.16349 (* 1 = 1.16349 loss)
I0529 16:02:00.133235 16806 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0529 16:08:30.299975 16806 solver.cpp:237] Iteration 42000, loss = 1.0467
I0529 16:08:30.300154 16806 solver.cpp:253]     Train net output #0: loss = 1.0467 (* 1 = 1.0467 loss)
I0529 16:08:30.300169 16806 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0529 16:13:53.210098 16806 solver.cpp:237] Iteration 43500, loss = 1.19772
I0529 16:13:53.210269 16806 solver.cpp:253]     Train net output #0: loss = 1.19772 (* 1 = 1.19772 loss)
I0529 16:13:53.210284 16806 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0529 16:19:15.995622 16806 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_xuv_2016-05-29T11.13.49.302090_iter_45000.caffemodel
I0529 16:19:16.256497 16806 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_xuv_2016-05-29T11.13.49.302090_iter_45000.solverstate
I0529 16:19:16.338475 16806 solver.cpp:341] Iteration 45000, Testing net (#0)
I0529 16:21:31.147599 16806 solver.cpp:409]     Test net output #0: accuracy = 0.884161
I0529 16:21:31.147773 16806 solver.cpp:409]     Test net output #1: loss = 0.400756 (* 1 = 0.400756 loss)
I0529 16:22:34.235884 16806 solver.cpp:237] Iteration 45000, loss = 1.19112
I0529 16:22:34.236071 16806 solver.cpp:253]     Train net output #0: loss = 1.19112 (* 1 = 1.19112 loss)
I0529 16:22:34.236086 16806 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0529 16:27:52.924067 16806 solver.cpp:237] Iteration 46500, loss = 1.11806
I0529 16:27:52.924247 16806 solver.cpp:253]     Train net output #0: loss = 1.11806 (* 1 = 1.11806 loss)
I0529 16:27:52.924262 16806 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0529 16:34:14.769085 16806 solver.cpp:237] Iteration 48000, loss = 1.14412
I0529 16:34:14.769268 16806 solver.cpp:253]     Train net output #0: loss = 1.14412 (* 1 = 1.14412 loss)
I0529 16:34:14.769284 16806 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0529 16:39:33.442682 16806 solver.cpp:237] Iteration 49500, loss = 1.06279
I0529 16:39:33.442858 16806 solver.cpp:253]     Train net output #0: loss = 1.06279 (* 1 = 1.06279 loss)
I0529 16:39:33.442873 16806 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0529 16:45:55.351317 16806 solver.cpp:237] Iteration 51000, loss = 1.0798
I0529 16:45:55.351511 16806 solver.cpp:253]     Train net output #0: loss = 1.0798 (* 1 = 1.0798 loss)
I0529 16:45:55.351526 16806 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0529 16:51:14.086515 16806 solver.cpp:237] Iteration 52500, loss = 1.18733
I0529 16:51:14.086697 16806 solver.cpp:253]     Train net output #0: loss = 1.18733 (* 1 = 1.18733 loss)
I0529 16:51:14.086712 16806 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0529 16:57:35.828235 16806 solver.cpp:237] Iteration 54000, loss = 1.23097
I0529 16:57:35.828433 16806 solver.cpp:253]     Train net output #0: loss = 1.23097 (* 1 = 1.23097 loss)
I0529 16:57:35.828449 16806 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0529 17:02:54.616080 16806 solver.cpp:237] Iteration 55500, loss = 1.11316
I0529 17:02:54.616258 16806 solver.cpp:253]     Train net output #0: loss = 1.11316 (* 1 = 1.11316 loss)
I0529 17:02:54.616272 16806 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0529 17:09:16.320305 16806 solver.cpp:237] Iteration 57000, loss = 1.14727
I0529 17:09:16.320485 16806 solver.cpp:253]     Train net output #0: loss = 1.14727 (* 1 = 1.14727 loss)
I0529 17:09:16.320502 16806 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0529 17:14:35.200556 16806 solver.cpp:237] Iteration 58500, loss = 1.43836
I0529 17:14:35.200736 16806 solver.cpp:253]     Train net output #0: loss = 1.43836 (* 1 = 1.43836 loss)
I0529 17:14:35.200750 16806 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
aprun: Apid 11282557: Caught signal Terminated, sending to application
*** Aborted at 1464556589 (unix time) try "date -d @1464556589" if you are using GNU date ***
PC: @     0x2aaab7f0d4a9 __GI_memcpy
=>> PBS: job killed: walltime 7214 exceeded limit 7200
*** SIGTERM (@0x41a3) received by PID 16806 (TID 0x2aaac746f900) from PID 16803; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab7f0d4a9 __GI_memcpy
    @     0x2aaab7f04f96 _int_realloc
aprun: Apid 11282557: Caught signal Terminated, sending to application
    @     0x2aaab7f053ba __GI___libc_realloc
aprun: Apid 11282557: Caught signal Terminated, sending to application
    @     0x2aaab1450ac4 H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11282557: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11282557: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
aprun: Apid 11282557: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03794] [c8-1c0s6n2] [Sun May 29 17:16:34 2016] PE RANK 0 exit signal Terminated
Application 11282557 exit codes: 143
Application 11282557 resources: utime ~6141s, stime ~1058s, Rss ~15288680, inblocks ~10780964, outblocks ~76664
