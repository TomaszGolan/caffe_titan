2816733
I0530 07:39:22.173547  7768 caffe.cpp:184] Using GPUs 0
I0530 07:39:22.599238  7768 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 5000
base_lr: 0.0025
display: 5000
max_iter: 150000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0001
stepsize: 5000
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_inv_2016-05-30T07.39.00.897234.prototxt"
I0530 07:39:22.601498  7768 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_inv_2016-05-30T07.39.00.897234.prototxt
I0530 07:39:22.621873  7768 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0530 07:39:22.621956  7768 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0530 07:39:22.622685  7768 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0530 07:39:22.623044  7768 layer_factory.hpp:77] Creating layer data
I0530 07:39:22.623070  7768 net.cpp:106] Creating Layer data
I0530 07:39:22.623085  7768 net.cpp:411] data -> hits-x
I0530 07:39:22.623119  7768 net.cpp:411] data -> hits-u
I0530 07:39:22.623143  7768 net.cpp:411] data -> hits-v
I0530 07:39:22.623158  7768 net.cpp:411] data -> segments
I0530 07:39:22.623181  7768 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.trainlist
I0530 07:39:22.624668  7768 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0530 07:39:22.627805  7768 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0530 07:40:26.591465  7768 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0530 07:40:26.596989  7768 net.cpp:150] Setting up data
I0530 07:40:26.597029  7768 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 07:40:26.597044  7768 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 07:40:26.597059  7768 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 07:40:26.597071  7768 net.cpp:157] Top shape: 100 (100)
I0530 07:40:26.597081  7768 net.cpp:165] Memory required for data: 7620400
I0530 07:40:26.597095  7768 layer_factory.hpp:77] Creating layer conv_x1
I0530 07:40:26.597128  7768 net.cpp:106] Creating Layer conv_x1
I0530 07:40:26.597141  7768 net.cpp:454] conv_x1 <- hits-x
I0530 07:40:26.597162  7768 net.cpp:411] conv_x1 -> conv_x1
I0530 07:40:26.958717  7768 net.cpp:150] Setting up conv_x1
I0530 07:40:26.958761  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:40:26.958772  7768 net.cpp:165] Memory required for data: 35268400
I0530 07:40:26.958803  7768 layer_factory.hpp:77] Creating layer relu_x1
I0530 07:40:26.958824  7768 net.cpp:106] Creating Layer relu_x1
I0530 07:40:26.958837  7768 net.cpp:454] relu_x1 <- conv_x1
I0530 07:40:26.958849  7768 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0530 07:40:26.959370  7768 net.cpp:150] Setting up relu_x1
I0530 07:40:26.959388  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:40:26.959398  7768 net.cpp:165] Memory required for data: 62916400
I0530 07:40:26.959408  7768 layer_factory.hpp:77] Creating layer pool_x1
I0530 07:40:26.959425  7768 net.cpp:106] Creating Layer pool_x1
I0530 07:40:26.959435  7768 net.cpp:454] pool_x1 <- conv_x1
I0530 07:40:26.959450  7768 net.cpp:411] pool_x1 -> pool_x1
I0530 07:40:26.959532  7768 net.cpp:150] Setting up pool_x1
I0530 07:40:26.959545  7768 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 07:40:26.959554  7768 net.cpp:165] Memory required for data: 76740400
I0530 07:40:26.959564  7768 layer_factory.hpp:77] Creating layer conv_x2
I0530 07:40:26.959588  7768 net.cpp:106] Creating Layer conv_x2
I0530 07:40:26.959599  7768 net.cpp:454] conv_x2 <- pool_x1
I0530 07:40:26.959612  7768 net.cpp:411] conv_x2 -> conv_x2
I0530 07:40:26.962301  7768 net.cpp:150] Setting up conv_x2
I0530 07:40:26.962329  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:40:26.962342  7768 net.cpp:165] Memory required for data: 96612400
I0530 07:40:26.962363  7768 layer_factory.hpp:77] Creating layer relu_x2
I0530 07:40:26.962376  7768 net.cpp:106] Creating Layer relu_x2
I0530 07:40:26.962388  7768 net.cpp:454] relu_x2 <- conv_x2
I0530 07:40:26.962399  7768 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0530 07:40:26.962743  7768 net.cpp:150] Setting up relu_x2
I0530 07:40:26.962756  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:40:26.962767  7768 net.cpp:165] Memory required for data: 116484400
I0530 07:40:26.962777  7768 layer_factory.hpp:77] Creating layer pool_x2
I0530 07:40:26.962790  7768 net.cpp:106] Creating Layer pool_x2
I0530 07:40:26.962800  7768 net.cpp:454] pool_x2 <- conv_x2
I0530 07:40:26.962812  7768 net.cpp:411] pool_x2 -> pool_x2
I0530 07:40:26.962882  7768 net.cpp:150] Setting up pool_x2
I0530 07:40:26.962895  7768 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 07:40:26.962905  7768 net.cpp:165] Memory required for data: 126420400
I0530 07:40:26.962915  7768 layer_factory.hpp:77] Creating layer conv_x3
I0530 07:40:26.962934  7768 net.cpp:106] Creating Layer conv_x3
I0530 07:40:26.962944  7768 net.cpp:454] conv_x3 <- pool_x2
I0530 07:40:26.962957  7768 net.cpp:411] conv_x3 -> conv_x3
I0530 07:40:26.964877  7768 net.cpp:150] Setting up conv_x3
I0530 07:40:26.964897  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:40:26.964907  7768 net.cpp:165] Memory required for data: 137262000
I0530 07:40:26.964926  7768 layer_factory.hpp:77] Creating layer relu_x3
I0530 07:40:26.964941  7768 net.cpp:106] Creating Layer relu_x3
I0530 07:40:26.964951  7768 net.cpp:454] relu_x3 <- conv_x3
I0530 07:40:26.964963  7768 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0530 07:40:26.965435  7768 net.cpp:150] Setting up relu_x3
I0530 07:40:26.965451  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:40:26.965472  7768 net.cpp:165] Memory required for data: 148103600
I0530 07:40:26.965483  7768 layer_factory.hpp:77] Creating layer pool_x3
I0530 07:40:26.965497  7768 net.cpp:106] Creating Layer pool_x3
I0530 07:40:26.965507  7768 net.cpp:454] pool_x3 <- conv_x3
I0530 07:40:26.965519  7768 net.cpp:411] pool_x3 -> pool_x3
I0530 07:40:26.965590  7768 net.cpp:150] Setting up pool_x3
I0530 07:40:26.965602  7768 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 07:40:26.965615  7768 net.cpp:165] Memory required for data: 153524400
I0530 07:40:26.965626  7768 layer_factory.hpp:77] Creating layer conv_x4
I0530 07:40:26.965642  7768 net.cpp:106] Creating Layer conv_x4
I0530 07:40:26.965652  7768 net.cpp:454] conv_x4 <- pool_x3
I0530 07:40:26.965665  7768 net.cpp:411] conv_x4 -> conv_x4
I0530 07:40:26.968633  7768 net.cpp:150] Setting up conv_x4
I0530 07:40:26.968657  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:40:26.968667  7768 net.cpp:165] Memory required for data: 157153200
I0530 07:40:26.968683  7768 layer_factory.hpp:77] Creating layer relu_x4
I0530 07:40:26.968696  7768 net.cpp:106] Creating Layer relu_x4
I0530 07:40:26.968706  7768 net.cpp:454] relu_x4 <- conv_x4
I0530 07:40:26.968720  7768 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0530 07:40:26.969184  7768 net.cpp:150] Setting up relu_x4
I0530 07:40:26.969200  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:40:26.969211  7768 net.cpp:165] Memory required for data: 160782000
I0530 07:40:26.969221  7768 layer_factory.hpp:77] Creating layer pool_x4
I0530 07:40:26.969233  7768 net.cpp:106] Creating Layer pool_x4
I0530 07:40:26.969244  7768 net.cpp:454] pool_x4 <- conv_x4
I0530 07:40:26.969256  7768 net.cpp:411] pool_x4 -> pool_x4
I0530 07:40:26.969326  7768 net.cpp:150] Setting up pool_x4
I0530 07:40:26.969339  7768 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 07:40:26.969349  7768 net.cpp:165] Memory required for data: 162596400
I0530 07:40:26.969358  7768 layer_factory.hpp:77] Creating layer dl_x1
I0530 07:40:26.969379  7768 net.cpp:106] Creating Layer dl_x1
I0530 07:40:26.969389  7768 net.cpp:454] dl_x1 <- pool_x4
I0530 07:40:26.969403  7768 net.cpp:411] dl_x1 -> dl_x1
I0530 07:40:26.984802  7768 net.cpp:150] Setting up dl_x1
I0530 07:40:26.984827  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:26.984836  7768 net.cpp:165] Memory required for data: 162674800
I0530 07:40:26.984858  7768 layer_factory.hpp:77] Creating layer relu_x5
I0530 07:40:26.984874  7768 net.cpp:106] Creating Layer relu_x5
I0530 07:40:26.984884  7768 net.cpp:454] relu_x5 <- dl_x1
I0530 07:40:26.984899  7768 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0530 07:40:26.985242  7768 net.cpp:150] Setting up relu_x5
I0530 07:40:26.985255  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:26.985265  7768 net.cpp:165] Memory required for data: 162753200
I0530 07:40:26.985275  7768 layer_factory.hpp:77] Creating layer drop_x1
I0530 07:40:26.985297  7768 net.cpp:106] Creating Layer drop_x1
I0530 07:40:26.985307  7768 net.cpp:454] drop_x1 <- dl_x1
I0530 07:40:26.985319  7768 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0530 07:40:26.985364  7768 net.cpp:150] Setting up drop_x1
I0530 07:40:26.985378  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:26.985388  7768 net.cpp:165] Memory required for data: 162831600
I0530 07:40:26.985396  7768 layer_factory.hpp:77] Creating layer conv_u1
I0530 07:40:26.985419  7768 net.cpp:106] Creating Layer conv_u1
I0530 07:40:26.985430  7768 net.cpp:454] conv_u1 <- hits-u
I0530 07:40:26.985443  7768 net.cpp:411] conv_u1 -> conv_u1
I0530 07:40:26.987290  7768 net.cpp:150] Setting up conv_u1
I0530 07:40:26.987313  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:40:26.987325  7768 net.cpp:165] Memory required for data: 190479600
I0530 07:40:26.987339  7768 layer_factory.hpp:77] Creating layer relu_u1
I0530 07:40:26.987354  7768 net.cpp:106] Creating Layer relu_u1
I0530 07:40:26.987363  7768 net.cpp:454] relu_u1 <- conv_u1
I0530 07:40:26.987375  7768 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0530 07:40:26.987864  7768 net.cpp:150] Setting up relu_u1
I0530 07:40:26.987882  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:40:26.987893  7768 net.cpp:165] Memory required for data: 218127600
I0530 07:40:26.987903  7768 layer_factory.hpp:77] Creating layer pool_u1
I0530 07:40:26.987916  7768 net.cpp:106] Creating Layer pool_u1
I0530 07:40:26.987926  7768 net.cpp:454] pool_u1 <- conv_u1
I0530 07:40:26.987939  7768 net.cpp:411] pool_u1 -> pool_u1
I0530 07:40:26.988011  7768 net.cpp:150] Setting up pool_u1
I0530 07:40:26.988024  7768 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 07:40:26.988034  7768 net.cpp:165] Memory required for data: 231951600
I0530 07:40:26.988044  7768 layer_factory.hpp:77] Creating layer conv_u2
I0530 07:40:26.988060  7768 net.cpp:106] Creating Layer conv_u2
I0530 07:40:26.988070  7768 net.cpp:454] conv_u2 <- pool_u1
I0530 07:40:26.988085  7768 net.cpp:411] conv_u2 -> conv_u2
I0530 07:40:26.989908  7768 net.cpp:150] Setting up conv_u2
I0530 07:40:26.989931  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:40:26.989943  7768 net.cpp:165] Memory required for data: 251823600
I0530 07:40:26.989958  7768 layer_factory.hpp:77] Creating layer relu_u2
I0530 07:40:26.989970  7768 net.cpp:106] Creating Layer relu_u2
I0530 07:40:26.989980  7768 net.cpp:454] relu_u2 <- conv_u2
I0530 07:40:26.989994  7768 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0530 07:40:26.990312  7768 net.cpp:150] Setting up relu_u2
I0530 07:40:26.990326  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:40:26.990336  7768 net.cpp:165] Memory required for data: 271695600
I0530 07:40:26.990346  7768 layer_factory.hpp:77] Creating layer pool_u2
I0530 07:40:26.990360  7768 net.cpp:106] Creating Layer pool_u2
I0530 07:40:26.990368  7768 net.cpp:454] pool_u2 <- conv_u2
I0530 07:40:26.990381  7768 net.cpp:411] pool_u2 -> pool_u2
I0530 07:40:26.990454  7768 net.cpp:150] Setting up pool_u2
I0530 07:40:26.990469  7768 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 07:40:26.990479  7768 net.cpp:165] Memory required for data: 281631600
I0530 07:40:26.990489  7768 layer_factory.hpp:77] Creating layer conv_u3
I0530 07:40:26.990505  7768 net.cpp:106] Creating Layer conv_u3
I0530 07:40:26.990516  7768 net.cpp:454] conv_u3 <- pool_u2
I0530 07:40:26.990530  7768 net.cpp:411] conv_u3 -> conv_u3
I0530 07:40:26.992454  7768 net.cpp:150] Setting up conv_u3
I0530 07:40:26.992476  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:40:26.992489  7768 net.cpp:165] Memory required for data: 292473200
I0530 07:40:26.992507  7768 layer_factory.hpp:77] Creating layer relu_u3
I0530 07:40:26.992524  7768 net.cpp:106] Creating Layer relu_u3
I0530 07:40:26.992534  7768 net.cpp:454] relu_u3 <- conv_u3
I0530 07:40:26.992547  7768 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0530 07:40:26.992877  7768 net.cpp:150] Setting up relu_u3
I0530 07:40:26.992892  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:40:26.992902  7768 net.cpp:165] Memory required for data: 303314800
I0530 07:40:26.992911  7768 layer_factory.hpp:77] Creating layer pool_u3
I0530 07:40:26.992923  7768 net.cpp:106] Creating Layer pool_u3
I0530 07:40:26.992933  7768 net.cpp:454] pool_u3 <- conv_u3
I0530 07:40:26.992945  7768 net.cpp:411] pool_u3 -> pool_u3
I0530 07:40:26.993016  7768 net.cpp:150] Setting up pool_u3
I0530 07:40:26.993028  7768 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 07:40:26.993037  7768 net.cpp:165] Memory required for data: 308735600
I0530 07:40:26.993048  7768 layer_factory.hpp:77] Creating layer conv_u4
I0530 07:40:26.993064  7768 net.cpp:106] Creating Layer conv_u4
I0530 07:40:26.993075  7768 net.cpp:454] conv_u4 <- pool_u3
I0530 07:40:26.993089  7768 net.cpp:411] conv_u4 -> conv_u4
I0530 07:40:26.995307  7768 net.cpp:150] Setting up conv_u4
I0530 07:40:26.995331  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:40:26.995342  7768 net.cpp:165] Memory required for data: 312364400
I0530 07:40:26.995365  7768 layer_factory.hpp:77] Creating layer relu_u4
I0530 07:40:26.995378  7768 net.cpp:106] Creating Layer relu_u4
I0530 07:40:26.995398  7768 net.cpp:454] relu_u4 <- conv_u4
I0530 07:40:26.995412  7768 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0530 07:40:26.995883  7768 net.cpp:150] Setting up relu_u4
I0530 07:40:26.995900  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:40:26.995910  7768 net.cpp:165] Memory required for data: 315993200
I0530 07:40:26.995920  7768 layer_factory.hpp:77] Creating layer pool_u4
I0530 07:40:26.995934  7768 net.cpp:106] Creating Layer pool_u4
I0530 07:40:26.995944  7768 net.cpp:454] pool_u4 <- conv_u4
I0530 07:40:26.995956  7768 net.cpp:411] pool_u4 -> pool_u4
I0530 07:40:26.996027  7768 net.cpp:150] Setting up pool_u4
I0530 07:40:26.996040  7768 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 07:40:26.996052  7768 net.cpp:165] Memory required for data: 317807600
I0530 07:40:26.996062  7768 layer_factory.hpp:77] Creating layer dl_u1
I0530 07:40:26.996074  7768 net.cpp:106] Creating Layer dl_u1
I0530 07:40:26.996084  7768 net.cpp:454] dl_u1 <- pool_u4
I0530 07:40:26.996098  7768 net.cpp:411] dl_u1 -> dl_u1
I0530 07:40:27.011445  7768 net.cpp:150] Setting up dl_u1
I0530 07:40:27.011473  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:27.011487  7768 net.cpp:165] Memory required for data: 317886000
I0530 07:40:27.011503  7768 layer_factory.hpp:77] Creating layer relu_u5
I0530 07:40:27.011518  7768 net.cpp:106] Creating Layer relu_u5
I0530 07:40:27.011528  7768 net.cpp:454] relu_u5 <- dl_u1
I0530 07:40:27.011543  7768 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0530 07:40:27.011885  7768 net.cpp:150] Setting up relu_u5
I0530 07:40:27.011898  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:27.011909  7768 net.cpp:165] Memory required for data: 317964400
I0530 07:40:27.011919  7768 layer_factory.hpp:77] Creating layer drop_u1
I0530 07:40:27.011932  7768 net.cpp:106] Creating Layer drop_u1
I0530 07:40:27.011942  7768 net.cpp:454] drop_u1 <- dl_u1
I0530 07:40:27.011955  7768 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0530 07:40:27.011998  7768 net.cpp:150] Setting up drop_u1
I0530 07:40:27.012012  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:27.012022  7768 net.cpp:165] Memory required for data: 318042800
I0530 07:40:27.012030  7768 layer_factory.hpp:77] Creating layer conv_v1
I0530 07:40:27.012048  7768 net.cpp:106] Creating Layer conv_v1
I0530 07:40:27.012058  7768 net.cpp:454] conv_v1 <- hits-v
I0530 07:40:27.012071  7768 net.cpp:411] conv_v1 -> conv_v1
I0530 07:40:27.014025  7768 net.cpp:150] Setting up conv_v1
I0530 07:40:27.014048  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:40:27.014060  7768 net.cpp:165] Memory required for data: 345690800
I0530 07:40:27.014075  7768 layer_factory.hpp:77] Creating layer relu_v1
I0530 07:40:27.014099  7768 net.cpp:106] Creating Layer relu_v1
I0530 07:40:27.014109  7768 net.cpp:454] relu_v1 <- conv_v1
I0530 07:40:27.014122  7768 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0530 07:40:27.014605  7768 net.cpp:150] Setting up relu_v1
I0530 07:40:27.014622  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:40:27.014633  7768 net.cpp:165] Memory required for data: 373338800
I0530 07:40:27.014643  7768 layer_factory.hpp:77] Creating layer pool_v1
I0530 07:40:27.014657  7768 net.cpp:106] Creating Layer pool_v1
I0530 07:40:27.014667  7768 net.cpp:454] pool_v1 <- conv_v1
I0530 07:40:27.014680  7768 net.cpp:411] pool_v1 -> pool_v1
I0530 07:40:27.014755  7768 net.cpp:150] Setting up pool_v1
I0530 07:40:27.014768  7768 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 07:40:27.014778  7768 net.cpp:165] Memory required for data: 387162800
I0530 07:40:27.014787  7768 layer_factory.hpp:77] Creating layer conv_v2
I0530 07:40:27.014804  7768 net.cpp:106] Creating Layer conv_v2
I0530 07:40:27.014814  7768 net.cpp:454] conv_v2 <- pool_v1
I0530 07:40:27.014827  7768 net.cpp:411] conv_v2 -> conv_v2
I0530 07:40:27.016540  7768 net.cpp:150] Setting up conv_v2
I0530 07:40:27.016556  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:40:27.016568  7768 net.cpp:165] Memory required for data: 407034800
I0530 07:40:27.016597  7768 layer_factory.hpp:77] Creating layer relu_v2
I0530 07:40:27.016610  7768 net.cpp:106] Creating Layer relu_v2
I0530 07:40:27.016621  7768 net.cpp:454] relu_v2 <- conv_v2
I0530 07:40:27.016634  7768 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0530 07:40:27.017117  7768 net.cpp:150] Setting up relu_v2
I0530 07:40:27.017133  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:40:27.017143  7768 net.cpp:165] Memory required for data: 426906800
I0530 07:40:27.017154  7768 layer_factory.hpp:77] Creating layer pool_v2
I0530 07:40:27.017166  7768 net.cpp:106] Creating Layer pool_v2
I0530 07:40:27.017176  7768 net.cpp:454] pool_v2 <- conv_v2
I0530 07:40:27.017189  7768 net.cpp:411] pool_v2 -> pool_v2
I0530 07:40:27.017261  7768 net.cpp:150] Setting up pool_v2
I0530 07:40:27.017274  7768 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 07:40:27.017284  7768 net.cpp:165] Memory required for data: 436842800
I0530 07:40:27.017294  7768 layer_factory.hpp:77] Creating layer conv_v3
I0530 07:40:27.017308  7768 net.cpp:106] Creating Layer conv_v3
I0530 07:40:27.017319  7768 net.cpp:454] conv_v3 <- pool_v2
I0530 07:40:27.017333  7768 net.cpp:411] conv_v3 -> conv_v3
I0530 07:40:27.019295  7768 net.cpp:150] Setting up conv_v3
I0530 07:40:27.019318  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:40:27.019331  7768 net.cpp:165] Memory required for data: 447684400
I0530 07:40:27.019346  7768 layer_factory.hpp:77] Creating layer relu_v3
I0530 07:40:27.019359  7768 net.cpp:106] Creating Layer relu_v3
I0530 07:40:27.019369  7768 net.cpp:454] relu_v3 <- conv_v3
I0530 07:40:27.019382  7768 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0530 07:40:27.019702  7768 net.cpp:150] Setting up relu_v3
I0530 07:40:27.019716  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:40:27.019727  7768 net.cpp:165] Memory required for data: 458526000
I0530 07:40:27.019737  7768 layer_factory.hpp:77] Creating layer pool_v3
I0530 07:40:27.019749  7768 net.cpp:106] Creating Layer pool_v3
I0530 07:40:27.019759  7768 net.cpp:454] pool_v3 <- conv_v3
I0530 07:40:27.019773  7768 net.cpp:411] pool_v3 -> pool_v3
I0530 07:40:27.019841  7768 net.cpp:150] Setting up pool_v3
I0530 07:40:27.019855  7768 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 07:40:27.019865  7768 net.cpp:165] Memory required for data: 463946800
I0530 07:40:27.019876  7768 layer_factory.hpp:77] Creating layer conv_v4
I0530 07:40:27.019891  7768 net.cpp:106] Creating Layer conv_v4
I0530 07:40:27.019901  7768 net.cpp:454] conv_v4 <- pool_v3
I0530 07:40:27.019914  7768 net.cpp:411] conv_v4 -> conv_v4
I0530 07:40:27.022006  7768 net.cpp:150] Setting up conv_v4
I0530 07:40:27.022028  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:40:27.022040  7768 net.cpp:165] Memory required for data: 467575600
I0530 07:40:27.022055  7768 layer_factory.hpp:77] Creating layer relu_v4
I0530 07:40:27.022068  7768 net.cpp:106] Creating Layer relu_v4
I0530 07:40:27.022078  7768 net.cpp:454] relu_v4 <- conv_v4
I0530 07:40:27.022090  7768 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0530 07:40:27.022567  7768 net.cpp:150] Setting up relu_v4
I0530 07:40:27.022583  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:40:27.022594  7768 net.cpp:165] Memory required for data: 471204400
I0530 07:40:27.022614  7768 layer_factory.hpp:77] Creating layer pool_v4
I0530 07:40:27.022629  7768 net.cpp:106] Creating Layer pool_v4
I0530 07:40:27.022639  7768 net.cpp:454] pool_v4 <- conv_v4
I0530 07:40:27.022651  7768 net.cpp:411] pool_v4 -> pool_v4
I0530 07:40:27.022727  7768 net.cpp:150] Setting up pool_v4
I0530 07:40:27.022739  7768 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 07:40:27.022750  7768 net.cpp:165] Memory required for data: 473018800
I0530 07:40:27.022760  7768 layer_factory.hpp:77] Creating layer dl_v1
I0530 07:40:27.022774  7768 net.cpp:106] Creating Layer dl_v1
I0530 07:40:27.022785  7768 net.cpp:454] dl_v1 <- pool_v4
I0530 07:40:27.022799  7768 net.cpp:411] dl_v1 -> dl_v1
I0530 07:40:27.038246  7768 net.cpp:150] Setting up dl_v1
I0530 07:40:27.038286  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:27.038302  7768 net.cpp:165] Memory required for data: 473097200
I0530 07:40:27.038322  7768 layer_factory.hpp:77] Creating layer relu_v5
I0530 07:40:27.038337  7768 net.cpp:106] Creating Layer relu_v5
I0530 07:40:27.038348  7768 net.cpp:454] relu_v5 <- dl_v1
I0530 07:40:27.038362  7768 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0530 07:40:27.038722  7768 net.cpp:150] Setting up relu_v5
I0530 07:40:27.038736  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:27.038746  7768 net.cpp:165] Memory required for data: 473175600
I0530 07:40:27.038758  7768 layer_factory.hpp:77] Creating layer drop_v1
I0530 07:40:27.038770  7768 net.cpp:106] Creating Layer drop_v1
I0530 07:40:27.038780  7768 net.cpp:454] drop_v1 <- dl_v1
I0530 07:40:27.038792  7768 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0530 07:40:27.038837  7768 net.cpp:150] Setting up drop_v1
I0530 07:40:27.038851  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:40:27.038861  7768 net.cpp:165] Memory required for data: 473254000
I0530 07:40:27.038871  7768 layer_factory.hpp:77] Creating layer concat_xuv
I0530 07:40:27.038892  7768 net.cpp:106] Creating Layer concat_xuv
I0530 07:40:27.038902  7768 net.cpp:454] concat_xuv <- dl_x1
I0530 07:40:27.038913  7768 net.cpp:454] concat_xuv <- dl_u1
I0530 07:40:27.038924  7768 net.cpp:454] concat_xuv <- dl_v1
I0530 07:40:27.038936  7768 net.cpp:411] concat_xuv -> concat_xuv
I0530 07:40:27.038988  7768 net.cpp:150] Setting up concat_xuv
I0530 07:40:27.039001  7768 net.cpp:157] Top shape: 100 588 (58800)
I0530 07:40:27.039011  7768 net.cpp:165] Memory required for data: 473489200
I0530 07:40:27.039021  7768 layer_factory.hpp:77] Creating layer dl_xuv
I0530 07:40:27.039034  7768 net.cpp:106] Creating Layer dl_xuv
I0530 07:40:27.039046  7768 net.cpp:454] dl_xuv <- concat_xuv
I0530 07:40:27.039058  7768 net.cpp:411] dl_xuv -> dl_xuv
I0530 07:40:27.040091  7768 net.cpp:150] Setting up dl_xuv
I0530 07:40:27.040115  7768 net.cpp:157] Top shape: 100 98 (9800)
I0530 07:40:27.040125  7768 net.cpp:165] Memory required for data: 473528400
I0530 07:40:27.040140  7768 layer_factory.hpp:77] Creating layer relu_xuv
I0530 07:40:27.040154  7768 net.cpp:106] Creating Layer relu_xuv
I0530 07:40:27.040164  7768 net.cpp:454] relu_xuv <- dl_xuv
I0530 07:40:27.040176  7768 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0530 07:40:27.040724  7768 net.cpp:150] Setting up relu_xuv
I0530 07:40:27.040741  7768 net.cpp:157] Top shape: 100 98 (9800)
I0530 07:40:27.040752  7768 net.cpp:165] Memory required for data: 473567600
I0530 07:40:27.040762  7768 layer_factory.hpp:77] Creating layer drop_xuv
I0530 07:40:27.040776  7768 net.cpp:106] Creating Layer drop_xuv
I0530 07:40:27.040784  7768 net.cpp:454] drop_xuv <- dl_xuv
I0530 07:40:27.040797  7768 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0530 07:40:27.040843  7768 net.cpp:150] Setting up drop_xuv
I0530 07:40:27.040855  7768 net.cpp:157] Top shape: 100 98 (9800)
I0530 07:40:27.040866  7768 net.cpp:165] Memory required for data: 473606800
I0530 07:40:27.040876  7768 layer_factory.hpp:77] Creating layer output
I0530 07:40:27.040889  7768 net.cpp:106] Creating Layer output
I0530 07:40:27.040899  7768 net.cpp:454] output <- dl_xuv
I0530 07:40:27.040911  7768 net.cpp:411] output -> output
I0530 07:40:27.041139  7768 net.cpp:150] Setting up output
I0530 07:40:27.041152  7768 net.cpp:157] Top shape: 100 11 (1100)
I0530 07:40:27.041162  7768 net.cpp:165] Memory required for data: 473611200
I0530 07:40:27.041193  7768 layer_factory.hpp:77] Creating layer drop_output
I0530 07:40:27.041205  7768 net.cpp:106] Creating Layer drop_output
I0530 07:40:27.041215  7768 net.cpp:454] drop_output <- output
I0530 07:40:27.041227  7768 net.cpp:397] drop_output -> output (in-place)
I0530 07:40:27.041270  7768 net.cpp:150] Setting up drop_output
I0530 07:40:27.041283  7768 net.cpp:157] Top shape: 100 11 (1100)
I0530 07:40:27.041295  7768 net.cpp:165] Memory required for data: 473615600
I0530 07:40:27.041303  7768 layer_factory.hpp:77] Creating layer loss
I0530 07:40:27.041332  7768 net.cpp:106] Creating Layer loss
I0530 07:40:27.041342  7768 net.cpp:454] loss <- output
I0530 07:40:27.041353  7768 net.cpp:454] loss <- segments
I0530 07:40:27.041366  7768 net.cpp:411] loss -> loss
I0530 07:40:27.041383  7768 layer_factory.hpp:77] Creating layer loss
I0530 07:40:27.041887  7768 net.cpp:150] Setting up loss
I0530 07:40:27.041901  7768 net.cpp:157] Top shape: (1)
I0530 07:40:27.041911  7768 net.cpp:160]     with loss weight 1
I0530 07:40:27.041955  7768 net.cpp:165] Memory required for data: 473615604
I0530 07:40:27.041965  7768 net.cpp:226] loss needs backward computation.
I0530 07:40:27.041976  7768 net.cpp:226] drop_output needs backward computation.
I0530 07:40:27.041987  7768 net.cpp:226] output needs backward computation.
I0530 07:40:27.041997  7768 net.cpp:226] drop_xuv needs backward computation.
I0530 07:40:27.042007  7768 net.cpp:226] relu_xuv needs backward computation.
I0530 07:40:27.042017  7768 net.cpp:226] dl_xuv needs backward computation.
I0530 07:40:27.042027  7768 net.cpp:226] concat_xuv needs backward computation.
I0530 07:40:27.042038  7768 net.cpp:226] drop_v1 needs backward computation.
I0530 07:40:27.042048  7768 net.cpp:226] relu_v5 needs backward computation.
I0530 07:40:27.042057  7768 net.cpp:226] dl_v1 needs backward computation.
I0530 07:40:27.042068  7768 net.cpp:226] pool_v4 needs backward computation.
I0530 07:40:27.042078  7768 net.cpp:226] relu_v4 needs backward computation.
I0530 07:40:27.042088  7768 net.cpp:226] conv_v4 needs backward computation.
I0530 07:40:27.042098  7768 net.cpp:226] pool_v3 needs backward computation.
I0530 07:40:27.042111  7768 net.cpp:226] relu_v3 needs backward computation.
I0530 07:40:27.042122  7768 net.cpp:226] conv_v3 needs backward computation.
I0530 07:40:27.042134  7768 net.cpp:226] pool_v2 needs backward computation.
I0530 07:40:27.042143  7768 net.cpp:226] relu_v2 needs backward computation.
I0530 07:40:27.042153  7768 net.cpp:226] conv_v2 needs backward computation.
I0530 07:40:27.042165  7768 net.cpp:226] pool_v1 needs backward computation.
I0530 07:40:27.042174  7768 net.cpp:226] relu_v1 needs backward computation.
I0530 07:40:27.042184  7768 net.cpp:226] conv_v1 needs backward computation.
I0530 07:40:27.042196  7768 net.cpp:226] drop_u1 needs backward computation.
I0530 07:40:27.042206  7768 net.cpp:226] relu_u5 needs backward computation.
I0530 07:40:27.042215  7768 net.cpp:226] dl_u1 needs backward computation.
I0530 07:40:27.042224  7768 net.cpp:226] pool_u4 needs backward computation.
I0530 07:40:27.042235  7768 net.cpp:226] relu_u4 needs backward computation.
I0530 07:40:27.042246  7768 net.cpp:226] conv_u4 needs backward computation.
I0530 07:40:27.042256  7768 net.cpp:226] pool_u3 needs backward computation.
I0530 07:40:27.042266  7768 net.cpp:226] relu_u3 needs backward computation.
I0530 07:40:27.042276  7768 net.cpp:226] conv_u3 needs backward computation.
I0530 07:40:27.042287  7768 net.cpp:226] pool_u2 needs backward computation.
I0530 07:40:27.042299  7768 net.cpp:226] relu_u2 needs backward computation.
I0530 07:40:27.042309  7768 net.cpp:226] conv_u2 needs backward computation.
I0530 07:40:27.042320  7768 net.cpp:226] pool_u1 needs backward computation.
I0530 07:40:27.042330  7768 net.cpp:226] relu_u1 needs backward computation.
I0530 07:40:27.042341  7768 net.cpp:226] conv_u1 needs backward computation.
I0530 07:40:27.042352  7768 net.cpp:226] drop_x1 needs backward computation.
I0530 07:40:27.042363  7768 net.cpp:226] relu_x5 needs backward computation.
I0530 07:40:27.042374  7768 net.cpp:226] dl_x1 needs backward computation.
I0530 07:40:27.042385  7768 net.cpp:226] pool_x4 needs backward computation.
I0530 07:40:27.042395  7768 net.cpp:226] relu_x4 needs backward computation.
I0530 07:40:27.042405  7768 net.cpp:226] conv_x4 needs backward computation.
I0530 07:40:27.042417  7768 net.cpp:226] pool_x3 needs backward computation.
I0530 07:40:27.042428  7768 net.cpp:226] relu_x3 needs backward computation.
I0530 07:40:27.042438  7768 net.cpp:226] conv_x3 needs backward computation.
I0530 07:40:27.042454  7768 net.cpp:226] pool_x2 needs backward computation.
I0530 07:40:27.042465  7768 net.cpp:226] relu_x2 needs backward computation.
I0530 07:40:27.042475  7768 net.cpp:226] conv_x2 needs backward computation.
I0530 07:40:27.042486  7768 net.cpp:226] pool_x1 needs backward computation.
I0530 07:40:27.042497  7768 net.cpp:226] relu_x1 needs backward computation.
I0530 07:40:27.042507  7768 net.cpp:226] conv_x1 needs backward computation.
I0530 07:40:27.042520  7768 net.cpp:228] data does not need backward computation.
I0530 07:40:27.042529  7768 net.cpp:270] This network produces output loss
I0530 07:40:27.042574  7768 net.cpp:283] Network initialization done.
I0530 07:40:27.045490  7768 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/logs/epsilon_inv_2016-05-30T07.39.00.897234.prototxt
I0530 07:40:27.045622  7768 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0530 07:40:27.046401  7768 net.cpp:49] Initializing net from parameters: 
name: "epsilon_127x50_xuv"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "hits-x"
  top: "hits-u"
  top: "hits-v"
  top: "segments"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv_x1"
  type: "Convolution"
  bottom: "hits-x"
  top: "conv_x1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_x1"
  type: "ReLU"
  bottom: "conv_x1"
  top: "conv_x1"
}
layer {
  name: "pool_x1"
  type: "Pooling"
  bottom: "conv_x1"
  top: "pool_x1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x2"
  type: "Convolution"
  bottom: "pool_x1"
  top: "conv_x2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_x2"
  type: "ReLU"
  bottom: "conv_x2"
  top: "conv_x2"
}
layer {
  name: "pool_x2"
  type: "Pooling"
  bottom: "conv_x2"
  top: "pool_x2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x3"
  type: "Convolution"
  bottom: "pool_x2"
  top: "conv_x3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x3"
  type: "ReLU"
  bottom: "conv_x3"
  top: "conv_x3"
}
layer {
  name: "pool_x3"
  type: "Pooling"
  bottom: "conv_x3"
  top: "pool_x3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_x4"
  type: "Convolution"
  bottom: "pool_x3"
  top: "conv_x4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_x4"
  type: "ReLU"
  bottom: "conv_x4"
  top: "conv_x4"
}
layer {
  name: "pool_x4"
  type: "Pooling"
  bottom: "conv_x4"
  top: "pool_x4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_x1"
  type: "InnerProduct"
  bottom: "pool_x4"
  top: "dl_x1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_x5"
  type: "ReLU"
  bottom: "dl_x1"
  top: "dl_x1"
}
layer {
  name: "drop_x1"
  type: "Dropout"
  bottom: "dl_x1"
  top: "dl_x1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_u1"
  type: "Convolution"
  bottom: "hits-u"
  top: "conv_u1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_u1"
  type: "ReLU"
  bottom: "conv_u1"
  top: "conv_u1"
}
layer {
  name: "pool_u1"
  type: "Pooling"
  bottom: "conv_u1"
  top: "pool_u1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u2"
  type: "Convolution"
  bottom: "pool_u1"
  top: "conv_u2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_u2"
  type: "ReLU"
  bottom: "conv_u2"
  top: "conv_u2"
}
layer {
  name: "pool_u2"
  type: "Pooling"
  bottom: "conv_u2"
  top: "pool_u2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u3"
  type: "Convolution"
  bottom: "pool_u2"
  top: "conv_u3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u3"
  type: "ReLU"
  bottom: "conv_u3"
  top: "conv_u3"
}
layer {
  name: "pool_u3"
  type: "Pooling"
  bottom: "conv_u3"
  top: "pool_u3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_u4"
  type: "Convolution"
  bottom: "pool_u3"
  top: "conv_u4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_u4"
  type: "ReLU"
  bottom: "conv_u4"
  top: "conv_u4"
}
layer {
  name: "pool_u4"
  type: "Pooling"
  bottom: "conv_u4"
  top: "pool_u4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_u1"
  type: "InnerProduct"
  bottom: "pool_u4"
  top: "dl_u1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_u5"
  type: "ReLU"
  bottom: "dl_u1"
  top: "dl_u1"
}
layer {
  name: "drop_u1"
  type: "Dropout"
  bottom: "dl_u1"
  top: "dl_u1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_v1"
  type: "Convolution"
  bottom: "hits-v"
  top: "conv_v1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu_v1"
  type: "ReLU"
  bottom: "conv_v1"
  top: "conv_v1"
}
layer {
  name: "pool_v1"
  type: "Pooling"
  bottom: "conv_v1"
  top: "pool_v1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v2"
  type: "Convolution"
  bottom: "pool_v1"
  top: "conv_v2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu_v2"
  type: "ReLU"
  bottom: "conv_v2"
  top: "conv_v2"
}
layer {
  name: "pool_v2"
  type: "Pooling"
  bottom: "conv_v2"
  top: "pool_v2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v3"
  type: "Convolution"
  bottom: "pool_v2"
  top: "conv_v3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v3"
  type: "ReLU"
  bottom: "conv_v3"
  top: "conv_v3"
}
layer {
  name: "pool_v3"
  type: "Pooling"
  bottom: "conv_v3"
  top: "pool_v3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv_v4"
  type: "Convolution"
  bottom: "pool_v3"
  top: "conv_v4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu_v4"
  type: "ReLU"
  bottom: "conv_v4"
  top: "conv_v4"
}
layer {
  name: "pool_v4"
  type: "Pooling"
  bottom: "conv_v4"
  top: "pool_v4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "dl_v1"
  type: "InnerProduct"
  bottom: "pool_v4"
  top: "dl_v1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_v5"
  type: "ReLU"
  bottom: "dl_v1"
  top: "dl_v1"
}
layer {
  name: "drop_v1"
  type: "Dropout"
  bottom: "dl_v1"
  top: "dl_v1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat_xuv"
  type: "Concat"
  bottom: "dl_x1"
  bottom: "dl_u1"
  bottom: "dl_v1"
  top: "concat_xuv"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dl_xuv"
  type: "InnerProduct"
  bottom: "concat_xuv"
  top: "dl_xuv"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_xuv"
  type: "ReLU"
  bottom: "dl_xuv"
  top: "dl_xuv"
}
layer {
  name: "drop_xuv"
  type: "Dropout"
  bottom: "dl_xuv"
  top: "dl_xuv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "output"
  type: "InnerProduct"
  bottom: "dl_xuv"
  top: "output"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop_output"
  type: "Dropout"
  bottom: "output"
  top: "output"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "output"
  bottom: "segments"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "output"
  bottom: "segments"
  top: "loss"
}
I0530 07:40:27.046783  7768 layer_factory.hpp:77] Creating layer data
I0530 07:40:27.046799  7768 net.cpp:106] Creating Layer data
I0530 07:40:27.046811  7768 net.cpp:411] data -> hits-x
I0530 07:40:27.046828  7768 net.cpp:411] data -> hits-u
I0530 07:40:27.046844  7768 net.cpp:411] data -> hits-v
I0530 07:40:27.046861  7768 net.cpp:411] data -> segments
I0530 07:40:27.046876  7768 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/xuv/epsilon_127x50_xuv.testlist
I0530 07:40:27.048231  7768 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0530 07:41:31.491009  7768 net.cpp:150] Setting up data
I0530 07:41:31.491169  7768 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 07:41:31.491184  7768 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 07:41:31.491199  7768 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0530 07:41:31.491211  7768 net.cpp:157] Top shape: 100 (100)
I0530 07:41:31.491220  7768 net.cpp:165] Memory required for data: 7620400
I0530 07:41:31.491235  7768 layer_factory.hpp:77] Creating layer segments_data_3_split
I0530 07:41:31.491261  7768 net.cpp:106] Creating Layer segments_data_3_split
I0530 07:41:31.491272  7768 net.cpp:454] segments_data_3_split <- segments
I0530 07:41:31.491286  7768 net.cpp:411] segments_data_3_split -> segments_data_3_split_0
I0530 07:41:31.491308  7768 net.cpp:411] segments_data_3_split -> segments_data_3_split_1
I0530 07:41:31.491385  7768 net.cpp:150] Setting up segments_data_3_split
I0530 07:41:31.491400  7768 net.cpp:157] Top shape: 100 (100)
I0530 07:41:31.491410  7768 net.cpp:157] Top shape: 100 (100)
I0530 07:41:31.491420  7768 net.cpp:165] Memory required for data: 7621200
I0530 07:41:31.491430  7768 layer_factory.hpp:77] Creating layer conv_x1
I0530 07:41:31.491454  7768 net.cpp:106] Creating Layer conv_x1
I0530 07:41:31.491466  7768 net.cpp:454] conv_x1 <- hits-x
I0530 07:41:31.491479  7768 net.cpp:411] conv_x1 -> conv_x1
I0530 07:41:31.493691  7768 net.cpp:150] Setting up conv_x1
I0530 07:41:31.493715  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:41:31.493727  7768 net.cpp:165] Memory required for data: 35269200
I0530 07:41:31.493747  7768 layer_factory.hpp:77] Creating layer relu_x1
I0530 07:41:31.493762  7768 net.cpp:106] Creating Layer relu_x1
I0530 07:41:31.493772  7768 net.cpp:454] relu_x1 <- conv_x1
I0530 07:41:31.493784  7768 net.cpp:397] relu_x1 -> conv_x1 (in-place)
I0530 07:41:31.494297  7768 net.cpp:150] Setting up relu_x1
I0530 07:41:31.494313  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:41:31.494323  7768 net.cpp:165] Memory required for data: 62917200
I0530 07:41:31.494333  7768 layer_factory.hpp:77] Creating layer pool_x1
I0530 07:41:31.494349  7768 net.cpp:106] Creating Layer pool_x1
I0530 07:41:31.494359  7768 net.cpp:454] pool_x1 <- conv_x1
I0530 07:41:31.494372  7768 net.cpp:411] pool_x1 -> pool_x1
I0530 07:41:31.494454  7768 net.cpp:150] Setting up pool_x1
I0530 07:41:31.494468  7768 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 07:41:31.494478  7768 net.cpp:165] Memory required for data: 76741200
I0530 07:41:31.494488  7768 layer_factory.hpp:77] Creating layer conv_x2
I0530 07:41:31.494506  7768 net.cpp:106] Creating Layer conv_x2
I0530 07:41:31.494516  7768 net.cpp:454] conv_x2 <- pool_x1
I0530 07:41:31.494531  7768 net.cpp:411] conv_x2 -> conv_x2
I0530 07:41:31.496433  7768 net.cpp:150] Setting up conv_x2
I0530 07:41:31.496456  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:41:31.496466  7768 net.cpp:165] Memory required for data: 96613200
I0530 07:41:31.496485  7768 layer_factory.hpp:77] Creating layer relu_x2
I0530 07:41:31.496500  7768 net.cpp:106] Creating Layer relu_x2
I0530 07:41:31.496510  7768 net.cpp:454] relu_x2 <- conv_x2
I0530 07:41:31.496523  7768 net.cpp:397] relu_x2 -> conv_x2 (in-place)
I0530 07:41:31.497035  7768 net.cpp:150] Setting up relu_x2
I0530 07:41:31.497051  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:41:31.497061  7768 net.cpp:165] Memory required for data: 116485200
I0530 07:41:31.497072  7768 layer_factory.hpp:77] Creating layer pool_x2
I0530 07:41:31.497086  7768 net.cpp:106] Creating Layer pool_x2
I0530 07:41:31.497095  7768 net.cpp:454] pool_x2 <- conv_x2
I0530 07:41:31.497109  7768 net.cpp:411] pool_x2 -> pool_x2
I0530 07:41:31.497267  7768 net.cpp:150] Setting up pool_x2
I0530 07:41:31.497282  7768 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 07:41:31.497292  7768 net.cpp:165] Memory required for data: 126421200
I0530 07:41:31.497301  7768 layer_factory.hpp:77] Creating layer conv_x3
I0530 07:41:31.497321  7768 net.cpp:106] Creating Layer conv_x3
I0530 07:41:31.497331  7768 net.cpp:454] conv_x3 <- pool_x2
I0530 07:41:31.497346  7768 net.cpp:411] conv_x3 -> conv_x3
I0530 07:41:31.499626  7768 net.cpp:150] Setting up conv_x3
I0530 07:41:31.499650  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:41:31.499661  7768 net.cpp:165] Memory required for data: 137262800
I0530 07:41:31.499681  7768 layer_factory.hpp:77] Creating layer relu_x3
I0530 07:41:31.499696  7768 net.cpp:106] Creating Layer relu_x3
I0530 07:41:31.499706  7768 net.cpp:454] relu_x3 <- conv_x3
I0530 07:41:31.499719  7768 net.cpp:397] relu_x3 -> conv_x3 (in-place)
I0530 07:41:31.500066  7768 net.cpp:150] Setting up relu_x3
I0530 07:41:31.500080  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:41:31.500090  7768 net.cpp:165] Memory required for data: 148104400
I0530 07:41:31.500100  7768 layer_factory.hpp:77] Creating layer pool_x3
I0530 07:41:31.500114  7768 net.cpp:106] Creating Layer pool_x3
I0530 07:41:31.500124  7768 net.cpp:454] pool_x3 <- conv_x3
I0530 07:41:31.500138  7768 net.cpp:411] pool_x3 -> pool_x3
I0530 07:41:31.500216  7768 net.cpp:150] Setting up pool_x3
I0530 07:41:31.500229  7768 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 07:41:31.500239  7768 net.cpp:165] Memory required for data: 153525200
I0530 07:41:31.500250  7768 layer_factory.hpp:77] Creating layer conv_x4
I0530 07:41:31.500268  7768 net.cpp:106] Creating Layer conv_x4
I0530 07:41:31.500278  7768 net.cpp:454] conv_x4 <- pool_x3
I0530 07:41:31.500293  7768 net.cpp:411] conv_x4 -> conv_x4
I0530 07:41:31.502471  7768 net.cpp:150] Setting up conv_x4
I0530 07:41:31.502495  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:41:31.502506  7768 net.cpp:165] Memory required for data: 157154000
I0530 07:41:31.502522  7768 layer_factory.hpp:77] Creating layer relu_x4
I0530 07:41:31.502535  7768 net.cpp:106] Creating Layer relu_x4
I0530 07:41:31.502545  7768 net.cpp:454] relu_x4 <- conv_x4
I0530 07:41:31.502558  7768 net.cpp:397] relu_x4 -> conv_x4 (in-place)
I0530 07:41:31.503059  7768 net.cpp:150] Setting up relu_x4
I0530 07:41:31.503075  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:41:31.503087  7768 net.cpp:165] Memory required for data: 160782800
I0530 07:41:31.503096  7768 layer_factory.hpp:77] Creating layer pool_x4
I0530 07:41:31.503110  7768 net.cpp:106] Creating Layer pool_x4
I0530 07:41:31.503119  7768 net.cpp:454] pool_x4 <- conv_x4
I0530 07:41:31.503134  7768 net.cpp:411] pool_x4 -> pool_x4
I0530 07:41:31.503212  7768 net.cpp:150] Setting up pool_x4
I0530 07:41:31.503226  7768 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 07:41:31.503235  7768 net.cpp:165] Memory required for data: 162597200
I0530 07:41:31.503245  7768 layer_factory.hpp:77] Creating layer dl_x1
I0530 07:41:31.503260  7768 net.cpp:106] Creating Layer dl_x1
I0530 07:41:31.503271  7768 net.cpp:454] dl_x1 <- pool_x4
I0530 07:41:31.503285  7768 net.cpp:411] dl_x1 -> dl_x1
I0530 07:41:31.519356  7768 net.cpp:150] Setting up dl_x1
I0530 07:41:31.519382  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.519398  7768 net.cpp:165] Memory required for data: 162675600
I0530 07:41:31.519421  7768 layer_factory.hpp:77] Creating layer relu_x5
I0530 07:41:31.519436  7768 net.cpp:106] Creating Layer relu_x5
I0530 07:41:31.519448  7768 net.cpp:454] relu_x5 <- dl_x1
I0530 07:41:31.519459  7768 net.cpp:397] relu_x5 -> dl_x1 (in-place)
I0530 07:41:31.519820  7768 net.cpp:150] Setting up relu_x5
I0530 07:41:31.519834  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.519843  7768 net.cpp:165] Memory required for data: 162754000
I0530 07:41:31.519853  7768 layer_factory.hpp:77] Creating layer drop_x1
I0530 07:41:31.519872  7768 net.cpp:106] Creating Layer drop_x1
I0530 07:41:31.519882  7768 net.cpp:454] drop_x1 <- dl_x1
I0530 07:41:31.519896  7768 net.cpp:397] drop_x1 -> dl_x1 (in-place)
I0530 07:41:31.519944  7768 net.cpp:150] Setting up drop_x1
I0530 07:41:31.519958  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.519968  7768 net.cpp:165] Memory required for data: 162832400
I0530 07:41:31.519978  7768 layer_factory.hpp:77] Creating layer conv_u1
I0530 07:41:31.519996  7768 net.cpp:106] Creating Layer conv_u1
I0530 07:41:31.520020  7768 net.cpp:454] conv_u1 <- hits-u
I0530 07:41:31.520035  7768 net.cpp:411] conv_u1 -> conv_u1
I0530 07:41:31.522034  7768 net.cpp:150] Setting up conv_u1
I0530 07:41:31.522058  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:41:31.522070  7768 net.cpp:165] Memory required for data: 190480400
I0530 07:41:31.522085  7768 layer_factory.hpp:77] Creating layer relu_u1
I0530 07:41:31.522099  7768 net.cpp:106] Creating Layer relu_u1
I0530 07:41:31.522109  7768 net.cpp:454] relu_u1 <- conv_u1
I0530 07:41:31.522122  7768 net.cpp:397] relu_u1 -> conv_u1 (in-place)
I0530 07:41:31.522454  7768 net.cpp:150] Setting up relu_u1
I0530 07:41:31.522467  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:41:31.522477  7768 net.cpp:165] Memory required for data: 218128400
I0530 07:41:31.522487  7768 layer_factory.hpp:77] Creating layer pool_u1
I0530 07:41:31.522501  7768 net.cpp:106] Creating Layer pool_u1
I0530 07:41:31.522511  7768 net.cpp:454] pool_u1 <- conv_u1
I0530 07:41:31.522523  7768 net.cpp:411] pool_u1 -> pool_u1
I0530 07:41:31.522621  7768 net.cpp:150] Setting up pool_u1
I0530 07:41:31.522635  7768 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 07:41:31.522645  7768 net.cpp:165] Memory required for data: 231952400
I0530 07:41:31.522655  7768 layer_factory.hpp:77] Creating layer conv_u2
I0530 07:41:31.522673  7768 net.cpp:106] Creating Layer conv_u2
I0530 07:41:31.522683  7768 net.cpp:454] conv_u2 <- pool_u1
I0530 07:41:31.522698  7768 net.cpp:411] conv_u2 -> conv_u2
I0530 07:41:31.524657  7768 net.cpp:150] Setting up conv_u2
I0530 07:41:31.524673  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:41:31.524684  7768 net.cpp:165] Memory required for data: 251824400
I0530 07:41:31.524700  7768 layer_factory.hpp:77] Creating layer relu_u2
I0530 07:41:31.524713  7768 net.cpp:106] Creating Layer relu_u2
I0530 07:41:31.524724  7768 net.cpp:454] relu_u2 <- conv_u2
I0530 07:41:31.524736  7768 net.cpp:397] relu_u2 -> conv_u2 (in-place)
I0530 07:41:31.525238  7768 net.cpp:150] Setting up relu_u2
I0530 07:41:31.525254  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:41:31.525264  7768 net.cpp:165] Memory required for data: 271696400
I0530 07:41:31.525274  7768 layer_factory.hpp:77] Creating layer pool_u2
I0530 07:41:31.525288  7768 net.cpp:106] Creating Layer pool_u2
I0530 07:41:31.525298  7768 net.cpp:454] pool_u2 <- conv_u2
I0530 07:41:31.525311  7768 net.cpp:411] pool_u2 -> pool_u2
I0530 07:41:31.525390  7768 net.cpp:150] Setting up pool_u2
I0530 07:41:31.525403  7768 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 07:41:31.525413  7768 net.cpp:165] Memory required for data: 281632400
I0530 07:41:31.525424  7768 layer_factory.hpp:77] Creating layer conv_u3
I0530 07:41:31.525440  7768 net.cpp:106] Creating Layer conv_u3
I0530 07:41:31.525451  7768 net.cpp:454] conv_u3 <- pool_u2
I0530 07:41:31.525465  7768 net.cpp:411] conv_u3 -> conv_u3
I0530 07:41:31.527514  7768 net.cpp:150] Setting up conv_u3
I0530 07:41:31.527536  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:41:31.527549  7768 net.cpp:165] Memory required for data: 292474000
I0530 07:41:31.527565  7768 layer_factory.hpp:77] Creating layer relu_u3
I0530 07:41:31.527578  7768 net.cpp:106] Creating Layer relu_u3
I0530 07:41:31.527588  7768 net.cpp:454] relu_u3 <- conv_u3
I0530 07:41:31.527601  7768 net.cpp:397] relu_u3 -> conv_u3 (in-place)
I0530 07:41:31.527930  7768 net.cpp:150] Setting up relu_u3
I0530 07:41:31.527945  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:41:31.527954  7768 net.cpp:165] Memory required for data: 303315600
I0530 07:41:31.527964  7768 layer_factory.hpp:77] Creating layer pool_u3
I0530 07:41:31.527977  7768 net.cpp:106] Creating Layer pool_u3
I0530 07:41:31.527987  7768 net.cpp:454] pool_u3 <- conv_u3
I0530 07:41:31.528002  7768 net.cpp:411] pool_u3 -> pool_u3
I0530 07:41:31.528079  7768 net.cpp:150] Setting up pool_u3
I0530 07:41:31.528092  7768 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 07:41:31.528103  7768 net.cpp:165] Memory required for data: 308736400
I0530 07:41:31.528127  7768 layer_factory.hpp:77] Creating layer conv_u4
I0530 07:41:31.528147  7768 net.cpp:106] Creating Layer conv_u4
I0530 07:41:31.528159  7768 net.cpp:454] conv_u4 <- pool_u3
I0530 07:41:31.528173  7768 net.cpp:411] conv_u4 -> conv_u4
I0530 07:41:31.530381  7768 net.cpp:150] Setting up conv_u4
I0530 07:41:31.530405  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:41:31.530416  7768 net.cpp:165] Memory required for data: 312365200
I0530 07:41:31.530439  7768 layer_factory.hpp:77] Creating layer relu_u4
I0530 07:41:31.530453  7768 net.cpp:106] Creating Layer relu_u4
I0530 07:41:31.530463  7768 net.cpp:454] relu_u4 <- conv_u4
I0530 07:41:31.530477  7768 net.cpp:397] relu_u4 -> conv_u4 (in-place)
I0530 07:41:31.530817  7768 net.cpp:150] Setting up relu_u4
I0530 07:41:31.530830  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:41:31.530840  7768 net.cpp:165] Memory required for data: 315994000
I0530 07:41:31.530849  7768 layer_factory.hpp:77] Creating layer pool_u4
I0530 07:41:31.530864  7768 net.cpp:106] Creating Layer pool_u4
I0530 07:41:31.530872  7768 net.cpp:454] pool_u4 <- conv_u4
I0530 07:41:31.530886  7768 net.cpp:411] pool_u4 -> pool_u4
I0530 07:41:31.530963  7768 net.cpp:150] Setting up pool_u4
I0530 07:41:31.530977  7768 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 07:41:31.530987  7768 net.cpp:165] Memory required for data: 317808400
I0530 07:41:31.530997  7768 layer_factory.hpp:77] Creating layer dl_u1
I0530 07:41:31.531010  7768 net.cpp:106] Creating Layer dl_u1
I0530 07:41:31.531021  7768 net.cpp:454] dl_u1 <- pool_u4
I0530 07:41:31.531035  7768 net.cpp:411] dl_u1 -> dl_u1
I0530 07:41:31.547443  7768 net.cpp:150] Setting up dl_u1
I0530 07:41:31.547472  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.547484  7768 net.cpp:165] Memory required for data: 317886800
I0530 07:41:31.547502  7768 layer_factory.hpp:77] Creating layer relu_u5
I0530 07:41:31.547516  7768 net.cpp:106] Creating Layer relu_u5
I0530 07:41:31.547528  7768 net.cpp:454] relu_u5 <- dl_u1
I0530 07:41:31.547541  7768 net.cpp:397] relu_u5 -> dl_u1 (in-place)
I0530 07:41:31.548131  7768 net.cpp:150] Setting up relu_u5
I0530 07:41:31.548153  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.548166  7768 net.cpp:165] Memory required for data: 317965200
I0530 07:41:31.548177  7768 layer_factory.hpp:77] Creating layer drop_u1
I0530 07:41:31.548190  7768 net.cpp:106] Creating Layer drop_u1
I0530 07:41:31.548200  7768 net.cpp:454] drop_u1 <- dl_u1
I0530 07:41:31.548214  7768 net.cpp:397] drop_u1 -> dl_u1 (in-place)
I0530 07:41:31.548262  7768 net.cpp:150] Setting up drop_u1
I0530 07:41:31.548276  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.548287  7768 net.cpp:165] Memory required for data: 318043600
I0530 07:41:31.548296  7768 layer_factory.hpp:77] Creating layer conv_v1
I0530 07:41:31.548326  7768 net.cpp:106] Creating Layer conv_v1
I0530 07:41:31.548336  7768 net.cpp:454] conv_v1 <- hits-v
I0530 07:41:31.548352  7768 net.cpp:411] conv_v1 -> conv_v1
I0530 07:41:31.550312  7768 net.cpp:150] Setting up conv_v1
I0530 07:41:31.550333  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:41:31.550345  7768 net.cpp:165] Memory required for data: 345691600
I0530 07:41:31.550361  7768 layer_factory.hpp:77] Creating layer relu_v1
I0530 07:41:31.550375  7768 net.cpp:106] Creating Layer relu_v1
I0530 07:41:31.550385  7768 net.cpp:454] relu_v1 <- conv_v1
I0530 07:41:31.550398  7768 net.cpp:397] relu_v1 -> conv_v1 (in-place)
I0530 07:41:31.550740  7768 net.cpp:150] Setting up relu_v1
I0530 07:41:31.550753  7768 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0530 07:41:31.550763  7768 net.cpp:165] Memory required for data: 373339600
I0530 07:41:31.550775  7768 layer_factory.hpp:77] Creating layer pool_v1
I0530 07:41:31.550788  7768 net.cpp:106] Creating Layer pool_v1
I0530 07:41:31.550797  7768 net.cpp:454] pool_v1 <- conv_v1
I0530 07:41:31.550812  7768 net.cpp:411] pool_v1 -> pool_v1
I0530 07:41:31.550892  7768 net.cpp:150] Setting up pool_v1
I0530 07:41:31.550920  7768 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0530 07:41:31.550930  7768 net.cpp:165] Memory required for data: 387163600
I0530 07:41:31.550940  7768 layer_factory.hpp:77] Creating layer conv_v2
I0530 07:41:31.550958  7768 net.cpp:106] Creating Layer conv_v2
I0530 07:41:31.550968  7768 net.cpp:454] conv_v2 <- pool_v1
I0530 07:41:31.550983  7768 net.cpp:411] conv_v2 -> conv_v2
I0530 07:41:31.553031  7768 net.cpp:150] Setting up conv_v2
I0530 07:41:31.553055  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:41:31.553066  7768 net.cpp:165] Memory required for data: 407035600
I0530 07:41:31.553081  7768 layer_factory.hpp:77] Creating layer relu_v2
I0530 07:41:31.553094  7768 net.cpp:106] Creating Layer relu_v2
I0530 07:41:31.553105  7768 net.cpp:454] relu_v2 <- conv_v2
I0530 07:41:31.553118  7768 net.cpp:397] relu_v2 -> conv_v2 (in-place)
I0530 07:41:31.553622  7768 net.cpp:150] Setting up relu_v2
I0530 07:41:31.553638  7768 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0530 07:41:31.553648  7768 net.cpp:165] Memory required for data: 426907600
I0530 07:41:31.553659  7768 layer_factory.hpp:77] Creating layer pool_v2
I0530 07:41:31.553673  7768 net.cpp:106] Creating Layer pool_v2
I0530 07:41:31.553683  7768 net.cpp:454] pool_v2 <- conv_v2
I0530 07:41:31.553695  7768 net.cpp:411] pool_v2 -> pool_v2
I0530 07:41:31.553776  7768 net.cpp:150] Setting up pool_v2
I0530 07:41:31.553788  7768 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0530 07:41:31.553799  7768 net.cpp:165] Memory required for data: 436843600
I0530 07:41:31.553809  7768 layer_factory.hpp:77] Creating layer conv_v3
I0530 07:41:31.553828  7768 net.cpp:106] Creating Layer conv_v3
I0530 07:41:31.553838  7768 net.cpp:454] conv_v3 <- pool_v2
I0530 07:41:31.553853  7768 net.cpp:411] conv_v3 -> conv_v3
I0530 07:41:31.555960  7768 net.cpp:150] Setting up conv_v3
I0530 07:41:31.555982  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:41:31.555995  7768 net.cpp:165] Memory required for data: 447685200
I0530 07:41:31.556010  7768 layer_factory.hpp:77] Creating layer relu_v3
I0530 07:41:31.556025  7768 net.cpp:106] Creating Layer relu_v3
I0530 07:41:31.556035  7768 net.cpp:454] relu_v3 <- conv_v3
I0530 07:41:31.556047  7768 net.cpp:397] relu_v3 -> conv_v3 (in-place)
I0530 07:41:31.556565  7768 net.cpp:150] Setting up relu_v3
I0530 07:41:31.556581  7768 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0530 07:41:31.556592  7768 net.cpp:165] Memory required for data: 458526800
I0530 07:41:31.556602  7768 layer_factory.hpp:77] Creating layer pool_v3
I0530 07:41:31.556617  7768 net.cpp:106] Creating Layer pool_v3
I0530 07:41:31.556627  7768 net.cpp:454] pool_v3 <- conv_v3
I0530 07:41:31.556640  7768 net.cpp:411] pool_v3 -> pool_v3
I0530 07:41:31.556720  7768 net.cpp:150] Setting up pool_v3
I0530 07:41:31.556733  7768 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0530 07:41:31.556742  7768 net.cpp:165] Memory required for data: 463947600
I0530 07:41:31.556753  7768 layer_factory.hpp:77] Creating layer conv_v4
I0530 07:41:31.556771  7768 net.cpp:106] Creating Layer conv_v4
I0530 07:41:31.556782  7768 net.cpp:454] conv_v4 <- pool_v3
I0530 07:41:31.556797  7768 net.cpp:411] conv_v4 -> conv_v4
I0530 07:41:31.559015  7768 net.cpp:150] Setting up conv_v4
I0530 07:41:31.559037  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:41:31.559049  7768 net.cpp:165] Memory required for data: 467576400
I0530 07:41:31.559065  7768 layer_factory.hpp:77] Creating layer relu_v4
I0530 07:41:31.559079  7768 net.cpp:106] Creating Layer relu_v4
I0530 07:41:31.559089  7768 net.cpp:454] relu_v4 <- conv_v4
I0530 07:41:31.559103  7768 net.cpp:397] relu_v4 -> conv_v4 (in-place)
I0530 07:41:31.559433  7768 net.cpp:150] Setting up relu_v4
I0530 07:41:31.559448  7768 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0530 07:41:31.559458  7768 net.cpp:165] Memory required for data: 471205200
I0530 07:41:31.559468  7768 layer_factory.hpp:77] Creating layer pool_v4
I0530 07:41:31.559481  7768 net.cpp:106] Creating Layer pool_v4
I0530 07:41:31.559502  7768 net.cpp:454] pool_v4 <- conv_v4
I0530 07:41:31.559516  7768 net.cpp:411] pool_v4 -> pool_v4
I0530 07:41:31.559595  7768 net.cpp:150] Setting up pool_v4
I0530 07:41:31.559608  7768 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0530 07:41:31.559618  7768 net.cpp:165] Memory required for data: 473019600
I0530 07:41:31.559628  7768 layer_factory.hpp:77] Creating layer dl_v1
I0530 07:41:31.559644  7768 net.cpp:106] Creating Layer dl_v1
I0530 07:41:31.559655  7768 net.cpp:454] dl_v1 <- pool_v4
I0530 07:41:31.559669  7768 net.cpp:411] dl_v1 -> dl_v1
I0530 07:41:31.576072  7768 net.cpp:150] Setting up dl_v1
I0530 07:41:31.576100  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.576114  7768 net.cpp:165] Memory required for data: 473098000
I0530 07:41:31.576134  7768 layer_factory.hpp:77] Creating layer relu_v5
I0530 07:41:31.576151  7768 net.cpp:106] Creating Layer relu_v5
I0530 07:41:31.576162  7768 net.cpp:454] relu_v5 <- dl_v1
I0530 07:41:31.576175  7768 net.cpp:397] relu_v5 -> dl_v1 (in-place)
I0530 07:41:31.576782  7768 net.cpp:150] Setting up relu_v5
I0530 07:41:31.576800  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.576807  7768 net.cpp:165] Memory required for data: 473176400
I0530 07:41:31.576820  7768 layer_factory.hpp:77] Creating layer drop_v1
I0530 07:41:31.576833  7768 net.cpp:106] Creating Layer drop_v1
I0530 07:41:31.576844  7768 net.cpp:454] drop_v1 <- dl_v1
I0530 07:41:31.576858  7768 net.cpp:397] drop_v1 -> dl_v1 (in-place)
I0530 07:41:31.576907  7768 net.cpp:150] Setting up drop_v1
I0530 07:41:31.576920  7768 net.cpp:157] Top shape: 100 196 (19600)
I0530 07:41:31.576930  7768 net.cpp:165] Memory required for data: 473254800
I0530 07:41:31.576941  7768 layer_factory.hpp:77] Creating layer concat_xuv
I0530 07:41:31.576953  7768 net.cpp:106] Creating Layer concat_xuv
I0530 07:41:31.576964  7768 net.cpp:454] concat_xuv <- dl_x1
I0530 07:41:31.576977  7768 net.cpp:454] concat_xuv <- dl_u1
I0530 07:41:31.576987  7768 net.cpp:454] concat_xuv <- dl_v1
I0530 07:41:31.577002  7768 net.cpp:411] concat_xuv -> concat_xuv
I0530 07:41:31.577051  7768 net.cpp:150] Setting up concat_xuv
I0530 07:41:31.577064  7768 net.cpp:157] Top shape: 100 588 (58800)
I0530 07:41:31.577074  7768 net.cpp:165] Memory required for data: 473490000
I0530 07:41:31.577083  7768 layer_factory.hpp:77] Creating layer dl_xuv
I0530 07:41:31.577097  7768 net.cpp:106] Creating Layer dl_xuv
I0530 07:41:31.577108  7768 net.cpp:454] dl_xuv <- concat_xuv
I0530 07:41:31.577123  7768 net.cpp:411] dl_xuv -> dl_xuv
I0530 07:41:31.578168  7768 net.cpp:150] Setting up dl_xuv
I0530 07:41:31.578187  7768 net.cpp:157] Top shape: 100 98 (9800)
I0530 07:41:31.578200  7768 net.cpp:165] Memory required for data: 473529200
I0530 07:41:31.578215  7768 layer_factory.hpp:77] Creating layer relu_xuv
I0530 07:41:31.578229  7768 net.cpp:106] Creating Layer relu_xuv
I0530 07:41:31.578239  7768 net.cpp:454] relu_xuv <- dl_xuv
I0530 07:41:31.578251  7768 net.cpp:397] relu_xuv -> dl_xuv (in-place)
I0530 07:41:31.578582  7768 net.cpp:150] Setting up relu_xuv
I0530 07:41:31.578595  7768 net.cpp:157] Top shape: 100 98 (9800)
I0530 07:41:31.578613  7768 net.cpp:165] Memory required for data: 473568400
I0530 07:41:31.578621  7768 layer_factory.hpp:77] Creating layer drop_xuv
I0530 07:41:31.578634  7768 net.cpp:106] Creating Layer drop_xuv
I0530 07:41:31.578645  7768 net.cpp:454] drop_xuv <- dl_xuv
I0530 07:41:31.578658  7768 net.cpp:397] drop_xuv -> dl_xuv (in-place)
I0530 07:41:31.578706  7768 net.cpp:150] Setting up drop_xuv
I0530 07:41:31.578719  7768 net.cpp:157] Top shape: 100 98 (9800)
I0530 07:41:31.578728  7768 net.cpp:165] Memory required for data: 473607600
I0530 07:41:31.578738  7768 layer_factory.hpp:77] Creating layer output
I0530 07:41:31.578752  7768 net.cpp:106] Creating Layer output
I0530 07:41:31.578763  7768 net.cpp:454] output <- dl_xuv
I0530 07:41:31.578778  7768 net.cpp:411] output -> output
I0530 07:41:31.579025  7768 net.cpp:150] Setting up output
I0530 07:41:31.579037  7768 net.cpp:157] Top shape: 100 11 (1100)
I0530 07:41:31.579061  7768 net.cpp:165] Memory required for data: 473612000
I0530 07:41:31.579092  7768 layer_factory.hpp:77] Creating layer drop_output
I0530 07:41:31.579107  7768 net.cpp:106] Creating Layer drop_output
I0530 07:41:31.579118  7768 net.cpp:454] drop_output <- output
I0530 07:41:31.579130  7768 net.cpp:397] drop_output -> output (in-place)
I0530 07:41:31.579176  7768 net.cpp:150] Setting up drop_output
I0530 07:41:31.579188  7768 net.cpp:157] Top shape: 100 11 (1100)
I0530 07:41:31.579198  7768 net.cpp:165] Memory required for data: 473616400
I0530 07:41:31.579208  7768 layer_factory.hpp:77] Creating layer output_drop_output_0_split
I0530 07:41:31.579221  7768 net.cpp:106] Creating Layer output_drop_output_0_split
I0530 07:41:31.579231  7768 net.cpp:454] output_drop_output_0_split <- output
I0530 07:41:31.579244  7768 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_0
I0530 07:41:31.579260  7768 net.cpp:411] output_drop_output_0_split -> output_drop_output_0_split_1
I0530 07:41:31.579335  7768 net.cpp:150] Setting up output_drop_output_0_split
I0530 07:41:31.579349  7768 net.cpp:157] Top shape: 100 11 (1100)
I0530 07:41:31.579361  7768 net.cpp:157] Top shape: 100 11 (1100)
I0530 07:41:31.579370  7768 net.cpp:165] Memory required for data: 473625200
I0530 07:41:31.579381  7768 layer_factory.hpp:77] Creating layer accuracy
I0530 07:41:31.579403  7768 net.cpp:106] Creating Layer accuracy
I0530 07:41:31.579412  7768 net.cpp:454] accuracy <- output_drop_output_0_split_0
I0530 07:41:31.579424  7768 net.cpp:454] accuracy <- segments_data_3_split_0
I0530 07:41:31.579437  7768 net.cpp:411] accuracy -> accuracy
I0530 07:41:31.579462  7768 net.cpp:150] Setting up accuracy
I0530 07:41:31.579474  7768 net.cpp:157] Top shape: (1)
I0530 07:41:31.579483  7768 net.cpp:165] Memory required for data: 473625204
I0530 07:41:31.579493  7768 layer_factory.hpp:77] Creating layer loss
I0530 07:41:31.579507  7768 net.cpp:106] Creating Layer loss
I0530 07:41:31.579517  7768 net.cpp:454] loss <- output_drop_output_0_split_1
I0530 07:41:31.579529  7768 net.cpp:454] loss <- segments_data_3_split_1
I0530 07:41:31.579542  7768 net.cpp:411] loss -> loss
I0530 07:41:31.579561  7768 layer_factory.hpp:77] Creating layer loss
I0530 07:41:31.580282  7768 net.cpp:150] Setting up loss
I0530 07:41:31.580303  7768 net.cpp:157] Top shape: (1)
I0530 07:41:31.580313  7768 net.cpp:160]     with loss weight 1
I0530 07:41:31.580332  7768 net.cpp:165] Memory required for data: 473625208
I0530 07:41:31.580343  7768 net.cpp:226] loss needs backward computation.
I0530 07:41:31.580353  7768 net.cpp:228] accuracy does not need backward computation.
I0530 07:41:31.580365  7768 net.cpp:226] output_drop_output_0_split needs backward computation.
I0530 07:41:31.580375  7768 net.cpp:226] drop_output needs backward computation.
I0530 07:41:31.580384  7768 net.cpp:226] output needs backward computation.
I0530 07:41:31.580394  7768 net.cpp:226] drop_xuv needs backward computation.
I0530 07:41:31.580405  7768 net.cpp:226] relu_xuv needs backward computation.
I0530 07:41:31.580415  7768 net.cpp:226] dl_xuv needs backward computation.
I0530 07:41:31.580425  7768 net.cpp:226] concat_xuv needs backward computation.
I0530 07:41:31.580436  7768 net.cpp:226] drop_v1 needs backward computation.
I0530 07:41:31.580446  7768 net.cpp:226] relu_v5 needs backward computation.
I0530 07:41:31.580456  7768 net.cpp:226] dl_v1 needs backward computation.
I0530 07:41:31.580467  7768 net.cpp:226] pool_v4 needs backward computation.
I0530 07:41:31.580477  7768 net.cpp:226] relu_v4 needs backward computation.
I0530 07:41:31.580488  7768 net.cpp:226] conv_v4 needs backward computation.
I0530 07:41:31.580500  7768 net.cpp:226] pool_v3 needs backward computation.
I0530 07:41:31.580512  7768 net.cpp:226] relu_v3 needs backward computation.
I0530 07:41:31.580523  7768 net.cpp:226] conv_v3 needs backward computation.
I0530 07:41:31.580533  7768 net.cpp:226] pool_v2 needs backward computation.
I0530 07:41:31.580543  7768 net.cpp:226] relu_v2 needs backward computation.
I0530 07:41:31.580562  7768 net.cpp:226] conv_v2 needs backward computation.
I0530 07:41:31.580572  7768 net.cpp:226] pool_v1 needs backward computation.
I0530 07:41:31.580584  7768 net.cpp:226] relu_v1 needs backward computation.
I0530 07:41:31.580593  7768 net.cpp:226] conv_v1 needs backward computation.
I0530 07:41:31.580605  7768 net.cpp:226] drop_u1 needs backward computation.
I0530 07:41:31.580615  7768 net.cpp:226] relu_u5 needs backward computation.
I0530 07:41:31.580622  7768 net.cpp:226] dl_u1 needs backward computation.
I0530 07:41:31.580634  7768 net.cpp:226] pool_u4 needs backward computation.
I0530 07:41:31.580644  7768 net.cpp:226] relu_u4 needs backward computation.
I0530 07:41:31.580657  7768 net.cpp:226] conv_u4 needs backward computation.
I0530 07:41:31.580667  7768 net.cpp:226] pool_u3 needs backward computation.
I0530 07:41:31.580678  7768 net.cpp:226] relu_u3 needs backward computation.
I0530 07:41:31.580688  7768 net.cpp:226] conv_u3 needs backward computation.
I0530 07:41:31.580698  7768 net.cpp:226] pool_u2 needs backward computation.
I0530 07:41:31.580709  7768 net.cpp:226] relu_u2 needs backward computation.
I0530 07:41:31.580719  7768 net.cpp:226] conv_u2 needs backward computation.
I0530 07:41:31.580730  7768 net.cpp:226] pool_u1 needs backward computation.
I0530 07:41:31.580741  7768 net.cpp:226] relu_u1 needs backward computation.
I0530 07:41:31.580751  7768 net.cpp:226] conv_u1 needs backward computation.
I0530 07:41:31.580761  7768 net.cpp:226] drop_x1 needs backward computation.
I0530 07:41:31.580771  7768 net.cpp:226] relu_x5 needs backward computation.
I0530 07:41:31.580781  7768 net.cpp:226] dl_x1 needs backward computation.
I0530 07:41:31.580792  7768 net.cpp:226] pool_x4 needs backward computation.
I0530 07:41:31.580802  7768 net.cpp:226] relu_x4 needs backward computation.
I0530 07:41:31.580812  7768 net.cpp:226] conv_x4 needs backward computation.
I0530 07:41:31.580823  7768 net.cpp:226] pool_x3 needs backward computation.
I0530 07:41:31.580833  7768 net.cpp:226] relu_x3 needs backward computation.
I0530 07:41:31.580844  7768 net.cpp:226] conv_x3 needs backward computation.
I0530 07:41:31.580855  7768 net.cpp:226] pool_x2 needs backward computation.
I0530 07:41:31.580865  7768 net.cpp:226] relu_x2 needs backward computation.
I0530 07:41:31.580876  7768 net.cpp:226] conv_x2 needs backward computation.
I0530 07:41:31.580885  7768 net.cpp:226] pool_x1 needs backward computation.
I0530 07:41:31.580896  7768 net.cpp:226] relu_x1 needs backward computation.
I0530 07:41:31.580906  7768 net.cpp:226] conv_x1 needs backward computation.
I0530 07:41:31.580919  7768 net.cpp:228] segments_data_3_split does not need backward computation.
I0530 07:41:31.580931  7768 net.cpp:228] data does not need backward computation.
I0530 07:41:31.580941  7768 net.cpp:270] This network produces output accuracy
I0530 07:41:31.580951  7768 net.cpp:270] This network produces output loss
I0530 07:41:31.581009  7768 net.cpp:283] Network initialization done.
I0530 07:41:31.581295  7768 solver.cpp:60] Solver scaffolding done.
I0530 07:41:31.584455  7768 caffe.cpp:212] Starting Optimization
I0530 07:41:31.584475  7768 solver.cpp:288] Solving epsilon_127x50_xuv
I0530 07:41:31.584483  7768 solver.cpp:289] Learning Rate Policy: inv
I0530 07:41:31.586804  7768 solver.cpp:341] Iteration 0, Testing net (#0)
I0530 07:43:49.239887  7768 solver.cpp:409]     Test net output #0: accuracy = 0.102193
I0530 07:43:49.240066  7768 solver.cpp:409]     Test net output #1: loss = 2.3982 (* 1 = 2.3982 loss)
I0530 07:43:49.311094  7768 solver.cpp:237] Iteration 0, loss = 2.4015
I0530 07:43:49.311132  7768 solver.cpp:253]     Train net output #0: loss = 2.4015 (* 1 = 2.4015 loss)
I0530 07:43:49.311164  7768 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0530 08:02:29.611274  7768 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_5000.caffemodel
I0530 08:02:29.892524  7768 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_5000.solverstate
I0530 08:02:29.973809  7768 solver.cpp:341] Iteration 5000, Testing net (#0)
I0530 08:04:44.860687  7768 solver.cpp:409]     Test net output #0: accuracy = 0.730086
I0530 08:04:44.860852  7768 solver.cpp:409]     Test net output #1: loss = 0.959807 (* 1 = 0.959807 loss)
I0530 08:05:52.268666  7768 solver.cpp:237] Iteration 5000, loss = 1.48315
I0530 08:05:52.268849  7768 solver.cpp:253]     Train net output #0: loss = 1.48315 (* 1 = 1.48315 loss)
I0530 08:05:52.268867  7768 sgd_solver.cpp:106] Iteration 5000, lr = 0.00184447
I0530 08:24:33.197142  7768 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_10000.caffemodel
I0530 08:24:33.457051  7768 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_10000.solverstate
I0530 08:24:33.539327  7768 solver.cpp:341] Iteration 10000, Testing net (#0)
I0530 08:27:51.909466  7768 solver.cpp:409]     Test net output #0: accuracy = 0.804441
I0530 08:27:51.909636  7768 solver.cpp:409]     Test net output #1: loss = 0.697242 (* 1 = 0.697242 loss)
I0530 08:28:59.280498  7768 solver.cpp:237] Iteration 10000, loss = 1.62857
I0530 08:28:59.280680  7768 solver.cpp:253]     Train net output #0: loss = 1.62857 (* 1 = 1.62857 loss)
I0530 08:28:59.280697  7768 sgd_solver.cpp:106] Iteration 10000, lr = 0.00148651
I0530 08:47:40.351703  7768 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_15000.caffemodel
I0530 08:47:40.613183  7768 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_15000.solverstate
I0530 08:47:40.695111  7768 solver.cpp:341] Iteration 15000, Testing net (#0)
I0530 08:49:54.591630  7768 solver.cpp:409]     Test net output #0: accuracy = 0.830933
I0530 08:49:54.591815  7768 solver.cpp:409]     Test net output #1: loss = 0.597668 (* 1 = 0.597668 loss)
I0530 08:50:57.953811  7768 solver.cpp:237] Iteration 15000, loss = 1.34064
I0530 08:50:57.953984  7768 solver.cpp:253]     Train net output #0: loss = 1.34064 (* 1 = 1.34064 loss)
I0530 08:50:57.954001  7768 sgd_solver.cpp:106] Iteration 15000, lr = 0.00125743
I0530 09:09:22.940742  7768 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_20000.caffemodel
I0530 09:09:23.205343  7768 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_20000.solverstate
I0530 09:09:23.289080  7768 solver.cpp:341] Iteration 20000, Testing net (#0)
I0530 09:12:41.696781  7768 solver.cpp:409]     Test net output #0: accuracy = 0.843372
I0530 09:12:41.696954  7768 solver.cpp:409]     Test net output #1: loss = 0.520449 (* 1 = 0.520449 loss)
I0530 09:13:45.136363  7768 solver.cpp:237] Iteration 20000, loss = 1.25858
I0530 09:13:45.136543  7768 solver.cpp:253]     Train net output #0: loss = 1.25858 (* 1 = 1.25858 loss)
I0530 09:13:45.136559  7768 sgd_solver.cpp:106] Iteration 20000, lr = 0.00109673
I0530 09:32:10.277798  7768 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_25000.caffemodel
I0530 09:32:10.542143  7768 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/xuv/snapshots/epsilon_inv_2016-05-30T07.39.00.897234_iter_25000.solverstate
I0530 09:32:10.626205  7768 solver.cpp:341] Iteration 25000, Testing net (#0)
I0530 09:34:25.544456  7768 solver.cpp:409]     Test net output #0: accuracy = 0.854973
I0530 09:34:25.544636  7768 solver.cpp:409]     Test net output #1: loss = 0.475083 (* 1 = 0.475083 loss)
I0530 09:35:28.914302  7768 solver.cpp:237] Iteration 25000, loss = 1.33089
I0530 09:35:28.914480  7768 solver.cpp:253]     Train net output #0: loss = 1.33089 (* 1 = 1.33089 loss)
I0530 09:35:28.914499  7768 sgd_solver.cpp:106] Iteration 25000, lr = 0.000976987
aprun: Apid 11284981: Caught signal Terminated, sending to application
*** Aborted at 1464615578 (unix time) try "date -d @1464615578" if you are using GNU date ***
aprun: Apid 11284981: Caught signal Terminated, sending to application
PC: @     0x2aaab928a3b8 (unknown)
aprun: Apid 11284981: Caught signal Terminated, sending to application
*** SIGTERM (@0x1e55) received by PID 7768 (TID 0x2aaac746f900) from PID 7765; stack trace: ***
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7225 exceeded limit 7200
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @     0x2aaab928a3b8 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11284981: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
aprun: Apid 11284981: Caught signal Terminated, sending to application
