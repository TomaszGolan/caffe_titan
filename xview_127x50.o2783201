I0505 16:28:33.179786 21364 caffe.cpp:184] Using GPUs 0
I0505 16:28:33.612131 21364 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 15000
lr_policy: "fixed"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0001
stepsize: 1000
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc_model"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt"
I0505 16:28:33.614017 21364 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt
I0505 16:28:33.617537 21364 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0505 16:28:33.617589 21364 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0505 16:28:33.618005 21364 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0505 16:28:33.618198 21364 layer_factory.hpp:77] Creating layer data_hdf5
I0505 16:28:33.618219 21364 net.cpp:106] Creating Layer data_hdf5
I0505 16:28:33.618237 21364 net.cpp:411] data_hdf5 -> data
I0505 16:28:33.618270 21364 net.cpp:411] data_hdf5 -> label
I0505 16:28:33.618299 21364 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0505 16:28:33.620389 21364 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0505 16:28:33.622619 21364 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0505 16:28:40.157253 21364 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0505 16:28:40.160686 21364 net.cpp:150] Setting up data_hdf5
I0505 16:28:40.160733 21364 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0505 16:28:40.160748 21364 net.cpp:157] Top shape: 100 (100)
I0505 16:28:40.160758 21364 net.cpp:165] Memory required for data: 2540400
I0505 16:28:40.160771 21364 layer_factory.hpp:77] Creating layer conv1
I0505 16:28:40.160806 21364 net.cpp:106] Creating Layer conv1
I0505 16:28:40.160818 21364 net.cpp:454] conv1 <- data
I0505 16:28:40.160840 21364 net.cpp:411] conv1 -> conv1
I0505 16:28:40.588317 21364 net.cpp:150] Setting up conv1
I0505 16:28:40.588357 21364 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0505 16:28:40.588368 21364 net.cpp:165] Memory required for data: 30188400
I0505 16:28:40.588402 21364 layer_factory.hpp:77] Creating layer relu1
I0505 16:28:40.588423 21364 net.cpp:106] Creating Layer relu1
I0505 16:28:40.588434 21364 net.cpp:454] relu1 <- conv1
I0505 16:28:40.588448 21364 net.cpp:397] relu1 -> conv1 (in-place)
I0505 16:28:40.588948 21364 net.cpp:150] Setting up relu1
I0505 16:28:40.588965 21364 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0505 16:28:40.588975 21364 net.cpp:165] Memory required for data: 57836400
I0505 16:28:40.588985 21364 layer_factory.hpp:77] Creating layer pool1
I0505 16:28:40.589002 21364 net.cpp:106] Creating Layer pool1
I0505 16:28:40.589011 21364 net.cpp:454] pool1 <- conv1
I0505 16:28:40.589025 21364 net.cpp:411] pool1 -> pool1
I0505 16:28:40.589104 21364 net.cpp:150] Setting up pool1
I0505 16:28:40.589118 21364 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0505 16:28:40.589128 21364 net.cpp:165] Memory required for data: 71660400
I0505 16:28:40.589135 21364 layer_factory.hpp:77] Creating layer conv2
I0505 16:28:40.589157 21364 net.cpp:106] Creating Layer conv2
I0505 16:28:40.589167 21364 net.cpp:454] conv2 <- pool1
I0505 16:28:40.589179 21364 net.cpp:411] conv2 -> conv2
I0505 16:28:40.592033 21364 net.cpp:150] Setting up conv2
I0505 16:28:40.592061 21364 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0505 16:28:40.592072 21364 net.cpp:165] Memory required for data: 91532400
I0505 16:28:40.592092 21364 layer_factory.hpp:77] Creating layer relu2
I0505 16:28:40.592120 21364 net.cpp:106] Creating Layer relu2
I0505 16:28:40.592131 21364 net.cpp:454] relu2 <- conv2
I0505 16:28:40.592144 21364 net.cpp:397] relu2 -> conv2 (in-place)
I0505 16:28:40.592485 21364 net.cpp:150] Setting up relu2
I0505 16:28:40.592499 21364 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0505 16:28:40.592509 21364 net.cpp:165] Memory required for data: 111404400
I0505 16:28:40.592519 21364 layer_factory.hpp:77] Creating layer pool2
I0505 16:28:40.592535 21364 net.cpp:106] Creating Layer pool2
I0505 16:28:40.592545 21364 net.cpp:454] pool2 <- conv2
I0505 16:28:40.592556 21364 net.cpp:411] pool2 -> pool2
I0505 16:28:40.592628 21364 net.cpp:150] Setting up pool2
I0505 16:28:40.592640 21364 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0505 16:28:40.592650 21364 net.cpp:165] Memory required for data: 121340400
I0505 16:28:40.592659 21364 layer_factory.hpp:77] Creating layer conv3
I0505 16:28:40.592681 21364 net.cpp:106] Creating Layer conv3
I0505 16:28:40.592692 21364 net.cpp:454] conv3 <- pool2
I0505 16:28:40.592706 21364 net.cpp:411] conv3 -> conv3
I0505 16:28:40.594750 21364 net.cpp:150] Setting up conv3
I0505 16:28:40.594777 21364 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0505 16:28:40.594787 21364 net.cpp:165] Memory required for data: 132182000
I0505 16:28:40.594805 21364 layer_factory.hpp:77] Creating layer relu3
I0505 16:28:40.594821 21364 net.cpp:106] Creating Layer relu3
I0505 16:28:40.594831 21364 net.cpp:454] relu3 <- conv3
I0505 16:28:40.594847 21364 net.cpp:397] relu3 -> conv3 (in-place)
I0505 16:28:40.595327 21364 net.cpp:150] Setting up relu3
I0505 16:28:40.595347 21364 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0505 16:28:40.595358 21364 net.cpp:165] Memory required for data: 143023600
I0505 16:28:40.595368 21364 layer_factory.hpp:77] Creating layer pool3
I0505 16:28:40.595381 21364 net.cpp:106] Creating Layer pool3
I0505 16:28:40.595391 21364 net.cpp:454] pool3 <- conv3
I0505 16:28:40.595407 21364 net.cpp:411] pool3 -> pool3
I0505 16:28:40.595475 21364 net.cpp:150] Setting up pool3
I0505 16:28:40.595489 21364 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0505 16:28:40.595499 21364 net.cpp:165] Memory required for data: 148444400
I0505 16:28:40.595509 21364 layer_factory.hpp:77] Creating layer conv4
I0505 16:28:40.595527 21364 net.cpp:106] Creating Layer conv4
I0505 16:28:40.595538 21364 net.cpp:454] conv4 <- pool3
I0505 16:28:40.595556 21364 net.cpp:411] conv4 -> conv4
I0505 16:28:40.598671 21364 net.cpp:150] Setting up conv4
I0505 16:28:40.598701 21364 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0505 16:28:40.598711 21364 net.cpp:165] Memory required for data: 152073200
I0505 16:28:40.598726 21364 layer_factory.hpp:77] Creating layer relu4
I0505 16:28:40.598740 21364 net.cpp:106] Creating Layer relu4
I0505 16:28:40.598750 21364 net.cpp:454] relu4 <- conv4
I0505 16:28:40.598767 21364 net.cpp:397] relu4 -> conv4 (in-place)
I0505 16:28:40.599244 21364 net.cpp:150] Setting up relu4
I0505 16:28:40.599261 21364 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0505 16:28:40.599270 21364 net.cpp:165] Memory required for data: 155702000
I0505 16:28:40.599280 21364 layer_factory.hpp:77] Creating layer pool4
I0505 16:28:40.599293 21364 net.cpp:106] Creating Layer pool4
I0505 16:28:40.599303 21364 net.cpp:454] pool4 <- conv4
I0505 16:28:40.599319 21364 net.cpp:411] pool4 -> pool4
I0505 16:28:40.599390 21364 net.cpp:150] Setting up pool4
I0505 16:28:40.599403 21364 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0505 16:28:40.599413 21364 net.cpp:165] Memory required for data: 157516400
I0505 16:28:40.599423 21364 layer_factory.hpp:77] Creating layer ip1
I0505 16:28:40.599447 21364 net.cpp:106] Creating Layer ip1
I0505 16:28:40.599457 21364 net.cpp:454] ip1 <- pool4
I0505 16:28:40.599474 21364 net.cpp:411] ip1 -> ip1
I0505 16:28:40.615422 21364 net.cpp:150] Setting up ip1
I0505 16:28:40.615450 21364 net.cpp:157] Top shape: 100 196 (19600)
I0505 16:28:40.615465 21364 net.cpp:165] Memory required for data: 157594800
I0505 16:28:40.615488 21364 layer_factory.hpp:77] Creating layer relu5
I0505 16:28:40.615516 21364 net.cpp:106] Creating Layer relu5
I0505 16:28:40.615527 21364 net.cpp:454] relu5 <- ip1
I0505 16:28:40.615540 21364 net.cpp:397] relu5 -> ip1 (in-place)
I0505 16:28:40.615883 21364 net.cpp:150] Setting up relu5
I0505 16:28:40.615901 21364 net.cpp:157] Top shape: 100 196 (19600)
I0505 16:28:40.615911 21364 net.cpp:165] Memory required for data: 157673200
I0505 16:28:40.615921 21364 layer_factory.hpp:77] Creating layer drop1
I0505 16:28:40.615938 21364 net.cpp:106] Creating Layer drop1
I0505 16:28:40.615948 21364 net.cpp:454] drop1 <- ip1
I0505 16:28:40.615960 21364 net.cpp:397] drop1 -> ip1 (in-place)
I0505 16:28:40.616011 21364 net.cpp:150] Setting up drop1
I0505 16:28:40.616024 21364 net.cpp:157] Top shape: 100 196 (19600)
I0505 16:28:40.616034 21364 net.cpp:165] Memory required for data: 157751600
I0505 16:28:40.616042 21364 layer_factory.hpp:77] Creating layer ip2
I0505 16:28:40.616065 21364 net.cpp:106] Creating Layer ip2
I0505 16:28:40.616075 21364 net.cpp:454] ip2 <- ip1
I0505 16:28:40.616088 21364 net.cpp:411] ip2 -> ip2
I0505 16:28:40.616570 21364 net.cpp:150] Setting up ip2
I0505 16:28:40.616583 21364 net.cpp:157] Top shape: 100 98 (9800)
I0505 16:28:40.616593 21364 net.cpp:165] Memory required for data: 157790800
I0505 16:28:40.616608 21364 layer_factory.hpp:77] Creating layer relu6
I0505 16:28:40.616626 21364 net.cpp:106] Creating Layer relu6
I0505 16:28:40.616636 21364 net.cpp:454] relu6 <- ip2
I0505 16:28:40.616647 21364 net.cpp:397] relu6 -> ip2 (in-place)
I0505 16:28:40.617166 21364 net.cpp:150] Setting up relu6
I0505 16:28:40.617187 21364 net.cpp:157] Top shape: 100 98 (9800)
I0505 16:28:40.617197 21364 net.cpp:165] Memory required for data: 157830000
I0505 16:28:40.617207 21364 layer_factory.hpp:77] Creating layer drop2
I0505 16:28:40.617219 21364 net.cpp:106] Creating Layer drop2
I0505 16:28:40.617229 21364 net.cpp:454] drop2 <- ip2
I0505 16:28:40.617244 21364 net.cpp:397] drop2 -> ip2 (in-place)
I0505 16:28:40.617288 21364 net.cpp:150] Setting up drop2
I0505 16:28:40.617301 21364 net.cpp:157] Top shape: 100 98 (9800)
I0505 16:28:40.617311 21364 net.cpp:165] Memory required for data: 157869200
I0505 16:28:40.617321 21364 layer_factory.hpp:77] Creating layer ip3
I0505 16:28:40.617333 21364 net.cpp:106] Creating Layer ip3
I0505 16:28:40.617343 21364 net.cpp:454] ip3 <- ip2
I0505 16:28:40.617358 21364 net.cpp:411] ip3 -> ip3
I0505 16:28:40.617576 21364 net.cpp:150] Setting up ip3
I0505 16:28:40.617588 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:40.617599 21364 net.cpp:165] Memory required for data: 157873600
I0505 16:28:40.617612 21364 layer_factory.hpp:77] Creating layer relu6
I0505 16:28:40.617624 21364 net.cpp:106] Creating Layer relu6
I0505 16:28:40.617635 21364 net.cpp:454] relu6 <- ip3
I0505 16:28:40.617646 21364 net.cpp:397] relu6 -> ip3 (in-place)
I0505 16:28:40.618119 21364 net.cpp:150] Setting up relu6
I0505 16:28:40.618144 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:40.618155 21364 net.cpp:165] Memory required for data: 157878000
I0505 16:28:40.618165 21364 layer_factory.hpp:77] Creating layer drop3
I0505 16:28:40.618176 21364 net.cpp:106] Creating Layer drop3
I0505 16:28:40.618186 21364 net.cpp:454] drop3 <- ip3
I0505 16:28:40.618198 21364 net.cpp:397] drop3 -> ip3 (in-place)
I0505 16:28:40.618242 21364 net.cpp:150] Setting up drop3
I0505 16:28:40.618254 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:40.618264 21364 net.cpp:165] Memory required for data: 157882400
I0505 16:28:40.618273 21364 layer_factory.hpp:77] Creating layer loss
I0505 16:28:40.618289 21364 net.cpp:106] Creating Layer loss
I0505 16:28:40.618300 21364 net.cpp:454] loss <- ip3
I0505 16:28:40.618319 21364 net.cpp:454] loss <- label
I0505 16:28:40.618335 21364 net.cpp:411] loss -> loss
I0505 16:28:40.618362 21364 layer_factory.hpp:77] Creating layer loss
I0505 16:28:40.618859 21364 net.cpp:150] Setting up loss
I0505 16:28:40.618880 21364 net.cpp:157] Top shape: (1)
I0505 16:28:40.618891 21364 net.cpp:160]     with loss weight 1
I0505 16:28:40.618937 21364 net.cpp:165] Memory required for data: 157882404
I0505 16:28:40.618948 21364 net.cpp:226] loss needs backward computation.
I0505 16:28:40.618959 21364 net.cpp:226] drop3 needs backward computation.
I0505 16:28:40.618970 21364 net.cpp:226] relu6 needs backward computation.
I0505 16:28:40.618979 21364 net.cpp:226] ip3 needs backward computation.
I0505 16:28:40.618989 21364 net.cpp:226] drop2 needs backward computation.
I0505 16:28:40.618999 21364 net.cpp:226] relu6 needs backward computation.
I0505 16:28:40.619009 21364 net.cpp:226] ip2 needs backward computation.
I0505 16:28:40.619019 21364 net.cpp:226] drop1 needs backward computation.
I0505 16:28:40.619027 21364 net.cpp:226] relu5 needs backward computation.
I0505 16:28:40.619036 21364 net.cpp:226] ip1 needs backward computation.
I0505 16:28:40.619046 21364 net.cpp:226] pool4 needs backward computation.
I0505 16:28:40.619056 21364 net.cpp:226] relu4 needs backward computation.
I0505 16:28:40.619066 21364 net.cpp:226] conv4 needs backward computation.
I0505 16:28:40.619077 21364 net.cpp:226] pool3 needs backward computation.
I0505 16:28:40.619087 21364 net.cpp:226] relu3 needs backward computation.
I0505 16:28:40.619096 21364 net.cpp:226] conv3 needs backward computation.
I0505 16:28:40.619107 21364 net.cpp:226] pool2 needs backward computation.
I0505 16:28:40.619117 21364 net.cpp:226] relu2 needs backward computation.
I0505 16:28:40.619127 21364 net.cpp:226] conv2 needs backward computation.
I0505 16:28:40.619137 21364 net.cpp:226] pool1 needs backward computation.
I0505 16:28:40.619146 21364 net.cpp:226] relu1 needs backward computation.
I0505 16:28:40.619156 21364 net.cpp:226] conv1 needs backward computation.
I0505 16:28:40.619168 21364 net.cpp:228] data_hdf5 does not need backward computation.
I0505 16:28:40.619177 21364 net.cpp:270] This network produces output loss
I0505 16:28:40.619204 21364 net.cpp:283] Network initialization done.
I0505 16:28:40.621002 21364 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt
I0505 16:28:40.621070 21364 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0505 16:28:40.621525 21364 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0505 16:28:40.621729 21364 layer_factory.hpp:77] Creating layer data_hdf5
I0505 16:28:40.621744 21364 net.cpp:106] Creating Layer data_hdf5
I0505 16:28:40.621755 21364 net.cpp:411] data_hdf5 -> data
I0505 16:28:40.621772 21364 net.cpp:411] data_hdf5 -> label
I0505 16:28:40.621788 21364 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0505 16:28:40.624106 21364 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0505 16:28:47.128602 21364 net.cpp:150] Setting up data_hdf5
I0505 16:28:47.128643 21364 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0505 16:28:47.128662 21364 net.cpp:157] Top shape: 100 (100)
I0505 16:28:47.128672 21364 net.cpp:165] Memory required for data: 2540400
I0505 16:28:47.128686 21364 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0505 16:28:47.128715 21364 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0505 16:28:47.128726 21364 net.cpp:454] label_data_hdf5_1_split <- label
I0505 16:28:47.128741 21364 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0505 16:28:47.128760 21364 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0505 16:28:47.128832 21364 net.cpp:150] Setting up label_data_hdf5_1_split
I0505 16:28:47.128845 21364 net.cpp:157] Top shape: 100 (100)
I0505 16:28:47.128871 21364 net.cpp:157] Top shape: 100 (100)
I0505 16:28:47.128882 21364 net.cpp:165] Memory required for data: 2541200
I0505 16:28:47.128892 21364 layer_factory.hpp:77] Creating layer conv1
I0505 16:28:47.128913 21364 net.cpp:106] Creating Layer conv1
I0505 16:28:47.128923 21364 net.cpp:454] conv1 <- data
I0505 16:28:47.128937 21364 net.cpp:411] conv1 -> conv1
I0505 16:28:47.130909 21364 net.cpp:150] Setting up conv1
I0505 16:28:47.130939 21364 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0505 16:28:47.130949 21364 net.cpp:165] Memory required for data: 30189200
I0505 16:28:47.130969 21364 layer_factory.hpp:77] Creating layer relu1
I0505 16:28:47.130983 21364 net.cpp:106] Creating Layer relu1
I0505 16:28:47.130993 21364 net.cpp:454] relu1 <- conv1
I0505 16:28:47.131008 21364 net.cpp:397] relu1 -> conv1 (in-place)
I0505 16:28:47.131342 21364 net.cpp:150] Setting up relu1
I0505 16:28:47.131356 21364 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0505 16:28:47.131366 21364 net.cpp:165] Memory required for data: 57837200
I0505 16:28:47.131376 21364 layer_factory.hpp:77] Creating layer pool1
I0505 16:28:47.131391 21364 net.cpp:106] Creating Layer pool1
I0505 16:28:47.131400 21364 net.cpp:454] pool1 <- conv1
I0505 16:28:47.131415 21364 net.cpp:411] pool1 -> pool1
I0505 16:28:47.131487 21364 net.cpp:150] Setting up pool1
I0505 16:28:47.131500 21364 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0505 16:28:47.131510 21364 net.cpp:165] Memory required for data: 71661200
I0505 16:28:47.131518 21364 layer_factory.hpp:77] Creating layer conv2
I0505 16:28:47.131541 21364 net.cpp:106] Creating Layer conv2
I0505 16:28:47.131551 21364 net.cpp:454] conv2 <- pool1
I0505 16:28:47.131564 21364 net.cpp:411] conv2 -> conv2
I0505 16:28:47.133496 21364 net.cpp:150] Setting up conv2
I0505 16:28:47.133517 21364 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0505 16:28:47.133530 21364 net.cpp:165] Memory required for data: 91533200
I0505 16:28:47.133548 21364 layer_factory.hpp:77] Creating layer relu2
I0505 16:28:47.133560 21364 net.cpp:106] Creating Layer relu2
I0505 16:28:47.133570 21364 net.cpp:454] relu2 <- conv2
I0505 16:28:47.133589 21364 net.cpp:397] relu2 -> conv2 (in-place)
I0505 16:28:47.134075 21364 net.cpp:150] Setting up relu2
I0505 16:28:47.134096 21364 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0505 16:28:47.134106 21364 net.cpp:165] Memory required for data: 111405200
I0505 16:28:47.134116 21364 layer_factory.hpp:77] Creating layer pool2
I0505 16:28:47.134130 21364 net.cpp:106] Creating Layer pool2
I0505 16:28:47.134140 21364 net.cpp:454] pool2 <- conv2
I0505 16:28:47.134155 21364 net.cpp:411] pool2 -> pool2
I0505 16:28:47.134227 21364 net.cpp:150] Setting up pool2
I0505 16:28:47.134240 21364 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0505 16:28:47.134249 21364 net.cpp:165] Memory required for data: 121341200
I0505 16:28:47.134259 21364 layer_factory.hpp:77] Creating layer conv3
I0505 16:28:47.134284 21364 net.cpp:106] Creating Layer conv3
I0505 16:28:47.134294 21364 net.cpp:454] conv3 <- pool2
I0505 16:28:47.134315 21364 net.cpp:411] conv3 -> conv3
I0505 16:28:47.136363 21364 net.cpp:150] Setting up conv3
I0505 16:28:47.136379 21364 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0505 16:28:47.136390 21364 net.cpp:165] Memory required for data: 132182800
I0505 16:28:47.136409 21364 layer_factory.hpp:77] Creating layer relu3
I0505 16:28:47.136421 21364 net.cpp:106] Creating Layer relu3
I0505 16:28:47.136431 21364 net.cpp:454] relu3 <- conv3
I0505 16:28:47.136443 21364 net.cpp:397] relu3 -> conv3 (in-place)
I0505 16:28:47.136950 21364 net.cpp:150] Setting up relu3
I0505 16:28:47.136965 21364 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0505 16:28:47.136976 21364 net.cpp:165] Memory required for data: 143024400
I0505 16:28:47.136986 21364 layer_factory.hpp:77] Creating layer pool3
I0505 16:28:47.136998 21364 net.cpp:106] Creating Layer pool3
I0505 16:28:47.137008 21364 net.cpp:454] pool3 <- conv3
I0505 16:28:47.137023 21364 net.cpp:411] pool3 -> pool3
I0505 16:28:47.137095 21364 net.cpp:150] Setting up pool3
I0505 16:28:47.137117 21364 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0505 16:28:47.137127 21364 net.cpp:165] Memory required for data: 148445200
I0505 16:28:47.137137 21364 layer_factory.hpp:77] Creating layer conv4
I0505 16:28:47.137159 21364 net.cpp:106] Creating Layer conv4
I0505 16:28:47.137171 21364 net.cpp:454] conv4 <- pool3
I0505 16:28:47.137183 21364 net.cpp:411] conv4 -> conv4
I0505 16:28:47.139415 21364 net.cpp:150] Setting up conv4
I0505 16:28:47.139437 21364 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0505 16:28:47.139451 21364 net.cpp:165] Memory required for data: 152074000
I0505 16:28:47.139464 21364 layer_factory.hpp:77] Creating layer relu4
I0505 16:28:47.139477 21364 net.cpp:106] Creating Layer relu4
I0505 16:28:47.139487 21364 net.cpp:454] relu4 <- conv4
I0505 16:28:47.139503 21364 net.cpp:397] relu4 -> conv4 (in-place)
I0505 16:28:47.139832 21364 net.cpp:150] Setting up relu4
I0505 16:28:47.139845 21364 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0505 16:28:47.139855 21364 net.cpp:165] Memory required for data: 155702800
I0505 16:28:47.139865 21364 layer_factory.hpp:77] Creating layer pool4
I0505 16:28:47.139878 21364 net.cpp:106] Creating Layer pool4
I0505 16:28:47.139888 21364 net.cpp:454] pool4 <- conv4
I0505 16:28:47.139902 21364 net.cpp:411] pool4 -> pool4
I0505 16:28:47.139973 21364 net.cpp:150] Setting up pool4
I0505 16:28:47.139986 21364 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0505 16:28:47.139997 21364 net.cpp:165] Memory required for data: 157517200
I0505 16:28:47.140007 21364 layer_factory.hpp:77] Creating layer ip1
I0505 16:28:47.140025 21364 net.cpp:106] Creating Layer ip1
I0505 16:28:47.140035 21364 net.cpp:454] ip1 <- pool4
I0505 16:28:47.140053 21364 net.cpp:411] ip1 -> ip1
I0505 16:28:47.155889 21364 net.cpp:150] Setting up ip1
I0505 16:28:47.155916 21364 net.cpp:157] Top shape: 100 196 (19600)
I0505 16:28:47.155927 21364 net.cpp:165] Memory required for data: 157595600
I0505 16:28:47.155948 21364 layer_factory.hpp:77] Creating layer relu5
I0505 16:28:47.155966 21364 net.cpp:106] Creating Layer relu5
I0505 16:28:47.155977 21364 net.cpp:454] relu5 <- ip1
I0505 16:28:47.155994 21364 net.cpp:397] relu5 -> ip1 (in-place)
I0505 16:28:47.156543 21364 net.cpp:150] Setting up relu5
I0505 16:28:47.156566 21364 net.cpp:157] Top shape: 100 196 (19600)
I0505 16:28:47.156579 21364 net.cpp:165] Memory required for data: 157674000
I0505 16:28:47.156589 21364 layer_factory.hpp:77] Creating layer drop1
I0505 16:28:47.156610 21364 net.cpp:106] Creating Layer drop1
I0505 16:28:47.156620 21364 net.cpp:454] drop1 <- ip1
I0505 16:28:47.156633 21364 net.cpp:397] drop1 -> ip1 (in-place)
I0505 16:28:47.156679 21364 net.cpp:150] Setting up drop1
I0505 16:28:47.156693 21364 net.cpp:157] Top shape: 100 196 (19600)
I0505 16:28:47.156702 21364 net.cpp:165] Memory required for data: 157752400
I0505 16:28:47.156713 21364 layer_factory.hpp:77] Creating layer ip2
I0505 16:28:47.156729 21364 net.cpp:106] Creating Layer ip2
I0505 16:28:47.156739 21364 net.cpp:454] ip2 <- ip1
I0505 16:28:47.156751 21364 net.cpp:411] ip2 -> ip2
I0505 16:28:47.157244 21364 net.cpp:150] Setting up ip2
I0505 16:28:47.157258 21364 net.cpp:157] Top shape: 100 98 (9800)
I0505 16:28:47.157268 21364 net.cpp:165] Memory required for data: 157791600
I0505 16:28:47.157282 21364 layer_factory.hpp:77] Creating layer relu6
I0505 16:28:47.157299 21364 net.cpp:106] Creating Layer relu6
I0505 16:28:47.157310 21364 net.cpp:454] relu6 <- ip2
I0505 16:28:47.157321 21364 net.cpp:397] relu6 -> ip2 (in-place)
I0505 16:28:47.157644 21364 net.cpp:150] Setting up relu6
I0505 16:28:47.157656 21364 net.cpp:157] Top shape: 100 98 (9800)
I0505 16:28:47.157666 21364 net.cpp:165] Memory required for data: 157830800
I0505 16:28:47.157676 21364 layer_factory.hpp:77] Creating layer drop2
I0505 16:28:47.157691 21364 net.cpp:106] Creating Layer drop2
I0505 16:28:47.157702 21364 net.cpp:454] drop2 <- ip2
I0505 16:28:47.157714 21364 net.cpp:397] drop2 -> ip2 (in-place)
I0505 16:28:47.157758 21364 net.cpp:150] Setting up drop2
I0505 16:28:47.157770 21364 net.cpp:157] Top shape: 100 98 (9800)
I0505 16:28:47.157790 21364 net.cpp:165] Memory required for data: 157870000
I0505 16:28:47.157800 21364 layer_factory.hpp:77] Creating layer ip3
I0505 16:28:47.157814 21364 net.cpp:106] Creating Layer ip3
I0505 16:28:47.157824 21364 net.cpp:454] ip3 <- ip2
I0505 16:28:47.157840 21364 net.cpp:411] ip3 -> ip3
I0505 16:28:47.158066 21364 net.cpp:150] Setting up ip3
I0505 16:28:47.158078 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:47.158088 21364 net.cpp:165] Memory required for data: 157874400
I0505 16:28:47.158103 21364 layer_factory.hpp:77] Creating layer relu6
I0505 16:28:47.158115 21364 net.cpp:106] Creating Layer relu6
I0505 16:28:47.158124 21364 net.cpp:454] relu6 <- ip3
I0505 16:28:47.158139 21364 net.cpp:397] relu6 -> ip3 (in-place)
I0505 16:28:47.158632 21364 net.cpp:150] Setting up relu6
I0505 16:28:47.158648 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:47.158658 21364 net.cpp:165] Memory required for data: 157878800
I0505 16:28:47.158668 21364 layer_factory.hpp:77] Creating layer drop3
I0505 16:28:47.158680 21364 net.cpp:106] Creating Layer drop3
I0505 16:28:47.158690 21364 net.cpp:454] drop3 <- ip3
I0505 16:28:47.158705 21364 net.cpp:397] drop3 -> ip3 (in-place)
I0505 16:28:47.158748 21364 net.cpp:150] Setting up drop3
I0505 16:28:47.158761 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:47.158769 21364 net.cpp:165] Memory required for data: 157883200
I0505 16:28:47.158779 21364 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0505 16:28:47.158795 21364 net.cpp:106] Creating Layer ip3_drop3_0_split
I0505 16:28:47.158804 21364 net.cpp:454] ip3_drop3_0_split <- ip3
I0505 16:28:47.158815 21364 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0505 16:28:47.158829 21364 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0505 16:28:47.158906 21364 net.cpp:150] Setting up ip3_drop3_0_split
I0505 16:28:47.158918 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:47.158938 21364 net.cpp:157] Top shape: 100 11 (1100)
I0505 16:28:47.158948 21364 net.cpp:165] Memory required for data: 157892000
I0505 16:28:47.158958 21364 layer_factory.hpp:77] Creating layer accuracy
I0505 16:28:47.158977 21364 net.cpp:106] Creating Layer accuracy
I0505 16:28:47.158987 21364 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0505 16:28:47.158998 21364 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0505 16:28:47.159010 21364 net.cpp:411] accuracy -> accuracy
I0505 16:28:47.159032 21364 net.cpp:150] Setting up accuracy
I0505 16:28:47.159044 21364 net.cpp:157] Top shape: (1)
I0505 16:28:47.159054 21364 net.cpp:165] Memory required for data: 157892004
I0505 16:28:47.159065 21364 layer_factory.hpp:77] Creating layer loss
I0505 16:28:47.159081 21364 net.cpp:106] Creating Layer loss
I0505 16:28:47.159091 21364 net.cpp:454] loss <- ip3_drop3_0_split_1
I0505 16:28:47.159102 21364 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0505 16:28:47.159116 21364 net.cpp:411] loss -> loss
I0505 16:28:47.159132 21364 layer_factory.hpp:77] Creating layer loss
I0505 16:28:47.159780 21364 net.cpp:150] Setting up loss
I0505 16:28:47.159801 21364 net.cpp:157] Top shape: (1)
I0505 16:28:47.159813 21364 net.cpp:160]     with loss weight 1
I0505 16:28:47.159832 21364 net.cpp:165] Memory required for data: 157892008
I0505 16:28:47.159842 21364 net.cpp:226] loss needs backward computation.
I0505 16:28:47.159852 21364 net.cpp:228] accuracy does not need backward computation.
I0505 16:28:47.159863 21364 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0505 16:28:47.159873 21364 net.cpp:226] drop3 needs backward computation.
I0505 16:28:47.159883 21364 net.cpp:226] relu6 needs backward computation.
I0505 16:28:47.159891 21364 net.cpp:226] ip3 needs backward computation.
I0505 16:28:47.159901 21364 net.cpp:226] drop2 needs backward computation.
I0505 16:28:47.159911 21364 net.cpp:226] relu6 needs backward computation.
I0505 16:28:47.159921 21364 net.cpp:226] ip2 needs backward computation.
I0505 16:28:47.159931 21364 net.cpp:226] drop1 needs backward computation.
I0505 16:28:47.159948 21364 net.cpp:226] relu5 needs backward computation.
I0505 16:28:47.159958 21364 net.cpp:226] ip1 needs backward computation.
I0505 16:28:47.159967 21364 net.cpp:226] pool4 needs backward computation.
I0505 16:28:47.159978 21364 net.cpp:226] relu4 needs backward computation.
I0505 16:28:47.159987 21364 net.cpp:226] conv4 needs backward computation.
I0505 16:28:47.159998 21364 net.cpp:226] pool3 needs backward computation.
I0505 16:28:47.160008 21364 net.cpp:226] relu3 needs backward computation.
I0505 16:28:47.160019 21364 net.cpp:226] conv3 needs backward computation.
I0505 16:28:47.160029 21364 net.cpp:226] pool2 needs backward computation.
I0505 16:28:47.160040 21364 net.cpp:226] relu2 needs backward computation.
I0505 16:28:47.160050 21364 net.cpp:226] conv2 needs backward computation.
I0505 16:28:47.160060 21364 net.cpp:226] pool1 needs backward computation.
I0505 16:28:47.160069 21364 net.cpp:226] relu1 needs backward computation.
I0505 16:28:47.160079 21364 net.cpp:226] conv1 needs backward computation.
I0505 16:28:47.160089 21364 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0505 16:28:47.160101 21364 net.cpp:228] data_hdf5 does not need backward computation.
I0505 16:28:47.160110 21364 net.cpp:270] This network produces output accuracy
I0505 16:28:47.160120 21364 net.cpp:270] This network produces output loss
I0505 16:28:47.160153 21364 net.cpp:283] Network initialization done.
I0505 16:28:47.160286 21364 solver.cpp:60] Solver scaffolding done.
I0505 16:28:47.161384 21364 caffe.cpp:212] Starting Optimization
I0505 16:28:47.161404 21364 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0505 16:28:47.161417 21364 solver.cpp:289] Learning Rate Policy: fixed
I0505 16:28:47.162493 21364 solver.cpp:341] Iteration 0, Testing net (#0)
I0505 16:29:20.099426 21364 solver.cpp:409]     Test net output #0: accuracy = 0.07096
I0505 16:29:20.099597 21364 solver.cpp:409]     Test net output #1: loss = 2.39793 (* 1 = 2.39793 loss)
I0505 16:29:20.132303 21364 solver.cpp:237] Iteration 0, loss = 2.3979
I0505 16:29:20.132335 21364 solver.cpp:253]     Train net output #0: loss = 2.3979 (* 1 = 2.3979 loss)
I0505 16:29:20.132354 21364 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0505 16:29:25.940104 21364 solver.cpp:237] Iteration 100, loss = 2.36205
I0505 16:29:25.940140 21364 solver.cpp:253]     Train net output #0: loss = 2.36205 (* 1 = 2.36205 loss)
I0505 16:29:25.940155 21364 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0505 16:29:31.753376 21364 solver.cpp:237] Iteration 200, loss = 2.37291
I0505 16:29:31.753409 21364 solver.cpp:253]     Train net output #0: loss = 2.37291 (* 1 = 2.37291 loss)
I0505 16:29:31.753425 21364 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0505 16:29:37.565151 21364 solver.cpp:237] Iteration 300, loss = 2.36451
I0505 16:29:37.565183 21364 solver.cpp:253]     Train net output #0: loss = 2.36451 (* 1 = 2.36451 loss)
I0505 16:29:37.565199 21364 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0505 16:29:43.374482 21364 solver.cpp:237] Iteration 400, loss = 2.33812
I0505 16:29:43.374521 21364 solver.cpp:253]     Train net output #0: loss = 2.33812 (* 1 = 2.33812 loss)
I0505 16:29:43.374534 21364 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0505 16:29:49.187618 21364 solver.cpp:237] Iteration 500, loss = 2.35367
I0505 16:29:49.187649 21364 solver.cpp:253]     Train net output #0: loss = 2.35367 (* 1 = 2.35367 loss)
I0505 16:29:49.187664 21364 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0505 16:29:54.998209 21364 solver.cpp:237] Iteration 600, loss = 2.34663
I0505 16:29:54.998363 21364 solver.cpp:253]     Train net output #0: loss = 2.34663 (* 1 = 2.34663 loss)
I0505 16:29:54.998376 21364 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0505 16:30:00.804369 21364 solver.cpp:237] Iteration 700, loss = 2.37563
I0505 16:30:00.804401 21364 solver.cpp:253]     Train net output #0: loss = 2.37563 (* 1 = 2.37563 loss)
I0505 16:30:00.804417 21364 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0505 16:30:06.618484 21364 solver.cpp:237] Iteration 800, loss = 2.33736
I0505 16:30:06.618516 21364 solver.cpp:253]     Train net output #0: loss = 2.33736 (* 1 = 2.33736 loss)
I0505 16:30:06.618538 21364 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0505 16:30:12.428339 21364 solver.cpp:237] Iteration 900, loss = 2.35298
I0505 16:30:12.428371 21364 solver.cpp:253]     Train net output #0: loss = 2.35298 (* 1 = 2.35298 loss)
I0505 16:30:12.428386 21364 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0505 16:30:18.180058 21364 solver.cpp:341] Iteration 1000, Testing net (#0)
I0505 16:30:47.762006 21364 solver.cpp:409]     Test net output #0: accuracy = 0.162633
I0505 16:30:47.762173 21364 solver.cpp:409]     Test net output #1: loss = 2.32775 (* 1 = 2.32775 loss)
I0505 16:30:56.015702 21364 solver.cpp:237] Iteration 1000, loss = 2.34546
I0505 16:30:56.015755 21364 solver.cpp:253]     Train net output #0: loss = 2.34546 (* 1 = 2.34546 loss)
I0505 16:30:56.015772 21364 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0505 16:31:01.832038 21364 solver.cpp:237] Iteration 1100, loss = 2.35932
I0505 16:31:01.832073 21364 solver.cpp:253]     Train net output #0: loss = 2.35932 (* 1 = 2.35932 loss)
I0505 16:31:01.832092 21364 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0505 16:31:07.646255 21364 solver.cpp:237] Iteration 1200, loss = 2.33467
I0505 16:31:07.646286 21364 solver.cpp:253]     Train net output #0: loss = 2.33467 (* 1 = 2.33467 loss)
I0505 16:31:07.646302 21364 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0505 16:31:13.461221 21364 solver.cpp:237] Iteration 1300, loss = 2.35353
I0505 16:31:13.461254 21364 solver.cpp:253]     Train net output #0: loss = 2.35353 (* 1 = 2.35353 loss)
I0505 16:31:13.461269 21364 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0505 16:31:19.278417 21364 solver.cpp:237] Iteration 1400, loss = 2.30387
I0505 16:31:19.278559 21364 solver.cpp:253]     Train net output #0: loss = 2.30387 (* 1 = 2.30387 loss)
I0505 16:31:19.278573 21364 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0505 16:31:25.090595 21364 solver.cpp:237] Iteration 1500, loss = 2.38888
I0505 16:31:25.090626 21364 solver.cpp:253]     Train net output #0: loss = 2.38888 (* 1 = 2.38888 loss)
I0505 16:31:25.090636 21364 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0505 16:31:30.904932 21364 solver.cpp:237] Iteration 1600, loss = 2.36524
I0505 16:31:30.904964 21364 solver.cpp:253]     Train net output #0: loss = 2.36524 (* 1 = 2.36524 loss)
I0505 16:31:30.904980 21364 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0505 16:31:36.720722 21364 solver.cpp:237] Iteration 1700, loss = 2.30547
I0505 16:31:36.720757 21364 solver.cpp:253]     Train net output #0: loss = 2.30547 (* 1 = 2.30547 loss)
I0505 16:31:36.720772 21364 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0505 16:31:42.536427 21364 solver.cpp:237] Iteration 1800, loss = 2.33602
I0505 16:31:42.536460 21364 solver.cpp:253]     Train net output #0: loss = 2.33602 (* 1 = 2.33602 loss)
I0505 16:31:42.536475 21364 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0505 16:31:48.351645 21364 solver.cpp:237] Iteration 1900, loss = 2.36995
I0505 16:31:48.351687 21364 solver.cpp:253]     Train net output #0: loss = 2.36995 (* 1 = 2.36995 loss)
I0505 16:31:48.351701 21364 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0505 16:31:54.107007 21364 solver.cpp:341] Iteration 2000, Testing net (#0)
I0505 16:32:27.340068 21364 solver.cpp:409]     Test net output #0: accuracy = 0.16226
I0505 16:32:27.340226 21364 solver.cpp:409]     Test net output #1: loss = 2.33119 (* 1 = 2.33119 loss)
I0505 16:32:35.837219 21364 solver.cpp:237] Iteration 2000, loss = 2.3695
I0505 16:32:35.837275 21364 solver.cpp:253]     Train net output #0: loss = 2.3695 (* 1 = 2.3695 loss)
I0505 16:32:35.837290 21364 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0505 16:32:41.652218 21364 solver.cpp:237] Iteration 2100, loss = 2.36494
I0505 16:32:41.652262 21364 solver.cpp:253]     Train net output #0: loss = 2.36494 (* 1 = 2.36494 loss)
I0505 16:32:41.652277 21364 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0505 16:32:47.464329 21364 solver.cpp:237] Iteration 2200, loss = 2.31705
I0505 16:32:47.464360 21364 solver.cpp:253]     Train net output #0: loss = 2.31705 (* 1 = 2.31705 loss)
I0505 16:32:47.464375 21364 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0505 16:32:53.278220 21364 solver.cpp:237] Iteration 2300, loss = 2.33538
I0505 16:32:53.278252 21364 solver.cpp:253]     Train net output #0: loss = 2.33538 (* 1 = 2.33538 loss)
I0505 16:32:53.278267 21364 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0505 16:32:59.090358 21364 solver.cpp:237] Iteration 2400, loss = 2.34791
I0505 16:32:59.090515 21364 solver.cpp:253]     Train net output #0: loss = 2.34791 (* 1 = 2.34791 loss)
I0505 16:32:59.090529 21364 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0505 16:33:04.904110 21364 solver.cpp:237] Iteration 2500, loss = 2.33915
I0505 16:33:04.904155 21364 solver.cpp:253]     Train net output #0: loss = 2.33915 (* 1 = 2.33915 loss)
I0505 16:33:04.904170 21364 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0505 16:33:10.718387 21364 solver.cpp:237] Iteration 2600, loss = 2.34921
I0505 16:33:10.718420 21364 solver.cpp:253]     Train net output #0: loss = 2.34921 (* 1 = 2.34921 loss)
I0505 16:33:10.718436 21364 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0505 16:33:16.531991 21364 solver.cpp:237] Iteration 2700, loss = 2.39476
I0505 16:33:16.532023 21364 solver.cpp:253]     Train net output #0: loss = 2.39476 (* 1 = 2.39476 loss)
I0505 16:33:16.532038 21364 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0505 16:33:22.344254 21364 solver.cpp:237] Iteration 2800, loss = 2.3859
I0505 16:33:22.344285 21364 solver.cpp:253]     Train net output #0: loss = 2.3859 (* 1 = 2.3859 loss)
I0505 16:33:22.344301 21364 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0505 16:33:28.154417 21364 solver.cpp:237] Iteration 2900, loss = 2.32868
I0505 16:33:28.154459 21364 solver.cpp:253]     Train net output #0: loss = 2.32868 (* 1 = 2.32868 loss)
I0505 16:33:28.154479 21364 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0505 16:33:33.910358 21364 solver.cpp:341] Iteration 3000, Testing net (#0)
I0505 16:34:03.206234 21364 solver.cpp:409]     Test net output #0: accuracy = 0.162826
I0505 16:34:03.206284 21364 solver.cpp:409]     Test net output #1: loss = 2.33608 (* 1 = 2.33608 loss)
I0505 16:34:11.705624 21364 solver.cpp:237] Iteration 3000, loss = 2.42021
I0505 16:34:11.705799 21364 solver.cpp:253]     Train net output #0: loss = 2.42021 (* 1 = 2.42021 loss)
I0505 16:34:11.705813 21364 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0505 16:34:17.515516 21364 solver.cpp:237] Iteration 3100, loss = 2.38217
I0505 16:34:17.515557 21364 solver.cpp:253]     Train net output #0: loss = 2.38217 (* 1 = 2.38217 loss)
I0505 16:34:17.515576 21364 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0505 16:34:23.324650 21364 solver.cpp:237] Iteration 3200, loss = 2.33668
I0505 16:34:23.324683 21364 solver.cpp:253]     Train net output #0: loss = 2.33668 (* 1 = 2.33668 loss)
I0505 16:34:23.324698 21364 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0505 16:34:29.131650 21364 solver.cpp:237] Iteration 3300, loss = 2.33755
I0505 16:34:29.131682 21364 solver.cpp:253]     Train net output #0: loss = 2.33755 (* 1 = 2.33755 loss)
I0505 16:34:29.131697 21364 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0505 16:34:34.940395 21364 solver.cpp:237] Iteration 3400, loss = 2.32939
I0505 16:34:34.940429 21364 solver.cpp:253]     Train net output #0: loss = 2.32939 (* 1 = 2.32939 loss)
I0505 16:34:34.940443 21364 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0505 16:34:40.748479 21364 solver.cpp:237] Iteration 3500, loss = 2.36022
I0505 16:34:40.748512 21364 solver.cpp:253]     Train net output #0: loss = 2.36022 (* 1 = 2.36022 loss)
I0505 16:34:40.748528 21364 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0505 16:34:46.557374 21364 solver.cpp:237] Iteration 3600, loss = 2.40449
I0505 16:34:46.557528 21364 solver.cpp:253]     Train net output #0: loss = 2.40449 (* 1 = 2.40449 loss)
I0505 16:34:46.557541 21364 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0505 16:34:52.367650 21364 solver.cpp:237] Iteration 3700, loss = 2.35856
I0505 16:34:52.367681 21364 solver.cpp:253]     Train net output #0: loss = 2.35856 (* 1 = 2.35856 loss)
I0505 16:34:52.367697 21364 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0505 16:34:58.172978 21364 solver.cpp:237] Iteration 3800, loss = 2.32796
I0505 16:34:58.173012 21364 solver.cpp:253]     Train net output #0: loss = 2.32796 (* 1 = 2.32796 loss)
I0505 16:34:58.173027 21364 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0505 16:35:03.982859 21364 solver.cpp:237] Iteration 3900, loss = 2.34586
I0505 16:35:03.982892 21364 solver.cpp:253]     Train net output #0: loss = 2.34586 (* 1 = 2.34586 loss)
I0505 16:35:03.982908 21364 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0505 16:35:09.735986 21364 solver.cpp:341] Iteration 4000, Testing net (#0)
I0505 16:35:42.820040 21364 solver.cpp:409]     Test net output #0: accuracy = 0.161593
I0505 16:35:42.820211 21364 solver.cpp:409]     Test net output #1: loss = 2.33473 (* 1 = 2.33473 loss)
I0505 17:00:14.225087 21364 solver.cpp:237] Iteration 4000, loss = 2.38693
I0505 17:00:14.225280 21364 solver.cpp:253]     Train net output #0: loss = 2.38693 (* 1 = 2.38693 loss)
I0505 17:00:14.225294 21364 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0505 17:00:20.037641 21364 solver.cpp:237] Iteration 4100, loss = 2.34786
I0505 17:00:20.037673 21364 solver.cpp:253]     Train net output #0: loss = 2.34786 (* 1 = 2.34786 loss)
I0505 17:00:20.037688 21364 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0505 17:00:25.851469 21364 solver.cpp:237] Iteration 4200, loss = 2.32773
I0505 17:00:25.851501 21364 solver.cpp:253]     Train net output #0: loss = 2.32773 (* 1 = 2.32773 loss)
I0505 17:00:25.851518 21364 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0505 17:00:31.661043 21364 solver.cpp:237] Iteration 4300, loss = 2.42198
I0505 17:00:31.661077 21364 solver.cpp:253]     Train net output #0: loss = 2.42198 (* 1 = 2.42198 loss)
I0505 17:00:31.661093 21364 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0505 17:00:37.474882 21364 solver.cpp:237] Iteration 4400, loss = 2.35477
I0505 17:00:37.474913 21364 solver.cpp:253]     Train net output #0: loss = 2.35477 (* 1 = 2.35477 loss)
I0505 17:00:37.474936 21364 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0505 17:00:43.289139 21364 solver.cpp:237] Iteration 4500, loss = 2.39236
I0505 17:00:43.289170 21364 solver.cpp:253]     Train net output #0: loss = 2.39236 (* 1 = 2.39236 loss)
I0505 17:00:43.289186 21364 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0505 17:00:49.101452 21364 solver.cpp:237] Iteration 4600, loss = 2.34949
I0505 17:00:49.101590 21364 solver.cpp:253]     Train net output #0: loss = 2.34949 (* 1 = 2.34949 loss)
I0505 17:00:49.101603 21364 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0505 17:00:54.912760 21364 solver.cpp:237] Iteration 4700, loss = 2.32514
I0505 17:00:54.912791 21364 solver.cpp:253]     Train net output #0: loss = 2.32514 (* 1 = 2.32514 loss)
I0505 17:00:54.912806 21364 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0505 17:01:00.722316 21364 solver.cpp:237] Iteration 4800, loss = 2.3867
I0505 17:01:00.722352 21364 solver.cpp:253]     Train net output #0: loss = 2.3867 (* 1 = 2.3867 loss)
I0505 17:01:00.722373 21364 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0505 17:01:06.536864 21364 solver.cpp:237] Iteration 4900, loss = 2.37044
I0505 17:01:06.536896 21364 solver.cpp:253]     Train net output #0: loss = 2.37044 (* 1 = 2.37044 loss)
I0505 17:01:06.536912 21364 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0505 17:01:12.288072 21364 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc_model_iter_5000.caffemodel
I0505 17:01:12.391661 21364 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc_model_iter_5000.solverstate
I0505 17:01:12.425793 21364 solver.cpp:341] Iteration 5000, Testing net (#0)
I0505 17:01:41.735405 21364 solver.cpp:409]     Test net output #0: accuracy = 0.16244
I0505 17:01:41.735587 21364 solver.cpp:409]     Test net output #1: loss = 2.32985 (* 1 = 2.32985 loss)
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
aprun: Apid 11124676: Caught signal Terminated, sending to application
